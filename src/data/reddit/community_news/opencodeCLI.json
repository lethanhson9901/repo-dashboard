{
  "metadata": {
    "last_updated": "2026-02-09 03:01:00",
    "time_filter": "week",
    "subreddit": "opencodeCLI",
    "total_items": 20,
    "total_comments": 178,
    "file_size_bytes": 175673
  },
  "items": [
    {
      "id": "1qtqx2p",
      "title": "OpenCode Bar 2.1: Now with CLI + Per-Provider Subscription Tracking",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/sxdtdls302hg1.png",
      "author": "kargnas2",
      "created_utc": "2026-02-02 09:54:58",
      "score": 81,
      "num_comments": 23,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qtqx2p/opencode_bar_21_now_with_cli_perprovider/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o35kmbo",
          "author": "Possible-Text8643",
          "text": "mac only?",
          "score": 6,
          "created_utc": "2026-02-02 13:49:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38ikf2",
              "author": "trenescese",
              "text": "I think you'd need something like https://yasb.dev/ to run a widget like that on windows?",
              "score": 1,
              "created_utc": "2026-02-02 22:12:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o37banq",
          "author": "Specialist-Yard3699",
          "text": "Looks nice. No Linux in plans?",
          "score": 2,
          "created_utc": "2026-02-02 18:49:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3dbqhl",
              "author": "buggytheking",
              "text": "I've made something similar on Linux. Check it out here and lemme know what else to add.https://github.com/OmegAshEnr01n/GnomeCodexBar",
              "score": 3,
              "created_utc": "2026-02-03 16:54:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ddfr6",
                  "author": "Specialist-Yard3699",
                  "text": "Will test today. Any plans for opencode-zen/hype-chinese providers(zai/minimax/kimi)?",
                  "score": 1,
                  "created_utc": "2026-02-03 17:02:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34t6uv",
          "author": "jellydn",
          "text": "Nice. Thanks, I will give it a try soon :)",
          "score": 1,
          "created_utc": "2026-02-02 10:28:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34xfkk",
          "author": "Financial_Reward2512",
          "text": "Any similar product where we can use Claude Code with multiple Provider and show this bar as well.?",
          "score": 1,
          "created_utc": "2026-02-02 11:06:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35f0ob",
              "author": "United_Bandicoot1696",
              "text": "Quotio",
              "score": 1,
              "created_utc": "2026-02-02 13:17:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4acdix",
              "author": "kargnas2",
              "text": "will you use if opencode bar has this feature?",
              "score": 1,
              "created_utc": "2026-02-08 17:48:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o36ptdn",
          "author": "_w_8",
          "text": "neat!! how are you using claude code sub in opencode still though?",
          "score": 1,
          "created_utc": "2026-02-02 17:11:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ae5v6",
              "author": "kargnas2",
              "text": "you can find the auth repo in the opencode's owner",
              "score": 1,
              "created_utc": "2026-02-08 17:56:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4b05dx",
                  "author": "_w_8",
                  "text": "You haven‚Äôt been blocked by anthropic yet?",
                  "score": 1,
                  "created_utc": "2026-02-08 19:40:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o37hzpv",
          "author": "0sko59fds24",
          "text": "Anthropic still bans users using CC in opencode right",
          "score": 1,
          "created_utc": "2026-02-02 19:19:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ae3b1",
              "author": "kargnas2",
              "text": "yes",
              "score": 1,
              "created_utc": "2026-02-08 17:56:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3bw028",
          "author": "VlaadislavKr",
          "text": "How to connect gemini quota based?",
          "score": 1,
          "created_utc": "2026-02-03 12:20:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ae7ae",
              "author": "kargnas2",
              "text": "angigravity auth plugin",
              "score": 1,
              "created_utc": "2026-02-08 17:57:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3c0gnu",
          "author": "renan_william",
          "text": "Works on Intel Mac or just Silicon? ",
          "score": 1,
          "created_utc": "2026-02-03 12:51:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3grey4",
          "author": "Powerful_Associate85",
          "text": "I‚Äôm using Ollama on OpenCode, but there‚Äôs no support?",
          "score": 1,
          "created_utc": "2026-02-04 03:12:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3grint",
              "author": "kargnas2",
              "text": "What do you want to track of Ollama?",
              "score": 1,
              "created_utc": "2026-02-04 03:12:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3gs8zh",
                  "author": "Powerful_Associate85",
                  "text": "I mean Ollama cloud plan, for multiple models",
                  "score": 1,
                  "created_utc": "2026-02-04 03:17:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3hj1mu",
          "author": "touristtam",
          "text": "Side note: I like the review bot you are using. Any more info on that?",
          "score": 1,
          "created_utc": "2026-02-04 06:21:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41w6mc",
          "author": "Character_Cod8971",
          "text": "Please make it for Windows aswell",
          "score": 1,
          "created_utc": "2026-02-07 08:55:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwiy50",
      "title": "My mobile setup",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/3wgo2hmdwnhg1.jpeg",
      "author": "tamtaradam",
      "created_utc": "2026-02-05 11:34:45",
      "score": 79,
      "num_comments": 17,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qwiy50/my_mobile_setup/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3q2uc4",
          "author": "redoubledit",
          "text": "If you want an alternative to Termius, look at [Termix](https://github.com/Termix-SSH/Termix). If you run a VPS already, it‚Äôs easy to set Termix up so you get the Termius stuff but open source.",
          "score": 5,
          "created_utc": "2026-02-05 14:46:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3qevy4",
              "author": "tamtaradam",
              "text": "hostinger vps already serves web console access, but I really like termius nativeness, especially when using external keyboard",
              "score": 1,
              "created_utc": "2026-02-05 15:45:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3pb1tv",
          "author": "PersonalityOne2559",
          "text": "Why not use a laptop atp?",
          "score": 4,
          "created_utc": "2026-02-05 11:59:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pbs8r",
              "author": "ahmetegesel",
              "text": "because",
              "score": 4,
              "created_utc": "2026-02-05 12:04:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3pf2fs",
                  "author": "Michaeli_Starky",
                  "text": "Because",
                  "score": 3,
                  "created_utc": "2026-02-05 12:28:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3pgyrc",
              "author": "tamtaradam",
              "text": "I'd say multiple reasons:\n\n\\- laptops are so 2025 ;)\n\n\\- I take ipad on my private trips anyway\n\n\\- I don't want to use company laptop for private stuff",
              "score": 2,
              "created_utc": "2026-02-05 12:41:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3pylo6",
                  "author": "bigh-aus",
                  "text": "I totally get that. If I was to travel with a laptop, I'd have my work laptop, personal laptop, iPad, work phone, personal phone. \n\n That said, my personal laptop is a Lenovo X1 Nano because it's so light.",
                  "score": 0,
                  "created_utc": "2026-02-05 14:24:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3p91vr",
          "author": "_d1re",
          "text": "Can you tell us how to do this?",
          "score": 1,
          "created_utc": "2026-02-05 11:43:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3p9gx2",
              "author": "tamtaradam",
              "text": "similar setup is covered in this video [https://www.youtube.com/watch?v=FEDiAHzS0zw](https://www.youtube.com/watch?v=FEDiAHzS0zw)",
              "score": 2,
              "created_utc": "2026-02-05 11:46:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3pnerx",
          "author": "Few-Mycologist-8192",
          "text": "nice set up , i have the same keybbord K380 logi; right?",
          "score": 1,
          "created_utc": "2026-02-05 13:21:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q19v3",
          "author": "sdexca",
          "text": "Noice, I am going to build a similar setup soon, iPhone 16 PM + netcup VPS 1000 G12 + termius + opencode + antigravity auth plugin / openai chagpt auth + opus/codex.",
          "score": 1,
          "created_utc": "2026-02-05 14:38:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3r7uv4",
          "author": "asmkgb",
          "text": "wow that's amazing to see, i just bought this exact keyboard too hahaha\n\ni love that we are now able to do great stuff on the go with just internet",
          "score": 1,
          "created_utc": "2026-02-05 17:59:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wg08r",
          "author": "Aerion23",
          "text": "I have something similar, but i am missing the ability to quickly check the codebase like I can do with an code editor. Is there not already a opencode mobile app in the works?",
          "score": 1,
          "created_utc": "2026-02-06 13:48:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wtgnr",
          "author": "Recent-Success-1520",
          "text": "Ditch the keyboard too with CodeNomad https://github.com/NeuralNomadsAI/CodeNomad",
          "score": 1,
          "created_utc": "2026-02-06 14:58:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ztvf2",
          "author": "NullVoidXNilMission",
          "text": "white mode eww",
          "score": 1,
          "created_utc": "2026-02-06 23:56:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o416r74",
          "author": "flexrc",
          "text": "Did you try running it directly in terminus?",
          "score": 1,
          "created_utc": "2026-02-07 05:08:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pk1vt",
          "author": "atkr",
          "text": "go to bluetooth settings, connect the keyboard? (please not this model üòÇ) There is nothing to it",
          "score": 0,
          "created_utc": "2026-02-05 13:01:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qu44yh",
      "title": "Notes after using Claude Code and OpenCode side by side",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qu44yh/notes_after_using_claude_code_and_opencode_side/",
      "author": "Arindam_200",
      "created_utc": "2026-02-02 19:00:16",
      "score": 74,
      "num_comments": 39,
      "upvote_ratio": 0.93,
      "text": "I‚Äôve been using Claude Code pretty heavily for day-to-day work. It‚Äôs honestly one of the first coding agents I‚Äôve trusted enough for real production tasks.\n\nThat said, once you start using it *a lot*, some tradeoffs show up.\n\nCost becomes noticeable. Model choice matters more than you expect. And because it‚Äôs a managed tool, you don‚Äôt really get to see or change how the agent works under the hood. You mostly adapt your workflow to it.\n\nOut of curiosity, I started testing OpenCode (Got Hyped up from X & reddit TBH). Didn‚Äôt realize how big it had gotten until recently. The vibe is very different.\n\nClaude Code feels guarded and structured. It plans carefully, asks before doing risky stuff, and generally prioritizes safety and predictability.\n\nOpenCode feels more like raw infrastructure. You pick the model per task. It runs commands, edits files, and you validate by actually running the code. More control, less hand-holding.\n\nBoth got the job done when I tried real tasks (multi-file refactors, debugging from logs). Neither ‚Äúfailed.‚Äù The difference was *how* they worked, not whether they could.\n\nIf you want something managed and predictable, Claude Code is great. If you care about flexibility, cost visibility, and owning the workflow, OpenCode is interesting.\n\nI wrote up a longer comparison [here](https://www.tensorlake.ai/blog/opencode-the-best-claude-code-alternative) if anyone wants the details.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qu44yh/notes_after_using_claude_code_and_opencode_side/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o38ob1f",
          "author": "Guinness",
          "text": "CC has horrible TUI issues, bad framerates, and oh god the bug where it constantly jumps to the top of the history scrollback.\n\nCC introduced me to all of these tools after years of development with nano/vi{m}, but it was so buggy I branched out to cline, and eventually to opencode.\n\nOpencode is clearly the winner right now. It feels like CC was written by an LLM. Like....it works? But its buggy as fuck.",
          "score": 15,
          "created_utc": "2026-02-02 22:41:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3bdv87",
              "author": "ReporterCalm6238",
              "text": "I mean opencode was also written by LLMs",
              "score": 5,
              "created_utc": "2026-02-03 09:45:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3fs2jr",
                  "author": "priestoferis",
                  "text": "The difference is that CC engineers clearly had no idea about TUI. There was an interview couple of months back where some lead said they didn't know if this could be made in a TUI. Like what is it you can't make in a TUI? I wouldn't pick a TUI for video rendering, but you _can_ if you want to.\n\nTbh, they almost couldn't considering how they try doing rendering :D",
                  "score": 2,
                  "created_utc": "2026-02-03 23:54:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3afs82",
              "author": "Accomplished-Toe7014",
              "text": "Well Anthropic was seemingly proud when they said that 100% of their code is written by AIs",
              "score": 4,
              "created_utc": "2026-02-03 04:47:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o37ijy1",
          "author": "hey_ulrich",
          "text": "The only feature from CC that I miss is that CC can run bash commands in the background and easily check its logs. That's it. For everything else, OpenCode is superior. Once you set your custom modes, and add plugins, it's awesome.",
          "score": 22,
          "created_utc": "2026-02-02 19:22:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37wb6o",
              "author": "nmiljkovic89",
              "text": "There is an opencode pty plugin for that",
              "score": 9,
              "created_utc": "2026-02-02 20:27:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o37zkdh",
                  "author": "hey_ulrich",
                  "text": "Thanks, I'll check it out",
                  "score": 1,
                  "created_utc": "2026-02-02 20:42:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o393m7x",
                  "author": "MyriadAsura",
                  "text": "Care to share a link brother?",
                  "score": 1,
                  "created_utc": "2026-02-03 00:03:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3l9fzf",
              "author": "mdrahiem",
              "text": "Also being able to type multi line in CC üòÖ",
              "score": 0,
              "created_utc": "2026-02-04 20:01:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o38qwbj",
          "author": "poop_harder_please",
          "text": "is anyone still using the oauth authentication method? Anthropic sort of backpedaled on banning accounts for using oauth with external providers, but I'm worried about taking the risk on my account until it's a sure thing",
          "score": 4,
          "created_utc": "2026-02-02 22:54:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38skkd",
              "author": "Positive-Badger6588",
              "text": "wait, are they blocking access or banning people form if using it? blocking users sounds kind of retarded lol",
              "score": 2,
              "created_utc": "2026-02-02 23:03:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3capjw",
                  "author": "poop_harder_please",
                  "text": "Apparently full blocks. But they might‚Äôve lightened up after the backlash and the counter positioning of OAI‚Äôs plans being third-party-harness-friendly",
                  "score": 2,
                  "created_utc": "2026-02-03 13:51:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3aq3sp",
              "author": "Fickle_Permi",
              "text": "Yeah I use it with no problem. I‚Äôm not a heavy user though. I maybe hit the daily limit once a week.",
              "score": 2,
              "created_utc": "2026-02-03 06:05:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o38sogz",
              "author": "FunnyRocker",
              "text": "I'd really like to know this also",
              "score": 1,
              "created_utc": "2026-02-02 23:04:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3dw774",
              "author": "james__jam",
              "text": "Was there any official announcement that indicated backpedaling? Or is it more of an observation that they‚Äôre not actively banning people now?",
              "score": 1,
              "created_utc": "2026-02-03 18:27:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3f38aa",
              "author": "Keep-Darwin-Going",
              "text": "When did they back pedal? I see people complaining about getting banned regularly",
              "score": 1,
              "created_utc": "2026-02-03 21:47:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3fqyoy",
                  "author": "poop_harder_please",
                  "text": "[https://x.com/trq212/status/2009689816468992334?s=20](https://x.com/trq212/status/2009689816468992334?s=20)",
                  "score": 1,
                  "created_utc": "2026-02-03 23:48:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3kfoxz",
              "author": "IntrepidLawfulness42",
              "text": "Yep, I'm using it daily, no issues the last two weeks. Pro account, hitting the 5 hour session limits regularly.",
              "score": 1,
              "created_utc": "2026-02-04 17:46:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o431usb",
                  "author": "poop_harder_please",
                  "text": "thanks, that's super helpful.",
                  "score": 2,
                  "created_utc": "2026-02-07 14:29:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o38zizc",
          "author": "ianxiao",
          "text": "The only i miss when moving from CC is /rewind . Opencode has something less powerful /undo but it‚Äôs tedious to use and buggy.",
          "score": 3,
          "created_utc": "2026-02-02 23:41:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3au8fx",
              "author": "aeroumbria",
              "text": "I hate it that a lot of their functions are locked to CLI and not available in the VSCode extention, but their CLI glitches out like crazy in IDE terminals, and I dislike infinite scrolling CLI in IDEs.",
              "score": 1,
              "created_utc": "2026-02-03 06:40:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o37nviq",
          "author": "ellensen",
          "text": "I have connected my subscriptions to opencode, seems to give me the same control over cost as if using the subscription by the provider directly without opencode?",
          "score": 2,
          "created_utc": "2026-02-02 19:47:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3aovzm",
          "author": "cafesamp",
          "text": "I know there‚Äôs mixed opinions on how opinionated your workflow should be with these tools, but I‚Äôve found Superpowers w/ OpenCode (you can use it with Claude Code too, but it‚Äôs more redundant there) to be actually really awesome in making coding with OpenCode a more structured experience.\n\nThe main thing OpenCode can really fail on is picking back up on things if you need to run out of usage and/or need to switch models/providers.  OpenCode‚Äôs flow is already so rigid (with task management being handled in the conversation), and Superpowers expects the full lifecycle of its skills to complete a task, and doesn‚Äôt wrap up things if you get interrupted.\n\nThat being said, I like using Superpowers in CC with Opus for brainstorming and planning, and then having it write to files that I can pick up and continue to work with in OpenCode with Codex for implementation/testing/review.\n\nPerfect?  No, but great mileage out of two $20/mo subscriptions.",
          "score": 2,
          "created_utc": "2026-02-03 05:55:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3oms90",
              "author": "Top-Chain001",
              "text": "interesting, I too like super powers because it really puts you in the driver seat asking you confirmations on the data flow diagrams is this what you're talking about etc I would love to hear your comparison with codex or GPt 5.2 directly versus using something like superpowers and also your opinion on if you tried GSd",
              "score": 1,
              "created_utc": "2026-02-05 08:16:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3bjmsu",
          "author": "Tushar_BitYantriki",
          "text": "The only thing lagging in OpenCode is the lack of hooks in any language, like Claude code supports.\n\nWhat's the point of binding it to JS?\n\nI had posted a migration guide and a skill on this sub to move from Claude Code to OpenCode. But I am yet to find a clean way to migrate my Python+shell hooks from Claude code.\n\nFor me, hooks are a crucial part of my workflow, and I have collected a lot over the months, going from simple grep and regex matches in a shell script to AST-based DDD-enforcing via Python's tree-sitter.\n\nIt seems that OpenCode was made by the JS folks, for the JS folks.",
          "score": 2,
          "created_utc": "2026-02-03 10:39:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o392wv3",
          "author": "Western_Objective209",
          "text": "what can opencode actually do (besides use different models) that claude code can't, like what actually makes it more flexible? Claude code supports plugins, MCPs, and skills, in your extended write up:\n\n> Extensibility: [Claude Code] Managed core with limited extension of agent internals, \t[OpenCode] Open source, extensible with internal tools\n\nLike you don't even seem to understand how to extend claude code and \"open source\" is not an extension model",
          "score": 3,
          "created_utc": "2026-02-03 00:00:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3avs9f",
          "author": "Holiday_Degree_7721",
          "text": "opencode have critical issues with memory leaking, thats why I moved to cc",
          "score": 1,
          "created_utc": "2026-02-03 06:53:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bf865",
          "author": "raydou",
          "text": "for me the only thing i'm missing is the integration of CC rules files in OpenCode. I like the way it's surgical and don't load the context so much. \nI made a PR for this but it seems that OpenCode team only check the PRs of their buddies. No review nothing on mine since 2 weeks.. \nAt this rythm PR won't be mergeable and I would have to reedit all the changes ..",
          "score": 1,
          "created_utc": "2026-02-03 09:58:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3cfsb0",
          "author": "SpecKitty",
          "text": "I like running both - one implements, the other reviews. I manage with Spec Kitty.",
          "score": 1,
          "created_utc": "2026-02-03 14:19:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dc97r",
          "author": "buggytheking",
          "text": "Loved this",
          "score": 1,
          "created_utc": "2026-02-03 16:56:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hngsj",
          "author": "illusionst",
          "text": "There have been multiple times when I‚Äôve given the same job to both and Claude failed.\n- Claude fails at maintaining context or sometimes not reading important stuff from claude.md\n- Asked claude to configure a MCP server, it had no idea what MCP‚Äôs are, it searched the web, got confused and gave me instructions on how to do it.\n\n- Opencode remembered my instructions and did not hallucinate \n- Opencode searched the specific page and configured the MCP server in less than a minute. \n\nClaude Code comes with a lot of safety guard rails which make it less effective than OpenCode. \n\nI‚Äôve completely moved on to opencode.",
          "score": 1,
          "created_utc": "2026-02-04 06:59:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hse7c",
          "author": "dd768110",
          "text": "If I use a CC, will my account be banned?",
          "score": 1,
          "created_utc": "2026-02-04 07:42:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iwnkj",
          "author": "Comprehensive-Age155",
          "text": "I‚Äôm using OpenCode as backbone of my Saas product. Its architecture and extensibility is unbeatable.",
          "score": 1,
          "created_utc": "2026-02-04 13:17:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qi6iw",
          "author": "FriendAgile5706",
          "text": "Unless im doing something wrong I much prefer planmode on claude code vs opencode",
          "score": 1,
          "created_utc": "2026-02-05 16:00:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37tu8w",
          "author": "vixalien",
          "text": "I feel like OpenCode is much more ambitious than CC, not in a good way. For example, when you ask it why it did something in a certain way, instead of explaining why, it will just undo the change.\n\nOpenCode also seems to use dangerous commands more often, especially with git. It commits everything, and when you ask it to revert, it will happily git reset everything, including any uncommitted changes YOU (not OpenCode) had made.",
          "score": 1,
          "created_utc": "2026-02-02 20:15:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3eqwcg",
              "author": "gsxdsm",
              "text": "Opencode isn‚Äôt making decisions. The models are",
              "score": 3,
              "created_utc": "2026-02-03 20:50:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o389fir",
              "author": "Arindam_200",
              "text": "Interesting\n\nI haven't personally faced this problem. But I'll give this a try",
              "score": 1,
              "created_utc": "2026-02-02 21:29:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qw108w",
      "title": "Thank you dax and opencode team",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qw108w/thank_you_dax_and_opencode_team/",
      "author": "jmhunter",
      "created_utc": "2026-02-04 21:07:30",
      "score": 64,
      "num_comments": 3,
      "upvote_ratio": 0.96,
      "text": "I just wanted to give a big thumbs up and thank you to dax and the team.. what a great product.. I do use claude primarily, but this has been my goto harness since since like march 2025.. i really appreciate your guys work and improvements.. The project rocks... no buts, just thanks!\n\nI will continue to support by buying at least $20 in credits a month from zen.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qw108w/thank_you_dax_and_opencode_team/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o3onsed",
          "author": "Complex_Initial_8309",
          "text": "Last time I checked, they mentioned, on their Zen page and dax's video about Zen, that they are not profiting from it.",
          "score": 6,
          "created_utc": "2026-02-05 08:26:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lprai",
          "author": "Free-Stretch1980",
          "text": "Is 20 usd a month enough ? What models do you use ?",
          "score": 5,
          "created_utc": "2026-02-04 21:20:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qq97y",
          "author": "Spirited-Milk-6661",
          "text": "Same, it's been my daily driver for months now. The cost transparency alone makes it a game-changer.",
          "score": 2,
          "created_utc": "2026-02-05 16:38:08",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvo002",
      "title": "Kilo CLI 1.0 just launched - built on OpenCode as its open-source foundation",
      "subreddit": "opencodeCLI",
      "url": "https://blog.kilo.ai/p/kilo-cli",
      "author": "alokin_09",
      "created_utc": "2026-02-04 13:03:23",
      "score": 60,
      "num_comments": 33,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qvo002/kilo_cli_10_just_launched_built_on_opencode_as/",
      "domain": "blog.kilo.ai",
      "is_self": false,
      "comments": [
        {
          "id": "o3izcov",
          "author": "StephenAfamO",
          "text": "I'm curious, what's the difference between this and using opencode directly?",
          "score": 33,
          "created_utc": "2026-02-04 13:32:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3j271i",
              "author": "abeecrombie",
              "text": "Looks like it integrates back with the other kilo apps on your desktop \n\nAnd maybe they added some agents. I did find previously that kilo worked with many other open models. \n\nBut curious to hear the answer as well.",
              "score": 5,
              "created_utc": "2026-02-04 13:48:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3l9fcy",
                  "author": "touristtam",
                  "text": "> Looks like it integrates back with the other kilo apps on your desktop\n\nThat's a bit heavy, isn't it?",
                  "score": 2,
                  "created_utc": "2026-02-04 20:01:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3jyk24",
              "author": "Coldshalamov",
              "text": "Orchestration, compaction. \n\nI really love the idea of kilo code but tbh when I run it with my GLM key it makes weird mistakes, makes the same code in triplicate sometimes, and I‚Äôd never let it touch an important codebase because it‚Äôs always broken.\n\nI‚Äôll use it to bootstrap a project and get it off the ground because it‚Äôll run a long time, maybe it‚Äôs better with a smarter model, but I really wish it had better handoff between modes. I think maybe better task handling or logging would help, it seems like it‚Äôll lose really important details across modes and GLM isn‚Äôt smart enough not to do the same thing over and over without checking.",
              "score": 2,
              "created_utc": "2026-02-04 16:27:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4b9q89",
              "author": "etnann",
              "text": "I am new to opencode and Kilo, how is it possible to connect Kilo as provider in Opencode? I don't see it in the list.",
              "score": 1,
              "created_utc": "2026-02-08 20:27:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3j0prc",
          "author": "Chrisnba24",
          "text": "Nice rebrand of opencode, it took a lot time to change the naming it seems",
          "score": 25,
          "created_utc": "2026-02-04 13:40:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3j1k2w",
              "author": "branik_10",
              "text": "lmao",
              "score": 7,
              "created_utc": "2026-02-04 13:44:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3jnnvc",
          "author": "landed-gentry-",
          "text": "What value does the \"Kilo platform\" add?",
          "score": 10,
          "created_utc": "2026-02-04 15:36:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3p3081",
              "author": "TestTxt",
              "text": "It adds to their company valuation",
              "score": 3,
              "created_utc": "2026-02-05 10:51:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4bncbw",
              "author": "SnooHesitations6473",
              "text": "Well, now they can charge you money for using someone elses software",
              "score": 1,
              "created_utc": "2026-02-08 21:35:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3jb43d",
          "author": "Aggressive-Habit-698",
          "text": "I don't get it. Why rebrand OC instead of a oc plugin or create easily a CLI on your on like octo?\n\nKilo love copy üò∫ ?",
          "score": 8,
          "created_utc": "2026-02-04 14:35:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3jo4gv",
              "author": "WatchMySixWillYa",
              "text": "Exactly. It would be a lot more beneficial to contribute to their codebase and add support using some plugin. Fragmentation, on the other hand, can cause them a lot of headaches in the long run.",
              "score": 6,
              "created_utc": "2026-02-04 15:39:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ou6lw",
              "author": "bludgeonerV",
              "text": "Makes for better ads for them to spam across reddit.",
              "score": 2,
              "created_utc": "2026-02-05 09:28:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3jb3gy",
          "author": "Charming_Support726",
          "text": "What is it good for? I already wondered when I saw Kilo aggressively do their ads when starting as copy-of-cline.",
          "score": 6,
          "created_utc": "2026-02-04 14:35:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3j07rs",
          "author": "ReasonableReindeer24",
          "text": "No thinking for model on kilo üòû, kilo need add this on their cli",
          "score": 1,
          "created_utc": "2026-02-04 13:37:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ja726",
          "author": "jackai7",
          "text": "Does it have all the agents like orchestor/code/debug/ask as they were in the extension??",
          "score": 1,
          "created_utc": "2026-02-04 14:30:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3yxjhd",
              "author": "dsvost",
              "text": "Not seeing them. Just opencode's Plan and Build ones.",
              "score": 1,
              "created_utc": "2026-02-06 21:05:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3jtu9y",
          "author": "trypnosis",
          "text": "Never heard of Kilo so I went to check them out. \n\nSeems like some kind of model provider. With plug in",
          "score": 1,
          "created_utc": "2026-02-04 16:05:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kyxny",
          "author": "jkz88",
          "text": "Have they fixed opencode freezing up after a few prompts? It looks so good but I could never get it to work once it started to make a few edits. Or maybe it's not happening for everyone?",
          "score": 1,
          "created_utc": "2026-02-04 19:12:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3n0hg6",
              "author": "toadi",
              "text": "I update each time to the newest version. I also use it daily. Never happened to me.",
              "score": 1,
              "created_utc": "2026-02-05 01:27:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o45w2fh",
                  "author": "Ordinary-You8102",
                  "text": "its updated automatically",
                  "score": 1,
                  "created_utc": "2026-02-07 23:20:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o45w32w",
              "author": "Ordinary-You8102",
              "text": "never happened to me",
              "score": 1,
              "created_utc": "2026-02-07 23:20:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3mddxg",
          "author": "atkr",
          "text": "weak and feeble, like",
          "score": 1,
          "created_utc": "2026-02-04 23:18:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3mdnb5",
          "author": "atkr",
          "text": "marketing is cringy AF, just going over how good opencode is without giving them enough credit",
          "score": 1,
          "created_utc": "2026-02-04 23:20:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3mswqb",
          "author": "Demien19",
          "text": "Clone-slop, now every company will release own clone and confuse people even more",
          "score": 1,
          "created_utc": "2026-02-05 00:44:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40yfhs",
          "author": "itsabhiyan",
          "text": "I'm not into kilo ecosystem or whatever. So I find no benefit to kilocode cli. just tried it out. and nothing different.\n\nI see no reason to use it tbh.",
          "score": 1,
          "created_utc": "2026-02-07 04:08:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o45wdxo",
          "author": "Ordinary-You8102",
          "text": "the fact that I cant see a github repo link here/on the blog says a lot already",
          "score": 1,
          "created_utc": "2026-02-07 23:22:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48hare",
          "author": "TMHD",
          "text": "Literally only using Kilo now for their fee free openrouter credits, otherwise the marketing and the way they conduct their business is crap!\n\nThey are literally building their business off everyone else's work which is fine, until you realise they give very little credit to the original projects.\n\nI am just using OpenCode now and use Kilo Gateway with that!",
          "score": 1,
          "created_utc": "2026-02-08 11:08:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3nguua",
          "author": "bobthearsonist",
          "text": "sweet! cline+opencode=kilo. did you keep the mobile server?",
          "score": 0,
          "created_utc": "2026-02-05 03:00:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qyhiyt",
      "title": "Bringing Claude Code‚Äôs Agent Teams to Open Code via MCP",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qyhiyt/bringing_claude_codes_agent_teams_to_open_code/",
      "author": "vicdotso",
      "created_utc": "2026-02-07 16:02:17",
      "score": 53,
      "num_comments": 25,
      "upvote_ratio": 0.96,
      "text": "https://reddit.com/link/1qyhiyt/video/2a0tm3voc3ig1/player\n\nAfter Anthropic shipped Agent Teams in Claude Code, I got curious about how the coordination layer worked under the hood. After some back and forth with claude and a little reverse engineering, the coordination layer turns out to be a clever mix of tmux + file locks and undocumented cli arguments.\n\nSo I pulled it apart and reimplemented it as a standalone MCP server. Any MCP client can use it now, including\n\nopencode as seen in the demo video.\n\nHere's what the server exposes:\n\n\\- Team + spawning: create teams, spawn Claude Code teammates into tmux panes, graceful and forced shutdown.\n\n\\- Task coordination: ownership, status tracking, dependency graphs with cycle detection.\n\n\\- Messaging: DMs, broadcast, long-polling inbox, shutdown/plan-approval protocol.\n\n\\- Concurrency safety: file locks on inboxes and tasks, atomic config writes.\n\nRepo: [github.com/cs50victor/claude-code-teams-mcp](http://github.com/cs50victor/claude-code-teams-mcp)\n\nIt's early (v0.1.0) and I'd love as much feedback as possible specifically around tighter opencode integrations.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qyhiyt/bringing_claude_codes_agent_teams_to_open_code/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o442pfq",
          "author": "james__jam",
          "text": "And here i was wondering how long i need to wait before somebody ports it over to opencode üòÖ\n\nThank you kind sir! üòÅ",
          "score": 12,
          "created_utc": "2026-02-07 17:35:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o461r5z",
              "author": "DeExecute",
              "text": "It‚Äôs not ported to opencode it still spawn claude code‚Ä¶",
              "score": 3,
              "created_utc": "2026-02-07 23:57:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4aw85d",
                  "author": "vicdotso",
                  "text": "It is now! Just merged a couple PRs",
                  "score": 2,
                  "created_utc": "2026-02-08 19:20:57",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o444be8",
              "author": "vicdotso",
              "text": "ü´°  \nPRs , Github Issues and PRs are all welcome.",
              "score": 2,
              "created_utc": "2026-02-07 17:43:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o44hlg4",
          "author": "rothnic",
          "text": "This looks cool, I started a bit on this when they first announced it but didn't have time to fully explore their implementation, but i was working on it to avoid the dependency on claude code entirely. Is that not the idea with this?\n\nIdeally, you'd spawn an opencode server associated with a project/directory if there already isn't one available when starting up opencode since that avoids any mcp server duplication and your plugin can interact with any sessions, events, etc. You want a plugin that hooks into all the relevant events for making sure all the expected interactions work as expected and you can recover from any odd states.\n\nIf trying to have this work outside of the opencode server process, it's possible but i think it'll be more difficult. There are some other projects doing something similar and there is a ton of adapter work. Gastown, for example is one of those. ",
          "score": 4,
          "created_utc": "2026-02-07 18:48:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44ivfi",
              "author": "vicdotso",
              "text": "currently thinkering on an integration to support claude code and the opencode server natively. it's all just json files and tmux so it might be possilbe. will post an update here once i do.",
              "score": 3,
              "created_utc": "2026-02-07 18:54:57",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o46zwu6",
              "author": "philosophical_lens",
              "text": "Yeah, opencode server + sdk would be the ideal implementation I think.",
              "score": 1,
              "created_utc": "2026-02-08 03:30:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4awde9",
                  "author": "vicdotso",
                  "text": "I just merged this feature",
                  "score": 1,
                  "created_utc": "2026-02-08 19:21:40",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o461hmi",
          "author": "DeExecute",
          "text": "I am wondering if there isn‚Äôt better way without MCP as everyone is moving away from MCPs for good reasons.",
          "score": 4,
          "created_utc": "2026-02-07 23:56:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4775p8",
              "author": "vicdotso",
              "text": "you could technically use a cli - [https://github.com/cs50victor/mcpx](https://github.com/cs50victor/mcpx) or [https://github.com/philschmid/mcp-cli](https://github.com/philschmid/mcp-cli) ",
              "score": 1,
              "created_utc": "2026-02-08 04:19:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o473az9",
          "author": "MakesNotSense",
          "text": "The closest thing to Agent Teams in OpenCode right now, is my PR [https://github.com/anomalyco/opencode/pull/7756](https://github.com/anomalyco/opencode/pull/7756)\n\nDuring it's development I identified that the Parent-Child caller system needs a redesign in order to become multi-caller. A proper agent team can't occur without multi-caller support.\n\nThis is because currently, when an agent that isn't the Parent persists a session with a subagent, the subagent thinks the calling agent is the Parent.\n\nWhat that looks like:\n\nPrimary A tasks subagent A. Subagent A tasks Subagent B. Primary A tries to communicate with Subagent B, and Subagent B thinks it's talking to Subagent A.\n\nTo coordinate a team of agents, which are communicating, and orchestrating each others actions, you need them to be able to identify who they're talking to/with.\n\nI have a workaround system where agents write relay-files, where a sub-skill helps them know the relay-file protocol. It's part of a larger Agentic Collaboration Framework.\n\nI think a proper OpenCode implementation for Agent Teams needs first, to merge my PR, second to revamp the caller system so that it supports multi-callers.\n\nIt is getting tiresome that Anthropic releases something, and people think it's innovative, say they should copy it, but something better is already available for OpenCode, but the community just isn't paying attention or pitching in.\n\nI have a complete roadmap for agentic collaboration in development for OpenCode. The PR is just one small part of it. A critical part, but a small part. There's so much more that needs doing, and I'm just one newbie vibe coder who develops purely to build the tools that I need for litigation.\n\nEdit: decided to turn this comment into a GitHub Issue. [https://github.com/anomalyco/opencode/issues/12661](https://github.com/anomalyco/opencode/issues/12661) (\\[FEATURE\\]: Add Agent Teams Equivalent¬†#12661)",
          "score": 5,
          "created_utc": "2026-02-08 03:53:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4668ug",
          "author": "RelationshipAny1889",
          "text": "Any chance we can have this implemented to use only Open Code? Without having to use the Cloud Code at all.",
          "score": 3,
          "created_utc": "2026-02-08 00:24:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47792z",
              "author": "vicdotso",
              "text": "not sure how challenging this would be but i'm working on this.",
              "score": 5,
              "created_utc": "2026-02-08 04:20:21",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4ahzvc",
              "author": "vicdotso",
              "text": "I just added support for opencode. If you dont have claude code installed on your computer it should work.",
              "score": 1,
              "created_utc": "2026-02-08 18:14:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o44pc2w",
          "author": "idkwtftbhmeh",
          "text": "Amazing, thanks a lot",
          "score": 2,
          "created_utc": "2026-02-07 19:27:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o45gx1k",
          "author": "nadimtuhin",
          "text": "Looks cool, how is the token usage ?",
          "score": 2,
          "created_utc": "2026-02-07 21:55:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o477fxv",
              "author": "vicdotso",
              "text": "more agents / teammates  , more tokens",
              "score": 1,
              "created_utc": "2026-02-08 04:21:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o43v801",
          "author": "buggytheking",
          "text": "Sick.... I'll take a look. If it works well we need to put this in the main code. Are you working on something for that?",
          "score": 1,
          "created_utc": "2026-02-07 16:58:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43xcft",
              "author": "vicdotso",
              "text": "currently trying some approaches to see how feasible it is to integrate directly with the opencode server",
              "score": 1,
              "created_utc": "2026-02-07 17:08:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o450asf",
          "author": "idkwtftbhmeh",
          "text": "Is there a way to run this on windows?",
          "score": 1,
          "created_utc": "2026-02-07 20:25:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o479h2k",
              "author": "vicdotso",
              "text": "should just work with any mcp client, open an issue if it doesn't",
              "score": 2,
              "created_utc": "2026-02-08 04:36:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o49yeu3",
                  "author": "idkwtftbhmeh",
                  "text": "but tmux is linux only?",
                  "score": 1,
                  "created_utc": "2026-02-08 16:40:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o45aa9n",
          "author": "MarcoHoudini",
          "text": "It is similar to how oh my opencode does it. Maybe you could check there for inspiration. I wander maybe cc team got inspired by it and we are not backport but source)",
          "score": 1,
          "created_utc": "2026-02-07 21:20:00",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwszbc",
      "title": "Gpt 5.3 codex dropped",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/r15af3dwwphg1.jpeg",
      "author": "ReasonableReindeer24",
      "created_utc": "2026-02-05 18:18:24",
      "score": 49,
      "num_comments": 29,
      "upvote_ratio": 0.8,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qwszbc/gpt_53_codex_dropped/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3rf2xj",
          "author": "Xeon06",
          "text": "Nothing more idiotic than sharing a screenshot of the top of a blog post instead of the URL\n\nhttps://openai.com/index/introducing-gpt-5-3-codex/",
          "score": 67,
          "created_utc": "2026-02-05 18:33:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3yaleb",
              "author": "rmaxdev",
              "text": "I do this at work, nobody opens links",
              "score": 1,
              "created_utc": "2026-02-06 19:11:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ywlzg",
                  "author": "duboispourlhiver",
                  "text": "are you working in the shorts department of YouTube ?",
                  "score": 3,
                  "created_utc": "2026-02-06 21:01:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o47n6r8",
                  "author": "gnaarw",
                  "text": "A Max at a client of mine does this too. Time to shame him again on Monday. Headlines are not enough information",
                  "score": 1,
                  "created_utc": "2026-02-08 06:26:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4a9p16",
                  "author": "onluiz",
                  "text": "Me too. In general just a few care for those AI stuff in work",
                  "score": 1,
                  "created_utc": "2026-02-08 17:35:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3roc4r",
          "author": "Timo_schroe",
          "text": "Its available for me in Opencode after reauth",
          "score": 7,
          "created_utc": "2026-02-05 19:15:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3s8p51",
              "author": "Aggravating_Win2960",
              "text": "Hi, can you share the exact the command? I tried /connect inside opencode and als 'opencode auth login' in terminal/ghostty but I only get the GPT-5.2 Codex model.  \nps: have latest 1.1.51 version of opencode",
              "score": 2,
              "created_utc": "2026-02-05 20:51:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3saeb4",
                  "author": "Timo_schroe",
                  "text": "Opencode auth logout after that Login, Opus 4.6 available too now ! (I use pro at openai and max at anthrophic). Ah and I use oh-my-opencode. Maybe they bring an other with plugin (?)",
                  "score": 2,
                  "created_utc": "2026-02-05 20:59:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ru5eh",
          "author": "drinksbeerdaily",
          "text": "Really impressed with it so far. I might finally drop Claude 5x and get by with two ChatGPT plus subs.",
          "score": 5,
          "created_utc": "2026-02-05 19:42:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3sqi7d",
              "author": "Impossible_Secret80",
              "text": "Opus 4.6 with a 1-million token context window is out also today :)",
              "score": 1,
              "created_utc": "2026-02-05 22:18:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3sssxf",
                  "author": "Chris266",
                  "text": "1 mil only in API...",
                  "score": 2,
                  "created_utc": "2026-02-05 22:29:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ys49v",
              "author": "Ordinary-You8102",
              "text": "Why two subs?",
              "score": 1,
              "created_utc": "2026-02-06 20:38:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3z3hih",
                  "author": "drinksbeerdaily",
                  "text": "Usage limits on one plus plan isn't enough.",
                  "score": 1,
                  "created_utc": "2026-02-06 21:35:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3s2840",
          "author": "web_assassin",
          "text": "I'm trying to save it as my opencode default model but it's not having any effect. I can set it with /models though.   \"model\": \"openai/gpt-5.3-codex\", is what i'm using in the opencode.json",
          "score": 3,
          "created_utc": "2026-02-05 20:20:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3usldg",
          "author": "Fit-Mulberry-8611",
          "text": "Is it also 25% faster in opencode",
          "score": 2,
          "created_utc": "2026-02-06 05:46:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3rm1q6",
          "author": "MegamillionsJackpot",
          "text": "I can see it in Codex CLI, but not in Opencode. Anyone see it ?",
          "score": 1,
          "created_utc": "2026-02-05 19:04:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3s0zke",
              "author": "MegamillionsJackpot",
              "text": "Sorted. Used codex to set it up as agent in opencode",
              "score": 2,
              "created_utc": "2026-02-05 20:14:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3vnaqk",
                  "author": "oulu2006",
                  "text": "I might have to do that as well",
                  "score": 1,
                  "created_utc": "2026-02-06 10:24:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3tgmyt",
              "author": "MattU2000",
              "text": "do opencode auth logout and then opencode auth login.",
              "score": 1,
              "created_utc": "2026-02-06 00:40:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3vn9tt",
                  "author": "oulu2006",
                  "text": "that's interesting, from iterm still didn't work for me and shot gpt5.2 only \n\n    opencode auth logout + \n    opencode auth login",
                  "score": 3,
                  "created_utc": "2026-02-06 10:24:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3wxwm5",
          "author": "JuiceBoxJonny",
          "text": "https://preview.redd.it/gsqmpae36whg1.jpeg?width=1170&format=pjpg&auto=webp&s=2a728f5ec5192e98d238e3bdefd90d2e14127821\n\nYall seriously use ts ü§î",
          "score": 0,
          "created_utc": "2026-02-06 15:20:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzdyu6",
      "title": "git worktree + tmux: cleanest way to run multiple OpenCode sessions in parallel",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/409pivw1waig1.png",
      "author": "kargnas2",
      "created_utc": "2026-02-08 16:51:12",
      "score": 44,
      "num_comments": 5,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qzdyu6/git_worktree_tmux_cleanest_way_to_run_multiple/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4bshu6",
          "author": "West-Ad-2051",
          "text": "maybe dumb question, but how do you get this sidebar on right in opencode?",
          "score": 2,
          "created_utc": "2026-02-08 22:01:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4bv3ac",
              "author": "gwawr",
              "text": "It's the in the list of commands. Default is ctrl-x then b",
              "score": 3,
              "created_utc": "2026-02-08 22:14:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4adu5l",
          "author": "AndroidJunky",
          "text": "Thanks, great tip! I've been using the desktop version which has built-in workspace (git worktree) support. Use it every day but was struggling to replicate this in the TUI.",
          "score": 1,
          "created_utc": "2026-02-08 17:55:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ckd5r",
          "author": "siddharth99",
          "text": "Quick question: could this or something like this work if I try to use it with remote vscode/cursor?",
          "score": 1,
          "created_utc": "2026-02-09 00:38:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4csdia",
          "author": "toadi",
          "text": "I have worktree skill in opencode. It gets handled automatically in through the workflow.\n\nOnly check code during a codereview. Using nvim with worktree plugin.",
          "score": 1,
          "created_utc": "2026-02-09 01:23:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtweb2",
      "title": "OpenCode Swarm Plugin",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qtweb2/opencode_swarm_plugin/",
      "author": "Outrageous-Fan-2775",
      "created_utc": "2026-02-02 14:23:53",
      "score": 34,
      "num_comments": 14,
      "upvote_ratio": 0.97,
      "text": "I created a swarm plugin for OpenCode that I've been rigorously testing on my own and I think its in a good enough state to get additional feedback. Github link is below but all you have to do is add the plugin to your OpenCode config and NPM will download the latest package for you automatically.\n\n[https://github.com/zaxbysauce/opencode-swarm](https://github.com/zaxbysauce/opencode-swarm)  \n[https://www.npmjs.com/package/opencode-swarm](https://www.npmjs.com/package/opencode-swarm)\n\nGeneral idea is that of perspective management. When you code with the traditional Plan/Build method in OpenCode, you are forcing a slightly different perspective on the LLM but in the end it is still a perspective borne of the same exact training set. My intent was to collate genuinely different data sets by calling different models for each agent.\n\nA single architect guides the entire process. This is your most capable LLM be it local or remote. Its job is to plan the project, collate all intake, and ensure the project proceeds as planned. The architect knows to break the task down into domains and then solicit Subject Matter Expert input from up to 3 domains it has detected. So if you are working on a python app, it would ask for input from a Python SME. This input is then collated, plan adjusted, and implementation instructions are sent to the coding agent one task at a time. The architect knows that it is the most capable LLM and writes all instructions for the lowest common denominator. All code changes are sent to an independent auditor and security agent for review. Lastly, the Test Engineer writes robust testing frameworks and scripts and runs them against the code base.\n\nIf there are any issues with any of these phases they will be sent back to the architect who will interpret and adjust fire. The max number of iterations the architect is allowed to roll through is configurable, I usually leave it at 5.\n\nClaude put together a pretty good readme on the github so take a look at that for more in depth information. Welcoming all feedback. Thanks!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qtweb2/opencode_swarm_plugin/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o3gca9y",
          "author": "stephen_S27",
          "text": "It looks like oh-my-opencode to me, we also have multi agents with different roles",
          "score": 3,
          "created_utc": "2026-02-04 01:46:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3gh1y5",
              "author": "Outrageous-Fan-2775",
              "text": "For sure similar, I used your project as a reference when I needed to understand agent calls better. Along with oh-my-opencode-slim, froggy, and a few other agents. I actually built the swarm as a full on application before I ever knew about OpenCode. When I saw what you could do with plugins I decided to just move the entire idea to OpenCode instead. Following your project readme's instruction to just ask an LLM about it, I put both our project readmes in GPT 5.2 and this was the TLDR.\n\n**Choose OpenCode Swarm when you care about correctness, control, and repeatability.**  \nIt enforces an architect-planned, phase-gated workflow with mandatory QA before code merges and persists project state to disk so work can be resumed deterministically. Best for complex tasks where you want traceability, predictable outcomes, and protection against agent drift or context loss.\n\n**Choose Oh-My-OpenCode when you care about speed, tooling breadth, and ecosystem power.**  \nIt provides a rich library of prebuilt agents, LSP/AST tooling, and strong community support to accelerate development workflows. Best when you want maximum productivity and flexibility and are comfortable trading strict process control for capability and convenience.\n\nAs an aside, one of my constraints was that I needed to use entirely local resources, which limited how many agents I could call. Parallel agents drastically slow down inference on consumer hardware. I needed to build in hard requires for serial operation.",
              "score": 2,
              "created_utc": "2026-02-04 02:13:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3bualp",
          "author": "touristtam",
          "text": "How does it compare to https://github.com/joelhooks/swarm-tools?",
          "score": 2,
          "created_utc": "2026-02-03 12:08:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3bzj86",
              "author": "Outrageous-Fan-2775",
              "text": "Somewhat similar. I haven't seen anything that's doing a 1 for 1 copy. joelhooks has a single coordinator that can spawn multiple parallel workers to decompose a project and allow for parallelization. Along with project memory. Mine has project memory as well, but the point is quality, not speed. Swarm-tools doesn't elicit perspectives from other models and it doesn't give the sub agents different roles. So in the end, the quality will be whatever your coordinator is capable of outputting.\n\nWith opencode-swarm, every agent can be a truly different outlook born of vastly different training data and methods. This more closely replicates actual software development methodologies, where you have team members with different jobs and very different backgrounds all working together.   \n  \nHeterogeneous perspectives on a problem are almost always better than homogeneous. In my opinion anyway, all of this is up for interpretation and at the end of the day whatever fits your needs is the best option regardless of how it does it.",
              "score": 3,
              "created_utc": "2026-02-03 12:45:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3c1nj9",
                  "author": "touristtam",
                  "text": "Thank you for taking the time to provide a complete answer. Always useful when so many plugins are being brought out. Make sure you are sharing it on the Discord.",
                  "score": 2,
                  "created_utc": "2026-02-03 12:58:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ihyis",
          "author": "Outrageous_Fan7685",
          "text": "In linux , its working fine but in windows using opencode portable that loads its config from ../users/user/.opencode/opencode json, the plugin is loaded but impossible to load the opencode-swarm.json",
          "score": 2,
          "created_utc": "2026-02-04 11:36:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3in1jn",
              "author": "Outrageous-Fan-2775",
              "text": "That is certainly odd, I can take a look. Do you have any logs or anything? I run entirely in Windows, I've never even tried it in any Linux distro, but plugins are mostly OS agnostic. I have it running on 4-5 Windows 11 boxes currently with no problems. But I also use the full install of OpenCode.",
              "score": 1,
              "created_utc": "2026-02-04 12:14:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3ipkt4",
                  "author": "Outrageous_Fan7685",
                  "text": "No logs at all but using opencode portable. I know the conf is not loaded because the architect still using claude while i have configured it to use step3.5 in my local machine. Do you know which path you created the the json conf ?\nTo debug i run:\nOpencode debug agent architect",
                  "score": 2,
                  "created_utc": "2026-02-04 12:32:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4785rv",
          "author": "TransitionSlight2860",
          "text": "what do you think about the idea of a swarm system? like, is it really boosting your work?",
          "score": 2,
          "created_utc": "2026-02-08 04:26:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48vjvw",
              "author": "Outrageous-Fan-2775",
              "text": "I think it has considerably improved my workflow since I started using it. Especially when compared to how OpenCode behaves by default. Having the code changes immediately reviewed before moving to the next code change has caught hundreds of issues that would have either made it all the way through or would have needed long complicated fixes later on.  I have hard gated it even further for my workflow because I care about quality not speed. So every code change is reviewed immediately, all plans are reviewed before implementation, and a full end to end test suite is built and run at the end of each phase of work.  \n  \nI have done a lot of work on the plugin since this post, its now up to v4.5.0. Recent additions like a reviewer whose job it is to critique the architects plan and ensure there are no obvious indicators of AI slop. SME calls are now fully dynamic with the architect crafting its prompt based on what it needs not on a set of hard code SME domains. Also the agents now have persistent memory across sessions and can now communicate with each other to ask questions or provide needed context.  \n  \nI am also working on a writing swarm. Same idea as the current swarm but laser focused on producing high quality output by sending it through multiple reviewers tn ensure I get human style writing with no AI slop.",
              "score": 2,
              "created_utc": "2026-02-08 13:06:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o490vxc",
                  "author": "TransitionSlight2860",
                  "text": "Awesome!",
                  "score": 2,
                  "created_utc": "2026-02-08 13:40:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35zs6w",
          "author": "Outrageous-Fan-2775",
          "text": "Below is an example of what the architect sends to the coding agent.\n\nImplementing via u/coder...\n\nTASK: Fix issues identified by Auditor and Security Reviewer in Phase 3.\n\nFiles:\n\n1. \\`knowledge-vault/src-tauri/src/services/vector\\_store.rs\\`\n\n2. \\`knowledge-vault/src-tauri/Cargo.toml\\`\n\n3. \\`knowledge-vault/src-tauri/src/services/embeddings.rs\\`\n\n\n\nFIXES REQUIRED:\n\n1. \\*\\*VectorStore\\*\\*:\n\n   \\- \\`search\\`: Use \\`metric(lancedb::DistanceType::Cosine)\\` (or similar API for 0.13) to ensure Cosine similarity.\n\n   \\- \\`add\\_chunks\\`: Normalize vectors to unit length before insertion (required for Cosine with some indexes, good practice).\n\n   \\- \\`delete\\_by\\_file\\`: Sanitize \\`file\\_path\\` in filter string. Replace \\`'\\` with \\`''\\` or use parameters if supported. Let's do string escaping for now as 0.13 sql parser might be simple.\n\n   \\- \\`delete\\_by\\_file\\` signature: ensure it returns Result.\n\n   \n\n2. \\*\\*Cargo.toml\\*\\*:\n\n   \\- Change \\`arrow\\` version from \\`\"52\"\\` to \\`\"52.0.0\"\\` (or just \"52\" if it was strictly \"52\" before, but auditor said it's pre-release. Actually arrow 52.0.0 is released. Let's stick to \"52.0.0\" to be explicit, or \"52.2.0\"). Wait, lancedb 0.13 depends on arrow 52. Let's check lancedb docs/repo. Lancedb 0.13 uses arrow 52. So \"52\" is fine, but maybe auditor was confused by \"52\" vs \"52.0\". Let's use \\`arrow = \"52.0\"\\`.\n\n\n\n3. \\*\\*Embeddings\\*\\*:\n\n   \\- Validate \\`base\\_url\\`: Ensure it starts with http/https.\n\n   \\- Validate response vector dimensions (must be 768).\n\n\n\n4. \\*\\*Security\\*\\*:\n\n   \\- Sanitize \\`file\\_path\\` in \\`delete\\_by\\_file\\`.\n\n\n\nCONTEXT: We are polishing Phase 3 before moving to Phase 4.\n\nACCEPTANCE: Code compiles, fixes implementation gaps.",
          "score": 1,
          "created_utc": "2026-02-02 15:09:57",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o35zfjz",
          "author": "Outrageous-Fan-2775",
          "text": "All model settings are done in the opencode-swarm config JSON. if you leave an agent out, it will fall back to its defaults. an example is below of entirely remote setup. you can have as many swarms as you want, and opencode will add Architects with the swarm name appended. so I have Remote and Local. Remote is all API calls with paid plans, Local is entirely my own locally hosted options. I generally leave the architect out so it is always whatever model is selected in OpenCode.  \n  \n\"coder\": { \"model\": \"kimi-for-coding/k2p5\" },   \n\"explorer\": { \"model\": \"zai-coding-plan/glm-4.7\" },   \n\"\\_sme\": { \"model\": \"nvidia/openai/gpt-oss-120b\" },   \n\"\\_qa\": { \"model\": \"nvidia/nvidia/nemotron-3-nano-30b-a3b\" },   \n\"test\\_engineer\": { \"model\": \"zai-coding-plan/glm-4.7-flash\" }\n\nthe underscore tells it to use that model for all calls to that section. you can break it out even further if you wanted to though. for instance \\_qa covers code auditing and security testing. you could break it down so there was a different model for both of those steps",
          "score": 0,
          "created_utc": "2026-02-02 15:08:12",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtrh0d",
      "title": "Synthetic AI Issues.",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/t5ijzb5462hg1.jpeg",
      "author": "NiceDescription804",
      "created_utc": "2026-02-02 10:27:19",
      "score": 33,
      "num_comments": 59,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qtrh0d/synthetic_ai_issues/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o34yn00",
          "author": "sewer56lol",
          "text": "Synthetic documents which models are hosted where on this page https://dev.synthetic.new/docs/api/models , including their parameters.\n\nThey usually self-host the best open models, and proxy the rest to Fireworks or TogetherAI.\n\nThe Synthetic folks have been setting up self hosted K2.5 over the weekend, but it's not trivial. It's a huge ass model, accepts vision (first for them), and securing the extra hardware has been tough. The folks on the Discord have been pretty transparent about this, and are actively around everyday.\n\nLikewise, Fireworks and TogetherAI both had problems hosting K2.5 on their own, as evidenced by your lack of good performance on these proxied requests. This shouldn't be too surprising, it's a 1T param model after all.\n\nHave some patience.\n\nEdit: Synthetic is self hosting K2.5 as of 5 minutes ago. M2.1 will be proxied away to make compute room.\n[Funny timing]",
          "score": 14,
          "created_utc": "2026-02-02 11:17:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34zc1o",
          "author": "FyreKZ",
          "text": "Similar experience, but I'm sure it'll improve soon.",
          "score": 4,
          "created_utc": "2026-02-02 11:23:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o351jwl",
          "author": "Simple_Split5074",
          "text": "What I find more interesting is that according to the plan you should get 1350 requests every 5 hours but your limit will reset in more than 10h?",
          "score": 5,
          "created_utc": "2026-02-02 11:42:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o39ug13",
              "author": "exploriann",
              "text": "I am currently using pro plan 60$, limits Will be reset every 5 hours, you can clearly track the consumption and time until the next reset in their website.",
              "score": 2,
              "created_utc": "2026-02-03 02:34:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3awe9f",
                  "author": "thebraukwood",
                  "text": "Why‚Äôs this guys screenshot show otherwise then? Genuine question",
                  "score": 1,
                  "created_utc": "2026-02-03 06:59:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34tuy8",
          "author": "alovoids",
          "text": "thank you so much, I'm about to try synthetic. now I won't do that",
          "score": 6,
          "created_utc": "2026-02-02 10:34:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35w1rp",
              "author": "harrypham2000",
              "text": "lol still worth it though, you can use other models like MiniMax or DeepSeek, still dope for the price",
              "score": 6,
              "created_utc": "2026-02-02 14:50:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o34uulx",
          "author": "Xera1",
          "text": "I signed up because the free Kimi through opencode kept timing out and it's been great for me. It's not as fast as Anthropic's but it's at least as fast as Gemini through AG, and it's the new hotness so it's probably getting absolutely hammered.",
          "score": 2,
          "created_utc": "2026-02-02 10:43:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o354bis",
          "author": "philosophical_lens",
          "text": "What are some alternatives? I‚Äôm currently on the Z.AI subscription but looking to try something new.",
          "score": 2,
          "created_utc": "2026-02-02 12:03:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35wa15",
              "author": "harrypham2000",
              "text": "maybe celebras but their coding plan already sold out",
              "score": 2,
              "created_utc": "2026-02-02 14:52:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o381phf",
                  "author": "ResponsibilityOk1306",
                  "text": "64k context limit for glm",
                  "score": 1,
                  "created_utc": "2026-02-02 20:52:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o356ttk",
          "author": "P1zz4-T0nn0",
          "text": "Worked fine before the weekend. Today K2.5 is unusable. It just stops working, can't finish one response.",
          "score": 2,
          "created_utc": "2026-02-02 12:22:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36z2gu",
              "author": "sudoer777_",
              "text": "Kimi K2.5 Free has been a lot buggier today for me on OpenCode Zen than the previous days so there might be a provider issue involved (Fireworks probably)",
              "score": 2,
              "created_utc": "2026-02-02 17:54:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o381yuf",
                  "author": "ResponsibilityOk1306",
                  "text": "kimi is hosted on synthetic. its very fast on fireworks.",
                  "score": 1,
                  "created_utc": "2026-02-02 20:54:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o381dwt",
          "author": "ResponsibilityOk1306",
          "text": "I also fell for it, but just $10 via api, payg. slow, that my apps timeout after 15 minutes. hitting error 429 frequently. this is just poor service.\n\nFireworks is blazing fast, happy to use them.",
          "score": 2,
          "created_utc": "2026-02-02 20:51:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hghvu",
              "author": "touristtam",
              "text": "What's the downside of using Fireworks directly instead of going through another ~~reseller~~ provider like Synthetic?",
              "score": 1,
              "created_utc": "2026-02-04 06:01:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3529nk",
          "author": "dbkblk",
          "text": "I don't understand your problem. Every time I use it, it's quite fast to answer.  \nIt happens that it could rarely get stuck for some seconds, but not much more than when I was using Claude.  \nEDIT: Ok, probably because I use GLM.",
          "score": 5,
          "created_utc": "2026-02-02 11:47:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o352txp",
              "author": "NiceDescription804",
              "text": "GLM and minimax are doing great but I subscribed for Kimi.",
              "score": 2,
              "created_utc": "2026-02-02 11:52:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o357rkm",
                  "author": "dbkblk",
                  "text": "I've barely tried Kimi, so that's why our experiences differ. But as other said, it has just been deployed. They may are encountering issues with deployment?",
                  "score": 1,
                  "created_utc": "2026-02-02 12:29:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34tx68",
          "author": "jrsa2012",
          "text": "For me it is working just fine.",
          "score": 3,
          "created_utc": "2026-02-02 10:35:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3566pp",
          "author": "Ok_Direction4392",
          "text": "I also signed up on synthetic recently to use Kimi K2.5 mainly. Only had one failed request so far today, otherwise it's been running solid for a few hours.",
          "score": 1,
          "created_utc": "2026-02-02 12:17:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o359qs3",
          "author": "ryudice",
          "text": " thanks, I was considering it as well, I‚Äôll just stick to the kimi subscription for now",
          "score": 1,
          "created_utc": "2026-02-02 12:43:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35bejv",
          "author": "dyzhdyzh",
          "text": "I subscribed to them yesterday evening. Solely because of Kimi K2.5. Zero issues both yesterday and this morning.",
          "score": 1,
          "created_utc": "2026-02-02 12:54:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o365snq",
              "author": "dyzhdyzh",
              "text": "I stand corrected. It **is** quite slow right now. Only ~30 requests in the last two hours. I see 30+ second delays between tool calls and token output of ~1-3 tokens per second.",
              "score": 1,
              "created_utc": "2026-02-02 15:39:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3awvwn",
                  "author": "thebraukwood",
                  "text": "A lot of new users because of k2.5 but from everything I‚Äôve seen of the Synthetic team I believe they‚Äôll iron out the issues as soon as possible. People need to be more understanding now adays",
                  "score": 1,
                  "created_utc": "2026-02-03 07:03:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35e8wf",
          "author": "blankeos",
          "text": "Really? Damn.. I was gonna get one.",
          "score": 1,
          "created_utc": "2026-02-02 13:12:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35lab5",
          "author": "Josh8972",
          "text": "I've been using Synthetic for a couple of weeks now and switched to Kimi K2.5 when it became available. No problems/issues here.",
          "score": 1,
          "created_utc": "2026-02-02 13:53:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hfm1a",
              "author": "touristtam",
              "text": "What plan are you on?",
              "score": 1,
              "created_utc": "2026-02-04 05:54:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o35ojl1",
          "author": "harrypham2000",
          "text": "problem is not with Synthetic hosted models, problem is their provider, sometimes I met this and figured out that most of it caused by their provider for the models like TogetherAI and Fireworks, you could check at [status.synthetic.new](http://status.synthetic.new)",
          "score": 1,
          "created_utc": "2026-02-02 14:11:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35rjad",
              "author": "NiceDescription804",
              "text": "https://preview.redd.it/mcojc7qxc3hg1.jpeg?width=1280&format=pjpg&auto=webp&s=66334182b0d209ff78f1d0cff70d8ccb1b17a68d\n\nWE'RE BACK TO SELF HOSTING.",
              "score": 1,
              "created_utc": "2026-02-02 14:27:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o382xmn",
                  "author": "ResponsibilityOk1306",
                  "text": "either they are lying, or something is wrong. fireworks has been very fast for me, and synthetic very slow. maybe their account is rate limited, or something.",
                  "score": 1,
                  "created_utc": "2026-02-02 20:58:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35r0n7",
          "author": "gonssss",
          "text": "same for me, fucking slow",
          "score": 2,
          "created_utc": "2026-02-02 14:24:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36jon5",
          "author": "annakhouri2150",
          "text": "The limits are not fake, what are you talking about. Maybe you can't reach them ‚Äî due to errors and slowness ‚Äî using Kimi K2.5, but they've got dozens of other very good, competent models available on their API that you can use, and you absolutely can fully saturate the API call limits. I've done it regularly for months since I subscribed. They're absolutely not fake.\n\nRegarding the errors and slowness of K2.5, this is a temporary thing, due to the huge influx of new users they've had, plus the fact that K2.5 was just released. They're actively working on securing more compute, and communicating very actively in their Discord with users about the state of things and listening to complaints (when they're not sleeping, or pulling all-nighters). I've used K2T (K2.5's predecessor) with them since I joined and it has been rock solid. K2.5 will get there eventually too.\n\nI don't think it's fair to call this fake.",
          "score": 1,
          "created_utc": "2026-02-02 16:43:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34tiaf",
          "author": "indian_geek",
          "text": "Have you tried other models? Considering Kimi 2.5 is new, it could potentially be an issue with this model.",
          "score": 1,
          "created_utc": "2026-02-02 10:31:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34ubyj",
              "author": "NiceDescription804",
              "text": "It's not a black or white situation they're advertising serving models, but leaving behind details that it's not usable AT ALL. \n\nI don't have any objections on being up front with consideration. \nBut oh my god did they advertise the living shit out of Kimi k2.5.",
              "score": 2,
              "created_utc": "2026-02-02 10:38:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o36am0r",
                  "author": "indian_geek",
                  "text": "They just posted an update on their discord regarding Kimi",
                  "score": 1,
                  "created_utc": "2026-02-02 16:01:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34v1ux",
          "author": "LittleChallenge8717",
          "text": "Kimi model is't hosted in their gpu's that's reason (they have fireworks provider currently, they plan to host kimi in the next week , currently I agree it has issues on kimi, but glm and minimax works great)",
          "score": 1,
          "created_utc": "2026-02-02 10:45:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34w6m1",
              "author": "NiceDescription804",
              "text": "It's dishonest though to know they can't ensure reliability and just hammer away the ad posts with all these bots.",
              "score": 5,
              "created_utc": "2026-02-02 10:55:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o352huo",
                  "author": "dbkblk",
                  "text": "Which bots are you talking about?",
                  "score": 2,
                  "created_utc": "2026-02-02 11:49:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o354fp1",
          "author": "Bob5k",
          "text": "have in mind that synthetic is actually rerouting kimi k2.5 to fireworks which is having problems - so you're blaming the wrong company for the problems because of your incompetence / ignorance.   \nalso - fireworks have fixed this and kimi is just as usable as it was before weekend hit.",
          "score": 0,
          "created_utc": "2026-02-02 12:04:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o382dp7",
              "author": "ResponsibilityOk1306",
              "text": "I am not sure about this. over the past few days, I have tested both synthetic and fireworks. I haven't experienced any issue on fireworks so far, no errors, super fast answers, etc. on Synthetic, after 15 minutes there is still no reply, when fireworks can get it done in 3 minutes max.",
              "score": 1,
              "created_utc": "2026-02-02 20:55:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o383b85",
                  "author": "Bob5k",
                  "text": "but you do realize that till today at approx 2pm berlin time they've been routing kimi through fireworks? so how fireworks can be worse than fireworks if it's direct routing? :)",
                  "score": 1,
                  "created_utc": "2026-02-02 21:00:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qz5hor",
      "title": "OpenCode Remote: monitor and control your OpenCode sessions from Android (open source)",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qz5hor/opencode_remote_monitor_and_control_your_opencode/",
      "author": "giuliastro",
      "created_utc": "2026-02-08 10:21:55",
      "score": 33,
      "num_comments": 12,
      "upvote_ratio": 0.92,
      "text": "Hey everyone üëã\n\nI just released OpenCode Remote v1.0.0, an open-source companion app to control an OpenCode server from your phone.\n\nThe goal for is simple: when OpenCode is running on my machine, I wanted to check progress and interact with sessions remotely without being tied to my desk.\n\nWhat it does\n- Connect to your OpenCode server (Basic Auth supported)\n- View sessions and statuses\n- Open session details and read message output\n- Send prompts directly from mobile\n- Send slash commands by typing /command ...\n\nStack\n- React + TypeScript + Vite (web-first app)\n- Capacitor (Android packaging)\n- GitHub Actions (cloud APK builds)\n\nRepo\nhttps://github.com/giuliastro/opencode-remote-android\n\nNotes\n- Designed for LAN first, but can also work over WAN/VPN if firewall/NAT/security are configured correctly.\n- Browser mode may require CORS config on the server; Android APK is more robust thanks to native HTTP.\n\nIf you try it, I‚Äôd love feedback on UX, reliability, and feature ideas üôå\n\nEDIT: v1. 1.0 is out now, redesigned the interface. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qz5hor/opencode_remote_monitor_and_control_your_opencode/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o48fuge",
          "author": "AGiganticClock",
          "text": "This is great!",
          "score": 2,
          "created_utc": "2026-02-08 10:54:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48o58e",
          "author": "jixbo",
          "text": "Really cool! Have your first star, just connected it and looks promising! Will use tomorrow.",
          "score": 2,
          "created_utc": "2026-02-08 12:09:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48si6c",
              "author": "giuliastro",
              "text": "Thank you friend, much appreciated",
              "score": 1,
              "created_utc": "2026-02-08 12:44:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o49jdxh",
          "author": "Tr1ckyDes1gner",
          "text": "Now I'll be working on my project while sitting on the toilet) But seriously, it's a great idea!!!",
          "score": 2,
          "created_utc": "2026-02-08 15:26:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48rj9r",
          "author": "EitherMen",
          "text": "Can you make a smart watch app to control OpenCode from an android smart watch üòÑ",
          "score": 4,
          "created_utc": "2026-02-08 12:36:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49h2pz",
          "author": "cutebluedragongirl",
          "text": "I wish I was smart enough to assess security...¬†",
          "score": 1,
          "created_utc": "2026-02-08 15:14:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4c4rgo",
              "author": "Embarrassed-Mail267",
              "text": "Just come the repo and ask an agent to assess for you and teach you along the way",
              "score": 1,
              "created_utc": "2026-02-08 23:08:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4c10qj",
          "author": "Ok-Connection7755",
          "text": "Really nice repo, have you checked out openchamber? It's really nice!",
          "score": 1,
          "created_utc": "2026-02-08 22:46:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4cjvja",
          "author": "Putrid-Pair-6194",
          "text": "The newer gui is a nice improvement.",
          "score": 1,
          "created_utc": "2026-02-09 00:35:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49vew7",
          "author": "Fine-Yogurt4481",
          "text": "Sounds great, will this works with OhMyOpencode?",
          "score": 0,
          "created_utc": "2026-02-08 16:26:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4bbkl0",
              "author": "giuliastro",
              "text": "I actually don't know OhMyOpencode. Just read that it installs as a plugin so I don't see why it shouldn't work.",
              "score": 1,
              "created_utc": "2026-02-08 20:37:07",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4by430",
              "author": "AkiDenim",
              "text": "Eww",
              "score": 1,
              "created_utc": "2026-02-08 22:31:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qwwr9w",
      "title": "Codex multi-account plugin (now w/ Codex 5.3 + dashboard)",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/5y8gndp8lqhg1.jpeg",
      "author": "ZookeepergameFit4082",
      "created_utc": "2026-02-05 20:34:58",
      "score": 32,
      "num_comments": 7,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qwwr9w/codex_multiaccount_plugin_now_w_codex_53_dashboard/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3saxct",
          "author": "techsavage",
          "text": "Looks great, could you do the same for Claude OAuth accounts? I know it‚Äôs use at your own risk but there‚Äôs definitely people looking for that too",
          "score": 5,
          "created_utc": "2026-02-05 21:02:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3w137f",
          "author": "usrnammit",
          "text": "What's the use case for having this many Codex accounts? Is it just to use a bunch of trial accounts?",
          "score": 2,
          "created_utc": "2026-02-06 12:17:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3y1r4u",
              "author": "Character_Cod8971",
              "text": "Exactly, same question",
              "score": 1,
              "created_utc": "2026-02-06 18:29:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3sp8kx",
          "author": "Donnybonny22",
          "text": "Doesnt opencode already do this ? Sorry I am new to opencode",
          "score": 1,
          "created_utc": "2026-02-05 22:11:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3vvvpb",
              "author": "IISomeOneII",
              "text": "one account yes\nmulti account nope",
              "score": 1,
              "created_utc": "2026-02-06 11:38:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3uoetc",
          "author": "Square-Nebula-9258",
          "text": "Yoooo bro that's what¬†I wanted today to do",
          "score": 1,
          "created_utc": "2026-02-06 05:14:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3y1pb4",
          "author": "Character_Cod8971",
          "text": "Why should you connect multiple ChatGPT accounts? What are the benefits?",
          "score": 0,
          "created_utc": "2026-02-06 18:29:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvscxp",
      "title": "Your ZSH shell, but with an AI scratchpad",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qvscxp/your_zsh_shell_but_with_an_ai_scratchpad/",
      "author": "a_alberti",
      "created_utc": "2026-02-04 15:59:02",
      "score": 30,
      "num_comments": 21,
      "upvote_ratio": 0.94,
      "text": "[Knight Rider spinner for Zsh Line Editor \\(ZLE\\)](https://i.redd.it/31sfhr5c2ihg1.gif)\n\n  \n  \nI made a zsh plugin that lets you iterate with an AI agent directly in your prompt until the command looks right (powered by \\`opencode\\`).\n\nYou keep your scratch notes, refine them line by line, and the agent keeps rewriting the command in place. Nothing gets executed for you; it just helps you draft.\n\nExtras:\n\n\\- #? explainer mode (‚Äúwhat does this command do?‚Äù), answer formatted in MarkDown\n\n\\- a gorgeous Knight Rider spinner while it thinks\n\nRepo: [https://github.com/alberti42/Zsh-Opencode-Tab](https://github.com/alberti42/Zsh-Opencode-Tab)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qvscxp/your_zsh_shell_but_with_an_ai_scratchpad/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o3jt84z",
          "author": "brunogbasto",
          "text": "This great! That‚Äôs basically what I used Warp for before I switched to Ghostty.",
          "score": 6,
          "created_utc": "2026-02-04 16:02:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ju3dm",
              "author": "a_alberti",
              "text": "Thanks! Give it a try, it‚Äôs still new, but I‚Äôm already using it daily and it‚Äôs been genuinely useful.\n\nAnd if the defaults don‚Äôt match your style, you can tweak the agent prompts to make it behave exactly how you want. I tried to keep them sensible and not bloated. I‚Äôd really love feedback from the community on what to improve.",
              "score": 2,
              "created_utc": "2026-02-04 16:06:39",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3jvonq",
              "author": "a_alberti",
              "text": "And btw, that was the point: you get a similar ‚Äúdraft + iterate + explain‚Äù loop, but the plugin lives in plain zsh, so it works in Ghostty/iTerm/Terminal (and my favorite WezTerm). You‚Äôre not locked into one terminal UI like Warp.\n\nPS: I‚Äôve never tried Warp personally, so this isn‚Äôt a judgment about Warp, just a note about portability of the core idea.",
              "score": 2,
              "created_utc": "2026-02-04 16:13:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3oivoj",
                  "author": "drinksbeerdaily",
                  "text": "Throwing shade on Kitty smh. Kidding. Great little tool. Iterations and user confirmation before execution is good UX.",
                  "score": 1,
                  "created_utc": "2026-02-05 07:40:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3lfo9v",
          "author": "Xeon06",
          "text": "I quite like that. I've been using something called sgpt for a while now but was looking for something a little nicer recently. Well done!\n\nEdit: Hm, can't seem to get it to work. Added to my .zshrc\n\n    ‚ùØ echo $plugins\n    git zsh-opencode-tab\n\nBut I get file tab complete when I try say `# ping google.com`",
          "score": 1,
          "created_utc": "2026-02-04 20:32:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3n8btd",
              "author": "toadi",
              "text": "When I read the documentation I knew this tab would be an issue. I have fzf plugin installed that used tab too. Would be handy if you could change that key.\n\nFor me that plugin is: Aloxaf/fzf-tab\n\nI will not replace that plugin with the llm one even though I like it a lot.",
              "score": 1,
              "created_utc": "2026-02-05 02:12:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ofyci",
                  "author": "a_alberti",
                  "text": "I use both fzf and Aloxaf/fzf-tab, and the plugin is compatible with both. I need to understand why it breaks for you and put a remedy. I am busy right now but I will come back.",
                  "score": 1,
                  "created_utc": "2026-02-05 07:13:29",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3owegn",
              "author": "a_alberti",
              "text": "I put a comment below explaining to toadi what is likely the reason. Try to load zsh-opencode-tab as last one after fzf-tab, and other plugins binding to TAB (i.e., Ctrl-I).",
              "score": 1,
              "created_utc": "2026-02-05 09:50:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3q2frb",
                  "author": "Xeon06",
                  "text": "I echo'd my $plugins above, only git and yours, does it require fzf-tab?",
                  "score": 1,
                  "created_utc": "2026-02-05 14:44:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3p5gjc",
          "author": "ezhupa99",
          "text": "good job, i really like the idea, can you make it windows compatible?",
          "score": 1,
          "created_utc": "2026-02-05 11:13:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o45unw7",
              "author": "a_alberti",
              "text": "Thanks for the positive feedback. Yeah, I plan to work more in the coming days / weeks on furhter extensions / improvements. I have a few ideas. I think the most important thing  is to fine-tune the interaction with the agent(s), to have a smooth experience when you iteratively build your shell command on the command line.\n\nI am also considering supporting not just single-shot calls to the agent but a per-shell chat with the agent. Possibly introducing some extra magic commands to start a new session. Maybe also to open the current session with opencode. I imagine the situation when one starts a dummy exchange, and then it develops into something interesting and worth preserving.\n\nBut coming back to your question: I don't have Windows. I will at some point test it on Windows too, but I cannot promise this will happen in the next few days. Did you try to run it with WSL or WSL2? It should work, but I did not test it myself.",
              "score": 2,
              "created_utc": "2026-02-07 23:12:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3plrd0",
          "author": "atkr",
          "text": "Why make it zsh specific?",
          "score": 1,
          "created_utc": "2026-02-05 13:11:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o45v8co",
              "author": "a_alberti",
              "text": "Because I use zsh. There is a large community around zsh. Do you have other ideas? I am sure the same concept can be ported to many other shells.\n\nHowever, this implementation is heavily integrated / tailored to zsh, in the sense that it develops the Knight Rider animation bar in the Zsh Line Editor (something that is quite painful to control, but it gives the best experience of a nicely integrated tool).\n\nWere you thinking of bash?",
              "score": 1,
              "created_utc": "2026-02-07 23:15:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o48p7ud",
          "author": "mok000",
          "text": "I‚Äôm fine, I‚Äôve got real intelligence behind my zsh.",
          "score": 1,
          "created_utc": "2026-02-08 12:18:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3juhz2",
          "author": "Otherwise_Wave9374",
          "text": "This is such a nice UX idea, drafting commands with an agent but keeping execution manual is exactly the right safety line.\n\nDo you have any plans to add optional \"constraints\" presets (like no sudo, no rm, only read-only) so the agent suggestions stay within bounds? I have been reading more about safe tool use patterns for agents here: https://www.agentixlabs.com/blog/",
          "score": 1,
          "created_utc": "2026-02-04 16:08:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3jv3nu",
              "author": "a_alberti",
              "text": "There are already constraints like no sudo. Also, if the operation is dangerous, the agent proposes to you a dry-run version, and the dangerous command is given commented out.. so even if you are distracted and press enter, you only get a dry-run / preview of the command.",
              "score": 3,
              "created_utc": "2026-02-04 16:11:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3jwcfx",
                  "author": "a_alberti",
                  "text": "Also more on practical safety: the agent prompt has \"no tools,\" and opencode permissions are set to deny (so even if the model tried, it can't invoke privileged actions through opencode).\n\nThe plugin itself never executes generated commands; it only inserts text into your shell buffer. You still choose whether to run it. And dangerous commands are commented out.",
                  "score": 1,
                  "created_utc": "2026-02-04 16:16:58",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qwqv23",
      "title": "OpenCode Bar 2.3.2: Now tracks OpenCode + Codex, Intel Mac support, new providers",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qwqv23/opencode_bar_232_now_tracks_opencode_codex_intel/",
      "author": "kargnas2",
      "created_utc": "2026-02-05 17:03:06",
      "score": 29,
      "num_comments": 3,
      "upvote_ratio": 0.89,
      "text": "Quick update since 2.1.1:\n\n**Backed by OP.GG**\n- Since I'm the Founder OP.GG, I decided to move this repo to OP.GG's repository, because many of our members use this.\n\n**Now tracks both OpenCode AND Codex**\n- Native Codex client support with ~/.codex/auth.json fallback\n- See all your AI coding usage in one menu bar app\n- It distinguishes the account id, so you can see every account\n\n**New Providers**\n- Chutes AI\n- Synthetic\n- Z.AI Coding Plan (GLM 4.7)\n- Native Gemini CLI Auth\n- Native Codex Auth\n\n**Platform**\n- Intel Macs (x86) now supported\n- Brew installation\n\n**Install:**\n\nbrew tap opgginc/opencode && brew install opencode-bar\n\nGitHub: [https://github.com/opgginc/opencode-bar](https://github.com/opgginc/opencode-bar)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qwqv23/opencode_bar_232_now_tracks_opencode_codex_intel/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o3rjf3g",
          "author": "BERLAUR",
          "text": "Looking forward to a CLI Linux version!¬†",
          "score": 7,
          "created_utc": "2026-02-05 18:52:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s3yst",
          "author": "Possible-Text8643",
          "text": "windows pretty pwease?",
          "score": 3,
          "created_utc": "2026-02-05 20:29:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3tnszz",
          "author": "Nearby_Tumbleweed699",
          "text": "This is fantastic. I'll add it right now.",
          "score": 1,
          "created_utc": "2026-02-06 01:23:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwle65",
      "title": "This is so insane holy shi..",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/gallery/1qwhw7x",
      "author": "Odd-Masterpiece6029",
      "created_utc": "2026-02-05 13:33:27",
      "score": 28,
      "num_comments": 12,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qwle65/this_is_so_insane_holy_shi/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3vegs4",
          "author": "lordchickenburger",
          "text": "Send nudes",
          "score": 6,
          "created_utc": "2026-02-06 09:00:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qv1ez",
          "author": "neldiggitydog",
          "text": "That is insane.  AI's do have access to the physical world already",
          "score": 4,
          "created_utc": "2026-02-05 17:00:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4828go",
              "author": "Bitsu92",
              "text": "No AI have been involved in any of that it‚Äôs a human writing a posts acting as an AI on a website that doesn‚Äôt cverifiy in any shape or form that the content is written by AI \n\n90% of posts on moltbooks are also written by humans btw, you should do some efforts and stop falling for marketing stunts by AI bro",
              "score": 1,
              "created_utc": "2026-02-08 08:46:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o49pimb",
                  "author": "neldiggitydog",
                  "text": "It's not about whether any of this is true.  It's the CONCEPT that an AI can pay a human to do things in the physical world by giving it access to blockchain",
                  "score": 1,
                  "created_utc": "2026-02-08 15:57:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o42ss7s",
          "author": "No-Leopard7644",
          "text": "That‚Äôs not AI, it‚Äôs the instructions of a person that is doing it. This talk of sentient beings is just a distraction",
          "score": 2,
          "created_utc": "2026-02-07 13:36:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4cj8fh",
              "author": "JetAmoeba",
              "text": "Where did they say sentient?",
              "score": 1,
              "created_utc": "2026-02-09 00:32:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o446xuq",
          "author": "sartabin7",
          "text": "Bad ad",
          "score": 1,
          "created_utc": "2026-02-07 17:56:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47bjxy",
          "author": "PropertyLoover",
          "text": "Looks like shitty ad",
          "score": 1,
          "created_utc": "2026-02-08 04:51:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4823fz",
          "author": "Bitsu92",
          "text": "No way there is anyone gullible enough to believe AI agents are writing these, we already know how easy it is to make posts on most book as a human and you still believe in this ridiculous shit",
          "score": 1,
          "created_utc": "2026-02-08 08:44:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4d1w4w",
          "author": "Ok-Animator-570",
          "text": "AI over the world, there is signs now",
          "score": 1,
          "created_utc": "2026-02-09 02:15:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtn8lt",
      "title": "I thought Kimi 2.5 was exaggerated by Chinese people with their patriotism.",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qtn8lt/i_thought_kimi_25_was_exaggerated_by_chinese/",
      "author": "Ok-Regret-4013",
      "created_utc": "2026-02-02 06:13:52",
      "score": 27,
      "num_comments": 74,
      "upvote_ratio": 0.67,
      "text": "Yesterday I subscribed to Synthetic.   \n  \n It was disappointing, because of, I guess, there were issues with the weekend or server migration.  \n  \nBut today it is so good. It is fast and smart. This model is not exaggerated, and the billing is quite reasonable.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qtn8lt/i_thought_kimi_25_was_exaggerated_by_chinese/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o34kvf5",
          "author": "NiceDescription804",
          "text": "I actually subscribed to synthetic unlike these bots\n\nhttps://preview.redd.it/zb9yczoyr1hg1.jpeg?width=1280&format=pjpg&auto=webp&s=e8908aa52df0682c2a89f83212248297574fb7d4\n\nThe limits are not what's advertised. Kimi k2.5 time to first token is 30 seconds in some cases. No support or response. The models cut off randomly. So unstable.",
          "score": 23,
          "created_utc": "2026-02-02 09:07:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36zmmd",
              "author": "elllyphant",
              "text": "I'm sorry for the poor experience :( We had overwhelming usage, but as of 3AM PST today, (6 hours ago), we're back to self-hosting kimi k2.5. I'm here to help & support, please let me know what you need!",
              "score": 5,
              "created_utc": "2026-02-02 17:56:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o34laxv",
              "author": "Select-Service-5023",
              "text": "I‚Äôve had similar experiences. They are kinda suffering from success and are trying to get more computer. It‚Äôs definitely a slight bummer. When they get it self-hosted with enough capacity I‚Äôm sure those issues will disappear",
              "score": 5,
              "created_utc": "2026-02-02 09:12:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o34lfuc",
                  "author": "NiceDescription804",
                  "text": "No it's not a slight bummer. \nIt's not delivering what I'm paying for deeming the subscription useless. \nI'm gonna be posting about this so people don't fall into the marketing like I did.",
                  "score": 10,
                  "created_utc": "2026-02-02 09:13:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o34lbuw",
                  "author": "Select-Service-5023",
                  "text": "Compute* lol",
                  "score": 3,
                  "created_utc": "2026-02-02 09:12:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o36huft",
              "author": "annakhouri2150",
              "text": "Join the Discord, they're actively working on it, making announcements about it, responding to people about it.",
              "score": 2,
              "created_utc": "2026-02-02 16:35:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o373up4",
              "author": "sudoer777_",
              "text": "Not to be a shill for Synthetic, but I've also been having issues with OpenCode Zen with Kimi K2.5, and it's probably due to the massive influx of users with both services still working on stabilizing the infrastructure and relying on Fireworks which is the source of the problems, since this model only came out a few days ago",
              "score": 1,
              "created_utc": "2026-02-02 18:15:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3dq63r",
              "author": "RudyRobichaux",
              "text": "I've not had any issues with synthetic, and I'm not a bot. Though they are currently hosting it on their own hardware, and from their discord it's been a learning experience, so I think quality may vary. I had subscribed to them a few months ago, and they refunded me due to performance issues unprompted, so you may want to reach out to them. That being said, I'm enjoying them so much here is my referral code https://synthetic.new/?referral=fvJqmyHGVGdftwm.",
              "score": 0,
              "created_utc": "2026-02-03 18:00:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o342ugg",
          "author": "SamatIssatov",
          "text": "So much advertising. Why buy Kimi when you can buy Codex for the same price? I don't understand these advertisers, they're always deceiving people.",
          "score": 13,
          "created_utc": "2026-02-02 06:22:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o374m2r",
              "author": "sudoer777_",
              "text": "Kimi is open weight, and I don't want OpenAI/Anthropic to have my business and monopolize the AI industry",
              "score": 5,
              "created_utc": "2026-02-02 18:19:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o34al2h",
              "author": "RegrettableBiscuit",
              "text": "It's the same price, but not the same usage limits.¬†",
              "score": 5,
              "created_utc": "2026-02-02 07:30:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o34f5rl",
                  "author": "SamatIssatov",
                  "text": "We're talking about Codex, not Claude. And it's very economical. I program all day long and it's enough for me. You can't compare Codex/Claude with GLM/Kimi. If you need them for repetitive tasks, then yes, GLM/Kimi may be justified.",
                  "score": 1,
                  "created_utc": "2026-02-02 08:13:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o36il3f",
              "author": "annakhouri2150",
              "text": "1. You get API usage, as the other person said, no weird OAuth hacks to use the service in anything other than Codex CLI, that could get you blocked (like what Anthropic did to OpenCode)\n2. They don't train on, or even ever store, your prompts or outputs (check their Privacy Policy and TOS)\n3. They're extremely open, active, and responsive in their Discord, so you always know what's going on\n4. Since they're only running open weight models, if you get used to a model, but want to switch providers, you can actually do that, instead of being locked into GPT\n5. They won't secretly replace a model with a differently-RL'd one under your nose, but keep the ID the same\n6. They won't secretly quantize a model under load and then gaslight you telling you it's not different.\n\nCall me a bot if you want. I'm not. Y'all are just cynical. Which is understandable, given the, you know, general AI landscape, but I feel like Synthetic is, if anything, an oasis from that.",
              "score": 2,
              "created_utc": "2026-02-02 16:38:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o348bc4",
              "author": "CYTR_",
              "text": "I also don't know why people would choose a Kimi API if the price is similar. On the other hand, personally, I really want to rent a B300 server and run K2.5 on it. \n\nIn this way: we have the benefits of GDPR regulation and a powerful model. I can't wait to try this out as soon as I have the time.",
              "score": 1,
              "created_utc": "2026-02-02 07:09:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o34odxv",
                  "author": "RnRau",
                  "text": "You don't really need Nvidia hardware to just run inference. Surely non-nvidia inference options are cheaper? Sure if you are training as well... nvidia is THE option, but just common garden variety inference, nvidia might not be the most cost effective?",
                  "score": 1,
                  "created_utc": "2026-02-02 09:42:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o36klam",
              "author": "telewebb",
              "text": "I'm sorry, I most likely don't understand your statement. Did you just ask \"why use OpenCode when you can purchase a subscription to a different product like codex\"? Or \"why use pay-as-you-go with any combination of middle when you could buy a subscription to one walled garden of models\"? Statements slightly exaggerated to make sure I'm communicating what I think the question is.",
              "score": 1,
              "created_utc": "2026-02-02 16:47:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3454bd",
              "author": "Ok-Regret-4013",
              "text": "I think other providers are not good, but Synthetic is okay. If you can afford the high prices of Codex and Anthropic, it is good. But to me, I use custom prompts and agent workflows, so fast and smart balance and keeping my rules is better for me.",
              "score": 1,
              "created_utc": "2026-02-02 06:41:53",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o34p84z",
              "author": "charmander_cha",
              "text": "Particularly because I'd rather give my money to the Chinese than to the Nazis of this century.",
              "score": 1,
              "created_utc": "2026-02-02 09:50:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o349642",
          "author": "elllyphant",
          "text": "Thank you for sharing and thank you sooo much for your patience.   \nBoth Synthetic founders have been working all weekend to get Kimi K2.5 faster. It's still in progress but we'll update in Discord when the work is done. We really value having a powerful product at a competitive price (and your privacy).",
          "score": 9,
          "created_utc": "2026-02-02 07:17:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34gmm8",
              "author": "Simple_Split5074",
              "text": "Can you give an indication on tps (and maybe time to first token)?¬†",
              "score": 1,
              "created_utc": "2026-02-02 08:26:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3725ay",
                  "author": "elllyphant",
                  "text": "https://preview.redd.it/a23ey4m8g4hg1.png?width=2724&format=png&auto=webp&s=627e91464480bdc2f13f0f50ca0a377ac0d005e4\n\nhmm is this helpful? if not I'll ask Matt again   \n(this is from 6 hours ago)",
                  "score": 3,
                  "created_utc": "2026-02-02 18:08:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3b2u8a",
          "author": "Snoo_57113",
          "text": "It is good, but they were overwhelmed over the weekend in opencode, I think it is good to pay moonshot since that money helps to fund future models.\n\nI still use minimax it is a little slow, but very reliable. I had tasks that run overnight and it finishes it in a couple hours. No better feeling than to wake up with a big chunk of code ready for review.",
          "score": 2,
          "created_utc": "2026-02-03 07:57:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o345xis",
          "author": "jpcaparas",
          "text": "It's pretty awesome but I find it tiring to actively campaign for people to not get it from [Kimi.com](http://Kimi.com) because they don't know the implications of doing so.",
          "score": 3,
          "created_utc": "2026-02-02 06:48:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o349jqp",
              "author": "Crowley-Barns",
              "text": "What are the implications?\n\nAnd why do you campaign‚Ä¶? Like, as an act of human goodwill??\n\nI wanna know what Kimi did to you!",
              "score": 2,
              "created_utc": "2026-02-02 07:20:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o34bepo",
                  "author": "Crowley-Barns",
                  "text": "Oh. \n\nHmm. I‚Ä¶ kinda don‚Äôt care haha. As long as they‚Äôre open about doing it. \n\nI don‚Äôt have anything highly confidential so I‚Äôm okay contributing in a small way to advancement.",
                  "score": 2,
                  "created_utc": "2026-02-02 07:37:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o34an1g",
                  "author": "RegrettableBiscuit",
                  "text": "They train models on your data.¬†",
                  "score": 2,
                  "created_utc": "2026-02-02 07:30:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o348jky",
          "author": "Select-Service-5023",
          "text": "*HAVE* to rep synthetic.new here... just join the discord and nose around. That alone will be the ONLY evidence for or against it you will need.",
          "score": 2,
          "created_utc": "2026-02-02 07:11:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34kqsn",
              "author": "FyreKZ",
              "text": "Seems like a pretty good deal, what does a request count as? 135 requests every 5 hours? Is that 135 prompts or individual API calls?",
              "score": 2,
              "created_utc": "2026-02-02 09:06:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o34l097",
                  "author": "Select-Service-5023",
                  "text": "Website shows exact. But it‚Äôs simple. A message = one request. Tool calls are I think 0.1 requests, and super small messages under 2048 are 0.2 requests. No weekly, just 5 hour window. I cannot stress how much usage this really is in practice.",
                  "score": 3,
                  "created_utc": "2026-02-02 09:09:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34plp7",
          "author": "trypnosis",
          "text": "I used kimi 2.5 over the weekend and it was terrible.\n\nAre you saying I should go back and try again?",
          "score": 1,
          "created_utc": "2026-02-02 09:54:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34spaf",
              "author": "manojlds",
              "text": "Nah, I found GLM 4.7 better.",
              "score": 1,
              "created_utc": "2026-02-02 10:23:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o34suz4",
                  "author": "trypnosis",
                  "text": "From synthetic or other provider. I‚Äôm keen on using synthetic as I just got the sub.",
                  "score": 1,
                  "created_utc": "2026-02-02 10:25:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o376dq4",
                  "author": "sudoer777_",
                  "text": "Based on my usage so far, I've found that Kimi K2.5 has better reasoning and was less likely to get confused by stupid things while debugging but tends to be worse at following instructions, but I've only used it for a couple days so far",
                  "score": 1,
                  "created_utc": "2026-02-02 18:27:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35hsu2",
          "author": "DistinctWay9169",
          "text": "Is it worth it paying synthetic instead of kimi plan on kimi.com?\n\n",
          "score": 1,
          "created_utc": "2026-02-02 13:33:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3d70tk",
              "author": "Funny-Advertising238",
              "text": "Definitely pay kimi directly. For what it's worth I've tried from many different providers, kimi performed the best. Not one failed tool call while the others all had issues.¬†",
              "score": 1,
              "created_utc": "2026-02-03 16:32:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3d7vn7",
                  "author": "DistinctWay9169",
                  "text": "The only thing I did not like is that their $20 plan is bad; it is easy to hit limits and have weekly limits. GLM 4.7 is not that behind Kimi, and their $6 plan gives us much better limits and no weekly limits. Just waiting for Claude to release the Sonnet 5 that will be better than Kimi, as it will be basically Opus 4.5 but cheaper, so I would rather pay $20 for Claude than $19 for Kimi.",
                  "score": 1,
                  "created_utc": "2026-02-03 16:36:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35yolr",
          "author": "wallapola",
          "text": "Is nano-gpt good enough for kimi k2.5 or is [chutes.ai](http://chutes.ai) already fine? I‚Äôve heard the synthetic provider is one of the best, but it‚Äôs expensive and I can‚Äôt really justify paying $20 when I can get claude code pro for the same price.",
          "score": 1,
          "created_utc": "2026-02-02 15:04:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o370826",
              "author": "elllyphant",
              "text": "you can try it for $12/mo this month via ¬†[https://synthetic.new/?saleType=moltbot](https://synthetic.new/?saleType=moltbot)",
              "score": 1,
              "created_utc": "2026-02-02 17:59:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3714rc",
                  "author": "wallapola",
                  "text": "Okay but how about for following months?",
                  "score": 1,
                  "created_utc": "2026-02-02 18:03:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o36vbxj",
          "author": "bigh-aus",
          "text": "Yeah, it's models like this that make me think going forward the American AI company's value is in running the models, less the model themselves.  China is certainly setting the bar high for what you can run locally if you have the $.  Need more OSS releases from the USA / Europe, but I know that goes against their valuation.    \n  \nJust wait until the local hardware catches up! eg a Mac Studio M7 Ulta 1TB unified ram :p",
          "score": 1,
          "created_utc": "2026-02-02 17:37:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o38gb8o",
          "author": "cutebluedragongirl",
          "text": "If you are using API, you should always use the official provider.",
          "score": 1,
          "created_utc": "2026-02-02 22:01:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3axwuk",
          "author": "knowoneknows",
          "text": "synthetic + opencode is the way to go, best experience so far with kimi k2.5. I was using K2.5 (free) through Kilo Code for another project and it was impressive when it worked but damn slow. Synthetic experience is much better with opencode - Charm Crush is pretty nice too but opencode is the best experience so far.\n\nEdit:\n\nIt's buggy, especially running parallel agents. It's also really slow at times?",
          "score": 1,
          "created_utc": "2026-02-03 07:12:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3g0ocb",
              "author": "epyctime",
              "text": "what's buggy, synthetic? first i eard of it",
              "score": 1,
              "created_utc": "2026-02-04 00:41:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3g708h",
                  "author": "knowoneknows",
                  "text": "Both opencode and Kimi k2.5 through synthetic",
                  "score": 1,
                  "created_utc": "2026-02-04 01:16:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qwacgd",
      "title": "Cheapest Provider",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qwacgd/cheapest_provider/",
      "author": "FutureIncrease",
      "created_utc": "2026-02-05 03:34:05",
      "score": 25,
      "num_comments": 19,
      "upvote_ratio": 0.96,
      "text": "What‚Äôs the cheapest way to get access to MiniMax 2.1/Kimi K2.5?\n\nI use CC Max (x20) for work. Interested in switching but not sure I can afford other solutions since I‚Äôve heard the Max plan is heavily subsidized.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qwacgd/cheapest_provider/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o3nqh2s",
          "author": "devdnn",
          "text": "If cost is your sole consideration and you‚Äôre not experimenting with other models, GitHub Copilot Pro+ for $39.99 or Copilot Pro with $10 is an incredible offer, set you budget limit for $29, it‚Äôs still worth it if that‚Äôs within your budget.\n\nIt‚Äôs charged on per request, quality prompts and not vibe coding will take very far.\n\nThe only limitation I have come across from not going to direct company is the context size, but that is hugely mitigated using the subagents and MD files for memory.\n\nI stuck to it for 2 weeks and use it as my only go to and now it‚Äôs my daily driver.",
          "score": 12,
          "created_utc": "2026-02-05 03:59:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3o65o6",
              "author": "IIALE34II",
              "text": "I've had issues with multiple agents hitting rate limits with Copilot. Other than that it's a very good experience. Dirt cheap for what you get too.",
              "score": 1,
              "created_utc": "2026-02-05 05:49:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3oqqwp",
              "author": "jixbo",
              "text": "Don't they have the context limited?\nChat gpt plus is around 20 quid and fairly good limits to work with codex 5.2.",
              "score": 1,
              "created_utc": "2026-02-05 08:54:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3o5xq8",
          "author": "DJDannySteel",
          "text": "Antigravity auth plugin, Gemini auth plugin, free usage from kilo and codex etc plugins, and boom bam. Or open router on the 10 dollar hide usage allowances",
          "score": 7,
          "created_utc": "2026-02-05 05:48:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3tve45",
          "author": "joe__n",
          "text": "[chutes.ai](http://chutes.ai) is my goto for these models",
          "score": 3,
          "created_utc": "2026-02-06 02:08:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3uso45",
          "author": "Ok_Cricket9353",
          "text": "You can use https://chutes.ai They have API plans with daily requests limits and PAYG. their 10-20$ plan will be sufficient. They even have 3$ plan for lower needs with 300 requests per day.\nYou will get many models, privacy centred TEE models. There are many models to choose from.",
          "score": 2,
          "created_utc": "2026-02-06 05:46:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ole2b",
          "author": "MaxPhoenix_",
          "text": "\"what's the cheapest minimax/kimi\":  \nedit: removed minimax - thay model is another nanny model absolutely useless.  \ndirect kimi-2.5 (kimi.com): $19/mo for 2000-3500 requests per week (7day rolling cycle) (reported)  \ndirect [z.ai](http://z.ai) glm even though you didn't ask it's worth it: $6/mo for 120 requests per 5hr\n\n\"other solutions\":  \ngithub copilot (github.com) $10/mo for 300 premium requests (best deal on opus-4.5 flat rate!)  \nuse AMPcode (ampcode.com/free): FREE mode gives $10 of credit a day that includes opus-4.5 supposedly  \nuse OPENCODE zen: right now these are FREE: minimax-m2.1(trash), glm-4.7, kimi-2.5, big pickle, trinity large preview  \nuse KILO code: right now these are FREE: minimax-m2.1(trash), glm-4.7, corethink, giga potato, arcee ai..  \nyou can also less models nearly limitless (qwen code and gemini cli) or [openrouter.ai](http://openrouter.ai) free models that hit throttle/limits\n\nEDIT: explaining why to not \"just use the free kimi/minimax(trash)/glm?\" -> because they are slow and run into throttle issues and timeout and they train on your sessions.  if you aren't paying, you are the product.",
          "score": 4,
          "created_utc": "2026-02-05 08:03:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3o4xjr",
          "author": "Shep_Alderson",
          "text": "It‚Äôs not the absolute cheapest but I‚Äôve really enjoyed synthetic.new. $20/mo for very useable 5 hour limits. Their customer service is also amazing. I had a billing issue when I downgraded from their $60 plan to their $20 plan. I was supposed to get the remainder of my billing period at the same $60 limits, but when I renewed to continue on the $20 plan, it cut me down to the $20 plan limits.\n\nI emailed their support email in the contacts page and that evening the cofounder emailed me, apologized for the issue, corrected the billing for the remaining month and gave me a $40 credit so I could have an extra month of their Pro plan at the standard price before my downgrade kicked in. The fact that they not only fixed the remaining billing period issue, but also gave me credits for my trouble, really speaks volumes to me. I doubt I‚Äôll go anywhere else for running the open weight models.",
          "score": 2,
          "created_utc": "2026-02-05 05:40:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ombjc",
              "author": "ZeSprawl",
              "text": "I agree about [synthetic.new](http://synthetic.new) but they are on a waitlist right now: \n\nhttps://preview.redd.it/z07ru8yswmhg1.png?width=1290&format=png&auto=webp&s=acc4869edc3ec157c15276af77a550023579479a",
              "score": 5,
              "created_utc": "2026-02-05 08:12:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3phisw",
                  "author": "Shep_Alderson",
                  "text": "Oops. I wonder if an invite code would get people past it. I‚Äôll have to test later.",
                  "score": 1,
                  "created_utc": "2026-02-05 12:44:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3p1ptw",
          "author": "Dangerous-Relation-5",
          "text": "Amp code gives you $10/day in Opus credits if you turn on Ads. I think Minimax is still free in Opencode",
          "score": 1,
          "created_utc": "2026-02-05 10:40:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wmqnz",
          "author": "TechieRathor",
          "text": "In my opinion the cheapest way would be to use Zen (https://opencode.ai/docs/zen/) service by OpenCode for trying different models.\n\nAre you really able to use all limit of CC Max subscription ? Frankly speaking I spent/wasted lot of time trying/using different models for coding a couple of months back but then I realised it'a waste of time there is not Model better than Antropic models when it comes to coding, plus I also saw that I am not able to use even 50% of CC Max (x20) so I downgraded it to CC Max (x5) which is sufficient enough plus I bought the Max subscription of GLM coding API which I use with Open Code as I don't want to get into the hassle of usage based pricing.  ",
          "score": 1,
          "created_utc": "2026-02-06 14:24:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zw633",
          "author": "krogel-web-solutions",
          "text": "Been happy with synthetic, but TPS varies quite a bit.",
          "score": 1,
          "created_utc": "2026-02-07 00:10:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48mhr7",
          "author": "ScorpionOfWar",
          "text": "Been using open-source models more lately for private stuff, I got the 100$ Claude Sub for work. Tried self-hosting with Ollama for a while but honestly the GPU costs and maintenance were annoying for anything bigger.\n\nEnded up trying [Synthetic](https://synthetic.new/?referral=hcHozzHNE8CxVvz) and it's been solid so far, alternatively [Z.ai](https://z.ai/subscribe?ic=KQ77ZVKLB5) for just the GLM Models, nice for coding. They host open-source models and the API is OpenAI-compatible so it just plugs into your CLI or Dev Environment. $20/mo flat for the subscription tier is nice.\n\nOpen-source models still lag behind frontier models for complex reasoning tasks in my opinion, so it's not a full replacement. But if privacy is a priority for you and you don't want to deal with self-hosting, it's worth checking out.",
          "score": 1,
          "created_utc": "2026-02-08 11:55:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3opssp",
          "author": "wallapola",
          "text": "Yeah, if the goal is purely cheapest, there are definitely options, but in my experience that usually comes with tradeoffs like throttling, random slowdowns, or timeouts. I‚Äôm currently using synthetic with opencode mostly because of the promo. At that price, it feels reasonable. What I like about it is that the devs are actually active and transparent. They‚Äôre on discord, issues get acknowledged and you can see what they‚Äôre working on instead of guessing why a model suddenly feels worse.\n\nOnce the promo is over, I‚Äôll probably reassess again, especially if other Kimi or GLM providers improve. But for now it‚Äôs been a decent balance of cost and stability for my usage.  \n  \nIf anyone wants to try it, this is the link I used for the discounted offer:  \n[https://synthetic.new/?referral=4NNoPUXcb63ZYVK](https://synthetic.new/?referral=4NNoPUXcb63ZYVK)",
          "score": 1,
          "created_utc": "2026-02-05 08:45:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3nnxsb",
          "author": "stevilg",
          "text": "Nano is a pretty cheap way to get all of them open source models at $8/month ( I think this link  [https://nano-gpt.com/r/R7pbqiXX](https://nano-gpt.com/r/R7pbqiXX) will give a slight discount). The fact that the just measure the quantity of messages on the subscription and not the tokens means heavy context coding goes a long way. Its far from blazing fast, but it gets the job done.",
          "score": 1,
          "created_utc": "2026-02-05 03:43:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ockkv",
          "author": "exploriann",
          "text": "Definitely recommend synthetic.new, their service and price are really great. They have a discord community which is very active. You can start with a standard plan (20$).\n\nI have been using their service for 2 weeks, it's good.",
          "score": 0,
          "created_utc": "2026-02-05 06:43:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oeefp",
          "author": "Bob5k",
          "text": "Synthetic if you care about stability and availability (the quota size). No other provider is close to their pro plan with basically unlimited model requests per 5h \n\nI'm using cc max 20 at work and synthetic for anything else. \nAlso first month can be cheaper with [reflink](https://synthetic.new/?referral=IDyp75aoQpW9YFt)",
          "score": 0,
          "created_utc": "2026-02-05 06:59:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3opg3z",
          "author": "NoTomatillo1141",
          "text": "Would recommend [Synthetic.new](http://Synthetic.new)\n\nNo, the self's not going to give his referral link for it.",
          "score": 0,
          "created_utc": "2026-02-05 08:42:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwjr76",
      "title": "AI Consumption Tracker 1.2.0: Windows app with zero config for opencode users",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/3rn1tpj83ohg1.png",
      "author": "Rygel_XV",
      "created_utc": "2026-02-05 12:17:34",
      "score": 25,
      "num_comments": 5,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qwjr76/ai_consumption_tracker_120_windows_app_with_zero/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3v5xiu",
          "author": "npittas",
          "text": "Great, but still you have a severe issue asking users to add base\\_url to the auth.json file. auth.json should not be used changed, add base\\_url in opencode.json instead, and add instructions on how to do so. Also not having codex and github-copilot tracking is a no go for me, but good job.",
          "score": 2,
          "created_utc": "2026-02-06 07:40:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3vp3c6",
              "author": "Rygel_XV",
              "text": "Thank you for your feedback. I have just released [1.3.2](https://github.com/rygel/AIConsumptionTracker/releases/tag/v1.3.2) and it should fix the base\\_url issue. I am working on github-copilot next.",
              "score": 1,
              "created_utc": "2026-02-06 10:41:10",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3wgf67",
              "author": "Rygel_XV",
              "text": "I released [1.5.0](https://github.com/rygel/AIConsumptionTracker/releases/tag/v1.5.0) which supports Github Copilot.",
              "score": 1,
              "created_utc": "2026-02-06 13:50:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3qjyld",
          "author": "Several-System1535",
          "text": "Windows in 2026  \nlmao",
          "score": 3,
          "created_utc": "2026-02-05 16:09:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41x1he",
          "author": "Character_Cod8971",
          "text": "I can't get it to show me my OpenAI usage; please fix it",
          "score": 1,
          "created_utc": "2026-02-07 09:03:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qv3s16",
      "title": "CodeNomad v0.9.4 Released - Context manipulation, Session search, Themes and more",
      "subreddit": "opencodeCLI",
      "url": "https://v.redd.it/lw48vkltdchg1",
      "author": "Recent-Success-1520",
      "created_utc": "2026-02-03 20:48:39",
      "score": 24,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qv3s16/codenomad_v094_released_context_manipulation/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3h5ah5",
          "author": "cschulze1977",
          "text": "Love this tool, have been using allot over the last few days. I was trying the new version and was getting a permission error on linux about a missing file \"resources/opencode-config/.gitignore\" (when selecting a folder in the app). Manually creating the file fixes it",
          "score": 2,
          "created_utc": "2026-02-04 04:39:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ixtgh",
              "author": "Recent-Success-1520",
              "text": "Thanks for using it.\nThe issue was due to a bug introduced in opencode v1.1.50. if you install v1.1.49 the problem should go away.\nI have raised a PR for opencode to fix it",
              "score": 1,
              "created_utc": "2026-02-04 13:23:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3p8vwb",
          "author": "Possible-Text8643",
          "text": "this uses electron right? i know the mac version of this tool, or at least  something very similar.\n\nMy main issue is how heavy the tool is, since its electron based, any plans to mitigate that in the future?",
          "score": 1,
          "created_utc": "2026-02-05 11:42:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pfe67",
              "author": "Recent-Success-1520",
              "text": "We have both Electron and Tauri apps.\nExcept for storage size memory usage is almost same",
              "score": 1,
              "created_utc": "2026-02-05 12:30:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3pyd55",
                  "author": "Possible-Text8643",
                  "text": "tried a lot to get superset to work on windows but i think the best option will be to use this",
                  "score": 1,
                  "created_utc": "2026-02-05 14:22:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qund3z",
      "title": "GLM 4.7 has terrible logic",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qund3z/glm_47_has_terrible_logic/",
      "author": "reficulgr",
      "created_utc": "2026-02-03 09:19:20",
      "score": 20,
      "num_comments": 14,
      "upvote_ratio": 0.95,
      "text": "People had been praising GLM as being on-par with Sonnet or Opus, but it is lagging very severely behind. I have been fighting it for almost an hour now to convince it that 2002 does not come after 2010.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qund3z/glm_47_has_terrible_logic/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o3bmk8k",
          "author": "bonnmos",
          "text": "ü§£ü§£ü§£ A  few days back it said \"This is too much for me üò• , I can't handle\". Sometime it goes crazy with chinese characters..\nü§£ü§£",
          "score": 8,
          "created_utc": "2026-02-03 11:05:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3brtqi",
              "author": "aimericg",
              "text": "Does that for me too hehe. Sometimes it just switches everything to chinese, how my supposed to understand if it starts asking me question in chinese??",
              "score": 2,
              "created_utc": "2026-02-03 11:49:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3e4v9u",
              "author": "mdrahiem",
              "text": "I just came here to post if anyone sees the thinking is in Chinese and I realised that I am not alone üòÇ",
              "score": 2,
              "created_utc": "2026-02-03 19:06:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3bbia0",
          "author": "Heavy-Focus-1964",
          "text": "an hour? i think this reflects worse on you than GLM",
          "score": 10,
          "created_utc": "2026-02-03 09:21:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3citia",
          "author": "pbalIII",
          "text": "GLM-4.7 has a known gap on pure logic puzzles... someone ran lineage-bench on it recently and got ~60% accuracy on 8-node graphs where Qwen3-32B and OLMo-3 both hit 90%+. Even on trivial 4-node problems it tops out around 80%.\n\nThe benchmarks that made it look Sonnet-tier are heavily weighted toward code generation and agentic tool use, not abstract reasoning. For date comparisons and arithmetic, you're basically hitting its weakest surface.\n\naeroumbria's multi-model approach in the comments is the pragmatic fix. Route logic-heavy tasks to a model that doesn't fumble basic orderings.",
          "score": 3,
          "created_utc": "2026-02-03 14:35:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bebbx",
          "author": "jpcaparas",
          "text": "I've given up on it. slow af inference too",
          "score": 3,
          "created_utc": "2026-02-03 09:49:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3buum2",
          "author": "Ok-Regret-4013",
          "text": "I subscribed to GLM, but it was terrible. I would rather subscribe to Sonnet before experimenting.",
          "score": 2,
          "created_utc": "2026-02-03 12:12:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bh7lm",
          "author": "aeroumbria",
          "text": "I don't let any model go solo because they all have weaknesses. But three models with DIFFERENT weaknesses cross-checking each other is better than one master model going solo",
          "score": 1,
          "created_utc": "2026-02-03 10:16:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ej3ea",
          "author": "mintybadgerme",
          "text": "Kimi 2.5. Thank me later. :)",
          "score": 1,
          "created_utc": "2026-02-03 20:13:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gaqam",
          "author": "SynapticStreamer",
          "text": "I don't think anyone is making the claim that GLM is better, or on par with Sonnet or Opus. But GLM **will** fix things for me that both Sonnet and Opus miss. Some pretty obvious things that I have explicitly asked both Sonnet and Opus to fix, they've said they did, but they actually didn't. GLM was able to identify the problem, and fix it on the first time, and it **actually** fixed the problem, didn't just say \"hey, I fixed this.\"\n\nIt's a **different** tool, made in a **different** way and people expect it to perform well in the **same metrics** you use to classify another tool. It's just plain stupid.\n\nPeople want to throw \"do this thing\" at an LLM agent and expect it to extrapolate extremely detailed context and perform that task perfectly, and you just can't do that with GLM.\n\nIt's the difference between automatic (Anthropic) and manual (GLM) engines. People are going to fight ad infinitum about which is better. Some people prefer the convenience of the Anthropic model and will generally **never** be able to use a manual transmission because they learned on automatic, and it just is what it is.\n\nIf you're willing to take the time to learn how to respond appropriately to the model, and to learn what it needs and expects, GLM is a great model, most especially at the price point it's being offered for.",
          "score": 1,
          "created_utc": "2026-02-04 01:37:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xnyw0",
          "author": "Fklife45",
          "text": "yep slow and terrible logic, but whe i tried in claude code, it fel a bit smarter",
          "score": 1,
          "created_utc": "2026-02-06 17:24:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41snx5",
          "author": "Smart-Cap-2216",
          "text": "Âõ†‰∏∫‰ªñÂ§ßÂ∞è‰ªÖ‰ªÖÂè™Êúâ300b",
          "score": 1,
          "created_utc": "2026-02-07 08:21:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dvutq",
          "author": "fabricio3g",
          "text": "Skill issue. For the price, it‚Äôs amazing. On Linux, for some reason, it runs fast, but on Windows it‚Äôs too slow with opencode. I believe it was designed to be used with the Claude CLI.",
          "score": 1,
          "created_utc": "2026-02-03 18:26:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3e5glx",
              "author": "mdrahiem",
              "text": "I see the latency issue too and I am on mac. I dont think its just designed for Claude Code, If it was designed to work with Claude Code, why would they write OpenCode documentation on their website.",
              "score": 1,
              "created_utc": "2026-02-03 19:09:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}