{
  "metadata": {
    "last_updated": "2026-02-16 03:09:31",
    "time_filter": "week",
    "subreddit": "opencodeCLI",
    "total_items": 20,
    "total_comments": 188,
    "file_size_bytes": 194803
  },
  "items": [
    {
      "id": "1r00tsx",
      "title": "Thank you to the OpenCode maintainers",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r00tsx/thank_you_to_the_opencode_maintainers/",
      "author": "Far-Association2923",
      "created_utc": "2026-02-09 10:32:43",
      "score": 192,
      "num_comments": 22,
      "upvote_ratio": 0.99,
      "text": "Hey OpenCode folks,\n\nJust wanted to say thanks to everyone maintaining OpenCode and keeping it open source. Projects like this are rare. It is genuinely useful in day-to-day work, and it is also built in a way that lets other people actually build on top of it.\n\nI have been working on a cross-platform desktop app using Tauri, and running OpenCode as a local sidecar has been a huge help. Having a solid headless runtime I can rely on means I get to focus on the desktop experience, security boundaries, and local-first behavior instead of reinventing an agent runtime from scratch.\n\nA few things I really appreciate:\n\n* The CLI and runtime are practical and easy to ship, not just a demo.\n* The clear separation between the engine and the UI makes embedding possible.\n* The architecture makes it possible to build on top of OpenCode or embed it elsewhere, rather than having to fork the core runtime. (EDIT for clarity)\n\nAnyway, just a sincere thank you for the work you are doing. It is unglamorous, hard engineering, and it is helping other open-source projects actually ship. I also love the frequent updates. Keep up the great work!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r00tsx/thank_you_to_the_opencode_maintainers/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4evgkd",
          "author": "SparePartsHere",
          "text": "Yes, Opencode is an incredible product and I am very thankful for the work they are putting in. I really like the way Dax thinks about OC and generally OSS and the value it can provide to every developer, no matter how strange our personal workflows and quirks are.",
          "score": 13,
          "created_utc": "2026-02-09 10:43:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4exhus",
              "author": "Far-Association2923",
              "text": "Totally agree. That flexibility is what really stands out to me too. Everyoneâ€™s workflows are a bit weird in their own way, and having an OSS foundation that doesnâ€™t force a single opinionated path makes a huge difference.",
              "score": 2,
              "created_utc": "2026-02-09 11:02:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4eww4b",
          "author": "HarjjotSinghh",
          "text": "open source = my favorite kind of caffeine",
          "score": 6,
          "created_utc": "2026-02-09 10:57:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4exphn",
              "author": "Far-Association2923",
              "text": "OSS for the people â˜•ï¸",
              "score": 2,
              "created_utc": "2026-02-09 11:04:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4fsbxu",
          "author": "Superfishintights",
          "text": "It's great, just needs better sub agent/parallelisation/swarm support and it is an easy equal to codex/claude code with multi model support.",
          "score": 4,
          "created_utc": "2026-02-09 14:34:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4fx260",
              "author": "Far-Association2923",
              "text": "Interesting.. I actually ran into the same â€œone agent can only do so much at onceâ€ limitation, and ended up building a simple orchestration layer into my app to solve it.\n\nThe inspiration for this was OpenClawâ€™s multiâ€‘agent setup: multiple agents working in parallel toward a shared goal, then folding their results back together.\n\nIn practice my setup looks like: a list of tasks -> one Orchestrator -> multiple worker agents. The Orchestrator assigns tasks concurrently (so research, extraction, code changes, verification, etc. can happen sideâ€‘byâ€‘side), tracks progress, and then merges the outputs into a final answer/plan.\n\nOpencode could absolutely implement the same idea. Theyâ€™d ***just*** need an orchestration layer that can run multiple sessions/tasks at the same time, handle coordination (whoâ€™s doing what), and then aggregate results. Thatâ€™s basically the missing piece between a single agent session and a team of agents collaborating.\n\nThis does not require multiple opencode instances either.",
              "score": 2,
              "created_utc": "2026-02-09 14:59:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4kmb7e",
                  "author": "SparePartsHere",
                  "text": "That's what oh-my-opencode does already (and why people call it token-burner).",
                  "score": 1,
                  "created_utc": "2026-02-10 06:24:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4ie8d5",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2026-02-09 22:12:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4h3ghf",
          "author": "affalatoon",
          "text": "*Processing img a14hou5fhiig1...*",
          "score": 3,
          "created_utc": "2026-02-09 18:23:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rnxjt",
          "author": "bzBetty",
          "text": "Huge fan of the desktop app - lets me multitask over multiple projects, worktrees or just on the same dir.",
          "score": 2,
          "created_utc": "2026-02-11 08:43:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ymyqa",
          "author": "Few-Mycologist-8192",
          "text": "I really wish I could have create a post like this, it resonates with my feelings exactly. Thanks so much to their team. I guess it speaks for many people's hearts.",
          "score": 2,
          "created_utc": "2026-02-12 11:03:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ynxiz",
              "author": "Far-Association2923",
              "text": "The OSS community definitely needs more praise, especially when they are building such high quality products that are free to use. Hopefully they are earning some good income from the opencode zen servivces.",
              "score": 2,
              "created_utc": "2026-02-12 11:11:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4f5kf0",
          "author": "t4a8945",
          "text": ">The architecture leaves room for extensions and experimentation without needing to fork everything.\n\nI've hit a few walls trying to add my own little things to OpenCode though (like I wanted to add a \"time spent thinking\" timer on the UI and tried with Opus 4.6, 4.5 and also Sonnet ; they all said something like that would require forking the project)\n\nDid I miss something?\n\n(totally agree otherwise, OpenCode is my daily driver and I freaking love it)",
          "score": 2,
          "created_utc": "2026-02-09 12:10:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4f65ug",
              "author": "Far-Association2923",
              "text": "Some UI-level changes like a â€œtime spent thinkingâ€ timer would realistically require forking today unless youâ€™re building your own layer on top of OpenCode and treating it more like a headless engine.\n\nWhen I said it leaves room for extensions, I was mostly thinking in terms of the runtime, protocol, and embedding side rather than direct UI customization of the upstream app. I probably shouldâ€™ve been clearer there.\n\nAlsoâ€¦ the â€œtime spent thinkingâ€ timer is a great idea. If you donâ€™t mind, I may shamelessly steal that concept for my own app ðŸ˜„",
              "score": 3,
              "created_utc": "2026-02-09 12:15:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4fbp9w",
                  "author": "t4a8945",
                  "text": "Okay I understand what you were talking about now.\n\nYeah I'm surprised this is not a feature yet. It's very useful for me because I do lots of videos where I compare different models on the same prompts.\n\nI ended up having a bash utility, which I can launch with ! and the \"timer\". It automatically parses the logs from the opencode session and gives me the answer.\n\nI'd prefer to have it as a command within opencode, but couldn't make it work.",
                  "score": 2,
                  "created_utc": "2026-02-09 12:54:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4f4dwi",
          "author": "EchoesInBackpack",
          "text": "Is there any support channels available? Afair they mentioned in the docs that there is no profit margin on openzen",
          "score": 1,
          "created_utc": "2026-02-09 12:01:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4f5lio",
              "author": "Far-Association2923",
              "text": "I'm not aware of specific channels although if it's related to opencode software you can always post an issue on [github](https://github.com/anomalyco/opencode/issues). They have some pretty great free models on zen although the rate limiting can cut you off pretty quickly if you are not careful.",
              "score": 2,
              "created_utc": "2026-02-09 12:10:48",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4ff71l",
              "author": "lll1412",
              "text": "They offer a subscription service: [https://opencode.ai/black](https://opencode.ai/black)",
              "score": 2,
              "created_utc": "2026-02-09 13:17:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4p5nky",
          "author": "DeExecute",
          "text": "The web interface is unfortunately still in alpha state, but I also appreciate the core product.",
          "score": 1,
          "created_utc": "2026-02-10 22:29:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r27hm2",
      "title": "GLM-5 is now on OpenCode (via Z.ai coding plan)",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r27hm2/glm5_is_now_on_opencode_via_zai_coding_plan/",
      "author": "jpcaparas",
      "created_utc": "2026-02-11 19:46:29",
      "score": 74,
      "num_comments": 28,
      "upvote_ratio": 0.96,
      "text": "https://preview.redd.it/5pstp85z5xig1.png?width=599&format=png&auto=webp&s=400616601878804d681c97da7fd1c4fbd8c6a48d\n\nRun \\`opencode models --refresh\\`\n\nHN thread: [https://news.ycombinator.com/item?id=46974853](https://news.ycombinator.com/item?id=46974853)\n\nWriteup: [https://extended.reading.sh/glm-5](https://extended.reading.sh/glm-5)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r27hm2/glm5_is_now_on_opencode_via_zai_coding_plan/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4uw05c",
          "author": "jpcaparas",
          "text": "I'll post some amateur feedback here once I've used it for a bit. Key comparison would be against GLM 4.7 ðŸŒ. I'm mostly interested about speed, tool-calling efficacy, and subagent orchestration.",
          "score": 8,
          "created_utc": "2026-02-11 19:59:05",
          "is_submitter": true,
          "replies": [
            {
              "id": "o4wujae",
              "author": "jpcaparas",
              "text": "My honest thoughts after a few hours of usage:\n\n1. Tool-calling efficacy: at par with K2.5 and Opus 4.6. Doesn't miss. This fucker is smart.\n2. Subagent orchestration: After disabling a couple of MCP servers, it performed well, so I think it *does* struggle quite a bit with middle-of-the-road context bloat. Note that I almost always exhaust my context usage at the end of a session due to heavy research tasks.\n3. Inference: (I'm on ultra, so YMMV), Almost at par with Kimi K2.5 on Synthetic. Not blazing fast, but definitely an improvement over GLM 4.7 on Z.ai.\n\nIf you are keen to try it out, please check out the writeup above first.",
              "score": 12,
              "created_utc": "2026-02-12 02:16:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4xdqg9",
                  "author": "keroro7128",
                  "text": "sorry What is Kimi 4.5ï¼Ÿ",
                  "score": 1,
                  "created_utc": "2026-02-12 04:17:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4uy7b8",
          "author": "Evening-Piglet-7471",
          "text": "rate limitâ€¦.",
          "score": 9,
          "created_utc": "2026-02-11 20:09:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xzrbd",
          "author": "Lpaydat",
          "text": "Thank you bro. I just realized that they drop glm 5 by this post. I can finally use my ultra plan now after leaving it idle for months ðŸ˜†",
          "score": 3,
          "created_utc": "2026-02-12 07:19:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4y06gm",
              "author": "jpcaparas",
              "text": "Oh you'll love GLM-5, you betcha. GLM-4.7 on [Z.ai](http://Z.ai) was such a letdown.",
              "score": 2,
              "created_utc": "2026-02-12 07:23:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o529j0d",
                  "author": "Lpaydat",
                  "text": "It's amazing. GLM4.7 just barely worked for me. But this 5.0 is on another level. I haven't used it for coding tasks yet but reasoning tasks bring me really good results.",
                  "score": 1,
                  "created_utc": "2026-02-12 22:23:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4uynht",
          "author": "jpcaparas",
          "text": "https://preview.redd.it/iz5oaefiaxig1.png?width=1320&format=png&auto=webp&s=19c02cc867568398608906f0aeaefdfedd7d4907\n\nHoly shit it's so bad with subagent orchestration lmao. Even GLM 4.7 wasn't this bad.\n\nFor context, I'm having it do deep research. I'm on the Ultra plan btw.",
          "score": 6,
          "created_utc": "2026-02-11 20:11:53",
          "is_submitter": true,
          "replies": [
            {
              "id": "o4v0hzv",
              "author": "jpcaparas",
              "text": "https://preview.redd.it/vvdxzlm4cxig1.png?width=1384&format=png&auto=webp&s=7d76e99cda91266004a47d8ff4559bc27ec0a7d1\n\nGood reasoning and fact-checking skills.",
              "score": 4,
              "created_utc": "2026-02-11 20:20:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4yq5w8",
                  "author": "Living_Tax1592",
                  "text": "how have you found its context compaction and rot handling? i use ohmyopencode with op4.6 on max  and that context gets ripped through but its compaction and ability to mitigate rot is miles better than 4.5",
                  "score": 1,
                  "created_utc": "2026-02-12 11:30:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4ypowh",
              "author": "Living_Tax1592",
              "text": "have you tried this again after a prompt to \"be more fucking patient\"?",
              "score": 1,
              "created_utc": "2026-02-12 11:26:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4z5ga0",
          "author": "Ai_Pirates",
          "text": "But only max coding plan",
          "score": 2,
          "created_utc": "2026-02-12 13:19:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4vwnto",
          "author": "TwisTedUK",
          "text": "Used it via NanoGPT and god damn is it slow",
          "score": 1,
          "created_utc": "2026-02-11 22:58:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vxysv",
              "author": "jpcaparas",
              "text": "maybe because I'm on glm ultra I get peak male LLM inference?",
              "score": 1,
              "created_utc": "2026-02-11 23:05:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4xp37y",
                  "author": "xmnstr",
                  "text": "Peak male?!",
                  "score": 2,
                  "created_utc": "2026-02-12 05:44:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4vsfyt",
          "author": "SynapticStreamer",
          "text": "Anyone literally unable to get it to work? I keep getting \"rate limit reached.\"\n\nWow, never-mind. Looks like the coding plan literally doesn't even work with it: \"Only supports GLM-4.7 and historical text models\" despite being informed when I got the damn thing that new models would be included.",
          "score": 1,
          "created_utc": "2026-02-11 22:37:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4w7roh",
              "author": "Illustrious-Many-782",
              "text": "Agreed. Pretty crappy. I realize the cost is almost double, so just give different limits for glm-5 ... Problem solved.",
              "score": 3,
              "created_utc": "2026-02-12 00:00:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4wo4qm",
                  "author": "SynapticStreamer",
                  "text": "This seems reasonable. Like, I can't even access the free tier with my token? Like wtf.",
                  "score": 2,
                  "created_utc": "2026-02-12 01:37:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4wmvqd",
              "author": "Outrageous-Fan-2775",
              "text": "I'm on the coding plan and I've been using GLM 5 for 3-4 hours now with no rate limits. Could be a tier difference though.",
              "score": 2,
              "created_utc": "2026-02-12 01:30:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4wo1hb",
                  "author": "SynapticStreamer",
                  "text": "Likely. I'm on the cheap ass one.",
                  "score": 2,
                  "created_utc": "2026-02-12 01:37:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4uvc0e",
          "author": "Fearless-Elephant-81",
          "text": "When is synthetic gonna add it :3",
          "score": 0,
          "created_utc": "2026-02-11 19:55:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4uvo4d",
              "author": "jpcaparas",
              "text": "I suggest joining their Discord to get the latest updates. It's a great community. ",
              "score": 2,
              "created_utc": "2026-02-11 19:57:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4vbpih",
                  "author": "ahmetegesel",
                  "text": "why downvoted tho lol",
                  "score": 1,
                  "created_utc": "2026-02-11 21:15:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4uv1tk",
          "author": "HarjjotSinghh",
          "text": "that's exactly what i needed: open-source pain in a cli",
          "score": -13,
          "created_utc": "2026-02-11 19:54:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0wgwr",
      "title": "PSA: Kimi.com shipped DarkWallet code in production. Stop using them.",
      "subreddit": "opencodeCLI",
      "url": "https://extended.reading.sh/stop-using-kimi-dotcom",
      "author": "jpcaparas",
      "created_utc": "2026-02-10 09:41:02",
      "score": 74,
      "num_comments": 18,
      "upvote_ratio": 0.6,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r0wgwr/psa_kimicom_shipped_darkwallet_code_in_production/",
      "domain": "extended.reading.sh",
      "is_self": false,
      "comments": [
        {
          "id": "o4pvb3c",
          "author": "cyh555",
          "text": "people who vibecobe don't really care tbh",
          "score": 3,
          "created_utc": "2026-02-11 00:52:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m0ckr",
          "author": "HarjjotSinghh",
          "text": "darkwallet looks better than my bank app.",
          "score": 5,
          "created_utc": "2026-02-10 13:28:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4p7kky",
          "author": "cutebluedragongirl",
          "text": "I for one know what it's like to constantly implement new features instead of fixing stuff.Â ",
          "score": 2,
          "created_utc": "2026-02-10 22:39:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4l8mpn",
          "author": "TransitionSlight2860",
          "text": "interesting. they should be more cautious about how they expose their codebase without letting people aware. LMAO.",
          "score": 1,
          "created_utc": "2026-02-10 09:55:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4l8zky",
              "author": "jpcaparas",
              "text": "https://preview.redd.it/jfzlyw474nig1.png?width=1536&format=png&auto=webp&s=14beee6ed0c952e85e1f2c02d950849daed7d078\n\nNot their first rodeo. They haven't learned their lesson, and I don't think they have any intention to.",
              "score": 6,
              "created_utc": "2026-02-10 09:58:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4lely8",
                  "author": "Bob5k",
                  "text": "Sadly we can't just ban then in western world.\nI just got kicked from kimi subreddit for sayng a few negative things about their subscription model for Kimi code, so...\nI think as fast as they grew up - they'll be done (at least in eu / us) when people realize how shady they are lol.",
                  "score": 1,
                  "created_utc": "2026-02-10 10:50:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4tyoqe",
          "author": "HarjjotSinghh",
          "text": "i feel your pain - wifi security is fun.",
          "score": 1,
          "created_utc": "2026-02-11 17:23:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m2fo9",
          "author": "evilbarron2",
          "text": "How uncommon are failures like this? Has anyone audited say Google or Amazonâ€™s or Teslaâ€™s codebase for example? Is this really uncommon?",
          "score": -2,
          "created_utc": "2026-02-10 13:40:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mg9x9",
              "author": "mcowger",
              "text": "As a former Google SWE in this space - yes, various parts of our codebase were audited at least every 6 months.",
              "score": 8,
              "created_utc": "2026-02-10 14:54:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4mfgzl",
              "author": "jpcaparas",
              "text": "google and amazon both have soc2. \n\nthat's why kimi.com registered in SG. purely for optics and regulatory buffers but they don't have anything remotely close to audits done if they were say in the us",
              "score": 2,
              "created_utc": "2026-02-10 14:50:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4prz85",
                  "author": "sylfy",
                  "text": "PDPA is an analogue to GDPR, itâ€™s not meant for this purpose. https://regulations.ai/regulations/singapore-summary this should give a more comprehensive overview of the regulatory approach specific to AI.",
                  "score": 0,
                  "created_utc": "2026-02-11 00:33:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4mpvzk",
              "author": "jpcaparas",
              "text": "https://preview.redd.it/0i4oikfktoig1.jpeg?width=1320&format=pjpg&auto=webp&s=27a684f7fb20e86a98af3e82556fcc585f4ea631",
              "score": 2,
              "created_utc": "2026-02-10 15:42:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r4mzch",
      "title": "OpenCode Zen is dead, but MiniMax M2.5 is the ultimate Opus replacement",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r4mzch/opencode_zen_is_dead_but_minimax_m25_is_the/",
      "author": "pipubx",
      "created_utc": "2026-02-14 15:09:29",
      "score": 46,
      "num_comments": 64,
      "upvote_ratio": 0.71,
      "text": "Everyone is mourning the free version of OpenCode Zen, but the real play is moving to MiniMax M2.5. It's the most reliable alternative to Opus I've found. It's a Real World Coworker that costs $1 an hour and hits SOTA benchmarks (80.2% SWE-Bench). I've seen people complain about M2.1 fixing linting instead of errors, but M2.5 is a massive upgrade in task decomposition. If you want the cheapest, most accurate model for your CLI, this is it. Their RL tech blog is a must-read for anyone looking to optimize their dev workflow.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r4mzch/opencode_zen_is_dead_but_minimax_m25_is_the/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o5du9el",
          "author": "mintybadgerme",
          "text": "In my, admittedly limited tests, Kimi 2.5 is both cheaper and better at the moment.",
          "score": 20,
          "created_utc": "2026-02-14 18:56:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fyh9j",
              "author": "ideadude",
              "text": "Same m2.5 keeps running into issues it could get around if it slowed down and thought things through, but it's deciding to just rewrite things that are out of scope. Maybe folks who start from scratch with it have better outcomes, but i have to have other models clean up for it when it breaks shit.",
              "score": 4,
              "created_utc": "2026-02-15 02:20:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5hafba",
                  "author": "mintybadgerme",
                  "text": "Not to mention that M 2.5 is a little bit more expensive than Kimi 2.5. Which makes quite a difference if you're doing a fairly complex project. I get some quite Sonnet vibes out of Kimi.",
                  "score": 1,
                  "created_utc": "2026-02-15 08:57:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5gefng",
              "author": "oulu2006",
              "text": "Same",
              "score": 3,
              "created_utc": "2026-02-15 04:13:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5d1bzt",
          "author": "Big-Masterpiece-9581",
          "text": "Why is it dead?",
          "score": 11,
          "created_utc": "2026-02-14 16:32:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fp0qp",
              "author": "No_Success3928",
              "text": "Its not, OP is being dramatic ðŸ˜‚",
              "score": 10,
              "created_utc": "2026-02-15 01:17:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5cy4ip",
          "author": "DRBragg",
          "text": "Wait, what happened to opencode zen?",
          "score": 10,
          "created_utc": "2026-02-14 16:16:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5d021x",
              "author": "touristtam",
              "text": "No idea the pricing page still list free models: https://opencode.ai/docs/zen#pricing",
              "score": 11,
              "created_utc": "2026-02-14 16:25:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5d56kq",
                  "author": "UseHopeful8146",
                  "text": "If I had to guess they are (or did) rotating models. The free subs change every month or so. At least that was my understanding.",
                  "score": 9,
                  "created_utc": "2026-02-14 16:51:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ev22f",
          "author": "_Turd_Reich",
          "text": "Another clickbait title.",
          "score": 8,
          "created_utc": "2026-02-14 22:14:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cp71p",
          "author": "Specialist-Yard3699",
          "text": "Maybe not Opus, but itâ€™s really good.\nCancel kimi25 subs, and use only minimax+glm now.",
          "score": 8,
          "created_utc": "2026-02-14 15:30:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5es5zv",
              "author": "skewbed",
              "text": "I would avoid subscribing to inference providers. Just use OpenRouter or something similar like OpenCode Zen.",
              "score": 4,
              "created_utc": "2026-02-14 21:58:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5exg2l",
                  "author": "pires1995",
                  "text": "The [nano-gpt](https://nano-gpt.com/r/kVxQFNRB) is a great option for it. The plan is USD 8 and have almost all open-source models (Kimi, GLM, Minimax). I notice some models not working or taking too long, but for the price worth try it. ",
                  "score": 5,
                  "created_utc": "2026-02-14 22:28:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5f8ui9",
                  "author": "Unlikely_Word_5607",
                  "text": "Isn't the whole point of subscribing to inference providers that they subsidise the costs compared to using the API?",
                  "score": 1,
                  "created_utc": "2026-02-14 23:36:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ehi4t",
          "author": "KnifeFed",
          "text": "> Everyone is mourning the free version of OpenCode Zen\n\ntf are you talking about?",
          "score": 3,
          "created_utc": "2026-02-14 21:00:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fknyu",
          "author": "robberviet",
          "text": "It's great for its size (200b). Not Opus or GPT level but good enough.\nAlsocI think you should look at swe-rebench, not swe-bench.",
          "score": 3,
          "created_utc": "2026-02-15 00:49:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cud30",
          "author": "benzflow",
          "text": "How does it compare with Kimi k2.5 and GLM 5?",
          "score": 2,
          "created_utc": "2026-02-14 15:56:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5du3dx",
              "author": "mintybadgerme",
              "text": "Kimi 2.5  is better in my tests.",
              "score": 7,
              "created_utc": "2026-02-14 18:55:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5drkc1",
          "author": "Comrade-Porcupine",
          "text": "I like these open models but I fail to see how $1/hour is better value e.g. the $200/month Codex membership which is basically fully unlimited value.\n\nEthically, yes. And for strictly **API** uses, yes.  I use DeepSeek and others using API tokens and they're dirt cheap and quite effective. But the *coding plans* from GLM and MiniMax and Moonshot are not that awesome of value.",
          "score": 2,
          "created_utc": "2026-02-14 18:43:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fpd75",
              "author": "No_Success3928",
              "text": "Codex Fully unlimited? Not even close.",
              "score": 2,
              "created_utc": "2026-02-15 01:19:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5e5u8o",
          "author": "Crafty_Chart1694",
          "text": "until deepseek 4 comes out",
          "score": 2,
          "created_utc": "2026-02-14 19:56:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e91mb",
          "author": "soul105",
          "text": "Kimi K2.5 is still free and available for me",
          "score": 2,
          "created_utc": "2026-02-14 20:14:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5gevds",
              "author": "Wildnimal",
              "text": "Free where?",
              "score": 0,
              "created_utc": "2026-02-15 04:17:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5h9hka",
                  "author": "soul105",
                  "text": "https://preview.redd.it/2usu5t91gmjg1.png?width=544&format=png&auto=webp&s=dee2668095d144a0627e96ba20f32ff7d59cbf81\n\nYou can also check the current list of [free models](https://opencode.ai/docs/zen/#pricing).",
                  "score": 1,
                  "created_utc": "2026-02-15 08:48:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5cn1sa",
          "author": "HarjjotSinghh",
          "text": "this m2.5 is basically code's new gym rat - cheap, brutal efficiency.",
          "score": 5,
          "created_utc": "2026-02-14 15:18:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cod4i",
          "author": "idkwtftbhmeh",
          "text": "Minimax M2.5 Falls behind both Kimi K2.5 and GLM5 in every bench, hell even glm7 is in front, trully disappointed with the model",
          "score": 6,
          "created_utc": "2026-02-14 15:25:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5f12cv",
              "author": "DinoAmino",
              "text": "Disappointed that a 230B model doesn't score better than models that are 3x and 4x larger? srsly? That's some wildly unrealistic expectations there.",
              "score": 1,
              "created_utc": "2026-02-14 22:49:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5g6hza",
                  "author": "idkwtftbhmeh",
                  "text": "well, I did create my expectations out of the benchs that they announced, which in theory would surpass these models in some cases (doesn't happen)",
                  "score": 1,
                  "created_utc": "2026-02-15 03:15:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5f9ean",
              "author": "Squale279",
              "text": "Bench isnâ€™t the best way to evaluate a llm, try it in real use cases and compare it with other products.",
              "score": 1,
              "created_utc": "2026-02-14 23:39:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5g6ev6",
                  "author": "idkwtftbhmeh",
                  "text": "oh I did, it's quite bad overall to be honest, the speed is great tho",
                  "score": 1,
                  "created_utc": "2026-02-15 03:15:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5d59d3",
              "author": "UseHopeful8146",
              "text": "Iâ€™m sorry, glm 7?",
              "score": 1,
              "created_utc": "2026-02-14 16:51:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5d8g22",
                  "author": "zuk987",
                  "text": "He probably meant 4.7",
                  "score": 4,
                  "created_utc": "2026-02-14 17:07:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5esxea",
              "author": "cri10095",
              "text": "M2.5 is much smaller then the other models",
              "score": 1,
              "created_utc": "2026-02-14 22:02:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5eybxo",
                  "author": "idkwtftbhmeh",
                  "text": "It is indeed, still disappointed, I saw the blog post and benchs and it seems VERY cherrypicked compared to individual researchers like swe-rebench",
                  "score": 2,
                  "created_utc": "2026-02-14 22:33:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5d3swd",
          "author": "touristtam",
          "text": "> Their RL tech blog is a must-read for anyone looking to optimize their dev workflow.\n\nLink please?",
          "score": 3,
          "created_utc": "2026-02-14 16:44:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dmo8h",
          "author": "Both_Ad2330",
          "text": "Hope this gets on AWS Bedrock soon.",
          "score": 1,
          "created_utc": "2026-02-14 18:19:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5f30f1",
          "author": "Moist_Associate_7061",
          "text": "i used minimax 2.5 all day long, and it was not even close kimi k2.5. babysitting is needed..",
          "score": 1,
          "created_utc": "2026-02-14 23:00:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5f6o33",
              "author": "johnerp",
              "text": "Which one is better, Iâ€™m not clear.",
              "score": 4,
              "created_utc": "2026-02-14 23:22:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5gzjg9",
          "author": "XtoddscottX",
          "text": "Can it work with images? Cause yeah, if you need to generate simple code these models are okay, but for some frontend tasks itâ€™s better to use model that accept visual input too, and as I know these Chinese models donâ€™t whilst three American big models do.",
          "score": 1,
          "created_utc": "2026-02-15 07:12:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h20vn",
          "author": "wjjia",
          "text": "Honestly, it was about time we stopped relying on OpenCode Zen anyway. Everyone is freaking out over the shutdown, but it was a loss leader from day one. I haven't put M2.5 through the wringer yet, but if that 80.2% SWE-Bench score actually holds up in real-world messy codebases, it's a massive jump. Most of these models talk a big game and then fail the moment you hit a weird dependency issue.",
          "score": 1,
          "created_utc": "2026-02-15 07:35:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h94py",
          "author": "Relative-Honey-4485",
          "text": "The jump from 2.1 to 2.5 is the real conversation here. 2.1 was driving me insane with that linting obsession - fixing my tabs while the actual logic was still broken. If the task decomposition is actually improved, I might give it a shot. Still skeptical about the $1/hr claim though, there is always a catch with token windows.",
          "score": 1,
          "created_utc": "2026-02-15 08:44:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h9e2k",
          "author": "Capital_Standard4603",
          "text": "RIP OpenCode Zen. It was good while it lasted.",
          "score": 1,
          "created_utc": "2026-02-15 08:47:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hdefr",
          "author": "elaytot",
          "text": "Minimax m2.5 is not better! Cant even tell my project was in typescript after it reviewed the whole codebase.. got me bunch of typeerrors",
          "score": 1,
          "created_utc": "2026-02-15 09:26:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hgw56",
          "author": "Yukeyii",
          "text": "Did anyone actually read the RL tech blog OP mentioned? I just skimmed it and the way they are handling reinforcement learning is actually pretty clever if you are into the infra side of things. It explains why the task breakdown feels more \"human\" than the older versions.",
          "score": 1,
          "created_utc": "2026-02-15 10:00:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5llki0",
              "author": "touristtam",
              "text": "Do you have a link, I have no idea what is the RL tech blog that is being mentioned.\n\nIs that: https://www.minimax.io/news/forge-scalable-agent-rl-framework-and-algorithm ?",
              "score": 1,
              "created_utc": "2026-02-16 00:16:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5i21vo",
          "author": "LionelOOK",
          "text": "\"Opus replacement\" is a bold claim. Opus has that specific feel for creative logic that is hard to replicate, but for pure CLI work and bug fixing, I can see MiniMax taking that spot if it is really that cheap.",
          "score": 1,
          "created_utc": "2026-02-15 13:05:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5i4otx",
          "author": "Feeling-Whole4574",
          "text": "$1 an hour? I will believe it when I see my invoice at the end of the month.",
          "score": 1,
          "created_utc": "2026-02-15 13:23:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5i89ww",
          "author": "Virtual-Path1704",
          "text": "Glad I am not the only one who noticed the linting thing. M2.1 would spend half its energy fixing my indentation instead of actually solving the logic error I was pointing at. If 2.5 fixed that, it is worth the switch.",
          "score": 1,
          "created_utc": "2026-02-15 13:46:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5i9i1h",
          "author": "linegel",
          "text": "Their SWE bench is basically fake news due to too heavy reliance on Anthrophic models \n\nCheck updated SWE bench",
          "score": 1,
          "created_utc": "2026-02-15 13:53:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ib39u",
          "author": "Icy_Net5151",
          "text": "Benchmark obsession needs to stop. SWE-Bench is one thing, but how does it handle a 10-year-old legacy codebase with zero documentation? That is the real test for any \"coworker\" model.",
          "score": 1,
          "created_utc": "2026-02-15 14:03:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5id9c8",
          "author": "ChanningACE",
          "text": "Just switched. It is definitely snappier than 2.1. Not sure if it is \"ultimate\" yet, but it is actually usable for once.",
          "score": 1,
          "created_utc": "2026-02-15 14:15:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ifoi1",
          "author": "Dantenmd",
          "text": "Been looking for a solid Opus alternative since the quality started dipping recently. I will check out that blog post later, thanks for the heads up.",
          "score": 1,
          "created_utc": "2026-02-15 14:29:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5jhoni",
          "author": "amri2k",
          "text": "kimi 2.5 > minimax 2.5",
          "score": 1,
          "created_utc": "2026-02-15 17:40:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cpuqt",
          "author": "0Bitz",
          "text": "How well does it work with Oh-My opencodeâ€¦?",
          "score": 1,
          "created_utc": "2026-02-14 15:33:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5d61rc",
              "author": "UseHopeful8146",
              "text": "In my experience OmO has the structure to make most of the reasoning relatively simple - you could probably get close to kimi/glm level execution with much smaller models, provided they have tool calling support and decent context window.\n\nIâ€™m still in the process of working on tooling and stuff, but testing for local model execution in Opcode/OmO is on my todo list specifically because I hold that theory at present.",
              "score": 3,
              "created_utc": "2026-02-14 16:55:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r2psy1",
      "title": "I just got banned from gemini :)",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r2psy1/i_just_got_banned_from_gemini/",
      "author": "Eastern-Guess-1187",
      "created_utc": "2026-02-12 10:17:46",
      "score": 41,
      "num_comments": 73,
      "upvote_ratio": 0.94,
      "text": "I know that is something that they warn. :) I am afraid of being banned from claude too.. so I just use gpt 5.3 codex in opencode now. which models should I use now? and what's your workflow? I am using omo slim.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r2psy1/i_just_got_banned_from_gemini/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o50b3fa",
          "author": "xmnstr",
          "text": "Happened to me too. If you're in the EU please file a DMA/DSA complaint, not allowing third party access to Antigravity is likely a breach of EU law. Additionally, just banning people without any notice and no method for appeal is also a very likely breach of EU consumer laws.\n\nThey are under investigation for this behavior and now is the perfect time to provide more information about their anticompetitive and anticonsumer actions!",
          "score": 15,
          "created_utc": "2026-02-12 16:49:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50n0ah",
              "author": "Villain_99",
              "text": "Whatâ€™s the process ?",
              "score": 5,
              "created_utc": "2026-02-12 17:46:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o50tjtt",
                  "author": "xmnstr",
                  "text": "I'm not quite sure yet, but looking into it.",
                  "score": 2,
                  "created_utc": "2026-02-12 18:16:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4yk31e",
          "author": "Skquark",
          "text": "I also got banned from Gemini today, didn't expect that. I've been using the opencode-antigravity-auth plug-in to use Claude with Antigravity because I've been running out of my Claude Max 20x weekly limit way too quickly, and I've been paying for Gemini ultra for $250 a month which I hardly used because I just didn't like Gemini 3 Pro nearly as much as I expected, so I thought it was safe to supplement my usage and take advantage of that subscription. I'm writing a letter of appeal to Google in hopes that they might grant me a pardon, but I don't expect much.\n\nI would cancel my Gemini subscription and pay Anthropic $400 a month instead if I could so I don't have to worry about running out of my Opus limits, but that's not even an option. Apparently it's against their terms of service to have two Max accounts, which is really lame. Now I'm being forced to use codex to supplement my addiction, but it's just not satisfying my itch. I guess I have to lean more on Kimi K2.5 and now GLM-5 as my fallbacks. What's a full-time independent developer to do? I've been going all in to take my commercial project I've been working on for so long to completion, can't slow down now...",
          "score": 4,
          "created_utc": "2026-02-12 10:37:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zqril",
              "author": "bigh-aus",
              "text": "At $1000 every 4 months, I'd consider trying out kimi k2.5 on cloud, and if it's good for your use case drop the money on a mac studio.",
              "score": 9,
              "created_utc": "2026-02-12 15:14:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4zyo86",
              "author": "HistorianIll5959",
              "text": "Canâ€™t get a Max account under friend or family members name and just use your card?",
              "score": 1,
              "created_utc": "2026-02-12 15:52:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o50hmbo",
              "author": "HotRelationship1127",
              "text": "I wonder how they knew to ban you. Can you post whatever email announcement they made to you? Maybe there are some clues.",
              "score": 1,
              "created_utc": "2026-02-12 17:20:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55qmdx",
                  "author": "powerfulparadox",
                  "text": "If the prompts and headers from the harness aren't identical, it can be as simple as comparing against expected incoming information. After that, I'm sure there can be behavioral differences that are observable.",
                  "score": 1,
                  "created_utc": "2026-02-13 13:18:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o538y8b",
              "author": "DeathShot7777",
              "text": "Antigravity auth wasnt working for claude models last time i checked. Does it work now? I tried it around a week ago",
              "score": 1,
              "created_utc": "2026-02-13 01:46:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o54cewn",
              "author": "ZeroBraneZ",
              "text": "Brother how TF are you running out of Claude max 20xâ€¦. Like thatâ€™s the first place Iâ€™d look..",
              "score": 1,
              "created_utc": "2026-02-13 06:16:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o561mau",
                  "author": "Skquark",
                  "text": "Dude, I use up 90% of my weekly 20x in about 3-4 days, especially now with Opus 4.6... I'm full time, running 2-4 agents on my giant projects simultaneously, and would be doing more but trying to pace myself and conserve my tokens.. Wish I could tell ya the projects I'm working on obsessively, but keeping my mouth shut until my commercial launches.. Also using Codex Max and Kimi K2.5 at the same time on different sections, but Claude is my main man..",
                  "score": 1,
                  "created_utc": "2026-02-13 14:18:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o59erag",
              "author": "forcaster89",
              "text": "What makes it worth paying 400$ for ai models? Working on multiple projects with almost no revenue , thanks",
              "score": 1,
              "created_utc": "2026-02-14 00:31:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5atwqk",
                  "author": "Skquark",
                  "text": "You're not paying just for AI models, you're paying for an employee with high-level skills that does what you ask and doesn't complain. When you're working full-time with them and break down the cost, you're basically paying a team of super geniuses around $2 an hour. Even if you don't see revenue now, I believe if you keep at it and take it seriously, it pays off in the end, but not if you treat it only as a hobby or curiosity. For a developer that is committed, it's an easily justified cost of business...",
                  "score": 1,
                  "created_utc": "2026-02-14 06:29:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5fqi06",
              "author": "GarageExtreme",
              "text": "You can open two antrhopic accounts and just switch when you fill the quota on one, that's not against ToS",
              "score": 1,
              "created_utc": "2026-02-15 01:26:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4ymx96",
              "author": "Desperate-Bath5208",
              "text": "Were you banned for using the Gemini Opencode Plugin or the Antigravity Opencode Plugin?",
              "score": 1,
              "created_utc": "2026-02-12 11:02:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ys7u3",
                  "author": "Skquark",
                  "text": "It was for using the Antigravity opencode plug-in and using it primarily to access Opus 4.6... I also had the Gemini open code plug-in, but I never really used that since I had the Gemini CLI that I could use anyways, but that didn't let you use anthropic sadly, and I caught Gemini 3 way too many times screwing up my code and not understanding what it was doing in my monorepo. I liked the opencode interface better than the Antigravity IDE, especially because it wasn't maintaining a reliable connection with my SSH to work on through their application. Do they really have to be so strict about their terms of services? Seems territorial...",
                  "score": 2,
                  "created_utc": "2026-02-12 11:47:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ytm7o",
                  "author": "Eastern-Guess-1187",
                  "text": "I was using both. ",
                  "score": -1,
                  "created_utc": "2026-02-12 11:58:53",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4yu25c",
              "author": "Eastern-Guess-1187",
              "text": "yeah I am using codex gpt 5.3 but its not like gemini 3 or opus 4.6. it feels it's dumber ",
              "score": 0,
              "created_utc": "2026-02-12 12:02:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4zdm43",
                  "author": "Character_Cod8971",
                  "text": "How can GPT-5.3-Codex be dumber than Gemini 3 or Opus 4.6?",
                  "score": 2,
                  "created_utc": "2026-02-12 14:05:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4yltbg",
              "author": "aitorserra",
              "text": "Why they banned you?",
              "score": 0,
              "created_utc": "2026-02-12 10:52:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ysdq1",
                  "author": "Skquark",
                  "text": "Because apparently they don't like it when you use third-party software for accessing their services unless you're using API key and not your subscription... Same with Anthropic.",
                  "score": 5,
                  "created_utc": "2026-02-12 11:49:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4ywwjz",
              "author": "Key_Mousse_8034",
              "text": "BTW how are you gonna switch between claude accounts? Because I'm thinking of doing the same. Just 2 claude subscriptions ðŸ˜€",
              "score": 0,
              "created_utc": "2026-02-12 12:23:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55t4pu",
                  "author": "unnamedb",
                  "text": "try cc switch",
                  "score": 1,
                  "created_utc": "2026-02-13 13:32:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o58irwn",
                  "author": "Disillusioned_Sleepr",
                  "text": "Cli use shell variables",
                  "score": 1,
                  "created_utc": "2026-02-13 21:34:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ymxf4",
          "author": "Desperate-Bath5208",
          "text": "Were you banned for using the Gemini Opencode Plugin or the Antigravity Opencode Plugin?",
          "score": 2,
          "created_utc": "2026-02-12 11:03:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ytnk0",
              "author": "Eastern-Guess-1187",
              "text": "I was using both bro",
              "score": 3,
              "created_utc": "2026-02-12 11:59:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o52ler8",
          "author": "dyzhdyzh",
          "text": "Got banned too. The only reason I got their subscription was to use their Opus with OpenCode.\nI have Copilot subscription from work, but the context window is crippled on the most models, and I exhaust the non-premium quota in a few days of coding.\nI guess I'll stick to Synthetic's models then. Kimi K2.5 is fairly good. As many others said, somewhere between Sonnet and Opus. Also, GLM-5 will be available soon.",
          "score": 1,
          "created_utc": "2026-02-12 23:27:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54i48f",
              "author": "YayaBruno",
              "text": "I've been using Kimi K2.5 via Nano-GPT, but it's quite slow, How do you see its speed at Synthetic? I've been considering switching to it. Also, how do you find the rate limits? Are they too restrictive?",
              "score": 1,
              "created_utc": "2026-02-13 07:05:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5bpvyi",
          "author": "HarjjotSinghh",
          "text": "this is the new gemini game show.",
          "score": 1,
          "created_utc": "2026-02-14 11:36:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5djlru",
          "author": "Euphoric-Doughnut538",
          "text": "Everyone needs to perform charge backs since they are banning the API",
          "score": 1,
          "created_utc": "2026-02-14 18:03:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dtk57",
          "author": "layer4down",
          "text": "This is my nightmare. Everyone asks why I donâ€™t use Opus-4.6 or other SaaS models? Thatâ€™s why. I mean they donâ€™t have a SMB tier offering for power user devs grinding out projects like this?",
          "score": 1,
          "created_utc": "2026-02-14 18:53:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5j2pre",
          "author": "evilissimo",
          "text": "Reading this thread, I am so glad that I stopped doing that entirely. I just use my pro account within AG, Jules and Gemini cli and when I need more opus I use my copilot plan on 10$. For OC I have Kimi, MiniMax and GLM coding plans and codex plus which with all of it I canâ€™t use that much at the moment as I am switching around. But I feel like I get fair value out of all my subscriptions.\nAlso using oc zen and open router free models.\n\nI donâ€™t manage to run out of quota anywhere",
          "score": 1,
          "created_utc": "2026-02-15 16:27:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ytjwh",
          "author": "krimpenrik",
          "text": "Use GitHub copilot access to multiple models",
          "score": 1,
          "created_utc": "2026-02-12 11:58:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51wi6z",
              "author": "aydgn",
              "text": "Are you using that way?",
              "score": 1,
              "created_utc": "2026-02-12 21:21:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o54xy8a",
              "author": "oVerde",
              "text": "With only 128k of context window",
              "score": 1,
              "created_utc": "2026-02-13 09:32:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o57xcjf",
              "author": "BoThatch",
              "text": "I've read that Copilot still has issues with opencode in terms of preium request charge. Can you confirm that?\nI want to use Copilot, too. But I'm afraid that my budget will get eaten in no time with any subagent flow/tool calls, when opencode does not set the headers etc correctly.\nThere are still open [issues](https://github.com/anomalyco/opencode/issues/8030) regarding that.",
              "score": 1,
              "created_utc": "2026-02-13 19:47:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5dtrm7",
                  "author": "Dazzling-Solution173",
                  "text": "There has been workarounds that are said in the github copilot reddit, basically since they use subagents to gather context it's basically another premium request, however u can just set it up for tool calls or subagents to use the free 0x models to do it while the main agent stays to what you choose.",
                  "score": 1,
                  "created_utc": "2026-02-14 18:54:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4yivea",
          "author": "Sukkii",
          "text": "I did too, yesterday, and am also keen for recommendations. Going the API route (e.g. open router) is just too steep, what other coding plans are available?",
          "score": 1,
          "created_utc": "2026-02-12 10:25:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zdww5",
              "author": "Character_Cod8971",
              "text": "Were you banned for using the Gemini Opencode Plugin or the Antigravity Opencode Plugin?",
              "score": 0,
              "created_utc": "2026-02-12 14:07:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4zneni",
                  "author": "Sukkii",
                  "text": "Using opencode-antigravity-auth",
                  "score": 3,
                  "created_utc": "2026-02-12 14:57:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4yr9gu",
          "author": "t1maccapp",
          "text": "Same:\n\nGemini has been disabled in this account for violation of Terms of\n    Service. If you believe this is an error, please contact Google Cloud Support, or email\n    gemini-code-assist-user-feedback@google.com.",
          "score": 1,
          "created_utc": "2026-02-12 11:40:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4yt979",
              "author": "benchb",
              "text": "can you explain, which plug in you used and what did you do ?",
              "score": 1,
              "created_utc": "2026-02-12 11:56:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o519q3t",
                  "author": "t1maccapp",
                  "text": "Was using https://github.com/NoeFabris/opencode-antigravity-auth in a pretty chill manner. Like 5-10 requests per day maybe. Both gemini 3 pro and opus 4.5.\n\nI've managed to use opus 4.6 couple of times, until I got banned yesterday.\n\nI don't think I've ever reached the quota limit or even used half of it.",
                  "score": 1,
                  "created_utc": "2026-02-12 19:32:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4z0anv",
              "author": "Eastern-Guess-1187",
              "text": "Emailed and I am waiting for the result",
              "score": 1,
              "created_utc": "2026-02-12 12:46:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o51ae2u",
                  "author": "t1maccapp",
                  "text": "Same, said I'm sorry, won't do ever again. \n\nNot like I care much though, I don't see me leaving opencode, will just probly use Chinese models.",
                  "score": 0,
                  "created_utc": "2026-02-12 19:35:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4zdoxj",
              "author": "Character_Cod8971",
              "text": "Were you banned for using the Gemini Opencode Plugin or the Antigravity Opencode Plugin?",
              "score": 1,
              "created_utc": "2026-02-12 14:06:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o519a3b",
                  "author": "t1maccapp",
                  "text": "For this one https://github.com/NoeFabris/opencode-antigravity-auth",
                  "score": 1,
                  "created_utc": "2026-02-12 19:30:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o52xqzy",
          "author": "cutebluedragongirl",
          "text": "Based, fuck Google",
          "score": 0,
          "created_utc": "2026-02-13 00:38:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yq8my",
          "author": "pinklove9",
          "text": "What kind of a ban is this",
          "score": 0,
          "created_utc": "2026-02-12 11:31:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ytriz",
              "author": "Eastern-Guess-1187",
              "text": "only for gemini / antigravity. but I emailed them and I promised that I won't use anything thats 3rd party :D",
              "score": 1,
              "created_utc": "2026-02-12 12:00:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o53ph35",
                  "author": "StrixGGUY",
                  "text": "you are the amin admin of the subscription? if yes simple add another gmail acc, add to your family sharing, add allow google on sharing, you have new access to antigravity -> always use second shared acc for this, if you get banned simple remove from familys haring and add another one easy and fast \n\nhttps://preview.redd.it/i8rnw7qhl6jg1.png?width=1015&format=png&auto=webp&s=40d911905e7da7342de8ebece4fd693ee36e3df1\n\n",
                  "score": 5,
                  "created_utc": "2026-02-13 03:28:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o51p385",
                  "author": "ItsStrike13",
                  "text": "Any response from them?",
                  "score": 1,
                  "created_utc": "2026-02-12 20:45:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o51ycyx",
                  "author": "aydgn",
                  "text": "Can you use [gemini.google.com](http://gemini.google.com) or it is just for Gemini CLI/Antigravity?",
                  "score": 1,
                  "created_utc": "2026-02-12 21:29:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o521yyt",
          "author": "HarjjotSinghh",
          "text": "what's next when gemini bans you, a new ai god named my boss?",
          "score": 0,
          "created_utc": "2026-02-12 21:47:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53ymeh",
          "author": "lundrog",
          "text": "Synthetic.new has a waiting list but be a good option. Dm me for a referral if interested",
          "score": 0,
          "created_utc": "2026-02-13 04:30:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56rl6b",
              "author": "Halfwalker",
              "text": "I hadn't heard of Synthetic before, just took a look. Their SignUp link is there and looks to be working ?  What does a referral get you ?",
              "score": 0,
              "created_utc": "2026-02-13 16:26:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o57kcnk",
                  "author": "lundrog",
                  "text": "We each get credit to use either $10 or $20 off a month",
                  "score": 0,
                  "created_utc": "2026-02-13 18:44:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o58d3x3",
          "author": "SalvadorTMZ",
          "text": "how do you know if you're banned?",
          "score": 0,
          "created_utc": "2026-02-13 21:06:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58swyo",
          "author": "No_Strategy_6034",
          "text": "Can someone actually explain whats happening? I dont understand what got you all banned, idk what the TOS is, all of your comments skip explaining what is the reason of the Ban...\n\nYou cant use gemini / Claude in opencode? Thats it?",
          "score": 0,
          "created_utc": "2026-02-13 22:24:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ynzt5",
          "author": "MegamillionsJackpot",
          "text": "I use Codex + synthetic.new that works nicely.\n\nI think synthetic.new has done some covert marketing on Reddit, so they get some hate for that, but it is still a nice deal. Hopefully, they will add GLM 5.0 soon .\n\nEdit with some news from synthetic:\n\nJust finished setting up our new B200 GPU cluster, where we'll be running `hf:Kimi-K2.5-NVFP4`. The deploy to flip backends is going out now and should be out within the half hour. ðŸ™‚\n\nWe plan to get a version of GLM 5 up for all of you to try soonâ„¢! We plan to move all our infrastructure to (presumably US based) Blackwells in the coming days which should signfiicantly increase our request capacity. ðŸ™‚ \n\n-# You can check when we're back to US only by running `curl \"https://api.synthetic.new/openai/v1/models?provider=synthetic\" | jq '.data[] | select(.id == \"hf:nvidia/Kimi-K2.5-NVFP4\") | {name, datacenters}'` and waiting for `IL` to flip to `US` ðŸ˜›",
          "score": -5,
          "created_utc": "2026-02-12 11:12:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50p0f2",
              "author": "Crinkez",
              "text": "Your standard and pro price point limits are not linear. Stardard users get ripped off.",
              "score": 0,
              "created_utc": "2026-02-12 17:55:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o50pga5",
                  "author": "MegamillionsJackpot",
                  "text": "It's not my prices. I'm really not affiliated with the firm. I just use it.",
                  "score": 0,
                  "created_utc": "2026-02-12 17:57:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o50mqz0",
          "author": "Villain_99",
          "text": "Use kimi or the upcoming glm 5",
          "score": -1,
          "created_utc": "2026-02-12 17:44:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r058ba",
      "title": "I just wanted to make a shout out to OpenCode developers",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r058ba/i_just_wanted_to_make_a_shout_out_to_opencode/",
      "author": "OptimizmSolutions",
      "created_utc": "2026-02-09 14:12:22",
      "score": 36,
      "num_comments": 2,
      "upvote_ratio": 0.96,
      "text": "I have been trying it for a while and what you have built is truly amazing. It's the only opensource alternative to Code Claude that truly convinced me! I'm sure that with the next generation of os LLMs it will become a no Brainerd vs the other options",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r058ba/i_just_wanted_to_make_a_shout_out_to_opencode/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4fxq95",
          "author": "Ok-Connection7755",
          "text": "to all the devs who are / have worked on opencode, heartfelt thanks! You make my life so much better daily!",
          "score": 3,
          "created_utc": "2026-02-09 15:03:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4l4jc4",
          "author": "HarjjotSinghh",
          "text": "open source llms? sounds like some kind of cult meeting i want in.",
          "score": 1,
          "created_utc": "2026-02-10 09:15:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4uuiw",
      "title": "Opencode for all!1!1!1!",
      "subreddit": "opencodeCLI",
      "url": "https://v.redd.it/4doqqb8yqijg1",
      "author": "Extension_Armadillo3",
      "created_utc": "2026-02-14 20:21:29",
      "score": 32,
      "num_comments": 4,
      "upvote_ratio": 0.82,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r4uuiw/opencode_for_all111/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5khton",
          "author": "HarjjotSinghh",
          "text": "wow that's actually genius ceiling tech",
          "score": 1,
          "created_utc": "2026-02-15 20:39:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5eow8q",
          "author": "jpcaparas",
          "text": "at costco atm. dont give me ideas.",
          "score": 0,
          "created_utc": "2026-02-14 21:40:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ec2kn",
          "author": "HarjjotSinghh",
          "text": "this shop's ceiling looks like a tech-themed skylight.",
          "score": -1,
          "created_utc": "2026-02-14 20:30:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5eepto",
          "author": "soul105",
          "text": "Big Pickle at your service!",
          "score": -1,
          "created_utc": "2026-02-14 20:45:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3jbfd",
      "title": "All-in-one subscription that gives both strong reasoning + cheap coding models?",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r3jbfd/allinone_subscription_that_gives_both_strong/",
      "author": "minhpro279",
      "created_utc": "2026-02-13 07:55:23",
      "score": 26,
      "num_comments": 21,
      "upvote_ratio": 0.91,
      "text": "Iâ€™ve been using OpenCode with Antigravity, but got banned recently and now Iâ€™m looking for a replacement.\n\nMy ideal setup is simple:\none strong model for reasoning/planning,\none cheaper fast model as the workhorse for implementation,\nand preferably under a single subscription since I donâ€™t want to manage multiple subscription.\n\nIâ€™m considering Cursor, Copilot, Chutes, Synthetic, etc., but would love to hear whatâ€™s actually working well in practice.\n\nIâ€™ve heard opencode burn through premium requests quickly on Copilot, while Chutes/Synthetic donâ€™t really offer a strong planning model ( i miss opus TT kimi 2.5 is good, but not there yet. have not used gpt5.3 )\n\nAnyway if youâ€™re in a similar situation, would love to hear your experience. Any recommendations?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r3jbfd/allinone_subscription_that_gives_both_strong/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o55baw1",
          "author": "dengar69",
          "text": "In looking at GitHub Copilot Pro+ for all the closed models, and NanoGPT for all the open ones.  $47 per month for both.",
          "score": 6,
          "created_utc": "2026-02-13 11:33:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56msk5",
              "author": "Desperate-Bath5208",
              "text": "https://www.reddit.com/r/opencodeCLI/comments/1r2fjyn/opencode_vs_github_copilot_cli_huge_credit_usage/\n\nhttps://github.com/anomalyco/opencode/issues/8030\n\nhttps://github.com/anomalyco/opencode/issues/13360",
              "score": 2,
              "created_utc": "2026-02-13 16:03:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o57bm7o",
                  "author": "dengar69",
                  "text": "Thanks.  Looks like Im keeping my OpenAI plan open for now.",
                  "score": 1,
                  "created_utc": "2026-02-13 18:02:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o54t6yf",
          "author": "Desperate-Bath5208",
          "text": "z.ai",
          "score": 8,
          "created_utc": "2026-02-13 08:47:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5eb1sd",
              "author": "pablonhc",
              "text": "I feel that with use it becomes less intelligent",
              "score": 1,
              "created_utc": "2026-02-14 20:25:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o54u1d9",
          "author": "Bob5k",
          "text": "Have a note synthetic has Kimi k2.5 via Nvidia which is more preformant than any other source for this model.\nAlso have in mind that they have -20$ discount on pro plan with [reflink](https://synthetic.new/?referral=IDyp75aoQpW9YFt).\n\nOn another note tho, minimax M2.5 is pretty damn powerful and fast aswell and it's available across mm coding plans (with [discount](https://platform.minimax.io/subscribe/coding-plan?code=HO46LCwAJ5&source=link) aswell). \nThis or [glm coding plan](https://z.ai/subscribe?ic=CUEFJ9ALMX) are a solid backup plans which are also quite cheap around to get into.",
          "score": 9,
          "created_utc": "2026-02-13 08:55:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o55i5k9",
              "author": "pungggi",
              "text": "Is synthetic from Nvidia? Really?",
              "score": -4,
              "created_utc": "2026-02-13 12:24:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o56buhu",
                  "author": "mcowger",
                  "text": "No.  \n\nSynthetic has a â€œturboâ€ variant of K2.5 that uses nvidias NVFP4 format for better performance",
                  "score": 3,
                  "created_utc": "2026-02-13 15:10:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o54pczw",
          "author": "wallapola",
          "text": "I'm not a bot and this is not an ad. Just sharing my experience since I actually use this. Iâ€™m using synthetic mainly because of the promo and so far itâ€™s been noticeably faster than before. I might even stay after the promo expires since their service is a lot better compared to other providers. I feel more secure using it and I no longer want to explore other AI providers because it takes a lot of time and usually requires paying just to try their plans.\n\nThey recently added US-based servers, and one of them is using NVIDIA GPUs. I donâ€™t really understand all the infra details, but performance-wise itâ€™s definitely faster compared to their previous setup. Latency feels a lot better on my end.\n\nOne thing to note is that I think the standard plan is still on a waitlist right now, while the pro plan is available. If anyone wants to double-check, their discord is probably the best place. The devs are active there and they post updates about infra changes, issues and what theyâ€™re working on.\n\nIf you want to try it with the discounted offer:  \n[https://synthetic.new/?referral=4NNoPUXcb63ZYVK](https://synthetic.new/?referral=4NNoPUXcb63ZYVK)\n\nEdit: Based on what Iâ€™ve seen on their discord, theyâ€™re really focusing on improving and stabilizing the service with their new infra setup and servers. They plan to add glm-5 once the infrastructure can handle more users, since adding it too early would definitely flood the service and cause slowdowns.",
          "score": 4,
          "created_utc": "2026-02-13 08:11:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o59dn7g",
              "author": "sudoer777_",
              "text": "What countries where they using before for servers?",
              "score": 1,
              "created_utc": "2026-02-14 00:24:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o55qvhi",
              "author": "disrupted_bln",
              "text": "currently when you sign up for one of their plans there is a waitlist",
              "score": 1,
              "created_utc": "2026-02-13 13:19:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o59lyec",
                  "author": "elllyphant",
                  "text": "Yes there's a waitlist and it'll take a couple more weeks. We'll email those on the waitlist and announce in our [Discord](https://discord.gg/syntheticlab) when we're ready to take on more new subscribers.  \n  \nThe reason is that we want to ensure users get the experience they are paying for so we're taking time to ensure we can scale properly. Thank you so much for your patience in the meantime and I hope you get to try Synthetic soon!",
                  "score": 2,
                  "created_utc": "2026-02-14 01:15:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o56s20l",
          "author": "jorgejhms",
          "text": "Any news about Opencode Black?",
          "score": 1,
          "created_utc": "2026-02-13 16:28:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5b9qob",
          "author": "alp82",
          "text": "Windsurf is a very strong contender. You won't get a better token for money count. Lots of models to choose from.\n\nI don't know Chutes and Synthetic though.",
          "score": 1,
          "created_utc": "2026-02-14 08:59:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o551n6g",
          "author": "Putrid-Pair-6194",
          "text": "My setup.\nWorkhorses: Kimi 2.5 from Moonshot, GLM from Z.ai (pro plan).  \nPlanning and validation: GPT 5.2, 5.3 codex via OpenAI team plan.  \n\nNew Fallback: Gemini 3.0 flash via API (free credits)\n\nI just learned about the Gemini API free credits route and set it up so havenâ€™t used extensively yet. Everything else works well",
          "score": 1,
          "created_utc": "2026-02-13 10:07:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o552ayh",
          "author": "Embarrassed_Bread_16",
          "text": "I'm using 20 USD plan from chutes.ai, it allows for making 5k requests daily, the most I can use is 2k when working on many projects at once, it allows for using open source models, like Kimi, glm, minimax\n\n\nIt has drawback that some models might temporarily be over utilized by people and API will become unresponsive and u need to change to other model, but it happened to me only for half an hour yesterday and I'm subscribed for 2 days\n\n\nI also bought minimax coding plan to try out the m2.5, gotta say it is super fast, but haven't used it enough to compare the quality",
          "score": 0,
          "created_utc": "2026-02-13 10:13:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55brpu",
          "author": "keroro7128",
          "text": "High-order model source: GitHub; low-order model source: Minimaz coding plan.",
          "score": 0,
          "created_utc": "2026-02-13 11:37:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5566xz",
          "author": "amba420",
          "text": "I'm using the synthetic new pro plan and Kimi is quite fast the last 2 days now. \n\nI'm using Kimi for planning and glm4.7 mostly for the work horse part. Works good\n\nBut they have a wait-list for new customers if anyone would like here is my referral:\n\nhttps://synthetic.new/?referral=vVOTagHw7nzmm2b",
          "score": -2,
          "created_utc": "2026-02-13 10:49:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54vmme",
          "author": "ScorpionOfWar",
          "text": "Been using open-source models more lately for private stuff, I got the 100$ Claude Sub for work.\n\nEnded up trying [Synthetic](https://synthetic.new/?referral=hcHozzHNE8CxVvz)(\\~50% off) and it's been very solid so far, alternatively [Z.ai](https://z.ai/subscribe?ic=KQ77ZVKLB5)(\\~10% off) for just the GLM Models, nice for coding, but kind of unreliable at the moment. They host open-source models and the API is OpenAI-compatible so it just plugs into your CLI or Dev Environment. $20/mo flat for the subscription tier is nice.\n\nWith my ref link to Synthetic and Z you are able to get a rebate.",
          "score": -2,
          "created_utc": "2026-02-13 09:10:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r18htv",
      "title": "$80 budget for AI subs this month (lost $20 to GLM)â€”whatâ€™s the best stack?",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r18htv/80_budget_for_ai_subs_this_month_lost_20_to/",
      "author": "Anxious-Candidate588",
      "created_utc": "2026-02-10 18:18:13",
      "score": 23,
      "num_comments": 28,
      "upvote_ratio": 0.9,
      "text": "I get a $100/month reimbursement for AI, but I forgot to cancel a GLM model subscription, so Iâ€™m stuck with only $80 left for this cycle.\n\nIâ€™m a heavy user and usually go for Claude Max ($100). Since I canâ€™t afford that this month, whatâ€™s the best combination of subscriptions I can get for $80?\n\nNote: I prefer flat-rate monthly subscriptions and do not want pay-as-you-go API pricing.\n\nWhat would you pick to get the most \"unlimited\" feel for coding and heavy usage?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r18htv/80_budget_for_ai_subs_this_month_lost_20_to/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4nyfqa",
          "author": "t4a8945",
          "text": "Easy choice! Get only 1 ChatGPT Plus ($20), and just get 1 or 2 or 3 more accounts if necessary given your budget.\n\nRight now Codex 5.3 is awesome, and usage is double for the next two months. That's what I'd do in your shoes.",
          "score": 13,
          "created_utc": "2026-02-10 19:06:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nst6h",
          "author": "guillefix",
          "text": "GitHub Copilot Pro+ for $39 then connect it to Open Code.",
          "score": 22,
          "created_utc": "2026-02-10 18:41:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4q3683",
              "author": "jpcaparas",
              "text": "It's insanely good value, and you get a really rich model garden. There's so much utility for GH on multiple interfaces. ",
              "score": 6,
              "created_utc": "2026-02-11 01:39:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4rsrm4",
              "author": "foolsgold1",
              "text": "Yes, but having the quota only renew per month is really frustrating.  Burn through the quota in week 1, then wait 3 weeks to use it again.",
              "score": 3,
              "created_utc": "2026-02-11 09:29:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4svuuc",
              "author": "KPOTOB",
              "text": "Would the opencode accessing codex burn premium requests?",
              "score": 1,
              "created_utc": "2026-02-11 14:14:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4x1ho3",
              "author": "Rude-Needleworker-56",
              "text": "Don't github copilot still silently cap the context  behind the scenes to a fraction of what is supported by the model?",
              "score": 1,
              "created_utc": "2026-02-12 02:57:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4xu9r6",
                  "author": "guillefix",
                  "text": "Well, what did you expect for $39 instead of $100.",
                  "score": 0,
                  "created_utc": "2026-02-12 06:29:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4nun2i",
          "author": "jpcaparas",
          "text": "If you are not a power user, GitHub Copilot Pro+ offers the best value for money for Opus 4.6 and Codex 5.3 access. It suffers from rate limiting when spawning parallel subagents (for reference, I always have 40 in parallel at any given time for research tasks), but for basic stuff like writing code (ie max 5-10 agents in parallel), it's worth it. The inference is also slower compared to Claude sub and Claude direct API access\n\nFor Kimi K2.5 and GLM 4.7, the king is still Synthetic and OpenCode Zen (which reminds me, my Black sub hasn't been activated after a month of waiting).\n\nDo not get from Kimi dot com if you are working on non-hobby projects.",
          "score": 11,
          "created_utc": "2026-02-10 18:49:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4o4dbl",
          "author": "Outrageous-Story3325",
          "text": "Kimi k2.5 on opencode",
          "score": 6,
          "created_utc": "2026-02-10 19:34:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5du0bp",
              "author": "AGiganticClock",
              "text": "What's the best way to buy this? Zen API credits?",
              "score": 1,
              "created_utc": "2026-02-14 18:55:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4ydcia",
              "author": "downvotedbylife",
              "text": "Been using this plus a $20 chatgpt plan for codex and I dont really run into any limitations. Considering cancelling chatgpt and use just kimi once the 0.99 month ends",
              "score": 1,
              "created_utc": "2026-02-12 09:31:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4npi7z",
          "author": "calben99",
          "text": "With $80 and wanting flat-rate unlimited coding, I'd go with Cursor Pro ($20) + ChatGPT Plus ($20) + Claude Pro ($20). That gives you three different model approaches and stays well under budget at $60 total. Cursor is unbeatable for coding workflow, ChatGPT has the best tool ecosystem, and Claude excels at reasoning through complex problems. Save the extra $20 for next month or grab Perplexity Pro if you want research capabilities.",
          "score": 3,
          "created_utc": "2026-02-10 18:26:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4nqa3j",
              "author": "Anxious-Candidate588",
              "text": "I dont use cursor. I mostly use Zed or neovim and these days mostly using opencode. So not sure if cursor is a good choice",
              "score": 7,
              "created_utc": "2026-02-10 18:29:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4pxmyg",
                  "author": "Shep_Alderson",
                  "text": "Drop cursor pro and add copilot+",
                  "score": 5,
                  "created_utc": "2026-02-11 01:06:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4nxjaa",
                  "author": "Visible-Ground2810",
                  "text": "I also use neovim and cli. The best so far is opus in Claude code. I have tried everything.",
                  "score": 1,
                  "created_utc": "2026-02-10 19:02:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4onbhb",
          "author": "jhartumc",
          "text": "$20 GPT plus + $20 Kimi For Coding  \nGPT-5.3 as planing and Kimi k2.5 as subagents worker",
          "score": 2,
          "created_utc": "2026-02-10 21:02:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r1td0",
              "author": "BuildAISkills",
              "text": "That's a solid plan.\nSomeone said a GPT Team plan at 30 USD gives even more usage than Plus, but I haven't tried it. For now you still get 2X quota anyway.",
              "score": 2,
              "created_utc": "2026-02-11 05:26:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4p40l1",
          "author": "SeniorFallRisk",
          "text": "1x GPT Plus account and 2x GPT Business accounts (a single gpt account can have plus and business accounts with separate quotas so you only need 2 email addresses for this), is $80.\nThen you can use something like my opencode-codex-auth plugin to use all 3 amounts in a single app.\n\nEdit: you could also just spend all $100 every month on maximum ChatGPT / Codex credits, or do a $20 plus account and $80 of credits. Thats probably the better option.",
          "score": 2,
          "created_utc": "2026-02-10 22:21:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ntjdy",
          "author": "EuSouTehort",
          "text": "Github Copilot Pro+ for implementation and access to chatgpt models, on Opencode  \nclaude 1x for brainstorming / planning",
          "score": 1,
          "created_utc": "2026-02-10 18:44:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54tz70",
          "author": "HarjjotSinghh",
          "text": "glm is just paying for your future regret.",
          "score": 1,
          "created_utc": "2026-02-13 08:54:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ry9fb",
          "author": "ScorpionOfWar",
          "text": "Been using open-source models more lately for private stuff, I got the 100$ Claude Sub for work.\n\nEnded up trying [Synthetic](https://synthetic.new/?referral=hcHozzHNE8CxVvz)(\\~50% off) and it's been very solid so far, alternatively [Z.ai](https://z.ai/subscribe?ic=KQ77ZVKLB5)(\\~10% off) for just the GLM Models, nice for coding, but kind of unreliable at the moment. They host open-source models and the API is OpenAI-compatible so it just plugs into your CLI or Dev Environment. $20/mo flat for the subscription tier is nice.\n\nWith my ref link to Synthetic and Z you are able to get a rebate.",
          "score": 1,
          "created_utc": "2026-02-11 10:19:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4o3yyp",
          "author": "trypnosis",
          "text": "Look I know you said you donâ€™t like pay as you go but stay with me.\n\nBuy Co pilot pro+ thatâ€™s 1500 gpt 5.2 the rest left in the kitty in case you need more thatâ€™s another 1250ish.\n\nIf you assume a 4 week month thatâ€™s 20 days of work.\n\nCoding 7 hours a day thatâ€™s one request per 3 min \n\nNow personally I donâ€™t code 7 hours a day. Nor do i need gpt 5.2 for all my tasks.",
          "score": 0,
          "created_utc": "2026-02-10 19:32:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rlxhm",
          "author": "TurnUpThe4D3D3D3",
          "text": "Codex with 5.3 is an excellent value. They have a very generous $20 tier.\n\nAlternatively, OpenCode with Kimi is also great",
          "score": 0,
          "created_utc": "2026-02-11 08:24:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nr41b",
          "author": "atiqrahmanx",
          "text": "Get   \n1. ChatGPT Pro ($20)  \n2. Claude Pro ($20)  \n3. GitHub Copilot Pro ($10)  \n4. AmpCode (daily $10 free usage of Opus, GPT models)  \n5. OpenCode (free usage of sub-par models e.g. Kimi, GLM)",
          "score": -1,
          "created_utc": "2026-02-10 18:33:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r1m16",
              "author": "ZeSprawl",
              "text": "AmpCode shut off access for new users to the free 10 dollars of usage",
              "score": 0,
              "created_utc": "2026-02-11 05:25:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4r4eib",
                  "author": "atiqrahmanx",
                  "text": "If you email them, pretty sure theyâ€™ll give you access.",
                  "score": 0,
                  "created_utc": "2026-02-11 05:47:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4nxdev",
          "author": "Visible-Ground2810",
          "text": "Best deal is to get Claude max 5x with this amount",
          "score": -3,
          "created_utc": "2026-02-10 19:01:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4qbn66",
              "author": "Codemonkeyzz",
              "text": "Nope",
              "score": -1,
              "created_utc": "2026-02-11 02:30:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r2fjyn",
      "title": "OpenCode vs GitHub Copilot CLI â€” huge credit usage difference for same prompt?",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r2fjyn/opencode_vs_github_copilot_cli_huge_credit_usage/",
      "author": "usernameIsRand0m",
      "created_utc": "2026-02-12 01:05:14",
      "score": 23,
      "num_comments": 23,
      "upvote_ratio": 0.96,
      "text": "Trying to figure out if I messed something up in my OpenCode config or if this is just how it works.\n\nIâ€™m on OpenCode 1.1.59.  \nI ran a single prompt. No sub agents.  \nIt cost me 27 credits.\n\nI thought maybe OpenCode was doing extra stuff in the background, so I disabled agents:\n\n    \"permission\": {\n      \"task\": \"deny\"\n    },\n    \"agent\": {\n      \"general\": {\n        \"disable\": true\n      },\n      \"explore\": {\n        \"disable\": true\n      }\n    }\n    \n\nRan the exact same prompt again. Still 27 credits.\n\nFor comparison, I tried the same prompt with GitHub Copilot CLI and it only used 3 credits for basically the same task and output.\n\nNot talking about model pricing here. Iâ€™m specifically wondering if:\n\n* Thereâ€™s some other config Iâ€™m missing that controls how much work OpenCode does per prompt\n* OpenCode is doing extra planning or background steps even with agents disabled\n* Anyone else has seen similar credit usage and figured out what was causing it\n\nBasically, is this normal for OpenCode or am I accidentally paying for extra stuff I donâ€™t need?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r2fjyn/opencode_vs_github_copilot_cli_huge_credit_usage/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4wl2bh",
          "author": "simap2000",
          "text": "Wonder if each round trip in opencode for every tool call, etc counts as a request vs many tool calls and agents in copilot is like 1?",
          "score": 4,
          "created_utc": "2026-02-12 01:18:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4wmgbk",
              "author": "usernameIsRand0m",
              "text": "It was not like this few (maybe 5-6 versions?) versions ago. I am wondering if I am missing something in the config that I need to have.",
              "score": 1,
              "created_utc": "2026-02-12 01:27:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ycer8",
                  "author": "SvenVargHimmel",
                  "text": "Use litellm proxy and run with ---detailed-debug  and point opencode to that  with the proxy configured to point to your llm backend and you can see exactly what it is sending per request. \n\n  \nThen point your Copilot at the same endpoint. \n\n  \nYou can see exactly what's going on. \n\nAnd if you want to test your theory that it used be less expensive a few versions ago , just roll back and repeat \n\n  \n",
                  "score": 4,
                  "created_utc": "2026-02-12 09:22:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4xjj39",
                  "author": "albertortilla",
                  "text": "There were problems in older version (1.1.38 if I am no wrong) regarding this: each tool call counted in GitHub copilot as a new request, which was solved in the next versions... Maybe the problem appeared again... I would try to install an older version and check for the same prompt",
                  "score": 1,
                  "created_utc": "2026-02-12 05:00:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4z25wj",
          "author": "krimpenrik",
          "text": "Same issue saw that I am already using a lot opencode with copilot sub, this month is fucked",
          "score": 3,
          "created_utc": "2026-02-12 12:59:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51at7x",
          "author": "PayTheRaant",
          "text": "Check your small model configuration. This is the model for generating the titles of sessions and messages. You should use a free model for that. \n\nAlso try the same prompt with a free model: if your premium request cost is not zero, then something else is triggering premium requests with a paid model.",
          "score": 3,
          "created_utc": "2026-02-12 19:37:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51c6ap",
              "author": "PayTheRaant",
              "text": "You can also use debug logs to track every single call to the LLM\n\nhttps://opencode.ai/docs/troubleshooting/#journaux",
              "score": 1,
              "created_utc": "2026-02-12 19:44:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o53oh68",
                  "author": "usernameIsRand0m",
                  "text": "So, apart from the above config which I have shared in OP, I have to add small model config?\n\nI'll check the debug logs. Thanks.",
                  "score": 1,
                  "created_utc": "2026-02-13 03:22:28",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o537bmt",
          "author": "itsjase",
          "text": "its a known bug: [https://github.com/anomalyco/opencode/issues/8030](https://github.com/anomalyco/opencode/issues/8030)",
          "score": 3,
          "created_utc": "2026-02-13 01:36:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xpzyi",
          "author": "Michaeli_Starky",
          "text": "Yep, noticed the same. Switched to Copilot CLI",
          "score": 2,
          "created_utc": "2026-02-12 05:52:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ykxmn",
          "author": "Adorable_Buffalo1900",
          "text": "opencode claude model use chat completions api, but copilot use message api. you need raise a issue for opencode",
          "score": 2,
          "created_utc": "2026-02-12 10:44:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4y2ywi",
          "author": "keroro7128",
          "text": "I've heard that some people are saying they can use the free GPT 5 Mini model to call advanced models ï¼ˆopus 4.6ï¼‰ via a sub-agent without consuming any requests, but some are saying they got their accounts banned for it.",
          "score": 1,
          "created_utc": "2026-02-12 07:49:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51ce6k",
              "author": "PayTheRaant",
              "text": "Normally, switching model for sub agent is considered a new premium request.",
              "score": 2,
              "created_utc": "2026-02-12 19:45:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4yrzcr",
              "author": "usernameIsRand0m",
              "text": "Yes, there are lot of instances of that happening, I have Pro+ account, so there are more than enough requests per month for me.",
              "score": 1,
              "created_utc": "2026-02-12 11:46:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4y7uxq",
          "author": "Tadomeku",
          "text": "The system prompt in Opencode is likely longer than the system prompt in GitHub CLI. YOUR prompt may be simple, but it gets appended to the system prompt in Opencode, along with AGENTS.md, CLAUDE.md, SKILLS, etc.    \n    \nI don't know what GitHub CLI does under the hood but I imagine it's pretty different.",
          "score": 1,
          "created_utc": "2026-02-12 08:37:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51a49q",
              "author": "PayTheRaant",
              "text": "Copilot model is expected to consume ONE premium request per ONE user prompt.\nEverything else that is agent initiated is expected to be included in that initial premium request (all tools, even sub agent) as long as it stays in the same model. \nIn theory, it should not even care about input token cache.\n\nSo this is why having 27 premium requests consumed is considered a big problem.",
              "score": 1,
              "created_utc": "2026-02-12 19:34:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ydnqg",
          "author": "soul105",
          "text": "Noticed the same here.  \nSome business users have the limit for 300 requests and cannot buy more due to company policies, making the problem even bigger.",
          "score": 1,
          "created_utc": "2026-02-12 09:35:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o528g2s",
          "author": "HarjjotSinghh",
          "text": "wow copilot's gonna charge you like a slot machine.",
          "score": 1,
          "created_utc": "2026-02-12 22:18:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53n2tt",
          "author": "Desperate-Bath5208",
          "text": "Happened to me as well, I barely used it and I've consumed $2 worth of quota.",
          "score": 1,
          "created_utc": "2026-02-13 03:13:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xd8l2",
          "author": "jmhunter",
          "text": "The preamble/system prompt is probably a lot juicier w opencode",
          "score": 1,
          "created_utc": "2026-02-12 04:14:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xoc9l",
              "author": "IIALE34II",
              "text": "Billing should be one premium request per user initialized message. Or well there is the per model scaling.",
              "score": 5,
              "created_utc": "2026-02-12 05:38:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4x434i",
          "author": "ok_i_am_nobody",
          "text": "Same issue. \nMoved to pi coding agent for simple tasks.\nHow are you tracking the credits usage?",
          "score": 0,
          "created_utc": "2026-02-12 03:13:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xnagy",
              "author": "usernameIsRand0m",
              "text": "In your settings page, here - [https://github.com/settings/billing/premium\\_requests\\_usage](https://github.com/settings/billing/premium_requests_usage)",
              "score": 0,
              "created_utc": "2026-02-12 05:29:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r5cdq7",
      "title": "Built a tool to track OpenCode/Claude Code API usage - Anthropic Pro/Max limits, Copilot, and more",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/yyypov9x8njg1.jpeg",
      "author": "prakersh",
      "created_utc": "2026-02-15 11:28:44",
      "score": 22,
      "num_comments": 2,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r5cdq7/built_a_tool_to_track_opencodeclaude_code_api/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5j98i0",
          "author": "landed-gentry-",
          "text": "Will this be useful if I use the same key (e.g., Anthropic) on different machines? Or will it lose track of the bigger picture.",
          "score": 1,
          "created_utc": "2026-02-15 16:58:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5j9vx1",
              "author": "prakersh",
              "text": "Yes,\nIt'll work of you use same key across systems. I've separate monitoring linux server and use claude code on my macbook.",
              "score": 1,
              "created_utc": "2026-02-15 17:01:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r13qup",
      "title": "Am I the Only One Using GUI? and is the CLI Better?",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r13qup/am_i_the_only_one_using_gui_and_is_the_cli_better/",
      "author": "Level-Dig-4807",
      "created_utc": "2026-02-10 15:27:04",
      "score": 21,
      "num_comments": 26,
      "upvote_ratio": 0.83,
      "text": "Hello, \n\nI downloaded Opencode a week ago after a youtube video suggested it to me. \n\nI have always worked on GUIs rather than the CLI. I noticed a few things,\n\nThe GUI's MCP calling is not very good and fails mostly, \n\n  \nAfter Antigravity's new rate limiting on the Claude models, I needed a daily driver for which I choose Kimi 2.5 however on the \n\n  \nMost of the Youtube tutorial workflows suggested Opus for Planning and use OpenCodeCLI inside the Antigravity terminal rather than the CLI.\n\nI tried the GUI and Kimi 2.5 was performing very bad instead I had to switch to Kilocode which I found better. Idk y but I feel the CLI is noticeable better than the GUI than most cases and even it's used by most of the people.\n\n  \nWould like to know ur views",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r13qup/am_i_the_only_one_using_gui_and_is_the_cli_better/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4mv5dg",
          "author": "mcowger",
          "text": "The CLI and GUI are identical in how they interact with the model.  \n\nBoth are just a way to communicate with the underlying opencode server.",
          "score": 11,
          "created_utc": "2026-02-10 16:06:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mv592",
          "author": "rusl1",
          "text": "OpenChamber is a bless",
          "score": 6,
          "created_utc": "2026-02-10 16:06:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4px7mq",
              "author": "SvenVargHimmel",
              "text": "I use it with tailwind. It developing nicely. \n\nsubagent calling is a drop down menu instead of the @ subagent  , that can get old pretty quickly\n\n",
              "score": 2,
              "created_utc": "2026-02-11 01:03:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4nkztn",
              "author": "touristtam",
              "text": "> OpenChamber\n\nLemme guess another electron app?",
              "score": 1,
              "created_utc": "2026-02-10 18:05:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4nodvg",
                  "author": "rusl1",
                  "text": "Nope :) it's written in Go or Rust, I don't recall",
                  "score": 0,
                  "created_utc": "2026-02-10 18:21:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4qlpik",
              "author": "gsxdsm",
              "text": "Openchamber is amazing",
              "score": 0,
              "created_utc": "2026-02-11 03:32:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4r4p3b",
              "author": "Haunting_Good1948",
              "text": "openchamber on my left, antigravity on my right, middle is the editor.",
              "score": 0,
              "created_utc": "2026-02-11 05:49:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4pxe9i",
          "author": "aeroumbria",
          "text": "Opencode CLI is basically as feature rich as GUIs from other developers in terms of \"graphical\" functions, but I do find the Web UI easier to use when managing multiple sessions without giving them complete permission to everything. \n\nI personally would not use any of the other \"scrolling\" type CLI agents in an interactive manner. One shot tasks or \"the questions and forget\" maybe, but it is frustrating to stare at stacked edits and try to figure out what is going on. Opencode at least lets you see edits in a nicely highlighted manner and list all current edits and TODOs at once.",
          "score": 2,
          "created_utc": "2026-02-11 01:04:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4qgicm",
              "author": "Potential-Leg-639",
              "text": "Agree, Opencode changed the whole workflow completely for me. Still want to integrate Opencode Desktop as well to better manage all the open sessions.",
              "score": 1,
              "created_utc": "2026-02-11 02:59:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4qxtpg",
          "author": "FlyingDogCatcher",
          "text": "You guys know you can use your mouse on the cli, right?. To just click stuff",
          "score": 2,
          "created_utc": "2026-02-11 04:56:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mp1sb",
          "author": "mr_ignatz",
          "text": "I donâ€™t know if itâ€™s the same for OpenCode, but many of the CLIs use ink, a framework for making console apps with React, enabling the underlying logic to be much closer to the same.",
          "score": 1,
          "created_utc": "2026-02-10 15:38:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4nekof",
              "author": "shaonline",
              "text": "OpenCode's team made their own TUI library (OpenTUI) but yeah in principle it's about the same, using React (or SolidJS in OpenTUI's case) for building TUIs. I think only Codex CLI is a special case, it's built in Rust.",
              "score": 4,
              "created_utc": "2026-02-10 17:36:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4qg59b",
          "author": "Potential-Leg-639",
          "text": "Use opencode in a terminal in an IDE ;)",
          "score": 1,
          "created_utc": "2026-02-11 02:57:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tnemz",
              "author": "Mr-Fan-Tas-Tic",
              "text": "but how do you manage code like let say you dont like the code it generated ?  \ndo you use simple git ?\n\n",
              "score": 1,
              "created_utc": "2026-02-11 16:30:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4u0j2t",
                  "author": "Potential-Leg-639",
                  "text": "simply copy the code you dont like into your opencode session, tell opencode what you dont like and review the result again. the IDE is just there to check your files/codebase if you want, i normally use it without IDE at all.",
                  "score": 2,
                  "created_utc": "2026-02-11 17:31:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4rm9xx",
          "author": "OtherwiseHornet4503",
          "text": "Thereâ€™s a GUI?!?",
          "score": 1,
          "created_utc": "2026-02-11 08:27:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4towhn",
          "author": "beall49",
          "text": "I use it. It's freaking awesome",
          "score": 1,
          "created_utc": "2026-02-11 16:37:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5048en",
          "author": "Illustrious_Club2865",
          "text": "Not reading everything here ... but I don't understand how you would do things like this from a gui?:  \n\\- Install tshark and anylyze this .pcapng file in this folder and tell me the communications between [1.1.1.1](http://1.1.1.1) and [2.2.2.2](http://2.2.2.2) and what could be causing communication errors  \n\\-or-  \n\\- Create a node.script to query url abce123 dot com and give the data betwen div1 and div2 and save in json format - run here and debug accordingly - we can use playwrite/chromium  \n\\-or-  \n\\- Create a Get-WinEvent to query events 1,2,3,4 and tell me wyz abc  \n\\-or-  \n\\- Save the entire process we performed here as an MD file so we can revisit later  \n\\-or- -or- -or- ... ",
          "score": 1,
          "created_utc": "2026-02-12 16:17:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mofnv",
          "author": "HarjjotSinghh",
          "text": "i love command line so much, but my hands are too lazy to type",
          "score": 1,
          "created_utc": "2026-02-10 15:35:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4n26ce",
          "author": "Recent-Success-1520",
          "text": "You can try CodeNomad , it uses Opencode behind the scenes.\nWhatever tool you use to interact TUI, Web, Desktop they all are the same internally use opencode",
          "score": 1,
          "created_utc": "2026-02-10 16:39:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5awy8a",
          "author": "HarjjotSinghh",
          "text": "oh damn i just got a gui that actually works.",
          "score": 0,
          "created_utc": "2026-02-14 06:57:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r08c11",
      "title": "Running Opencode on Docker (Safe and working!)",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r08c11/running_opencode_on_docker_safe_and_working/",
      "author": "LinsaFTW",
      "created_utc": "2026-02-09 16:11:34",
      "score": 19,
      "num_comments": 12,
      "upvote_ratio": 0.89,
      "text": "I was struggling to get this working so after some workarounds I found the solution and just wanted to share it with you.\n\n## **Step 1 â€” Project Structure**\n\nCreate a folder for your setup:\n\n```\nopencode-docker/\nâ”œâ”€â”€ Dockerfile        # Dockerfile to install OpenCode AI\nâ”œâ”€â”€ build.sh          # Script to build the Docker image\nâ”œâ”€â”€ run.sh            # Script to run OpenCode AI safely\nâ”œâ”€â”€ container-data/   # Writable folder for OpenCode AI runtime & config\nâ””â”€â”€ projects/         # Writable folder for AI projects/code\n```\n\n---\n\n### **Step 2 â€” Dockerfile**\n\n```dockerfile\n# Dockerfile for OpenCode AI\nFROM ubuntu:latest\n\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install dependencies\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    curl \\\n    ca-certificates \\\n    git \\\n    openssh-client \\\n    sudo \\\n && rm -rf /var/lib/apt/lists/*\n\n# Create non-root user if not exists\nRUN id -u ubuntu &>/dev/null || useradd -m -s /bin/bash ubuntu \\\n && echo \"ubuntu ALL=(ALL) NOPASSWD: ALL\" > /etc/sudoers.d/ubuntu \\\n && chmod 0440 /etc/sudoers.d/ubuntu\n\nUSER ubuntu\nWORKDIR /home/ubuntu\n\n# Prepare SSH config and known_hosts for git\nRUN mkdir -p /home/ubuntu/.ssh \\\n && touch /home/ubuntu/.ssh/known_hosts \\\n && ssh-keyscan -T 5 github.com 2>/dev/null >> /home/ubuntu/.ssh/known_hosts || true\n\n# Install OpenCode AI\nRUN curl -fsSL https://opencode.ai/install | bash\n\n# Add OpenCode AI binary to PATH\nENV PATH=\"/home/ubuntu/.opencode/bin:${PATH}\"\n```\n\n---\n\n### **Step 3 â€” Build Script (`build.sh`)**\n\n```bash\n#!/bin/bash\nset -e\n\n# Build OpenCode AI Docker image\ndocker build -t opencode-ai:latest .\n```\n\nMake executable:\n\n```bash\nchmod 700 build.sh\n```\n\n---\n\n### **Step 4 â€” Run Script (`run.sh`)**\n\n```bash\n#!/bin/bash\n\ndocker run --rm -it \\\n  # Writable runtime/config folder\n  -v \"$HOME/opencode-docker/container-data:/home/ubuntu/.local\" \\\n  -v \"$HOME/opencode-docker/container-data/config:/home/ubuntu/.config/opencode\" \\\n  # Writable project workspace\n  -v \"$HOME/opencode-docker/projects:/workspace\" \\\n  -w /workspace \\\n  # Ensure OpenCode AI binary is in PATH\n  -e PATH=\"/home/ubuntu/.opencode/bin:${PATH}\" \\\n  opencode-ai:latest \\\n  opencode\n```\n\nMake executable:\n\n```bash\nchmod 700 run.sh\n```\n\n---\n\n### **Step 5 â€” Setup Host Directories**\n\n```bash\nmkdir -p ~/opencode-docker/container-data/config\nmkdir -p ~/opencode-docker/projects\n\n# Give container ownership of writable folders\nsudo chown -R 1000:1000 ~/opencode-docker/container-data ~/opencode-docker/projects\n```\n\n> These folders are where OpenCode AI can safely store runtime files and project code.\n\n---\n\n### **Step 6 â€” Build the Docker Image**\n\n```bash\n./build.sh\n```\n\n* This installs OpenCode AI in a non-root container.\n* All credentials and runtime files stay outside the image.\n\n---\n\n### **Step 7 â€” Run OpenCode AI**\n\n```bash\n./run.sh\n```\n\n* The container uses `/workspace` for your project code.\n* Scripts (`build.sh` and `run.sh`) are read-only to Docker.\n* OpenCode AI can create/edit files in `projects/` without modifying your host scripts.\n\n---\n\n### **Step 8 â€” Tips**\n\n* Keep all sensitive host credentials outside the image.\n* Rebuild image to update OpenCode AI: `./build.sh`\n* Add new projects inside `projects/` folder; the container has write access here.\n* Use read-only mounts (`:ro`) for scripts if you want extra safety.\n\n---\n\n### âœ… **Folder Summary**\n\n| Folder               | Purpose                                  |\n| -------------------- | ---------------------------------------- |\n| `build.sh`, `run.sh` | Host-only, immutable scripts             |\n| `container-data/`    | Writable container runtime/config files  |\n| `projects/`          | Writable workspace for AI-generated code |",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r08c11/running_opencode_on_docker_safe_and_working/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4gfs5i",
          "author": "DavidNorena",
          "text": "Nice, another alternative im using in linux is just to use setpriv to sandbox my projects. (if your kernel version supports it)",
          "score": 5,
          "created_utc": "2026-02-09 16:31:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ghw46",
          "author": "Michaeli_Starky",
          "text": "Devcontainers",
          "score": 4,
          "created_utc": "2026-02-09 16:41:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4han95",
              "author": "Kylecribbs",
              "text": "This is the best way imo",
              "score": 2,
              "created_utc": "2026-02-09 18:56:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4gnfsx",
              "author": "telewebb",
              "text": "porkchop sandwiches",
              "score": 1,
              "created_utc": "2026-02-09 17:07:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4i2zsp",
                  "author": "Michaeli_Starky",
                  "text": "Excuse me?",
                  "score": 1,
                  "created_utc": "2026-02-09 21:16:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4h7sgz",
          "author": "_stuikerd",
          "text": "https://github.com/glennvdv/opencode-dockerized this is my setup, maybe you can get some inspiration out of it",
          "score": 2,
          "created_utc": "2026-02-09 18:43:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i9lbp",
              "author": "LinsaFTW",
              "text": "I made this tutorial from that base, did not work for me!",
              "score": 2,
              "created_utc": "2026-02-09 21:49:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4kydar",
          "author": "viss_bus_labi",
          "text": "Docker is not safe, should not be considered safe.",
          "score": 1,
          "created_utc": "2026-02-10 08:14:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pcg5f",
              "author": "ElPastinak",
              "text": "Why is it so? I find this approach interesting regarding keeping the agent isolated from sensitive data/code.",
              "score": 1,
              "created_utc": "2026-02-10 23:05:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5hpxnk",
                  "author": "viss_bus_labi",
                  "text": "docker containers inherently are not a true sandbox and a lot of escapes are possible. ",
                  "score": 1,
                  "created_utc": "2026-02-15 11:26:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4l1lut",
          "author": "HarjjotSinghh",
          "text": "this docker config sounds way safer than my last attempt where opencode broke my keyboard.",
          "score": 1,
          "created_utc": "2026-02-10 08:46:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lwuwc",
          "author": "No-Leopard7644",
          "text": "Does this work for multi user access?",
          "score": 1,
          "created_utc": "2026-02-10 13:07:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0hate",
      "title": "Z.aiâ€™s GLM-5 leaked through GitHub PRs and a zodiac easter egg",
      "subreddit": "opencodeCLI",
      "url": "https://extended.reading.sh/glm-5-leaked",
      "author": "jpcaparas",
      "created_utc": "2026-02-09 21:33:11",
      "score": 19,
      "num_comments": 13,
      "upvote_ratio": 0.83,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r0hate/zais_glm5_leaked_through_github_prs_and_a_zodiac/",
      "domain": "extended.reading.sh",
      "is_self": false,
      "comments": [
        {
          "id": "o4k56p4",
          "author": "Vaviloff",
          "text": "Member-only story (paywalled). Sorry, I'd rather subscribe to your patreon than give money to that garbage service called Medium.",
          "score": 9,
          "created_utc": "2026-02-10 04:15:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kn5cl",
              "author": "jpcaparas",
              "text": "apologies, should be sorted now\n\n(starts substack)",
              "score": 3,
              "created_utc": "2026-02-10 06:31:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4lr87v",
                  "author": "Vaviloff",
                  "text": "Thank you for opening it, just finished reading, what a piece!",
                  "score": 1,
                  "created_utc": "2026-02-10 12:30:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4kop4g",
          "author": "Simple_Split5074",
          "text": "The details on glm 4.5 seem wrong, it's the same size as 4.6 and 4.7",
          "score": 1,
          "created_utc": "2026-02-10 06:45:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kq7m6",
              "author": "jpcaparas",
              "text": "Thanks for pointing it out. I'll make the apt updates shortly.\n\n(Edit: Just need a bit more time to one-shot it and not having to correct factual errors too often)",
              "score": 1,
              "created_utc": "2026-02-10 06:58:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4n0sp4",
          "author": "HarjjotSinghh",
          "text": "this guy knew how to hide his secret weapon like a pro",
          "score": 1,
          "created_utc": "2026-02-10 16:32:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4u6viz",
          "author": "HarjjotSinghh",
          "text": "glm 5 sounds like my new favorite ghost project.",
          "score": 1,
          "created_utc": "2026-02-11 18:01:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kmv6p",
          "author": "Atomzwieback",
          "text": "Anyway z.ai is shit itâ€™s slow as fuck and a cash grab",
          "score": -1,
          "created_utc": "2026-02-10 06:29:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kn24p",
              "author": "jpcaparas",
              "text": "yep, GLM is slow af on Z.ai. only reason I have it is the MCP servers ðŸ¤·â€â™‚ï¸ and the free year of ultra\n\nbut I'm hopeful for GLM-5 on other providers.",
              "score": 2,
              "created_utc": "2026-02-10 06:31:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4m2bzy",
                  "author": "Professional-Cup916",
                  "text": "Free year?",
                  "score": 1,
                  "created_utc": "2026-02-10 13:39:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r4oqi8",
      "title": "Best GUI for OpenCode",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r4oqi8/best_gui_for_opencode/",
      "author": "Character_Cod8971",
      "created_utc": "2026-02-14 16:20:30",
      "score": 19,
      "num_comments": 30,
      "upvote_ratio": 0.89,
      "text": "Is the OpenCode desktop app really the best GUI there is out there for Windows? I tried it for a few days now and it doesn't have Worktrees support and in general doesn't really feel well thought out or treated with much love. What are all of you using? Maybe you use something completely decoupled from OpenCode.....\n\nEDIT: There are workspaces in OpenCode desktop but there are super hidden (Hover the project title, three dots appear to the right of it. Enable workspaces.) and I didnt get them to work yet which is why they don't really exist for me in this app. (https://github.com/anomalyco/opencode/issues/11089)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r4oqi8/best_gui_for_opencode/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o5d1ifq",
          "author": "BarryTownCouncil",
          "text": "I don't think the gui is at all good, but then also the tui sucks when it comes to copy and paste on nix. And in both I find it impossible to see it's thoughts.\n\nI tried openchamber. Openly vibe coded and boy it shows. Broken in weird and unacceptable ways. That was quite a new experience looking for alternatives and being very disappointed.\n\nCodeNomad seems ok for it, not amazing but worth a look.",
          "score": 7,
          "created_utc": "2026-02-14 16:32:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5d7ow8",
              "author": "UseHopeful8146",
              "text": "Also nix user, so far I much prefer codenomad to everything else. The remote feature is really the best part to me - though even with tailscale and and adding the site page as a PWA to Home Screen, it still gives me problems sometimes. Rarely critical as long as Iâ€™m home, but it can be annoying.\n\nIf there were a program that offered all that, ran only as well, and offered stt I would recommend that instead js (manifesting, manifesting)",
              "score": 2,
              "created_utc": "2026-02-14 17:03:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5fwhau",
                  "author": "Electronic_Newt_8105",
                  "text": "does codenomad stream properly? i was having issues with most of the GUI options streaming the reasoning properly",
                  "score": 1,
                  "created_utc": "2026-02-15 02:07:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5d16on",
          "author": "Ok-Connection7755",
          "text": "Openchamber, hands down wins!",
          "score": 12,
          "created_utc": "2026-02-14 16:31:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5dst65",
              "author": "cmbtlu",
              "text": "I use Openchamber as well. Itâ€™s the best for mobile right now until a native app is released.",
              "score": 5,
              "created_utc": "2026-02-14 18:49:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5d19us",
              "author": "Ok-Connection7755",
              "text": "But I also tried sidecar, maestro, etc. several nice projects coming up",
              "score": 2,
              "created_utc": "2026-02-14 16:31:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5gsrjw",
              "author": "gsxdsm",
              "text": "Definitely open chamber",
              "score": 1,
              "created_utc": "2026-02-15 06:09:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5dunwo",
          "author": "mirza_rizvi",
          "text": "Just run \"opencode web\" instead of \"opencode\"",
          "score": 3,
          "created_utc": "2026-02-14 18:58:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d5wao",
          "author": "Recent-Success-1520",
          "text": "CodeNomad supports worktrees, desktop, web, mobile, remote",
          "score": 6,
          "created_utc": "2026-02-14 16:54:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5di05v",
              "author": "Character_Cod8971",
              "text": "How do you think it compares to OpenChamber?",
              "score": 0,
              "created_utc": "2026-02-14 17:56:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5djqcm",
                  "author": "Recent-Success-1520",
                  "text": "I am biased as I built it. TBH\nI like to see all the details but optionally can make it less verbose.\nI haven't used openchamber, it doesn't work for me on my Intel Mac when I tried recently",
                  "score": 2,
                  "created_utc": "2026-02-14 18:04:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5gssfk",
          "author": "gsxdsm",
          "text": "Openchamber",
          "score": 2,
          "created_utc": "2026-02-15 06:09:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dg7nc",
          "author": "pixeladdie",
          "text": "I haven't needed anything but the TUI.",
          "score": 1,
          "created_utc": "2026-02-14 17:47:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dmzqb",
          "author": "atkr",
          "text": "web / desktop app is still beta, no one should rely on it",
          "score": 1,
          "created_utc": "2026-02-14 18:20:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5do4pz",
              "author": "Character_Cod8971",
              "text": "So what are your recommendations?",
              "score": 1,
              "created_utc": "2026-02-14 18:26:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5fnaa4",
          "author": "mr_ignatz",
          "text": "TIL that Kilo is based on OpenCode underneath",
          "score": 1,
          "created_utc": "2026-02-15 01:05:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gwvob",
          "author": "Outrageous_Client272",
          "text": "I don't think it's the best for coding. But, I've working on OpenWork for non-coding tasks. It's more meant to share you opencode config with non-tech friends, family, and colleagues.\n\nWould love to get feedback on it we launched a month ago and grew to close to 10k stars on github and 70k downloads.\n\n  \nStill pretty early though, so would love some feedback from the community :)",
          "score": 1,
          "created_utc": "2026-02-15 06:47:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h92p0",
          "author": "HarjjotSinghh",
          "text": "yeah workspaces are buried under layers here - wish devs would just fix the ui!",
          "score": 1,
          "created_utc": "2026-02-15 08:44:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5hpbfn",
              "author": "Character_Cod8971",
              "text": "Didn't get them to work.... ðŸ˜­",
              "score": 1,
              "created_utc": "2026-02-15 11:20:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hsvzv",
          "author": "Purple_End4828",
          "text": "Hey OpenCode community,\n\nTL;DR: Iâ€™m building UnLoveable, a self-hosted Loveable/Bolt-style â€œprompt -> docs -> checklist -> agent swarm executesâ€ builder on top of OpenCode. This repo already has a Next.js build UI (Monaco editor, file explorer, diffs, PTY terminal, orchestrator dashboard) talking to a Bun/Hono OpenCode server (SSE orchestrator events, file read/write, PTY websockets, multi-provider LLM). What I need help finishing: a real safe preview/sandbox (not just iframe-a-URL), reliable parallel worker isolation + merging, and better prompt-to-plan output quality so agents produce working code more consistently.\n\nHereâ€™s how my Valentineâ€™s Day went: sitting alone in my apartment in, Georgia, doomscrolling and thinking â€œwhy am I paying for yet another â€˜AI builds your appâ€™ tool when Iâ€™m literally surrounded by an agent runtime?â€\n\nSo I snapped and started building a self-hosted alternative on top of OpenCode.\n\nWhat I built: UnLoveable\n\nA local-first â€œprompt â†’ docs â†’ plan â†’ agent swarm executes while you watchâ€ builder.\n\nItâ€™s not trying to be a magic SaaS website generator. The premise is: generate the planning artifacts first (spec/UI spec/architecture/registry/implementation plan/prompt), then have multiple OpenCode agents chew through the checklist with tests/validation, with a UI that lets you observe + intervene.\n\nCodebase tour (whatâ€™s actually in this repo)\n\n- web/: Next.js (React 19) app with a split-pane build UI (Monaco editor, diff viewer, orchestrator dashboard, SSE event console) + an xterm PTY terminal.\n\n- opencode/: Bun + Hono headless server exposing:\n\n- Orchestrator routes (/orchestrator/...) including SSE stream at /orchestrator/:id/event\n\n- File browser + read/write (/file, /file/content, /file/status)\n\n- PTY over WebSocket (/pty/:id/connect)\n\n- Provider plumbing via Vercel AI SDK (OpenAI + OpenAI-compatible + others)\n\n- workspace/: mounted project directory where generated docs/code live (see docker-compose.yml volume mounts).\n\n- Loop packs/templates: templates/unloveable/, unloveable_loop_v2/ (â€œRalph Wiggum static-context loopâ€: checklist-driven, fresh context per iter, runlogs, validation profiles).\n\nWhatâ€™s working right now\n\n- /build â€œIDEâ€: file explorer + Monaco edit/save via /file/content, diff viewer via /file/status, orchestrator panel for editing generated docs, terminal via /pty.\n\n- â€œSimple Modeâ€ kickoff: start orchestrator â†’ generate docs via pipeline â†’ run checklist executor with configurable workers.\n\n- Real-time-ish updates: the UI listens to orchestrator SSE events and refreshes status/dashboards.\n\nWhere Iâ€™m stuck (and what I want help with)\n\n1.\tâ Preview / sandboxing / â€œrun what we builtâ€\n\n- Current â€œLive Previewâ€ is literally an iframe that loads a URL you paste (web/src/components/live-preview.tsx). Itâ€™s not a sandbox.\n\n- What I want: click â€œPreviewâ€ and it spins up the generated app (Vite/Next/etc.) in an isolated way, then embeds it reliably (ideally same-origin proxied) without CORS/postMessage misery or security footguns.\n\n2) Multi-worker isolation + merging back\n\n- The runner can parallelize tasks; when workers > 1 it tries to use git worktrees (opencode/src/orchestrator/runner.ts + worktree pool/merger).\n\n- I need battle-tested guidance on merge strategy + conflict handling + how to make parallel agents not trample each other (and what to do when the target workspace isnâ€™t a git repo).\n\n3) Output quality (docs + plan â†’ executable tasks)\n\n- Pipeline doc generation is currently a pretty bare prompt that returns JSON schema (opencode/src/orchestrator/pipeline.ts).\n\n- I need stronger prompting + post-processing so the implementation plan becomes â€œagent-executableâ€ more consistently (right granularity, no deprecated libs, fewer dead-end tasks, better validation hooks).\n\nWhy Iâ€™m posting\n\nItâ€™s 3AM energy, but the bones feel real: OpenCode is already the hard part. This UI + orchestration layer is the missing â€œBolt/Loveable experienceâ€ for people who want self-hosted + transparent + hackable.\n\nIf you want to dig in, the most relevant files:\n\n- docker-compose.yml\n\n- web/src/app/build/page.tsx\n\n- web/src/components/live-preview.tsx\n\n- opencode/src/orchestrator/pipeline.ts\n\n- opencode/src/orchestrator/runner.ts\n\n- opencode/src/server/routes/orchestrator.ts\n\n- opencode/src/server/routes/file.ts\n\n- opencode/src/server/routes/pty.ts\n\nHow you can help\n\n- If youâ€™ve solved â€œsafe preview for untrusted/generated web codeâ€ in a product: tell me the architecture youâ€™d use here.\n\n- If youâ€™ve built parallel agent systems: Iâ€™d love opinions on worktree/branch/patch-based workflows + conflict resolution ergonomics.\n\n- If youâ€™re good at prompt-to-plan reliability: help me tighten the pipeline so it produces better specs + checklists.\n\nRepo link: Iâ€™ll drop it once I push a cleaned snapshot (itâ€™s currently living as this local codebase).\n\nIf youâ€™ve ever rage-coded something at 2AM and thought â€œwait, this might actually be useful,â€ please chime in.\n\nThis version does not work yet, but has some much needed architecture changes\n\nhttps://github.com/unloveabledev/UnLoveable-parallel\n\nThis version works but has way too much logic in the frontend, and runs loops in series, so it is kinda slow.\n\nhttps://github.com/unloveabledev/unloveable-series",
          "score": 1,
          "created_utc": "2026-02-15 11:52:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dc74o",
          "author": "SynapticStreamer",
          "text": "CLI.",
          "score": 0,
          "created_utc": "2026-02-14 17:26:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5lxkol",
              "author": "Docs_For_Developers",
              "text": "tell the people",
              "score": 1,
              "created_utc": "2026-02-16 01:29:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5dqoyb",
              "author": "Character_Cod8971",
              "text": "Nah, GUIs are better, and I see what they did with the Codex desktop app for Mac and it seems awesome.",
              "score": -1,
              "created_utc": "2026-02-14 18:38:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5g9gek",
                  "author": "SynapticStreamer",
                  "text": "gross",
                  "score": 0,
                  "created_utc": "2026-02-15 03:37:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5d1ms6",
          "author": "HarjjotSinghh",
          "text": "ohhh worktrees would've saved my soul.",
          "score": 0,
          "created_utc": "2026-02-14 16:33:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5d5iw6",
              "author": "AndroidJunky",
              "text": "Hover the project title, three dots appear to the right of it. Enable workspaces.",
              "score": 1,
              "created_utc": "2026-02-14 16:52:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5dq8gz",
                  "author": "Character_Cod8971",
                  "text": "Whoaahhh, why do they hide it like this? This feature is so important. They should really place it more prominently somewhere, as they did for the Codex Mac Desktop app",
                  "score": 1,
                  "created_utc": "2026-02-14 18:36:36",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r2mw1u",
      "title": "No time for release notes, let's ship it a daily update /s",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r2mw1u/no_time_for_release_notes_lets_ship_it_a_daily/",
      "author": "soul105",
      "created_utc": "2026-02-12 07:13:01",
      "score": 18,
      "num_comments": 5,
      "upvote_ratio": 0.92,
      "text": "https://preview.redd.it/ya0lig1ak0jg1.png?width=1980&format=png&auto=webp&s=fe92a7273ebb8fbcd3094b39ec310a2f81407aee\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r2mw1u/no_time_for_release_notes_lets_ship_it_a_daily/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4ya76g",
          "author": "sitkarev",
          "text": "i still have frequent memory leakages",
          "score": 3,
          "created_utc": "2026-02-12 09:00:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56510t",
              "author": "_Deftera_",
              "text": "You should stop drinking alcohol",
              "score": 3,
              "created_utc": "2026-02-13 14:36:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o51ds9s",
          "author": "HarjjotSinghh",
          "text": "this means beta.",
          "score": 1,
          "created_utc": "2026-02-12 19:51:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z95uz",
          "author": "Heavy-Focus-1964",
          "text": "people on this sub seem to often forget that this product is *free.* have you ever heard the term â€œyou get what you pay for?â€",
          "score": -2,
          "created_utc": "2026-02-12 13:41:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zdjhp",
              "author": "soul105",
              "text": "You are right, the product is awesome and it's free.  \n  \nThe intention was to have a moment of fun where the wishes to deliver something faster were stronger than waiting for a good headline for the release notes. Release notes don't need to be boring.",
              "score": 6,
              "created_utc": "2026-02-12 14:05:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r2uylw",
      "title": "MiniMax-M2.5 Now First to Go Live on NetMind (Before the Official Launch), Free for a Limited Time Only",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/gu8hlkc1r2jg1.png",
      "author": "MarketingNetMind",
      "created_utc": "2026-02-12 14:33:08",
      "score": 18,
      "num_comments": 12,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r2uylw/minimaxm25_now_first_to_go_live_on_netmind_before/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4zjtyr",
          "author": "Nexmean",
          "text": "> M2.5 surpasses Claude Opus 4.6 on both SWE-bench Pro and SWE-bench Verified, placing it among the absolute best models for real-world software engineering. \n\nCrazy if true",
          "score": 7,
          "created_utc": "2026-02-12 14:38:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o501c86",
              "author": "getaway-3007",
              "text": "It's always untrue.\n\nBecause imagine someone is selling an axe for $10, now you've built a new axe which outperforms the best(or 2nd best if you think 5.3-codex xhigh is #1) then why would you sell for cheap? You would at least sell for $6 or $7 because it would still be cheaper than $10. \n\nI think the good comparison is Sonnet 4.5. all the open-source models are in that range not the Opus, Gpt-5.2 xhigh, etc",
              "score": 3,
              "created_utc": "2026-02-12 16:04:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o507m1d",
                  "author": "RegrettableBiscuit",
                  "text": "I don't believe that M2.5 will beat Opus 4.6. However, compared to Anthropic's pricing, Chinese models like K2.5 and GLM-5, both of which are superb models, do provide much better performance and quota per cost.\n\n\nThere are a bunch of reasons for that, primarily the need for these companies to take away market share from the big American providers.Â ",
                  "score": 3,
                  "created_utc": "2026-02-12 16:33:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o50f82c",
                  "author": "Nexmean",
                  "text": "> why would you sell for cheap\n\nwhy would you release open weights as well?",
                  "score": 2,
                  "created_utc": "2026-02-12 17:09:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4zlhwj",
              "author": "Embarrassed_Bread_16",
              "text": "ill try and see",
              "score": 1,
              "created_utc": "2026-02-12 14:47:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o52kps7",
          "author": "HarjjotSinghh",
          "text": "how many devs actually need netmind's free cloud?",
          "score": 1,
          "created_utc": "2026-02-12 23:24:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zy48c",
          "author": "jhartumc",
          "text": "There is no free access ",
          "score": 1,
          "created_utc": "2026-02-12 15:49:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50mahi",
              "author": "LittleChallenge8717",
              "text": "try in opencode, free for a week",
              "score": 1,
              "created_utc": "2026-02-12 17:42:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o51460g",
              "author": "MarketingNetMind",
              "text": "So sry abt the inconvenience & thx for spotting this! We have fixed the issue. You are able to use it for completely free now",
              "score": 1,
              "created_utc": "2026-02-12 19:05:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4zzxwb",
          "author": "jackai7",
          "text": "If free why Asking to add credit??",
          "score": 0,
          "created_utc": "2026-02-12 15:57:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5148s7",
              "author": "MarketingNetMind",
              "text": "So sry abt the inconvenience & thx for spotting this! We have fixed the issue. You are able to use it for completely free now",
              "score": 2,
              "created_utc": "2026-02-12 19:06:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r0d34g",
      "title": "Whatâ€™s the best practice to define multi (sub-)agent workflow",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r0d34g/whats_the_best_practice_to_define_multi_subagent/",
      "author": "No_Issue_4425",
      "created_utc": "2026-02-09 19:01:08",
      "score": 17,
      "num_comments": 2,
      "upvote_ratio": 0.95,
      "text": "I want to create a really simple workflow to optimize context usage and therefore save tokens and increase efficiency. Therefore I want to create something like a plan, build, review workflow, where planning an and review are done by dedicated subagents (with specific models, prompt, temperature, â€¦). I created the subagents according to the documentation https://opencode.ai/docs/agents/ in the agents folder of the projects and placed the desired workflow in the AGENTS.md file. But somehow it is kind of random if it is picked up by the main agent. Do I have to write my own orchestrator agent to make it work? I donâ€™t want to write the system prompt for the main agent.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r0d34g/whats_the_best_practice_to_define_multi_subagent/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4m2lm7",
          "author": "lmdz6oz",
          "text": "Hello! I did something similar recently, took inspiration from this [Gist](https://gist.github.com/gc-victor/1d3eeb46ddfda5257c08744972e0fc4c) . I tried other existing solutions like Oh My Opencode or GSD but it was overkill for me. I took the template from this Gist and tailored it for my needs and so far so good",
          "score": 1,
          "created_utc": "2026-02-10 13:41:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jp317",
          "author": "nickkkk77",
          "text": "Why not? Do you have a repo to have a look? Which model are you using?",
          "score": 0,
          "created_utc": "2026-02-10 02:34:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r32eyj",
      "title": "Â£25~ budget. What is best for me?",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r32eyj/25_budget_what_is_best_for_me/",
      "author": "TheSagaciousPanda",
      "created_utc": "2026-02-12 19:10:18",
      "score": 16,
      "num_comments": 39,
      "upvote_ratio": 0.94,
      "text": "I've used claude code for sometime now with a pro subscription but its become frustrating to use hitting session and weekly limits where they keep lowering it. I'm not a developer but i know my usage shouldnt be hitting limits like they are and therefore looking for a change. I also want to be able to use opencode again instead of claude code.\n\nI'm on the waiting list for opencode black which looks decent but no idea when that's coming and there are various subscriptions/ai stacks i can choose from but... I've no clue on what would be best for me.\n\n\\- Primary uses are ricing, debugging or optimising my computer.   \n\\- Secondary use would be asking questions, research for various things  \n\\- Sometimes use to vibecode small apps depending on what i need  \n  \nI'd appreciate any and all advice!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r32eyj/25_budget_what_is_best_for_me/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o519u6j",
          "author": "smile132465798",
          "text": "Codex and some provider that has kimi/minimax. Minimax 2.5 is really a solid sonnet replacement, kimi 2.5 is fast and codex for hard stuff",
          "score": 15,
          "created_utc": "2026-02-12 19:32:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51gudq",
          "author": "shaonline",
          "text": "If you want Opus-esque performance: Codex (via a ChatGPT Plus sub) for sure I mean not even a contest, at least while the rate limits are generous... You can use it through OpenCode \"legally\" as well.",
          "score": 8,
          "created_utc": "2026-02-12 20:06:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53jilr",
          "author": "BingGongTing",
          "text": "Codex until April (when 2x usage ends), then GLM Lite (should have GLM5 by then).\nGemini CLI also has a generous free tier.\nGitHub Copilot also has a free tier.",
          "score": 5,
          "created_utc": "2026-02-13 02:51:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51gy9o",
          "author": "Apprehensive_Half_68",
          "text": "Opus to create PRD, architect docs, and test driven development steps..then GLM 5 to code it up then Opus to grade. Rinse, repeat. Use Antigravity for Claude for free. And GLM for 3 bucks or so.",
          "score": 6,
          "created_utc": "2026-02-12 20:07:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o536wrn",
              "author": "ECrispy",
              "text": "how do you set this up? using different llms for the tasks? do you have to switch llm in opencode, copy/paste previous conversations etc?",
              "score": 3,
              "created_utc": "2026-02-13 01:33:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o56wzel",
                  "author": "Apprehensive_Half_68",
                  "text": "Like everything else, I just ask AI to set it up, i'm really that lazy and it does a better job than I ever could.  \"I want to help save money by using x ide as a world-class software architect and y for a regular senior dev to do the actual coding up..research and develop and perfect a series of methodology docs that always keep up to date so i can switch back and forth any time and both x and y can pick up where the other left off. Right now model x costs n.1 USD input and n.2 Output and model y cost n.3 USD input and n.4 USD output per 1m tokens . Research the latest trends in AI task-driven-development theory then adapt it for someone who knows something about code but doesn't really want to even look at it much. it should include all best practices for security, docs, and any other best practices a software development studio would put into place but adapted for a lazy vibe coder. .Put all these magical docs in ./docs/methodology/. Any new ai agent who begins coding should be able to start working in the repo immediately being pointed by [AGENTS.md](http://AGENTS.md) to all the correct files it needs.  Don't over-engineeer or under-engineer this. Use Claude's 'Ultrathink' mode if available or whichever is the best agent available in this current ide and spend a bunch of time thinking about how to improve on this method.  Oh and then make an easy to read pretty user guide in markdown language for me to use this with step by step instructions i can keep in another window to follow along.  Oh and add a paragraph after each step to teach me what you are doing and why so I can learn to do better next time.  What other things should I be asking you that i have forgotten in order to save even more money in my budget?\"\n\nThen before i send it I have them clean up that prompt itself, wipe its memory then paste it.",
                  "score": 1,
                  "created_utc": "2026-02-13 16:51:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o53eqr4",
              "author": "kam1L-",
              "text": "Iâ€™m doing this with Claude as a brain and Gemini free tier 1 as a builder, so far best free combo for small stuff and some coding.",
              "score": 1,
              "created_utc": "2026-02-13 02:21:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o51zchp",
          "author": "SnooHesitations6473",
          "text": "OpenAI plus plan, very generous limits, separated limits for chat app. Top tier models. ",
          "score": 2,
          "created_utc": "2026-02-12 21:34:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53ax4v",
          "author": "DependentGuava2343",
          "text": "try copilot, with agents +subagents it might be a good thing for you, I believe \"copilot pro +\" is around Â£25\\~",
          "score": 2,
          "created_utc": "2026-02-13 01:58:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o515vkq",
          "author": "e979d9",
          "text": "[z.ai](http://z.ai) pro plan. I can share an invite link with you if you wish (10% off for you & me). Personally I'm satisfied with the service, and quite impressed GLM-5 that came out yesterday",
          "score": 3,
          "created_utc": "2026-02-12 19:13:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5237lr",
              "author": "TestTxt",
              "text": "minimax is cheaper and better",
              "score": 2,
              "created_utc": "2026-02-12 21:52:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o55855w",
              "author": "Pipimi",
              "text": "They increased the priced after glm 5 ðŸ¥€. I paid $34 for an annual lite plan",
              "score": 1,
              "created_utc": "2026-02-13 11:06:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5175ku",
          "author": "not_particulary",
          "text": "I just switched from Claude pro to codex, trying that out. It's honestly not a bad idea to just get an API key from some aggregator like openrouter, either.",
          "score": 1,
          "created_utc": "2026-02-12 19:19:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52iaj7",
          "author": "TheSagaciousPanda",
          "text": "Thanks for the replies everyone. \n\nI have antigravity on the freeplan but that burns through rate limits quickly if you use opus so unless im missing something that isn't viable unless you mean getting the google ai pro at 18.99 for the gemini models and antigravity usage. Problem is that people are getting banned from using claude models in opencode now aren't they so thats risky?\n\nI'm thinking chatgpt plus subscription for the codex models in opencode and then use [z.ai](http://z.ai) lite plan for GLM5.0 but I have questions\n\na) Would getting [z.ai](http://z.ai) pro plan be better than the above? What justifies the increased cost for it compared to chatgpt plus subscription currently?  \nb) What would be the recommended models regarding the relevant model/models mentioned for different stages - planning > executing > auditing/fixing/improving\n\n",
          "score": 1,
          "created_utc": "2026-02-12 23:10:34",
          "is_submitter": true,
          "replies": [
            {
              "id": "o52omp0",
              "author": "No_Success3928",
              "text": "A) No\nB) Stick with $20 claude or chatgpt, anything else will be a recipe for misery in your situation",
              "score": 3,
              "created_utc": "2026-02-12 23:46:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o53rfqi",
          "author": "keroro7128",
          "text": "My approach is to utilize various incentives to use high-end service providers on the market, including Claude, Codex, and Gemini, while keeping costs as low as possible. This year's cost is approximately $7.60 USD , or $0.63 per month, which is sufficient for casual users, such as those purely interested or students. The only drawback is Claude's relatively low quota, but I think it's enough for creating and conceiving plans. Codex and Gemini offer quotas equivalent to those for regular plus users.",
          "score": 1,
          "created_utc": "2026-02-13 03:41:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o541zui",
          "author": "Icy-Organization-223",
          "text": "I wrote this before in another post but I'll give you the breakdown. If you do things in smaller increments where the model doesn't have to keep building, fixing, and in turn making the context bloat. Just do small directed prompts by giving a file path makes me work on Claude pro plans all day and opencode with kimi 2.5 non stop all day for about $3-$4 but I mean alot of coding. I have let loose when I am lazy and let the model search around but have found out if you give full file.paths and limit it's scope it's better. Be specific on the prompt and the few things it should do. \n\nIn short The plan modes work real well with tight scope and don't let the context go to far as it gets sent again and again. For every new prompt. Start a new session for each file or few files that are related. It's so much faster as well. I do sometimes tell.it to browse my code and suggest things but that for assessments not getting tasks done.\n\nIf I wanted to get it down to less I would even use dumber models for simple refactors. Many cheaper models interpret and debug pretty well when given something to look at but very few models can write something new well. So preserve the refactor assessment document use cases in opencode to smaller parameter models. Now if your asking to write a whole app with it iterating and with context bloat it will burn tokens like a wild fire. \n\nAlso chatgpt free is excellent for code if you give it a full coding document and ask it to fix something. I use that for free and when I want to assess bugs etc. It usually fixes them. I leave sonnet,haiku,and kimi for more agentic coding. It's all about style. I have fit massive coding in the pro plan. But again you complained about the weekly limit which I can't seem to hit",
          "score": 1,
          "created_utc": "2026-02-13 04:54:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55109r",
          "author": "Dinth",
          "text": "Im in the same situation as op. My main useless are managing my docker compose files and configs for various services, home assistant automations and nix configurations. I do have access to Gemini 3.0 pro from work, and find that quality Sonnet 4.5 answers is literally a several levels above Gemini Pro for my usage. Would OpenAI codex be comparable for my use case to Gemini 3.0 Pro or more like Sonner 4.5? \n\nAlso Iâ€™ve got an ollama server with 16gb gpu, potentially will expand to around 24gb soon. Is that something I can realistically use with my OpenCode? Iâ€™ve done several attempts to use OpenCode with 13b models so far, and it seems that 13b models fail to do even simplest tooling",
          "score": 1,
          "created_utc": "2026-02-13 10:01:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o58lp2c",
              "author": "shaonline",
              "text": "GPT/GPT-Codex takes on Opus, they each have their strengths. You can tweak the reasoning effort to save on tokens if you just need a decent executor (GPT-Codex medium).\n\nSmall (local) models will always struggle with proper output formatting (at the end of the day it just sends a big JSON for each command) nevermind actual \"knowledge\", and it's hardly something you'll band-aid with MCP servers.",
              "score": 1,
              "created_utc": "2026-02-13 21:48:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5623po",
          "author": "Queasy_Change4668",
          "text": "[https://cortexai.io/](https://cortexai.io/) , it gives unlmited usage of every ai in the world, Ä± deffinitly suggest you to try it, go and join to the discord and write someone to pay,  [https://discord.gg/VVsYkH9f](https://discord.gg/VVsYkH9f)",
          "score": 1,
          "created_utc": "2026-02-13 14:21:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c1bjs",
          "author": "HarjjotSinghh",
          "text": "ahhhhh budget hack time.",
          "score": 1,
          "created_utc": "2026-02-14 13:08:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o516y4d",
          "author": "HarjjotSinghh",
          "text": "clumsy devs making $25 budget look impossible. try i386 mode.",
          "score": 0,
          "created_utc": "2026-02-12 19:18:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53hvrk",
          "author": "Diligent_Speaker4692",
          "text": "As you mention you should do PRD with any good chat then put on you project with claude code. Claude code is good for user intention and  good follow instructions so this is the way.  For a developer my best combo is openspec + codex 5.3 high codex planning and 5.3 codex for implement this work perfect",
          "score": 0,
          "created_utc": "2026-02-13 02:41:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51cs19",
          "author": "Popular-Category711",
          "text": "bro just switch to claude code\n\nwere an early stage startup so basically we give claude code max equivalent subscription for the price of the pro plan for now as were early and users stay at same price for 1 year\n\nu will get like 200 million something tokens of claude sonnet and other models\n\nwe have a free trial as well we will give you 10 million tokens which u can use\n\nif u like it u can go ahead",
          "score": -4,
          "created_utc": "2026-02-12 19:47:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51sevd",
              "author": "touristtam",
              "text": "> were an early stage startup so basically we give claude code max equivalent subscription for the price of the pro plan for now as were early and users stay at same price for 1 year\n\nSorry I might be thick but can you break down what you are trying to say?",
              "score": 4,
              "created_utc": "2026-02-12 21:01:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o52nyvx",
                  "author": "No_Success3928",
                  "text": "Looks like they are reselling claude access?",
                  "score": 2,
                  "created_utc": "2026-02-12 23:42:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o52cs40",
                  "author": "TheSagaciousPanda",
                  "text": "u/Popular-Category711 not sure what your copy paste response is trying to say because you dont even mention what service your trying to offer as a new startup and how your able to get what your claiming",
                  "score": 1,
                  "created_utc": "2026-02-12 22:40:51",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o54kugg",
                  "author": "Popular-Category711",
                  "text": "were planning to launch our own ai models in future so were trying to get early users\n\nthus were giving massive discounts on ai models \n\nwere giving like 200 million tokens of claude and other models for the price of pro plan which generally costs 200$",
                  "score": 0,
                  "created_utc": "2026-02-13 07:29:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o52ea0s",
          "author": "Rygel_XV",
          "text": "You can also checkout [synthetic.new](http://synthetic.new). They have Kimi 2.5, GLM 4.7 (but plan to host 5 once it is released as open source) and Minimax 2.1 (and will probably also host 2.5 once it is released as open source). \n\nI am using them myself, and I am very happy with their performance. \n\n[https://synthetic.new/?referral=SNJDbFCgSUZso9E](https://synthetic.new/?referral=SNJDbFCgSUZso9E)",
          "score": -1,
          "created_utc": "2026-02-12 22:48:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52p5p6",
              "author": "No_Success3928",
              "text": "OP should also know new signups are on a waitlist for access.",
              "score": 0,
              "created_utc": "2026-02-12 23:49:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o548luj",
                  "author": "Rygel_XV",
                  "text": "Oh, I didn't know about the waitlist. Thank you for mentioning it.",
                  "score": 2,
                  "created_utc": "2026-02-13 05:45:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o52tanz",
              "author": "Shep_Alderson",
              "text": "Seconding synthetic.new. Their customer support has been top notch and Iâ€™m sure they will have the latest Kimi and MiniMax models up soon. Iâ€™m guessing they just need to prove it out and such first.",
              "score": -1,
              "created_utc": "2026-02-13 00:13:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o52h8ue",
          "author": "ch4dev_lab",
          "text": "!RemindMe 1week",
          "score": -1,
          "created_utc": "2026-02-12 23:04:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52hh21",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 7 days on [**2026-02-19 23:04:49 UTC**](http://www.wolframalpha.com/input/?i=2026-02-19%2023:04:49%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/opencodeCLI/comments/1r32eyj/25_budget_what_is_best_for_me/o52h8ue/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FopencodeCLI%2Fcomments%2F1r32eyj%2F25_budget_what_is_best_for_me%2Fo52h8ue%2F%5D%0A%0ARemindMe%21%202026-02-19%2023%3A04%3A49%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201r32eyj)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": -1,
              "created_utc": "2026-02-12 23:06:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o52kjn3",
          "author": "ScorpionOfWar",
          "text": "Been using open-source models more lately for private stuff, I got the 100$ Claude Sub for work.\n\nEnded up trying [Synthetic](https://synthetic.new/?referral=hcHozzHNE8CxVvz)(\\~50% off) and it's been very solid so far, alternatively [Z.ai](https://z.ai/subscribe?ic=KQ77ZVKLB5)(\\~10% off) for just the GLM Models, nice for coding, but kind of unreliable at the moment. They host open-source models and the API is OpenAI-compatible so it just plugs into your CLI or Dev Environment. $20/mo flat for the subscription tier is nice.\n\nWith my ref link to Synthetic and Z you are able to get a rebate.",
          "score": -1,
          "created_utc": "2026-02-12 23:23:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52ovlv",
              "author": "No_Success3928",
              "text": "Synthetic have a wait list for new signups. Perhaps you should mention that?",
              "score": 2,
              "created_utc": "2026-02-12 23:47:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o52q4zs",
                  "author": "ScorpionOfWar",
                  "text": "That is true, they recently got new GPU resources though. So there will be more places available soon",
                  "score": 0,
                  "created_utc": "2026-02-12 23:54:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o53juil",
          "author": "Senior-Cod993",
          "text": "anthopic needs to stop tring to push woke agenda into the models",
          "score": -4,
          "created_utc": "2026-02-13 02:53:14",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4v7by",
      "title": "OCMONITOR - a CLI tool to monitor OPENCODE CLI usage",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r4v7by/ocmonitor_a_cli_tool_to_monitor_opencode_cli_usage/",
      "author": "WriterOld3018",
      "created_utc": "2026-02-14 20:36:06",
      "score": 16,
      "num_comments": 3,
      "upvote_ratio": 0.94,
      "text": "https://preview.redd.it/95r6b42ktijg1.png?width=3790&format=png&auto=webp&s=e0b2919618f556d387b59e6071b3bb85890aa3bc\n\nHello opencode community,\n\n5 months ago I madeÂ ocmonitor, an open-source CLI tool to monitor opencode usage. Since yesterday (version 1.2.0+), opencode migrated from storing sessions in JSON files to using a SQLite database. Iâ€™ve updated ocmonitor to support this change.\n\nI also added a hierarchy view to show subagents as part of the parent session, and monitoring of output rate (TPS) to give an indication of model performance.\n\nI would appreciate any feedback or bug reports (preferably via GitHub). PRs and contributions are also welcome.  \n[https://github.com/Shlomob/ocmonitor-share](https://github.com/Shlomob/ocmonitor-share)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r4v7by/ocmonitor_a_cli_tool_to_monitor_opencode_cli_usage/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o5fclrh",
          "author": "rizal72",
          "text": "I love it! Beautifully done, very useful, very good job!",
          "score": 1,
          "created_utc": "2026-02-14 23:59:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ijgae",
          "author": "altsyst",
          "text": "Nice! Is there a way to inspect the whole context window besides having the number of tokens? I'm looking for a tool allowing me to see easily the whole context.",
          "score": 1,
          "created_utc": "2026-02-15 14:50:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5kgktq",
          "author": "HarjjotSinghh",
          "text": "this is unreasonably cool actually!",
          "score": 1,
          "created_utc": "2026-02-15 20:33:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}