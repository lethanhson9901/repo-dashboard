{
  "metadata": {
    "last_updated": "2026-01-24 08:42:05",
    "time_filter": "week",
    "subreddit": "opencodeCLI",
    "total_items": 20,
    "total_comments": 130,
    "file_size_bytes": 142320
  },
  "items": [
    {
      "id": "1qimlua",
      "title": "We built Kuse Cowork: an open-source, Rust-native alternative to Claude Cowork",
      "subreddit": "opencodeCLI",
      "url": "https://v.redd.it/vl8say66emeg1",
      "author": "Loose_Kangaroo91",
      "created_utc": "2026-01-21 03:16:51",
      "score": 121,
      "num_comments": 22,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qimlua/we_built_kuse_cowork_an_opensource_rustnative/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0tcczy",
          "author": "tdi",
          "text": "will you maintain it ?",
          "score": 5,
          "created_utc": "2026-01-21 06:57:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0th6of",
              "author": "Loose_Kangaroo91",
              "text": "Absolutely!! We have always thinking about open source and this is actually a great opportunity to actually encourage us to do this, pls drop your feedback, experience, comments anytime and we would love to keep optimizing this!!",
              "score": 2,
              "created_utc": "2026-01-21 07:40:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ujxoq",
          "author": "TheHeadSalad",
          "text": "I don’t understand these posts sharing : “we built this over last 24/48 hours”, like is that supposed to be a testament?(even when we have these marvelous coding agents). \nIMO, that just screams that what you have built is still immature and bug prone. It takes time to build nice things,    \n…but anything has to start somewhere, I guess.",
          "score": 6,
          "created_utc": "2026-01-21 13:07:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0vouju",
              "author": "gottapointreally",
              "text": "I think they are trying to communicate that it is in early dev.",
              "score": 2,
              "created_utc": "2026-01-21 16:31:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tcywp",
          "author": "Lonely_Noyaaa",
          "text": "Cool project and thanks for sharing! It's really ambitious to build this within a weekend. Do you guys support multiple models switch for now?",
          "score": 2,
          "created_utc": "2026-01-21 07:02:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0th806",
              "author": "Loose_Kangaroo91",
              "text": "Thank you! And yes this supports most trendy LLMs",
              "score": 1,
              "created_utc": "2026-01-21 07:40:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tf7es",
          "author": "No_Point_9687",
          "text": "Haven't you recently said Claude killed your business or was it someone else. \nPromising product, will check it out. Thank you.",
          "score": 1,
          "created_utc": "2026-01-21 07:22:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0thfb2",
              "author": "Loose_Kangaroo91",
              "text": "Oh thanks! Yes I think one of our folks made that post! Please drop your feedback anytime and we would love to keep optimizing this!",
              "score": 1,
              "created_utc": "2026-01-21 07:42:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tvv2f",
          "author": "mintybadgerme",
          "text": "Your readme's broken. Pretty fundamental. :)\n\n# Clone the repo\ngit clone https://github.com/kuse-ai/kuse-cowork.git",
          "score": 1,
          "created_utc": "2026-01-21 10:00:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0uvdoc",
          "author": "MrChevyCeleb42",
          "text": "cant wait to try it! I built something similar and shelved it, excited to see this!!!!",
          "score": 1,
          "created_utc": "2026-01-21 14:11:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ybxfb",
              "author": "Loose_Kangaroo91",
              "text": "Thanks!! Please let us know your experience and would be excited to see your work as well!!",
              "score": 1,
              "created_utc": "2026-01-21 23:51:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0wv8zi",
          "author": "JealousBid3992",
          "text": "Nice you even implemented the Terminal scrolling / refresh bug in Claude Code, that's authentic",
          "score": 1,
          "created_utc": "2026-01-21 19:39:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o112bvy",
          "author": "Wrong_Daikon3202",
          "text": "An interesting proposal, I'm testing it right now and I come up with a couple of suggestions.\n\n\\- It would be very good if you pre-compiled each new version of the APP for the main systems.  \n\\- It would be great to have the same list of free LLM (Grok, GLM-4.7, MiniMax...) that has opencode to a clik.",
          "score": 1,
          "created_utc": "2026-01-22 11:31:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16deb3",
              "author": "Loose_Kangaroo91",
              "text": "Thanks for the suggestions!! Well received!!",
              "score": 1,
              "created_utc": "2026-01-23 03:49:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0t0pmz",
          "author": "Ok-Machine-8071",
          "text": "oh my god",
          "score": 1,
          "created_utc": "2026-01-21 05:23:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0t64h4",
              "author": "Loose_Kangaroo91",
              "text": "Is this omg in a good way haha?",
              "score": 1,
              "created_utc": "2026-01-21 06:04:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0t1ogz",
          "author": "true-though",
          "text": "Congrats, and great job!!",
          "score": 1,
          "created_utc": "2026-01-21 05:30:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0t62vd",
              "author": "Loose_Kangaroo91",
              "text": "Thanks! Feel free to try it out and let us know your feedback!!",
              "score": 2,
              "created_utc": "2026-01-21 06:04:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tovm5",
          "author": "ApprehensiveNail42",
          "text": "I’d love to know how it compares. Cowork is still in its infancy but I urgently need a tool for a dispute I’m handling with the other owners in the complex I live in, reason being that Claude’s interface is much too basic. No proper filing in projects (unlabelled thumbnails just don’t cut it when you have over 50 documents), no tabs (needed with how buggy things get when switching between conversations - messages disappearing for example). Cowork has been much better as it works directly with the files on the system but yeah, it’s very new and there’s room for improvement.",
          "score": 0,
          "created_utc": "2026-01-21 08:52:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0trv3e",
              "author": "Loose_Kangaroo91",
              "text": "I am so thrilled to see such a detailed and right on point user needs!! Basically we cover all capabilities that claude provide in thie open source version, and it also supports other llms switch if you have other preferences. It's totally free so pls try it out and let us know how it meets your needs!!",
              "score": 1,
              "created_utc": "2026-01-21 09:21:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0uwyyo",
                  "author": "ApprehensiveNail42",
                  "text": "Awesome, thanks. I’m a long time web designer, now product designer so pick up on product limitations quicker than most. Like so many others, AI and Claude in particular have gifted me the freedom to place a larger focus on what I’m actually good at. Itching to get some stuff built, shipped and start earning. And hopefully I’ll be able to do away with client-deadline-based work altogether someday!",
                  "score": 1,
                  "created_utc": "2026-01-21 14:19:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qjr325",
      "title": "I built a tool to use OpenCode from Mobile phone while away from my desk (With Voice input and Push Notifications).",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/gallery/1qjr325",
      "author": "LogPractical2639",
      "created_utc": "2026-01-22 10:28:45",
      "score": 68,
      "num_comments": 28,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qjr325/i_built_a_tool_to_use_opencode_from_mobile_phone/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o10x6o4",
          "author": "Tommertom2",
          "text": "Cool - so this goes via your server to connect the backend with the app, correct?",
          "score": 7,
          "created_utc": "2026-01-22 10:47:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10y26d",
              "author": "LogPractical2639",
              "text": "Yes, traffic from CLI to Mobile goes through a server in AWS. Communication is encrypted, so server can not read it.",
              "score": -3,
              "created_utc": "2026-01-22 10:55:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o12p12w",
                  "author": "Tommertom2",
                  "text": "Did you consider using your server only for setting up the connection and then handling the traffic peer to peer? Seems more efficient for your own server as well",
                  "score": 7,
                  "created_utc": "2026-01-22 16:47:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o112cmf",
          "author": "cloudsurfer48902",
          "text": "Does it support opencode sessions running with different server ports?",
          "score": 4,
          "created_utc": "2026-01-22 11:31:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1142s0",
              "author": "LogPractical2639",
              "text": "Termly works at the terminal level - it just streams what you see in your terminal to your phone. It doesn't care about OpenCode's internal servers or ports. If I got your question correctly",
              "score": 0,
              "created_utc": "2026-01-22 11:44:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o18ecwx",
                  "author": "cloudsurfer48902",
                  "text": "Hadn't gone through the repo to notice the ability to pass arguments. What I had meant was for example `termly start --ai opencode --ai-args \"--port 4096\"` which worked well.\n\nIt's a cool project, only problem is the handling of wraping and and the resizing which is interpreted as unicode.\n\nhttps://preview.redd.it/5kl7cvlfn3fg1.jpeg?width=1080&format=pjpg&auto=webp&s=ddc9fa1d943ecb6717fa83542f4d874ab95dc3d3",
                  "score": 2,
                  "created_utc": "2026-01-23 13:17:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o11ofjv",
          "author": "AaBJxjxO",
          "text": "How about Termux + SSH + tmux?",
          "score": 3,
          "created_utc": "2026-01-22 13:52:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11qk3t",
              "author": "LogPractical2639",
              "text": "Works, but SSH from outside your network needs port forwarding or VPN. Termly just works anywhere - scan QR and go. Plus Push notifications when AI needs your input.\n\nCLI: macOS, Windows, Linux - install via npm, runs on Node 18+\n\nMobile: native apps for iOS and Android with TUI support, touch gestures, voice input",
              "score": 3,
              "created_utc": "2026-01-22 14:03:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o12k5r3",
                  "author": "ResonantClari",
                  "text": "> SSH from outside your network needs port forwarding or VPN\n\nTailscale!!",
                  "score": 2,
                  "created_utc": "2026-01-22 16:26:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o11t3np",
                  "author": "AaBJxjxO",
                  "text": "VPN is assumed.  Voice can be done out of the box with voice input (eg from Gboard) into Termux.\n\nPush notifications are interesting though.",
                  "score": 4,
                  "created_utc": "2026-01-22 14:17:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1153yp",
          "author": "Glum-Atmosphere9248",
          "text": "But opencode already has web ui",
          "score": 3,
          "created_utc": "2026-01-22 11:52:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11yz4d",
              "author": "rothnic",
              "text": "I think the idea is it would work across any agent framework. \n\nI do think though that if you are at this level of need you'd probably build your own tool specific to your needs. This kind of tool is a pretty common thing to see launched every other day, which is kind of my biggest concern at the moment.\n\nThe moat you create by investing in software development is going to be more and more fragile. Since any service has features you don't need, you can build exactly what you want using coding agents much cheaper. I think the SAAS business as we know it is in big trouble.",
              "score": 3,
              "created_utc": "2026-01-22 14:47:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o116m7l",
              "author": "LogPractical2639",
              "text": "Yes. The question is why do you need this app? :) if you like to work on your computer, but you need to leave it sometime or often. You can not open your local session through web. And I'm still working on use cases",
              "score": 1,
              "created_utc": "2026-01-22 12:03:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o11t9e5",
          "author": "Extension-Pen-109",
          "text": "I run 8 opencode instance in diferent directories, this will work with all or just one of them?",
          "score": 2,
          "created_utc": "2026-01-22 14:17:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11u47i",
              "author": "LogPractical2639",
              "text": "Yes, you will see the list of all your connected session and you will be able to switch between them in application. I would love if you try this scenario and share your feedback.",
              "score": 2,
              "created_utc": "2026-01-22 14:22:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o13d2k8",
          "author": "blissofbeing",
          "text": "How is this different from [https://happy.engineering](https://happy.engineering) or [https://github.com/tiann/hapi](https://github.com/tiann/hapi) ?",
          "score": 2,
          "created_utc": "2026-01-22 18:35:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13iw4j",
              "author": "LogPractical2639",
              "text": "It works with Open Code",
              "score": 1,
              "created_utc": "2026-01-22 19:00:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1607c4",
          "author": "compostcompost",
          "text": "fuck it, i'll give it a try",
          "score": 2,
          "created_utc": "2026-01-23 02:34:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16db03",
              "author": "compostcompost",
              "text": "...... this is not bad",
              "score": 2,
              "created_utc": "2026-01-23 03:48:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o16ejjx",
                  "author": "compostcompost",
                  "text": "u/LogPractical2639 user feedback: a way to add newlines. opencode (and some other AI tools) only supports adding newlines via \"ctrl+j\".",
                  "score": 3,
                  "created_utc": "2026-01-23 03:56:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o12nm84",
          "author": "robberviet",
          "text": "So like https://github.com/slopus/happy?",
          "score": 1,
          "created_utc": "2026-01-22 16:41:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13evc4",
          "author": "blissofbeing",
          "text": "Be very careful using this, it looks to be a vibe coded clone of [https://github.com/slopus/happy](https://github.com/slopus/happy) and all your data will travel through the devs relay server.",
          "score": 1,
          "created_utc": "2026-01-22 18:43:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14hsdo",
          "author": "drinksbeerdaily",
          "text": "I'd be interested if I could run it without involving any remote server out of my control. Most people who use opencode is very likely also using Wireguard, Tailscale or similar..",
          "score": 1,
          "created_utc": "2026-01-22 21:43:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhvzoi",
      "title": "OpenCode’s creator on model freedom, Anthropic blocks, and the “double miracle” of open source",
      "subreddit": "opencodeCLI",
      "url": "https://jpcaparas.medium.com/opencodes-creator-on-model-freedom-anthropic-blocks-and-the-double-miracle-of-open-source-bd94bd8fc763?sk=de6ec2383dae5cdd8e135a345dd2adfe",
      "author": "jpcaparas",
      "created_utc": "2026-01-20 08:52:20",
      "score": 57,
      "num_comments": 7,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qhvzoi/opencodes_creator_on_model_freedom_anthropic/",
      "domain": "jpcaparas.medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0os4m3",
          "author": "Michaeli_Starky",
          "text": "OC is plain better to that as agentic harness.",
          "score": 7,
          "created_utc": "2026-01-20 16:13:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0qatfp",
              "author": "jpcaparas",
              "text": "undeniably.",
              "score": 2,
              "created_utc": "2026-01-20 20:23:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0n4htj",
          "author": "Old-School8916",
          "text": "Streisand effect",
          "score": 5,
          "created_utc": "2026-01-20 10:02:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oeix8",
              "author": "taylorlistens",
              "text": "Don’t look that up!",
              "score": 2,
              "created_utc": "2026-01-20 15:08:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0ozmj5",
                  "author": "EmreErdoqan",
                  "text": "Haha exactly this!",
                  "score": 2,
                  "created_utc": "2026-01-20 16:47:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0om7hm",
          "author": "eMperror_",
          "text": "So, what's the current method to use the Max subscription without being blocked?",
          "score": 4,
          "created_utc": "2026-01-20 15:45:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0n06b4",
          "author": "jpcaparas",
          "text": "Yo Dax is a cool dude.",
          "score": 7,
          "created_utc": "2026-01-20 09:21:09",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qificf",
      "title": "The best CLI",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qificf/the_best_cli/",
      "author": "DreamDragonP7",
      "created_utc": "2026-01-20 22:19:24",
      "score": 57,
      "num_comments": 38,
      "upvote_ratio": 0.97,
      "text": "I am in awe. srsly fangirling. also super pissed I spent so long curating and creating custom plugins/skills/agents with claude code just to try out Opencode and spend substantially less tokens and get the same quality. \n\nNote: for anyone trying out the oh-my-opencode plugin? dont. token burner for no reason. This shit works right out of the box. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qificf/the_best_cli/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0r62v2",
          "author": "Apart-Permission-849",
          "text": "+1 on oh my open code burning tokens",
          "score": 24,
          "created_utc": "2026-01-20 22:51:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0trw0a",
          "author": "Familiar-Pomelo-8654",
          "text": "For me, the biggest improvement came from keeping my API specs clean. Apidog CLI alone cut a lot of token waste.\n ",
          "score": 13,
          "created_utc": "2026-01-21 09:22:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11hlw8",
              "author": "tamanaga",
              "text": "Can you share a bit more, I'm interested to know how Apidog CLI can cut a lot of token waste. It is used for running api test scenarios, right?",
              "score": 1,
              "created_utc": "2026-01-22 13:15:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o125m67",
                  "author": "InternalFarmer2650",
                  "text": "I think it even creates the docs for your API? not 100% confident but i remember seeing them advertising that somewhere",
                  "score": 1,
                  "created_utc": "2026-01-22 15:19:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0r6bj8",
          "author": "gobitpide",
          "text": "Agreed on the OmO part. The Default Plan and Build cycle is the workflow I keep returning to.",
          "score": 8,
          "created_utc": "2026-01-20 22:53:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ssywz",
          "author": "SynapticStreamer",
          "text": "> This shit works right out of the box. \n\nAnd this is why Anthropic is pissed that people like OpenCode. Ultimately it's going to decrease token usage which is less $ for them.\n\nThere's not a single thing anyone can tell me to convince me that I'm wrong.",
          "score": 6,
          "created_utc": "2026-01-21 04:29:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0x3958",
              "author": "kkordikk",
              "text": "They do the work themselves to reduce the token usage - compacting, dynamically loaded skills, dynamic tool search and more!",
              "score": 1,
              "created_utc": "2026-01-21 20:15:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0rzuxp",
          "author": "atkr",
          "text": "oh my anything tools are all junk, ever since any of them existed",
          "score": 7,
          "created_utc": "2026-01-21 01:35:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tolbp",
              "author": "buggytheking",
              "text": "oh my zsh is decent",
              "score": 6,
              "created_utc": "2026-01-21 08:50:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0wwos5",
                  "author": "Silent-Tie-3683",
                  "text": "Isn't starship better?",
                  "score": 2,
                  "created_utc": "2026-01-21 19:46:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o12jx7r",
                  "author": "Real-Entertainer5379",
                  "text": "zsh4humans has been my default choice since 2021",
                  "score": 1,
                  "created_utc": "2026-01-22 16:25:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0rdf8c",
          "author": "devdnn",
          "text": "Does the opencode cli document the plan or spec for documentation purpose?\n\nI didn’t see a way to extend the agent to make sure document the plan or specs",
          "score": 2,
          "created_utc": "2026-01-20 23:31:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rflyw",
              "author": "Hot_Dig8208",
              "text": "By default no. You need to ask the plan agent to do it. But you can use spec driven tool like [openspec](https://openspec.dev). The default workflow of openspec is to write the plan in a markdown file, so we can review it before the implementation.",
              "score": 3,
              "created_utc": "2026-01-20 23:43:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0wev82",
          "author": "alp82",
          "text": "Can you share your setup? Which rules, skills, commands? MCP, models?\n\nCurious to learn from you",
          "score": 2,
          "created_utc": "2026-01-21 18:26:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0xtnte",
              "author": "Fantastic_Grand1050",
              "text": "Up",
              "score": 1,
              "created_utc": "2026-01-21 22:16:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0shvqv",
          "author": "Rude-Needleworker-56",
          "text": "The same feeling I had until I tried pi",
          "score": 1,
          "created_utc": "2026-01-21 03:19:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0simm0",
              "author": "DreamDragonP7",
              "text": "Pi?",
              "score": 1,
              "created_utc": "2026-01-21 03:23:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0sll67",
                  "author": "Rude-Needleworker-56",
                  "text": "Pi coding agent. Simple and extremely hackable",
                  "score": 2,
                  "created_utc": "2026-01-21 03:41:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0sivz1",
          "author": "larowin",
          "text": "What model do you typically use?",
          "score": 1,
          "created_utc": "2026-01-21 03:25:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0sjkft",
              "author": "DreamDragonP7",
              "text": "Opus 4.5\n\nAll other models are vastly inferior. Except maybe gemini 3 pro for fast bug hunting.",
              "score": 1,
              "created_utc": "2026-01-21 03:29:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0wjy1n",
                  "author": "ganderofvenice",
                  "text": "You should try GPT-5.2-Codex-xHigh. Good to find errors made by Opus.",
                  "score": 1,
                  "created_utc": "2026-01-21 18:48:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0wyf1q",
                  "author": "Silent-Tie-3683",
                  "text": "I've recently seen this issue where gemini 3 pro goes on a loop, it outputs the same thinking multiple time!",
                  "score": 1,
                  "created_utc": "2026-01-21 19:53:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0x83nk",
                  "author": "alphaQ314",
                  "text": "Are you using it with Claude max plan ?",
                  "score": 1,
                  "created_utc": "2026-01-21 20:38:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0tg426",
          "author": "whimsicaljess",
          "text": "honestly same. i did a review of all the coding agents the other day and instantly switched to opencode after 1 session. it's so good!",
          "score": 1,
          "created_utc": "2026-01-21 07:30:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12hehs",
          "author": "SimpleG404",
          "text": "i use it with my chatgpt subscription and i don’t worry about token spent with my flat monthly payer, am i just not using it enough?",
          "score": 1,
          "created_utc": "2026-01-22 16:13:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13dgqo",
          "author": "drinksbeerdaily",
          "text": "Any merit to Anthropic banning accounts that use opencode?",
          "score": 1,
          "created_utc": "2026-01-22 18:37:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13jgum",
              "author": "DreamDragonP7",
              "text": "Hasn't happened to me yet. But it could happen at anytime Im hearing?",
              "score": 2,
              "created_utc": "2026-01-22 19:03:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tqsfe",
          "author": "Cheap_Drawing4073",
          "text": "I disagree with your opinion about oMo. They are working on developing an excellent planning workflow. The 3.0 beta version is quite impressive. However, there are still some bugs that they are actively working on. I highly recommend giving it a try",
          "score": 1,
          "created_utc": "2026-01-21 09:11:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tzw6c",
              "author": "awfulalexey",
              "text": "I was shocked by the scale of Beta 3. I deleted it for now when it was at version 3.0.7, staying on the stable version for the time being. It seems to me that there is too much orchestration, and for something like that, you need the strongest models everywhere, like Opus, Sonnet, Gemini 3 Pro, Codex. If the models are smaller, they might not be able to handle such a scale of work. I really like oMo, but now I'm not sure; it seems too bulky. I'll say more—I have never worked in pure Opencode, maybe it's worth a try.",
              "score": 2,
              "created_utc": "2026-01-21 10:37:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0u0b4x",
                  "author": "Cheap_Drawing4073",
                  "text": "Beta 11 has a few issues. oMo automatically falls back to models it considers “performant,” but you know, I set up the antigravity auth provider and configured all the agents and “categories” to flash 3. I only use that one for now, and I really like it. I don’t lose anything, and it’s almost free. I’ve been running it non-stop for 3 days so far. I added 5 google accounts, and it auto-switches between them. You just need to properly configure the oh-my-opencode.json file. I set flash 3 everywhere, hahaha.",
                  "score": 1,
                  "created_utc": "2026-01-21 10:41:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0r1iej",
          "author": "SuccessfulScene6174",
          "text": "You mean same quality but without any commands skills etc?",
          "score": 1,
          "created_utc": "2026-01-20 22:28:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rtill",
              "author": "DreamDragonP7",
              "text": "Yes",
              "score": 1,
              "created_utc": "2026-01-21 00:59:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfzaju",
      "title": "Built a multi-agent orchestrator plugin for OpenCode after struggling with GLM-4.7",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qfzaju/built_a_multiagent_orchestrator_plugin_for/",
      "author": "ChangeDirect4762",
      "created_utc": "2026-01-18 04:50:54",
      "score": 50,
      "num_comments": 19,
      "upvote_ratio": 0.95,
      "text": "https://preview.redd.it/78u9krhyf1eg1.png?width=3826&format=png&auto=webp&s=eaa14b014a85d34823c68ff354dc998de60d8883\n\nGLM-4.7 kept hitting walls on complex tasks — rate limits, context overflow, losing track halfway through. Got frustrated enough to build my own solution.\n\n0.9 version\n\nSo I made \\[opencode-orchestrator\\]([https://github.com/agnusdei1207/opencode-orchestrator](https://github.com/agnusdei1207/opencode-orchestrator)). It's a plugin for OpenCode that handles:\n\n\\- \\*\\*Parallel sessions\\*\\* — up to 50 isolated sessions running simultaneously\n\n\\- \\*\\*Agent distribution\\*\\* — Commander delegates to Planner, Workers, Reviewer\n\n\\- \\*\\*Background tasks\\*\\* — non-blocking, async execution\n\n\\- \\*\\*Auto-retry\\*\\* — handles crashes, rate limits, context issues automatically\n\n\\- \\*\\*Loop until done\\*\\* — keeps going until all TODOs are complete and verified\n\nThe idea is simple: instead of one agent trying to do everything, split the work across specialized agents that run in parallel and coordinate through shared state.\n\n  \nIf you try it out and run into anything, feel free to open an issue — or since it's open source, just fork it and tinker with it yourself. If you come up with something cool, I'd love to hear about it.\n\n\n\nI think in the AI era, we're all going to end up building our own tools anyway.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qfzaju/built_a_multiagent_orchestrator_plugin_for/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0c7ung",
          "author": "Visible_Jury_6547",
          "text": "why not just config Oh my opencode ? [https://github.com/code-yeongyu/oh-my-opencode](https://github.com/code-yeongyu/oh-my-opencode)",
          "score": 6,
          "created_utc": "2026-01-18 19:04:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0frqfi",
              "author": "splitbrainhack",
              "text": "unnecessary chaos",
              "score": 2,
              "created_utc": "2026-01-19 07:08:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0a709j",
          "author": "writing_rainbow",
          "text": "Are you able to assign specific models for each mode? Like chat 5.2 high for commander and planner and then glm for implementation and then codex 5.2 high for review?",
          "score": 4,
          "created_utc": "2026-01-18 12:52:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09gl6c",
          "author": "redoubledit",
          "text": "So frustrating. At one time, I had beautifully laid out plans with extensive todo list, broken up into execution phases. I was so ready, so it started. Finishing the first todo item, using the todo write tool to check off the item. But didn’t read the list before so now, all todos are checked and verified and it stopped. Trying to iterate, it totally messed up from there. Forgetting parts of the plan, checking off items and deleting others in the same step. \n\nMight give your project a try. See if it can help.",
          "score": 2,
          "created_utc": "2026-01-18 08:59:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08vblp",
          "author": "lundrog",
          "text": "Interesting, ill check it out",
          "score": 1,
          "created_utc": "2026-01-18 05:52:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o097hp5",
              "author": "ChangeDirect4762",
              "text": "Thx. :)",
              "score": 1,
              "created_utc": "2026-01-18 07:36:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0avr5y",
          "author": "mintybadgerme",
          "text": "I'm getting a little confused with all these new agent systems coming online. What makes them different from one another? I've got open agents installed. How is that different from this one? I'm assuming that running them all together will destroy the platform completely.",
          "score": 1,
          "created_utc": "2026-01-18 15:17:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0c2z3g",
              "author": "Zexanima",
              "text": "Its a new problem domain that people are running into around the same time. Not everyone can/wants to keep up to date with everything new that drops, so they will roll their own solution. I think its great to have all these options in the beginning. People will evetually gravitate to the best solutions, they will start to homogenize features, and those will become the go-to.",
              "score": 5,
              "created_utc": "2026-01-18 18:41:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0c4l4r",
                  "author": "mintybadgerme",
                  "text": "But how on earth do you decide what's the best solution? Seems to me that there's no benchmarks,  no quality assurance, no testing. They're just released onto the market and us poor suckers have got to make a decision. Really hard.",
                  "score": 1,
                  "created_utc": "2026-01-18 18:49:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0e7d3x",
          "author": "Redoer_7",
          "text": "Which IDE is this",
          "score": 1,
          "created_utc": "2026-01-19 01:06:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0f64g2",
              "author": "Ruin_Mediocre",
              "text": "https://zed.dev/",
              "score": 1,
              "created_utc": "2026-01-19 04:24:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0fk8dc",
          "author": "NullzeroJP",
          "text": "Wow, crazy. How long did it take you to plan and build out something like this? And did it help fix some of the issues with GLM 4.7? Having similar issues myself with GLM 4.7 and ClaudeCode. But I'm new to vibe coding, so I thought maybe it was just a \"me\" problem.",
          "score": 1,
          "created_utc": "2026-01-19 06:06:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mbifl",
          "author": "pkief",
          "text": "Maybe it's also worth checking this project: https://www.swarmtools.ai/\n\nIt does quite the same and is already a little popular. It's an open code plugin optimized for multiple agent orchestration.",
          "score": 1,
          "created_utc": "2026-01-20 05:45:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfa59w",
      "title": "Love for Big Pickle",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qfa59w/love_for_big_pickle/",
      "author": "External_Ad1549",
      "created_utc": "2026-01-17 10:45:00",
      "score": 49,
      "num_comments": 37,
      "upvote_ratio": 0.95,
      "text": "disclaimer: I'm not a vibe coder. I’m a senior backend dev and I don’t code on things I don’t understand at least 70% clarity is mandatory for me.\n\nThat said, I love Big Pickle.\n\nThe response speed is insane, and more importantly, the quality doesn't degrade while being fast. I've been using it for the past hour for refactoring, debugging, and small script creation it just works. \"Great\" feels like an understatement.\n\nI don't care whether it's GLM-4.6, Opus, or something else. I only care about two things: high tokens/sec and solid output quality. Big Pickle nails both.\n\nWhoever operating this model at this speed I genuinely love you.\n\nMy only concern: it's currently free. That creates anxiety. I don’t want the model to stop working in the middle of serious work.\n\nPlease introduce clear limits or a paid coding plan (ZAI-level or slightly above).  \nIf one plan expires, I'll switch accounts or plans and continue no issue.\n\nJust give us predictability",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qfa59w/love_for_big_pickle/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0384hx",
          "author": "Erebea01",
          "text": "I think they self host their free models and say they don't cost much to host or something so they decide to provide them for free. I might be wrong tho.",
          "score": 7,
          "created_utc": "2026-01-17 11:29:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04b0wc",
              "author": "verbose-airman",
              "text": "My guess was it is smaller models that wanna market their models so they give free access for a limited time.",
              "score": 2,
              "created_utc": "2026-01-17 15:32:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o04tmqc",
              "author": "smile132465798",
              "text": "https://x.com/thdxr/status/1980317899828129992?s=46\nFor reference",
              "score": 1,
              "created_utc": "2026-01-17 17:00:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o06y98c",
                  "author": "touristtam",
                  "text": "> so our costs are 12.5x cheaper than a general purpose one\n\nThat's mental. I wonder if there is a possibility to run a similar setup locally on a consumer laptop and still get decent performances.",
                  "score": 1,
                  "created_utc": "2026-01-17 23:14:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o04catn",
          "author": "Big-Masterpiece-9581",
          "text": "The free ones on opencode zen are with clear TOS. You get free. They get your data and feedback to improve. They will all eventually move to paid only.\n\nBig Pickle is more. It’s a stealth model. That means one of the big ai companies has a new model they’re testing pre-release. There is no paid version because it’s not yet released. And we might never find out when it’s released that it was previously called big pickle.\n\nYou have to take that into account if using free models.",
          "score": 6,
          "created_utc": "2026-01-17 15:39:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04cyt8",
              "author": "seaweeduk",
              "text": "Big pickle is not a stealth model, it's glm 4.6 with a funny name hosted with one of their providers. Dax has confirmed this multiple times already.\n\nhttps://twitter.com/thdxr/status/1984090146460020966",
              "score": 3,
              "created_utc": "2026-01-17 15:42:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o05n2jl",
                  "author": "pwarnock",
                  "text": "It may have been glm-4.6 at the time he said that, but nothing prevents it from being changed. \n\nKilo has a new stealth model from a Chinese Lab called Giga Potato. Similar naming; size + food. Could be coincidence. \n\nWhen it leaked that Mistral’s model was stealth (spectre I think), they declined it and the following day announced it. \n\nSo take what you see on X with a grain of salt and assume that using Big Pickle for free means you’re helping them train, debug, and scale to get it to a state that they are confident charging for.",
                  "score": 2,
                  "created_utc": "2026-01-17 19:17:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o04cser",
              "author": "External_Ad1549",
              "text": "yeah i read it but it is being stealth for a very long time",
              "score": 1,
              "created_utc": "2026-01-17 15:41:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0360z0",
          "author": "lundrog",
          "text": "Pretty sure its k2 thinking",
          "score": 10,
          "created_utc": "2026-01-17 11:10:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03k7z9",
              "author": "seaweeduk",
              "text": "dax has confirmed multiple times before, its just glm 4.6 with a funny name",
              "score": 10,
              "created_utc": "2026-01-17 13:04:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03zrb9",
                  "author": "KnifeFed",
                  "text": "So why use it over GLM 4.7? Is it faster?",
                  "score": 4,
                  "created_utc": "2026-01-17 14:34:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o04d6u3",
                  "author": "External_Ad1549",
                  "text": "i am kind of using glm models like from 4.5 it doesn't seem like 4.6 i might be wrong when context increased it kind of behaved on it's own k2 will do that or I might be wrong",
                  "score": 4,
                  "created_utc": "2026-01-17 15:43:26",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o04qgs2",
                  "author": "minaskar",
                  "text": "It certainly used to be GLM-4.6, but I'm pretty sure it's been replaced with K2 Thinking now. If you notice at the OpenCode Desktop app, Big Pickle allows you to change the reasoning effort, just like K2 Thinking. GLM-4.6/4.7 do not have this freedom.",
                  "score": 1,
                  "created_utc": "2026-01-17 16:46:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o036ulu",
              "author": "External_Ad1549",
              "text": "can be, I completely forgot that it existed",
              "score": 1,
              "created_utc": "2026-01-17 11:17:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o03h1at",
          "author": "websitegest",
          "text": "That anxiety about “this is awesome AND free, so it’s probably going to vanish mid‑project” is very real. Free tiers are nice for experimentation, but for serious backend work predictability > freebies.\n\nWhat worked for me was building around a paid coding plan with known limits as the backbone, and then treating fast/free models like Big Pickle as opportunistic accelerators. Opus (or similar) sets the architecture, GLM 4.7 and Big Pickle handles the implementation and refactor loops, and anything else fast just rides on top.\n\nIf you’re looking for something closer to a predictable, paid plan rather than a gamble on a free endpoint, Zai has coding plans where you can still get 50% discount for first year + 30% discount (current offers + additional 10% coupon code) but I think it will expire soon (some offers are already gone!) > [https://z.ai/subscribe?ic=TLDEGES7AK](https://z.ai/subscribe?ic=TLDEGES7AK)",
          "score": 4,
          "created_utc": "2026-01-17 12:42:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03nx7g",
              "author": "External_Ad1549",
              "text": "thanks i have max plan zai it is my work horse, chatgpt for architectural decisions but sometimes zai goes very slow for a simple tasks glm 4.7 took 28 sec same big picke took 7.5 sec but when the depth increased big pickle kind of left me and wrote its own code despite having correct plan.md in place never happened with glm 4.7. I completely agree with u",
              "score": 3,
              "created_utc": "2026-01-17 13:28:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o048mrj",
                  "author": "ZeSprawl",
                  "text": "Try GLM 4.7 on Cerebras. You can try it out on the free tier. The speed is actually insane. Fastest response I've ever seen for a smart coding model. It's addictive and I hope they offer it on their coding plan whenever there's availability again.",
                  "score": 2,
                  "created_utc": "2026-01-17 15:21:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o04p5cc",
          "author": "psilokan",
          "text": "Interesting.  I've found big pickle to be very slow when using it. Also found it to be very buggy.  One time it just randomly switched to chinese and all the output was in chinese characters, no idea why lol.",
          "score": 2,
          "created_utc": "2026-01-17 16:40:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04s4uw",
              "author": "External_Ad1549",
              "text": "😂😂 switch to chinese happened in Antigravity as well\nwhen did you tested this?",
              "score": 1,
              "created_utc": "2026-01-17 16:53:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o04xb51",
                  "author": "psilokan",
                  "text": "This was right before Christmas.  The funny thing it still understood me and kept doing what I asked despite me having no clue what it was saying back lol",
                  "score": 2,
                  "created_utc": "2026-01-17 17:17:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o05wzoo",
          "author": "Easy_Zucchini_3529",
          "text": "Use GLM-4.7 with Fireworks or Cerebras.",
          "score": 2,
          "created_utc": "2026-01-17 20:05:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05xiov",
              "author": "External_Ad1549",
              "text": "crebras  is limited, trail version got some burst but it is always pushing 1 min break like limited tokens in 1 min. not available right now, coding plans are not available. fireworks ai is little costly need to check whether it has coding plans",
              "score": 1,
              "created_utc": "2026-01-17 20:08:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o05zbo4",
                  "author": "Easy_Zucchini_3529",
                  "text": "true, both are not the most cheapest solution, but the tokens per second are insane (specially Cerebras)",
                  "score": 2,
                  "created_utc": "2026-01-17 20:17:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0fb2vx",
          "author": "37chairs",
          "text": "Big pickle was a total joke at first. I used it again on a whim after hitting limits and was blown away. Is also possible I got better at talking to the things in the interim, but it went from trash to cash.",
          "score": 2,
          "created_utc": "2026-01-19 04:57:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qigg6v",
      "title": "Vercel just launched skills.sh, and it already has 20K installs",
      "subreddit": "opencodeCLI",
      "url": "https://jpcaparas.medium.com/vercel-just-launched-skills-sh-and-it-already-has-20k-installs-c07e6da7e29e?sk=98a3faa46bb67d1e492d6a8361f36dd1",
      "author": "jpcaparas",
      "created_utc": "2026-01-20 22:55:40",
      "score": 42,
      "num_comments": 5,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qigg6v/vercel_just_launched_skillssh_and_it_already_has/",
      "domain": "jpcaparas.medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0re79u",
          "author": "Nexmean",
          "text": "I decided to open source my own billion dollars skills tool, there it is:\n\n```bash\nwhile getopts \"a:\" o; do\n  case \"$o\" in\n    a) AGENT=\"$OPTARG\" ;;\n  esac\ndone\nshift $((OPTIND - 1))\n\nREPO=\"$1\"\n: \"${AGENT:?}\" \"${REPO:?}\"\n\ngit clone --depth=1 \"https://github.com/$REPO.git\" \"/tmp/$REPO\"\n\nmkdir -p \"$PWD/.$AGENT/skills\"\n\nfind \"/tmp/$REPO\" -name SKILL.md -type f | while read -r f; do\n  d=\"$(dirname \"$f\")\"\n  cp -R \"$d\" \"$PWD/.$AGENT/skills/$(basename \"$d\")\"\ndone\n```",
          "score": 14,
          "created_utc": "2026-01-20 23:35:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0sjtqg",
              "author": "Enesce",
              "text": "I'm gonna wrap your tool and make a TWO billion dollar skills tool",
              "score": 4,
              "created_utc": "2026-01-21 03:30:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0tyapp",
              "author": "rmaxdev",
              "text": "Vercel is on drugs releasing ideas that EVERYONE has \n\nThey just piggyback on their reputation, but they are not doing anything exceptional and likely will become irrelevant soon",
              "score": 2,
              "created_utc": "2026-01-21 10:22:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0tk516",
              "author": "Coded_Kaa",
              "text": "What is this 😂",
              "score": 1,
              "created_utc": "2026-01-21 08:07:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tykpy",
          "author": "rmaxdev",
          "text": "You don’t needs to install skills, your agent can write their own skills for your specific problem \n\nThe agentic space is become very BLOATED because code is cheap \n\nIt takes me longer to understand how to reuse what others have done than to ask implement the same for my specific needs",
          "score": 5,
          "created_utc": "2026-01-21 10:25:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qj2qjc",
      "title": "I experimented with an open source Figma-style spatial canvas to run Coding Agents in parallel. Implementing Opencode rn. What do you think?",
      "subreddit": "opencodeCLI",
      "url": "https://v.redd.it/gbr9sv2hcqeg1",
      "author": "DistanceOpen7845",
      "created_utc": "2026-01-21 16:35:06",
      "score": 39,
      "num_comments": 13,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qj2qjc/i_experimented_with_an_open_source_figmastyle/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0xbmwa",
          "author": "typescape_",
          "text": "The spatial component is underrated. Most agent orchestration tools treat parallel workflows as a list, but the Figma-style canvas lets you visually group related agents and see the branching structure. That's genuinely useful when you're running 5-10 agents and need to remember what each one is doing.The reactflow + embedded terminals approach is clever. I've been using Claude Code and OpenCode heavily, and the biggest friction is context-switching between sessions. Having them all visible on a canvas with decision nodes surfaced would save real time.The JSONL file structure that Claude Code uses is surprisingly hackable. You're right that the clean separation between tool calls and messages makes it easy to build secondary interfaces. The session awareness via tagged IDs is a nice touch for handling highlighted text [context.One](http://context.One) thing i'd want: persistent state between canvas sessions. When you close and reopen, do the agent sessions restore with their full history, or do you need to restart from scratch? The worst part of the current IDE experience is losing context when you close a tab.Curious what the memory footprint looks like running multiple terminal instances. Electron apps can get heavy.",
          "score": 3,
          "created_utc": "2026-01-21 20:53:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0y8ku2",
              "author": "DistanceOpen7845",
              "text": "awesome to hear, and super happy if you try it :)\n\nThey get restored and are stored from session to session so the consistency is there. It is all having the JSONls as a backbone so that sticks around.\n\nWith memory it never got too bloated for me and I was running some 5-6 branches together, but fair to observe.\n\nlet me know if you checked it out",
              "score": 1,
              "created_utc": "2026-01-21 23:33:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0x3b7c",
          "author": "gottapointreally",
          "text": "Very interesting concept. Will try",
          "score": 1,
          "created_utc": "2026-01-21 20:16:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0x5ndp",
              "author": "DistanceOpen7845",
              "text": "awesome, let me know what you think :)",
              "score": 2,
              "created_utc": "2026-01-21 20:26:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0y7xle",
          "author": "0b_1000101",
          "text": "I had the exact same idea. I just don't have that much frontend experience. Looks good!",
          "score": 1,
          "created_utc": "2026-01-21 23:29:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0y8vwo",
              "author": "DistanceOpen7845",
              "text": "haha, thanks! then I'd be super happy if you contribute to the backend :) be my guest u/0b_1000101",
              "score": 1,
              "created_utc": "2026-01-21 23:34:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o102mzg",
          "author": "Cultural-Match1529",
          "text": "Looks awesome will give it a shot.",
          "score": 1,
          "created_utc": "2026-01-22 06:12:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o102p77",
              "author": "Cultural-Match1529",
              "text": "can't give it a shot windows :(",
              "score": 1,
              "created_utc": "2026-01-22 06:13:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o10kt1o",
                  "author": "DistanceOpen7845",
                  "text": "oh no, sorry about that :( thought about working on windows later",
                  "score": 1,
                  "created_utc": "2026-01-22 08:53:07",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o109kjd",
          "author": "PassengerLatter8",
          "text": "This looks indeed pretty cool, unfortunately a windows / wsl user. But I like the idea",
          "score": 1,
          "created_utc": "2026-01-22 07:10:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10kuw5",
              "author": "DistanceOpen7845",
              "text": "thanks! Happy about anyone who wants to support with the windows version :)",
              "score": 1,
              "created_utc": "2026-01-22 08:53:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1146ci",
          "author": "Wrong_Daikon3202",
          "text": "It looks really good.\n\nIt would be nice if you pre-compiled it for Linux.",
          "score": 1,
          "created_utc": "2026-01-22 11:45:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11z32o",
              "author": "DistanceOpen7845",
              "text": "awesome, yeah we focused mostly on macOS but more might come soon",
              "score": 2,
              "created_utc": "2026-01-22 14:47:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qkozvt",
      "title": "Free models",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/jdkxpid1a3fg1.png",
      "author": "beneficialdiet18",
      "created_utc": "2026-01-23 12:03:10",
      "score": 36,
      "num_comments": 24,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qkozvt/free_models/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o18h8js",
          "author": "bonnmos",
          "text": "It seems like the free glm4.7 ended today. It now asks for payment information when I try to use GLM4.7-free.",
          "score": 14,
          "created_utc": "2026-01-23 13:33:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o19txjl",
              "author": "deadcoder0904",
              "text": "U can use GLM 4.6 instead which is the Big Pickle model. Or buy a GLM 4.7 Coding plan for the quarter for $8.10 (discount ends on 31st Jan)",
              "score": 5,
              "created_utc": "2026-01-23 17:26:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1dhouw",
                  "author": "bonnmos",
                  "text": "thanks 👍",
                  "score": 1,
                  "created_utc": "2026-01-24 04:53:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1dvnpc",
                  "author": "indian_geek",
                  "text": "Warning - the performance of the coding plan has been borderline unusable since almost a month now and the team behind it are not bothered.",
                  "score": 1,
                  "created_utc": "2026-01-24 06:40:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o18y53y",
          "author": "Suitable-Program-181",
          "text": "You got late to the party bro! They took them out today.\n\nThe ones left are 2023 all over again is so hilarious...",
          "score": 9,
          "created_utc": "2026-01-23 15:00:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1838fa",
          "author": "sdatta11",
          "text": "I also noticed same thing .. when I using glm 4.7 it says no payment method set",
          "score": 3,
          "created_utc": "2026-01-23 12:05:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o183guc",
              "author": "beneficialdiet18",
              "text": "It's not available for me to select at all unless I provide an API key, yet I see other users saying they have GLM and Minimax available for free.",
              "score": 0,
              "created_utc": "2026-01-23 12:07:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1848d3",
                  "author": "abhiramskrishna",
                  "text": "it was free for a limited time, it ended now.",
                  "score": 3,
                  "created_utc": "2026-01-23 12:13:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o18mvhu",
          "author": "redoubledit",
          "text": "Gone for me since yesterday. Minimax as well.",
          "score": 2,
          "created_utc": "2026-01-23 14:03:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o185vhe",
          "author": "UniqueAttourney",
          "text": "The CLI doesn't show GPT-5 Nano at all, though",
          "score": 1,
          "created_utc": "2026-01-23 12:24:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o186694",
              "author": "beneficialdiet18",
              "text": "Yep, noticed that as well. Only available on the desktop version.",
              "score": 2,
              "created_utc": "2026-01-23 12:26:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o18hs8x",
                  "author": "bonnmos",
                  "text": "I haven't used the desktop version yet..is it as good as the CLI though?",
                  "score": 1,
                  "created_utc": "2026-01-23 13:36:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o18mzi8",
          "author": "smile132465798",
          "text": "I’m in love with Minimax M2 for general tasks. Sad that I must back to using Gemini and pray it doesn’t act stupid.",
          "score": 1,
          "created_utc": "2026-01-23 14:04:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18r1o1",
              "author": "seaal",
              "text": "First month of minimax plan is $2, basically infinite use with their 5 hour refreshing quota.",
              "score": 5,
              "created_utc": "2026-01-23 14:25:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o19k9p5",
          "author": "Few-Mycologist-8192",
          "text": "thank god , i love you",
          "score": 1,
          "created_utc": "2026-01-23 16:42:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19pril",
          "author": "richardlau898",
          "text": "minimax disappeared too",
          "score": 1,
          "created_utc": "2026-01-23 17:06:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bj1xm",
          "author": "Round_Mixture_7541",
          "text": "Big pickle? Wtf? 😅😅😅\nCmoon...",
          "score": 1,
          "created_utc": "2026-01-23 22:09:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18d7yx",
          "author": "Silver-Ideal9451",
          "text": "glm 4.7 이제 유료 인가요?",
          "score": 1,
          "created_utc": "2026-01-23 13:11:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qgnad6",
      "title": "Fix memory Leak please",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/8rc4r45sv6eg1.png",
      "author": "ZookeepergameFit4082",
      "created_utc": "2026-01-18 23:07:16",
      "score": 34,
      "num_comments": 5,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qgnad6/fix_memory_leak_please/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0er6n5",
          "author": "james__jam",
          "text": "Sounds like something that needs to be posted in github issues and not reddit 😅",
          "score": 20,
          "created_utc": "2026-01-19 02:54:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gaxla",
          "author": "AVX_Instructor",
          "text": "Its probably LSP, i have get simular issue, if keep long session in huge code base",
          "score": 2,
          "created_utc": "2026-01-19 10:05:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0h8wmh",
          "author": "FatherImPregnant",
          "text": "Are you using OhMyOpencode? I’ve noticed the same issue",
          "score": 1,
          "created_utc": "2026-01-19 14:15:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0hbqfm",
          "author": "trypnosis",
          "text": "I use basic opencode with a few mcps and run them all day multiple instance in tmux and my memory is fine. \n\nCould it be an addon or customisation of some kind?",
          "score": 1,
          "created_utc": "2026-01-19 14:30:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lojn9",
          "author": "tripleshielded",
          "text": "It needs memory leaks to give a similar experience to gemini cli.",
          "score": 1,
          "created_utc": "2026-01-20 03:20:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfsg1t",
      "title": "Switch to OpenCode for Money Efficiency",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qfsg1t/switch_to_opencode_for_money_efficiency/",
      "author": "Demon-Martin",
      "created_utc": "2026-01-17 23:34:26",
      "score": 34,
      "num_comments": 51,
      "upvote_ratio": 0.97,
      "text": "Heyo devs,\n\nBeen thinking on switching to OpenCode from Cursor to save some money.\n\nCurrently I run 2 cursor ultra accounts and I am still burning though limits too quickly. Can‘t afford to keep those costs tho, so I been planning on switching to OpenCode with a few chatgpt/google (maybe glm) accounts. I‘m pretty Sure those would end up being was cheaper for more tokens. My biggest costs is Claude Opus 4.5.\n\nThe problem is: I love cursor‘s IDE and I really got used to it. I don‘t really like CLIs (didn’t like claude code too).\n\nAnd sadly I read that Anthropic is now actively attacking external usage of their subs.\n\nI want to test OpenCode (or something similar). OpenChamber is what I found, but thats more like an Chatbox than an Editor if I understood correctly.\n\nI also tried Google‘s AntiGravity but it‘s straight up not the level that Cursor is. And I also read last days that they also started making rate limits worse.\n\nWhat would you do in my situation? Is there a good OpenCode Extension? How good is OpenCode actually?\n\nThanks.\n\nEDIT:\n\nI forgot to mention, I currently usually work like this:\n\nI first let a cheaper model do some research in the project based on a task. Then use Opus to create a plan and iterate till it creates a plan that follows what I want. Then I execute this plan with either composer, if I want it fast, or Gemini Flash 3, if I want it cheap (there is no other cheap model on cursor that‘s also good, flash is the 2nd cheapest next to GPT 5 nano on cursor, afaik). If Gemini fails, I also let it run though Gemini 3 Pro, Claude Sonnet and Opus itself, depending on the situation and project.\n\nEDIT 2 (18.01.2026):\n\nI tried OpenCode, added my ChatGPT Sub, Google Sub and GitHub Copilot Sub (got most of it for free because I am a student). It generally worked good, but I still don‘t really like working in the CLI. It just doesn‘t give me the User Experience and viewing that an Editor like Cursor gives me. I also tried OpenCode Desktop and that‘s also not optimal.\n\nEven tho my credit usage might suggest otherwise: I am not a „pure vibe coder“. I actively manually check all edits, fix stuff manually and code manually. I don‘t let AI do everything by itself.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qfsg1t/switch_to_opencode_for_money_efficiency/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o07ig6h",
          "author": "Putrid-Pair-6194",
          "text": "I was exactly the same situation with cursor. So recently, I switched to a combination of opencode plus Antigravity. For me, the differences in antigravity from cursor for me were very small. \n\nSo now my set up is focused on opencode with the antigravity authentication extension. That gives me access to all of the opus and sonnet usage you get with antigravity. The Opus and sonnet usage you get with a single user is very limited. But, you can significantly increase that by buying a $20 a month family plan to the Google AI Pro subscription. That subscription allows you to sign up five “family members”.  Every family member gets its own unique quota for antigravity Claude models. So if you set this up for $20 a month you get a fairly substantial amount of daily Claude usage. \n\nI also purchased a three dollar a month GLM 4.7 subscription for day-to-day tasks. Together the Google AI pro subscription with the “five family members” and the GLM 4.7  subscription give a very significant amount of usage for low cost. That’s probably enough for most people, but I also have a ChatGPT $20 a month subscription that also hooks into opencode. ChatGPT 5.2 may be slow, but I found it to be very reliable. I have plenty of horsepower for 4 to 5 hour coding sessions.\n\nThis is certainly much more complex than just paying for cursor. But my cursor bills were often exceeding $120 a month. Right now this costs me closer to $40-$50 a month and I don’t feel like I’m losing much. The extra complexity may not be right for everyone, but it works pretty well for me.",
          "score": 13,
          "created_utc": "2026-01-18 01:01:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o085r0r",
              "author": "Delicious_Ease2595",
              "text": "How do you use my multiple family accounts with OpenCode? I'm using the same setup between Antigravity and OpenCode",
              "score": 3,
              "created_utc": "2026-01-18 03:06:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o08rn9n",
                  "author": "Putrid-Pair-6194",
                  "text": "I don’t remember the details off-hand, but I think instructions were on the antigravity opencode authentication repo. I’m assuming you have setup 5 gmail accounts and added them to your family. Then if memory serves, you use the instructions for the antigravity authentication extension to log into each one. And the extension rotates across all of them automatically.",
                  "score": 1,
                  "created_utc": "2026-01-18 05:24:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o099lgn",
              "author": "pl201",
              "text": "Don’t think Google AI pro family share each gets separate quota for $20. It’s one pool shared with up to 5 people. Don’t believe it is very useful if more than one person try to use Antigravity.",
              "score": -1,
              "created_utc": "2026-01-18 07:55:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0cln4p",
                  "author": "Putrid-Pair-6194",
                  "text": "I don’t know what are you basing that view on. Here is information from Google that aligns with my personal experience. Other forums seem to concur.\n   \n\n1. Individual Quotas for Family Members\nAccording to Google One Help and official developer forum clarifications from January 2026.\n  \n\n• Independent Limits: Each member of a Google Family group (up to 5 additional members) receives their own full set of daily and recurring rate limits.  \n• Not a Shared Pool: Unlike storage (which is shared from a common pool), AI quotas for features like Antigravity are per-user. One person’s heavy usage does not deplete the quota for another family member.",
                  "score": 1,
                  "created_utc": "2026-01-18 20:10:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07qoil",
          "author": "Coldshalamov",
          "text": "[z.ai](http://z.ai) subscription (https://z.ai/subscribe?ic=QDKACAZ1KX and 3x  the usage of claude pro) $2.50 a month\n\nGithub copilot with unlimited chatgpt 4o, 4.1, 5 mini, and grok code fast: $10/m\n\nOpencode Zen: Big Pickle, GLM 4.7, Minimax 2.1, and grok code fast 1 for free\n\nMinimax subscription: $2/m\n\nMoonshot Kimi k2 thinking subscription: $3/m\n\nAll told in opencode: $14.50/m and will never ever hit my limits. I have an extensive subagent driven /build command I loop 3 times that takes 12 hours each, and a /prune command I run once or twice to trim the fat once its done, and then 90% of my projects are functional and need a few tuneups.",
          "score": 10,
          "created_utc": "2026-01-18 01:44:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08mm7s",
              "author": "GullibleDragonfly131",
              "text": "Can you share your Git repo? I'm interested to see how those LLMs compare to Opus.",
              "score": 2,
              "created_utc": "2026-01-18 04:49:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o09r38q",
              "author": "Rygel_XV",
              "text": "How did you get the Minimax and Kimi subscription so cheap? I can find both for $10 respective $9 per month.",
              "score": 1,
              "created_utc": "2026-01-18 10:37:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09rhh8",
                  "author": "Coldshalamov",
                  "text": "strangely, you have to argue with kimi for the price, there's like a promotional event but it actually seems like its response is largely uncalibrated from the price it gives, you just have to keep prompting it until it gives you the right price, I've done it multiple months in a row on the same account. It does look to me now that I checked that the $2 starter plan promo that they had has ended, I know [z.ai](http://z.ai) has theirs until the 30th so i plan on inviting myself and getting another $25 year of lite just because, who knows what i could automate with an extra key.",
                  "score": 1,
                  "created_utc": "2026-01-18 10:40:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0a1f2b",
              "author": "ekalaivan",
              "text": "How to get z ai sub so cheap? In fact except for GitHub i don't see how you get those services for that cheap!",
              "score": 1,
              "created_utc": "2026-01-18 12:08:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0a485s",
                  "author": "Rygel_XV",
                  "text": "They have a reduced price offer running until 31.01. And if you pay quarterly or yearly you get a big discount as well. On top of that they have referral codes for another 10%.\n\nFor example here is my referral :)\nhttps://z.ai/subscribe?ic=JQTB1W1M0L\n\nI think their idea is to lock in people now. If you prepaid for a whole year, will you switch to a different company with a better model if it would arrive?\n\nI myself chose to get the quarterly plan. To play it safe.",
                  "score": 2,
                  "created_utc": "2026-01-18 12:30:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07rrix",
          "author": "FlyingDogCatcher",
          "text": "What are you people doing that you burn through two premium accounts and still can't afford them?",
          "score": 7,
          "created_utc": "2026-01-18 01:49:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09bufv",
              "author": "P1zz4-T0nn0",
              "text": "I've got the same question. I'm a self-employed senior-developer coding all day and I don't hit the limits on a single Max 5x lol. Maybe that are people who don't actually know programming and try 10 workstrees at once, idk.",
              "score": 2,
              "created_utc": "2026-01-18 08:15:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09iegy",
                  "author": "Demon-Martin",
                  "text": "No I don’t run 10 work trees, and I am a Full-Stack Developer. Opus is just way too expensive. If I understood correctly, Claude Subs can‘t even be compared with Cursors costs. The sub‘s efficiency is way higher than cursors prices.",
                  "score": 1,
                  "created_utc": "2026-01-18 09:16:15",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o09n3uc",
                  "author": "UMANTHEGOD",
                  "text": "Power users (doing ralph loops etc) can burn through tokens pretty quickly but it depends on what you're using it for. I'm currently building a personal budget app, a personal fitness app and a refactoring app for work so I'm getting limited constantly.\n\nAll vibe coded of course because the quality of the code doesn't really matter for these apps.\n\nI've also used opus for everything and I could probably be more mindful to swap to sonnet at times.",
                  "score": 0,
                  "created_utc": "2026-01-18 10:00:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o09i6ns",
              "author": "Demon-Martin",
              "text": "My current project is a rather big turborepo with multiple packages and projects (apps) and most tasks require a big context for the produced code to be good and properly use the available packages. I am already running different methods to minimize the context usage, but still some opus requests cost like 1-3$, and when you code for like 8 hours straight a day, that adds up after time.\n\nObv running a simpler project with less context would be way cheaper.",
              "score": 1,
              "created_utc": "2026-01-18 09:14:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0730p6",
          "author": "No-Concentrate-6037",
          "text": "I would try to learn to use the CLI if I want Opus that badly",
          "score": 3,
          "created_utc": "2026-01-17 23:39:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o076fwr",
              "author": "Demon-Martin",
              "text": "I assume you are talking about Claude Code / an Anthropic Sub with OpenCode\n\nProblem is: I read a TON of negative information about Anthropic the past weeks.\n\nClaude Code is consuming an enormous big amount of tokens compared to before. They are making the ratelimits way way more harsh. And I personally don‘t really like when I want to work, but can‘t because the provider decided to make the model 10x dumber and make the token limit to be 1 prompt per session.\n\nAlso, read that opencode and anthropic ain‘t best friends atm.\n\nhttps://www.reddit.com/r/ClaudeAI/comments/1qa50sq/anthropic_banning_thirdparty_harnesses_while/\nhttps://news.ycombinator.com/item?id=46625918\n\nInfo I was talking about with ratelimits:\nhttps://www.theregister.com/2026/01/05/claude_devs_usage_limits/\nhttps://github.com/anthropics/claude-code/issues/16157#issuecomment-3712177862\nhttps://news.ycombinator.com/item?id=46514221\n\nTheir discord also has an open thread about it with people complaining daily, but the main is probably: https://github.com/anthropics/claude-code/issues/16157",
              "score": 3,
              "created_utc": "2026-01-17 23:57:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o07kjy2",
                  "author": "Historical-Lie9697",
                  "text": "Github copilot is actually not bad for $10/month for supplementing Claude use, has unlimited use of gpt5 mini for easy stuff and 300 premium requests/month that includes a lot of models and they all work in OpenCode. I think for a budget that + Codex $20/m to use them all in OpenCode is a good option. Then if you want multimedia generation and the big context window you could add gemini",
                  "score": 3,
                  "created_utc": "2026-01-18 01:12:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o07bcr3",
                  "author": "No-Concentrate-6037",
                  "text": "No, I mean using Claude Code itself. And yes. I know about all above discussion, but hard to beat Opus as of now",
                  "score": 2,
                  "created_utc": "2026-01-18 00:23:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o08rnhh",
          "author": "NearbyBig3383",
          "text": "People use chutes.ai, it's only 20 bucks man, it's cheap and it never runs out.",
          "score": 3,
          "created_utc": "2026-01-18 05:24:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o092rn0",
              "author": "MorningFew1574",
              "text": "How does chutes compare to nanogpt?",
              "score": 1,
              "created_utc": "2026-01-18 06:54:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0fy6zf",
                  "author": "Complex-Maybe3123",
                  "text": "NanoGPT user here. I`m currently using their Subscription. Never used chutes. \n\nI believe NanoGPT uses some cheaper providers to keep their prices competitive, so I end up getting some very big token speed variation. I use mostly GLM 4.7 Thinking nowadays. Hardly for coding, but in the end, there`s not a lot of difference. Sometimes my requests start processing instantly, others times, it seems like I enter a queue. I time the whole request time (from the moment I press enter, to the moment I receive the whole response, I don`t usually use streaming), so I`m not sure of the actual TPS. But if I`d calculate the tokens per second with the whole request time, sometimes I get 100t/s, some rarer cases it`s very close to 10t/s. Usually it`s more in the middle. But I believe this variation is the delay until my request starts getting processed instead of actual TPS variation. These calcs I mentioned were usually done with around 20k~30k input context and 1k~3k output.\n\nI tried the big boys (GPT and Claude) a few times and they seem to respond the same as from the source.\nAll in all, I`m not a vibe coder, I prefer to use mostly tab-autocomplete, which is outside of what NanoGPT offers. So I don`t really mind the speed variation. At this point in time, I wouldn`t leave NanoGPT for any other provider. New released models become available almost immediately. The devs are also always listening to the users and suggestions are quickly implemented (when they make sense).\n\nSo for open source models, I`m of the opinion that it`s the best, in terms of price, available models and support. When it comes to premium models, there doesn`t seem to be much difference from other providers besides some discounts.",
                  "score": 2,
                  "created_utc": "2026-01-19 08:05:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o09zvdi",
          "author": "kkordikk",
          "text": "Actually switch your approach. Let the more expensive models do the research and plan the work out with granular tasks. Then smaller models to implement small tasks. GLM is great, cheap, fast, limits reset each 5hrs, it’s great reasoning, multimodal. I highly recommend getting quarterly plan right now, there’s a promo still going. Also free Gemini API key and if you like opus, just use it sparingly via Anthropic 100$ sub. Also, you can still use free cursor as an ide",
          "score": 2,
          "created_utc": "2026-01-18 11:55:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a2e35",
              "author": "Demon-Martin",
              "text": "I would be using other subs, but cursor itself sadly doesn’t really support it inside their built-in interface. I don‘t really like CLIs/Terminals so OpenCode/Claude Code isn‘t optimal for me.\n\nI was planning on getting GLM or Minimax or similar, just cursor is very annoying with only supporting „one base url overwrite“ that breaks all other models…",
              "score": 1,
              "created_utc": "2026-01-18 12:16:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0a6rb6",
                  "author": "jorgejhms",
                  "text": "Maybe you could try Zed then. Is a code editor written in Rust (it's not a fork of vscode) and one of their key principles is to be open. They allow you to use it's AI features with their own subscription or with any API key. I have it set with GLM currently, with also copilot free and Gemini API keys. They also developed the Agent Client Protocol (ACP) that allows third party cli agents like Claude Code or OpenCode to be used inside Zed UI, like a panel. Seems like the best option for you that don't like terminals.",
                  "score": 2,
                  "created_utc": "2026-01-18 12:50:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0b9pic",
                  "author": "kkordikk",
                  "text": "Huh? It does. Go into cursor settings -> models -> scroll down and there you can use Anthropic key, openAI endpoint / API key (this is for ChatGPT, custom gateway like z.ai) \nPersonally I’m hosting LiteLLM (alternative to OpenRouter) and using all my models through it",
                  "score": 1,
                  "created_utc": "2026-01-18 16:24:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0afs8j",
          "author": "febryanvald0",
          "text": "Try OpenCode Black\n\n\nhttps://opencode.ai/black",
          "score": 2,
          "created_utc": "2026-01-18 13:50:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0adzyz",
          "author": "Fun-Understanding862",
          "text": "would suggest you to give github copilot a try, it has upped its game, for me claude code(20$) and github copilot(10$) plan works well",
          "score": 1,
          "created_utc": "2026-01-18 13:39:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0am2px",
          "author": "PweraUsog",
          "text": "Switch to Qwen CLI",
          "score": 1,
          "created_utc": "2026-01-18 14:26:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0f900o",
          "author": "RayanAr",
          "text": "Isn't opencode slower than claudecode?",
          "score": 1,
          "created_utc": "2026-01-19 04:43:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lj9xp",
          "author": "raptor_champs",
          "text": "GitHub copilot is in VScode and has a great cli\nAnd you can chose your model",
          "score": 1,
          "created_utc": "2026-01-20 02:50:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfnus6",
      "title": "I don’t get it",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qfnus6/i_dont_get_it/",
      "author": "Mindless_Art4177",
      "created_utc": "2026-01-17 20:26:14",
      "score": 26,
      "num_comments": 28,
      "upvote_ratio": 0.77,
      "text": "I think I’m missing something basic I don’t get the hype around open code\n\nI’m using cursor 20$ plan ( get blocked ) which I like the most in terms of ui and workflow\n\nCodex cli when I run out of credits (chat gpt 20$) which is also ok Antigravity from time to time (free)\n\nWhy should I switch to opencode ? What’s the big Change ? Should I buy 20$ plan ? From what I see the IDE extension is just running terminal in sidebar.\n\nPlease enlighten me 🙏\n\n—-\n\nEdit:\n\nNow I get it, you can connect multiple accounts from multiple vendors using /connect and keep using only one tool.\n\nSupports all subagents/commnads/skills so you don’t need to rewrite them when you’re switching between models.\n\nOpen source with  big community around it with additional products such as open chamber.\n\nThanks.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qfnus6/i_dont_get_it/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o063ngn",
          "author": "Funny-Advertising238",
          "text": "First of all you can get openchamber from GitHub which is a frontend interface for opencode, I love it.\n\n\nSecond you can connect you chatgpt accounts, antigravity accounts, as well as use all the free models that opencode providers (glm 4.7, minimax etc.).\n\n\nI have 7 antigravity accounts connected and 3 chatgpt accounts. Never get rate limited and antigravity rate limits reset every 5 hours which is great. \n\n\nI was tired if switching between different ones, opencode has everything you need, model agnostic, exposes a openapi server as well and sdk for automations, it has all the features you need like subagents, hooks, skills, etc.\n\n\nAnd a little trick if you feel a little bit grey hat, you can get google ai pro and chatgpt plus accounts for 1-2$ on digital goods marketplaces.",
          "score": 11,
          "created_utc": "2026-01-17 20:40:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o066hiy",
              "author": "technischer_walzer",
              "text": "How do you have 7 antigravity accounts accounts? Did you create them? And you pay for 3 chatgpt accounts?",
              "score": 4,
              "created_utc": "2026-01-17 20:54:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o067pja",
                  "author": "Funny-Advertising238",
                  "text": "Nope I buy chatgpt plus accounts for 2$ each. Same with antigravity for 3-4$. I have 3 google ai pro accounts and the rest are just my own google accounts that don't have a subscription but they still work just the rate limits are much lower.",
                  "score": -3,
                  "created_utc": "2026-01-17 21:00:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0754lb",
              "author": "matija2209",
              "text": "Can you recommend some of those digital goods markets please. Thanks",
              "score": 2,
              "created_utc": "2026-01-17 23:50:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o081soq",
                  "author": "ezhupa99",
                  "text": "plati market",
                  "score": 0,
                  "created_utc": "2026-01-18 02:44:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o064x4a",
              "author": "Mindless_Art4177",
              "text": "Thanks for explaining I’ll try to figure out how to connect my other accounts and give it a chance.",
              "score": 0,
              "created_utc": "2026-01-17 20:46:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o064ksm",
          "author": "Michaeli_Starky",
          "text": "You are not obliged. \n\nTo me OC has a special place because it's open source. Also it works with multiple subs: Copilot, GPT, Antigravity... Anthropic is an exception since recently.",
          "score": 4,
          "created_utc": "2026-01-17 20:44:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o062mlr",
          "author": "No-Concentrate-6037",
          "text": "no you should not change. It's totally just hype. keep using your codex and antigravity.\n\nhappy?",
          "score": 9,
          "created_utc": "2026-01-17 20:34:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o067epv",
          "author": "trypnosis",
          "text": "It’s a weird one.\n\nI think it’s the level of customisation for terminal gremlins.\n\nIf you look at the terminal as a cool fun tool then Claude Code, codex and OpenCode fill certain holes in your work flow.\n\nIf terminal is something you see as a more complicated way of using git then. Cursor, CS code with plugins and IntelliJ IDEs are for you.\n\nAll IDEs be they TUI or App have a workflow to leverage the power of LLMs to code. You need to find the one that works for you. I would say none is better than the other. What matters is best for you.",
          "score": 2,
          "created_utc": "2026-01-17 20:59:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o06h1vf",
          "author": "Haspe",
          "text": "This is a tool firstly designed to us terminal users, something that you can use, while you don't have to switch out from the terminal - TUI was their first \"product.\" Their architectic choice of client/server model however enables different client creation, and they're now providing Web, Electron for Desktop and probably a Mobile client in the future. You can also build your own front-end to talk with the server as well and use OpenCode as part of your thing.\n\nOpenCode's another selling point is model agnosticity. You can work with every model with single tool - it's like Visual Studio Code or Neovim of the Agentic Tools. The flavor of the month on the model market will change - perhaps you want to work with OpenAI models. Perhaps you want to work it some self-hosted model as well. Perhaps your workflow consists of using multi-provider models for different things. So if your toolkit is model agnostic, swapping the models that you use does not mean that you have to change your whole workflow - thats the point. For example as a Claude user you're breaking their TOS if you're not using their own clients for their own tools (except the API option, but their API option is quite expensive)\n\nI guess Cursor does that same thing to an extend - but OpenCode is open-source and Cursor is not (this might not mean anything to you, but for other people it does). I can see what the OpenCode does under the hood - and I can even fork it and create my own version of it if I want to. In the end the value proposition of a product is also a preference thing. I prefer to work in terminal, you might not - and you don't have to. Cursor is extremely good as well.",
          "score": 2,
          "created_utc": "2026-01-17 21:48:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o06iw8b",
              "author": "Mindless_Art4177",
              "text": "Now I get it\nYou’re model agnostic, so you write your subagents/commands/skills and you don’t need to port it or switch tools when you’re running out of credits. Greet selling point.\n\nI’m used for cli tools so it’s not a problem, only when I’m developing ui I like to attach screenshots directly from clipboard to the conversion , cursor does it very well, not sure it’s will work in cli context.\n\nThanks any way 🙏",
              "score": 1,
              "created_utc": "2026-01-17 21:57:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o07uxab",
                  "author": "Big_Bed_7240",
                  "text": "Opencode has image support",
                  "score": 2,
                  "created_utc": "2026-01-18 02:06:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o06305f",
          "author": "pokemonplayer2001",
          "text": "Imagine trying it and deciding for yourself!  \n\nJust imagine a modicum of effort!",
          "score": 5,
          "created_utc": "2026-01-17 20:36:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o064gl8",
              "author": "Mindless_Art4177",
              "text": "I tried and it’s felt exactly like any other cli (codex, Gemini-cli)\nThat’s why I got to feeling I’m missing something \nSometimes you might find goldmine by just asking",
              "score": 2,
              "created_utc": "2026-01-17 20:44:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o072zp3",
          "author": "Apprehensive_Half_68",
          "text": "I liked OpenCode after I gave it a shot a few weeks ago like you.  However what I wasn't ready for was \"Oh My OpenCode\" which has changed the way I develop software with most of the presets I use already built in.  It actually is TURNING me into a CLI guy as it feels just like cursor with a sidebar to chat and a file explorer open.. mcp status always visible etc but makes using Ralph Wiggum almost too easy.",
          "score": 1,
          "created_utc": "2026-01-17 23:39:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o07cxr8",
          "author": "dubh31241",
          "text": "The biggest selling points to me are the built in client/server architecture with pretty much API parity with what you can do locally as well as the ability to build literally any type of interface on top of opencode. This is now an AI compute engine. With some imagination and creativity, you can build tons of stuff on top of this. I just deployed this on a K8 cluster to interact with all of my resources; its like a bloomberg terminal for my K8 cluster.  \n\nMy next idea is to build a K8 operator for this to deploy multiple instances, because why do I need \"Agentic Frameworks\" if I can somehow orchestrate these using Skills and Agent file.",
          "score": 1,
          "created_utc": "2026-01-18 00:31:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08h31w",
          "author": "SynapticStreamer",
          "text": "> Why should I switch to opencode ?\n\nWhy are you acting like everyone here is just dying for you to swap up your workflow? You're approaching everything about this entirely wrong... A better question is why would you want to use 4 tools when you can deal with only 1.",
          "score": 1,
          "created_utc": "2026-01-18 04:12:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a5hm0",
          "author": "sbayit",
          "text": "My primary model is GLM, and DeepSeek's Opencode works best with it when running on its own server rather than through Openrouter.",
          "score": 1,
          "created_utc": "2026-01-18 12:40:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o064y2o",
          "author": "trmnl_cmdr",
          "text": "I tried vscode and it was exactly like notepad, I don’t see why I should switch",
          "score": 0,
          "created_utc": "2026-01-17 20:46:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qk3b8m",
      "title": "OpenCode Image Generation Plugin",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/gallery/1qk3b8m",
      "author": "xdestroyer83",
      "created_utc": "2026-01-22 18:58:26",
      "score": 26,
      "num_comments": 10,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qk3b8m/opencode_image_generation_plugin/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o13j35g",
          "author": "xdestroyer83",
          "text": "for anyone curious here's the generated image \n\nhttps://preview.redd.it/al4vpx8u7yeg1.jpeg?width=1376&format=pjpg&auto=webp&s=8a95d9d555c432fc71c3ceee8c953f41e03578cf",
          "score": 7,
          "created_utc": "2026-01-22 19:01:45",
          "is_submitter": true,
          "replies": [
            {
              "id": "o168oe4",
              "author": "xdestroyer83",
              "text": "Here's a post showcasing it's capabilities when paired with coding: [https://www.reddit.com/r/opencodeCLI/comments/1qkflwi/image\\_generation\\_plugin\\_test/](https://www.reddit.com/r/opencodeCLI/comments/1qkflwi/image_generation_plugin_test/)",
              "score": 1,
              "created_utc": "2026-01-23 03:21:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o140dee",
          "author": "Putrid-Pair-6194",
          "text": "Nice. I will try it.",
          "score": 2,
          "created_utc": "2026-01-22 20:20:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o188r2q",
              "author": "Putrid-Pair-6194",
              "text": "Installed last night. Was able to generate a few images. Thank you!",
              "score": 2,
              "created_utc": "2026-01-23 12:43:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1d5si3",
                  "author": "xdestroyer83",
                  "text": "Thankss, glad it helped you can check [ArtifexMCP](https://github.com/jkalasas/artifex-mcp) as well, i turned it into an MCP so that you can easily connect it with different AI clients",
                  "score": 1,
                  "created_utc": "2026-01-24 03:35:29",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o19taof",
          "author": "trypnosis",
          "text": "Very cool.\n\nWhat’s the use case from development perspective?",
          "score": 2,
          "created_utc": "2026-01-23 17:23:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1d5fq8",
              "author": "xdestroyer83",
              "text": "no need to hunt for assets now 😎😎😎",
              "score": 1,
              "created_utc": "2026-01-24 03:33:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o13n2fp",
          "author": "sudonem",
          "text": "Neato.",
          "score": 1,
          "created_utc": "2026-01-22 19:19:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o153ibc",
          "author": "ReasonableReindeer24",
          "text": "Gemini 3 pro did it better than opus 4.5",
          "score": 1,
          "created_utc": "2026-01-22 23:36:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17gn0p",
          "author": "Several_Explorer1375",
          "text": "Commenting to remember in the morning",
          "score": 1,
          "created_utc": "2026-01-23 08:50:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qky971",
      "title": "How OpenCode went from zero to titan in eight months",
      "subreddit": "opencodeCLI",
      "url": "https://jpcaparas.medium.com/dcdcd8ff5572?sk=e4d734988b81d43db236a2c910e584e4",
      "author": "jpcaparas",
      "created_utc": "2026-01-23 18:11:11",
      "score": 25,
      "num_comments": 3,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qky971/how_opencode_went_from_zero_to_titan_in_eight/",
      "domain": "jpcaparas.medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "o1bjz4h",
          "author": "FreakyT",
          "text": "I feel like this post doesn't address what, to me, is the most important part of the story: why are people running Opencode with Claude anyway?\n\nWasn't the main purpose of Opencode to be Claude code but for people who want to use other models?",
          "score": 4,
          "created_utc": "2026-01-23 22:13:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1dm7ud",
              "author": "james__jam",
              "text": "Here’s my interpretation of what happened\n\nTDLR: opencode was for terminal lovers, but what resonated the most to people is its model agnostic nature\n\nOpencode was made for terminal lovers. It’s when you want to hack and customize your agentic system just like you would your nvim. I remember their docs saying something like that. So the tui experience was their #1 priority. And that’s the reason why they have keybindings and extensibility. extensibility in the form of you can have your own commands, agents, your own models, and a plugin system for further expansion (_those are the first few that they have out of the box_).\n\nAlso, they’ve always recommend claude models (_im not sure if they do still, but they did for the longest time_). \n\nBut i think what got people reaching for opencode is to avoid the vendor lockin. It’s not just anthropic. Every model provider has been accused of nerfing their model post launch. And having your own setup from one agentic tool only to be rug pulled is annoying to the say the least. \n\nSo yeah, i think people are switching to opencode because it’s model agnostic. \n\nAnd although not everybody would hack and customize their setup, we have a few that would even turn their setups into plugins and make it available for others.",
              "score": 1,
              "created_utc": "2026-01-24 05:25:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1d8hte",
          "author": "cuba_guy",
          "text": "Definitely not from zero, some very respected top devs behind it. We've been using sst (serverless framework from the same people) for years at work as default",
          "score": 2,
          "created_utc": "2026-01-24 03:52:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qixs8i",
      "title": "Super simple way to migrate your Claude Code configs to OpenCode",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/5lybeqq8apeg1.png",
      "author": "hyericlee",
      "created_utc": "2026-01-21 13:24:04",
      "score": 24,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qixs8i/super_simple_way_to_migrate_your_claude_code/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0ushkb",
          "author": "buggytheking",
          "text": "My G thank you so much for this. I just built an agent to do this but this is so much better.",
          "score": 2,
          "created_utc": "2026-01-21 13:55:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0utdgn",
              "author": "hyericlee",
              "text": "Glad it helped! Yeah as a CLI tool it doesn’t use up any of your tokens, so that’s a plus.",
              "score": 1,
              "created_utc": "2026-01-21 14:00:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uvdbd",
          "author": "raydou",
          "text": "Do you know if there's a compatibility in OpenCode to Claude Code rules which are markdown files in  /rules folder (project or user's home)\nIf they exists is opkg compatible with them?",
          "score": 2,
          "created_utc": "2026-01-21 14:11:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0uxqlb",
              "author": "hyericlee",
              "text": "Great question actually, OpenCode rules works a bit different than Claude, Cursor, etc. as it needs to be mapped via opencode.json and not individual files, so I’m working on a mapping feature that will allow OpenPackage to map these file names to opencode.json “instructions” field. This should be ready in one of the next few updates.",
              "score": 2,
              "created_utc": "2026-01-21 14:23:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0wfk06",
          "author": "Heavy-Focus-1964",
          "text": "I just cobbled together a much worse version of this out of symlinks yesterday, but this is much better. A star and an upvote for you.\n\n  \nAre claude hooks/opencode plugins on your radar at all? Even though they do almost the same thing, I know the implementation of each is very different. I know this doesn't have an easy answer, just wondering what your thoughts are",
          "score": 2,
          "created_utc": "2026-01-21 18:29:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0yyg71",
              "author": "hyericlee",
              "text": "Yeah it’s precisely that the two systems are quite different that it hasn’t been implemented so far.\n\nThe primary reason is that the two systems are using different “engines”, Claude hooks using bash commands while OpenCode plugins using JS/TS runtime. This leads to a very large set of differences to map.\n\nHowever there’s a direction that I’m looking at where we may be able to wrap JS code into files for CC to run via bash, and for the other direction run bash commands to invoke JS code. Not an easy task to unify though!\n\nI’m glad OpenPackage has been useful, thanks for the suggestion and your support! This is great food for thought.",
              "score": 2,
              "created_utc": "2026-01-22 01:56:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qhj9ua",
      "title": "Bringing \"Advanced Tool Use\" to OpenCode with mcpx",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qhj9ua/bringing_advanced_tool_use_to_opencode_with_mcpx/",
      "author": "vicdotso",
      "created_utc": "2026-01-19 22:41:29",
      "score": 23,
      "num_comments": 3,
      "upvote_ratio": 0.96,
      "text": "Anthropic recently published their advanced tool use - [https://www.anthropic.com/engineering/advanced-tool-use](https://www.anthropic.com/engineering/advanced-tool-use) approach. The key insight is moving tool discovery to runtime instead of loading schemas upfront.\n\nThe problem: MCP integrations are fragmented. Claude Code has native support, most other tools don't. If you switch agents, you lose access to your MCP setup.\n\nBuilt mcpx to bring this pattern to any agent with bash. OpenCode, Aider, your custom setup. If it can run bash, it can use MCP servers now.\n\n\\- brew tap cs50victor/mcpx && brew install mcpx\n\n\\- mcpx  ( list all servers/tools )\n\n\\- mcpx grep \"\\*browser\\*\"          ( search by pattern )\n\n\\- mcpx playwright/click          ( get schema )\n\n\\- mcpx playwright/click '{\"selector\": \"#submit\"}'  ( call tool )\n\nwhy this approach:\n\n\\- Works across agents - not locked to any specific tool\n\n\\- Runtime discovery - \\~400 tokens vs 47k for upfront schema loading\n\n\\- Daemon mode - keeps stateful connections alive (browser sessions, db handles)\n\n\\- Uses your existing MCP config - no migration needed\n\nIt's open source: [https://github.com/cs50victor/mcpx](https://github.com/cs50victor/mcpx)\n\nWould love feedback, especially from folks who've been switching between agents.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qhj9ua/bringing_advanced_tool_use_to_opencode_with_mcpx/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0nnkz7",
          "author": "ExtentOdd",
          "text": "Why dont you create the PR? I believe this feature should be native to Opencode",
          "score": 6,
          "created_utc": "2026-01-20 12:37:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nq76o",
          "author": "touristtam",
          "text": "Looks similar to https://github.com/kenneth-liao/mcp-launchpad?",
          "score": 2,
          "created_utc": "2026-01-20 12:55:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0o5vfv",
              "author": "vicdotso",
              "text": "just checked this out. this looks really like a solid project / alternative to mcpx.",
              "score": 1,
              "created_utc": "2026-01-20 14:24:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qho03o",
      "title": "Happy Coder for OpenCode",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qho03o/happy_coder_for_opencode/",
      "author": "opus-sophont",
      "created_utc": "2026-01-20 01:59:54",
      "score": 21,
      "num_comments": 19,
      "upvote_ratio": 0.92,
      "text": "I’ve been using OpenCode for my agentic coding workflows and I really like it, but managing it on mobile is a pain.\n\nI know I can SSH into my remote server (using Termius, etc.), but text-based terminal interactions on a phone screen are clunky compared to a proper chat interface. I recently saw [**Happy.engineering**](http://Happy.engineering) (for Claude Code) and the UX is exactly what I want—a clean, mobile-friendly chat UI that connects to my agent without needing to fiddle with raw SSH commands every time.\n\nDoes anyone know if a similar wrapper or mobile-first UI exists for OpenCode? I know `opencode-web` exists, but I'm looking for something that feels more like a native app or a smoother relay service.\n\nHas anyone solved this mobile workflow yet?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qho03o/happy_coder_for_opencode/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0lmvnr",
          "author": "Open_Scallion9015",
          "text": "Yep there’s OpenChamber. It works great on mobile. https://github.com/btriapitsyn/openchamber",
          "score": 10,
          "created_utc": "2026-01-20 03:10:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ml1eu",
              "author": "opus-sophont",
              "text": "Thanks for sharing this, this is actually great.\n\nFor those who might not know this, you could fire up a local host login and then set up a cloudflared tunnel with your own domain to access the host from anywhere. Make sure to have some appropriate security measures other than just the password protect that OpenChamber provides, though.",
              "score": 2,
              "created_utc": "2026-01-20 07:02:26",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0mh21w",
              "author": "WholesomeGMNG",
              "text": "Thanks for sharing this!",
              "score": 1,
              "created_utc": "2026-01-20 06:29:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0llxw3",
          "author": "lundrog",
          "text": "So your saying we should vibe code something?",
          "score": 6,
          "created_utc": "2026-01-20 03:05:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0o5mm7",
              "author": "TopSimple3181",
              "text": "already on it ( [X](https://x.com/devmuzzammil/status/2013502484518457530) ), building [broski](https://broskiapp.com)",
              "score": 2,
              "created_utc": "2026-01-20 14:23:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ll0bz",
          "author": "woundedknee_x2",
          "text": "Opencode has a built in web client (opencode web --port 3000), but it’s not very mobile friendly. Would love something like this.",
          "score": 4,
          "created_utc": "2026-01-20 03:00:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0o5xnf",
              "author": "TopSimple3181",
              "text": "already on it ( [X](https://x.com/devmuzzammil/status/2013502484518457530) ), building [broski](https://broskiapp.com)",
              "score": 1,
              "created_utc": "2026-01-20 14:24:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0lmb50",
          "author": "skinnydill",
          "text": "Mac only: https://vibetunnel.sh/",
          "score": 4,
          "created_utc": "2026-01-20 03:07:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mthwi",
              "author": "maxz2040",
              "text": "What a mad soundtrack. Bring back chip tunes to vibe coded apps",
              "score": 1,
              "created_utc": "2026-01-20 08:18:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0lazsj",
          "author": "Dudmaster",
          "text": "Happy coder supports codex, so my first instinct would be to write the integration with AI or at least gauge difficulty. It is open source so I'd hope the framework is fairly extensible",
          "score": 2,
          "created_utc": "2026-01-20 02:05:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mlqpx",
          "author": "Recent-Success-1520",
          "text": "https://github.com/NeuralNomadsAI/CodeNomad allows you to remote handover",
          "score": 1,
          "created_utc": "2026-01-20 07:08:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nm4x9",
              "author": "opus-sophont",
              "text": "That's interesting, thanks for sharing. I looked at the project and it looks neat. One question I have though is, is the experience much better than just using the given OpenCode webui? One thing I like about OpenChamber that another guy mentioned in the comments is that the mobile UI is extremely friendly, so I was wondering what about CodeNomad appeals to you personally.",
              "score": 1,
              "created_utc": "2026-01-20 12:27:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0nmq98",
                  "author": "Recent-Success-1520",
                  "text": "Disclaimer - I built CodeNomad.\n\nThe reason I built it was that opencode webui or Desktop app is more geared towards making it an easy to use tool without looking at what's happening under the hood.\n\nIt supports Desktop app mode, web ui mode, remote server mode and easy handover to phone from desktop mode and server modes.\nTry it out, it's easy to try.",
                  "score": 1,
                  "created_utc": "2026-01-20 12:32:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0n6t6a",
          "author": "sentrix_l",
          "text": "I've faced the same problem; most tools arent good enough for this.\n\nCursor solved it with their cloud agents. Downside: leave it for too long and you can't continue the conversation. But you can comment on github and mention cursor and it'll do it. It's finicky imo. As setup of the cloud agent makes it use a large portion of the context window. ON SETUP...\n\nClaude solved this too and their ecosystem is a bit better, similar approach to cursor.\n\nOpencode should have a github mention integration where AI does its thing. Pretty sure you can set this up using GH Actions.\n\nBut... all of them miss critical infrastructure.\n\nI built SprintFlint, a tool similar to Linear but you can autoplay issues and AI creates PRs for you, utilising what you give it; skills, mcps, plugins, agent browser and so on. No vendor lock in so you can use any AI with it (as long as it runs in the terminal). Utilising GH Actions.\n\nI started using this to further develop SprintFlint, needless to say this AI feature is still a work in progress. The agent asks questions in issue comments if it has any and creates the PR if it has enough clarity.\n\nI want to improve it further so you can see what's going on and chat with the AI properly in SprintFlint, but that'll take some time.",
          "score": 1,
          "created_utc": "2026-01-20 10:23:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0o5elu",
          "author": "TopSimple3181",
          "text": "Yes I’m building [broski](https://broskiapp.com) for that, about to ship to app store and excited. Just preparing final screenshots and all",
          "score": 1,
          "created_utc": "2026-01-20 14:21:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qx3fu",
          "author": "pRizzAtGitHub",
          "text": "I’ll throw my hat in the ring and also mention I’m building something somewhat similar to what you’re asking for. I wasn’t aware of all these other projects when I started building it, but I feel it’s kinda similar to CodeNomad in spirit, except closer to being an opencode mod + cockpit. Here’s my repo: https://github.com/pRizz/opencode-cloud",
          "score": 1,
          "created_utc": "2026-01-20 22:06:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wirph",
          "author": "TheHeadSalad",
          "text": "There’s also opencode-manager. Works like a charm. I use it on mobile every day. \n\nhttps://github.com/chriswritescode-dev/opencode-manager",
          "score": 1,
          "created_utc": "2026-01-21 18:43:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qin7zr",
      "title": "Best plugins, AI agents and workflows 2025",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qin7zr/best_plugins_ai_agents_and_workflows_2025/",
      "author": "joshuajm01",
      "created_utc": "2026-01-21 03:44:52",
      "score": 20,
      "num_comments": 8,
      "upvote_ratio": 0.95,
      "text": "Hi All \n\nWhen I say \"best\" I mean for you and your workflow. What has been tried and tested by you or your company personally.\n\nI'm wanting to know what are everyones plugins or agents being used in Opencode right now? What is your workflow with those plugins or agents? \n\n  \nI've tried using oh my opencode and I have to say it takes way too long to do anything. I've seen others say the same. So I'm curious to know what everyone's setup is. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qin7zr/best_plugins_ai_agents_and_workflows_2025/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0sntxu",
          "author": "jhartumc",
          "text": "antigravity auth  \ndynamic context pruning  \nsuperpowers",
          "score": 5,
          "created_utc": "2026-01-21 03:55:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0x0q96",
          "author": "Practical_Oil_1312",
          "text": "Definitely antigravity auth",
          "score": 2,
          "created_utc": "2026-01-21 20:04:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o14v1lm",
              "author": "joshuajm01",
              "text": "Why is that",
              "score": 1,
              "created_utc": "2026-01-22 22:52:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1755cx",
                  "author": "Practical_Oil_1312",
                  "text": "You can use antigravity model quota in opencode",
                  "score": 2,
                  "created_utc": "2026-01-23 07:07:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o17hnoo",
              "author": "BedForeign4467",
              "text": "I saw this recommendation and would like to try it but then I saw the warning about the chance of getting banned so I didn't get the courage to try it 😭",
              "score": 1,
              "created_utc": "2026-01-23 08:59:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0syq62",
          "author": "Kitchen_Fix1464",
          "text": "I built some custom tools to add mem0 support. That has been the most noticeable extension I've used so far.",
          "score": 1,
          "created_utc": "2026-01-21 05:08:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tq43b",
          "author": "bebenzer",
          "text": "I am trying openspec, it seems nice, in my experience it adds strong guardrails to the model and the work done is good, obviously sometimes I may need to adjust the spec created or I need to chat a bit to guide the llm for the feature.\n\nI don't know if it's overkill yet, and maybe in a near future this tool will be obsolete because opencode will add a similar feature (I saw a tweet or on the discord their next plan mode based on cursor one or something similar).\n\nhowever there is something annoying, I dont know what should I do with all the markdowns generated, should I commit them or add them in the gitignore. I'm not sure about what is the right workflow when you work in a team as some colleagues may use openspec or other similar tools or none, what if we have the same spec names etc.",
          "score": 0,
          "created_utc": "2026-01-21 09:04:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi20vk",
      "title": "I built open-source Claude CoWork on OpenCode with app integrations. Works on Windows and Linux.",
      "subreddit": "opencodeCLI",
      "url": "https://github.com/ComposioHQ/open-claude-cowork",
      "author": "Gullible-Time-8816",
      "created_utc": "2026-01-20 14:08:01",
      "score": 19,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qi20vk/i_built_opensource_claude_cowork_on_opencode_with/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0qhdjo",
          "author": "Michaeli_Starky",
          "text": "Building MVP of that is trivial. Maintaining and developing it is not. Letting LLM run unrestricted on your PC is a HUGE gamble. You absolutely must build extremely intricate guardrails.",
          "score": 1,
          "created_utc": "2026-01-20 20:54:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhrnwf",
      "title": "interviewed with oh-my-opencode creator",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qhrnwf/interviewed_with_ohmyopencode_creator/",
      "author": "Ok_Rub1689",
      "created_utc": "2026-01-20 04:48:28",
      "score": 17,
      "num_comments": 3,
      "upvote_ratio": 0.85,
      "text": "[https://www.youtube.com/watch?v=6RUIK5gI6l4&feature=youtu.be](https://www.youtube.com/watch?v=6RUIK5gI6l4&feature=youtu.be)  \n  \nWhile the world is busy \"vibe coding,\" YeonGyu has built a system that treats AI agents as a precision-engineered workforce.  \n  \nAccording to Kim, OmO isn't just a wrapper. It’s a multi-model orchestration layer that puts your coding productivity on steroids.\n\n  \nhope you enjoy this.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qhrnwf/interviewed_with_ohmyopencode_creator/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0poeer",
          "author": "rmaxdev",
          "text": "Spends too many tokens in background search the often continues after I got my answer \n\nThat’s my only complain",
          "score": 2,
          "created_utc": "2026-01-20 18:41:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10t5ly",
          "author": "mr_Fixit_1974",
          "text": "Token heavy for sure",
          "score": 1,
          "created_utc": "2026-01-22 10:11:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0m97ee",
          "author": "mustafamohsen",
          "text": "Interesting. Thanks",
          "score": 1,
          "created_utc": "2026-01-20 05:28:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}