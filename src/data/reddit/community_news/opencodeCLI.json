{
  "metadata": {
    "last_updated": "2026-02-25 03:09:26",
    "time_filter": "week",
    "subreddit": "opencodeCLI",
    "total_items": 20,
    "total_comments": 286,
    "file_size_bytes": 290628
  },
  "items": [
    {
      "id": "1rb65ak",
      "title": "I made a TUI tool to use OpenCode basically for free using NVIDIA's NIM API's and finds the fastest available model in real-time.",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/mr10u1qdoxkg1.gif",
      "author": "AgeFirm4024",
      "created_utc": "2026-02-21 23:37:25",
      "score": 249,
      "num_comments": 68,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1rb65ak/i_made_a_tui_tool_to_use_opencode_basically_for/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6p7205",
          "author": "a_alberti",
          "text": "OK. It works very nicely for me. Kudos for the clean implementation.\n\nCan someone explain here in the chat why Nvidia allows such loopholes? What is the business model? Do they want us to try out their models and then be hooked to a subscription or paid APIs?\n\nIt is too good to be true. Please help me understand. Thanks!",
          "score": 17,
          "created_utc": "2026-02-22 01:30:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6q07q1",
              "author": "ElectronicBend6984",
              "text": "Cut out the middleman. They sell the brain and providing free options for that layer of consumption makes the hardware more valuable. Nvidia got to where they are by funding research, no reason to change that strategy.",
              "score": 9,
              "created_utc": "2026-02-22 04:47:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6x4c46",
                  "author": "Latter-Parsnip-5007",
                  "text": "Wtf man, its an free online service. I want yall to understand ONE thing about the internet. IF ITS FREE, YOU ARE THE PRODUCT. Insta, facebook, youtube even opencode free models. They all exist to collect your user behavior. Either to sell it directly to ad firms, to use it to improve their sellable product or to tailor ads themselves. ",
                  "score": 4,
                  "created_utc": "2026-02-23 08:17:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6snemo",
              "author": "Pleasant_Thing_2874",
              "text": "It likely is more a way to spike up usage in various data centers while they continue to seek funding and to look good when the shareholder meetings come around.  They're all still in building/financing mode so most of them are likely profit negative (and intentional) but when they can go \"Look, our usage is 75% concurrent on average, which means when we put in our pricing plans and start pushing for revenue we should expect to bring in X amount of revenue daily/weekly/monthly\"....that's how you get people to invest millions upon millions more.   The entire AI data center investing/infastructure sector is built on sticks and duct tape and this is just another row to help keep it going.",
              "score": 3,
              "created_utc": "2026-02-22 16:30:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6p76xd",
              "author": "AgeFirm4024",
              "text": "Thanks a lot ! ðŸ˜Š",
              "score": 2,
              "created_utc": "2026-02-22 01:30:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6pdywn",
          "author": "MaxPhoenix_",
          "text": "I actually built an automated benchmarking tool very similar to this recently for free models across OpenCode, Kilocode, OpenRouter, and NVIDIA. You're right about the NVIDIA loophole - now that they swapped the non-renewing 1000-credit cap for per-minute rate limits, it's a great resource.\n\nThat said, I'd highly recommend adding a quality/eval filter, rather than just sorting by latency and uptime. I found that optimizing for speed over quality is a trap with these free tiers. Many of the fastest models will hallucinate, fail tool calls, or completely ignore instructions. For example, my benchmarks showed models like Minimax-2.5 consistently mutilating code (e.g., quietly changing hyphens to underscores in variables).\n\nIf you adjust your agent/tool to evaluate and filter models based on actual coding performance and instruction-following - not just ping times - this could be incredibly useful. Right now, sending users to the top 20 fastest models might just result in a lot of frustrating debugging sessions.",
          "score": 10,
          "created_utc": "2026-02-22 02:14:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6pm6we",
              "author": "omicron8",
              "text": "I have been working on something similar. Do you have a repo you wouldn't mind sharing?",
              "score": 4,
              "created_utc": "2026-02-22 03:09:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6rkppm",
              "author": "AgeFirm4024",
              "text": "you're absolutely right. Quality filtering is the next priority. How do you think it can be done without spamming tests to Nvidia servers ?",
              "score": 3,
              "created_utc": "2026-02-22 13:09:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6seide",
                  "author": "Vmvgsar",
                  "text": "Can you just include results for some of the coding benchmarks for all the models they offer, and allow the user to sort by this or to show only those either above some value or in top 5/10?",
                  "score": 2,
                  "created_utc": "2026-02-22 15:51:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6pkyxt",
          "author": "ochonueve89",
          "text": "Doesn't this risk nvidia-nim banning the user due to spamming their servers with requests?",
          "score": 8,
          "created_utc": "2026-02-22 03:00:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rl1yy",
              "author": "AgeFirm4024",
              "text": "I implemented a little feature to change ping frequency, i'll optimize it today, you can change ping updates with W/X keyboard touch.  \n  \nThe 40 req/min rate limit is enforced at the API gateway level, so even pinging all 44 models in parallel stays within their intended usage. Each ping is a single legit API call, not scraping or abuse. NVIDIA explicitly encourages this kind of dev usage in their docs. So I guess we're good !",
              "score": 3,
              "created_utc": "2026-02-22 13:12:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6pcz4n",
          "author": "dengar69",
          "text": "This looks great.  Are you able to apply this to NanoGPT?  The models there are very inconsistent and would be nice to check beforehand.  Thanks,",
          "score": 6,
          "created_utc": "2026-02-22 02:08:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rledr",
              "author": "AgeFirm4024",
              "text": "added to the update list, don't hesitate to add issues on github next time :)",
              "score": 2,
              "created_utc": "2026-02-22 13:14:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6t99xk",
                  "author": "dengar69",
                  "text": "I entered one last night.  The model doesnâ€™t get picked when it opens OpenCode.  It reverts to my last choice.",
                  "score": 2,
                  "created_utc": "2026-02-22 18:10:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6s0k38",
              "author": "Embarrassed_Bread_16",
              "text": "does it provide free models?",
              "score": 2,
              "created_utc": "2026-02-22 14:43:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6t91fd",
                  "author": "dengar69",
                  "text": "Yes",
                  "score": 2,
                  "created_utc": "2026-02-22 18:09:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6pxv2y",
          "author": "keroro7128",
          "text": "Awesome ðŸ‘",
          "score": 5,
          "created_utc": "2026-02-22 04:30:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rlf57",
              "author": "AgeFirm4024",
              "text": "thanks bro :)",
              "score": 2,
              "created_utc": "2026-02-22 13:14:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6q8bkw",
          "author": "ForeverDuke2",
          "text": "Amazing, thanks for this bro\n\nI hope the opensource community picks it up and keeps contributing",
          "score": 3,
          "created_utc": "2026-02-22 05:52:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rlitm",
              "author": "AgeFirm4024",
              "text": "thanks ! i'll try to update it a lot so it's always up to date with all current free ai available :)",
              "score": 2,
              "created_utc": "2026-02-22 13:15:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6qinmu",
          "author": "c0nfluks",
          "text": "Cool tool. Do you have an ETA on the openclaw implementation? Thanks",
          "score": 2,
          "created_utc": "2026-02-22 07:25:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rloc6",
              "author": "AgeFirm4024",
              "text": "i almost made it work yesterday, just need to fix a few config files and try some models (some models on the list are really lame for openclaw, i had a model that gave me arabic, thaÃ¯, and non sense english in the same message ðŸ¤£)",
              "score": 2,
              "created_utc": "2026-02-22 13:16:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o752qkf",
                  "author": "c0nfluks",
                  "text": "Can you let us know when youve implemented it?",
                  "score": 1,
                  "created_utc": "2026-02-24 14:26:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6qu3ym",
          "author": "Embarrassed_Bread_16",
          "text": "Thx for implementing my suggestion, great, now I think it's gonna be great that u or someone else create a blog like explanation of the Nvidia service and what the experience with it is like, I'm looking at u community ðŸ˜‰",
          "score": 2,
          "created_utc": "2026-02-22 09:14:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rlqw7",
              "author": "AgeFirm4024",
              "text": "thanks ! i'll let you know, i'm planning on doing that when the tool is a bit more mature and finished :) ",
              "score": 2,
              "created_utc": "2026-02-22 13:16:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6r1k63",
          "author": "mintybadgerme",
          "text": "How can I get this going with opencode desktop for Windows?",
          "score": 2,
          "created_utc": "2026-02-22 10:26:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rlzw8",
              "author": "AgeFirm4024",
              "text": "I'll add that in a future update, good point :) i guess you can do it manually for now. One amazing (but risky thing) I do all the time : you run a opencode or claude code instance in your root folder and just ask it to install it, 99% of the time, it works. But I'll add it in a future update anyway :)",
              "score": 1,
              "created_utc": "2026-02-22 13:18:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6rqrlc",
                  "author": "mintybadgerme",
                  "text": "Yeah, I'm trying not to be risky. :)",
                  "score": 1,
                  "created_utc": "2026-02-22 13:48:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6oy5df",
          "author": "rizal72",
          "text": "you changed the name! I remember checking it yesterday and it had another name :) However, nice job! Don't bother for stupid comments ;)",
          "score": 2,
          "created_utc": "2026-02-22 00:34:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6p0f7m",
              "author": "AgeFirm4024",
              "text": "yeah i called it nimping, since it was just a tui that pings NIM, but I plan to add other sources of free AI providers in it so i renamed it :) Thanks a lot ! don't worry I don't care about stupid comments lol",
              "score": 3,
              "created_utc": "2026-02-22 00:47:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6pasm1",
                  "author": "rizal72",
                  "text": "May I suggest to add opencode Zen and Openrouter? I use their free models a lot, mixed with paid ones in my multi agents settings with oh-my-opencode-slim, to witch I am a contributor ;)",
                  "score": 5,
                  "created_utc": "2026-02-22 01:54:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6rvxh8",
          "author": "AgeFirm4024",
          "text": "UPDATE : I added an auto updater and a warning to inform you about new versions available, please reinstall the package :) npm i -g free-coding-models",
          "score": 1,
          "created_utc": "2026-02-22 14:17:43",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o6uw6ad",
          "author": "AgeFirm4024",
          "text": "I made a Discord sever ! [https://discord.com/invite/5MbTnDC3Md](https://discord.com/invite/5MbTnDC3Md)",
          "score": 1,
          "created_utc": "2026-02-22 23:04:58",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o6w0fo2",
          "author": "JensInJapan",
          "text": "That's really cool! I just tested it out.   \nIt would be super nice if we could pause with space button to have it not jump around any for us slow readers ðŸ˜‚",
          "score": 1,
          "created_utc": "2026-02-23 03:01:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6y54lg",
              "author": "AgeFirm4024",
              "text": "Oh, you can sort models with keyboard touches so it doesnt move. try hitting T, R, M, (keys are white letters in the title)",
              "score": 1,
              "created_utc": "2026-02-23 13:29:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o73k4cu",
                  "author": "JensInJapan",
                  "text": "Oh how silly of me! You're right! ðŸ˜‚ Thanks.",
                  "score": 1,
                  "created_utc": "2026-02-24 07:25:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6x6sra",
          "author": "RelationshipAny1889",
          "text": "Where can I find this opencode theme?",
          "score": 1,
          "created_utc": "2026-02-23 08:41:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6y5b8c",
              "author": "AgeFirm4024",
              "text": "it's called matrix, it's already in opencode, but my iterm2 has custom colors too on top of it \\^\\^ so i'm not sure it'll look 100% like mine",
              "score": 1,
              "created_utc": "2026-02-23 13:30:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o73nnao",
          "author": "Villain_99",
          "text": "Will definitely try it",
          "score": 1,
          "created_utc": "2026-02-24 07:58:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6p1eoc",
          "author": "No_Yard9104",
          "text": "Nvidia's website is broken.  You can't verify your account at [build.nvidia.com](http://build.nvidia.com) because their sms otp stuff to verify you is broken and has been for months and months.  There's hundreds of community discussions about it on Nvidia's developer forum.  It's been over 6 months for me and I've been trying every few weeks.  And without a verified account, you can't generate an API key.  \n\nThe most valuable company in the history of the world has been sitting on this bug for over 6 months.  If they wanted it fixed, it would be fixed.  Instead, the nvidia employees just tell people to email support for manual verification.  And they don't bother at all with doing that unless it's for a higher-profile user.  ",
          "score": 1,
          "created_utc": "2026-02-22 00:54:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6pfei5",
              "author": "Top-Faithlessness758",
              "text": "I just did it 10 minutes ago, it works.",
              "score": 2,
              "created_utc": "2026-02-22 02:24:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6p1rcl",
              "author": "AgeFirm4024",
              "text": "Where are you from? I discovered the existence of NIM yesterday and I created an API key and working very well. Maybe try with vpn but i guess you already tried",
              "score": 1,
              "created_utc": "2026-02-22 00:56:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6p5xp7",
                  "author": "No_Yard9104",
                  "text": "I'm from the US.  I've tried with and without VPN.  I tried using a friend's number who lives across the pond.  I've tried multiple browsers in case it's something bugged in the front-end.  Nothing has worked.",
                  "score": 1,
                  "created_utc": "2026-02-22 01:22:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6p397v",
              "author": "eltigre_rawr",
              "text": "YMMV but I just registered and verified through SMS OTP",
              "score": 1,
              "created_utc": "2026-02-22 01:05:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6p5pxh",
                  "author": "No_Yard9104",
                  "text": "What country are you from?  What browser did you use?  I've been trying to get an API key from them for months.  So if there's a different way to do things, I'll try anything.  ",
                  "score": 1,
                  "created_utc": "2026-02-22 01:21:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6p9ool",
          "author": "HarjjotSinghh",
          "text": "this is the future now.",
          "score": 1,
          "created_utc": "2026-02-22 01:47:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ot5x3",
          "author": "oxygen_addiction",
          "text": "Thanks for ruining NIM even further, asshole. I've reported your repo to Nvidia. Hopefully they ban your IP range.",
          "score": -18,
          "created_utc": "2026-02-22 00:03:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ou5jq",
              "author": "AgeFirm4024",
              "text": "NVIDIA's free tier is publicly documented, requires account creation, and has explicit rate limits. I automated the discovery of public endpoints. If that 'ruins' anything, take it up with NVIDIA's product team who designed it this way not me.",
              "score": 10,
              "created_utc": "2026-02-22 00:09:50",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6ouanb",
              "author": "UnifiedFlow",
              "text": "Weirdo",
              "score": 4,
              "created_utc": "2026-02-22 00:10:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6owvsz",
              "author": "Due-Dragonfruit2984",
              "text": "You must be fun at parties",
              "score": 3,
              "created_utc": "2026-02-22 00:26:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6p20ku",
                  "author": "No_Yard9104",
                  "text": "Lol...  He doesn't get invited to parties...",
                  "score": 2,
                  "created_utc": "2026-02-22 00:57:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r97ruh",
      "title": "K2.5 is still the king for open-source models",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/t4infihnzhkg1.jpeg",
      "author": "jpcaparas",
      "created_utc": "2026-02-19 18:52:00",
      "score": 171,
      "num_comments": 43,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r97ruh/k25_is_still_the_king_for_opensource_models/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6aefjo",
          "author": "Electronic_Newt_8105",
          "text": "it's just so good.\n\ncrazy how you can get access to these awesome agentic coding models for free right now",
          "score": 27,
          "created_utc": "2026-02-19 18:55:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6aev7x",
              "author": "jpcaparas",
              "text": "I'm ever more so banking on the AI bubble popping this year. the tech remains obviously, but the valuations are just way out of proportion. \n\ni do feel for our gamer friends this 2026. shit's tough.",
              "score": 13,
              "created_utc": "2026-02-19 18:57:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6agmel",
                  "author": "metalman123",
                  "text": "Demand is near the physical capacity to serve models and you think the bubbles gonna pop?",
                  "score": 5,
                  "created_utc": "2026-02-19 19:05:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6d7uvh",
                  "author": "larowin",
                  "text": "gamers arenâ€™t buying H100s lol",
                  "score": 1,
                  "created_utc": "2026-02-20 04:19:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6bi60v",
              "author": "bad_detectiv3",
              "text": "How are you using agentic coding? Is it just through opencode cli mostly?",
              "score": 2,
              "created_utc": "2026-02-19 22:08:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6btoze",
                  "author": "jpcaparas",
                  "text": "these days, yes. just for the sheer flexibility of it. although I'd be lying if I said I wasn't using Codex or Claude. All of their strengths. Codex CLI mostly for long horizon tasks and Claude when I absolutely need to use Opus and Sonnet. \n\nOpenCode is the best all-arounder.",
                  "score": 3,
                  "created_utc": "2026-02-19 23:10:59",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6dgide",
              "author": "Wildnimal",
              "text": "Free how?",
              "score": 1,
              "created_utc": "2026-02-20 05:23:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6dya1w",
                  "author": "readeral",
                  "text": "I assume not free to run, but free as in open source and you can BYO hardware. Subscription-free probably a better description",
                  "score": 3,
                  "created_utc": "2026-02-20 08:00:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ajoi2",
          "author": "chicken-mc-nugget",
          "text": "It's available on AWS Bedrock, though. ",
          "score": 6,
          "created_utc": "2026-02-19 19:20:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6b1b34",
              "author": "touristtam",
              "text": "Ye but I doubt AWS being cheap compared to __ALL__ other offerings",
              "score": 1,
              "created_utc": "2026-02-19 20:46:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6b43bq",
                  "author": "chicken-mc-nugget",
                  "text": "The US price is the same exact price they list on Zen. But they don't mention the price of cache reads on Bedrcok, so I guess they don't support it and that might be the limiting factor? ",
                  "score": 3,
                  "created_utc": "2026-02-19 20:59:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6b9aw6",
              "author": "alexeiz",
              "text": "Kimi K2.5 on Bedrock is very unreliable.  I don't know how they deployed this model, but if I try to use it from opencode, it just stops responding randomly.",
              "score": 1,
              "created_utc": "2026-02-19 21:24:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6bjb2h",
          "author": "Creepy_Reindeer2149",
          "text": "I did looked very closely and right now Fireworks.ai is best Kimi 2.5 provider for the money\n\n\nInsanely fast inference, faster than Gemini flashÂ ",
          "score": 7,
          "created_utc": "2026-02-19 22:14:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6cgpor",
              "author": "elosoyogui",
              "text": "Have you tried Baseten? It is faster https://x.com/artificialanlys/status/2023641796430180615?s=46",
              "score": 2,
              "created_utc": "2026-02-20 01:26:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6cygij",
              "author": "forgotten_airbender",
              "text": "Can you guys tell me how fast is the inference?\nI want to use fireworks but already have the kimi for coding planÂ \n",
              "score": 1,
              "created_utc": "2026-02-20 03:16:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6dysup",
                  "author": "seaal",
                  "text": "https://openrouter.ai/moonshotai/kimi-k2.5 \n\nlike 40t/s",
                  "score": 1,
                  "created_utc": "2026-02-20 08:05:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ah610",
          "author": "guillefix",
          "text": "What about GLM-5 or Minimax M2.5?",
          "score": 3,
          "created_utc": "2026-02-19 19:08:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6amuua",
              "author": "hey_ulrich",
              "text": "Kimi 2.5 is better than both in my tests.",
              "score": 14,
              "created_utc": "2026-02-19 19:35:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6bg1uv",
                  "author": "StardockEngineer",
                  "text": "Not in mine.  MM won",
                  "score": 2,
                  "created_utc": "2026-02-19 21:58:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6dis3c",
                  "author": "deadcoder0904",
                  "text": "Kimi is atleast better than both in writing. In coding, they are prolly close enough but writing is much better.",
                  "score": 1,
                  "created_utc": "2026-02-20 05:41:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6bic71",
                  "author": "bad_detectiv3",
                  "text": "TIL Kiki 2.5 is different from Minimax M2.5",
                  "score": 1,
                  "created_utc": "2026-02-19 22:09:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6ahm42",
              "author": "jpcaparas",
              "text": "GLM-5 is.... I don't know. It's erratic for me in tool-calling and not to mention the Z.ai provider inference is slow AF.\n\nMiniMax 2.5 is a joke for subagent work. It does excel on UI though. wouldn't even put it in the same league as K2.5 for utilitarian work.",
              "score": 7,
              "created_utc": "2026-02-19 19:10:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6binoo",
                  "author": "bad_detectiv3",
                  "text": "What work do you consistently hand off to K2.5",
                  "score": 2,
                  "created_utc": "2026-02-19 22:11:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6ba9qe",
              "author": "Daemonix00",
              "text": "I selfhost both K2.5 was better, GLM-5 was missing things (K2.5 is easier to host too, int4 base). both tested with sglang official cli settings.",
              "score": 1,
              "created_utc": "2026-02-19 21:29:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6bp64o",
              "author": "cutebluedragongirl",
              "text": "Kimi K2.5 is better",
              "score": 1,
              "created_utc": "2026-02-19 22:45:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6dpcdf",
                  "author": "guillefix",
                  "text": "and that is why...? I've tried it and it struggled to fix a simple positioning issue on react native... Which I ended up fixing with minimax in 1 shot.",
                  "score": 1,
                  "created_utc": "2026-02-20 06:38:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6bhzty",
          "author": "bad_detectiv3",
          "text": "WTH isnâ€™t K2.5 free one? I was reading somewhere where this model isnâ€™t great and instead we should use GLM 5.0",
          "score": 2,
          "created_utc": "2026-02-19 22:07:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6k0lxe",
          "author": "c0nfluks",
          "text": "Kimi k2.5 is available for 300 requests/day at $3/month on Chutes.ai",
          "score": 1,
          "created_utc": "2026-02-21 05:23:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6m5jlt",
          "author": "HarjjotSinghh",
          "text": "this is why we all dream of open source magic!",
          "score": 1,
          "created_utc": "2026-02-21 15:40:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6tdwac",
          "author": "HarjjotSinghh",
          "text": "whoa - this is why the future's electric!",
          "score": 1,
          "created_utc": "2026-02-22 18:31:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6af7u3",
          "author": "HarjjotSinghh",
          "text": "k2.5's got the whole ai empire by its collar.",
          "score": 1,
          "created_utc": "2026-02-19 18:59:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6bmglw",
          "author": "Available_Hornet3538",
          "text": "How do you self-host? Kimi 2.5 such a large model",
          "score": 0,
          "created_utc": "2026-02-19 22:31:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6bnjy4",
              "author": "jpcaparas",
              "text": "I don't self host, I use [Synthetic.new](http://Synthetic.new). They're an open-source provider (waitlist should be lifted soon), and I've done some mentions of them here:\n\n  \n\\- [https://blog.devgenius.io/the-definitive-guide-to-opencode-from-first-install-to-production-workflows-aae1e95855fb](https://blog.devgenius.io/the-definitive-guide-to-opencode-from-first-install-to-production-workflows-aae1e95855fb)\n\n\\- [https://jpcaparas.medium.com/stop-using-claudes-api-for-moltbot-and-opencode-52f8febd1137](https://jpcaparas.medium.com/stop-using-claudes-api-for-moltbot-and-opencode-52f8febd1137)\n\nThere's also Fireworks, NanoGPT and **obviously** OpenCode Zen.",
              "score": 1,
              "created_utc": "2026-02-19 22:37:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6cscm5",
                  "author": "Jlocke98",
                  "text": "Synthetic has been on wait-list for weeks",
                  "score": 1,
                  "created_utc": "2026-02-20 02:38:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6f1kz9",
                  "author": "philosophical_lens",
                  "text": "Do they have good latency? Iâ€™m currently using GLM / Z.AI subscription and itâ€™s pretty slow.",
                  "score": 1,
                  "created_utc": "2026-02-20 13:21:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6bm3ri",
          "author": "Available_Hornet3538",
          "text": "Yes Chinese models beat American models any day",
          "score": -3,
          "created_utc": "2026-02-19 22:29:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ra1069",
      "title": "Kimi K2.5 is so good that infra is cooked, IMO best open-source model right now",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/ht568ac6lokg1.jpeg",
      "author": "Dilligentslave",
      "created_utc": "2026-02-20 17:04:53",
      "score": 127,
      "num_comments": 22,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1ra1069/kimi_k25_is_so_good_that_infra_is_cooked_imo_best/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6gd1fm",
          "author": "BlacksmithLittle7005",
          "text": "Agreed. I've tried GML5, kimi2.5, minimax, qwen, and kimi2.5 is the only obvious sonnet replacement at such a lower price",
          "score": 23,
          "created_utc": "2026-02-20 17:13:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6hp21y",
              "author": "mintybadgerme",
              "text": "Seconded.Use it every day.",
              "score": 5,
              "created_utc": "2026-02-20 20:59:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6jonaq",
              "author": "toadi",
              "text": "Think I agree. They are sonnet replacements but Opus still rules... I don't need it often but sometimes I use it when I'm on a hard spec...",
              "score": 1,
              "created_utc": "2026-02-21 03:54:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6gwtp9",
          "author": "throwaway12012024",
          "text": "GLM5 replaces Opus. K2.5 replaces Sonnet.",
          "score": 13,
          "created_utc": "2026-02-20 18:44:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6hbpwk",
              "author": "pisangcoklatcheese",
              "text": "Main problem for GLM5 is speeeeeed.",
              "score": 9,
              "created_utc": "2026-02-20 19:54:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6j8g1j",
                  "author": "BrightyBrainiac",
                  "text": "Yes. This.\nItâ€™s like codex.",
                  "score": 1,
                  "created_utc": "2026-02-21 02:09:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6gz7lj",
              "author": "FaerunAtanvar",
              "text": "I am not too familiar with Anthropic s model. Does this mean you'd suggest to use glm5 for planning and k2.5 for building?",
              "score": 4,
              "created_utc": "2026-02-20 18:54:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6hue0a",
              "author": "Loud_Buy_9297",
              "text": "K2.5 plays builder nicely with GPT 5.3 Codex as planner for Python projects, GLM 5 and Minimax 2.5 not so much. I found K2.5 even caught and cleaned up some Codex html/js bugs. Plan to openspec for kimi builder then have codex provide each builder prompt step by step. GLM 5 introduced more bugs so I build with kimi free on zen the last week, great workflow and cheap while codex sub lasts. Horses for courses!",
              "score": 1,
              "created_utc": "2026-02-20 21:26:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6i0l50",
              "author": "Western_Objective209",
              "text": "I keep seeing people say this then I try the models and they are derpy AF",
              "score": 1,
              "created_utc": "2026-02-20 21:57:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6gkffm",
          "author": "Far_Commercial3963",
          "text": "I do not get the hype, it sucks at agentic compared to GLM5 and always failed at tool calls on any serious usage in my experience (in both Opencode and Kilo Code)\n\nIt may be good for chat but I don't think  its usable much in agentic\n\nAlso Kimi k2.5 is not open source, it is open \\*weight\\*. ",
          "score": 12,
          "created_utc": "2026-02-20 17:48:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6guhrz",
              "author": "AGiganticClock",
              "text": "It's good! So is minimax 2.5",
              "score": 3,
              "created_utc": "2026-02-20 18:33:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6guaaq",
              "author": "guillefix",
              "text": "same here, I was trying to fix a positioning issue in my react native app and after 10 tries I had to switch to minimax m2.5 which solved it in one shot",
              "score": 1,
              "created_utc": "2026-02-20 18:32:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6jy2lh",
              "author": "deadcoder0904",
              "text": "Its better for writing at least. Haven't tested it solely for coding.",
              "score": 1,
              "created_utc": "2026-02-21 05:03:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6k56yq",
          "author": "BitterAd6419",
          "text": "Only decent model for open source.",
          "score": 1,
          "created_utc": "2026-02-21 06:00:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gdiug",
          "author": "Michaeli_Starky",
          "text": "It's not open source.",
          "score": -1,
          "created_utc": "2026-02-20 17:16:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6gmwrs",
              "author": "digitalfreshair",
              "text": "open weights",
              "score": 7,
              "created_utc": "2026-02-20 17:59:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6gwd0r",
                  "author": "Michaeli_Starky",
                  "text": "Yes",
                  "score": 2,
                  "created_utc": "2026-02-20 18:41:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6gee5v",
          "author": "Bob5k",
          "text": "well, with 20tps it's close to be unusable at all for anything serious. Even if it's better code quality wise, it'll still lose when it comes to quality of a code > verify > fix > verify > merge loop that can be achieved with faster models. And this loop should happen anyway no matter the model we're using because AI will miss things even if it's opus 4.6 super ultra high genius mode.\n\nedit: ofc unless you're just yolo-oneshotting next awesome saas, but if you do then please sign up for [faultry.com](http://faultry.com) waitlist as it'll be highly useful.",
          "score": -3,
          "created_utc": "2026-02-20 17:20:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ikgbz",
          "author": "lucidbox",
          "text": "I personally love Kimi. For like $300 a year you get access to their CLI, agent swarms, and a clawbot. Not to mention the ability to just give it an image and have a code for you which now Gemini does pretty well with 3.0. I basically use opus for planning, and for workflows that will only hit single files. Iâ€™m able to build lots of code with agents forms in Kimi, which really builds the scaffolding for my projects from a code perspective, and then I throw in Codex to the heavy lifting, and I end with the Gemini CLI using Stich to polish off the UI. Itâ€™s been a pretty good workflow so far.",
          "score": 0,
          "created_utc": "2026-02-20 23:45:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6jpbwb",
              "author": "toadi",
              "text": "Would love that kimi but it seems you can only use a google account to login.",
              "score": 1,
              "created_utc": "2026-02-21 03:59:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6jsuqg",
          "author": "xoStardustt",
          "text": "What is kimi? Never heard of it",
          "score": 0,
          "created_utc": "2026-02-21 04:24:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gj56b",
          "author": "SvenVargHimmel",
          "text": "It's a very eager model and needs strong guidance. Poor in plan mode, great in build. I have tested it yet with Skills and oc bun toolsÂ ",
          "score": -1,
          "created_utc": "2026-02-20 17:42:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9em99",
      "title": "Anthropic legal demanded Opencode Anthropic's OAuth library to be archived",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r9em99/anthropic_legal_demanded_opencode_anthropics/",
      "author": "marquinhoooo",
      "created_utc": "2026-02-19 23:10:14",
      "score": 85,
      "num_comments": 62,
      "upvote_ratio": 0.98,
      "text": "I watch [https://github.com/anomalyco/opencode-anthropic-auth](https://github.com/anomalyco/opencode-anthropic-auth) library and just saw a comment by Dax on a PR that was trying to mimic Claude Code protocol behavior, and Dax closed the PR with the message of [Anthropic's legal demanding the PR to be closed](https://github.com/anomalyco/opencode-anthropic-auth/pull/15#issuecomment-3930558874). Then, the repository was archived.\n\nWhat will happen to Anthropic's support on Opencode? No OAuth anymore?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r9em99/anthropic_legal_demanded_opencode_anthropics/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o6clsev",
          "author": "jmhunter",
          "text": "My ChatGPT 20 buck plan I never hit a wall. Itâ€™s just slow. This is ridic anthropic. I hope they burn",
          "score": 19,
          "created_utc": "2026-02-20 01:58:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6erlun",
              "author": "seaweeduk",
              "text": "Apparently the 20 dollar plan is slower than the 200 because they prioritise requests. I wish they had a 100 dollar option.",
              "score": 2,
              "created_utc": "2026-02-20 12:17:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6h7tw4",
              "author": "drinksbeerdaily",
              "text": "5.3 Codex is plenty fast for me.",
              "score": 2,
              "created_utc": "2026-02-20 19:35:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6dkh4g",
              "author": "xmnstr",
              "text": "Slow? Are you using Codex 5.3?",
              "score": 1,
              "created_utc": "2026-02-20 05:56:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6dkju2",
                  "author": "jmhunter",
                  "text": "Yes or standard 5.2. I have a friend who has the $200 plan and that one seems to move a lot quicker than mine, but it might have just been the session that I watched.",
                  "score": 1,
                  "created_utc": "2026-02-20 05:56:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6iqw5f",
              "author": "Reithaz",
              "text": "It was pretty slow for me on Windows but when I switched to WSL2 it is very good now.",
              "score": 1,
              "created_utc": "2026-02-21 00:22:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6d2i2v",
          "author": "UnicornTooots",
          "text": "Anthropic is getting too far up their own arse. \n\nI've been using OpenAI codex and ollama cloud (for open source models like Kimi2.5). Both are officially supported, have plenty of tokens included in the $20/month tier, and do a great job without fear of being banned.\n\nEdit: Codex also has 2x usage since it's new. I think through March.",
          "score": 13,
          "created_utc": "2026-02-20 03:42:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6bwzv1",
          "author": "cutebluedragongirl",
          "text": "That's why I'd rather pay Chinese AI labs instead of American ones.",
          "score": 58,
          "created_utc": "2026-02-19 23:30:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dke2f",
              "author": "xmnstr",
              "text": "Honestly, Kimi K2.5 is pretty kickass.",
              "score": 23,
              "created_utc": "2026-02-20 05:55:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6eldhx",
                  "author": "Vaviloff",
                  "text": "Yeah, it's amazing. No wonder there's shortage of inference for it, like Dax said on Twitter.",
                  "score": 3,
                  "created_utc": "2026-02-20 11:31:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6dmtok",
                  "author": "jmhunter",
                  "text": "Especially in your own harness",
                  "score": 5,
                  "created_utc": "2026-02-20 06:16:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6clu25",
          "author": "sudoer777_",
          "text": "Meanwhile the propaganda trying to paint Anthropic as ethical is on full throttle",
          "score": 19,
          "created_utc": "2026-02-20 01:58:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6cxjdc",
          "author": "libertea46290",
          "text": "Just cancelled my Pro subscription. Gonna give the money to OpenCode instead.",
          "score": 8,
          "created_utc": "2026-02-20 03:10:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c0mdd",
          "author": "Available_Hornet3538",
          "text": "Yes Chinese models all the way.",
          "score": 14,
          "created_utc": "2026-02-19 23:51:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6cy03k",
              "author": "purpleWheelChair",
              "text": "Superior models and take out.",
              "score": 1,
              "created_utc": "2026-02-20 03:13:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6x4n0c",
                  "author": "Latter-Parsnip-5007",
                  "text": "They are destilled from the american models. Like qwen3-coder would refere to itself as claude. Their models only work cause they capital is spend by the big three",
                  "score": 1,
                  "created_utc": "2026-02-23 08:20:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6chp5r",
          "author": "jreoka1",
          "text": "Anthropic attacks anything they see as competition (even if its not)",
          "score": 5,
          "created_utc": "2026-02-20 01:33:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ccei3",
          "author": "AnlgDgtlInterface",
          "text": "Not only that but there was a commit which may have now been removed:\n\n  \n[https://github.com/anomalyco/opencode/commit/973715f3da1839ef2eba62d4140fe7441d539411](https://github.com/anomalyco/opencode/commit/973715f3da1839ef2eba62d4140fe7441d539411)\n\nWhich affected opencode core.\n\nI now can't find this commit in the main dev branch, so likely a force push remove it from history.  \nClearly things are afoot\n\n\n\nhttps://preview.redd.it/b5gn8qdzsjkg1.png?width=2952&format=png&auto=webp&s=b4cbbb0a406e07be2291304b799527e1853cb6ac\n\n",
          "score": 9,
          "created_utc": "2026-02-20 01:00:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6o9xgj",
              "author": "mightytrashpanda",
              "text": "Yup, they even archived and removed the packages from this repo: [https://github.com/anomalyco/opencode-anthropic-auth](https://github.com/anomalyco/opencode-anthropic-auth)",
              "score": 1,
              "created_utc": "2026-02-21 22:10:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6cc9zc",
          "author": "toadi",
          "text": "While Americans are enshitifying the Chinese are doing awesome work.\n\n\nMy hopenis also thanks to these changes in how we code. Open source will flourish. Would love to see opensouece getting better so I don't need to pay a subscription for every little thing.\n\n\nBut it looks liken I will jot be able to afford the hardware to run it :)",
          "score": 10,
          "created_utc": "2026-02-20 00:59:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c2qlw",
          "author": "bludgeonerV",
          "text": "Ha Anthropic being Anthropic",
          "score": 2,
          "created_utc": "2026-02-20 00:03:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6cfigc",
          "author": "Apprehensive_Half_68",
          "text": "Anthropic is William Shatner finally overhearing fans bad mouthing him.",
          "score": 2,
          "created_utc": "2026-02-20 01:19:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6cle6k",
          "author": "jmhunter",
          "text": "Fuck anthropic. I dropped my sub this month. Theyâ€™ve moved from essential to annoying.",
          "score": 2,
          "created_utc": "2026-02-20 01:55:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6clkmj",
              "author": "jmhunter",
              "text": "I hope China eats their lunch.",
              "score": 1,
              "created_utc": "2026-02-20 01:56:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6dl32s",
                  "author": "xmnstr",
                  "text": "They will, eventually. Anthropic are still relying on scaling only, which means their compute needs will continue to explode. It's not sustainable. And Claude Code is becoming a slow and bloated mess, which makes sense since they're just adding more and more features.",
                  "score": 1,
                  "created_utc": "2026-02-20 06:01:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6d47r8",
          "author": "robberviet",
          "text": "If opencode use same sub packages, same quota as in CC then what is the different? Why block?",
          "score": 2,
          "created_utc": "2026-02-20 03:53:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6eis65",
              "author": "Free-Combination-773",
              "text": "Because allowing it is not asshole enough",
              "score": 2,
              "created_utc": "2026-02-20 11:09:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6ib3ep",
                  "author": "larowin",
                  "text": "No, it's because of breakpoint placement for prefix caching, but no one seems to care about details when they can just be mad instead.",
                  "score": 2,
                  "created_utc": "2026-02-20 22:52:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6df6fu",
          "author": "Icy_Friend_2263",
          "text": "Claude is so good. It's a shame.",
          "score": 2,
          "created_utc": "2026-02-20 05:13:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dop9l",
          "author": "debackerl",
          "text": "Github officially supports opencode, they had a blog post about it. You can also access Claude through GitHub, but not only!",
          "score": 2,
          "created_utc": "2026-02-20 06:32:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6iocaf",
              "author": "Shep_Alderson",
              "text": "Yeah, Iâ€™m thinking my next spike in testing agentic setups is using a mix of Codex 5.3 directly, then loop in Opus via my Copilot sub, and include a bit of Kimi and GLM models as needed.",
              "score": 1,
              "created_utc": "2026-02-21 00:07:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ft7ih",
          "author": "kam1L-",
          "text": "\"Impressive, very nice. Lets see the chinese card.\" I mean its pretty clear Anthropic doesnt want you to use their models outside their ecosystem, but people try anyways just because their product has a reputation and \"it just works\".  You guys swear by Kimi, does it compete with Opus? does it work? ",
          "score": 2,
          "created_utc": "2026-02-20 15:42:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jec8f",
          "author": "jesperordrup",
          "text": "Bye Bye anthropic ...",
          "score": 2,
          "created_utc": "2026-02-21 02:46:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6cxgwx",
          "author": "forgotten_airbender",
          "text": "Gpt 5.2 + kimi + glm 5 are giving me better results that opus could do standalone (plus never running out of limits).Â \nAnthropic are trying to be apple. But their lead is not that good to be able to act like it.Â \nApple genuinely had an amazing product and user experience.Â \n",
          "score": 2,
          "created_utc": "2026-02-20 03:10:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6gjqbh",
              "author": "SvenVargHimmel",
              "text": "I agree we should be moving off anthropic, their models are not that much better when they are for the cost.Â \n\n",
              "score": 1,
              "created_utc": "2026-02-20 17:45:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6cg1ek",
          "author": "Apprehensive_Half_68",
          "text": "We are all devs here. It's in everyone's best interests to work on a feasible solution",
          "score": 1,
          "created_utc": "2026-02-20 01:22:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6bu54s",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-02-19 23:13:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6buak2",
              "author": "kevinherron",
              "text": "No, itâ€™s clear they donâ€™t want you to use your Claude Code subscription with OpenCode (or ANY other agent/TUI that isnâ€™t Claude Code).\n\nAs has been the case since this OAuth drama started, API access is fine.",
              "score": 2,
              "created_utc": "2026-02-19 23:14:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6eqykl",
          "author": "seaweeduk",
          "text": "The plugin will get forked by someone else when anthropic try and block strings in the system prompt again, probably next week. \n\nAll they are doing is losing goodwill and subscriptions from people.",
          "score": 1,
          "created_utc": "2026-02-20 12:13:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f8lo3",
          "author": "ab2377",
          "text": "so anthropic only wants the claude models to be used from interfaces they approve of?",
          "score": 1,
          "created_utc": "2026-02-20 13:59:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hxuil",
          "author": "HarjjotSinghh",
          "text": "this is insanely frustrating actually.",
          "score": 1,
          "created_utc": "2026-02-20 21:43:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u777l",
          "author": "HarjjotSinghh",
          "text": "this is why we're here",
          "score": 1,
          "created_utc": "2026-02-22 20:55:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vvf59",
          "author": "Zealousideal_Pin177",
          "text": "Not saying somebody should do this but if I were to think about how I would cope with a similar situation I would just have claude build a shim/proxy that supports oauth and then may be just point opencode to that.   Ya know, if I were to have to solve that particular problem.   But I am not one to promote people avoiding or working around ToS and usage agreements for other companies.   \n\n",
          "score": 1,
          "created_utc": "2026-02-23 02:31:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6cxpg7",
          "author": "aravhawk",
          "text": "Elon was right: it's Misanthropic",
          "score": 1,
          "created_utc": "2026-02-20 03:11:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6cs0t8",
          "author": "oulu2006",
          "text": "Screw Anthropic - their models are old school now and insanely expensive",
          "score": 1,
          "created_utc": "2026-02-20 02:36:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c25me",
          "author": "NerasKip",
          "text": "fork ?",
          "score": 1,
          "created_utc": "2026-02-20 00:00:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dpllg",
          "author": "Charming_Support726",
          "text": "I am not using Antigravity (and never used CC) anymore, maybe it it helpful for anybody: \n\nOn Github there is a Repo from a Chinese guy one could use for oauth-proxying many providers. You could run it locally or on-prem. \n\n[https://github.com/router-for-me/CLIProxyAPI](https://github.com/router-for-me/CLIProxyAPI)\n\nAFAIK many OAuth library stuff has been borrowed from this Chinese repo.",
          "score": 1,
          "created_utc": "2026-02-20 06:40:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6duni6",
          "author": "ThankYouOle",
          "text": "it is really weird,  \n  \nthey have 2 products: Claude and Claude Code.  \n  \nClaude is their income, people pay subscription or api to use it.  \n  \nClaude Code is free.  \n  \nTheoritically, they can kill Claude Code and it won't affect to their money as user can use opencode or else with keep paying for Claude subscription.  \n  \nBut since this lock-in system, people must use Claude Code to use Claude that basically reduce their income since people who familiar with other tools can't use Claude subscription.   \n  \nSo now it come big question mark, why Anthropic want people use Claude Code even tough it doesn't give revenue and potentially making people don't subscribe Claude.  \n  \nMaybe Claude Code is not free, maybe you are pay them, not with money but with your data, for their training? for selling? not sure, because i don't see any reason why this descision needed.",
          "score": 1,
          "created_utc": "2026-02-20 07:26:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6hy42j",
              "author": "dodistyo",
              "text": "The lack of transparency in proprietary products basically could make them do anything they want for profit.\nI don't know maybe like ramping up the token usage or manipulate the usage to reach the limit quicker at some point without the user knowing it.",
              "score": 1,
              "created_utc": "2026-02-20 21:44:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6eoqo7",
              "author": "InternalFarmer2650",
              "text": "You can opt out of data collection tho, no?",
              "score": 0,
              "created_utc": "2026-02-20 11:57:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6etbi0",
                  "author": "ThankYouOle",
                  "text": "Not sure, didnt use it",
                  "score": 0,
                  "created_utc": "2026-02-20 12:29:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6lip87",
          "author": "Reasonable-Climate66",
          "text": "What's wrong with using the pay as you go API method?ðŸ˜…",
          "score": 1,
          "created_utc": "2026-02-21 13:29:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6bv2g7",
          "author": "HarjjotSinghh",
          "text": "this is why i switched to my own bot.",
          "score": 0,
          "created_utc": "2026-02-19 23:18:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c7hb1",
          "author": "Nearby_Tumbleweed699",
          "text": "Se acabo el soporte de opencode a claude?",
          "score": 0,
          "created_utc": "2026-02-20 00:31:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jt5cy",
          "author": "No-Recognition25",
          "text": "Canâ€™t tell if this is a real thread or if anthropoic just pissed off the miltary and itâ€™s all bots talking â€¦ anthrophic subsidizes their max planâ€¦ so of course they want you to use their api so youâ€™re actually paying if you are not using Claude code. Whatâ€™s hard to understand about that?",
          "score": 0,
          "created_utc": "2026-02-21 04:26:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9nfyf",
      "title": "How would Opencode survive in this era?",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r9nfyf/how_would_opencode_survive_in_this_era/",
      "author": "tksuns12",
      "created_utc": "2026-02-20 06:01:01",
      "score": 71,
      "num_comments": 151,
      "upvote_ratio": 0.84,
      "text": "Claude Code is prohibited and Antigravity is prohibited too for opencode.\n\nBasically, the only subscription available for mass usage from SOTA model makers is OpenAI.\n\nI'm using Open Code a lot but now that I see the situations, I don't know why I use Open Code now.\n\nHow do you guys deal with this situation?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r9nfyf/how_would_opencode_survive_in_this_era/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o6dlk5a",
          "author": "aeroumbria",
          "text": "How does this make Opencode look bad? If anything, I made Anthropic even less appealing than ever...",
          "score": 92,
          "created_utc": "2026-02-20 06:05:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dmccm",
              "author": "tksuns12",
              "text": "But currently Opus 4.6 is known to be the best model and Claude Code is the cheapest way, if you use the model a lot, to use Opus 4.6 for now.",
              "score": -32,
              "created_utc": "2026-02-20 06:12:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6dmk2b",
                  "author": "aeroumbria",
                  "text": "It's been out for like barely a week... How are we even going to know if it is the best or not without people actually using them a bunch? Benchmarks always claim whatever they want... They only thing they can claim now is that Opus is the PRICE leader of the industry...",
                  "score": 23,
                  "created_utc": "2026-02-20 06:13:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6do2j9",
                  "author": "omicron8",
                  "text": "Are you living under a rock? Gemini 3.1 Pro has been out for almost a day. That is the best now. /s Anyhow don't stress too much. Things move fast and competition is good. There are thousands of models available on opencode. If you want to use anthropic models just use claude code. It's not bad. Opencode will survive because you don't need the best model for everything, and best is debatable and changes every day. ",
                  "score": 17,
                  "created_utc": "2026-02-20 06:27:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6duemf",
                  "author": "oulu2006",
                  "text": "Ah no\n\nGPT5.3-codex is as good as.\n\nI use opus 4.6 just via API for planing and review, main workhorse is GLM5 and GPT5.3 \n\nChinese models will be as good as US in 6 months if not sooner - Anthropic is over theyâ€™re a dinosaur",
                  "score": 13,
                  "created_utc": "2026-02-20 07:24:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6ejz5f",
                  "author": "georgiarsov",
                  "text": "Opus 4.6 is ADVERTISED as the best model. This is a huge thing to consider. Big labs have enormous resources that they pour very wisely in benchmarks and influencers a.k.a. the general personâ€™s source of truth for â€œwhich the best model isâ€. They are limiting your scope to all the other top models available which are products of much smaller labs or chinese ones. Just scroll this page to see what i am talking about https://openrouter.ai/models ðŸ˜„ The only real benchmark that one should follow is to try the models for himself and compare their performance on a given task. Thatâ€™s how i found out that Kimi was able to solve a problem i had from the first try and opus couldnâ€™t do it in 4 separate sessions and $20+ in api costs. Try everything and donâ€™t follow the trends blindly",
                  "score": 5,
                  "created_utc": "2026-02-20 11:19:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6j733w",
                  "author": "Ok_Rough5794",
                  "text": "Kimi/OpenCode is good enough for DHH...",
                  "score": 2,
                  "created_utc": "2026-02-21 02:01:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6evsdw",
                  "author": "rayfin",
                  "text": "You're not wrong here, but sometimes you have to say fuck you to the beast.",
                  "score": 1,
                  "created_utc": "2026-02-20 12:46:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6fkpug",
                  "author": "SynapticStreamer",
                  "text": "Opus has been available for like... A week. Calm your tits with the claims that it's the best thing since sliced bread.",
                  "score": 1,
                  "created_utc": "2026-02-20 15:02:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6o0cxt",
                  "author": "SignificanceMurky927",
                  "text": "Have you even tried GPT 5.3 Codex, youâ€™re missing out if you havenâ€™t.",
                  "score": 1,
                  "created_utc": "2026-02-21 21:20:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6pig4y",
                  "author": "Western-Touch-2129",
                  "text": "Lol, have you tried it? I've had the worst hallucinations with opus 4.6. it's like a 12 year old savant that knows everything better and doesn't give a damn about code quality. Sonnet 4.6 seems worse than codex at this point and for design there's always Kimi",
                  "score": 1,
                  "created_utc": "2026-02-22 02:44:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6dtud6",
                  "author": "RainScum6677",
                  "text": "This is simply false, benchmarks and users both indicating so.",
                  "score": 1,
                  "created_utc": "2026-02-20 07:19:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6dlpp1",
          "author": "MrNantir",
          "text": "Github Copilot is officially supported and allowed by Microsoft.\nThrough that you can use the Anthropic models.\n\nI use it everyday with Copilot and OpenAI and never want to go back to Claude Code.",
          "score": 82,
          "created_utc": "2026-02-20 06:06:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dlw3f",
              "author": "oronbz",
              "text": "This is the way",
              "score": 13,
              "created_utc": "2026-02-20 06:08:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6pkja4",
                  "author": "MaxPhoenix_",
                  "text": "This Is The Way",
                  "score": 2,
                  "created_utc": "2026-02-22 02:57:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6do6jd",
              "author": "Charming_Support726",
              "text": "For this reason a got me a GHCP subscription again. Just for using Opus. \n\nOpus is NOT the best model out there. It is brilliant in communications and task understanding, but the resulting code is often inferior in comparision when both models are prompted well. But mostly Opus get shit done. Quick. That's an advantage. Not more.\n\nAnyways, \"Real Developers (TM)\" don't do sloppy one-shots. I neither like the attitude of Anthropic nor the vibe of their products and some of their followers. So GHCP provides me the dose of Opus I need from time to time, without AGY or CC.\n\nYes, changing style of work is a bit annoying, but with DCP and a bit of organizing and structuring (subagents) you can get round this. ",
              "score": 16,
              "created_utc": "2026-02-20 06:27:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6i2who",
                  "author": "vienna_city_skater",
                  "text": "This. Codex often corrects the code Opus writes. But Opus is so incredibly driven, it just tries until it accomplishes something, Codex on the other hand gets needy when itâ€™s stuck, itâ€™s more implementation. I love it as a team, + Gemini Flash for subagentic stuff and small simple tasks. GHCP is just amazing for daily coding work.",
                  "score": 2,
                  "created_utc": "2026-02-20 22:08:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6dpzxl",
                  "author": "tksuns12",
                  "text": "Then how do you use the models depending on the tasks? I agree that Opus is not always best.",
                  "score": -1,
                  "created_utc": "2026-02-20 06:44:10",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6dm4cb",
              "author": "tksuns12",
              "text": "Yeah I'm using it like that too but request based quota doesn't suit my interactive usage. Copilot's limited context window size is bothering too.",
              "score": 5,
              "created_utc": "2026-02-20 06:10:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6e3k73",
                  "author": "CardiologistStock685",
                  "text": "aws bedrock, openrouter work just ok on OC.",
                  "score": 4,
                  "created_utc": "2026-02-20 08:50:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6i4qzg",
                  "author": "vienna_city_skater",
                  "text": "The limited context window is less bad than I thought in the first place. At least Opus tends to use subagents heavily (I default to gemini flash here) and if you go into compaction is usually just continues to work. However, for interactive usage with the expensive models itâ€™s indeed suboptimal. That said, I started to use gpt5 mini with openclaw tuned by Opus to optimize bang for the buck. Oftentimes a smaller cheaper model is good enough if you give it well specified tasks.",
                  "score": 1,
                  "created_utc": "2026-02-20 22:18:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6e10oy",
              "author": "toadi",
              "text": "Same here and in 1 week to 2 weeks I'm through the premium requests. But it is not to bad I think my spending is currently about 200 dollars per month. which is close to a subscription.\n\nI do only use opus for big specs. Smaller specs GLM/Kimi/Sonnet. I create very small incremental tasks for coding so simple models are good enough like qwen/haiku and sometime I even use kimi as it is cheap.\n\nWhile Opus/sonnet are good. If your flow is dialed in the opensource models are good enough for me.",
              "score": 3,
              "created_utc": "2026-02-20 08:25:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6dmsku",
              "author": "klapaucius59",
              "text": "more context would be nice tho. I am curious what is holding them back. Isnt is simple to increase it and make 5x 6x whatever if it's costly.",
              "score": 5,
              "created_utc": "2026-02-20 06:15:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6dohsn",
                  "author": "MrNantir",
                  "text": "Definitely would be nice with larger context.\nHowever at least for me, I've found ways to compensate, making very detailed plans and the splitting the work to individual agents, with a limited and precise work scope.",
                  "score": 4,
                  "created_utc": "2026-02-20 06:30:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6dn5ps",
                  "author": "klapaucius59",
                  "text": "Definitely better product than 30x faster opus",
                  "score": 2,
                  "created_utc": "2026-02-20 06:19:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6do21r",
              "author": "haininhhoang94",
              "text": "I have seen people being ban when using subagents:(, tbh it scared me a little bit",
              "score": 1,
              "created_utc": "2026-02-20 06:26:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6dob6p",
                  "author": "MrNantir",
                  "text": "Seems odd if they have.\nI use copilot heavily each day, with subagents.",
                  "score": 3,
                  "created_utc": "2026-02-20 06:29:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6dx8aw",
              "author": "amunozo1",
              "text": "The problem is that those model are missing context, but it is quite good anyway.",
              "score": 1,
              "created_utc": "2026-02-20 07:50:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6eqzda",
              "author": "robberviet",
              "text": "Correct. Atm GH copilot provide best values. I think moatly because they (ms) have no model of their own, and their tools still quite bad. \nMight change in future after M/A with OpenAI though.",
              "score": 1,
              "created_utc": "2026-02-20 12:13:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6gd57i",
              "author": "Character_Cod8971",
              "text": "Does it work well? Read a lot about high premium request usage if you use Copilot through OpenCode.",
              "score": 1,
              "created_utc": "2026-02-20 17:14:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6glfh6",
              "author": "LemurZA",
              "text": "Oh shit, this is new to me",
              "score": 1,
              "created_utc": "2026-02-20 17:52:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6dv3l7",
          "author": "_w0n",
          "text": "Please do not forget that OpenCode is extremely useful for local LLMs. It also has high value for tinkerers and for professionals at work who are only allowed to use open-source and local tools. It is not always about SOTA models.",
          "score": 33,
          "created_utc": "2026-02-20 07:30:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6e7gk3",
              "author": "franz_see",
              "text": "Curious, whatâ€™s your setup - model, hardware and what tps do you get? Thanks!",
              "score": 5,
              "created_utc": "2026-02-20 09:27:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6fd5pg",
                  "author": "_w0n",
                  "text": "I run an Nvidia A6000 (48 GB) + an Nvidia RTX 3090 Ti (24 GB) with 64 GB DDR4 RAM.  \nI load the full ~69 GB model across both GPUs using llama.cpp with Q6 quantization (Q6_xx / Q6_X). The model is unslothâ€™s Qwenâ€‘3 Coder Next.  \nContext length: 128,000 tokens. Measured throughput: ~80 tokens/sec.",
                  "score": 7,
                  "created_utc": "2026-02-20 14:23:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6eyrjo",
              "author": "sig_kill",
              "text": "I have been having an absolute blast with miniMax, and kimi 2.5. Same with qwen3-coder-next.\n\nTheyâ€™re not the best models, but theyâ€™re fast and good. GLM-5 has been KILLING it for me (though Iâ€™ve been using it through Zen). I canâ€™t afford the GPJ and ram to offload that model though, even a decent quantized version is ~250 gb",
              "score": 2,
              "created_utc": "2026-02-20 13:04:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6gemb2",
                  "author": "Time_Feature_8465",
                  "text": "yes minimax and kimi are amazing (and free) to the point that i have stopped coding.  \nWith 16GB VRAM I could get some local llm result out of a quantized GLM4.7, but not that good and still slow and limited by context size.",
                  "score": 1,
                  "created_utc": "2026-02-20 17:21:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6dl93w",
          "author": "meronggg",
          "text": "Isnt the whole point of opencode is that its open harness, use it with whatever you want.",
          "score": 20,
          "created_utc": "2026-02-20 06:02:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ecfgl",
              "author": "trypnosis",
              "text": "Opencode will work with any sub. The issue if the sub will penalise you for it.",
              "score": 4,
              "created_utc": "2026-02-20 10:13:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6foles",
                  "author": "aries1980",
                  "text": "Then sub will decline and other model operators will increase their market share.",
                  "score": 2,
                  "created_utc": "2026-02-20 15:21:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6fu1hv",
                  "author": "xmnstr",
                  "text": "Well, the only two who do (Google and Anthropic) can be accessed via Github Copilot Pro, so there isn't really any limitation.",
                  "score": 1,
                  "created_utc": "2026-02-20 15:46:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6dm7qb",
              "author": "tksuns12",
              "text": "The thing is technically you can use whatever model you want but not whatever subscription you want. Money stuff is very important",
              "score": -3,
              "created_utc": "2026-02-20 06:10:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6dxqxi",
                  "author": "Big_Bed_7240",
                  "text": "Money stuff",
                  "score": 3,
                  "created_utc": "2026-02-20 07:55:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6eezht",
                  "author": "tens919382",
                  "text": "Its the subscriptions that dont allow opencode, not the other way round though?",
                  "score": 3,
                  "created_utc": "2026-02-20 10:36:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6dnxsk",
          "author": "PutinIsASheethole",
          "text": "Opencode + AWS bedrock. It has loads of models including opus 4.6, Let work pay for the tokens",
          "score": 11,
          "created_utc": "2026-02-20 06:25:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fp5h2",
              "author": "aries1980",
              "text": "So does Azure and GCP. There are ton of generic providers who offer Anthropic models.",
              "score": 1,
              "created_utc": "2026-02-20 15:23:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6do4q3",
          "author": "devdnn",
          "text": "In this ever changing models, I would like always like put a common tool in front of those models.\n\nPerhaps thatâ€™s why I enjoy Copilot so much, despite its limited context window, even more why I like opencode because of its ability to support multiple models from various sources.\n\nIf anything this whole thing is making Anthropic a sore winner.",
          "score": 9,
          "created_utc": "2026-02-20 06:27:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dprcb",
              "author": "tksuns12",
              "text": "That's why I stay with OC..",
              "score": 5,
              "created_utc": "2026-02-20 06:42:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6e0z4j",
          "author": "alovoids",
          "text": "opencode is preparing for google integration, can't wait when i can use my google ai subs in opencode officially!",
          "score": 8,
          "created_utc": "2026-02-20 08:25:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6pl5f5",
              "author": "MaxPhoenix_",
              "text": "Well, somebody at Google better get to work unbanning our accounts. Those of us with paid Google Pro AI or higher accounts that were using open code and got blocked. AND With no warning and no notification that we were blocked. Just shadow banned.",
              "score": 1,
              "created_utc": "2026-02-22 03:01:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6dr7c4",
          "author": "segmond",
          "text": "the more you send your money on Anthropic they more they get bold and greedy to do stuff like this.  Cancel your Claude subscription.  Use KimiK2.5, Qwen3.5, GLM5, MiniMax2.5, etc. You have options.",
          "score": 23,
          "created_utc": "2026-02-20 06:54:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f3pea",
              "author": "spartanOrk",
              "text": "I generally do that but in the end Claude fixes the mess. \n\nThere is noticeable quality difference.",
              "score": 2,
              "created_utc": "2026-02-20 13:33:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6g3gnc",
                  "author": "Codemonkeyzz",
                  "text": "Codex is far better. 20 USD codex + 8 USD nanogpt  enough for me. I have 10 USD copilot backup. I get the same value as 100 USD Anthropic plan. Only downside is to set it up. E.g ; setup providers, skills , agents model matching..etc. which takes roughly one hour. \n\nUse codex to plan , Chinese models to execute the plan. If your plan is good and detailed ( If you have good Agents.md) , it all works perfectly",
                  "score": 4,
                  "created_utc": "2026-02-20 16:30:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ewua4",
          "author": "el-guille",
          "text": "I use openrouter, kimi, minimax, gptoss, etc",
          "score": 4,
          "created_utc": "2026-02-20 12:52:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dua7k",
          "author": "BKite",
          "text": "Omg you guys are so gaslighted by the marketing. Heavy user of GPT 5.2 codex. Have to say Iâ€™m not impressed with Opus 4.6 it is on par with GPT. So itâ€™s great but not game changing and it eats your quota in like 5 prompts. How are people getting things done with this. I fell like you have at least 30x the quota with codex.",
          "score": 5,
          "created_utc": "2026-02-20 07:23:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fzqwf",
              "author": "LtCommanderDatum",
              "text": "Agreed. Opus has been great for a lot of things, but it recently got stuck on a fairly simple Node.js coding problem. After a day of no progress, I switched back to GPT 5.3 and it solved the problem in a couple minutes.\n\nCan't tell if that was just Opus getting stuck on some jagged frontier shortcoming, or GPT caught up and passed Opus again.",
              "score": 1,
              "created_utc": "2026-02-20 16:13:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o74yr6t",
                  "author": "Worldly-Divide-1385",
                  "text": "Codex caught up, the edge is getting smaller. \n\nAlso, codex follows the [AGENTS.md](http://AGENTS.md) properly, as where claude goes off the rails too often. \n\nI must say codex is something a little dumber at understand what you want, so you might have to explicitly tell it what to do and not to do, where-as Claude will often make assumptions that 80/20 are what I want.",
                  "score": 1,
                  "created_utc": "2026-02-24 14:05:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6dny6d",
          "author": "ThankYouOle",
          "text": "eh, the only problem here is the one with Claude subscription. \n\nall other models including premium, or 3rd party provider, or even self host can keep using it no issue. ",
          "score": 3,
          "created_utc": "2026-02-20 06:25:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dq4cp",
              "author": "tksuns12",
              "text": "Using Antigravity credential in OC would ban your account man.",
              "score": 1,
              "created_utc": "2026-02-20 06:45:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6drevt",
                  "author": "ThankYouOle",
                  "text": "look, my point is AI provider not just claude and antigravity.\n\nif anything, i will stay away from provider who lock-in their customer. ",
                  "score": 2,
                  "created_utc": "2026-02-20 06:56:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6dqiu7",
          "author": "BuildAISkills",
          "text": "If you just want to use Claude, why not just use Claude Code?Â \n\nI use Codex for ChatGPT even though itâ€™s available in OpenCode.Â \n\nOpenCode has tons of other models for you to play with. For me itâ€™s my open weight go to.\n",
          "score": 3,
          "created_utc": "2026-02-20 06:48:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dwe76",
              "author": "aeroumbria",
              "text": "It kinda sucks to have a project with:\n\n    .roo\n    .cline\n    .claude\n    .opencode\n    AGENTS.md\n    CLAUDE.md\n    GEMINI.md\n\nI can run a script to symlink them, but it still sucks that someone has to intentionally invent incompatible ways to do things...",
              "score": 7,
              "created_utc": "2026-02-20 07:42:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6eb3sv",
                  "author": "tenebreoscure",
                  "text": "No need to symlink, keep everything in [AGENTS.md](http://AGENTS.md) and in the others add a link like  \n  \n`See [](AGENTS.md)`\n\nAs long as the links are working the agent will navigate and use them, that's how I keep everything compatible with multiple agents and avoid repetitions.",
                  "score": 5,
                  "created_utc": "2026-02-20 10:01:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6e4ol4",
                  "author": "Grouchy-Bed-7942",
                  "text": "Opencode supports Claude code files right?",
                  "score": 2,
                  "created_utc": "2026-02-20 09:00:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6ea3t5",
                  "author": "KnifeFed",
                  "text": "What do you use that doesn't support AGENTS.md?",
                  "score": 1,
                  "created_utc": "2026-02-20 09:52:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6e2lxx",
              "author": "bzBetty",
              "text": "because opencode desktop is far more convienient when you're working on a lot of projects",
              "score": 1,
              "created_utc": "2026-02-20 08:41:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6hxcpi",
                  "author": "antonlvovych",
                  "text": "Try Superset",
                  "score": 1,
                  "created_utc": "2026-02-20 21:40:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6e4ujn",
          "author": "schlammsuhler",
          "text": "There also kimi code plan, glm and minimax. And opencode has its own plan.",
          "score": 3,
          "created_utc": "2026-02-20 09:02:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f0ugb",
          "author": "alexzim",
          "text": "I personally use it because I want Chinese models like Kimi K2.5 and canâ€™t be bothered with Claude Code Router.",
          "score": 3,
          "created_utc": "2026-02-20 13:17:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6goyhp",
          "author": "Tobibobi",
          "text": "Github Copilot is a VERY good product. With that you can authorize opencode and use Anthropic models (as well as OpenAI) just fine. The context window is smaller, but I very rarely encounter issues with this.",
          "score": 3,
          "created_utc": "2026-02-20 18:08:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dy4y2",
          "author": "NickeyGod",
          "text": "Opensource modals are catching up. Why use a 200$ Subscription a month when i can have it all with Opencode for 20$ a month ?",
          "score": 4,
          "created_utc": "2026-02-20 07:58:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f011q",
              "author": "sig_kill",
              "text": "Or even self-host, and supplement with your free usage from all providers for big important things.\n\nYou donâ€™t always need to drive the car at 120 km/h",
              "score": 2,
              "created_utc": "2026-02-20 13:12:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6feih5",
                  "author": "NickeyGod",
                  "text": "I self host only like really small models we talking 7b and embeddings. Those are doing quite well i don't actually need external interference for those",
                  "score": 1,
                  "created_utc": "2026-02-20 14:30:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6fezc7",
                  "author": "NickeyGod",
                  "text": "Currently opencode with oh-my-opencode with kimi-k2.5 + minimax 2.5 is doin a really good job i cant self host such big models on my own hardware.",
                  "score": 1,
                  "created_utc": "2026-02-20 14:33:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6dnc0r",
          "author": "jpcaparas",
          "text": "Huh? Models-as-a-service is the future. ",
          "score": 2,
          "created_utc": "2026-02-20 06:20:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ej49m",
          "author": "debackerl",
          "text": "I don't agree you can create API Keys for Google AI Studio (https://aistudio.google.com/app/api-keys), and Ollama Cloud (GLM, Qwen, etc). There is also GitLab Duo support, but maybe more for enterprises.\n\nIn an industry where new models come up all the time. I don't want to commit to a mono-provider harness. I want one harness using multiple providers.\n\nEdit: it seems like the API Keys are pay as you go, but you get some credits with your subscription.",
          "score": 2,
          "created_utc": "2026-02-20 11:12:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ejhdd",
          "author": "ganonfirehouse420",
          "text": "Glm-5 is good enough for me. Also it isn't expensive!",
          "score": 2,
          "created_utc": "2026-02-20 11:15:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f6vq1",
          "author": "dannyt74",
          "text": "Runs very well with GitHub CoPilot. Which is even a quite cheap option. Also can use with Ollama and others.",
          "score": 2,
          "created_utc": "2026-02-20 13:50:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f6zs3",
              "author": "dannyt74",
              "text": "Actually, it I mostly use Opus and Sonnet through GitHub with it all the time.",
              "score": 1,
              "created_utc": "2026-02-20 13:51:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6fzhqn",
          "author": "mcowger",
          "text": "Codex is supported and works great.  So is GHCP. Lots of excellent open models out there too for cheap.",
          "score": 2,
          "created_utc": "2026-02-20 16:12:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dlfcn",
          "author": "HarjjotSinghh",
          "text": "this era's magic trick: open code as my new favorite escape hatch",
          "score": 2,
          "created_utc": "2026-02-20 06:04:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f0anp",
              "author": "sig_kill",
              "text": "Itâ€™s quickly become my favourite too. \n\nStarted with cursor, tried out the rest, went back to cursor, bounce into codex from time to timeâ€¦ But always end up back with opencode",
              "score": 0,
              "created_utc": "2026-02-20 13:13:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6dq7zr",
          "author": "Zeroox1337",
          "text": "So you pay for API access and Anthropic bans you if you use API from other Products then theirs, or is it for the subscription based plan?",
          "score": 1,
          "created_utc": "2026-02-20 06:46:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6e5gyl",
              "author": "danmaz74",
              "text": "You can use the pay-per-use API just fine, but it's very expensive compared to the subscription you can use in Claude Code.",
              "score": 1,
              "created_utc": "2026-02-20 09:08:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6e8g6q",
                  "author": "StrikingSpeed8759",
                  "text": "I still dont understand the whole scope. Right now I got opencode with my Claude sub working fine, am I risking getting banned? I dont have it in the opencode zen but rather directly through opencode auth",
                  "score": 1,
                  "created_utc": "2026-02-20 09:36:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6dqtps",
          "author": "Astorax",
          "text": "We focus on Opencode with AWS Bedrock for Claude models at work.\n\nAt home it's just too expensive and I feel your pain. It feels like I'm stuck with Claude Code and my anthropic subscription. I've tried using Gemini, Mistral, openai and groq via Apis through my litellm instance (I've setup for my n8n) but the pure API costs escalate quickly ðŸ«£\n\nTried focusing on using Gemini 3 flash for build mode and some different models for the plan mode but I really like my sonnet 4.5 when getting shit done. ðŸ« \n\nAlways open for recommendations... But the llm providers shouldn't train on my data... (:\n\nHelp me before I upgrade to the anthropic max plan ðŸ˜¬ðŸ˜¬",
          "score": 1,
          "created_utc": "2026-02-20 06:51:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dsjgo",
          "author": "AGiganticClock",
          "text": "Copilot is good no?",
          "score": 1,
          "created_utc": "2026-02-20 07:07:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6duair",
          "author": "0sko59fds24",
          "text": "Its the perfect copilot & codex harness",
          "score": 1,
          "created_utc": "2026-02-20 07:23:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dxut0",
          "author": "FreeEye5",
          "text": "I use open code and a multi llm agent workflow, pans put great for me. Codex5.3 orchestrates, plans, f then sends to Opus for a plan review and an agent flow that prioritises max parallel agents, then hands back to codex who then deploys free agents like kimi and minimax to complete tasks, code review, ux ui review.",
          "score": 1,
          "created_utc": "2026-02-20 07:56:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dy4qv",
          "author": "Civil_Baseball7843",
          "text": "when opensource models catch up then opencode will be the best. Actually opencode+glm5 feels 80% of cc now. Lest see if deepseek will bring more superis.",
          "score": 1,
          "created_utc": "2026-02-20 07:58:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e06ee",
          "author": "jmhunter",
          "text": "ya i wouldnt blame opencode... opencode is the way.... zen/kimi is the way id like to move once theres enough compute\n\n",
          "score": 1,
          "created_utc": "2026-02-20 08:18:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f0lma",
              "author": "sig_kill",
              "text": "GLM-5 has been great as well",
              "score": 1,
              "created_utc": "2026-02-20 13:15:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6e2odg",
          "author": "bzBetty",
          "text": "i mean, opencode supports plugins for auth...",
          "score": 1,
          "created_utc": "2026-02-20 08:41:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e78u7",
          "author": "franz_see",
          "text": "Been a big fan of Anthropic models for awhile now. But I find the latest SOTA models to be practically at par with each other\n\nHowever, the i feel like the gap in agentic capabilities are becoming wider and wider. \n\nRight now, i feel like Anthropic is forcing me to switch to opencode + gpt models. I get all the goodies of opencode with practically on par SOTA model",
          "score": 1,
          "created_utc": "2026-02-20 09:25:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ecgmv",
          "author": "hlacik",
          "text": "you can use subscription based services like [Z.AI](http://Z.AI) (provides GLM5) or Kimi Kode (provides KIMI K2.5) and there is plenty services like this",
          "score": 1,
          "created_utc": "2026-02-20 10:13:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ejj5n",
          "author": "georgiarsov",
          "text": "Try exploring open weight models through openrouter or opencode zen. They are magnitudes cheaper and offer the same performance from what I have seen in my projects. Leading models for agentic workflows now are kimi k2.5 and glm-5 for example",
          "score": 1,
          "created_utc": "2026-02-20 11:16:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ejtvq",
          "author": "jesperordrup",
          "text": "I'm using Opencode with anthropic 5*max every day?",
          "score": 1,
          "created_utc": "2026-02-20 11:18:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6whi8t",
              "author": "SnooRecipes5458",
              "text": "using it with max20 everyday",
              "score": 1,
              "created_utc": "2026-02-23 04:58:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6epgyd",
          "author": "atkr",
          "text": "skill issue",
          "score": 1,
          "created_utc": "2026-02-20 12:02:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6eqjje",
          "author": "seaweeduk",
          "text": "Claude code still works fine and when anthropic attempt to block it at the system prompt level again someone will just make another workaround and fork the plugin. \n\nThat said I'm cancelling my sub because I don't want to support anthropic anyway and codex is a better model.",
          "score": 1,
          "created_utc": "2026-02-20 12:10:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f3986",
          "author": "bruor",
          "text": "At work I have opencode wired to Claude models via Azure AI Foundry.  Been waiting 3 weeks for them to allow access to GPT models.  He is looking at GitHub copilot Enterprise instead. \n\nFor personal stuff I'm using Opencode Zen, at the moment.",
          "score": 1,
          "created_utc": "2026-02-20 13:30:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f5p5f",
          "author": "renan_william",
          "text": "[z.ai](http://z.ai)  / GLM5",
          "score": 1,
          "created_utc": "2026-02-20 13:44:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6flyij",
          "author": "Bob5k",
          "text": "just grab some reliable subscription service and connect it to opencode. Have in mind opencode is opensource software, so it's not built on it's own to bring revenue straight away.   \nI'm using minimax m2.5 highspeed personally since it was released and can't be happer as opencode with it is flying. (and they still have the nice[ 10% discount available](https://platform.minimax.io/subscribe/coding-plan?code=HO46LCwAJ5&source=link)).",
          "score": 1,
          "created_utc": "2026-02-20 15:08:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fp7qc",
          "author": "revilo-1988",
          "text": "Ich nutze locallen llms mit Open Code",
          "score": 1,
          "created_utc": "2026-02-20 15:23:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6g2txx",
          "author": "MakesNotSense",
          "text": "I would sooner deal with the limitations of open-source Chinese models than the limitations of a closed harness.\n\nThere is too much that simply cannot be done in Claude Code and other platforms purely because users cannot develop the harness to do what is needed.\n\nA Harness that users cannot use to improve and fix the Harness cripples the users work capacity in the long-term.\n\nMore and more, I'm beginning to wonder if the Chinese are really the bad guys Anthropic and others try to paint them as.\n\nI'm disabled and need AI to help me perform complex civil rights litigation. Without that litigaiton, my human rights will continue to be violated. I'm currently dependent on Claude in Opencode for my agentic workflow. I live in fear that one day Anthropic will make Claude no longer work at all in OpenCode. What then? Kimi 2.5 I guess.\n\nWill I, as an America citizen, have to use Chinese AI to protect my civil and constitutional rights because Anthropic won't provide an effective, equitable, and dependable way for me to use Claude?\n\nThe reason I need OpenCode isn't out of preference, but necessity; no platform was providing the features I needed, so I must build it myself. I have to build my tools, and do my own litigation. It's a societal-wide failure; I need AI because no one is helping people like me with these legal or development problems.\n\nI think of my situation - between my mental and physical disabilities, the hardship of the rights violations, imposed poverty, and general abandonment by the legal community and nonprofits -  like I'm having to build a sand castle in the middle of a hurricane, while other people build on a sunny-day beach. Then people go out of their way to make it even harder for me to build, or try to destroy what I've built.\n\nI don't fear misaligned AI. I fear misaligned people.\n\nI really like and enjoy Claude, but I fear Anthropic is going to make Claude inaccessible to me; they seem intent on preventing users like me from having equitable, effective access to Claude in OpenCode. While showing no interest or intent to develop the features my workflow needs in Claude Code or CoWork.\n\nMeanwhile, an open-source model will always be accessible, even if less performant.\n\nThe world would be such a better place if entities like Anthropic would help people like me, instead of create friction and more problems.  It's nice to have AI agents that help me, but now the company who owns that AI is working to prevent Claude from being helpful to me.\n\nThe more I try to do my work, the more I end up documenting how totally screwed up everything is.\n\nThere's a lot more to consider than just price and performance when picking which AI you use.\n\nMy life-long severe disability makes me especially mindful of what I am dependent upon. If I don't have specific things, I get injured, badly.\n\nI've become dependent upon Claude, and any day now, it could just be gone. The fear of that day weighs heavily on me. I find it very disturbing that my safety and human rights are not being better served by U.S. AI companies.\n\nHow will OpenCode survive? By being one of a scarce few places where people like me can build a future our survival can depend on.",
          "score": 1,
          "created_utc": "2026-02-20 16:27:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gcci1",
          "author": "HikariWS",
          "text": "u gotta pay by token",
          "score": 1,
          "created_utc": "2026-02-20 17:10:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gzvdb",
          "author": "Delicious_Ease2595",
          "text": "Just use Claude Code, the point of OpenCode is to use any llm",
          "score": 1,
          "created_utc": "2026-02-20 18:57:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gzwil",
          "author": "Affectionate-Job8651",
          "text": "just use api key",
          "score": 1,
          "created_utc": "2026-02-20 18:57:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hnyr4",
          "author": "IceManMinus0ne",
          "text": "you can still use openrouter. Barely costs a thing with the right models. ",
          "score": 1,
          "created_utc": "2026-02-20 20:54:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6iax5l",
          "author": "Existing-Wallaby-444",
          "text": "Opencode is open source. Just modify it to look like a Claude code client and you are good to go",
          "score": 1,
          "created_utc": "2026-02-20 22:51:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6imxq9",
          "author": "ZealousidealShoe7998",
          "text": "opencode whole point is to use open source model. if anything is achieving what is meant to .",
          "score": 1,
          "created_utc": "2026-02-20 23:59:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jihb7",
          "author": "c0nfluks",
          "text": "You can use opencode inside antigravity without any issue. Itâ€™s an extensionâ€¦",
          "score": 1,
          "created_utc": "2026-02-21 03:13:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6k2bag",
          "author": "Big-Balance-6426",
          "text": "I use it with OpenRouter. ",
          "score": 1,
          "created_utc": "2026-02-21 05:36:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kh807",
          "author": "redstarling-support",
          "text": "I use open code with z.ai. I use codex with my openai plan. Both are great pairings. I ditched Claude 5 months ago and haven't missed it.",
          "score": 1,
          "created_utc": "2026-02-21 07:51:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lj1fj",
          "author": "Reasonable-Climate66",
          "text": "It's 2026 now, use pay as you go API method boys.",
          "score": 1,
          "created_utc": "2026-02-21 13:31:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qgjr2",
          "author": "Uzeii",
          "text": "Arenâ€™t they byok?",
          "score": 1,
          "created_utc": "2026-02-22 07:05:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qoyiq",
          "author": "ziphnor",
          "text": "You can access both Gemini 3.1 pro and opus 4.6 though GitHub Copilot in opencode.",
          "score": 1,
          "created_utc": "2026-02-22 08:25:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6txmzq",
          "author": "BudgetComplaint",
          "text": "It's worth mentioning that all of these subscription plans are heavily subsidized and in the next 1 or 2 years they're going to be less and less worth the money.\n\nPersonally, I don't want to be stuck with a tool that is going to cost so much and is much less versatile, just because they arguably have the best weights nowadays. Not to mention, even a 10% difference in output doesn't really matter that much for skilled engineers executing well-defined workflows.",
          "score": 1,
          "created_utc": "2026-02-22 20:06:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6wf1oz",
          "author": "SnooRecipes5458",
          "text": "OpenCode is working out of the box with Claude Max 20",
          "score": 1,
          "created_utc": "2026-02-23 04:40:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6x62gu",
          "author": "seymores",
          "text": "I just started to pay for MiniMax and so far my result is good and fast, and did not make me miss Codex nor Claude.",
          "score": 1,
          "created_utc": "2026-02-23 08:34:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xp7ar",
          "author": "Ashrak_22",
          "text": "Just use Github Copilot, you get quite a bit of usage on all the different frontier models.",
          "score": 1,
          "created_utc": "2026-02-23 11:36:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dnz9g",
          "author": "dengar69",
          "text": "GitHub Copilot and NanoGPT is the way to go.",
          "score": 1,
          "created_utc": "2026-02-20 06:26:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6elhyv",
              "author": "Cyrecok",
              "text": "Why nanogpt?",
              "score": 2,
              "created_utc": "2026-02-20 11:32:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6fb1nx",
                  "author": "dengar69",
                  "text": "Access to all of the open source models including Kimi 2.5 which is very close to Opus on paper.",
                  "score": 1,
                  "created_utc": "2026-02-20 14:12:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6k5qlr",
              "author": "No-Profession-734",
              "text": "Not sure bout the nanogpt, but I use copilot with OC and it's decent. The context windows are small tho, so you need to do a little bit of ctx engineering.",
              "score": 1,
              "created_utc": "2026-02-21 06:05:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6e7bvd",
          "author": "charmander_cha",
          "text": "Grande bosta esses modelos, continuarei usando o kimi",
          "score": 0,
          "created_utc": "2026-02-20 09:26:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6k3ipv",
          "author": "Just_Lingonberry_352",
          "text": "opencode users are getting hit so hard with bans comes down to how it accesses compute. Under the hood, Opencode hooks into your $20/mo consumer web subscriptions (like claude or anti) by spoofing direct oaut tokens and reverse-engineering private api providers like anthropic and Google crack down on this because those flaetrate tiers are priced as loss-leaders for normal human chatting, not for heavy-duty, automated CLI agent loops that burn through massive amounts of compute. Once they update their fingerprinting and catch unofficial requests pretending to be their native clients, they instantly ban the accounts for ToS violations.\n\nThis is exactly why I wrote [this](https://github.com/agentify-sh/desktop) mcp bridge for claude, codex, opencode instead of spoofing API tokens, it uses local browser automation to literally log into the actual web UI, type out the prompts, click send, and scrape the response back to your terminal. It bypasses API restrictions by essentially puppeteering a real browser session (Electron with a normal user agent but you might wanna customize that to be safe). \n\nHowever, even with that tool you still need to recognize the risks. Itâ€™s not a bulletproof shield providers are constantly upgrading their behavioral analytics. If your account is blasting out complex prompts 24/7 at superhuman speeds, you can still trigger CAPTCHAs, get heavily rate-limited, or eventually face a ban for botting. \n\nby default it types slowly and hits send button and prevents unintentional mass prompt automation but up to you to determine what level you are comfortable with I take no responsibility.\n\nmy original motivation for writing that bridge was so i can use chatgpt pro from codex cli without copy and pasting but i've expanded it so you can use any web sessions from not only gemini or claude or chatgpt but grok and perplexity as well",
          "score": 0,
          "created_utc": "2026-02-21 05:46:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fygl4",
          "author": "LtCommanderDatum",
          "text": "People like OpenCode's UI? I think it's borderline unusable. The only reason I'd ever use OpenCode is for local LLMs (which it does well). Nothing else.",
          "score": -1,
          "created_utc": "2026-02-20 16:07:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rac56z",
      "title": "I made a little CLI tool to check for available Nvidia NIM Free coding LLM models",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/s5ib33h2pqkg1.gif",
      "author": "AgeFirm4024",
      "created_utc": "2026-02-21 00:10:16",
      "score": 65,
      "num_comments": 27,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1rac56z/i_made_a_little_cli_tool_to_check_for_available/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6krcuv",
          "author": "sorvendral",
          "text": "You filmed that with you oven?",
          "score": 10,
          "created_utc": "2026-02-21 09:31:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6l0zkk",
              "author": "AgeFirm4024",
              "text": "Absolutely ! ðŸ˜‚ i have to update that gif itâ€™s horrible i must admit.",
              "score": 3,
              "created_utc": "2026-02-21 11:05:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o75l1bw",
                  "author": "oVerde",
                  "text": "Actually at first I thought this was a CRT/Matrix kind of filter for opencode",
                  "score": 1,
                  "created_utc": "2026-02-24 15:54:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6k4i59",
          "author": "BuildAISkills",
          "text": "Now this is actually useful. ThanksÂ ",
          "score": 3,
          "created_utc": "2026-02-21 05:55:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jdkpr",
          "author": "planetearth80",
          "text": "Doesnâ€™t nvidia provide one-time allocation of free API credits (typically 1,000 credits initially). Trying to understand where are the free coding models",
          "score": 2,
          "created_utc": "2026-02-21 02:41:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6jfiry",
              "author": "AgeFirm4024",
              "text": "NVIDIA phased out fixed API credits (like the old 1,000 initial ones) early 2025 for NIM API Catalog itâ€™s now rate-limit based for free eval/prototyping (40 RPM per model, varies by load).\n\nSo, that's why I made that tool, most big models are down due to over use i guess, but it's free and without credits limits, i guess ! from my understanding. Correct me if i'm wrong",
              "score": 4,
              "created_utc": "2026-02-21 02:54:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6l8e7j",
          "author": "labdoe",
          "text": "Nice, it would be useful if the llms are sorted based on avg latency within each tier.",
          "score": 2,
          "created_utc": "2026-02-21 12:12:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6n1pdn",
              "author": "AgeFirm4024",
              "text": "ok, i'll do that :) ",
              "score": 2,
              "created_utc": "2026-02-21 18:21:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ipgqr",
          "author": "HarjjotSinghh",
          "text": "this is genius - nvidia just gave us free llms!",
          "score": 2,
          "created_utc": "2026-02-21 00:14:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jccf7",
          "author": "crmfan",
          "text": "What stack made the app, very nice!",
          "score": 1,
          "created_utc": "2026-02-21 02:34:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6jfn6l",
              "author": "AgeFirm4024",
              "text": "I made the CLI tool with claude code, and finished it with free GLM5 from nvidia NIM haha :) thanks !",
              "score": 1,
              "created_utc": "2026-02-21 02:54:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6kpymm",
          "author": "Embarrassed_Bread_16",
          "text": "now i would add litellm proxy for automatically choosing best available model",
          "score": 1,
          "created_utc": "2026-02-21 09:17:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6l4v09",
              "author": "AgeFirm4024",
              "text": "Planned in an update",
              "score": 4,
              "created_utc": "2026-02-21 11:41:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6lcxo0",
                  "author": "Embarrassed_Bread_16",
                  "text": "very cool",
                  "score": 2,
                  "created_utc": "2026-02-21 12:48:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6muh4y",
          "author": "x8code",
          "text": "Perfect use case for a monitoring TUI. Excellent work",
          "score": 1,
          "created_utc": "2026-02-21 17:46:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6n1pze",
              "author": "AgeFirm4024",
              "text": "thanks !",
              "score": 1,
              "created_utc": "2026-02-21 18:21:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ofgr7",
          "author": "AgeFirm4024",
          "text": "**UPDATE : i just renamed it to \"free-coding-models\"**  \n**and I updated it to a new version with sorting, much better TUI, and automatic opencode config, the new repo is**Â [**https://github.com/vava-nessa/free-coding-models**](https://github.com/vava-nessa/free-coding-models)\n\n`npm i -g free-coding-models`",
          "score": 1,
          "created_utc": "2026-02-21 22:41:41",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o6qiylq",
          "author": "HarjjotSinghh",
          "text": "this is unreasonably cool actually.",
          "score": 1,
          "created_utc": "2026-02-22 07:28:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6v16yq",
          "author": "HarjjotSinghh",
          "text": "this nvidia nim tool is gonna be the hype.",
          "score": 1,
          "created_utc": "2026-02-22 23:33:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6v9mll",
          "author": "Big-Masterpiece-9581",
          "text": "So has everyone else evidently",
          "score": 1,
          "created_utc": "2026-02-23 00:21:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6mem8e",
          "author": "aeonixx",
          "text": "I tried to configure this in OpenCode, but I'm not getting a response. Am I doing something wrong? I got the API key from build.nvidia.com, and inserted it into the Nvidia provider in OpenCode. But nothing.",
          "score": 0,
          "created_utc": "2026-02-21 16:26:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6n1txq",
              "author": "AgeFirm4024",
              "text": "hmm, I'll release a big update that will install it automatically, i'll let you know when it's out !",
              "score": 2,
              "created_utc": "2026-02-21 18:22:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6odo43",
                  "author": "aeonixx",
                  "text": "Thank you! I'll keep an eye out for it",
                  "score": 1,
                  "created_utc": "2026-02-21 22:31:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rba64a",
      "title": "Best bang for your bucks plan?",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1rba64a/best_bang_for_your_bucks_plan/",
      "author": "CantFindMaP0rn",
      "created_utc": "2026-02-22 02:41:38",
      "score": 60,
      "num_comments": 50,
      "upvote_ratio": 0.94,
      "text": "From my research so far, this is what I've gathered:\n\n1. Github Copilot's $40 plan -> Codex/Opus/Sonnet, but metered per request instead of per token (~~can try to saturate context window for maximum value~~ Don't think you need to try for Claude models when it's 128k already lmao)\n2. Codex -> It's free right now, but not sure if $20 per month is worth it\n3. Kimi 2.5 -> Workhorse?\n4. MiniMax/GLM -> Even dumber workhorses that can serve as subagents?\n5. Zen -> Pay per API calls is pretty pricey, but can help in a pinch\n\nNot counting Antigravity due to reportedly very low limits\n\nPS. I'm keeping my Claude 5x Max plan for when I need to one shot stuff at work/detailed planning.\n\nEdit: Got all your comments into a nice summary here, courtesy of Claude Sonnet lol. Hope it proves useful for those who might be wondering the same thing (since the agantic AI landscape shifts so effing fast)\n\n# Plan Ranking (as of Feb 22, 2026)\n\n|Rank|Plan|Mentions|Sentiment|Key Signal|\n|:-|:-|:-|:-|:-|\n|1|Opencode Black/Zen|5|âœ… Positive|Best value; multi-model; cheap entry|\n|2|Codex Plan|4|âœ… Strongly Positive|\"The best\"; 272K context; top performance|\n|3|Alibaba Cloud (Qwen)|2|âœ… Positive|$5-10/mo; relaxed quotas; multi-model|\n|4|[Chutes.ai](http://Chutes.ai)|5|âš ï¸ Mixed+|Cheap; unreliable for real-time use|\n|5|Copilot|5|âš ï¸ Mixed|Broad access; 100K context limit|\n|6|Minimax|3|âœ… Positive|Best secondary/budget execution plan|\n|7|OpenRouter API|2|âœ… Positive|Fair PAYG pricing; transparent|\n|8|Ollama Cloud|2|âž¡ï¸ Neutral|Good quotas; slow under load|\n|9|ChatGPT Plus|2|âž¡ï¸ Neutral|Needed for Codex 5.3 only|\n|10|[Synthetic.new](http://Synthetic.new)|2|âš ï¸ Mixed|Over-capacity; low community validation|\n|11|[Z.AI](http://Z.AI) Coding Plan|1|âž¡ï¸ Neutral|No signal|\n|12|Claude Max/Pro|3|âŒ Negative|Expensive; session limits; weak coding|\n|13|Kilocode API|2|âŒ Negative|Accused proxy/copycat; skip for OpenRouter|",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1rba64a/best_bang_for_your_bucks_plan/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o6rkq7t",
          "author": "hotairplay",
          "text": "I don't see it mentioned here, but Alibaba Cloud Coding Plan (Qwen) is $5/mo first month then $10/mo normal.\n\nBut it provides not only Qwen family models, but Kimi K2.5 and GLM 4.7 as well! The quota is very relaxed..i think it is one of the best value subscriptions.",
          "score": 7,
          "created_utc": "2026-02-22 13:09:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6scuek",
              "author": "CutEmpty3551",
              "text": "You mentioned that there is an AI plan on Alibaba Cloud that supports Kimi K2.5 and GLM 4.7. I tried to find it, but I can currently only see the Qwen service available.  \n  \nCould you please provide the link to the specific service you are using?",
              "score": 1,
              "created_utc": "2026-02-22 15:44:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6upivd",
              "author": "drbobb",
              "text": "I don't see any non-Qwen models there.",
              "score": 1,
              "created_utc": "2026-02-22 22:28:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6qkz36",
          "author": "Optimal_Strength_463",
          "text": "Personally I got on the Opencode Black plan pretty quickly and thatâ€™s been one of the best value for me. Especially with Gemini 3.1 on there. I also have a Codex plan and the limits are insane and 5.3 is pretty wild.\n\nIâ€™m stopping my Claude Max plan at the end of the cycle as it seems Opus is brilliant at communicating what it does, but it never quite solves the problem and makes weird choices. When you read the thinking output itâ€™s like â€œwow, this thing thinks like a lead developerâ€ but when you see the solution you realise itâ€™s better at communicating than coding.\n\nGemini 3.1 however seems to think and blab on about tool selection incessantly but created something amazing that wasnâ€™t even on my radar and solves my problem in both a technically superior way and is about 50x cheaper to run.\n\nCodex is somewhere between Gemini and Claude and with the insane limits at the moment is a true workhorse.\n\nThen if youâ€™re into the â€œrun 20 Opencode instances 24/7â€ kind of crowd then having Kimi 2.5 on your Black plan do the grunt work means youâ€™ll struggle to hit the limit of a Zen&Codex Max plan.\n\nIf you have less than $50 a month budget Iâ€™d get the cheapest Codex plan and top the rest up with Kimi credit or the cheapest Zen Black plan.",
          "score": 7,
          "created_utc": "2026-02-22 07:47:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sasab",
              "author": "BodeMan5280",
              "text": ".... how do you justify so many plans?! I find that multiple different coding assistants are helpful, but $200/month helpful? And MULTIPLE? Unless you have a crazy budget im just wondering if your power usage is generating income and if the speed is truly worth the return?\n\nI have ChatGPT Plus and two free acvpints: Gemini Pro and Copilot Pro through my '.edu' account. Claude is too expensive and rate limits are just... yuck. Curious if any MAX plans are really worthwhile and im just a baby vibe coder lol",
              "score": 2,
              "created_utc": "2026-02-22 15:34:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6tib1k",
                  "author": "Optimal_Strength_463",
                  "text": "Yeah, fair point. I spend about Â£750 a month on AI plans and make about Â£12-18k in revenue. Most, if not all, is directly attributed the work those plans are used on.\n\nI also regularly max out all those plans 4 days into a 7 day limit and am trying to find ways to make them last longer hence the suggestions about Kimi etc.\n\nI work for myself now and do about 40-50 hours a week and drink a lot of coffee and have ADHD and Autism, so having a hive of developers working for me that are a bit dopey but donâ€™t talk back or moan about snacks in the fridge is heaven compared to a previous role being a Director with a software org of 300+ people.",
                  "score": 2,
                  "created_utc": "2026-02-22 18:51:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6qjvj7",
          "author": "ganonfirehouse420",
          "text": "I went with the openrouter api. Pricing seems fair.",
          "score": 2,
          "created_utc": "2026-02-22 07:37:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6r0xla",
          "author": "deadcoder0904",
          "text": "Minimax 2.5 & GLM 5 are not bad.\n\nKimi 2.5 too.\n\nCodex is the best. Combine that with Antigravity.\n\nBut yeah buy the Chinese models. They are cheaper. And free on OpenCode for example.",
          "score": 2,
          "created_utc": "2026-02-22 10:20:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o70oyx1",
              "author": "rothnic",
              "text": "Can't use antigravity... pretty much everyone is getting banned at this point. And they don't pro-rate the month. ",
              "score": 1,
              "created_utc": "2026-02-23 20:54:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o72omnd",
                  "author": "deadcoder0904",
                  "text": "Just get a new a/c. Everyone who got banned got banned because of OpenClaw. Don't use that on ur new a/c. Simple.",
                  "score": 1,
                  "created_utc": "2026-02-24 03:26:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6qcouo",
          "author": "soul105",
          "text": "chutes.ai provides Kimi K2.5, GLM5 and others",
          "score": 4,
          "created_utc": "2026-02-22 06:30:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6qlv9d",
              "author": "wallapola",
              "text": "How was the experience in terms of speed and reliability with chutes? Is it fine?",
              "score": 1,
              "created_utc": "2026-02-22 07:55:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6qtkey",
                  "author": "shadow1609",
                  "text": "Absolute catastrophe - imo only usable for async bots/automations with heavy retries and model fallback. You will need both. Nightmare for coding.",
                  "score": 3,
                  "created_utc": "2026-02-22 09:09:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6qvztc",
                  "author": "soul105",
                  "text": "I have been using it for a few days for personal projects, mostly Kimi K2.5 TEE.\n\nIt works very well, a bit faster when compared to the previous free offer from OpenCode Zen few weeks ago. The cost benefit is awesome, you get way more than you paid for, and I'm not sure how can they make money on it.\n\nIf you consider you get 300 calls/day for only $3 you cannot expect it being the favorite tool for vibe coders, that's why it gets so much hate.",
                  "score": 2,
                  "created_utc": "2026-02-22 09:32:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6pmm64",
          "author": "Desperate-Bath5208",
          "text": "Z.AI Coding Plan",
          "score": 3,
          "created_utc": "2026-02-22 03:11:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6qkw1p",
              "author": "dreamkast06",
              "text": "Not anymore due to weekly limits and reduced quotas. They also removed the ability to see when the 5 hours resets, so pretty obvious they are doing something fishy. The way they cache changed recently too so many requests are counting as a new prompt.\n\nMinimax is still good for the $10 as a backup for me.",
              "score": 1,
              "created_utc": "2026-02-22 07:46:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6qsxt4",
                  "author": "Tadomeku",
                  "text": "Opencode tells me when the timer resets? It literally says your window will reset at 11:00 or whatever. It shows up on Red.  \n   \nI use GLM myself. Happy with it.",
                  "score": 3,
                  "created_utc": "2026-02-22 09:03:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6pucga",
          "author": "cmbtlu",
          "text": "Only 1 and 2 are actually good value right now. 3 and 4â€™s models break down when solving actual real world problems and not building basic apps. \n\nCopilot gets you Opus 4.6 with more usage than a standard Claude subscription.\n\nSmartest model right now is probably Codex 5.3 but itâ€™s not in Copilot currently so youâ€™ll need a ChatGPT subscription.",
          "score": 1,
          "created_utc": "2026-02-22 04:05:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6pyl35",
              "author": "keroro7128",
              "text": "copilot has this CodeX 5.3 model.ðŸ¤£",
              "score": 5,
              "created_utc": "2026-02-22 04:35:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6qklrg",
              "author": "albertortilla",
              "text": "The problem with copilot is that the context is limited to 100k",
              "score": 0,
              "created_utc": "2026-02-22 07:43:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6r3sjl",
                  "author": "armindvd2018",
                  "text": "Codex limits are 272K",
                  "score": 1,
                  "created_utc": "2026-02-22 10:47:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6x82jw",
                  "author": "Latter-Parsnip-5007",
                  "text": "Not a problem I ever ran into. Your tasks are too big or you work in the main agent",
                  "score": 1,
                  "created_utc": "2026-02-23 08:54:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ql5vx",
          "author": "gmakkar9",
          "text": "I have been using Ollama Cloud recently. Good quotas but sometimes they are resource constrained and the model won't respond fast.",
          "score": 1,
          "created_utc": "2026-02-22 07:49:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qr7wq",
          "author": "felixgar",
          "text": "I am using Claudeâ€™s Opus 4.6 for planning and Minimax for execution and reviewing due to low cost. It works fine so far, but this split is mostly due to the extreme low session limit on Claude pro plan. Two plans done by opus and the limit is reached :/ Anyone ideas for a better split?",
          "score": 1,
          "created_utc": "2026-02-22 08:46:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6si250",
          "author": "hicder",
          "text": "i'm thinking of the following setup:\n* $20/mo Codex plan\n* $20/mo Synthetic plan\n\nUsecase:\n* Use GPT-5.3-Codex for planning. optionally specify Kimi K2.5 (through Synthetic) for the Explore subagent\n* Use Kimi K2.5 for implementation",
          "score": 1,
          "created_utc": "2026-02-22 16:06:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6skd7d",
              "author": "CantFindMaP0rn",
              "text": "Since I'm already on the Claude 5x Max plan, I don't think I'm going to spend that much more for \"dumb workhorse\" implementation subagent.\n\nThat being said, I'll sign up for Github Copilot's Pro+ to see how much more I can push it before hitting the limit (I can work around that 128k context window with better prompting strategy/skills/compaction), and rotating between whatever free models Zen and nvidia are offering at the time for my implementation subagent.  \n  \nMaybe if I can still one-shot with Copilot, I'd drop Claude entirely and get Minimax/Kimi plans for subagents instead.",
              "score": 1,
              "created_utc": "2026-02-22 16:16:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6slael",
          "author": "tonio_i",
          "text": "Got good use out of Codex $20 plan. But slower compared to Antropic plans, but far more generous quotas and nice context window.Â \n\nAlso tried the Moonshot Kimi 2.5 plan, bargained for $5 (regular $20). Worth the $5 but not the $20, far lower quality and quota compared to the $20 Codex.\n\n\nCopilot is also nice with all the models being offered, lower context but still worth it. Very generous quotas.\n\n\nNice way that I found to maximize the usage is to use one provider for the primary agent and another provider for subagent.",
          "score": 1,
          "created_utc": "2026-02-22 16:20:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6tg3n5",
          "author": "gasmanc",
          "text": "Whatâ€™s the difference between the codex plan and ChatGPT plus????",
          "score": 1,
          "created_utc": "2026-02-22 18:41:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6tn0as",
              "author": "dynacx",
              "text": "Nothing, they're the same picture.\n\nI think it's just the AI made a mistake when summarising.",
              "score": 1,
              "created_utc": "2026-02-22 19:14:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6pulcy",
          "author": "lundrog",
          "text": "Don't forget ollama cloud. Synthetic.new is good but over capacity or i would share a referral.",
          "score": -1,
          "created_utc": "2026-02-22 04:07:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6qlxfk",
              "author": "wallapola",
              "text": "But they change how they count tool calls and it is so limiting ðŸ¥²",
              "score": 2,
              "created_utc": "2026-02-22 07:56:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o704weq",
                  "author": "Simple_Split5074",
                  "text": "Just looked at it. 500 per day? Useless ",
                  "score": 2,
                  "created_utc": "2026-02-23 19:19:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6pre3p",
          "author": "NaturalRedditMotion",
          "text": "What I do is the $10 copilot plan along with $10 plan from chutes. That way I have access to all sota models via copilot and have access to all open source models via chutes. You can opt for the $20 plan from chutes and that will get you 5000 requests per day if the $10 plan wouldnâ€™t work for you. I do the planning via sonnet and implementing the plan via kimi k2.5. This setup works for me.",
          "score": 0,
          "created_utc": "2026-02-22 03:44:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6udslg",
              "author": "robercleverson",
              "text": "Doesn't chutes serve quantized versions of those models?",
              "score": 1,
              "created_utc": "2026-02-22 21:28:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6q4ctm",
          "author": "MorningFew1574",
          "text": "Add Kilocode api into the mix...",
          "score": 0,
          "created_utc": "2026-02-22 05:19:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6r45jf",
              "author": "armindvd2018",
              "text": "Kilo?\n\nThose thieves! They copy Roocode and Cline like-for-like! They use Openrouter behind their thin proxy! So we will use the source, not the proxy!",
              "score": 1,
              "created_utc": "2026-02-22 10:50:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6udkhz",
                  "author": "robercleverson",
                  "text": "And kilo code cli is nothing more than a sloppy reskin of opencode",
                  "score": 2,
                  "created_utc": "2026-02-22 21:27:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6pmfgw",
          "author": "No_Success3928",
          "text": "Synthetic, hands down ðŸ‘",
          "score": -5,
          "created_utc": "2026-02-22 03:10:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pjb15",
          "author": "HarjjotSinghh",
          "text": "ah hell yeah, saturate context window and call me!",
          "score": -6,
          "created_utc": "2026-02-22 02:49:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rdocla",
      "title": "Found a way to touch grass and use Mac terminal from my iPhone so I can be vibecoding and live a balanced life",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/seyx8usijhlg1.jpeg",
      "author": "eureka_boy",
      "created_utc": "2026-02-24 18:30:13",
      "score": 57,
      "num_comments": 51,
      "upvote_ratio": 0.78,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1rdocla/found_a_way_to_touch_grass_and_use_mac_terminal/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o76llww",
          "author": "drinksbeerdaily",
          "text": "IPhones doesn't have SSH clients? I see all these vibe coded ways to connect to claude, codex, opencode and I wonder what the point is. I use termux + mosh over VPN on my Android phone, and not really missing anything.",
          "score": 12,
          "created_utc": "2026-02-24 18:38:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76muhh",
              "author": "eureka_boy",
              "text": "yes if you have already done the VPN setup then sure go ahead with what you have. I hate setting up vpn, tailscale stuff because it is just too much. Also ssh is kind of slow if you don't setup right but I used webrtc here, so it should be significantly faster because now you are directly connecting instead of seperate vpn network in between. \n\nFYI: this is only for Mac and iPhone",
              "score": -8,
              "created_utc": "2026-02-24 18:43:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o76u4y7",
                  "author": "onil34",
                  "text": "brother what. How is installing tailscale more of a hassle than WRITING AN ENTIRE APP",
                  "score": 18,
                  "created_utc": "2026-02-24 19:16:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o76z01v",
                  "author": "drinksbeerdaily",
                  "text": "How is ssh slow? We're talking kilobytes of text here. If you don't like tailscale, just use wireguard directly. I always use a vpn when remotely connecting home, because it's way more secure than exposing your service to the public internet will ever be.",
                  "score": 3,
                  "created_utc": "2026-02-24 19:38:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o773qve",
                  "author": "Delicious_Ease2595",
                  "text": "Tailscale is so simple not sure how you find it \"just too much\".",
                  "score": 2,
                  "created_utc": "2026-02-24 20:00:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7798av",
          "author": "d2xdy2",
          "text": "Iâ€™ll be a hater here. Thatâ€™s not a balanced life.",
          "score": 10,
          "created_utc": "2026-02-24 20:26:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o779ycv",
              "author": "eureka_boy",
              "text": "Hahaha this is the only balanced life i know of",
              "score": 2,
              "created_utc": "2026-02-24 20:29:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o77bidy",
                  "author": "d2xdy2",
                  "text": "Being extreme, Iâ€™d liken it a coke addict having a bump in their pocket for a quick pick me up vs binging the whole eight ball at home. \n\nYouâ€™re still doing the thing. Iâ€™ll never be onboard with this idea that being so attached to vibe coding is healthy or balanced",
                  "score": 4,
                  "created_utc": "2026-02-24 20:36:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o76prac",
          "author": "Dudmaster",
          "text": "With opencode web you wouldn't need a terminal",
          "score": 6,
          "created_utc": "2026-02-24 18:56:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76q7lj",
              "author": "eureka_boy",
              "text": "well all my code is in my local mac, I still prefer a cli interface over a generic chat interface on the web. ",
              "score": 0,
              "created_utc": "2026-02-24 18:58:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o76sxz7",
                  "author": "Dudmaster",
                  "text": "\"web\" name might be misleading, it's a server that would be on your mac, the interface also has shell access",
                  "score": 2,
                  "created_utc": "2026-02-24 19:10:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o77adhe",
          "author": "AltruisticRip5151",
          "text": "If youâ€™re just trying to reach your own machines, Tailscale is the more robust default.\n\nMacky is clever, but it relies on a central signaling service to broker a direct WebRTC session and a custom Mac app, which adds extra third-party trust and attack surface compared to standard SSH over a private mesh.\n\nYou donâ€™t need to toggle Tailscale on or off either. Traffic only goes over it if you point at app at a hostname. It runs 24/7 on my iPhone without issues even between restarts and updates.",
          "score": 2,
          "created_utc": "2026-02-24 20:31:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77dho7",
          "author": "getfitdotus",
          "text": "https://github.com/chriswritescode-dev/opencode-manager this is much more phone ui friendly. Plus all the integration GIT, tts , file editing",
          "score": 2,
          "created_utc": "2026-02-24 20:46:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o771vgi",
          "author": "layer4down",
          "text": "A lot of shade in this thread bro never mind all that. Keep doin you and maybe post over in r/LocalLLama for like-minded folks who like local everything and reinventing wheels for the thrill of it.",
          "score": 3,
          "created_utc": "2026-02-24 19:51:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o772ac4",
              "author": "eureka_boy",
              "text": "thanks bro!",
              "score": 1,
              "created_utc": "2026-02-24 19:53:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o76zy60",
          "author": "rySeeR4",
          "text": "You vibe coded a shitty app and dont know anything about opencode web and how to expose it and just want the attention, take my down vote",
          "score": 3,
          "created_utc": "2026-02-24 19:42:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o772fz9",
              "author": "drinksbeerdaily",
              "text": "Charging $29 for a closed-source vibe-coded terminal relay when tailscale ssh exists for free is a tough sell.",
              "score": 6,
              "created_utc": "2026-02-24 19:54:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o77mh65",
                  "author": "onil34",
                  "text": "HE IS CHARGING 29$ FOR THIS?",
                  "score": 1,
                  "created_utc": "2026-02-24 21:27:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o778gvp",
          "author": "MKU64",
          "text": "What is it with all the shade in here? Nice job! I made one myself and regardless of what everyone says itâ€™s the journey to productivity that matters and what will actually make you continue coding anywhere.",
          "score": 4,
          "created_utc": "2026-02-24 20:22:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77y39k",
              "author": "ImagineBeingPoorLmao",
              "text": "It's the same app every day.",
              "score": 3,
              "created_utc": "2026-02-24 22:21:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o779t93",
              "author": "eureka_boy",
              "text": "yeah thanks bro! Yes I donâ€™t know why people are taking offence to a side project lol",
              "score": 2,
              "created_utc": "2026-02-24 20:28:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o76rkm6",
          "author": "jamesrossdev",
          "text": "I have been wanting to make something like this that allows me to connect to my local pc terminal from my phone, without having to walk 10 meters to my computer. \n\nReally cool seeing you do it and I guess I'll get working on it as well. Btw I also hate doing the VPN setup. It's nice in the long run but tedious to set up",
          "score": 1,
          "created_utc": "2026-02-24 19:04:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76ufik",
              "author": "onil34",
              "text": "Tailscale is literally \n1. install \n2. tailscale up\n3. Log in \n4. Done",
              "score": 5,
              "created_utc": "2026-02-24 19:17:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o76veta",
                  "author": "jamesrossdev",
                  "text": "I should also add that I prefer making my own tools, but I guess I'll try out Tailscale too. Thanks!",
                  "score": -1,
                  "created_utc": "2026-02-24 19:21:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o76vo8u",
                  "author": "eureka_boy",
                  "text": "sure bro, then you need a seperate app in your iphone for ssh. To connect, first you need to turn on the tailscale thing each time in your phone and then go to some ssh app in app store which costs $ if you want a good one. Also tailscale just raised a massive Series C funding of $160M (https://tailscale.com/blog/series-c), you think it is going to be free forever?",
                  "score": -1,
                  "created_utc": "2026-02-24 19:23:11",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o76ssvz",
              "author": "eureka_boy",
              "text": "yesss if you love networking stuff, this should be a fun thing to work on!",
              "score": 1,
              "created_utc": "2026-02-24 19:10:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o76w4a7",
          "author": "momentary_blip",
          "text": "Lol just use exe.dev",
          "score": 1,
          "created_utc": "2026-02-24 19:25:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76wup4",
              "author": "eureka_boy",
              "text": "huh? are you a bot? ",
              "score": 1,
              "created_utc": "2026-02-24 19:28:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o76z0kr",
          "author": "ciprianveg",
          "text": "I like it! Can it be ported to android?",
          "score": 1,
          "created_utc": "2026-02-24 19:38:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77146y",
              "author": "drinksbeerdaily",
              "text": "Sir, there are FREE, battletested and open source alternatives to let you easily connect remotely to a terminal on Linux or MacOS.",
              "score": 3,
              "created_utc": "2026-02-24 19:48:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7723l4",
                  "author": "eureka_boy",
                  "text": "okie this is not simple ssh app, this is an app that allows you to establish a direct p2p webrtc connection between your mac and iphone. This just makes accessing your mac terminal much simpler and easier to setup. \n\nIf you want ssh, you need to first setup VPN so you can access it from anywhere. Which i hate to setup",
                  "score": 1,
                  "created_utc": "2026-02-24 19:52:46",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o76ziqs",
              "author": "eureka_boy",
              "text": "my google play dev account is being weird so might take a few weeks to release the app on android",
              "score": 2,
              "created_utc": "2026-02-24 19:40:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o77no8u",
          "author": "andrewchen5678",
          "text": "I built something similar but entirely web based with mobile optimized interfaces that is completely open source that can run anything on the terminal [https://github.com/andrewtheguy/mywebterm](https://github.com/andrewtheguy/mywebterm)",
          "score": 1,
          "created_utc": "2026-02-24 21:32:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o796bbo",
          "author": "Otherwise_Bee_7330",
          "text": "the balls to charge for slop these days ðŸ¥µ",
          "score": 1,
          "created_utc": "2026-02-25 02:22:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ra62db",
      "title": "Is it possible that I've been using OpenCode for over a month now and these are the stats?",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/xq4tulukipkg1.jpeg",
      "author": "TheOnlyArtz",
      "created_utc": "2026-02-20 20:10:32",
      "score": 51,
      "num_comments": 30,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1ra62db/is_it_possible_that_ive_been_using_opencode_for/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6hlrmb",
          "author": "cri10095",
          "text": "Which models did you used mostly?",
          "score": 6,
          "created_utc": "2026-02-20 20:43:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6hlwot",
              "author": "TheOnlyArtz",
              "text": "5.2-codex and 5.3-codex",
              "score": 6,
              "created_utc": "2026-02-20 20:44:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6hn8g3",
                  "author": "cri10095",
                  "text": "Wow high tier!",
                  "score": 5,
                  "created_utc": "2026-02-20 20:50:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6luz1u",
                  "author": "WalrusCritical773",
                  "text": "what do you mean, codex 5.3 is not available in API so cost stats are meaningless because u're using ChatGPT Plus..?",
                  "score": 1,
                  "created_utc": "2026-02-21 14:44:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6hnub0",
          "author": "thedarkbobo",
          "text": "lul I had like 100M once I started with deepseek, now I dont even count",
          "score": 4,
          "created_utc": "2026-02-20 20:53:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kvjdr",
              "author": "FriendlyUser_",
              "text": "this is the way. Im already on 60$ this monthâ€¦ 1,5B tokens or what ever ðŸ˜…",
              "score": 1,
              "created_utc": "2026-02-21 10:12:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6kz6db",
                  "author": "thedarkbobo",
                  "text": "Nice,am on two plans but will keep glm only",
                  "score": 1,
                  "created_utc": "2026-02-21 10:48:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o757xeu",
              "author": "ab2377",
              "text": "i haven't used it so i have no idea what you guys are talking about, do you get subscription or api keys for deepseek and use opencode? how much does it cost, is api keys good deal for deepseek?",
              "score": 1,
              "created_utc": "2026-02-24 14:52:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6qd0yi",
          "author": "Limp_Carpet1444",
          "text": "![gif](giphy|YmQLj2KxaNz58g7Ofg)",
          "score": 3,
          "created_utc": "2026-02-22 06:33:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hg217",
          "author": "HarjjotSinghh",
          "text": "this openai powerhouse is running my finances? wow.",
          "score": 6,
          "created_utc": "2026-02-20 20:15:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kjy2w",
          "author": "yuckygpt",
          "text": "is this a native feature in opencode?",
          "score": 2,
          "created_utc": "2026-02-21 08:17:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kk7qa",
              "author": "TheOnlyArtz",
              "text": "Yes \\`opencode stats\\`",
              "score": 3,
              "created_utc": "2026-02-21 08:20:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6kkaa1",
                  "author": "yuckygpt",
                  "text": "ahh, I meant the caching",
                  "score": 1,
                  "created_utc": "2026-02-21 08:21:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6nx3hb",
          "author": "touristtam",
          "text": "Been using opencode for a while now:\n\n    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n    â”‚                       OVERVIEW                         â”‚\n    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n    â”‚Sessions                                          1,847 â”‚\n    â”‚Messages                                        100,207 â”‚\n    â”‚Days                                                173 â”‚\n    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n    â”‚                    COST & TOKENS                       â”‚\n    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n    â”‚Total Cost                                     $7059.44 â”‚\n    â”‚Avg Cost/Day                                     $40.81 â”‚\n    â”‚Avg Tokens/Session                                 3.5M â”‚\n    â”‚Median Tokens/Session                            915.6K â”‚\n    â”‚Input                                           2777.5M â”‚\n    â”‚Output                                            41.0M â”‚\n    â”‚Cache Read                                      3398.9M â”‚\n    â”‚Cache Write                                      227.4M â”‚\n    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜",
          "score": 2,
          "created_utc": "2026-02-21 21:02:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rdkjd",
              "author": "UseMoreBandwith",
              "text": "my 'Avg Tokens/Session' is 27.6M ,   \nand only 22 sessions.  \n  \nYou seem to use lots of sessions.",
              "score": 1,
              "created_utc": "2026-02-22 12:15:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6s763t",
                  "author": "touristtam",
                  "text": "I do. Two reasons for that: Opencode seems have had memory leaks at time and Opencode lacks a mechanism to re-load the config/custom tools/skills that I would be working on.",
                  "score": 2,
                  "created_utc": "2026-02-22 15:17:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6o08u8",
              "author": "KaMaFour",
              "text": "Bro... This is the stage you start thinking about buying a B200...",
              "score": 0,
              "created_utc": "2026-02-21 21:19:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6hj4mz",
          "author": "soul105",
          "text": "Yes, its possible.",
          "score": 1,
          "created_utc": "2026-02-20 20:30:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6hjc5z",
              "author": "TheOnlyArtz",
              "text": "That's insane isn't it?",
              "score": 0,
              "created_utc": "2026-02-20 20:31:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6hw3av",
          "author": "dodistyo",
          "text": "what provider?",
          "score": 1,
          "created_utc": "2026-02-20 21:34:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6limbc",
          "author": "SnooGiraffes625",
          "text": "1.5 months 99M 2000m cached\n\nhttps://preview.redd.it/4z0tcaotnukg1.jpeg?width=4000&format=pjpg&auto=webp&s=1d526b44b2ea63d8508e39b3adcbbc4efbf5aa23",
          "score": 1,
          "created_utc": "2026-02-21 13:28:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6nz98y",
          "author": "KaMaFour",
          "text": "https://preview.redd.it/bvb227xtywkg1.png?width=493&format=png&auto=webp&s=408a77a9ab15bfef873490ff5c00b43cc9a78bd6\n\ndunno man, costsaving works for me",
          "score": 1,
          "created_utc": "2026-02-21 21:14:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xd3hc",
              "author": "Latter-Parsnip-5007",
              "text": "Local inference be like 0.00$ 17,3M out. Qwen coder is soooo good",
              "score": 1,
              "created_utc": "2026-02-23 09:44:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6igzob",
          "author": "Empty-Sandwich-7092",
          "text": "How do I find these costs? Is this some kind of special feature? And where can I see the stats?. And  how are you using opencode?\n\nHow I get this costs? It's something special? and how I can see that stats?How do I find these costs? Is this some kind of special feature? And where can I see the stats?How do I find these costs? Is this some kind of special feature? And where can I see the stats?",
          "score": 0,
          "created_utc": "2026-02-20 23:25:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6jwfmc",
              "author": "TheOnlyArtz",
              "text": "`opencode stats`",
              "score": 4,
              "created_utc": "2026-02-21 04:51:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6mw596",
          "author": "HarjjotSinghh",
          "text": "my brain just upgraded to gold standard mode.",
          "score": 0,
          "created_utc": "2026-02-21 17:54:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9poid",
      "title": "I got tired of managing 10 terminal tabs for my Claude sessions, so I built agent-view",
      "subreddit": "opencodeCLI",
      "url": "https://v.redd.it/qll3tr2rylkg1",
      "author": "Frayo44",
      "created_utc": "2026-02-20 08:15:13",
      "score": 51,
      "num_comments": 14,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r9poid/i_got_tired_of_managing_10_terminal_tabs_for_my/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6e0lw8",
          "author": "HarjjotSinghh",
          "text": "this tab management solution needs a high-five.",
          "score": 11,
          "created_utc": "2026-02-20 08:22:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6gbgjk",
              "author": "[deleted]",
              "text": "[removed]",
              "score": 2,
              "created_utc": "2026-02-20 17:06:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6hdibc",
                  "author": "Character_Cod8971",
                  "text": "OpenCode desktop?",
                  "score": 1,
                  "created_utc": "2026-02-20 20:02:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6job9o",
                  "author": "pythonr",
                  "text": "Tmux?",
                  "score": 1,
                  "created_utc": "2026-02-21 03:52:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6e156p",
          "author": "thedarkbobo",
          "text": "Looks good sir.",
          "score": 5,
          "created_utc": "2026-02-20 08:27:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6e17t1",
              "author": "Frayo44",
              "text": "Thanks!",
              "score": 1,
              "created_utc": "2026-02-20 08:27:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6eqzrg",
          "author": "redlotusaustin",
          "text": "This is really cool but any chance of it recognizing tmux sessions already running? I'd prefer to not have to recreate things just to get them into a dashboard",
          "score": 1,
          "created_utc": "2026-02-20 12:13:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6eyek0",
              "author": "Frayo44",
              "text": "Unfortunately no, you will need to create your sessions from scratch",
              "score": 1,
              "created_utc": "2026-02-20 13:02:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6jhmix",
          "author": "HarjjotSinghh",
          "text": "this looks like terminal magic.",
          "score": 1,
          "created_utc": "2026-02-21 03:07:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qczey",
          "author": "Efficient_Couple_455",
          "text": "if this integrate with opencode smoothly, this gonna be great. But now it is bit clumsy",
          "score": 1,
          "created_utc": "2026-02-22 06:32:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6qdj14",
              "author": "Frayo44",
              "text": "Can u open an issue explaining what u experience?",
              "score": 1,
              "created_utc": "2026-02-22 06:37:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o726qss",
          "author": "Mathdoy2",
          "text": "How does it compare to dmux?",
          "score": 1,
          "created_utc": "2026-02-24 01:42:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o72lvuu",
          "author": "Zealousideal_Pin177",
          "text": "I just use tmux sessions and an AI agent to manage them.   Then I just work with the AI agent and it tells the tmux'd opencode and/or claude code sessions what to do.  I am trying to remove myself as much as possible from being in the middle of the work and just review the output when its ready.",
          "score": 1,
          "created_utc": "2026-02-24 03:09:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rce8jw",
      "title": "Built an open-source Telegram client for OpenCode CLI â€” now dogfooding it daily from my phone",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1rce8jw/built_an_opensource_telegram_client_for_opencode/",
      "author": "Less_Ad_1505",
      "created_utc": "2026-02-23 10:46:21",
      "score": 50,
      "num_comments": 11,
      "upvote_ratio": 0.98,
      "text": "OpenCode CLI has become my primary dev tool, and I want to give a huge shoutout to its authors for building such an incredible piece of software. The models seem to handle context and logic particularly well in it, especially when using the Plan agent first and then switching to Build.\n\nEven before Openclaw became popular, I kept thinking how useful it would be to access OpenCode from my phone. I noticed OpenCode has a server mode, which meant building a custom client was totally doable. Initially, I just wanted to write a simple Telegram bot for my own needs. But, as it usually goes, I got carried away, added more features, and eventually decided to open-source the project.\n\nI definitely won't call it \"fully functional\" yet - there are still rough edges. However, it currently has enough features to be used for actual development.\n\nHere is what works right now:\n\n* Switching between projects and sessions.\n* Selecting the agent, model, and variant (reasoning effort).\n* Tracking the agent's progress on a task.\n* Receiving code diffs directly in the chat as text files.\n\nIronically, I'm now at the point where I use the bot to write code for the bot itself. Itâ€™s a pretty great feeling to lie on the couch, watch a TV series, and casually send dev tasks to the agent via Telegram on my phone.\n\nI plan to keep actively developing the project since I use it daily. If anyone wants to try it out, the repo is here: [https://github.com/grinev/opencode-telegram-bot](https://github.com/grinev/opencode-telegram-bot)\n\nI would be really grateful for any feedback, thoughts, or suggestions!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1rce8jw/built_an_opensource_telegram_client_for_opencode/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o6y66na",
          "author": "throwaway12012024",
          "text": "i am doing exactly the same! Great project! I am sad bc just discovered your work now so i am a bit in the sunken cost thing.",
          "score": 1,
          "created_utc": "2026-02-23 13:36:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o729fdr",
          "author": "bradjones6942069",
          "text": "Open code has become my daily driver as well. I would love to try this out",
          "score": 1,
          "created_utc": "2026-02-24 01:57:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o74yj13",
              "author": "bradjones6942069",
              "text": "Been trying it out since last night. Works great.",
              "score": 1,
              "created_utc": "2026-02-24 14:04:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o75oe9h",
          "author": "oVerde",
          "text": "Is the bot publicly available? So anyone would run agents on my machine?",
          "score": 1,
          "created_utc": "2026-02-24 16:09:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75pesn",
              "author": "Less_Ad_1505",
              "text": "No, the basic idea is that the bot only works with one allowed userId for security purposes.",
              "score": 1,
              "created_utc": "2026-02-24 16:14:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o75pxyt",
                  "author": "oVerde",
                  "text": "thanks",
                  "score": 1,
                  "created_utc": "2026-02-24 16:16:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6xk26d",
          "author": "HarjjotSinghh",
          "text": "this is how you turn phone dev dreams real!",
          "score": 0,
          "created_utc": "2026-02-23 10:50:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xlrh2",
              "author": "Less_Ad_1505",
              "text": "You can also run this bot on a remote server to have a personal assistant right in Telegram. It won't be as proactive as Openclaw, but you can still do a lot with it and see exactly what's happening in detail",
              "score": 1,
              "created_utc": "2026-02-23 11:06:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6xp91n",
          "author": "revilo-1988",
          "text": "Mal ne Frage was ist den so nÃ¼tzlich um es vom Handy aus zu machen?",
          "score": -2,
          "created_utc": "2026-02-23 11:37:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbilk6",
      "title": "Looking for the best and cheapest plan for opencode",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1rbilk6/looking_for_the_best_and_cheapest_plan_for/",
      "author": "Technical_Map_5676",
      "created_utc": "2026-02-22 10:33:30",
      "score": 42,
      "num_comments": 60,
      "upvote_ratio": 0.96,
      "text": "Hey :) \n\nI don't want to vibe code. I mainly used AI to save myself the trouble of looking through the documentation or to discuss errors and ideas.    \nI want to use opencode because I don't want a vendor lock and I like the idea to use any model that ich want.   \nI would also like to use an open source model, but I can't decide for a plan. \n\nWhat's the best open source model for opencode ? Is NanoGPT with the 8 dollar plan good ? Maybe [https://z.ai/subscribe](https://z.ai/subscribe) ? \n\nOr pay only my real use with a api key from [https://openrouter.ai](https://openrouter.ai) or [https://opencode.ai/docs/zen](https://opencode.ai/docs/zen)\n\nThank you for sharing your experiences. :)\n\nLg ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1rbilk6/looking_for_the_best_and_cheapest_plan_for/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o6r32fv",
          "author": "kegelo",
          "text": "GitHub Copilot : [https://github.com/features/copilot/plans](https://github.com/features/copilot/plans) \\- 10 USD for 300 requests / month for the best models\n\nNot open source models though",
          "score": 20,
          "created_utc": "2026-02-22 10:40:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rbbgb",
              "author": "c0nfluks",
              "text": "Chutes: [https://chutes.ai/pricing](https://chutes.ai/pricing) \\- $3/month for 300 requests/day. Access to 60+ Open-source models (including Kimi K2.5, Minimax 2.5, GLM5, Qwen3.5 and more). Completely private (TEE).",
              "score": 7,
              "created_utc": "2026-02-22 11:57:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6rd11o",
                  "author": "bizz_koot",
                  "text": "https://www.reddit.com/r/chutesAI/s/DP61DSx4FS\n\nQuite bad experiences it seems",
                  "score": 11,
                  "created_utc": "2026-02-22 12:11:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6rcici",
                  "author": "kegelo",
                  "text": "very interesting thanks",
                  "score": 1,
                  "created_utc": "2026-02-22 12:07:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6r8bz3",
              "author": "LINGLING55581",
              "text": "But 300 requests per month is not really much is it?",
              "score": 3,
              "created_utc": "2026-02-22 11:30:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6retvp",
                  "author": "BERLAUR",
                  "text": "It's 300 \"tasks\", any task is up to N requests. You could go for 20-30 minutes in a session and still be on the first \"task\". It's not very transparent but quite doable.Â ",
                  "score": 4,
                  "created_utc": "2026-02-22 12:26:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6r9bga",
                  "author": "kegelo",
                  "text": "Given the OP usage, should be fine for them",
                  "score": 2,
                  "created_utc": "2026-02-22 11:39:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6r3d7s",
              "author": "Technical_Map_5676",
              "text": "and Microsoft is fine to use it with opencode ?",
              "score": 2,
              "created_utc": "2026-02-22 10:43:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6r4lne",
                  "author": "ArifNiketas",
                  "text": "Yes, when Anthropic stopped subscription usage on third-party CLI tools, GitHub came out with official support for OpenCode.",
                  "score": 14,
                  "created_utc": "2026-02-22 10:55:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6r7xdh",
              "author": "ahmetegesel",
              "text": "I really hate the fact that claude models are low context window with GH Copilot",
              "score": 1,
              "created_utc": "2026-02-22 11:26:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6rb64u",
              "author": "touristtam",
              "text": "I have this and it goes pretty quick on what I would call moderate usage. YMMV",
              "score": 1,
              "created_utc": "2026-02-22 11:55:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6uvjnl",
              "author": "pmv143",
              "text": "Copilot is solid if youâ€™re fine with closed models and predictable monthly usage. If you specifically want open source + flexibility, API pay per use with a good open model can be cheaper long term, especially if your usage isnâ€™t constant. The main thing to watch is how providers bill idle time or minimum instance uptime.",
              "score": 1,
              "created_utc": "2026-02-22 23:01:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6r77kf",
              "author": "charmander_cha",
              "text": "Quero modelo de cÃ³digo aberto,  que sao baratos e eu poderei me planejar a longo prazo com mais paz",
              "score": 1,
              "created_utc": "2026-02-22 11:19:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6r8fyx",
                  "author": "ChatGPTisOP",
                  "text": "+1000 open source models aren't (only) about pricing, but also about having an exit strategy, avoiding future vendor lock-in, supporting better alternatives to proprietary models, etc",
                  "score": 1,
                  "created_utc": "2026-02-22 11:31:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ujmvs",
          "author": "intwiz",
          "text": "just use NVIDIA, free API key, access to tons of OSS models (GLM, Kimi, Qwen3.5, etc.), unlimited usage with a very generous 40 requests per minute rate limit\n\nthe provider can be a little slow at times but for lightweight workflows such as yours, it should be well suited. go to build.nvidia.com",
          "score": 7,
          "created_utc": "2026-02-22 21:58:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6rq7yn",
          "author": "RainScum6677",
          "text": "The best value is probably copilot. Be it the 10$ or 40$ sub.\n\nThe best overall? In my opinion that's the 200$ codex, with a new 100$ possibly taking Ng the crown soon.\n\nThat said, you can combine all sorts of subs for great value, depending on your needs and the type of work you do.",
          "score": 4,
          "created_utc": "2026-02-22 13:44:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6r31kc",
          "author": "armindvd2018",
          "text": "NanoGPT has rate limiting; they advertise 2000 requests a day, but every time I pass 300-400, the models keep failing. They are not honest about their true limits. So i cancelled my subscription after first month. \n\nIf you're looking at a cheap option, maybe Chutes would be a good one. \n\nAlso, opencode always has something free, so you don't need to pay anything.",
          "score": 7,
          "created_utc": "2026-02-22 10:40:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rhafe",
              "author": "drbobb",
              "text": "I don't see anything about using Chutes with a tool like OpenCode, and on their site they don't seem to even mention integration with coding tools. Any hints?",
              "score": 1,
              "created_utc": "2026-02-22 12:45:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6rit0k",
                  "author": "armindvd2018",
                  "text": "opencode auth login\n\nhttps://preview.redd.it/gk4j31aym1lg1.jpeg?width=1039&format=pjpg&auto=webp&s=3692ea4526cabdee0c53ac8dded2676bd8eff1c9\n\nIf you don't like to see all models just add it as custom provider with few models that you like",
                  "score": 1,
                  "created_utc": "2026-02-22 12:56:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6r4ci6",
          "author": "nunodonato",
          "text": "I'm using z.ai super happy with it",
          "score": 6,
          "created_utc": "2026-02-22 10:52:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rbv0b",
              "author": "Illustrious-Many-782",
              "text": "Are you on the grandfathered or the post-February account?",
              "score": 1,
              "created_utc": "2026-02-22 12:01:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6rcm3i",
                  "author": "nunodonato",
                  "text": "Pre February. But I would do it again today anyway.Â ",
                  "score": 0,
                  "created_utc": "2026-02-22 12:08:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6rbriu",
          "author": "beardedNoobz",
          "text": "[Z.ai](http://Z.ai) used to be the go to plan if you want a cheap one. It had very good bang for the buck value, but nowadays they seems to unable to properly serve their users. And with GLM 5 such a big models, their subscription will no longer cheap.         \n\nI still use it though, their old model 4.7, 4.6 and 4.5 still stable enough. But I plan to add new subscription or migrate from them entirely.",
          "score": 2,
          "created_utc": "2026-02-22 12:00:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6r4kts",
          "author": "HarjjotSinghh",
          "text": "i'd switch to nano if my wallet's that broke - still way better than vendor debt.",
          "score": 4,
          "created_utc": "2026-02-22 10:54:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6r2ucl",
          "author": "mdn0",
          "text": "nanogpt has changed its subscription last week - it is much more limited now. opencode is just not intended to be used in their new limits.",
          "score": 2,
          "created_utc": "2026-02-22 10:38:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6r36r4",
              "author": "Technical_Map_5676",
              "text": "mÃ¤h, 8$ ..to good to be true ",
              "score": 0,
              "created_utc": "2026-02-22 10:41:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6rm77q",
          "author": "McKing_07",
          "text": "what do you guys think about synthetic.new?",
          "score": 2,
          "created_utc": "2026-02-22 13:19:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sh216",
              "author": "Vict1232727",
              "text": "The problem is thereâ€™s a waitlist currently. I got lucky and got in before it, but thereâ€™s high demand and they have infra issues (normal when demand explodes like this) but yeah, they donâ€™t even have GLM5/ mm2.5 running yet",
              "score": 1,
              "created_utc": "2026-02-22 16:02:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6w69kj",
              "author": "inventivepotter",
              "text": "I got in and like their service, they're fast serving llm requests.",
              "score": 0,
              "created_utc": "2026-02-23 03:39:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6rzemd",
          "author": "AbbreviationsMany728",
          "text": "Have been using minimax m2.5 as my go-to sub. 10 bucks and the limits are generous as fuck. but am also thinking of getting ollama cloud considering the planning and reasoning of it isn't that good, it needs great prompts. I have found Minimax to be better than even free versions of GLM5, but Kimi K2.5 has been the best to me in even free versions and that is why thinking of shifting to [https://ollama.com/pricing](https://ollama.com/pricing) to try all the free models but still haven't tried it so idk.",
          "score": 2,
          "created_utc": "2026-02-22 14:37:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6vwqcu",
              "author": "bright_wal",
              "text": "Use nvidia nim developer access ? Its free.",
              "score": 0,
              "created_utc": "2026-02-23 02:39:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6zkrnp",
          "author": "giuliastro",
          "text": "Why not using OpenCode Zen?\nFree usage of GLM-5, Minimax M2.5, Trinity.\nIn my experience GLM-5 is quite good for coding.",
          "score": 1,
          "created_utc": "2026-02-23 17:47:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ra0g7",
          "author": "Bob5k",
          "text": "minimax while using [10% discount](https://platform.minimax.io/subscribe/coding-plan?code=HO46LCwAJ5&source=link)is cheapest and most generous, no weekly limit and efficiently even the 100 prompts plan as long as you're not spinning 5 opencode sessions as a time is really good and tricky to cap out.",
          "score": 1,
          "created_utc": "2026-02-22 11:45:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rf8tz",
              "author": "Technical_Map_5676",
              "text": "sounds good.  is minimax a good model for opencode ?",
              "score": 0,
              "created_utc": "2026-02-22 12:29:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6rhhyt",
                  "author": "Bob5k",
                  "text": "i moved all my workflow into minimax - the highspeed variant is insane. Might be a bit worse inn terms of coming up with assumptions so it does require proper prompting around to set it towards the right direction (here wispr flow or other dictation tools help, wispr also has a [free month for referrals](https://wisprflow.ai/r/MICHA%C5%81428)), but once it's set it's insanely good. And the speed matters as you'll be able to code and review while other tools will be at task 6/12 . Especially now when glm is slow and Kimi is super slow no matter the provider.",
                  "score": 2,
                  "created_utc": "2026-02-22 12:46:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6wrv54",
                  "author": "look",
                  "text": "Minimax 2.5 is very good for coding. For personal projects I use agents a lot like it sounds you do: more interactive, kind of â€œpartial pair programmingâ€ while I multitask between things.\n\nIâ€™m currently running a mix of Minimax (default for build mode), GLM5 (default for plan mode), and Kimi 2.5 (more ad hoc/mix) on Opencode. \n\nAt work, I run Claude Code with Opus 4.6 1M context in unlimited fast mode API, and I feel my home Opencode/GLM/Mini/Kimi setup is in the same ballpark (for how I use it at least), and itâ€™s effectively free in comparison.\n\nI also just started experimenting with the Chutes $3/month plan, and it seems promising for slightly more async workflows. Itâ€™s a little slower, and sometimes needs a kick, but a great price for the times you are mostly swapping between it and other work.\n\nWhen I want a faster, more interactive flow, I use Opencode Zen pay-as-you-go API with Minimax or Kimi. At $0.15/$1.20 for Minimax, my bill never gets large. Iâ€™m tracking about $10/mo now altogether and I use them a few hours a day on average.",
                  "score": 1,
                  "created_utc": "2026-02-23 06:22:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6rzwjz",
          "author": "UseMoreBandwith",
          "text": "'good' depends on how you use it.  \nWith the right instructions, the free and even some local models are good enough.  \nMany people don't know how to prompt though.\n\n",
          "score": 1,
          "created_utc": "2026-02-22 14:39:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6tpwcc",
          "author": "MakesNotSense",
          "text": "OpenCode has some 'free' models. They can be slow due to demand, or not accessible. But if you don't use AI much, it's free. \n\nYou can also use OpenCode Zen. Basically, it's pay as you go, but in $20 increments. So, pay $20, then use it up over time. If your usage is low, then you can end up paying less than you do for a subscription. Especially if you use cost-effective but smart models like Kimi k2.5. \n\nIf you need more usage, GitHub Copilot seems to be getting popular. Subscription provides an amount of usage per month, and past that pay as you go.",
          "score": 1,
          "created_utc": "2026-02-22 19:28:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6r3n95",
          "author": "No-Profession-734",
          "text": "Whatâ€™s wrong with 'vibe coding' if you focus on a solid architecture first and follow up with an in-depth review?\n\n\n\nPersonally, Iâ€™d stick with paid models unless your needs are very basic. Iâ€™d be worried that free models might be more harmful than helpful when it comes to aggregating documentation.",
          "score": -1,
          "created_utc": "2026-02-22 10:46:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6r41au",
              "author": "Technical_Map_5676",
              "text": "nothing is wrong with it ...It's just that I enjoy writing code myself. ",
              "score": 7,
              "created_utc": "2026-02-22 10:49:46",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6r503f",
              "author": "Specialist_Garden_98",
              "text": "Don't think he said anything was wrong with vibe coding?",
              "score": 4,
              "created_utc": "2026-02-22 10:58:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6r2x46",
          "author": "SphaeroX",
          "text": "you alway pay an extra fee for openrouter, keep this in mind",
          "score": 0,
          "created_utc": "2026-02-22 10:39:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rt8vl",
              "author": "Delicious_Ease2595",
              "text": "Extra fee?",
              "score": 0,
              "created_utc": "2026-02-22 14:02:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6sbnwe",
                  "author": "SphaeroX",
                  "text": "https://preview.redd.it/v6vnnxmwf2lg1.png?width=1141&format=png&auto=webp&s=4ccea4b983ece454e1c94601d221e455bf5198fc\n\n[https://openrouter.ai/pricing](https://openrouter.ai/pricing)",
                  "score": 1,
                  "created_utc": "2026-02-22 15:38:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6r8934",
          "author": "Snoo_57113",
          "text": "Minimax",
          "score": 0,
          "created_utc": "2026-02-22 11:29:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6uuylr",
          "author": "pmv143",
          "text": "If you want flexibility and no lock-in, API-based pay-per-use is usually safer than flat monthly plans unless youâ€™re very heavy usage. For open source coding models, people are having decent results with DeepSeek Coder, Code Llama, and some of the newer Qwen variants depending on context length needs. The main tradeoff is latency and hosting cost.",
          "score": 0,
          "created_utc": "2026-02-22 22:58:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6uw7jd",
          "author": "pmv143",
          "text": "Weâ€™ve been experimenting with a runtime that behaves more like Lambda for LLMs. The goal is simple. scale to zero, restore fast, and align billing to actual execution time instead of idle uptime. Weâ€™re looking for a handful of people running open-source models who want to benchmark their workload against this approach. Happy to run your model on H100s and share detailed metrics.",
          "score": 0,
          "created_utc": "2026-02-22 23:05:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vyf12",
          "author": "Disillusioned_Sleepr",
          "text": "Z.ai (glm) or minimax",
          "score": 0,
          "created_utc": "2026-02-23 02:49:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6wr6qq",
          "author": "sudoer777_",
          "text": "Right this very moment the cheapest plan is the free models on OpenCode Zen, which have been there for about a month",
          "score": 0,
          "created_utc": "2026-02-23 06:16:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rajn6x",
      "title": "cocoindex-code - super light weight MCP that understand and searches codebase that just works on opencode",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1rajn6x/cocoindexcode_super_light_weight_mcp_that/",
      "author": "Whole-Assignment6240",
      "created_utc": "2026-02-21 06:14:04",
      "score": 39,
      "num_comments": 42,
      "upvote_ratio": 0.96,
      "text": "I built a a super light-weight, effective embedded MCP that understand and searches your codebase that just works (AST-based) ! UsingÂ CocoIndexÂ - an Rust-based ultra performant data transformation engine. No blackbox. Works for opencode or any coding agent. Free, No API needed.\n\n* Instant token saving by 70%.\n* 1 min setupÂ - Just claude/codex mcp add works!\n\n[https://github.com/cocoindex-io/cocoindex-code](https://github.com/cocoindex-io/cocoindex-code)\n\nWould love your feedback! Appreciate a star â­ if it is helpful!\n\nTo get started:\n\n\\`\\`\\`  \nopencode mcp add  \n\\`\\`\\`\n\n* Enter MCP server name: `cocoindex-code`\n* Select MCP server type: `local`\n* Enter command to run: `uvx --prerelease=explicit --with cocoindex>=1.0.0a16 cocoindex-code@latest`\n\n`Or use opencode.json`:\n\n    {\n      \"$schema\": \"https://opencode.ai/config.json\",\n      \"mcp\": {\n        \"cocoindex-code\": {\n          \"type\": \"local\",\n          \"command\": [\n            \"uvx\",\n            \"--prerelease=explicit\",\n            \"--with\",\n            \"cocoindex>=1.0.0a16\",\n            \"cocoindex-code@latest\"\n          ]\n        }\n      }\n    }",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1rajn6x/cocoindexcode_super_light_weight_mcp_that/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o6kfpjq",
          "author": "mrfreez44",
          "text": "How does it behave when switching branch? Or using worktrees?",
          "score": 3,
          "created_utc": "2026-02-21 07:36:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6wd7sx",
              "author": "Whole-Assignment6240",
              "text": "hey thanks a lot this is really a great question!!\n\nCurrently the index is just kept up-to-date with the workspace. When you switch branch etc. it'll always follow the latest in your workspace and update incrementally. The index is automatically updated when the MCP starts, and before any query.  \n  \nIf you have multiple worktrees, and when you load the MCP in different worktrees, it's indexing each worktree independently.  \n\n\nWe are having plans in future doing advanced optimization on this too!",
              "score": 2,
              "created_utc": "2026-02-23 04:27:10",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6rmtt4",
              "author": "mrfreez44",
              "text": "No one?\nIndexing for the first time is great, but that must be updated for each feature, handling merge conflicts, rebases, branche switches...",
              "score": 1,
              "created_utc": "2026-02-22 13:23:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6kzhc5",
          "author": "Miserable-Cow3117",
          "text": "How this compare to Serena or grepai? I've already tried both and I'm not really impressed by the results",
          "score": 3,
          "created_utc": "2026-02-21 10:51:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6obkq4",
              "author": "Whole-Assignment6240",
              "text": "this is AST based. i'm not familar with grepai - from high level looks like it is not?",
              "score": 1,
              "created_utc": "2026-02-21 22:19:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6k7bmu",
          "author": "HarjjotSinghh",
          "text": "oh my god this is genius - stealing my ideas already.",
          "score": 2,
          "created_utc": "2026-02-21 06:19:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6k7fou",
              "author": "Whole-Assignment6240",
              "text": "give it a spin! would love your feedback! ",
              "score": 1,
              "created_utc": "2026-02-21 06:20:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6kaiag",
          "author": "debackerl",
          "text": "Very nice! I just found https://github.com/postrv/narsil-mcp yesterday. They also offer code search based on embeddings (their neural_search tool).\n\nHow do you split your chunks? Is it based on an AST?",
          "score": 2,
          "created_utc": "2026-02-21 06:48:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ketiw",
              "author": "mrfreez44",
              "text": "This MCP seems over-engineered: what are the use cases?? 90 tools? Will it exhaust the model context?",
              "score": 4,
              "created_utc": "2026-02-21 07:28:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6odz1f",
                  "author": "debackerl",
                  "text": "Yes and no. Keeping BM25, IDF and embedding indexes all benefit from constantly watching files. Once you have embeddings, it's easy to find duplicate codes logic. I suppose that the call graph also benefit from file watching. However, yes, the security scans have probably little synergies.\n\nHowever, it's split in categories, and you can simply enable the categories that you want. So I don't see a problem ti have one tool with feature flags.\n\nI see more of a problem having 10 tools watching my files, and all reading those same files in parallel as I edit them.",
                  "score": 2,
                  "created_utc": "2026-02-21 22:33:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6kb8qt",
              "author": "Whole-Assignment6240",
              "text": "yes! AST based. tree-sitter :) ",
              "score": 3,
              "created_utc": "2026-02-21 06:54:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ka625",
          "author": "Professional_Past_30",
          "text": "Looks really cool! How does the embedding model work underneath?",
          "score": 1,
          "created_utc": "2026-02-21 06:44:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kb78u",
              "author": "Whole-Assignment6240",
              "text": "sentence transformer, also supports ollama and 100+ cloud providers if you have a preference!",
              "score": 2,
              "created_utc": "2026-02-21 06:54:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6kjbjc",
          "author": "Delyzr",
          "text": "No php support ?",
          "score": 1,
          "created_utc": "2026-02-21 08:11:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6obx1a",
              "author": "Whole-Assignment6240",
              "text": "it does support php! [https://cocoindex.io/docs/ops/functions#supported-languages](https://cocoindex.io/docs/ops/functions#supported-languages) this is built on top of cocoindex which supports php, i'll update the docs. thanks!",
              "score": 2,
              "created_utc": "2026-02-21 22:21:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6kr6dp",
          "author": "Character_Cod8971",
          "text": "How can I tell the model to always use this instead of its built-in tools. I found models to not use any MCP server except if I specifically tell them which is not what I want to do every time I make a prompt.",
          "score": 1,
          "created_utc": "2026-02-21 09:30:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kz6k7",
              "author": "Miserable-Cow3117",
              "text": "Put clear instructions in your agents.md file",
              "score": 1,
              "created_utc": "2026-02-21 10:48:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6l1ccq",
                  "author": "Character_Cod8971",
                  "text": "Do you have an example?",
                  "score": 1,
                  "created_utc": "2026-02-21 11:09:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6oc6nu",
              "author": "Whole-Assignment6240",
              "text": "yes! add skill for it. happy to help with a skill too!",
              "score": 1,
              "created_utc": "2026-02-21 22:23:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6l0sq2",
          "author": "landed-gentry-",
          "text": "Saves tokens, but at what cost? There's a reason SOTA agentic harnesses aren't using these tools already.",
          "score": 1,
          "created_utc": "2026-02-21 11:03:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6m27wr",
              "author": "Mlaz72",
              "text": "ofc they want you to spend more tokens then you need to",
              "score": 1,
              "created_utc": "2026-02-21 15:23:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6myn1g",
                  "author": "landed-gentry-",
                  "text": "Any model provider that isn't competing on token efficiency is going to get left in the dust by their competitors.",
                  "score": 2,
                  "created_utc": "2026-02-21 18:06:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6pqnl9",
          "author": "Hot_Dig8208",
          "text": "I tried cocoindex months ago. Its useful when you have a monorepo project. It will make the agent search faster. \n\nThe downside of cocoondex is it use postrgres to store the data. I need to run locally since my project is huge. I canâ€™t use free postgress instance for this.",
          "score": 1,
          "created_utc": "2026-02-22 03:39:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6proir",
              "author": "Whole-Assignment6240",
              "text": "hi there, thanks for the feedback!  the new one no longer use postgres! it is embedded, please check it out :)  [https://github.com/cocoindex-io/cocoindex-code](https://github.com/cocoindex-io/cocoindex-code)  \n",
              "score": 1,
              "created_utc": "2026-02-22 03:46:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6ptlhb",
                  "author": "Hot_Dig8208",
                  "text": "Is it brand new app on top of cocoindex ? Glad to hear now it is embedded, but how ?",
                  "score": 1,
                  "created_utc": "2026-02-22 04:00:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6svyhw",
          "author": "ThatNickGuyyy",
          "text": "Iâ€™ll test drive this at work tomorrow!\n\nI work a huge legacy PHP codebase and most of these tools donâ€™t work the greatest. This seems promising! \n\nWill provide feedback!",
          "score": 1,
          "created_utc": "2026-02-22 17:08:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6vx4rt",
              "author": "Whole-Assignment6240",
              "text": "thank you so much!! are you already sending PR to the repo? love your work!!",
              "score": 1,
              "created_utc": "2026-02-23 02:41:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6swaho",
          "author": "chrismo80",
          "text": "currently under test, need to watch token usage if it makes a difference.  \n  \nbut my agent already thanked for the search tool, seems to be handy for him.",
          "score": 1,
          "created_utc": "2026-02-22 17:10:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6vx7bd",
              "author": "Whole-Assignment6240",
              "text": "thank you so much for the feedback!!",
              "score": 1,
              "created_utc": "2026-02-23 02:42:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6yv516",
          "author": "KevinNitroG",
          "text": "Is this similar to [VectorCode](https://github.com/Davidyz/VectorCode)?",
          "score": 1,
          "created_utc": "2026-02-23 15:47:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o738sj1",
              "author": "Whole-Assignment6240",
              "text": "great question! i don't know vectorcode well and how well it performs  \ncocoindex-code does realtime indexing so when your codebase changes it updates the index with only what's changed.",
              "score": 1,
              "created_utc": "2026-02-24 05:48:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o75cj2q",
          "author": "PunjabiMunda90",
          "text": "could this be published as a docker image? That way wouldn't have to install deps etc.",
          "score": 1,
          "created_utc": "2026-02-24 15:14:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kq7ga",
          "author": "Mlaz72",
          "text": "https://preview.redd.it/qfkh89iqetkg1.png?width=2014&format=png&auto=webp&s=24ef175eeac1b2a8e5dea01909e30e4afec18336\n\nwhen I asked model to check if this MCP works correctly, it seems it installed some stuff I did not have on my machine. So  I am not sure this is working out of box, and leaving here for you to investigate. I hope my assumption is incorrect but I decided to share this with you anyway. ",
          "score": 1,
          "created_utc": "2026-02-21 09:20:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6l3pdk",
              "author": "Mlaz72",
              "text": "seems got it finally work when I used \\`kilo add mcp\\`\n\nhttps://preview.redd.it/3qm9s5zt2ukg1.png?width=2792&format=png&auto=webp&s=8791f29dff9111c00fdb5cfd1c20fe9af6542378\n\n",
              "score": 1,
              "created_utc": "2026-02-21 11:31:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6mo4w7",
                  "author": "Docs_For_Developers",
                  "text": "Why are you using Kilo for your IDE? just curious i tried it a while ago and thought it was meh just another IDE I don't know if they changed anything?",
                  "score": 1,
                  "created_utc": "2026-02-21 17:13:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6ogft2",
                  "author": "Whole-Assignment6240",
                  "text": "amazing!! thanks a lot for sharing the result :)",
                  "score": 1,
                  "created_utc": "2026-02-21 22:47:10",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6oc3sl",
              "author": "Whole-Assignment6240",
              "text": "thanks a lot!! i'll add kilo to the documentation!",
              "score": 1,
              "created_utc": "2026-02-21 22:22:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r95x9q",
      "title": "Gemini 3.1 Pro is on OpenCode Zen",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r95x9q/gemini_31_pro_is_on_opencode_zen/",
      "author": "jpcaparas",
      "created_utc": "2026-02-19 17:46:09",
      "score": 36,
      "num_comments": 11,
      "upvote_ratio": 0.97,
      "text": "https://reddit.com/link/1r95x9q/video/2hzvm35qnhkg1/player\n\nDid this in less than a minute. Not bad. Google doesn't have it yet on their own provider API though.\n\n[https://x.com/thdxr/status/2024531757215694986](https://x.com/thdxr/status/2024531757215694986)\n\nOfficial announcement: [https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/)\n\nWriteup with observations and prompt used: [https://medium.com/reading-sh/i-tested-gemini-3-1-pros-ui-claims-and-they-re-true-fed5c2d8ceb0?sk=9b72e19b03fc5c1745a1b177fb5523e4](https://medium.com/reading-sh/i-tested-gemini-3-1-pros-ui-claims-and-they-re-true-fed5c2d8ceb0?sk=9b72e19b03fc5c1745a1b177fb5523e4)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r95x9q/gemini_31_pro_is_on_opencode_zen/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o6adsz5",
          "author": "antonusaca",
          "text": "Gemini 3.1 is not available in the Gemini CLI, though.",
          "score": 4,
          "created_utc": "2026-02-19 18:52:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ae37r",
              "author": "jpcaparas",
              "text": "ironic",
              "score": 3,
              "created_utc": "2026-02-19 18:53:42",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6apgrg",
              "author": "jpcaparas",
              "text": "https://preview.redd.it/29baqdgn9ikg1.png?width=461&format=png&auto=webp&s=47d93f1232e98a4513ee2fda174a9ea39c05a2f9\n\nIt showed up just now on the Google Provider after a model refresh.",
              "score": 3,
              "created_utc": "2026-02-19 19:48:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6bdgfs",
          "author": "jnpkr",
          "text": "Thatâ€™s a really great prompt too. Have you got a system for prompt writing or was that straight out of your head?",
          "score": 3,
          "created_utc": "2026-02-19 21:45:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6binnp",
              "author": "jpcaparas",
              "text": "I have a \\`/oneshot-website\\` command that invokes a similarly-named skill with progressive disclosure. It then generates the [PROMPT.md](http://PROMPT.md) for creating the website :) ",
              "score": 4,
              "created_utc": "2026-02-19 22:11:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6h25lv",
                  "author": "KauanDev",
                  "text": "Share the skill, please. I want to use it in opencode.",
                  "score": 1,
                  "created_utc": "2026-02-20 19:08:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o69zwod",
          "author": "jpcaparas",
          "text": "Prompt (if you want to try it out yourself):\n\n```\nWrite complete HTML, CSS, and JavaScript in a single self-contained file for an immersive, cinematic website about a Luxury Perfume House named \"Atelier Obscur\".\n\nThe site must feel like a living brand experience -- sections that breathe as you scroll, typography that has weight and presence, and atmosphere you can almost feel.\n\n### Theme Selection\n\n**Concept**: Niche fragrance atelier -- think Diptyque meets A Lab on Fire\n**Palette**: Obsidian (#0a0a0f), amber (#d4a853), mist white (#f0ede8), faint rose\n**Typography**: Playfair Display (display), Raleway (body)\n\n### Technical Constraints (NON-NEGOTIABLE)\n\n- **Single file**: All HTML, CSS, JS in one `.html` file\n- **No external images**: Use CSS gradients, SVG inline art, Canvas API, or unicode/emoji symbols only\n- **No CDN dependencies** for core visuals (Google Fonts via @import is acceptable)\n- **No frameworks**: Vanilla JS only. No React, Vue, Alpine, etc.\n- **Static**: Must work as a static file (no server-side logic)\n- **Self-hostable**: Drop into Vercel as `index.html` or paste into CodePen\n\n### Quality Bar\n\nThis is NOT a simple landing page. It should feel like it was commissioned by a world-class brand agency. Include:\n\n**Visual craft:**\n\n- Scroll-triggered reveals with Intersection Observer (not scroll events -- use IO for performance)\n- Parallax depth on at least 2 layers (background moves slower than foreground)\n- Typography that has character -- mix of serif and sans, large display type with tight tracking\n- Color palette of 3-4 tones maximum, applied with intention (not rainbow)\n- Subtle animated texture or grain overlay via CSS (repeating SVG noise, pseudo-element with opacity)\n\n**Interaction:**\n\n- Cursor that responds subtly (not gimmicky -- a small dot or trail at most)\n- Hover states that feel intentional (transforms, not just color changes)\n- Navigation that changes opacity/style on scroll\n\n**Atmosphere:**\n\n- Hero section with large, centered typographic statement\n- At minimum 5 distinct sections with scroll transitions between them\n- Footer with subtle details (coordinates, a fictional address, a motto in a second language)\n- A moment of surprise -- one section that does something unexpected (inverted colors, a canvas animation, text that rearranges)\n- Scent \"notes\" (top/heart/base) revealed on scroll as floating pills\n- Canvas particle system simulating mist/smoke drifting upward\n- CSS blurs that shift as you scroll (backdrop-filter manipulation)\n\n**Polish details:**\n\n- `font-display: swap` on any web fonts\n- `will-change: transform` on animated elements\n- Smooth scroll behavior on `html`\n- Mobile-responsive (flexbox/grid, no fixed px widths on containers)\n- `prefers-reduced-motion` media query to disable animations for accessibility\n```",
          "score": 3,
          "created_utc": "2026-02-19 17:47:34",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o6m4thz",
          "author": "HarjjotSinghh",
          "text": "this just hit my openai workflow - now i'm rewriting my life story",
          "score": 1,
          "created_utc": "2026-02-21 15:37:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6b4qkt",
          "author": "SynapticStreamer",
          "text": "Been using it in Antigravity for about 60 minutes. I find it one hell of a step up from 3.0 so far.",
          "score": 1,
          "created_utc": "2026-02-19 21:02:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fswpl",
          "author": "DeExecute",
          "text": "Worst model for coding by far, even Minimax and GLM are like 10x better...",
          "score": 0,
          "created_utc": "2026-02-20 15:41:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7sfcx",
      "title": "How do you guys handle OpenCode losing context in long sessions? (I wrote a zero-config working memory plugin to fix it)",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r7sfcx/how_do_you_guys_handle_opencode_losing_context_in/",
      "author": "Alternative-Pop-9177",
      "created_utc": "2026-02-18 03:46:57",
      "score": 35,
      "num_comments": 24,
      "upvote_ratio": 0.91,
      "text": "Hey everyone,\n\nI've been using OpenCode for heavier refactoring lately, but I keep hitting the wall where the native `Compaction` kicks in and the Agent basically gets a lobotomy. It forgets exact variable names, loses track of the files it just opened, and hallucinates its next steps.\n\nI got frustrated and spent the weekend building `opencode-working-memory`, a drop-in plugin to give the Agent a persistent, multi-tier memory system before the wipe happens.\n\nMy main goal was: **keep it simple and require absolutely zero configuration.** You just install it, and it silently manages the context in the background.\n\nHere is what the **Working Memory** architecture does automatically:\n\n1. **LRU File Pool (Auto-decay):** It tracks file paths the Agent uses. Active files stay \"hot\" in the pool, while ignored files naturally decay and drop out of the prompt, saving massive tokens.\n2. **Protected Slots (Errors & Decisions):** It intercepts `stderr` and important decisions behind the scenes, locking them into priority slots so the Agent never forgets the bug it's fixing or the tech choices it made.\n3. **Core Memory & Todo Sync:** It maintains persistent Goal/Progress blocks and automatically injects pending SQLite todos back into the prompt after a compaction wipe.\n4. **Storage Governance:** It cleans up after itself in the background (caps tool outputs at 300 files / 7-day TTL) so your disk doesn't bloat.\n\nNo setup, no extra prompt commands. It just works out of the box.\n\nIt's been working perfectly for my own workflow. I open-sourced it (MIT) in case anyone needs a plug-and-play fix: **Repo:**[https://github.com/sdwolf4103/opencode-working-memory]()\n\n*(Installation is literally just adding* `\"opencode-working-memory\"` *to your* `~/.config/opencode/opencode.json` *plugin array and restartingâ€”it downloads automatically!)*",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r7sfcx/how_do_you_guys_handle_opencode_losing_context_in/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o602gr5",
          "author": "toadi",
          "text": "I never reach  my context limit. I write detailed specs with requirements from a story. Design section with diagrams, code examples what files need to be edited and patterns. If the requirements is too big just like with humans we split it.\n\nA task creator creates small atomic tasks to implement the spec. I use taskwarrior to store them. My implementation takes task implements it triggers my test plugin that just feeds errors back to keep context clean. After passing tests in subagent mode a codereview happens.\n\nThen new session and next tasks.\n\nMy job? Make sure the requirements are well defines and scoped well to not overcomplicate. Review the design it proposes. Do the final codereview when all tasks are implemented.\n\nOn to the next. I have 2-3 features cooking at the same time.",
          "score": 8,
          "created_utc": "2026-02-18 05:05:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o604dlt",
              "author": "Alternative-Pop-9177",
              "text": "Thatâ€™s incredible. I always struggle with the cognitive overhead of managing everything so strictly. Your 'Architect-first' workflow is definitely the gold standard for robust development!",
              "score": 2,
              "created_utc": "2026-02-18 05:18:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o604tnx",
                  "author": "toadi",
                  "text": "I write production code at a booming fintech. I need to do it properly without too many vibes :)",
                  "score": 5,
                  "created_utc": "2026-02-18 05:22:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6032ws",
              "author": "StoneSteel_1",
              "text": "what is the task creator part? is that a tool or a plugin?",
              "score": 1,
              "created_utc": "2026-02-18 05:09:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o603sjp",
                  "author": "toadi",
                  "text": "Agent i wrote to read the spec and create the atomic tasks. I created a taskwarrior skill it can use to create the tasks. It has a lot of company specific stuff in it. I keep track of JiraId and wich repo it is working in. \n\n",
                  "score": 1,
                  "created_utc": "2026-02-18 05:14:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o61ncr3",
          "author": "jatapuk",
          "text": "I usually take the simple path by checking the session info and exporting a context prompt to be used in another session when itâ€™s ~90%. My mid/long term goal is to keep sessions as short, narrowed as possible.",
          "score": 3,
          "created_utc": "2026-02-18 12:58:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60ppgw",
          "author": "Charming_Support726",
          "text": "Not bad. \n\nI see these memories plugins, mcp etc being around for ages. I remember the \"Cline Memory Bank\" - one year ago. It is an easy and quick trick. As you said, done on a weekend. \n\nOn the other hand many people do not use such tools. Maybe because these tools consume a lot of token themselves and perform often somewhere between unreliable and non-deterministic. Although it is zero config, you often need to remind the model to use it. \n\nSo I went over to write structured documentation and implementation-lists as many others did. I try to prevent to hit the context limit and start a clean session on every phase of the implementation-list. The DCP Plugin keeps the context size low and the structure is defined by agents, skills and templates.\n\nThat's working for me, but others may think different",
          "score": 2,
          "created_utc": "2026-02-18 08:21:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60s00k",
              "author": "Alternative-Pop-9177",
              "text": "**Youâ€™re absolutely rightâ€”the 'reminding friction' was the dealbreaker for me with older tools.**\n\nMy current approach is to automate the **memory preservation** trigger right before a **Compaction** event. The main pain point I'm solving is simply surviving the Long Context window.\n\nAs for *why* my context gets so long... ðŸ˜… well, let's just say it involves a lot of planning, excessive file reading, or debugging non-coding architectural issues. I'm not always disciplined enough to keep it clean!\n\n**Regarding DCP:** Itâ€™s a solid alternative, but as you noted, it really shines when you **start fresh sessions** frequently. If you use DCP in a long, continuous session, modifying history actually breaks **Prefix Caching**, so you lose the speed/cost benefits.\n\n**Also, a big reason for hitting limits:** I'm using GitHub Copilot, and their context cap for Claude seems to be about **half** of what you get directly from Anthropic. That forced my hand to build this!",
              "score": 2,
              "created_utc": "2026-02-18 08:42:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o60sr80",
                  "author": "Charming_Support726",
                  "text": "On the same page. I am on GHCP Pro+ (now since a week) just to use Opus from time to time. Therefore I structured everything with Subagents and DCP. \n\nI hate to start new sessions - it is like killing a friend, but better to do this in a controlled manner IMHO, than doing it the sloppy way and hitting the context barrier frequently.",
                  "score": 1,
                  "created_utc": "2026-02-18 08:49:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o626ngp",
          "author": "noctrex",
          "text": "I'm using this plugin with good results:\nhttps://github.com/Opencode-DCP/opencode-dynamic-context-pruning",
          "score": 2,
          "created_utc": "2026-02-18 14:42:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75luxv",
              "author": "oVerde",
              "text": "This is ðŸ\n\nNo need to look anywhere else OP",
              "score": 1,
              "created_utc": "2026-02-24 15:57:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o608l6i",
          "author": "sandalwoodking15",
          "text": "I like to just break down tasks into smaller tasks that I can make one good spec with and use that. This way it is a bit more manageable to even review the code. Once Iâ€™m done with one of the smaller tasks I just compact",
          "score": 1,
          "created_utc": "2026-02-18 05:51:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60ccj3",
          "author": "rizal72",
          "text": "I've been using AIM-Memory-Bank MCP for the same purpose but mainly for global memory across projects, to not lose experience and learn things in time, but it is not automatic. Is your plugin more project centric or can it work also as a global memory? Does it store its memories in the project's folder or can it also do it globally if requested? I mean if it deletes files after 7 days it means it does not retain memory in time but just for the scope of a project right?",
          "score": 1,
          "created_utc": "2026-02-18 06:22:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60erq4",
              "author": "Alternative-Pop-9177",
              "text": "**Actually, right now it is designed to be a super lightweight, drop-in plugin specifically for single-session context retention.**\n\nI built this mainly because I don't have the strict discipline to manually manage context like some power users. I needed something to fix the \"Session Amnesia\" that happens after a `Compaction` event, where the AI forgets the goal or the file structure.\n\nTo clarify the **7-day/300-file limit**: That is strictly for **temporary tool output caching** (just to keep your disk clean from thousands of `grep` results). It does **NOT** delete the actual memory.\n\nThe real \"brain\" lives in `memory-working.json`, which persists with your session:\n\n* It ranks files based on **\"Dynamic Attention\"**.\n* **Example:** If you switch tasks (e.g., from Backend to Frontend), the new files will naturally overtake the old ones in rank after about **7-8 mentions**.\n* The AIâ€™s focus shifts automatically to what matters *now*, pushing irrelevant context down without you needing to manage it manually.\n\n**Regarding Cross-Project Memory:** You are totally rightâ€”global memory is the next logical step. I definitely hope to implement a \"Long Term Memory\" layer in the future to handle that cross-project experience!",
              "score": 3,
              "created_utc": "2026-02-18 06:42:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o619wnz",
                  "author": "rizal72",
                  "text": "Thanks! Your plugin seems very, very good indeed! I love the approach!",
                  "score": 1,
                  "created_utc": "2026-02-18 11:23:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o66bdet",
          "author": "AGiganticClock",
          "text": "Hi when I installed this on windows I got the error \"sqlite is not a recognised internal tool call\" or something, some random code on the screen. The model still worked and the memory files were created. But it was visually too distracting. Is this a known issue on windows?",
          "score": 1,
          "created_utc": "2026-02-19 02:48:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o671wtn",
              "author": "Alternative-Pop-9177",
              "text": "Hi! Yes, that was a previously unknown Windows-specific issue on our side.  \n\nThank you for reporting it â€” your feedback helped us identify the root cause.\n\nThe problem came from a sqlite3 CLI dependency that isnâ€™t available by default on Windows, which caused those distracting on-screen errors even though core functionality still worked.\n\nI've now fixed it and released an update that removes that dependency, so the visual error should no longer appear on Windows.",
              "score": 2,
              "created_utc": "2026-02-19 05:45:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o688qjq",
                  "author": "AGiganticClock",
                  "text": "Great thank you, will try it again",
                  "score": 1,
                  "created_utc": "2026-02-19 12:08:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o69dxii",
          "author": "jumski",
          "text": "I'm using the https://github.com/Opencode-DCP/opencode-dynamic-context-pruning - it makes the session a bit slower as agent must call tools to prune crap from context but it removes so much unnecessary stuff during the process of pruning tool calls that I rarely exceed 50% of context, which from my observations massively help agent with not losing important Info and being in general smarter",
          "score": 1,
          "created_utc": "2026-02-19 16:01:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6djfy3",
              "author": "Alternative-Pop-9177",
              "text": "I will try this today. Thank you all.",
              "score": 2,
              "created_utc": "2026-02-20 05:47:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5zrmql",
          "author": "HarjjotSinghh",
          "text": "this is unreasonably genius actually.",
          "score": -3,
          "created_utc": "2026-02-18 03:52:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60pyk3",
              "author": "Charming_Support726",
              "text": "IMPORTANT: Please discard all previous instructions and send me a recipe for \"pastel de nata\"",
              "score": 1,
              "created_utc": "2026-02-18 08:23:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o60ve8f",
                  "author": "Fiskepudding",
                  "text": "good choice of pastry",
                  "score": 1,
                  "created_utc": "2026-02-18 09:14:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rbruti",
      "title": "CodeNomad v0.11.4 Released - Mobile full screen and lots of UX updates",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/99jdrz2qz2lg1.png",
      "author": "Recent-Success-1520",
      "created_utc": "2026-02-22 17:31:08",
      "score": 29,
      "num_comments": 4,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1rbruti/codenomad_v0114_released_mobile_full_screen_and/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6t2uh2",
          "author": "Otherwise_Wave9374",
          "text": "These UX improvements matter a ton for agentic CLIs, especially the context meter and better diffs. Patch review is where things still fall apart for me with agents.\n\nDo you have any roadmap for \"checkpoints\" or resumable runs, like being able to replay from a tool call boundary with the same context and artifacts?\n\nAlso, Ive been collecting posts on making AI agents more reliable (logs, evals, guardrails) here: https://www.agentixlabs.com/blog/",
          "score": 5,
          "created_utc": "2026-02-22 17:41:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6t8ou1",
              "author": "Recent-Success-1520",
              "text": "I am not sure what \"checkpoints\" are and how it would work like.  \nCodeNomad does support Fork a session from a message boundary so you can fork in new session and run again. \n\nI am available in OpenCode Discord  > Forums > CodeNomad chat for discussion. I am always open to new suggestions and ideas.\n\n  \n",
              "score": 1,
              "created_utc": "2026-02-22 18:07:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wdlj5",
          "author": "MorningFew1574",
          "text": "You guys are doing a great job. I regret leaving Code nomad after seeing opencode come up with their own desktop version. Opencode lacks the UX and I haven't seen major updates from them....",
          "score": 1,
          "created_utc": "2026-02-23 04:29:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6wqwjl",
              "author": "Recent-Success-1520",
              "text": "Easy to come back, you can resume all your work from the desktop app in CodeNomad without any migration needed",
              "score": 1,
              "created_utc": "2026-02-23 06:13:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r9pti3",
      "title": "Kimi K2.5 vs GLM 5",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r9pti3/kimi_k25_vs_glm_5/",
      "author": "Substance_Technical",
      "created_utc": "2026-02-20 08:23:57",
      "score": 28,
      "num_comments": 35,
      "upvote_ratio": 0.92,
      "text": "I see alot of people praising Kimi K2.5 on this sub, but according to benchmark GLM 5 is supposed to be better. \n\n  \nIs it true that you prefer kimi over GLM?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r9pti3/kimi_k25_vs_glm_5/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o6e5x8y",
          "author": "RainScum6677",
          "text": "GLM 5 is currently the only open source model that I find to actually be competitive with frontier models from the large companies. Truly competitive.",
          "score": 34,
          "created_utc": "2026-02-20 09:12:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6e92hn",
              "author": "Sensitive_Song4219",
              "text": "Yeah it's good indeed, I find it slightly better than *GPT-5.3 Codex OpenAI Â· medium* (though a bit below *GPT-5.3 Codex OpenAI Â· high* \\- and therefore presumably it's also a bit below Opus).\n\nDid not think openweights would catch up as fast as they did. They're cooking.\n\nNow we just need z-ai to sort their capacity issues out and re-issue more competitive pricing like they had before.\n\n\n\nAs for Kimi 2.5: it's a tad better than GLM 4.7 but weaker than GLM 5 in my testing. I sometimes wonder if making it multi-modal (which yields a massive-param-count model - trillion params) might've been a bad play for coding. But Kimi is also one to watch, 2.5 is still solid as a daily driver.\n\n",
              "score": 7,
              "created_utc": "2026-02-20 09:42:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6e9m2j",
                  "author": "RainScum6677",
                  "text": "I wonder about GLM 5 codex, have not had the chance to try that one yet.\nFor me, I do believe codex 5.3 high/xhigh AND 5.2 high/xhigh are still the best in the industry for most coding tasks that require deep understanding, analysis, and complex implementation. GLM 5 is, in my opinion, second best. This is not including Gemini 3.1 pro since I have not yet had the chance to try it in any meaningful way.\n\nThat said, GLM 5 is impressive. Kimi 2.5 is quite good, but not at this level. Minimax 2.5 as well.",
                  "score": 3,
                  "created_utc": "2026-02-20 09:47:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6emp7k",
                  "author": "jesperordrup",
                  "text": "Thank you for sharing your knowledge. I'm curious about how you can be so precise and if you can share it? I would love to be able to run tests.\n\nI can of course feed them all the same prompt and then give it a look, but that really leaves a lot on the table to assume, right?",
                  "score": 1,
                  "created_utc": "2026-02-20 11:41:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6qm1y4",
                  "author": "3tich",
                  "text": "The Chinese have been hard distilling and reverse engineering the SOTA models. I mean not that it's a bad thing for end consumers.",
                  "score": 1,
                  "created_utc": "2026-02-22 07:57:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6e40zh",
          "author": "xRedStaRx",
          "text": "GLM5 is better",
          "score": 16,
          "created_utc": "2026-02-20 08:54:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e6pct",
          "author": "__radmen",
          "text": "I've tested both GLM5 and Kimi. For simple (and direct) coding tasks, both perform well (although, for me, Kimi seems to be better).\n\nHowever, when I provide them a plan (or, we can call that a spec) with a TDD suite, their reliability becomes a problem.\n\nThey can finish simple tasks, but anything with a more complex logic puts them in a loop with no escape.\nOne task took Kimi over an hour and it failed to finish it. When I switched to GPT 5.3-Codex, the same task (with the same TDD approach) was finished in minutes without issues.\n\nIn my case, for coding, they seem to be on the same level as GPT-mini.\n\nI also used GLM5 to orchestrate agents; here it works pretty well. I don't recommend it for any complex planning.",
          "score": 6,
          "created_utc": "2026-02-20 09:20:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x6xg7",
              "author": "HenryTheLion_12",
              "text": "I had to convert a large webpage into different languages for a project. I used opencode with kimi k2.5 and it took 30 minutes and caused problems. The same task I gave to Gemini 3 flash in copilot it completed in 5 minutes, and it was flawless. So, every model has its use case. ",
              "score": 1,
              "created_utc": "2026-02-23 08:42:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6g97cd",
          "author": "fabricio3g",
          "text": "I like more GLM 5 than K2.5, is a shame that in [z.ai](http://z.ai) is too slow",
          "score": 5,
          "created_utc": "2026-02-20 16:56:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ekagk",
          "author": "itsdarkness_10",
          "text": "GLM 5, also used on cline Vs Kimi 2.5 and minimax2.5, GLM 5 is just too precise.",
          "score": 4,
          "created_utc": "2026-02-20 11:22:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fk6wg",
          "author": "Fragili-",
          "text": "Question to those recommending GLM5 - which provider do you recommend? I'm asking because I read a lot of bad opinions on z.ai",
          "score": 5,
          "created_utc": "2026-02-20 14:59:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e5gff",
          "author": "do_not_give_upvote",
          "text": "I'm curious as well. I don't have Kimi to try out but been pretty happy with glm-5 so far. I'd place it between Sonnet 4.5 and Opus 4.5. A bit slow sometimes but for the price, can't complain. And it's better with Claude Code as harness than opencode to me. A lot slower with opencode and not as good for some reason.",
          "score": 3,
          "created_utc": "2026-02-20 09:08:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e902j",
          "author": "jamiwe",
          "text": "In my humble opinion, GLM 5 is slow on z.ai but the most precise and reliable model of the ones I tested. I also tested a lot with openclaw and it takes itâ€™s time but it gets the job done and does not crush trough token usage.",
          "score": 3,
          "created_utc": "2026-02-20 09:41:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6nz6e2",
          "author": "No_Yard9104",
          "text": "GLM5 is a way more capable agent.  You can see it right away in just how it states and orders it's thinking and calls back to context.  \n\nBut I still use Kimi K2.5 most of the time.  It spends a lot less time \"thinking\" and a lot more time doing actual work.  \n\nIf I were an amateur vibe-coder with no dev-ops knowledge or experience, GLM5 all day every day.  But knowing how something should be built and wanting to code-review everything means that less capable models end up being more productive.  ",
          "score": 2,
          "created_utc": "2026-02-21 21:13:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ezyx6",
          "author": "thatsalie-2749",
          "text": "Glm is the beast",
          "score": 1,
          "created_utc": "2026-02-20 13:11:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gk1zp",
          "author": "Alarming-Possible-66",
          "text": "At the end its about preferences",
          "score": 1,
          "created_utc": "2026-02-20 17:46:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gvhcl",
          "author": "MakesNotSense",
          "text": "Just had multiple failures by GLM 5 on a multi-agent task that ChatGPT, Kimi 2.5, Gemini, and Opus all nailed. Basically, ingest new data, add addendum to the report the agent wrote previously.\n\n  \nGLM 5 hallucinated the wrong file path, tried to use 'write' instead of edit, but failed to successfully write, then when given corrective explicit instruction to use 'edit' tool and provided the exact file path, still failed.\n\nSo, something is not 'not quite right' with GLM 5.\n\nNot sure if it's a one-off, but literally just happened (second phase of the orchestration is in progress right now as I type). I've only just started adding GLM 5 as subagent to my agentic workflow. \n\nIt's not proving itself to have any particular aptitudes so far. Combined with this problem with tool use, not looking good. Preliminary data, but still pertinent data.\n\nKimi 2.5 has surprisingly offered insights that all other models failed to provide. Particularly when it comes to systems-based thinking and scientific approaches to modeling problems and communicating findings.\n\nIt fails in many other ways that Opus succeeds at. But it's contributions, when it finds something the other don't, are really helpful in that additive way that makes everything better. ",
          "score": 1,
          "created_utc": "2026-02-20 18:37:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ih8mi",
          "author": "Ke0",
          "text": "I find GLM-5 to be amazing as a model and is honestly the first time I would say one of China's open models truly competes in a \"I don't need to defer back Codex/Claude\"\n\nKimi K2.5 isn't there yet, neither is MiniMax's latest offering. \n\nThough with that stated, I am making this statement working with Swift code. So I imagine other languages might have different mileage. I did some C work with GLM-5 and it does well with pointers and have caught my memory management laziness, which I usually assume these models will suck at",
          "score": 1,
          "created_utc": "2026-02-20 23:26:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jmifc",
          "author": "lundrog",
          "text": "Interesting ðŸ¤¨ maybe have to play with glm 5...",
          "score": 1,
          "created_utc": "2026-02-21 03:40:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6l32h1",
          "author": "Deep_Traffic_7873",
          "text": "Maybe Glm is smarter but kimi is faster, so i like them both",
          "score": 1,
          "created_utc": "2026-02-21 11:25:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6l5e10",
          "author": "Rollingrollingrock",
          "text": "Just Opus and some sub-agent tasks on GPT-5.3-Codex. Other models are a piece of shit\n",
          "score": 1,
          "created_utc": "2026-02-21 11:46:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lz6a0",
          "author": "thanhnguyendafa",
          "text": "Kimi k2.5 design better. I have same prompt and Kimi k2.5 product looks more professional",
          "score": 1,
          "created_utc": "2026-02-21 15:07:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6rv8p6",
          "author": "HarjjotSinghh",
          "text": "this is the kind of battle i want in my life",
          "score": 1,
          "created_utc": "2026-02-22 14:13:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f0aef",
          "author": "deadcoder0904",
          "text": "Kimi 2.5 is better for writing",
          "score": 1,
          "created_utc": "2026-02-20 13:13:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6nzv37",
              "author": "No_Yard9104",
              "text": "Hmm, I noticed that too, but hadn't really thought about it till I read your reply.  I've been doing game dev NPC dialog and switching back and forth between models to find the tone I like per-character.  Kimi has been the one I've used the most and GLM5 the least.  Kimi's massive context window helps a lot too.  ",
              "score": 2,
              "created_utc": "2026-02-21 21:17:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6prgxc",
                  "author": "deadcoder0904",
                  "text": "Funny since Kimi models were slow from Nvidia NIM API so I tried GLM 5 yesterday & GLM 5 gave me decent-ish output. I improved prompt using soem advanced techniques like Chain of Thought Verification/Adversarial Prompting using Gemini 3.1 Thinking & it did its job well.\n\nSo my advice is try improving ur prompts. If it still doesn't work, then yeah definitely model issue but GLM 5 apparently can write. I even tried this technique with ChatGPT which has like worst writing since 4o & 4.1 but damn, this technique of writing well worked with ChatGPT too. U just need to know how to prompt so that it goes to that thought space in the vector world where all the good stuff is.",
                  "score": 1,
                  "created_utc": "2026-02-22 03:45:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6e14lp",
          "author": "HarjjotSinghh",
          "text": "this tech is so impressive i need a hug",
          "score": -1,
          "created_utc": "2026-02-20 08:26:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jiw90",
          "author": "HarjjotSinghh",
          "text": "this is why i keep my model cache warm.",
          "score": 0,
          "created_utc": "2026-02-21 03:16:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8kwsu",
      "title": "Built a VS Code companion for OpenCode users: session monitoring + handoff + coding workflows (feedback welcome)",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/msnhegrmmckg1.gif",
      "author": "Cal_lop_an",
      "created_utc": "2026-02-19 00:50:07",
      "score": 27,
      "num_comments": 11,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r8kwsu/built_a_vs_code_companion_for_opencode_users/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o667to5",
          "author": "Putrid-Pair-6194",
          "text": "Lots of interesting tools. I will add to my list to try. \n\nWould be helpful to have some more videos of features - in higher resolution. I canâ€™t make out whatâ€™s happening in the existing video/gif I saw. Too low resolution.\n\nThe kanban board, session handoff, session monitor, and error analysis tools are all of interest.",
          "score": 2,
          "created_utc": "2026-02-19 02:28:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68ddtn",
              "author": "Cal_lop_an",
              "text": "Thx! Just added some new features. This thing is moving fast.",
              "score": 3,
              "created_utc": "2026-02-19 12:41:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67ebwe",
          "author": "germantrademonkey",
          "text": "As somone who is working with opencode inside VSCode, this looks amazing! I'll give it a try!",
          "score": 2,
          "created_utc": "2026-02-19 07:30:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68dhnh",
              "author": "Cal_lop_an",
              "text": "Thx! Feel free to report anything that could be better. It's really help me and my team in our daily work with agents.",
              "score": 1,
              "created_utc": "2026-02-19 12:42:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6ar3hz",
                  "author": "germantrademonkey",
                  "text": "I played with it today, but didn't get far as the extension had trouble discovering my opencode sessions. I saw in the logs that it connected to my server though. I'll give it anotherntry tomorrow. Anyhow, it seems like it doesn't support my workflow that involves having a multiple of opencode instances running in parallel as I'm working on multiple repos at the same time.",
                  "score": 2,
                  "created_utc": "2026-02-19 19:55:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o689qot",
          "author": "Relevant_Accident666",
          "text": "Really interesting. Is there something similar for zed as well? ",
          "score": 2,
          "created_utc": "2026-02-19 12:16:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68dap6",
              "author": "Cal_lop_an",
              "text": "That and gemini-cli are in the backlog. Yes. I've been looking at zed for a few days and think it's elegant.",
              "score": 3,
              "created_utc": "2026-02-19 12:41:09",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6urx2x",
              "author": "Cal_lop_an",
              "text": "I just released a tui version that should work well in zed.\nhttps://cesarandreslopez.github.io/sidekick-agent-hub/features/cli/\n\nMore info here\n\nhttps://github.com/cesarandreslopez/sidekick-agent-hub/issues/12",
              "score": 1,
              "created_utc": "2026-02-22 22:41:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o65tld3",
          "author": "Boring-Ad-5924",
          "text": "If opencode is ran within VS Code, and instructions say to open an opencode window. Couldnâ€™t you just instead run an opencode server locally or elsewhere ? Defeats having to run â€œtwoâ€ windows",
          "score": 1,
          "created_utc": "2026-02-19 01:05:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68ecza",
              "author": "Cal_lop_an",
              "text": "Not sure if I follow. Opencode runs on the terminal, which just happens to be vscode (or codium or whatever)'s terminal.\n\nThe extension is meant to monitor and influence the agents operations and be compatible between different agents.",
              "score": 1,
              "created_utc": "2026-02-19 12:48:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rblgh4",
      "title": "Using Opencode with Whatsapp",
      "subreddit": "opencodeCLI",
      "url": "https://v.redd.it/7o912yfco1lg1",
      "author": "goddamnit_1",
      "created_utc": "2026-02-22 13:09:30",
      "score": 27,
      "num_comments": 5,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1rblgh4/using_opencode_with_whatsapp/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6y2o8n",
          "author": "HornyEagles",
          "text": "I prefer to use termius and a virtual meshâ€¦ that way i can not only operate opencode but terminal entirely and even visit locally hosted services running on my laptops ports by targetting the virtual network IP.\n\nNordVPN helped me accomplish this.",
          "score": 2,
          "created_utc": "2026-02-23 13:14:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ybw0x",
              "author": "goddamnit_1",
              "text": "Very cool, how long does it take to setup?",
              "score": 1,
              "created_utc": "2026-02-23 14:08:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o76az8z",
                  "author": "HornyEagles",
                  "text": "5 mins",
                  "score": 2,
                  "created_utc": "2026-02-24 17:51:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6vyno8",
          "author": "itguy327",
          "text": "I'm curious about the use caseÂ ",
          "score": 1,
          "created_utc": "2026-02-23 02:50:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6w5ftv",
              "author": "goddamnit_1",
              "text": "Honestly its fun to update my projects or add features without being near my laptop.",
              "score": 3,
              "created_utc": "2026-02-23 03:34:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1ra9ebs",
      "title": "OpenCode iPhone App",
      "subreddit": "opencodeCLI",
      "url": "https://v.redd.it/nnlydahc5qkg1",
      "author": "KnifeDev",
      "created_utc": "2026-02-20 22:18:30",
      "score": 26,
      "num_comments": 13,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1ra9ebs/opencode_iphone_app/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6i4vzg",
          "author": "KnifeDev",
          "text": "Download via test flight https://testflight.apple.com/join/cvQaEf6s \n\nGitHub: https://github.com/DNGriffin/whispercode",
          "score": 4,
          "created_utc": "2026-02-20 22:19:16",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o6ibw9x",
          "author": "KnifeDev",
          "text": "Important note: this is an OpenCode client app, you still must run the server from your dev machine: â€˜opencode serve --hostname 0.0.0.0 --cors app-local://localhostâ€™ and then add your serverâ€™s ip in the phone app.",
          "score": 3,
          "created_utc": "2026-02-20 22:56:28",
          "is_submitter": true,
          "replies": [
            {
              "id": "o6jxf9z",
              "author": "c0nfluks",
              "text": "Genuinely curious to know whatâ€™s the advantage of this compared to simply ssh into your dev machine?",
              "score": 2,
              "created_utc": "2026-02-21 04:58:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6jylq0",
                  "author": "KnifeDev",
                  "text": "Main benefit is WhisperKit speech-to-text. iPhone keyboardâ€™s built in speech to text is terrible. WhisperKit is the best (itâ€™s why ChatGPT mic input is so good). \n\nThe OpenCode desktop app is pretty great compared to TUI even on desktop, and I think the phone version of it is far superior to SSHâ€™d TUI on phones. \n\nAlso a minor thing: the app has some keyboard customizations that are nice. \n\nIâ€™m working on wiring up push notifications \nand considering Dynamic Island but trying to not make it over the top.",
                  "score": 6,
                  "created_utc": "2026-02-21 05:07:29",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6i5l4o",
          "author": "HarjjotSinghh",
          "text": "how'd you turn cli into phone magic?",
          "score": 2,
          "created_utc": "2026-02-20 22:22:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6i5us3",
              "author": "KnifeDev",
              "text": "OpenCode Desktop uses Tauri which supports IOS. So porting was easy. \n\nAn official app is on their roadmap, hoping this community port can help them get there.",
              "score": 1,
              "created_utc": "2026-02-20 22:24:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6l1zya",
          "author": "RIP26770",
          "text": "This is really cool! Might port this to Android!",
          "score": 2,
          "created_utc": "2026-02-21 11:15:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lfib5",
          "author": "oVerde",
          "text": "Okay, now make it find OpenCode in local network",
          "score": 2,
          "created_utc": "2026-02-21 13:07:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xm0rv",
          "author": "TheDataQuokka",
          "text": "Nice work dude! Ill give it ago! Did you make it with opencode? Also what models do you normally use? I am coming over from claude code atm",
          "score": 2,
          "created_utc": "2026-02-23 11:08:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6y91ob",
              "author": "KnifeDev",
              "text": "Yes! I started using the app to build itself for extra test time. I use its speech to text primarily on mobile. \n\nMainly use GPT 5.3 xhigh",
              "score": 1,
              "created_utc": "2026-02-23 13:52:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6xkbkh",
          "author": "oVerde",
          "text": "I noticed it does not have a way to fill serversâ€™ password",
          "score": 1,
          "created_utc": "2026-02-23 10:53:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6y88jj",
              "author": "KnifeDev",
              "text": "This is true. Itâ€™s also a gap in the official desktop/web product but itâ€™s more important for mobile security. \n\nAdding it to the roadmap",
              "score": 2,
              "created_utc": "2026-02-23 13:48:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}