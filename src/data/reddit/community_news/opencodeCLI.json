{
  "metadata": {
    "last_updated": "2026-02-13 17:01:29",
    "time_filter": "week",
    "subreddit": "opencodeCLI",
    "total_items": 20,
    "total_comments": 156,
    "file_size_bytes": 160853
  },
  "items": [
    {
      "id": "1r00tsx",
      "title": "Thank you to the OpenCode maintainers",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r00tsx/thank_you_to_the_opencode_maintainers/",
      "author": "Far-Association2923",
      "created_utc": "2026-02-09 10:32:43",
      "score": 183,
      "num_comments": 22,
      "upvote_ratio": 0.99,
      "text": "Hey OpenCode folks,\n\nJust wanted to say thanks to everyone maintaining OpenCode and keeping it open source. Projects like this are rare. It is genuinely useful in day-to-day work, and it is also built in a way that lets other people actually build on top of it.\n\nI have been working on a cross-platform desktop app using Tauri, and running OpenCode as a local sidecar has been a huge help. Having a solid headless runtime I can rely on means I get to focus on the desktop experience, security boundaries, and local-first behavior instead of reinventing an agent runtime from scratch.\n\nA few things I really appreciate:\n\n* The CLI and runtime are practical and easy to ship, not just a demo.\n* The clear separation between the engine and the UI makes embedding possible.\n* The architecture makes it possible to build on top of OpenCode or embed it elsewhere, rather than having to fork the core runtime. (EDIT for clarity)\n\nAnyway, just a sincere thank you for the work you are doing. It is unglamorous, hard engineering, and it is helping other open-source projects actually ship. I also love the frequent updates. Keep up the great work!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r00tsx/thank_you_to_the_opencode_maintainers/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4evgkd",
          "author": "SparePartsHere",
          "text": "Yes, Opencode is an incredible product and I am very thankful for the work they are putting in. I really like the way Dax thinks about OC and generally OSS and the value it can provide to every developer, no matter how strange our personal workflows and quirks are.",
          "score": 14,
          "created_utc": "2026-02-09 10:43:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4exhus",
              "author": "Far-Association2923",
              "text": "Totally agree. That flexibility is what really stands out to me too. Everyone‚Äôs workflows are a bit weird in their own way, and having an OSS foundation that doesn‚Äôt force a single opinionated path makes a huge difference.",
              "score": 2,
              "created_utc": "2026-02-09 11:02:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4eww4b",
          "author": "HarjjotSinghh",
          "text": "open source = my favorite kind of caffeine",
          "score": 7,
          "created_utc": "2026-02-09 10:57:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4exphn",
              "author": "Far-Association2923",
              "text": "OSS for the people ‚òïÔ∏è",
              "score": 2,
              "created_utc": "2026-02-09 11:04:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4fsbxu",
          "author": "Superfishintights",
          "text": "It's great, just needs better sub agent/parallelisation/swarm support and it is an easy equal to codex/claude code with multi model support.",
          "score": 5,
          "created_utc": "2026-02-09 14:34:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4fx260",
              "author": "Far-Association2923",
              "text": "Interesting.. I actually ran into the same ‚Äúone agent can only do so much at once‚Äù limitation, and ended up building a simple orchestration layer into my app to solve it.\n\nThe inspiration for this was OpenClaw‚Äôs multi‚Äëagent setup: multiple agents working in parallel toward a shared goal, then folding their results back together.\n\nIn practice my setup looks like: a list of tasks -> one Orchestrator -> multiple worker agents. The Orchestrator assigns tasks concurrently (so research, extraction, code changes, verification, etc. can happen side‚Äëby‚Äëside), tracks progress, and then merges the outputs into a final answer/plan.\n\nOpencode could absolutely implement the same idea. They‚Äôd ***just*** need an orchestration layer that can run multiple sessions/tasks at the same time, handle coordination (who‚Äôs doing what), and then aggregate results. That‚Äôs basically the missing piece between a single agent session and a team of agents collaborating.\n\nThis does not require multiple opencode instances either.",
              "score": 2,
              "created_utc": "2026-02-09 14:59:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4kmb7e",
                  "author": "SparePartsHere",
                  "text": "That's what oh-my-opencode does already (and why people call it token-burner).",
                  "score": 1,
                  "created_utc": "2026-02-10 06:24:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4ie8d5",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2026-02-09 22:12:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4h3ghf",
          "author": "affalatoon",
          "text": "*Processing img a14hou5fhiig1...*",
          "score": 3,
          "created_utc": "2026-02-09 18:23:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rnxjt",
          "author": "bzBetty",
          "text": "Huge fan of the desktop app - lets me multitask over multiple projects, worktrees or just on the same dir.",
          "score": 2,
          "created_utc": "2026-02-11 08:43:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ymyqa",
          "author": "Few-Mycologist-8192",
          "text": "I really wish I could have create a post like this, it resonates with my feelings exactly. Thanks so much to their team. I guess it speaks for many people's hearts.",
          "score": 2,
          "created_utc": "2026-02-12 11:03:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ynxiz",
              "author": "Far-Association2923",
              "text": "The OSS community definitely needs more praise, especially when they are building such high quality products that are free to use. Hopefully they are earning some good income from the opencode zen servivces.",
              "score": 2,
              "created_utc": "2026-02-12 11:11:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4f5kf0",
          "author": "t4a8945",
          "text": ">The architecture leaves room for extensions and experimentation without needing to fork everything.\n\nI've hit a few walls trying to add my own little things to OpenCode though (like I wanted to add a \"time spent thinking\" timer on the UI and tried with Opus 4.6, 4.5 and also Sonnet ; they all said something like that would require forking the project)\n\nDid I miss something?\n\n(totally agree otherwise, OpenCode is my daily driver and I freaking love it)",
          "score": 2,
          "created_utc": "2026-02-09 12:10:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4f65ug",
              "author": "Far-Association2923",
              "text": "Some UI-level changes like a ‚Äútime spent thinking‚Äù timer would realistically require forking today unless you‚Äôre building your own layer on top of OpenCode and treating it more like a headless engine.\n\nWhen I said it leaves room for extensions, I was mostly thinking in terms of the runtime, protocol, and embedding side rather than direct UI customization of the upstream app. I probably should‚Äôve been clearer there.\n\nAlso‚Ä¶ the ‚Äútime spent thinking‚Äù timer is a great idea. If you don‚Äôt mind, I may shamelessly steal that concept for my own app üòÑ",
              "score": 3,
              "created_utc": "2026-02-09 12:15:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4fbp9w",
                  "author": "t4a8945",
                  "text": "Okay I understand what you were talking about now.\n\nYeah I'm surprised this is not a feature yet. It's very useful for me because I do lots of videos where I compare different models on the same prompts.\n\nI ended up having a bash utility, which I can launch with ! and the \"timer\". It automatically parses the logs from the opencode session and gives me the answer.\n\nI'd prefer to have it as a command within opencode, but couldn't make it work.",
                  "score": 2,
                  "created_utc": "2026-02-09 12:54:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4f4dwi",
          "author": "EchoesInBackpack",
          "text": "Is there any support channels available? Afair they mentioned in the docs that there is no profit margin on openzen",
          "score": 1,
          "created_utc": "2026-02-09 12:01:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4f5lio",
              "author": "Far-Association2923",
              "text": "I'm not aware of specific channels although if it's related to opencode software you can always post an issue on [github](https://github.com/anomalyco/opencode/issues). They have some pretty great free models on zen although the rate limiting can cut you off pretty quickly if you are not careful.",
              "score": 2,
              "created_utc": "2026-02-09 12:10:48",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4ff71l",
              "author": "lll1412",
              "text": "They offer a subscription service: [https://opencode.ai/black](https://opencode.ai/black)",
              "score": 2,
              "created_utc": "2026-02-09 13:17:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4p5nky",
          "author": "DeExecute",
          "text": "The web interface is unfortunately still in alpha state, but I also appreciate the core product.",
          "score": 1,
          "created_utc": "2026-02-10 22:29:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzdyu6",
      "title": "git worktree + tmux: cleanest way to run multiple OpenCode sessions in parallel",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/409pivw1waig1.png",
      "author": "kargnas2",
      "created_utc": "2026-02-08 16:51:12",
      "score": 103,
      "num_comments": 19,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qzdyu6/git_worktree_tmux_cleanest_way_to_run_multiple/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4bshu6",
          "author": "West-Ad-2051",
          "text": "maybe dumb question, but how do you get this sidebar on right in opencode?",
          "score": 3,
          "created_utc": "2026-02-08 22:01:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4bv3ac",
              "author": "gwawr",
              "text": "It's the in the list of commands. Default is ctrl-x then b",
              "score": 3,
              "created_utc": "2026-02-08 22:14:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4j6oan",
          "author": "cosarccos",
          "text": "I've made https://github.com/mhamza15/forest for this type of workflow.",
          "score": 3,
          "created_utc": "2026-02-10 00:47:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4adu5l",
          "author": "AndroidJunky",
          "text": "Thanks, great tip! I've been using the desktop version which has built-in workspace (git worktree) support. Use it every day but was struggling to replicate this in the TUI.",
          "score": 1,
          "created_utc": "2026-02-08 17:55:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4dc4dn",
              "author": "Soileau",
              "text": "I‚Äôm also an Opencode desktop guy and use workspaces as well.\n\nSomething I don‚Äôt like about it ‚Äî it doesn‚Äôt just sync with your git worktrees! It‚Äôs got like a SQLite DB that tracks worktrees that ‚Äúit‚Äù made separate from ones that you made.\n\nSo it you make a worktree on your own (or have other tools that use them) they don‚Äôt appear in opencode‚Äôs UI.\n\nBeen a big headache for me honestly.",
              "score": 2,
              "created_utc": "2026-02-09 03:08:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ckd5r",
          "author": "siddharth99",
          "text": "Quick question: could this or something like this work if I try to use it with remote vscode/cursor?",
          "score": 1,
          "created_utc": "2026-02-09 00:38:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4csdia",
          "author": "toadi",
          "text": "I have worktree skill in opencode. It gets handled automatically in through the workflow.\n\nOnly check code during a codereview. Using nvim with worktree plugin.",
          "score": 1,
          "created_utc": "2026-02-09 01:23:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4j99d4",
              "author": "Silent-Tie-3683",
              "text": "Looks interesting, can you share your development workflow? I'm really confused on how to automate the ci/cd workflows for AI Agents especially!",
              "score": 1,
              "created_utc": "2026-02-10 01:02:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4et1j8",
          "author": "sasha-zelts",
          "text": "That‚Äôs not really convenient imo",
          "score": 1,
          "created_utc": "2026-02-09 10:20:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4j0nyp",
          "author": "Fun_Philosophy_8248",
          "text": "Could u share what setting u using? Ia it vscode with plugins? Im only using opencode cli",
          "score": 1,
          "created_utc": "2026-02-10 00:12:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4j8ua9",
          "author": "ElPastinak",
          "text": "Working on a project right now with the goal, to use cheaper models e.g. gpt-oss-120B or Kimi 2.5 to solve smaller isolated code implementation. The idea is kinda similar to your approach using git trees, but in addition trying to automatically merge the code.",
          "score": 1,
          "created_utc": "2026-02-10 00:59:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jn9o1",
          "author": "aeroumbria",
          "text": "Do you need to set some tmux variables to keep all opencode UI functions working? Like toggling scrolling or mouse?",
          "score": 1,
          "created_utc": "2026-02-10 02:23:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4npxq6",
          "author": "sasha-zelts",
          "text": "I built an app to use opencode with side by side panels but with cursor‚Äôs ux, dunno if you guys would be interested..",
          "score": 1,
          "created_utc": "2026-02-10 18:28:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4o7nfm",
          "author": "Popular-Cranberry333",
          "text": "Work trees make a big mess ... I build this tool for myself...  \n[https://github.com/drummel/git-watchtower](https://github.com/drummel/git-watchtower)\n\nI've mainly been using it with many agent threads running in the cloud. I think it would work with OpenCode. Happy to make some updates if anything gets sticky.\n\n(also, just for fun, don't miss out on casino mode üé∞ :P)",
          "score": 1,
          "created_utc": "2026-02-10 19:49:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4pqpon",
          "author": "gsxdsm",
          "text": "OpenChamber",
          "score": 1,
          "created_utc": "2026-02-11 00:25:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4pv5tf",
          "author": "prassi89",
          "text": "Have you checked out [worktrunk](https://github.com/max-sixty/worktrunk)?",
          "score": 1,
          "created_utc": "2026-02-11 00:51:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4daws0",
          "author": "HarjjotSinghh",
          "text": "i'm actually building the next opencode now.",
          "score": -4,
          "created_utc": "2026-02-09 03:01:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4htgbt",
              "author": "toltenos",
              "text": "bro",
              "score": 1,
              "created_utc": "2026-02-09 20:29:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r0wgwr",
      "title": "PSA: Kimi.com shipped DarkWallet code in production. Stop using them.",
      "subreddit": "opencodeCLI",
      "url": "https://extended.reading.sh/stop-using-kimi-dotcom",
      "author": "jpcaparas",
      "created_utc": "2026-02-10 09:41:02",
      "score": 75,
      "num_comments": 18,
      "upvote_ratio": 0.6,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r0wgwr/psa_kimicom_shipped_darkwallet_code_in_production/",
      "domain": "extended.reading.sh",
      "is_self": false,
      "comments": [
        {
          "id": "o4pvb3c",
          "author": "cyh555",
          "text": "people who vibecobe don't really care tbh",
          "score": 3,
          "created_utc": "2026-02-11 00:52:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m0ckr",
          "author": "HarjjotSinghh",
          "text": "darkwallet looks better than my bank app.",
          "score": 5,
          "created_utc": "2026-02-10 13:28:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4l8mpn",
          "author": "TransitionSlight2860",
          "text": "interesting. they should be more cautious about how they expose their codebase without letting people aware. LMAO.",
          "score": 3,
          "created_utc": "2026-02-10 09:55:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4l8zky",
              "author": "jpcaparas",
              "text": "https://preview.redd.it/jfzlyw474nig1.png?width=1536&format=png&auto=webp&s=14beee6ed0c952e85e1f2c02d950849daed7d078\n\nNot their first rodeo. They haven't learned their lesson, and I don't think they have any intention to.",
              "score": 5,
              "created_utc": "2026-02-10 09:58:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4lely8",
                  "author": "Bob5k",
                  "text": "Sadly we can't just ban then in western world.\nI just got kicked from kimi subreddit for sayng a few negative things about their subscription model for Kimi code, so...\nI think as fast as they grew up - they'll be done (at least in eu / us) when people realize how shady they are lol.",
                  "score": 2,
                  "created_utc": "2026-02-10 10:50:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4p7kky",
          "author": "cutebluedragongirl",
          "text": "I for one know what it's like to constantly implement new features instead of fixing stuff.¬†",
          "score": 1,
          "created_utc": "2026-02-10 22:39:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tyoqe",
          "author": "HarjjotSinghh",
          "text": "i feel your pain - wifi security is fun.",
          "score": 1,
          "created_utc": "2026-02-11 17:23:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m2fo9",
          "author": "evilbarron2",
          "text": "How uncommon are failures like this? Has anyone audited say Google or Amazon‚Äôs or Tesla‚Äôs codebase for example? Is this really uncommon?",
          "score": -2,
          "created_utc": "2026-02-10 13:40:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mg9x9",
              "author": "mcowger",
              "text": "As a former Google SWE in this space - yes, various parts of our codebase were audited at least every 6 months.",
              "score": 7,
              "created_utc": "2026-02-10 14:54:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4mfgzl",
              "author": "jpcaparas",
              "text": "google and amazon both have soc2. \n\nthat's why kimi.com registered in SG. purely for optics and regulatory buffers but they don't have anything remotely close to audits done if they were say in the us",
              "score": 2,
              "created_utc": "2026-02-10 14:50:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4prz85",
                  "author": "sylfy",
                  "text": "PDPA is an analogue to GDPR, it‚Äôs not meant for this purpose. https://regulations.ai/regulations/singapore-summary this should give a more comprehensive overview of the regulatory approach specific to AI.",
                  "score": 0,
                  "created_utc": "2026-02-11 00:33:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4mpvzk",
              "author": "jpcaparas",
              "text": "https://preview.redd.it/0i4oikfktoig1.jpeg?width=1320&format=pjpg&auto=webp&s=27a684f7fb20e86a98af3e82556fcc585f4ea631",
              "score": 2,
              "created_utc": "2026-02-10 15:42:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r27hm2",
      "title": "GLM-5 is now on OpenCode (via Z.ai coding plan)",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r27hm2/glm5_is_now_on_opencode_via_zai_coding_plan/",
      "author": "jpcaparas",
      "created_utc": "2026-02-11 19:46:29",
      "score": 74,
      "num_comments": 29,
      "upvote_ratio": 0.96,
      "text": "https://preview.redd.it/5pstp85z5xig1.png?width=599&format=png&auto=webp&s=400616601878804d681c97da7fd1c4fbd8c6a48d\n\nRun \\`opencode models --refresh\\`\n\nHN thread: [https://news.ycombinator.com/item?id=46974853](https://news.ycombinator.com/item?id=46974853)\n\nWriteup: [https://extended.reading.sh/glm-5](https://extended.reading.sh/glm-5)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r27hm2/glm5_is_now_on_opencode_via_zai_coding_plan/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4uw05c",
          "author": "jpcaparas",
          "text": "I'll post some amateur feedback here once I've used it for a bit. Key comparison would be against GLM 4.7 üêå. I'm mostly interested about speed, tool-calling efficacy, and subagent orchestration.",
          "score": 8,
          "created_utc": "2026-02-11 19:59:05",
          "is_submitter": true,
          "replies": [
            {
              "id": "o4wujae",
              "author": "jpcaparas",
              "text": "My honest thoughts after a few hours of usage:\n\n1. Tool-calling efficacy: at par with K2.5 and Opus 4.6. Doesn't miss. This fucker is smart.\n2. Subagent orchestration: After disabling a couple of MCP servers, it performed well, so I think it *does* struggle quite a bit with middle-of-the-road context bloat. Note that I almost always exhaust my context usage at the end of a session due to heavy research tasks.\n3. Inference: (I'm on ultra, so YMMV), Almost at par with Kimi K2.5 on Synthetic. Not blazing fast, but definitely an improvement over GLM 4.7 on Z.ai.\n\nIf you are keen to try it out, please check out the writeup above first.",
              "score": 10,
              "created_utc": "2026-02-12 02:16:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4xdqg9",
                  "author": "keroro7128",
                  "text": "sorry What is Kimi 4.5Ôºü",
                  "score": 1,
                  "created_utc": "2026-02-12 04:17:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4uy7b8",
          "author": "Evening-Piglet-7471",
          "text": "rate limit‚Ä¶.",
          "score": 9,
          "created_utc": "2026-02-11 20:09:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xzrbd",
          "author": "Lpaydat",
          "text": "Thank you bro. I just realized that they drop glm 5 by this post. I can finally use my ultra plan now after leaving it idle for months üòÜ",
          "score": 3,
          "created_utc": "2026-02-12 07:19:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4y06gm",
              "author": "jpcaparas",
              "text": "Oh you'll love GLM-5, you betcha. GLM-4.7 on [Z.ai](http://Z.ai) was such a letdown.",
              "score": 2,
              "created_utc": "2026-02-12 07:23:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o529j0d",
                  "author": "Lpaydat",
                  "text": "It's amazing. GLM4.7 just barely worked for me. But this 5.0 is on another level. I haven't used it for coding tasks yet but reasoning tasks bring me really good results.",
                  "score": 1,
                  "created_utc": "2026-02-12 22:23:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4uynht",
          "author": "jpcaparas",
          "text": "https://preview.redd.it/iz5oaefiaxig1.png?width=1320&format=png&auto=webp&s=19c02cc867568398608906f0aeaefdfedd7d4907\n\nHoly shit it's so bad with subagent orchestration lmao. Even GLM 4.7 wasn't this bad.\n\nFor context, I'm having it do deep research. I'm on the Ultra plan btw.",
          "score": 5,
          "created_utc": "2026-02-11 20:11:53",
          "is_submitter": true,
          "replies": [
            {
              "id": "o4v0hzv",
              "author": "jpcaparas",
              "text": "https://preview.redd.it/vvdxzlm4cxig1.png?width=1384&format=png&auto=webp&s=7d76e99cda91266004a47d8ff4559bc27ec0a7d1\n\nGood reasoning and fact-checking skills.",
              "score": 5,
              "created_utc": "2026-02-11 20:20:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4yq5w8",
                  "author": "Living_Tax1592",
                  "text": "how have you found its context compaction and rot handling? i use ohmyopencode with op4.6 on max  and that context gets ripped through but its compaction and ability to mitigate rot is miles better than 4.5",
                  "score": 1,
                  "created_utc": "2026-02-12 11:30:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4ypowh",
              "author": "Living_Tax1592",
              "text": "have you tried this again after a prompt to \"be more fucking patient\"?",
              "score": 1,
              "created_utc": "2026-02-12 11:26:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4z5ga0",
          "author": "Ai_Pirates",
          "text": "But only max coding plan",
          "score": 2,
          "created_utc": "2026-02-12 13:19:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4vwnto",
          "author": "TwisTedUK",
          "text": "Used it via NanoGPT and god damn is it slow",
          "score": 1,
          "created_utc": "2026-02-11 22:58:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vxysv",
              "author": "jpcaparas",
              "text": "maybe because I'm on glm ultra I get peak male LLM inference?",
              "score": 1,
              "created_utc": "2026-02-11 23:05:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4xp37y",
                  "author": "xmnstr",
                  "text": "Peak male?!",
                  "score": 2,
                  "created_utc": "2026-02-12 05:44:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4vsfyt",
          "author": "SynapticStreamer",
          "text": "Anyone literally unable to get it to work? I keep getting \"rate limit reached.\"\n\nWow, never-mind. Looks like the coding plan literally doesn't even work with it: \"Only supports GLM-4.7 and historical text models\" despite being informed when I got the damn thing that new models would be included.",
          "score": 1,
          "created_utc": "2026-02-11 22:37:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4w7roh",
              "author": "Illustrious-Many-782",
              "text": "Agreed. Pretty crappy. I realize the cost is almost double, so just give different limits for glm-5 ... Problem solved.",
              "score": 3,
              "created_utc": "2026-02-12 00:00:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4wo4qm",
                  "author": "SynapticStreamer",
                  "text": "This seems reasonable. Like, I can't even access the free tier with my token? Like wtf.",
                  "score": 2,
                  "created_utc": "2026-02-12 01:37:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4wmvqd",
              "author": "Outrageous-Fan-2775",
              "text": "I'm on the coding plan and I've been using GLM 5 for 3-4 hours now with no rate limits. Could be a tier difference though.",
              "score": 2,
              "created_utc": "2026-02-12 01:30:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4wo1hb",
                  "author": "SynapticStreamer",
                  "text": "Likely. I'm on the cheap ass one.",
                  "score": 2,
                  "created_utc": "2026-02-12 01:37:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4wykwc",
                  "author": "epyctime",
                  "text": "its max only",
                  "score": 2,
                  "created_utc": "2026-02-12 02:40:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4uvc0e",
          "author": "Fearless-Elephant-81",
          "text": "When is synthetic gonna add it :3",
          "score": -1,
          "created_utc": "2026-02-11 19:55:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4uvo4d",
              "author": "jpcaparas",
              "text": "I suggest joining their Discord to get the latest updates. It's a great community. ",
              "score": 2,
              "created_utc": "2026-02-11 19:57:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4vbpih",
                  "author": "ahmetegesel",
                  "text": "why downvoted tho lol",
                  "score": 1,
                  "created_utc": "2026-02-11 21:15:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4uv1tk",
          "author": "HarjjotSinghh",
          "text": "that's exactly what i needed: open-source pain in a cli",
          "score": -13,
          "created_utc": "2026-02-11 19:54:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qyhiyt",
      "title": "Bringing Claude Code‚Äôs Agent Teams to Open Code via MCP",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qyhiyt/bringing_claude_codes_agent_teams_to_open_code/",
      "author": "vicdotso",
      "created_utc": "2026-02-07 16:02:17",
      "score": 61,
      "num_comments": 27,
      "upvote_ratio": 0.97,
      "text": "https://reddit.com/link/1qyhiyt/video/2a0tm3voc3ig1/player\n\nAfter Anthropic shipped Agent Teams in Claude Code, I got curious about how the coordination layer worked under the hood. After some back and forth with claude and a little reverse engineering, the coordination layer turns out to be a clever mix of tmux + file locks and undocumented cli arguments.\n\nSo I pulled it apart and reimplemented it as a standalone MCP server. Any MCP client can use it now, including\n\nopencode as seen in the demo video.\n\nHere's what the server exposes:\n\n\\- Team + spawning: create teams, spawn Claude Code teammates into tmux panes, graceful and forced shutdown.\n\n\\- Task coordination: ownership, status tracking, dependency graphs with cycle detection.\n\n\\- Messaging: DMs, broadcast, long-polling inbox, shutdown/plan-approval protocol.\n\n\\- Concurrency safety: file locks on inboxes and tasks, atomic config writes.\n\nRepo: [github.com/cs50victor/claude-code-teams-mcp](http://github.com/cs50victor/claude-code-teams-mcp)\n\nIt's early (v0.1.0) and I'd love as much feedback as possible specifically around tighter opencode integrations.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qyhiyt/bringing_claude_codes_agent_teams_to_open_code/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o442pfq",
          "author": "james__jam",
          "text": "And here i was wondering how long i need to wait before somebody ports it over to opencode üòÖ\n\nThank you kind sir! üòÅ",
          "score": 13,
          "created_utc": "2026-02-07 17:35:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o461r5z",
              "author": "DeExecute",
              "text": "It‚Äôs not ported to opencode it still spawn claude code‚Ä¶",
              "score": 4,
              "created_utc": "2026-02-07 23:57:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4aw85d",
                  "author": "vicdotso",
                  "text": "It is now! Just merged a couple PRs",
                  "score": 2,
                  "created_utc": "2026-02-08 19:20:57",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o444be8",
              "author": "vicdotso",
              "text": "ü´°  \nPRs , Github Issues and PRs are all welcome.",
              "score": 2,
              "created_utc": "2026-02-07 17:43:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o44hlg4",
          "author": "rothnic",
          "text": "This looks cool, I started a bit on this when they first announced it but didn't have time to fully explore their implementation, but i was working on it to avoid the dependency on claude code entirely. Is that not the idea with this?\n\nIdeally, you'd spawn an opencode server associated with a project/directory if there already isn't one available when starting up opencode since that avoids any mcp server duplication and your plugin can interact with any sessions, events, etc. You want a plugin that hooks into all the relevant events for making sure all the expected interactions work as expected and you can recover from any odd states.\n\nIf trying to have this work outside of the opencode server process, it's possible but i think it'll be more difficult. There are some other projects doing something similar and there is a ton of adapter work. Gastown, for example is one of those. ",
          "score": 4,
          "created_utc": "2026-02-07 18:48:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44ivfi",
              "author": "vicdotso",
              "text": "currently thinkering on an integration to support claude code and the opencode server natively. it's all just json files and tmux so it might be possilbe. will post an update here once i do.",
              "score": 3,
              "created_utc": "2026-02-07 18:54:57",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o46zwu6",
              "author": "philosophical_lens",
              "text": "Yeah, opencode server + sdk would be the ideal implementation I think.",
              "score": 1,
              "created_utc": "2026-02-08 03:30:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4awde9",
                  "author": "vicdotso",
                  "text": "I just merged this feature",
                  "score": 2,
                  "created_utc": "2026-02-08 19:21:40",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o461hmi",
          "author": "DeExecute",
          "text": "I am wondering if there isn‚Äôt better way without MCP as everyone is moving away from MCPs for good reasons.",
          "score": 5,
          "created_utc": "2026-02-07 23:56:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4775p8",
              "author": "vicdotso",
              "text": "you could technically use a cli - [https://github.com/cs50victor/mcpx](https://github.com/cs50victor/mcpx) or [https://github.com/philschmid/mcp-cli](https://github.com/philschmid/mcp-cli) ",
              "score": 1,
              "created_utc": "2026-02-08 04:19:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o473az9",
          "author": "MakesNotSense",
          "text": "The closest thing to Agent Teams in OpenCode right now, is my PR [https://github.com/anomalyco/opencode/pull/7756](https://github.com/anomalyco/opencode/pull/7756)\n\nDuring it's development I identified that the Parent-Child caller system needs a redesign in order to become multi-caller. A proper agent team can't occur without multi-caller support.\n\nThis is because currently, when an agent that isn't the Parent persists a session with a subagent, the subagent thinks the calling agent is the Parent.\n\nWhat that looks like:\n\nPrimary A tasks subagent A. Subagent A tasks Subagent B. Primary A tries to communicate with Subagent B, and Subagent B thinks it's talking to Subagent A.\n\nTo coordinate a team of agents, which are communicating, and orchestrating each others actions, you need them to be able to identify who they're talking to/with.\n\nI have a workaround system where agents write relay-files, where a sub-skill helps them know the relay-file protocol. It's part of a larger Agentic Collaboration Framework.\n\nI think a proper OpenCode implementation for Agent Teams needs first, to merge my PR, second to revamp the caller system so that it supports multi-callers.\n\nIt is getting tiresome that Anthropic releases something, and people think it's innovative, say they should copy it, but something better is already available for OpenCode, but the community just isn't paying attention or pitching in.\n\nI have a complete roadmap for agentic collaboration in development for OpenCode. The PR is just one small part of it. A critical part, but a small part. There's so much more that needs doing, and I'm just one newbie vibe coder who develops purely to build the tools that I need for litigation.\n\nEdit: decided to turn this comment into a GitHub Issue. [https://github.com/anomalyco/opencode/issues/12661](https://github.com/anomalyco/opencode/issues/12661) (\\[FEATURE\\]: Add Agent Teams Equivalent¬†#12661)",
          "score": 7,
          "created_utc": "2026-02-08 03:53:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4668ug",
          "author": "RelationshipAny1889",
          "text": "Any chance we can have this implemented to use only Open Code? Without having to use the Cloud Code at all.",
          "score": 3,
          "created_utc": "2026-02-08 00:24:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47792z",
              "author": "vicdotso",
              "text": "not sure how challenging this would be but i'm working on this.",
              "score": 6,
              "created_utc": "2026-02-08 04:20:21",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4ahzvc",
              "author": "vicdotso",
              "text": "I just added support for opencode. If you dont have claude code installed on your computer it should work.",
              "score": 2,
              "created_utc": "2026-02-08 18:14:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o44pc2w",
          "author": "idkwtftbhmeh",
          "text": "Amazing, thanks a lot",
          "score": 2,
          "created_utc": "2026-02-07 19:27:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o45gx1k",
          "author": "nadimtuhin",
          "text": "Looks cool, how is the token usage ?",
          "score": 2,
          "created_utc": "2026-02-07 21:55:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o477fxv",
              "author": "vicdotso",
              "text": "more agents / teammates  , more tokens",
              "score": 1,
              "created_utc": "2026-02-08 04:21:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o43v801",
          "author": "buggytheking",
          "text": "Sick.... I'll take a look. If it works well we need to put this in the main code. Are you working on something for that?",
          "score": 1,
          "created_utc": "2026-02-07 16:58:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43xcft",
              "author": "vicdotso",
              "text": "currently trying some approaches to see how feasible it is to integrate directly with the opencode server",
              "score": 1,
              "created_utc": "2026-02-07 17:08:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o450asf",
          "author": "idkwtftbhmeh",
          "text": "Is there a way to run this on windows?",
          "score": 1,
          "created_utc": "2026-02-07 20:25:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o479h2k",
              "author": "vicdotso",
              "text": "should just work with any mcp client, open an issue if it doesn't",
              "score": 2,
              "created_utc": "2026-02-08 04:36:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o49yeu3",
                  "author": "idkwtftbhmeh",
                  "text": "but tmux is linux only?",
                  "score": 1,
                  "created_utc": "2026-02-08 16:40:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o45aa9n",
          "author": "MarcoHoudini",
          "text": "It is similar to how oh my opencode does it. Maybe you could check there for inspiration. I wander maybe cc team got inspired by it and we are not backport but source)",
          "score": 1,
          "created_utc": "2026-02-07 21:20:00",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qz5hor",
      "title": "OpenCode Remote: monitor and control your OpenCode sessions from Android (open source)",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qz5hor/opencode_remote_monitor_and_control_your_opencode/",
      "author": "giuliastro",
      "created_utc": "2026-02-08 10:21:55",
      "score": 40,
      "num_comments": 15,
      "upvote_ratio": 0.93,
      "text": "Hey everyone üëã\n\nI just released OpenCode Remote v1.0.0, an open-source companion app to control an OpenCode server from your phone.\n\nThe goal for is simple: when OpenCode is running on my machine, I wanted to check progress and interact with sessions remotely without being tied to my desk.\n\nWhat it does\n- Connect to your OpenCode server (Basic Auth supported)\n- View sessions and statuses\n- Open session details and read message output\n- Send prompts directly from mobile\n- Send slash commands by typing /command ...\n\nStack\n- React + TypeScript + Vite (web-first app)\n- Capacitor (Android packaging)\n- GitHub Actions (cloud APK builds)\n\nRepo\nhttps://github.com/giuliastro/opencode-remote-android\n\nNotes\n- Designed for LAN first, but can also work over WAN/VPN if firewall/NAT/security are configured correctly.\n- Browser mode may require CORS config on the server; Android APK is more robust thanks to native HTTP.\n\nIf you try it, I‚Äôd love feedback on UX, reliability, and feature ideas üôå\n\nEDIT: v1. 1.0 is out now, redesigned the interface. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qz5hor/opencode_remote_monitor_and_control_your_opencode/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o49jdxh",
          "author": "Tr1ckyDes1gner",
          "text": "Now I'll be working on my project while sitting on the toilet) But seriously, it's a great idea!!!",
          "score": 4,
          "created_utc": "2026-02-08 15:26:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jluan",
              "author": "wanabean",
              "text": "Great for dumps too",
              "score": 1,
              "created_utc": "2026-02-10 02:15:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o48fuge",
          "author": "AGiganticClock",
          "text": "This is great!",
          "score": 2,
          "created_utc": "2026-02-08 10:54:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48o58e",
          "author": "jixbo",
          "text": "Really cool! Have your first star, just connected it and looks promising! Will use tomorrow.",
          "score": 2,
          "created_utc": "2026-02-08 12:09:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o48si6c",
              "author": "giuliastro",
              "text": "Thank you friend, much appreciated",
              "score": 1,
              "created_utc": "2026-02-08 12:44:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4cjvja",
          "author": "Putrid-Pair-6194",
          "text": "The newer gui is a nice improvement.",
          "score": 2,
          "created_utc": "2026-02-09 00:35:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4q44z7",
          "author": "DylanDekes",
          "text": "Great stuff, love to see more being done for open code!",
          "score": 2,
          "created_utc": "2026-02-11 01:45:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r21a2",
              "author": "giuliastro",
              "text": "I totally agree, OpenCode is so powerful and versatile",
              "score": 1,
              "created_utc": "2026-02-11 05:28:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o48rj9r",
          "author": "EitherMen",
          "text": "Can you make a smart watch app to control OpenCode from an android smart watch üòÑ",
          "score": 4,
          "created_utc": "2026-02-08 12:36:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49h2pz",
          "author": "cutebluedragongirl",
          "text": "I wish I was smart enough to assess security...¬†",
          "score": 1,
          "created_utc": "2026-02-08 15:14:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4c4rgo",
              "author": "Embarrassed-Mail267",
              "text": "Just come the repo and ask an agent to assess for you and teach you along the way",
              "score": 2,
              "created_utc": "2026-02-08 23:08:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4c10qj",
          "author": "Ok-Connection7755",
          "text": "Really nice repo, have you checked out openchamber? It's really nice!",
          "score": 1,
          "created_utc": "2026-02-08 22:46:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49vew7",
          "author": "Fine-Yogurt4481",
          "text": "Sounds great, will this works with OhMyOpencode?",
          "score": 1,
          "created_utc": "2026-02-08 16:26:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4bbkl0",
              "author": "giuliastro",
              "text": "I actually don't know OhMyOpencode. Just read that it installs as a plugin so I don't see why it shouldn't work.",
              "score": 1,
              "created_utc": "2026-02-08 20:37:07",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4by430",
              "author": "AkiDenim",
              "text": "Eww",
              "score": 1,
              "created_utc": "2026-02-08 22:31:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qzswfa",
      "title": "I built an OpenCode plugin so you can monitor and control OpenCode from your phone. Feedback welcome.",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qzswfa/i_built_an_opencode_plugin_so_you_can_monitor_and/",
      "author": "ApprehensiveLoad2962",
      "created_utc": "2026-02-09 03:08:11",
      "score": 38,
      "num_comments": 11,
      "upvote_ratio": 0.87,
      "text": "TL;DR ‚Äî I added mobile support for OpenCode by building an open-source plugin. It lets you send prompts to OpenCode agents from your phone, track task progress, and get notified when jobs finish.\n\n* GitHub (plugin): [https://github.com/vicoa-ai/opencode-vicoa](https://github.com/vicoa-ai/opencode-vicoa)\n* App: [https://vicoa.ai/](https://vicoa.ai/) (iOS and web for now, Android coming soon, freemium)\n\n\n\n**Why I made it**\n\nVibe coding with OpenCode is great, but I need to constantly wait for the agents to finish. It feels like being chained to the desk, babysitting the agents.\n\nI want to be able to monitor the agent progress and prompt the OpenCode agents even on the go. \n\n**What it does**\n\n* Connects OpenCode to a mobile client (Vicoa)\n* Lets you send prompts to OpenCode agents from your phone\n* Real-time sync of task progress\n* Send task completion or permission required notifications\n* Send slash commands\n* Fuzzy file search on the app\n\nThe goal is to treat agents more like background workers instead of something you have to babysit.\n\n**Quick Start (easy)**\n\nThe integration is implemented as an OpenCode plugin and is fully open-source.\n\nAssuming you have OpenCode installed, you just need to install Vicoa with a single command: \n\n    pip install vicoa\n\nthen just run:\n\n    vicoa opencode\n\nThat‚Äôs it. It automatically installs the plugin and handles the connection.\n\nLinks again: \n\n* GitHub:¬†[https://github.com/vicoa-ai/opencode-vicoa](https://github.com/vicoa-ai/opencode-vicoa)\n* Documentation: [https://vicoa.ai/docs/agents/opencode](https://vicoa.ai/docs/agents/opencode)\n\nThanks for reading! Hope this is useful to a few of you.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qzswfa/i_built_an_opencode_plugin_so_you_can_monitor_and/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4dci0b",
          "author": "HarjjotSinghh",
          "text": "oh brother, you're finally letting me actually use opencode.",
          "score": 4,
          "created_utc": "2026-02-09 03:10:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ebrgq",
          "author": "t4a8945",
          "text": "Except Vicoa is only 50 messages free and then $13/mo. No thanks¬†",
          "score": 5,
          "created_utc": "2026-02-09 07:30:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4edp53",
          "author": "Hozukr",
          "text": "Another paid copy of https://happy.engineering/ (free)?",
          "score": 5,
          "created_utc": "2026-02-09 07:49:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ejx24",
              "author": "ApprehensiveLoad2962",
              "text": "It is not a copy, not even built from that. UI, functionality, and how it works for OpenCode are different. \n\nYou might still need to host it by yourself for that for more reliable service. ",
              "score": 2,
              "created_utc": "2026-02-09 08:49:52",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4pw703",
              "author": "adolf_twitchcock",
              "text": "copy of opencode web --hostname [0.0.0.0](http://0.0.0.0)",
              "score": 1,
              "created_utc": "2026-02-11 00:57:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4f7iv0",
          "author": "throwaway12012024",
          "text": "oh man, i am trying to write exactly this service, but using telegram (not a new app)",
          "score": 2,
          "created_utc": "2026-02-09 12:25:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4h9b9m",
          "author": "mprogano",
          "text": "Website loads a blank white page on my phone",
          "score": 1,
          "created_utc": "2026-02-09 18:50:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4di4pp",
          "author": "rjyo",
          "text": "Really cool to see someone else tackling this problem. I built something similar for Claude Code called Moshi -- it is a mobile terminal app that lets you run Claude Code sessions from your phone over SSH. The \"chained to the desk babysitting agents\" feeling is exactly what pushed me to build it too. Being able to kick off tasks, approve permissions, and check progress from anywhere completely changed how I work with AI coding agents. The notification angle you have with Vicoa is smart, that is one of the biggest pain points. Curious how you handle the real-time sync -- are you using websockets or polling?",
          "score": 1,
          "created_utc": "2026-02-09 03:42:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4dnc73",
          "author": "shikima",
          "text": "I was looking for something like this, I gonna give it a try tomorrow",
          "score": 1,
          "created_utc": "2026-02-09 04:15:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4dlam7",
          "author": "Otherwise_Wave9374",
          "text": "This is a super practical take, agents are way nicer when they behave like background workers instead of something you have to babysit in a terminal. The notifications + \"permission required\" flow is especially smart.\n\nHow are you thinking about security for the mobile client, like scoping which tools the agent can call and making sure you can revoke sessions quickly?\n\nAlso, I have been tracking patterns for running agents safely in production (permissions, approvals, audits) here: https://www.agentixlabs.com/blog/ - would love to compare notes.",
          "score": 0,
          "created_utc": "2026-02-09 04:02:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzgfx1",
      "title": "CodeNomad v0.10.1 - Worktrees, HTTPS, PWA and more",
      "subreddit": "opencodeCLI",
      "url": "https://v.redd.it/1j2ffcb6cbig1",
      "author": "Recent-Success-1520",
      "created_utc": "2026-02-08 18:22:24",
      "score": 38,
      "num_comments": 2,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qzgfx1/codenomad_v0101_worktrees_https_pwa_and_more/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4l48gm",
          "author": "bzBetty",
          "text": "Nice to see someone making a Windows compatible, will have to compare it to OpenCode",
          "score": 1,
          "created_utc": "2026-02-10 09:12:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4cyibk",
          "author": "oVerde",
          "text": "Not CLI ):",
          "score": -1,
          "created_utc": "2026-02-09 01:57:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2psy1",
      "title": "I just got banned from gemini :)",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r2psy1/i_just_got_banned_from_gemini/",
      "author": "Eastern-Guess-1187",
      "created_utc": "2026-02-12 10:17:46",
      "score": 37,
      "num_comments": 58,
      "upvote_ratio": 0.94,
      "text": "I know that is something that they warn. :) I am afraid of being banned from claude too.. so I just use gpt 5.3 codex in opencode now. which models should I use now? and what's your workflow? I am using omo slim.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r2psy1/i_just_got_banned_from_gemini/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o50b3fa",
          "author": "xmnstr",
          "text": "Happened to me too. If you're in the EU please file a DMA/DSA complaint, not allowing third party access to Antigravity is likely a breach of EU law. Additionally, just banning people without any notice and no method for appeal is also a very likely breach of EU consumer laws.\n\nThey are under investigation for this behavior and now is the perfect time to provide more information about their anticompetitive and anticonsumer actions!",
          "score": 14,
          "created_utc": "2026-02-12 16:49:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50n0ah",
              "author": "Villain_99",
              "text": "What‚Äôs the process ?",
              "score": 5,
              "created_utc": "2026-02-12 17:46:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o50tjtt",
                  "author": "xmnstr",
                  "text": "I'm not quite sure yet, but looking into it.",
                  "score": 2,
                  "created_utc": "2026-02-12 18:16:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4yk31e",
          "author": "Skquark",
          "text": "I also got banned from Gemini today, didn't expect that. I've been using the opencode-antigravity-auth plug-in to use Claude with Antigravity because I've been running out of my Claude Max 20x weekly limit way too quickly, and I've been paying for Gemini ultra for $250 a month which I hardly used because I just didn't like Gemini 3 Pro nearly as much as I expected, so I thought it was safe to supplement my usage and take advantage of that subscription. I'm writing a letter of appeal to Google in hopes that they might grant me a pardon, but I don't expect much.\n\nI would cancel my Gemini subscription and pay Anthropic $400 a month instead if I could so I don't have to worry about running out of my Opus limits, but that's not even an option. Apparently it's against their terms of service to have two Max accounts, which is really lame. Now I'm being forced to use codex to supplement my addiction, but it's just not satisfying my itch. I guess I have to lean more on Kimi K2.5 and now GLM-5 as my fallbacks. What's a full-time independent developer to do? I've been going all in to take my commercial project I've been working on for so long to completion, can't slow down now...",
          "score": 5,
          "created_utc": "2026-02-12 10:37:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zqril",
              "author": "bigh-aus",
              "text": "At $1000 every 4 months, I'd consider trying out kimi k2.5 on cloud, and if it's good for your use case drop the money on a mac studio.",
              "score": 5,
              "created_utc": "2026-02-12 15:14:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4zyo86",
              "author": "HistorianIll5959",
              "text": "Can‚Äôt get a Max account under friend or family members name and just use your card?",
              "score": 1,
              "created_utc": "2026-02-12 15:52:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o50hmbo",
              "author": "HotRelationship1127",
              "text": "I wonder how they knew to ban you. Can you post whatever email announcement they made to you? Maybe there are some clues.",
              "score": 1,
              "created_utc": "2026-02-12 17:20:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55qmdx",
                  "author": "powerfulparadox",
                  "text": "If the prompts and headers from the harness aren't identical, it can be as simple as comparing against expected incoming information. After that, I'm sure there can be behavioral differences that are observable.",
                  "score": 1,
                  "created_utc": "2026-02-13 13:18:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o538y8b",
              "author": "DeathShot7777",
              "text": "Antigravity auth wasnt working for claude models last time i checked. Does it work now? I tried it around a week ago",
              "score": 1,
              "created_utc": "2026-02-13 01:46:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o54cewn",
              "author": "ZeroBraneZ",
              "text": "Brother how TF are you running out of Claude max 20x‚Ä¶. Like that‚Äôs the first place I‚Äôd look..",
              "score": 1,
              "created_utc": "2026-02-13 06:16:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o561mau",
                  "author": "Skquark",
                  "text": "Dude, I use up 90% of my weekly 20x in about 3-4 days, especially now with Opus 4.6... I'm full time, running 2-4 agents on my giant projects simultaneously, and would be doing more but trying to pace myself and conserve my tokens.. Wish I could tell ya the projects I'm working on obsessively, but keeping my mouth shut until my commercial launches.. Also using Codex Max and Kimi K2.5 at the same time on different sections, but Claude is my main man..",
                  "score": 1,
                  "created_utc": "2026-02-13 14:18:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4ymx96",
              "author": "Desperate-Bath5208",
              "text": "Were you banned for using the Gemini Opencode Plugin or the Antigravity Opencode Plugin?",
              "score": 1,
              "created_utc": "2026-02-12 11:02:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ys7u3",
                  "author": "Skquark",
                  "text": "It was for using the Antigravity opencode plug-in and using it primarily to access Opus 4.6... I also had the Gemini open code plug-in, but I never really used that since I had the Gemini CLI that I could use anyways, but that didn't let you use anthropic sadly, and I caught Gemini 3 way too many times screwing up my code and not understanding what it was doing in my monorepo. I liked the opencode interface better than the Antigravity IDE, especially because it wasn't maintaining a reliable connection with my SSH to work on through their application. Do they really have to be so strict about their terms of services? Seems territorial...",
                  "score": 2,
                  "created_utc": "2026-02-12 11:47:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ytm7o",
                  "author": "Eastern-Guess-1187",
                  "text": "I was using both. ",
                  "score": -1,
                  "created_utc": "2026-02-12 11:58:53",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4yu25c",
              "author": "Eastern-Guess-1187",
              "text": "yeah I am using codex gpt 5.3 but its not like gemini 3 or opus 4.6. it feels it's dumber ",
              "score": 0,
              "created_utc": "2026-02-12 12:02:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4zdm43",
                  "author": "Character_Cod8971",
                  "text": "How can GPT-5.3-Codex be dumber than Gemini 3 or Opus 4.6?",
                  "score": 1,
                  "created_utc": "2026-02-12 14:05:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4yltbg",
              "author": "aitorserra",
              "text": "Why they banned you?",
              "score": 0,
              "created_utc": "2026-02-12 10:52:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ysdq1",
                  "author": "Skquark",
                  "text": "Because apparently they don't like it when you use third-party software for accessing their services unless you're using API key and not your subscription... Same with Anthropic.",
                  "score": 5,
                  "created_utc": "2026-02-12 11:49:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4ywwjz",
              "author": "Key_Mousse_8034",
              "text": "BTW how are you gonna switch between claude accounts? Because I'm thinking of doing the same. Just 2 claude subscriptions üòÄ",
              "score": 0,
              "created_utc": "2026-02-12 12:23:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55t4pu",
                  "author": "unnamedb",
                  "text": "try cc switch",
                  "score": 1,
                  "created_utc": "2026-02-13 13:32:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ymxf4",
          "author": "Desperate-Bath5208",
          "text": "Were you banned for using the Gemini Opencode Plugin or the Antigravity Opencode Plugin?",
          "score": 2,
          "created_utc": "2026-02-12 11:03:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ytnk0",
              "author": "Eastern-Guess-1187",
              "text": "I was using both bro",
              "score": 3,
              "created_utc": "2026-02-12 11:59:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o521yyt",
          "author": "HarjjotSinghh",
          "text": "what's next when gemini bans you, a new ai god named my boss?",
          "score": 1,
          "created_utc": "2026-02-12 21:47:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52ler8",
          "author": "dyzhdyzh",
          "text": "Got banned too. The only reason I got their subscription was to use their Opus with OpenCode.\nI have Copilot subscription from work, but the context window is crippled on the most models, and I exhaust the non-premium quota in a few days of coding.\nI guess I'll stick to Synthetic's models then. Kimi K2.5 is fairly good. As many others said, somewhere between Sonnet and Opus. Also, GLM-5 will be available soon.",
          "score": 1,
          "created_utc": "2026-02-12 23:27:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54i48f",
              "author": "YayaBruno",
              "text": "I've been using Kimi K2.5 via Nano-GPT, but it's quite slow, How do you see its speed at Synthetic? I've been considering switching to it. Also, how do you find the rate limits? Are they too restrictive?",
              "score": 1,
              "created_utc": "2026-02-13 07:05:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o53ymeh",
          "author": "lundrog",
          "text": "Synthetic.new has a waiting list but be a good option. Dm me for a referral if interested",
          "score": 1,
          "created_utc": "2026-02-13 04:30:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56rl6b",
              "author": "Halfwalker",
              "text": "I hadn't heard of Synthetic before, just took a look. Their SignUp link is there and looks to be working ?  What does a referral get you ?",
              "score": 1,
              "created_utc": "2026-02-13 16:26:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ytjwh",
          "author": "krimpenrik",
          "text": "Use GitHub copilot access to multiple models",
          "score": 1,
          "created_utc": "2026-02-12 11:58:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51wi6z",
              "author": "aydgn",
              "text": "Are you using that way?",
              "score": 1,
              "created_utc": "2026-02-12 21:21:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o54xy8a",
              "author": "oVerde",
              "text": "With only 128k of context window",
              "score": 1,
              "created_utc": "2026-02-13 09:32:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4yivea",
          "author": "Sukkii",
          "text": "I did too, yesterday, and am also keen for recommendations. Going the API route (e.g. open router) is just too steep, what other coding plans are available?",
          "score": 1,
          "created_utc": "2026-02-12 10:25:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zdww5",
              "author": "Character_Cod8971",
              "text": "Were you banned for using the Gemini Opencode Plugin or the Antigravity Opencode Plugin?",
              "score": 0,
              "created_utc": "2026-02-12 14:07:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4zneni",
                  "author": "Sukkii",
                  "text": "Using opencode-antigravity-auth",
                  "score": 3,
                  "created_utc": "2026-02-12 14:57:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4yr9gu",
          "author": "t1maccapp",
          "text": "Same:\n\nGemini has been disabled in this account for violation of Terms of\n    Service. If you believe this is an error, please contact Google Cloud Support, or email\n    gemini-code-assist-user-feedback@google.com.",
          "score": 1,
          "created_utc": "2026-02-12 11:40:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4yt979",
              "author": "benchb",
              "text": "can you explain, which plug in you used and what did you do ?",
              "score": 1,
              "created_utc": "2026-02-12 11:56:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o519q3t",
                  "author": "t1maccapp",
                  "text": "Was using https://github.com/NoeFabris/opencode-antigravity-auth in a pretty chill manner. Like 5-10 requests per day maybe. Both gemini 3 pro and opus 4.5.\n\nI've managed to use opus 4.6 couple of times, until I got banned yesterday.\n\nI don't think I've ever reached the quota limit or even used half of it.",
                  "score": 2,
                  "created_utc": "2026-02-12 19:32:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4z0anv",
              "author": "Eastern-Guess-1187",
              "text": "Emailed and I am waiting for the result",
              "score": 1,
              "created_utc": "2026-02-12 12:46:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o51ae2u",
                  "author": "t1maccapp",
                  "text": "Same, said I'm sorry, won't do ever again. \n\nNot like I care much though, I don't see me leaving opencode, will just probly use Chinese models.",
                  "score": 1,
                  "created_utc": "2026-02-12 19:35:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4zdoxj",
              "author": "Character_Cod8971",
              "text": "Were you banned for using the Gemini Opencode Plugin or the Antigravity Opencode Plugin?",
              "score": 1,
              "created_utc": "2026-02-12 14:06:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o519a3b",
                  "author": "t1maccapp",
                  "text": "For this one https://github.com/NoeFabris/opencode-antigravity-auth",
                  "score": 1,
                  "created_utc": "2026-02-12 19:30:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o52xqzy",
          "author": "cutebluedragongirl",
          "text": "Based, fuck Google",
          "score": 1,
          "created_utc": "2026-02-13 00:38:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yq8my",
          "author": "pinklove9",
          "text": "What kind of a ban is this",
          "score": 0,
          "created_utc": "2026-02-12 11:31:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ytriz",
              "author": "Eastern-Guess-1187",
              "text": "only for gemini / antigravity. but I emailed them and I promised that I won't use anything thats 3rd party :D",
              "score": 1,
              "created_utc": "2026-02-12 12:00:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o53ph35",
                  "author": "StrixGGUY",
                  "text": "you are the amin admin of the subscription? if yes simple add another gmail acc, add to your family sharing, add allow google on sharing, you have new access to antigravity -> always use second shared acc for this, if you get banned simple remove from familys haring and add another one easy and fast \n\nhttps://preview.redd.it/i8rnw7qhl6jg1.png?width=1015&format=png&auto=webp&s=40d911905e7da7342de8ebece4fd693ee36e3df1\n\n",
                  "score": 3,
                  "created_utc": "2026-02-13 03:28:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o51p385",
                  "author": "ItsStrike13",
                  "text": "Any response from them?",
                  "score": 1,
                  "created_utc": "2026-02-12 20:45:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o51ycyx",
                  "author": "aydgn",
                  "text": "Can you use [gemini.google.com](http://gemini.google.com) or it is just for Gemini CLI/Antigravity?",
                  "score": 1,
                  "created_utc": "2026-02-12 21:29:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o50mqz0",
          "author": "Villain_99",
          "text": "Use kimi or the upcoming glm 5",
          "score": 0,
          "created_utc": "2026-02-12 17:44:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ynzt5",
          "author": "MegamillionsJackpot",
          "text": "I use Codex + synthetic.new that works nicely.\n\nI think synthetic.new has done some covert marketing on Reddit, so they get some hate for that, but it is still a nice deal. Hopefully, they will add GLM 5.0 soon .\n\nEdit with some news from synthetic:\n\nJust finished setting up our new B200 GPU cluster, where we'll be running `hf:Kimi-K2.5-NVFP4`. The deploy to flip backends is going out now and should be out within the half hour. üôÇ\n\nWe plan to get a version of GLM 5 up for all of you to try soon‚Ñ¢! We plan to move all our infrastructure to (presumably US based) Blackwells in the coming days which should signfiicantly increase our request capacity. üôÇ \n\n-# You can check when we're back to US only by running `curl \"https://api.synthetic.new/openai/v1/models?provider=synthetic\" | jq '.data[] | select(.id == \"hf:nvidia/Kimi-K2.5-NVFP4\") | {name, datacenters}'` and waiting for `IL` to flip to `US` üòõ",
          "score": -5,
          "created_utc": "2026-02-12 11:12:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50p0f2",
              "author": "Crinkez",
              "text": "Your standard and pro price point limits are not linear. Stardard users get ripped off.",
              "score": 1,
              "created_utc": "2026-02-12 17:55:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o50pga5",
                  "author": "MegamillionsJackpot",
                  "text": "It's not my prices. I'm really not affiliated with the firm. I just use it.",
                  "score": 1,
                  "created_utc": "2026-02-12 17:57:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r058ba",
      "title": "I just wanted to make a shout out to OpenCode developers",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r058ba/i_just_wanted_to_make_a_shout_out_to_opencode/",
      "author": "OptimizmSolutions",
      "created_utc": "2026-02-09 14:12:22",
      "score": 35,
      "num_comments": 2,
      "upvote_ratio": 0.97,
      "text": "I have been trying it for a while and what you have built is truly amazing. It's the only opensource alternative to Code Claude that truly convinced me! I'm sure that with the next generation of os LLMs it will become a no Brainerd vs the other options",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r058ba/i_just_wanted_to_make_a_shout_out_to_opencode/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4fxq95",
          "author": "Ok-Connection7755",
          "text": "to all the devs who are / have worked on opencode, heartfelt thanks! You make my life so much better daily!",
          "score": 4,
          "created_utc": "2026-02-09 15:03:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4l4jc4",
          "author": "HarjjotSinghh",
          "text": "open source llms? sounds like some kind of cult meeting i want in.",
          "score": 1,
          "created_utc": "2026-02-10 09:15:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r13qup",
      "title": "Am I the Only One Using GUI? and is the CLI Better?",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r13qup/am_i_the_only_one_using_gui_and_is_the_cli_better/",
      "author": "Level-Dig-4807",
      "created_utc": "2026-02-10 15:27:04",
      "score": 23,
      "num_comments": 25,
      "upvote_ratio": 0.84,
      "text": "Hello, \n\nI downloaded Opencode a week ago after a youtube video suggested it to me. \n\nI have always worked on GUIs rather than the CLI. I noticed a few things,\n\nThe GUI's MCP calling is not very good and fails mostly, \n\n  \nAfter Antigravity's new rate limiting on the Claude models, I needed a daily driver for which I choose Kimi 2.5 however on the \n\n  \nMost of the Youtube tutorial workflows suggested Opus for Planning and use OpenCodeCLI inside the Antigravity terminal rather than the CLI.\n\nI tried the GUI and Kimi 2.5 was performing very bad instead I had to switch to Kilocode which I found better. Idk y but I feel the CLI is noticeable better than the GUI than most cases and even it's used by most of the people.\n\n  \nWould like to know ur views",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r13qup/am_i_the_only_one_using_gui_and_is_the_cli_better/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4mv5dg",
          "author": "mcowger",
          "text": "The CLI and GUI are identical in how they interact with the model.  \n\nBoth are just a way to communicate with the underlying opencode server.",
          "score": 9,
          "created_utc": "2026-02-10 16:06:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mv592",
          "author": "rusl1",
          "text": "OpenChamber is a bless",
          "score": 5,
          "created_utc": "2026-02-10 16:06:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4px7mq",
              "author": "SvenVargHimmel",
              "text": "I use it with tailwind. It developing nicely. \n\nsubagent calling is a drop down menu instead of the @ subagent  , that can get old pretty quickly\n\n",
              "score": 2,
              "created_utc": "2026-02-11 01:03:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4nkztn",
              "author": "touristtam",
              "text": "> OpenChamber\n\nLemme guess another electron app?",
              "score": 1,
              "created_utc": "2026-02-10 18:05:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4nodvg",
                  "author": "rusl1",
                  "text": "Nope :) it's written in Go or Rust, I don't recall",
                  "score": 0,
                  "created_utc": "2026-02-10 18:21:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4qlpik",
              "author": "gsxdsm",
              "text": "Openchamber is amazing",
              "score": 0,
              "created_utc": "2026-02-11 03:32:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4r4p3b",
              "author": "Haunting_Good1948",
              "text": "openchamber on my left, antigravity on my right, middle is the editor.",
              "score": 0,
              "created_utc": "2026-02-11 05:49:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4pxe9i",
          "author": "aeroumbria",
          "text": "Opencode CLI is basically as feature rich as GUIs from other developers in terms of \"graphical\" functions, but I do find the Web UI easier to use when managing multiple sessions without giving them complete permission to everything. \n\nI personally would not use any of the other \"scrolling\" type CLI agents in an interactive manner. One shot tasks or \"the questions and forget\" maybe, but it is frustrating to stare at stacked edits and try to figure out what is going on. Opencode at least lets you see edits in a nicely highlighted manner and list all current edits and TODOs at once.",
          "score": 2,
          "created_utc": "2026-02-11 01:04:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4qgicm",
              "author": "Potential-Leg-639",
              "text": "Agree, Opencode changed the whole workflow completely for me. Still want to integrate Opencode Desktop as well to better manage all the open sessions.",
              "score": 1,
              "created_utc": "2026-02-11 02:59:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4qxtpg",
          "author": "FlyingDogCatcher",
          "text": "You guys know you can use your mouse on the cli, right?. To just click stuff",
          "score": 2,
          "created_utc": "2026-02-11 04:56:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mp1sb",
          "author": "mr_ignatz",
          "text": "I don‚Äôt know if it‚Äôs the same for OpenCode, but many of the CLIs use ink, a framework for making console apps with React, enabling the underlying logic to be much closer to the same.",
          "score": 1,
          "created_utc": "2026-02-10 15:38:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4nekof",
              "author": "shaonline",
              "text": "OpenCode's team made their own TUI library (OpenTUI) but yeah in principle it's about the same, using React (or SolidJS in OpenTUI's case) for building TUIs. I think only Codex CLI is a special case, it's built in Rust.",
              "score": 5,
              "created_utc": "2026-02-10 17:36:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4qg59b",
          "author": "Potential-Leg-639",
          "text": "Use opencode in a terminal in an IDE ;)",
          "score": 1,
          "created_utc": "2026-02-11 02:57:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tnemz",
              "author": "Mr-Fan-Tas-Tic",
              "text": "but how do you manage code like let say you dont like the code it generated ?  \ndo you use simple git ?\n\n",
              "score": 1,
              "created_utc": "2026-02-11 16:30:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4u0j2t",
                  "author": "Potential-Leg-639",
                  "text": "simply copy the code you dont like into your opencode session, tell opencode what you dont like and review the result again. the IDE is just there to check your files/codebase if you want, i normally use it without IDE at all.",
                  "score": 2,
                  "created_utc": "2026-02-11 17:31:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4rm9xx",
          "author": "OtherwiseHornet4503",
          "text": "There‚Äôs a GUI?!?",
          "score": 1,
          "created_utc": "2026-02-11 08:27:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4towhn",
          "author": "beall49",
          "text": "I use it. It's freaking awesome",
          "score": 1,
          "created_utc": "2026-02-11 16:37:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5048en",
          "author": "Illustrious_Club2865",
          "text": "Not reading everything here ... but I don't understand how you would do things like this from a gui?:  \n\\- Install tshark and anylyze this .pcapng file in this folder and tell me the communications between [1.1.1.1](http://1.1.1.1) and [2.2.2.2](http://2.2.2.2) and what could be causing communication errors  \n\\-or-  \n\\- Create a node.script to query url abce123 dot com and give the data betwen div1 and div2 and save in json format - run here and debug accordingly - we can use playwrite/chromium  \n\\-or-  \n\\- Create a Get-WinEvent to query events 1,2,3,4 and tell me wyz abc  \n\\-or-  \n\\- Save the entire process we performed here as an MD file so we can revisit later  \n\\-or- -or- -or- ... ",
          "score": 1,
          "created_utc": "2026-02-12 16:17:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mofnv",
          "author": "HarjjotSinghh",
          "text": "i love command line so much, but my hands are too lazy to type",
          "score": 1,
          "created_utc": "2026-02-10 15:35:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4n26ce",
          "author": "Recent-Success-1520",
          "text": "You can try CodeNomad , it uses Opencode behind the scenes.\nWhatever tool you use to interact TUI, Web, Desktop they all are the same internally use opencode",
          "score": 1,
          "created_utc": "2026-02-10 16:39:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2fjyn",
      "title": "OpenCode vs GitHub Copilot CLI ‚Äî huge credit usage difference for same prompt?",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r2fjyn/opencode_vs_github_copilot_cli_huge_credit_usage/",
      "author": "usernameIsRand0m",
      "created_utc": "2026-02-12 01:05:14",
      "score": 21,
      "num_comments": 23,
      "upvote_ratio": 0.96,
      "text": "Trying to figure out if I messed something up in my OpenCode config or if this is just how it works.\n\nI‚Äôm on OpenCode 1.1.59.  \nI ran a single prompt. No sub agents.  \nIt cost me 27 credits.\n\nI thought maybe OpenCode was doing extra stuff in the background, so I disabled agents:\n\n    \"permission\": {\n      \"task\": \"deny\"\n    },\n    \"agent\": {\n      \"general\": {\n        \"disable\": true\n      },\n      \"explore\": {\n        \"disable\": true\n      }\n    }\n    \n\nRan the exact same prompt again. Still 27 credits.\n\nFor comparison, I tried the same prompt with GitHub Copilot CLI and it only used 3 credits for basically the same task and output.\n\nNot talking about model pricing here. I‚Äôm specifically wondering if:\n\n* There‚Äôs some other config I‚Äôm missing that controls how much work OpenCode does per prompt\n* OpenCode is doing extra planning or background steps even with agents disabled\n* Anyone else has seen similar credit usage and figured out what was causing it\n\nBasically, is this normal for OpenCode or am I accidentally paying for extra stuff I don‚Äôt need?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r2fjyn/opencode_vs_github_copilot_cli_huge_credit_usage/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4wl2bh",
          "author": "simap2000",
          "text": "Wonder if each round trip in opencode for every tool call, etc counts as a request vs many tool calls and agents in copilot is like 1?",
          "score": 4,
          "created_utc": "2026-02-12 01:18:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4wmgbk",
              "author": "usernameIsRand0m",
              "text": "It was not like this few (maybe 5-6 versions?) versions ago. I am wondering if I am missing something in the config that I need to have.",
              "score": 1,
              "created_utc": "2026-02-12 01:27:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ycer8",
                  "author": "SvenVargHimmel",
                  "text": "Use litellm proxy and run with ---detailed-debug  and point opencode to that  with the proxy configured to point to your llm backend and you can see exactly what it is sending per request. \n\n  \nThen point your Copilot at the same endpoint. \n\n  \nYou can see exactly what's going on. \n\nAnd if you want to test your theory that it used be less expensive a few versions ago , just roll back and repeat \n\n  \n",
                  "score": 4,
                  "created_utc": "2026-02-12 09:22:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4xjj39",
                  "author": "albertortilla",
                  "text": "There were problems in older version (1.1.38 if I am no wrong) regarding this: each tool call counted in GitHub copilot as a new request, which was solved in the next versions... Maybe the problem appeared again... I would try to install an older version and check for the same prompt",
                  "score": 1,
                  "created_utc": "2026-02-12 05:00:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4xpzyi",
          "author": "Michaeli_Starky",
          "text": "Yep, noticed the same. Switched to Copilot CLI",
          "score": 2,
          "created_utc": "2026-02-12 05:52:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ykxmn",
          "author": "Adorable_Buffalo1900",
          "text": "opencode claude model use chat completions api, but copilot use message api. you need raise a issue for opencode",
          "score": 2,
          "created_utc": "2026-02-12 10:44:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z25wj",
          "author": "krimpenrik",
          "text": "Same issue saw that I am already using a lot opencode with copilot sub, this month is fucked",
          "score": 2,
          "created_utc": "2026-02-12 12:59:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51at7x",
          "author": "PayTheRaant",
          "text": "Check your small model configuration. This is the model for generating the titles of sessions and messages. You should use a free model for that. \n\nAlso try the same prompt with a free model: if your premium request cost is not zero, then something else is triggering premium requests with a paid model.",
          "score": 2,
          "created_utc": "2026-02-12 19:37:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51c6ap",
              "author": "PayTheRaant",
              "text": "You can also use debug logs to track every single call to the LLM\n\nhttps://opencode.ai/docs/troubleshooting/#journaux",
              "score": 1,
              "created_utc": "2026-02-12 19:44:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o53oh68",
                  "author": "usernameIsRand0m",
                  "text": "So, apart from the above config which I have shared in OP, I have to add small model config?\n\nI'll check the debug logs. Thanks.",
                  "score": 1,
                  "created_utc": "2026-02-13 03:22:28",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4y2ywi",
          "author": "keroro7128",
          "text": "I've heard that some people are saying they can use the free GPT 5 Mini model to call advanced models Ôºàopus 4.6Ôºâ via a sub-agent without consuming any requests, but some are saying they got their accounts banned for it.",
          "score": 1,
          "created_utc": "2026-02-12 07:49:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51ce6k",
              "author": "PayTheRaant",
              "text": "Normally, switching model for sub agent is considered a new premium request.",
              "score": 2,
              "created_utc": "2026-02-12 19:45:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4yrzcr",
              "author": "usernameIsRand0m",
              "text": "Yes, there are lot of instances of that happening, I have Pro+ account, so there are more than enough requests per month for me.",
              "score": 1,
              "created_utc": "2026-02-12 11:46:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4y7uxq",
          "author": "Tadomeku",
          "text": "The system prompt in Opencode is likely longer than the system prompt in GitHub CLI. YOUR prompt may be simple, but it gets appended to the system prompt in Opencode, along with AGENTS.md, CLAUDE.md, SKILLS, etc.    \n    \nI don't know what GitHub CLI does under the hood but I imagine it's pretty different.",
          "score": 1,
          "created_utc": "2026-02-12 08:37:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51a49q",
              "author": "PayTheRaant",
              "text": "Copilot model is expected to consume ONE premium request per ONE user prompt.\nEverything else that is agent initiated is expected to be included in that initial premium request (all tools, even sub agent) as long as it stays in the same model. \nIn theory, it should not even care about input token cache.\n\nSo this is why having 27 premium requests consumed is considered a big problem.",
              "score": 1,
              "created_utc": "2026-02-12 19:34:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ydnqg",
          "author": "soul105",
          "text": "Noticed the same here.  \nSome business users have the limit for 300 requests and cannot buy more due to company policies, making the problem even bigger.",
          "score": 1,
          "created_utc": "2026-02-12 09:35:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o528g2s",
          "author": "HarjjotSinghh",
          "text": "wow copilot's gonna charge you like a slot machine.",
          "score": 1,
          "created_utc": "2026-02-12 22:18:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o537bmt",
          "author": "itsjase",
          "text": "its a known bug: [https://github.com/anomalyco/opencode/issues/8030](https://github.com/anomalyco/opencode/issues/8030)",
          "score": 1,
          "created_utc": "2026-02-13 01:36:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53n2tt",
          "author": "Desperate-Bath5208",
          "text": "Happened to me as well, I barely used it and I've consumed $2 worth of quota.",
          "score": 1,
          "created_utc": "2026-02-13 03:13:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xd8l2",
          "author": "jmhunter",
          "text": "The preamble/system prompt is probably a lot juicier w opencode",
          "score": 1,
          "created_utc": "2026-02-12 04:14:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xoc9l",
              "author": "IIALE34II",
              "text": "Billing should be one premium request per user initialized message. Or well there is the per model scaling.",
              "score": 4,
              "created_utc": "2026-02-12 05:38:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4x434i",
          "author": "ok_i_am_nobody",
          "text": "Same issue. \nMoved to pi coding agent for simple tasks.\nHow are you tracking the credits usage?",
          "score": 0,
          "created_utc": "2026-02-12 03:13:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xnagy",
              "author": "usernameIsRand0m",
              "text": "In your settings page, here - [https://github.com/settings/billing/premium\\_requests\\_usage](https://github.com/settings/billing/premium_requests_usage)",
              "score": 0,
              "created_utc": "2026-02-12 05:29:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r08c11",
      "title": "Running Opencode on Docker (Safe and working!)",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r08c11/running_opencode_on_docker_safe_and_working/",
      "author": "LinsaFTW",
      "created_utc": "2026-02-09 16:11:34",
      "score": 20,
      "num_comments": 11,
      "upvote_ratio": 0.92,
      "text": "I was struggling to get this working so after some workarounds I found the solution and just wanted to share it with you.\n\n## **Step 1 ‚Äî Project Structure**\n\nCreate a folder for your setup:\n\n```\nopencode-docker/\n‚îú‚îÄ‚îÄ Dockerfile        # Dockerfile to install OpenCode AI\n‚îú‚îÄ‚îÄ build.sh          # Script to build the Docker image\n‚îú‚îÄ‚îÄ run.sh            # Script to run OpenCode AI safely\n‚îú‚îÄ‚îÄ container-data/   # Writable folder for OpenCode AI runtime & config\n‚îî‚îÄ‚îÄ projects/         # Writable folder for AI projects/code\n```\n\n---\n\n### **Step 2 ‚Äî Dockerfile**\n\n```dockerfile\n# Dockerfile for OpenCode AI\nFROM ubuntu:latest\n\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install dependencies\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    curl \\\n    ca-certificates \\\n    git \\\n    openssh-client \\\n    sudo \\\n && rm -rf /var/lib/apt/lists/*\n\n# Create non-root user if not exists\nRUN id -u ubuntu &>/dev/null || useradd -m -s /bin/bash ubuntu \\\n && echo \"ubuntu ALL=(ALL) NOPASSWD: ALL\" > /etc/sudoers.d/ubuntu \\\n && chmod 0440 /etc/sudoers.d/ubuntu\n\nUSER ubuntu\nWORKDIR /home/ubuntu\n\n# Prepare SSH config and known_hosts for git\nRUN mkdir -p /home/ubuntu/.ssh \\\n && touch /home/ubuntu/.ssh/known_hosts \\\n && ssh-keyscan -T 5 github.com 2>/dev/null >> /home/ubuntu/.ssh/known_hosts || true\n\n# Install OpenCode AI\nRUN curl -fsSL https://opencode.ai/install | bash\n\n# Add OpenCode AI binary to PATH\nENV PATH=\"/home/ubuntu/.opencode/bin:${PATH}\"\n```\n\n---\n\n### **Step 3 ‚Äî Build Script (`build.sh`)**\n\n```bash\n#!/bin/bash\nset -e\n\n# Build OpenCode AI Docker image\ndocker build -t opencode-ai:latest .\n```\n\nMake executable:\n\n```bash\nchmod 700 build.sh\n```\n\n---\n\n### **Step 4 ‚Äî Run Script (`run.sh`)**\n\n```bash\n#!/bin/bash\n\ndocker run --rm -it \\\n  # Writable runtime/config folder\n  -v \"$HOME/opencode-docker/container-data:/home/ubuntu/.local\" \\\n  -v \"$HOME/opencode-docker/container-data/config:/home/ubuntu/.config/opencode\" \\\n  # Writable project workspace\n  -v \"$HOME/opencode-docker/projects:/workspace\" \\\n  -w /workspace \\\n  # Ensure OpenCode AI binary is in PATH\n  -e PATH=\"/home/ubuntu/.opencode/bin:${PATH}\" \\\n  opencode-ai:latest \\\n  opencode\n```\n\nMake executable:\n\n```bash\nchmod 700 run.sh\n```\n\n---\n\n### **Step 5 ‚Äî Setup Host Directories**\n\n```bash\nmkdir -p ~/opencode-docker/container-data/config\nmkdir -p ~/opencode-docker/projects\n\n# Give container ownership of writable folders\nsudo chown -R 1000:1000 ~/opencode-docker/container-data ~/opencode-docker/projects\n```\n\n> These folders are where OpenCode AI can safely store runtime files and project code.\n\n---\n\n### **Step 6 ‚Äî Build the Docker Image**\n\n```bash\n./build.sh\n```\n\n* This installs OpenCode AI in a non-root container.\n* All credentials and runtime files stay outside the image.\n\n---\n\n### **Step 7 ‚Äî Run OpenCode AI**\n\n```bash\n./run.sh\n```\n\n* The container uses `/workspace` for your project code.\n* Scripts (`build.sh` and `run.sh`) are read-only to Docker.\n* OpenCode AI can create/edit files in `projects/` without modifying your host scripts.\n\n---\n\n### **Step 8 ‚Äî Tips**\n\n* Keep all sensitive host credentials outside the image.\n* Rebuild image to update OpenCode AI: `./build.sh`\n* Add new projects inside `projects/` folder; the container has write access here.\n* Use read-only mounts (`:ro`) for scripts if you want extra safety.\n\n---\n\n### ‚úÖ **Folder Summary**\n\n| Folder               | Purpose                                  |\n| -------------------- | ---------------------------------------- |\n| `build.sh`, `run.sh` | Host-only, immutable scripts             |\n| `container-data/`    | Writable container runtime/config files  |\n| `projects/`          | Writable workspace for AI-generated code |",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r08c11/running_opencode_on_docker_safe_and_working/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4gfs5i",
          "author": "DavidNorena",
          "text": "Nice, another alternative im using in linux is just to use setpriv to sandbox my projects. (if your kernel version supports it)",
          "score": 4,
          "created_utc": "2026-02-09 16:31:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ghw46",
          "author": "Michaeli_Starky",
          "text": "Devcontainers",
          "score": 5,
          "created_utc": "2026-02-09 16:41:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4han95",
              "author": "Kylecribbs",
              "text": "This is the best way imo",
              "score": 2,
              "created_utc": "2026-02-09 18:56:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4gnfsx",
              "author": "telewebb",
              "text": "porkchop sandwiches",
              "score": 1,
              "created_utc": "2026-02-09 17:07:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4i2zsp",
                  "author": "Michaeli_Starky",
                  "text": "Excuse me?",
                  "score": 1,
                  "created_utc": "2026-02-09 21:16:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4h7sgz",
          "author": "_stuikerd",
          "text": "https://github.com/glennvdv/opencode-dockerized this is my setup, maybe you can get some inspiration out of it",
          "score": 2,
          "created_utc": "2026-02-09 18:43:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i9lbp",
              "author": "LinsaFTW",
              "text": "I made this tutorial from that base, did not work for me!",
              "score": 2,
              "created_utc": "2026-02-09 21:49:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4kydar",
          "author": "viss_bus_labi",
          "text": "Docker is not safe, should not be considered safe.",
          "score": 1,
          "created_utc": "2026-02-10 08:14:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pcg5f",
              "author": "ElPastinak",
              "text": "Why is it so? I find this approach interesting regarding keeping the agent isolated from sensitive data/code.",
              "score": 1,
              "created_utc": "2026-02-10 23:05:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4l1lut",
          "author": "HarjjotSinghh",
          "text": "this docker config sounds way safer than my last attempt where opencode broke my keyboard.",
          "score": 1,
          "created_utc": "2026-02-10 08:46:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lwuwc",
          "author": "No-Leopard7644",
          "text": "Does this work for multi user access?",
          "score": 1,
          "created_utc": "2026-02-10 13:07:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r18htv",
      "title": "$80 budget for AI subs this month (lost $20 to GLM)‚Äîwhat‚Äôs the best stack?",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r18htv/80_budget_for_ai_subs_this_month_lost_20_to/",
      "author": "Anxious-Candidate588",
      "created_utc": "2026-02-10 18:18:13",
      "score": 20,
      "num_comments": 27,
      "upvote_ratio": 0.86,
      "text": "I get a $100/month reimbursement for AI, but I forgot to cancel a GLM model subscription, so I‚Äôm stuck with only $80 left for this cycle.\n\nI‚Äôm a heavy user and usually go for Claude Max ($100). Since I can‚Äôt afford that this month, what‚Äôs the best combination of subscriptions I can get for $80?\n\nNote: I prefer flat-rate monthly subscriptions and do not want pay-as-you-go API pricing.\n\nWhat would you pick to get the most \"unlimited\" feel for coding and heavy usage?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r18htv/80_budget_for_ai_subs_this_month_lost_20_to/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4nyfqa",
          "author": "t4a8945",
          "text": "Easy choice! Get only 1 ChatGPT Plus ($20), and just get 1 or 2 or 3 more accounts if necessary given your budget.\n\nRight now Codex 5.3 is awesome, and usage is double for the next two months. That's what I'd do in your shoes.",
          "score": 13,
          "created_utc": "2026-02-10 19:06:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nst6h",
          "author": "guillefix",
          "text": "GitHub Copilot Pro+ for $39 then connect it to Open Code.",
          "score": 20,
          "created_utc": "2026-02-10 18:41:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4q3683",
              "author": "jpcaparas",
              "text": "It's insanely good value, and you get a really rich model garden. There's so much utility for GH on multiple interfaces. ",
              "score": 4,
              "created_utc": "2026-02-11 01:39:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4rsrm4",
              "author": "foolsgold1",
              "text": "Yes, but having the quota only renew per month is really frustrating.  Burn through the quota in week 1, then wait 3 weeks to use it again.",
              "score": 3,
              "created_utc": "2026-02-11 09:29:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4svuuc",
              "author": "KPOTOB",
              "text": "Would the opencode accessing codex burn premium requests?",
              "score": 1,
              "created_utc": "2026-02-11 14:14:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4x1ho3",
              "author": "Rude-Needleworker-56",
              "text": "Don't github copilot still silently cap the context  behind the scenes to a fraction of what is supported by the model?",
              "score": 1,
              "created_utc": "2026-02-12 02:57:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4xu9r6",
                  "author": "guillefix",
                  "text": "Well, what did you expect for $39 instead of $100.",
                  "score": 0,
                  "created_utc": "2026-02-12 06:29:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4nun2i",
          "author": "jpcaparas",
          "text": "If you are not a power user, GitHub Copilot Pro+ offers the best value for money for Opus 4.6 and Codex 5.3 access. It suffers from rate limiting when spawning parallel subagents (for reference, I always have 40 in parallel at any given time for research tasks), but for basic stuff like writing code (ie max 5-10 agents in parallel), it's worth it. The inference is also slower compared to Claude sub and Claude direct API access\n\nFor Kimi K2.5 and GLM 4.7, the king is still Synthetic and OpenCode Zen (which reminds me, my Black sub hasn't been activated after a month of waiting).\n\nDo not get from Kimi dot com if you are working on non-hobby projects.",
          "score": 10,
          "created_utc": "2026-02-10 18:49:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4o4dbl",
          "author": "Outrageous-Story3325",
          "text": "Kimi k2.5 on opencode",
          "score": 4,
          "created_utc": "2026-02-10 19:34:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ydcia",
              "author": "downvotedbylife",
              "text": "Been using this plus a $20 chatgpt plan for codex and I dont really run into any limitations. Considering cancelling chatgpt and use just kimi once the 0.99 month ends",
              "score": 0,
              "created_utc": "2026-02-12 09:31:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4npi7z",
          "author": "calben99",
          "text": "With $80 and wanting flat-rate unlimited coding, I'd go with Cursor Pro ($20) + ChatGPT Plus ($20) + Claude Pro ($20). That gives you three different model approaches and stays well under budget at $60 total. Cursor is unbeatable for coding workflow, ChatGPT has the best tool ecosystem, and Claude excels at reasoning through complex problems. Save the extra $20 for next month or grab Perplexity Pro if you want research capabilities.",
          "score": 4,
          "created_utc": "2026-02-10 18:26:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4nqa3j",
              "author": "Anxious-Candidate588",
              "text": "I dont use cursor. I mostly use Zed or neovim and these days mostly using opencode. So not sure if cursor is a good choice",
              "score": 7,
              "created_utc": "2026-02-10 18:29:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4pxmyg",
                  "author": "Shep_Alderson",
                  "text": "Drop cursor pro and add copilot+",
                  "score": 6,
                  "created_utc": "2026-02-11 01:06:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4nxjaa",
                  "author": "Visible-Ground2810",
                  "text": "I also use neovim and cli. The best so far is opus in Claude code. I have tried everything.",
                  "score": 1,
                  "created_utc": "2026-02-10 19:02:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4onbhb",
          "author": "jhartumc",
          "text": "$20 GPT plus + $20 Kimi For Coding  \nGPT-5.3 as planing and Kimi k2.5 as subagents worker",
          "score": 2,
          "created_utc": "2026-02-10 21:02:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r1td0",
              "author": "BuildAISkills",
              "text": "That's a solid plan.\nSomeone said a GPT Team plan at 30 USD gives even more usage than Plus, but I haven't tried it. For now you still get 2X quota anyway.",
              "score": 2,
              "created_utc": "2026-02-11 05:26:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ntjdy",
          "author": "EuSouTehort",
          "text": "Github Copilot Pro+ for implementation and access to chatgpt models, on Opencode  \nclaude 1x for brainstorming / planning",
          "score": 1,
          "created_utc": "2026-02-10 18:44:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54tz70",
          "author": "HarjjotSinghh",
          "text": "glm is just paying for your future regret.",
          "score": 1,
          "created_utc": "2026-02-13 08:54:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4p40l1",
          "author": "SeniorFallRisk",
          "text": "1x GPT Plus account and 2x GPT Business accounts (a single gpt account can have plus and business accounts with separate quotas so you only need 2 email addresses for this), is $80.\nThen you can use something like my opencode-codex-auth plugin to use all 3 amounts in a single app.\n\nEdit: you could also just spend all $100 every month on maximum ChatGPT / Codex credits, or do a $20 plus account and $80 of credits. Thats probably the better option.",
          "score": 1,
          "created_utc": "2026-02-10 22:21:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ry9fb",
          "author": "ScorpionOfWar",
          "text": "Been using open-source models more lately for private stuff, I got the 100$ Claude Sub for work.\n\nEnded up trying [Synthetic](https://synthetic.new/?referral=hcHozzHNE8CxVvz)(\\~50% off) and it's been very solid so far, alternatively [Z.ai](https://z.ai/subscribe?ic=KQ77ZVKLB5)(\\~10% off) for just the GLM Models, nice for coding, but kind of unreliable at the moment. They host open-source models and the API is OpenAI-compatible so it just plugs into your CLI or Dev Environment. $20/mo flat for the subscription tier is nice.\n\nWith my ref link to Synthetic and Z you are able to get a rebate.",
          "score": 1,
          "created_utc": "2026-02-11 10:19:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4o3yyp",
          "author": "trypnosis",
          "text": "Look I know you said you don‚Äôt like pay as you go but stay with me.\n\nBuy Co pilot pro+ that‚Äôs 1500 gpt 5.2 the rest left in the kitty in case you need more that‚Äôs another 1250ish.\n\nIf you assume a 4 week month that‚Äôs 20 days of work.\n\nCoding 7 hours a day that‚Äôs one request per 3 min \n\nNow personally I don‚Äôt code 7 hours a day. Nor do i need gpt 5.2 for all my tasks.",
          "score": 0,
          "created_utc": "2026-02-10 19:32:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rlxhm",
          "author": "TurnUpThe4D3D3D3",
          "text": "Codex with 5.3 is an excellent value. They have a very generous $20 tier.\n\nAlternatively, OpenCode with Kimi is also great",
          "score": 0,
          "created_utc": "2026-02-11 08:24:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nr41b",
          "author": "atiqrahmanx",
          "text": "Get   \n1. ChatGPT Pro ($20)  \n2. Claude Pro ($20)  \n3. GitHub Copilot Pro ($10)  \n4. AmpCode (daily $10 free usage of Opus, GPT models)  \n5. OpenCode (free usage of sub-par models e.g. Kimi, GLM)",
          "score": -1,
          "created_utc": "2026-02-10 18:33:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r1m16",
              "author": "ZeSprawl",
              "text": "AmpCode shut off access for new users to the free 10 dollars of usage",
              "score": 0,
              "created_utc": "2026-02-11 05:25:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4r4eib",
                  "author": "atiqrahmanx",
                  "text": "If you email them, pretty sure they‚Äôll give you access.",
                  "score": 0,
                  "created_utc": "2026-02-11 05:47:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4nxdev",
          "author": "Visible-Ground2810",
          "text": "Best deal is to get Claude max 5x with this amount",
          "score": -3,
          "created_utc": "2026-02-10 19:01:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4qbn66",
              "author": "Codemonkeyzz",
              "text": "Nope",
              "score": -1,
              "created_utc": "2026-02-11 02:30:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r0hate",
      "title": "Z.ai‚Äôs GLM-5 leaked through GitHub PRs and a zodiac easter egg",
      "subreddit": "opencodeCLI",
      "url": "https://extended.reading.sh/glm-5-leaked",
      "author": "jpcaparas",
      "created_utc": "2026-02-09 21:33:11",
      "score": 18,
      "num_comments": 13,
      "upvote_ratio": 0.8,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r0hate/zais_glm5_leaked_through_github_prs_and_a_zodiac/",
      "domain": "extended.reading.sh",
      "is_self": false,
      "comments": [
        {
          "id": "o4k56p4",
          "author": "Vaviloff",
          "text": "Member-only story (paywalled). Sorry, I'd rather subscribe to your patreon than give money to that garbage service called Medium.",
          "score": 9,
          "created_utc": "2026-02-10 04:15:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kn5cl",
              "author": "jpcaparas",
              "text": "apologies, should be sorted now\n\n(starts substack)",
              "score": 3,
              "created_utc": "2026-02-10 06:31:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4lr87v",
                  "author": "Vaviloff",
                  "text": "Thank you for opening it, just finished reading, what a piece!",
                  "score": 1,
                  "created_utc": "2026-02-10 12:30:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4kop4g",
          "author": "Simple_Split5074",
          "text": "The details on glm 4.5 seem wrong, it's the same size as 4.6 and 4.7",
          "score": 1,
          "created_utc": "2026-02-10 06:45:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kq7m6",
              "author": "jpcaparas",
              "text": "Thanks for pointing it out. I'll make the apt updates shortly.\n\n(Edit: Just need a bit more time to one-shot it and not having to correct factual errors too often)",
              "score": 1,
              "created_utc": "2026-02-10 06:58:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4n0sp4",
          "author": "HarjjotSinghh",
          "text": "this guy knew how to hide his secret weapon like a pro",
          "score": 1,
          "created_utc": "2026-02-10 16:32:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4u6viz",
          "author": "HarjjotSinghh",
          "text": "glm 5 sounds like my new favorite ghost project.",
          "score": 1,
          "created_utc": "2026-02-11 18:01:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kmv6p",
          "author": "Atomzwieback",
          "text": "Anyway z.ai is shit it‚Äôs slow as fuck and a cash grab",
          "score": -1,
          "created_utc": "2026-02-10 06:29:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kn24p",
              "author": "jpcaparas",
              "text": "yep, GLM is slow af on Z.ai. only reason I have it is the MCP servers ü§∑‚Äç‚ôÇÔ∏è and the free year of ultra\n\nbut I'm hopeful for GLM-5 on other providers.",
              "score": 2,
              "created_utc": "2026-02-10 06:31:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4m2bzy",
                  "author": "Professional-Cup916",
                  "text": "Free year?",
                  "score": 1,
                  "created_utc": "2026-02-10 13:39:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r0d34g",
      "title": "What‚Äôs the best practice to define multi (sub-)agent workflow",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r0d34g/whats_the_best_practice_to_define_multi_subagent/",
      "author": "No_Issue_4425",
      "created_utc": "2026-02-09 19:01:08",
      "score": 18,
      "num_comments": 2,
      "upvote_ratio": 0.95,
      "text": "I want to create a really simple workflow to optimize context usage and therefore save tokens and increase efficiency. Therefore I want to create something like a plan, build, review workflow, where planning an and review are done by dedicated subagents (with specific models, prompt, temperature, ‚Ä¶). I created the subagents according to the documentation https://opencode.ai/docs/agents/ in the agents folder of the projects and placed the desired workflow in the AGENTS.md file. But somehow it is kind of random if it is picked up by the main agent. Do I have to write my own orchestrator agent to make it work? I don‚Äôt want to write the system prompt for the main agent.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r0d34g/whats_the_best_practice_to_define_multi_subagent/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4m2lm7",
          "author": "lmdz6oz",
          "text": "Hello! I did something similar recently, took inspiration from this [Gist](https://gist.github.com/gc-victor/1d3eeb46ddfda5257c08744972e0fc4c) . I tried other existing solutions like Oh My Opencode or GSD but it was overkill for me. I took the template from this Gist and tailored it for my needs and so far so good",
          "score": 1,
          "created_utc": "2026-02-10 13:41:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jp317",
          "author": "nickkkk77",
          "text": "Why not? Do you have a repo to have a look? Which model are you using?",
          "score": 0,
          "created_utc": "2026-02-10 02:34:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2mw1u",
      "title": "No time for release notes, let's ship it a daily update /s",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r2mw1u/no_time_for_release_notes_lets_ship_it_a_daily/",
      "author": "soul105",
      "created_utc": "2026-02-12 07:13:01",
      "score": 18,
      "num_comments": 5,
      "upvote_ratio": 0.92,
      "text": "https://preview.redd.it/ya0lig1ak0jg1.png?width=1980&format=png&auto=webp&s=fe92a7273ebb8fbcd3094b39ec310a2f81407aee\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r2mw1u/no_time_for_release_notes_lets_ship_it_a_daily/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4ya76g",
          "author": "sitkarev",
          "text": "i still have frequent memory leakages",
          "score": 2,
          "created_utc": "2026-02-12 09:00:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56510t",
              "author": "_Deftera_",
              "text": "You should stop drinking alcohol",
              "score": 1,
              "created_utc": "2026-02-13 14:36:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o51ds9s",
          "author": "HarjjotSinghh",
          "text": "this means beta.",
          "score": 1,
          "created_utc": "2026-02-12 19:51:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z95uz",
          "author": "Heavy-Focus-1964",
          "text": "people on this sub seem to often forget that this product is *free.* have you ever heard the term ‚Äúyou get what you pay for?‚Äù",
          "score": -1,
          "created_utc": "2026-02-12 13:41:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zdjhp",
              "author": "soul105",
              "text": "You are right, the product is awesome and it's free.  \n  \nThe intention was to have a moment of fun where the wishes to deliver something faster were stronger than waiting for a good headline for the release notes. Release notes don't need to be boring.",
              "score": 3,
              "created_utc": "2026-02-12 14:05:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r2uylw",
      "title": "MiniMax-M2.5 Now First to Go Live on NetMind (Before the Official Launch), Free for a Limited Time Only",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/gu8hlkc1r2jg1.png",
      "author": "MarketingNetMind",
      "created_utc": "2026-02-12 14:33:08",
      "score": 16,
      "num_comments": 12,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r2uylw/minimaxm25_now_first_to_go_live_on_netmind_before/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4zjtyr",
          "author": "Nexmean",
          "text": "> M2.5 surpasses Claude Opus 4.6 on both SWE-bench Pro and SWE-bench Verified, placing it among the absolute best models for real-world software engineering. \n\nCrazy if true",
          "score": 9,
          "created_utc": "2026-02-12 14:38:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o501c86",
              "author": "getaway-3007",
              "text": "It's always untrue.\n\nBecause imagine someone is selling an axe for $10, now you've built a new axe which outperforms the best(or 2nd best if you think 5.3-codex xhigh is #1) then why would you sell for cheap? You would at least sell for $6 or $7 because it would still be cheaper than $10. \n\nI think the good comparison is Sonnet 4.5. all the open-source models are in that range not the Opus, Gpt-5.2 xhigh, etc",
              "score": 3,
              "created_utc": "2026-02-12 16:04:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o507m1d",
                  "author": "RegrettableBiscuit",
                  "text": "I don't believe that M2.5 will beat Opus 4.6. However, compared to Anthropic's pricing, Chinese models like K2.5 and GLM-5, both of which are superb models, do provide much better performance and quota per cost.\n\n\nThere are a bunch of reasons for that, primarily the need for these companies to take away market share from the big American providers.¬†",
                  "score": 3,
                  "created_utc": "2026-02-12 16:33:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o50f82c",
                  "author": "Nexmean",
                  "text": "> why would you sell for cheap\n\nwhy would you release open weights as well?",
                  "score": 2,
                  "created_utc": "2026-02-12 17:09:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4zlhwj",
              "author": "Embarrassed_Bread_16",
              "text": "ill try and see",
              "score": 1,
              "created_utc": "2026-02-12 14:47:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o52kps7",
          "author": "HarjjotSinghh",
          "text": "how many devs actually need netmind's free cloud?",
          "score": 1,
          "created_utc": "2026-02-12 23:24:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zy48c",
          "author": "jhartumc",
          "text": "There is no free access ",
          "score": 1,
          "created_utc": "2026-02-12 15:49:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50mahi",
              "author": "LittleChallenge8717",
              "text": "try in opencode, free for a week",
              "score": 1,
              "created_utc": "2026-02-12 17:42:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o51460g",
              "author": "MarketingNetMind",
              "text": "So sry abt the inconvenience & thx for spotting this! We have fixed the issue. You are able to use it for completely free now",
              "score": 1,
              "created_utc": "2026-02-12 19:05:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4zzxwb",
          "author": "jackai7",
          "text": "If free why Asking to add credit??",
          "score": 0,
          "created_utc": "2026-02-12 15:57:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5148s7",
              "author": "MarketingNetMind",
              "text": "So sry abt the inconvenience & thx for spotting this! We have fixed the issue. You are able to use it for completely free now",
              "score": 2,
              "created_utc": "2026-02-12 19:06:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r3jbfd",
      "title": "All-in-one subscription that gives both strong reasoning + cheap coding models?",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r3jbfd/allinone_subscription_that_gives_both_strong/",
      "author": "minhpro279",
      "created_utc": "2026-02-13 07:55:23",
      "score": 16,
      "num_comments": 14,
      "upvote_ratio": 0.87,
      "text": "I‚Äôve been using OpenCode with Antigravity, but got banned recently and now I‚Äôm looking for a replacement.\n\nMy ideal setup is simple:\none strong model for reasoning/planning,\none cheaper fast model as the workhorse for implementation,\nand preferably under a single subscription since I don‚Äôt want to manage multiple subscription.\n\nI‚Äôm considering Cursor, Copilot, Chutes, Synthetic, etc., but would love to hear what‚Äôs actually working well in practice.\n\nI‚Äôve heard opencode burn through premium requests quickly on Copilot, while Chutes/Synthetic don‚Äôt really offer a strong planning model ( i miss opus TT kimi 2.5 is good, but not there yet. have not used gpt5.3 )\n\nAnyway if you‚Äôre in a similar situation, would love to hear your experience. Any recommendations?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r3jbfd/allinone_subscription_that_gives_both_strong/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o54t6yf",
          "author": "Desperate-Bath5208",
          "text": "z.ai",
          "score": 7,
          "created_utc": "2026-02-13 08:47:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55baw1",
          "author": "dengar69",
          "text": "In looking at GitHub Copilot Pro+ for all the closed models, and NanoGPT for all the open ones.  $47 per month for both.",
          "score": 4,
          "created_utc": "2026-02-13 11:33:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56msk5",
              "author": "Desperate-Bath5208",
              "text": "https://www.reddit.com/r/opencodeCLI/comments/1r2fjyn/opencode_vs_github_copilot_cli_huge_credit_usage/\n\nhttps://github.com/anomalyco/opencode/issues/8030\n\nhttps://github.com/anomalyco/opencode/issues/13360",
              "score": 1,
              "created_utc": "2026-02-13 16:03:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o54u1d9",
          "author": "Bob5k",
          "text": "Have a note synthetic has Kimi k2.5 via Nvidia which is more preformant than any other source for this model.\nAlso have in mind that they have -20$ discount on pro plan with [reflink](https://synthetic.new/?referral=IDyp75aoQpW9YFt).\n\nOn another note tho, minimax M2.5 is pretty damn powerful and fast aswell and it's available across mm coding plans (with [discount](https://platform.minimax.io/subscribe/coding-plan?code=HO46LCwAJ5&source=link) aswell). \nThis or [glm coding plan](https://z.ai/subscribe?ic=CUEFJ9ALMX) are a solid backup plans which are also quite cheap around to get into.",
          "score": 5,
          "created_utc": "2026-02-13 08:55:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o55i5k9",
              "author": "pungggi",
              "text": "Is synthetic from Nvidia? Really?",
              "score": -3,
              "created_utc": "2026-02-13 12:24:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o56buhu",
                  "author": "mcowger",
                  "text": "No.  \n\nSynthetic has a ‚Äúturbo‚Äù variant of K2.5 that uses nvidias NVFP4 format for better performance",
                  "score": 4,
                  "created_utc": "2026-02-13 15:10:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o54pczw",
          "author": "wallapola",
          "text": "I'm not a bot and this is not an ad. Just sharing my experience since I actually use this. I‚Äôm using synthetic mainly because of the promo and so far it‚Äôs been noticeably faster than before. I might even stay after the promo expires since their service is a lot better compared to other providers. I feel more secure using it and I no longer want to explore other AI providers because it takes a lot of time and usually requires paying just to try their plans.\n\nThey recently added US-based servers, and one of them is using NVIDIA GPUs. I don‚Äôt really understand all the infra details, but performance-wise it‚Äôs definitely faster compared to their previous setup. Latency feels a lot better on my end.\n\nOne thing to note is that I think the standard plan is still on a waitlist right now, while the pro plan is available. If anyone wants to double-check, their discord is probably the best place. The devs are active there and they post updates about infra changes, issues and what they‚Äôre working on.\n\nIf you want to try it with the discounted offer:  \n[https://synthetic.new/?referral=4NNoPUXcb63ZYVK](https://synthetic.new/?referral=4NNoPUXcb63ZYVK)\n\nEdit: Based on what I‚Äôve seen on their discord, they‚Äôre really focusing on improving and stabilizing the service with their new infra setup and servers. They plan to add glm-5 once the infrastructure can handle more users, since adding it too early would definitely flood the service and cause slowdowns.",
          "score": 3,
          "created_utc": "2026-02-13 08:11:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o55qvhi",
              "author": "disrupted_bln",
              "text": "currently when you sign up for one of their plans there is a waitlist",
              "score": 0,
              "created_utc": "2026-02-13 13:19:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o56s20l",
          "author": "jorgejhms",
          "text": "Any news about Opencode Black?",
          "score": 1,
          "created_utc": "2026-02-13 16:28:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o551n6g",
          "author": "Putrid-Pair-6194",
          "text": "My setup.\nWorkhorses: Kimi 2.5 from Moonshot, GLM from Z.ai (pro plan).  \nPlanning and validation: GPT 5.2, 5.3 codex via OpenAI team plan.  \n\nNew Fallback: Gemini 3.0 flash via API (free credits)\n\nI just learned about the Gemini API free credits route and set it up so haven‚Äôt used extensively yet. Everything else works well",
          "score": 1,
          "created_utc": "2026-02-13 10:07:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o552ayh",
          "author": "Embarrassed_Bread_16",
          "text": "I'm using 20 USD plan from chutes.ai, it allows for making 5k requests daily, the most I can use is 2k when working on many projects at once, it allows for using open source models, like Kimi, glm, minimax\n\n\nIt has drawback that some models might temporarily be over utilized by people and API will become unresponsive and u need to change to other model, but it happened to me only for half an hour yesterday and I'm subscribed for 2 days\n\n\nI also bought minimax coding plan to try out the m2.5, gotta say it is super fast, but haven't used it enough to compare the quality",
          "score": 0,
          "created_utc": "2026-02-13 10:13:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55brpu",
          "author": "keroro7128",
          "text": "High-order model source: GitHub; low-order model source: Minimaz coding plan.",
          "score": 0,
          "created_utc": "2026-02-13 11:37:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5566xz",
          "author": "amba420",
          "text": "I'm using the synthetic new pro plan and Kimi is quite fast the last 2 days now. \n\nI'm using Kimi for planning and glm4.7 mostly for the work horse part. Works good\n\nBut they have a wait-list for new customers if anyone would like here is my referral:\n\nhttps://synthetic.new/?referral=vVOTagHw7nzmm2b",
          "score": -2,
          "created_utc": "2026-02-13 10:49:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54vmme",
          "author": "ScorpionOfWar",
          "text": "Been using open-source models more lately for private stuff, I got the 100$ Claude Sub for work.\n\nEnded up trying [Synthetic](https://synthetic.new/?referral=hcHozzHNE8CxVvz)(\\~50% off) and it's been very solid so far, alternatively [Z.ai](https://z.ai/subscribe?ic=KQ77ZVKLB5)(\\~10% off) for just the GLM Models, nice for coding, but kind of unreliable at the moment. They host open-source models and the API is OpenAI-compatible so it just plugs into your CLI or Dev Environment. $20/mo flat for the subscription tier is nice.\n\nWith my ref link to Synthetic and Z you are able to get a rebate.",
          "score": -4,
          "created_utc": "2026-02-13 09:10:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0umel",
      "title": "MegaMemory - agentic memory that grows with your project [all local, no api keys]",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1r0umel/megamemory_agentic_memory_that_grows_with_your/",
      "author": "Substantial-Fish617",
      "created_utc": "2026-02-10 07:42:59",
      "score": 15,
      "num_comments": 12,
      "upvote_ratio": 0.86,
      "text": "https://preview.redd.it/wepzs1fogmig1.png?width=1460&format=png&auto=webp&s=511ba2c7e86c8f3e3d6febd8766293f48825e8f7\n\nEvery new session your agent has amnesia. Re-explaining your architecture, your decisions, where stuff lives. Every. Single. Time.\n\nGot tired of it so I built MegaMemory. It's an MCP server that gives your coding agent persistent project memory through a local knowledge graph.\n\nSearch is semantic, not keyword matching. Your agent calls `understand(\"message cache timeout\")` and it finds related concepts even if those exact words never appear anywhere. It matches on meaning, not text. All embeddings run locally in-process, no API calls, no OpenAI key, nothing leaves your machine.\n\nKnowledge is stored as a graph, not flat notes. Concepts have types (module, pattern, decision, config) and real relationships between them (depends\\_on, implements, calls, configured\\_by). When the agent queries something it gets structure. How things connect, what depends on what, why decisions were made. Not just a wall of text.\n\nWhen the agent finishes work it calls `create_concept` to record what it built and why. Next session it picks up right where it left off. Memory grows with your project.\n\nQuick rundown:\n\n* `npx megamemory install` and pick your targets. Supports OpenCode, Claude Code, and Antigravity out of the box\n* Interactive installer walks you through setup, no manual config editing\n* Everything lives in `.megamemory/` in your repo. Commit it to git like anything else\n* Fully local, all processing happens on your machine\n* Web explorer with semantic search built in so you can browse your knowledge graph visually\n* Branch merging support so knowledge doesn't get lost across git branches\n* Open source, MIT licensed, zero external deps, Node 18+\n\nJust shipped v1.3.1 with a bunch of improvements since launch. Interactive multi-target installer, structured error handling, semantic search in the web explorer, and a lot more test coverage. Already getting external PRs from the community.\n\n[https://github.com/0xK3vin/MegaMemory](https://github.com/0xK3vin/MegaMemory)\n\n`npm install -g megamemory`\n\nHope you get some use out of it, check it out and let me know what you think.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1r0umel/megamemory_agentic_memory_that_grows_with_your/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o4lhe77",
          "author": "Legal_Dimension_",
          "text": "Would this work with ohmyopencode?",
          "score": 2,
          "created_utc": "2026-02-10 11:15:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4l8qpe",
          "author": "Ang_Drew",
          "text": "i like the idea like obsidian.md, one concern, context poisoning as the project grows..",
          "score": 1,
          "created_utc": "2026-02-10 09:56:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ld0up",
              "author": "Substantial-Fish617",
              "text": "Yeah that's a valid concern. The way it works is the agent doesn't just accumulate knowledge blindly. When it reads from a concept before working on code, it's prompted to update that concept and any linked concepts after it's done. So if concept\\_A says the cache TTL is 60s and the agent changes it to 120s, it updates concept\\_A and anything connected to it. Knowledge stays current because updating is part of the workflow, not a separate maintenance task.",
              "score": 1,
              "created_utc": "2026-02-10 10:36:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4lhzpk",
                  "author": "Ang_Drew",
                  "text": "can you try this on n8n repo? it's a heavy monorepo containing multi medium - large repo..\nwould be great demonstration if you can improve performance there..\n\nwhy? lately im working in customize the n8n, its been rough time.. gpt 5.2 took half an hour to think, accuracy dropped to 50%, some code got skipped, sometimes it hallucinated a bit / get confused",
                  "score": 1,
                  "created_utc": "2026-02-10 11:20:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4lcba5",
          "author": "tisDDM",
          "text": "Great Idea. I had a look at the repository. You are storing snippets in a SQL database - not using \"real Graph DB Knowledge Algorithms\" for lookup, don't you ?\n\nI am curious because I am currently looking into graph knowledge for solving a different task, not development related",
          "score": 1,
          "created_utc": "2026-02-10 10:30:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ldrdq",
              "author": "pythonr",
              "text": "Tried lightrag?",
              "score": 1,
              "created_utc": "2026-02-10 10:43:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4lfmaa",
                  "author": "tisDDM",
                  "text": "No not yet - but read some info about it a few month ago - Background is, that I have (already) prestructured graph knowledge, which is regularly updated. Got a few texts, but this is secondary.\n\nSo I am looking into ideas and implementations just for brainstorming and maybe find better solutions",
                  "score": 1,
                  "created_utc": "2026-02-10 10:59:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4levva",
              "author": "Substantial-Fish617",
              "text": "Yeah, it‚Äôs just SQLite with two tables: `nodes` and `edges`. No Neo4j, no traditional graph algorithms.\n\nBut it is real graph traversal, just not algorithm-driven. We start with semantic search using 384-dim MiniLM-L6-v2 embeddings and cosine similarity to surface relevant concepts. Each result comes with its local graph neighborhood, and the agent decides what to follow next. The LLM is effectively the traversal engine.\n\nBrute-force similarity works fine here. Even a large project is only a few hundred concepts, and 10k nodes is a theoretical ceiling. Best part, it‚Äôs a single `.db` file. No services, no infra, drop-in and done.",
              "score": 1,
              "created_utc": "2026-02-10 10:53:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ln3m5",
          "author": "HarjjotSinghh",
          "text": "this isn't ai this is lobotomized toddler but works",
          "score": 1,
          "created_utc": "2026-02-10 12:01:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4pcknu",
          "author": "Fit_Relative_8778",
          "text": "You should try Reseek. It's an AI second brain that handles semantic search across all your notes, bookmarks, and saved content automatically. It organizes everything with smart tags and extracts text from images and PDFs, which could extend the persistent memory concept beyond coding agents by providing a unified system for your entire digital library, letting you search across all your project knowledge and reference materials from one place",
          "score": 1,
          "created_utc": "2026-02-10 23:06:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ucyt5",
              "author": "mukul_29",
              "text": "but isn‚Äôt Reseek paid?",
              "score": 1,
              "created_utc": "2026-02-11 18:29:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4sufb8",
          "author": "HarjjotSinghh",
          "text": "this is what happens when you try to outsmart your own brain after 10 years of forgetting everything",
          "score": 1,
          "created_utc": "2026-02-11 14:07:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}