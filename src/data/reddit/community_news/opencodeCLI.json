{
  "metadata": {
    "last_updated": "2026-01-21 08:44:59",
    "time_filter": "week",
    "subreddit": "opencodeCLI",
    "total_items": 20,
    "total_comments": 191,
    "file_size_bytes": 210140
  },
  "items": [
    {
      "id": "1qdo24d",
      "title": "Opencode Privacy Policy is Concerning",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qdo24d/opencode_privacy_policy_is_concerning/",
      "author": "whamram",
      "created_utc": "2026-01-15 16:24:44",
      "score": 149,
      "num_comments": 30,
      "upvote_ratio": 0.97,
      "text": "Opencode's newest [privacy policy](https://opencode.ai/legal/privacy-policy), which went into effect December 16th, is extremely concerning. It is the polar opposite of their previous stance with not holding any data except for Anthropic and OpenAI's 30-day retention period, and should be especially concerning to all users who use zen or are planning to use the new black subscription.\n\nIt basically states that they collect all usage data, can store it \"as long as necessary,\" and they can share it with service providers, business partners, authorized third parties, government/law encforcement when required, and explicitly state that they will use it for marketing purposes. I was actually planning on switching to Opencode black from my Claude Pro plan, but at the very least Claude gives you a very clear 30-day retention number and provide *some* protections against using the data for marketing purposes. If you care about privacy at all, please spread the word and urge the Opencode team to at least make more clear their data retention policies or even try to change their stance on privacy completely.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qdo24d/opencode_privacy_policy_is_concerning/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nzrx5ko",
          "author": "digibioburden",
          "text": "Do they collect all of this kinda stuff if you're not using their models?",
          "score": 23,
          "created_utc": "2026-01-15 18:39:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwspwd",
              "author": "debian3",
              "text": "It's opensource, it's not like you can't look at the code to see what is happening. \n\nI just checked with opencode and the answer is no.",
              "score": 6,
              "created_utc": "2026-01-16 12:43:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrn69o",
          "author": "apodlesny",
          "text": "I have found some strange behaviour in terms of privacy in opencode CLI\n\nhttps://github.com/anomalyco/opencode/issues/8609\n\nI was really surprised seeing how my session data was sent to opencode servers for literally no reason.",
          "score": 13,
          "created_utc": "2026-01-15 17:55:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztlseu",
              "author": "touristtam",
              "text": "There is no step to reproduce the alleged observed behaviour, so I would take that with a grain of salt at first glance. I am not saying it isn't true, but the reporter doesn't provide enough evidences to definitely conclude this is the case.",
              "score": 2,
              "created_utc": "2026-01-15 23:25:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzur717",
                  "author": "mynameis_twat",
                  "text": "If you read the issue though you can easily recreate it and in the code it shows the mismatch. While explicit steps to reproduce should be included, if you‚Äôre not to see the issue or reproduce it with that info that‚Äôs on the reader not the reporter.",
                  "score": 1,
                  "created_utc": "2026-01-16 03:13:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzs3sp2",
          "author": "ori_303",
          "text": "I am honestly pretty shocked this happens‚Ä¶ really concerning",
          "score": 11,
          "created_utc": "2026-01-15 19:08:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzr8ozs",
          "author": "deegwaren",
          "text": "One thing I don't fully understand: is this about using opencode (the tool), or about using their Zen service?",
          "score": 17,
          "created_utc": "2026-01-15 16:50:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzr9s6n",
              "author": "whamram",
              "text": "I‚Äôm really not sure, but you can assume both since this is their overall privacy policy for the whole of ‚ÄúOpencode‚Äù",
              "score": 9,
              "created_utc": "2026-01-15 16:55:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzr5y8j",
          "author": "VerbaGPT",
          "text": "One great thing they did (kudos to Dax and team) - is to make it MIT. I think better privacy, especially as local models become more feasible, will be increasingly attractive vs claudecode. If they don't do it, maybe someone can fork and do it. I understand not easy.",
          "score": 13,
          "created_utc": "2026-01-15 16:37:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05fym4",
              "author": "Original_Finding2212",
              "text": "Codex is as well, no?",
              "score": 1,
              "created_utc": "2026-01-17 18:44:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzstmtn",
          "author": "kpetrovsky",
          "text": "From what I can see, privacy policy covers how they handle personal data - i.e. name, email, phone number etc. The Content (Inputs + Outputs) are described in Terms and conditions, and I don't see anything alarming there (so far) - as long as you use third-party or local services, no content is retained by Opencode.",
          "score": 6,
          "created_utc": "2026-01-15 21:08:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvfk8p",
              "author": "whamram",
              "text": "\"Other Identifying Information that You Voluntarily Choose to Provide such as information included in conversations or prompts that you submit to AI.\"\n\nThat reads to me like all conversation data is fair game, but let me know if I'm wrong there",
              "score": 6,
              "created_utc": "2026-01-16 05:51:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0cj3sc",
          "author": "PandaJunk",
          "text": "I had similar concerns reading the ToS, so I had Claude Code do a security audit on the actual code base (2026/01/18), focusing on CLI use. Specifically, I wanted to know if prompts or data were either directly or indirectly being sent anywhere besides the underlying model provider I am using.  \n  \nTL;DR: No, when using a third party LLM (i.e., not opencode's LLM) via the CLI, opencode doesn't access any prompts or data unless you use the /share command, or have set a key environmental variable, OPENCODE\\_AUTO\\_SHARE; Any stored states, prompts, or data are local to your machine (e.g., \\~/<user>/.opencaude/)",
          "score": 4,
          "created_utc": "2026-01-18 19:58:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0csy4i",
              "author": "whamram",
              "text": "Thanks, at least we know that! I am still concerned about black/zen as the idea of these services is great and fills a great niche to be able to keep up with whoever has the best/most token efficient model, but I really need it to have low or zero data retention.",
              "score": 1,
              "created_utc": "2026-01-18 20:46:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0cy7dt",
                  "author": "PandaJunk",
                  "text": "For me, we are looking at an agreement with Claude that basically says they will never use our data or any PII that gets sent to Anthropic for training or any kind of third party exposure. That opens up the potential to use otherodels for non-PII stuff, but then we can use specific models for any code that has more security issues associated with it, which is great, because then we're not locked into a single ecosystem.",
                  "score": 1,
                  "created_utc": "2026-01-18 21:15:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzvzfk2",
          "author": "rm-rf-rm",
          "text": "Theyre trending in the same trajectory as \"Open\"AI, Cline etc. Just call it \"open\" to get community momentum and the once there is sufficient traction, start the fuckery to maximize profits, appease investors etc.",
          "score": 3,
          "created_utc": "2026-01-16 08:39:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrhlm7",
          "author": "Puzzleheaded-Two7047",
          "text": "Unlike Claude Code, you can see the source of OpenCode and exactly what they‚Äôre collecting. \n\nUnlike Claude Code, you‚Äôre not locked into their policies at all. It‚Äôs MIT and you can fork it if you want.",
          "score": 8,
          "created_utc": "2026-01-15 17:30:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzripan",
              "author": "whamram",
              "text": "Is opencode black open source?",
              "score": 1,
              "created_utc": "2026-01-15 17:35:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzrjcku",
                  "author": "Puzzleheaded-Two7047",
                  "text": "I was referring to if this policy applies to opencode broadly. No idea re: black.\n\nhttps://www.reddit.com/r/opencodeCLI/s/MO4mwGECH5\n\nI use opencode strictly because I don‚Äôt want my local developer tooling to come with vendor / model lock in.",
                  "score": 7,
                  "created_utc": "2026-01-15 17:38:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrq4ww",
          "author": "rmaxdev",
          "text": "Data is gold",
          "score": 2,
          "created_utc": "2026-01-15 18:08:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs5o5p",
              "author": "Fickle_Degree_2728",
              "text": "Diamond",
              "score": 2,
              "created_utc": "2026-01-15 19:17:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nztj8g4",
          "author": "kgoncharuk",
          "text": "but it seems they collect only personal tracking data (like user with this IP has N agents and used M features) rather storing the source code. Last one would be very worrying indeed, but it's not listed in privacy policy as data they collect. \n\nAlso as you normally do not login in the OpenCode itself, imo it's not a massive risk that they store some usage analytics. Would make sense for them to have some expiration for that data, but I guess it will come with time.",
          "score": 1,
          "created_utc": "2026-01-15 23:11:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuywaa",
          "author": "zhambe",
          "text": "I mean, it's open source, right? You can literally use it to castrate its own code base, and tear out whatever snitch code they put in there.",
          "score": 1,
          "created_utc": "2026-01-16 03:59:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzveiug",
              "author": "xmnstr",
              "text": "The opencode zen platform isn't open source, is it? Kinda hard to tell what of our queries they save from looking at the client source code.",
              "score": 2,
              "created_utc": "2026-01-16 05:43:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzvsb79",
          "author": "chevdor",
          "text": "I did not dig but the change may be for a few simple reasons:\n- opencode uses the model of sessions so it may indeed to keep data for a while until the session is close. In theory that could be months. That being said, this is mostly local but that means that months after you started your session, the session's context will still be sent\n- since opencode uses multiple models, their term probably also need to match the weakest and the real conditions depend on the underlying model(s) you are using.\n\nTo clarify, they probably should clearly explain the diff between opencode the cli, the data they may gather from the cli and the data related to the models used for the processing.",
          "score": 1,
          "created_utc": "2026-01-16 07:35:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0itekq",
          "author": "elissaxy",
          "text": "Time to use OpenClone",
          "score": 0,
          "created_utc": "2026-01-19 18:37:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv6k4w",
          "author": "Lyuseefur",
          "text": "Ok I read all this and IDK. Legal buzzwords don‚Äôt mean shit. Code is where it is. All the closed providers of course dgaf. \n\nNow opencode by being a provider probably had some lawyer draft shit to say whatever so they can sell black for $200 a month.\n\nThat said, if someone can cite anything reasonable-and that GitHub comment above I couldn‚Äôt replicate, then we can do pitchfork sales too.\n\nMeanwhile, grains of salt is warranted at this time‚Ä¶",
          "score": -1,
          "created_utc": "2026-01-16 04:48:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qexcsu",
      "title": "i wanted to work 100% from the terminal",
      "subreddit": "opencodeCLI",
      "url": "https://v.redd.it/o0s0pgk9ysdg1",
      "author": "Professional_Cap3741",
      "created_utc": "2026-01-17 00:19:11",
      "score": 131,
      "num_comments": 32,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qexcsu/i_wanted_to_work_100_from_the_terminal/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o01x296",
          "author": "sudonem",
          "text": "This is rad, and it‚Äôs essentially the workflow I have by pairing OpenCode with neovim & tmux. \n\nCurious to see how it shapes up (but you‚Äôll have to extricate tmux & neovim from my cold dead carcass üôÉ)",
          "score": 16,
          "created_utc": "2026-01-17 04:37:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o049bux",
              "author": "92smola",
              "text": "Hahahah same",
              "score": 3,
              "created_utc": "2026-01-17 15:24:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o01o8up",
          "author": "Old-Sherbert-4495",
          "text": "will you be sharing this project?? or at least how you built?",
          "score": 9,
          "created_utc": "2026-01-17 03:36:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03jug0",
          "author": "verkavo",
          "text": "Tmux split screen with Lazygit and Opencode is an easy way to follow what AI had changed.",
          "score": 6,
          "created_utc": "2026-01-17 13:01:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02hx73",
          "author": "awfulalexey",
          "text": "Link?",
          "score": 3,
          "created_utc": "2026-01-17 07:24:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0332sq",
          "author": "splitbrainhack",
          "text": "linkeroo ?",
          "score": 3,
          "created_utc": "2026-01-17 10:42:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01k6pu",
          "author": "Old-Sherbert-4495",
          "text": "I wanted this all along.",
          "score": 2,
          "created_utc": "2026-01-17 03:09:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02g5qy",
          "author": "jirubizu",
          "text": "Is there a gh link dont want to lose this project",
          "score": 2,
          "created_utc": "2026-01-17 07:08:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02ya36",
          "author": "4gustaf",
          "text": "Exactly my gripe, good job!",
          "score": 2,
          "created_utc": "2026-01-17 09:57:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o034k1d",
          "author": "Embarrassed-Mail267",
          "text": "Man this is the most beautiful thing I've seen this year.... well designed!! Fluid! Beautiful.   \nthis feature alone makes me want to switch to opencode..\n\n  \ni am a cli power user through and through (see my other posts)... but I need the IDE for effective code review / checking agent work / stress testing its architecture.... Antigravity delivered what i needed.   \n\n  \nBut your thing is so clean, i want to use it just to stare at its beauty.",
          "score": 2,
          "created_utc": "2026-01-17 10:56:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03bj68",
          "author": "silopolis",
          "text": "WANT! üòç",
          "score": 2,
          "created_utc": "2026-01-17 11:58:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03gyrv",
          "author": "grepharders",
          "text": "Tried the new UI as well  it‚Äôs nice but the terminal is still my go to",
          "score": 2,
          "created_utc": "2026-01-17 12:41:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o042f18",
          "author": "tkdeveloper",
          "text": "This kind of what i do with helix + zellij. Have one tab for helix, one for shell commands, one for opencode, and one for lazygit",
          "score": 2,
          "created_utc": "2026-01-17 14:49:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04ocr5",
          "author": "Ok_Proposal_1290",
          "text": "If it's possible could I get a Link? This looks AMAZING",
          "score": 2,
          "created_utc": "2026-01-17 16:36:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o055geb",
          "author": "Forgot_Password_Dude",
          "text": "Where GitHub repo for this",
          "score": 2,
          "created_utc": "2026-01-17 17:56:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05ns3f",
          "author": "anon_wick",
          "text": "Link please",
          "score": 2,
          "created_utc": "2026-01-17 19:21:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0951dc",
          "author": "Serious_Client6274",
          "text": "warp or ghostty + zellij, opening the CLI coding agent of your choice + lazygit + yazi + neovim",
          "score": 2,
          "created_utc": "2026-01-18 07:14:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02e6h9",
          "author": "garloid64",
          "text": "What are we doing here? We've had this experience for so long with so many vscode extensions, why is our hyper advanced state of the art autonomous AI agent technology regressing to the 1980s when it comes to UI?",
          "score": 2,
          "created_utc": "2026-01-17 06:51:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03tcqp",
              "author": "vienna_city_skater",
              "text": "The reality is building good desktop applications is hard and the TUI is a shortcut that devs accept. That was the reasoning behing Claude Code and many projects copied this strategy. Also the agentic future may involve less manual input than many anticipate, so why spend time building good UX?",
              "score": 2,
              "created_utc": "2026-01-17 14:00:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0btkn9",
                  "author": "SquareAbrocoma2203",
                  "text": "Writing graphical apps is a pain in the ass, that's true, especially ones that work on all the 58 billion edge cases of different operating systems.  I've literally built webUI's on a local system just so I didn't have to fuck with the OS.",
                  "score": 3,
                  "created_utc": "2026-01-18 17:59:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o04rtx1",
                  "author": "trypnosis",
                  "text": "That makes sense. Maybe the future will be GUI free.",
                  "score": 1,
                  "created_utc": "2026-01-17 16:52:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0bezst",
                  "author": "Maasu",
                  "text": "I just hate touching my mouse, it's a dickhead that slows me down",
                  "score": 1,
                  "created_utc": "2026-01-18 16:50:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o02ikt7",
              "author": "trypnosis",
              "text": "I spent the last 15 years going full GUI. Now i feel like I‚Äôm going before to before the GUI revolution. I spending more and more time in the terminal.",
              "score": 2,
              "created_utc": "2026-01-17 07:30:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03tnpt",
                  "author": "vienna_city_skater",
                  "text": "I feel like I'm back at university where I went all Emacs from coding to notes to email to web browsing. Not sure why I did it, but it felt L337 for sure. EDIT: That was right after my clickibunti Vista phase, so maybe a backlash from that era.",
                  "score": 2,
                  "created_utc": "2026-01-17 14:01:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0bt9yq",
              "author": "SquareAbrocoma2203",
              "text": "~~Regressing~~  Progressing.",
              "score": 1,
              "created_utc": "2026-01-18 17:57:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o09b7xm",
          "author": "lev400",
          "text": "Have you tried OpenCode Desktop ?",
          "score": 1,
          "created_utc": "2026-01-18 08:09:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0otz9m",
          "author": "erracode",
          "text": "Really good, what I keep struggling the most is that I really like to add images in the chats, that's why I keep having antigravity or cursor opened with a terminal of open code inside it, I wonder how can I have best of all worlds",
          "score": 1,
          "created_utc": "2026-01-20 16:21:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01m6r1",
          "author": "Ok-Painter573",
          "text": "So recreating gh copilot/cursor in terminal?",
          "score": 0,
          "created_utc": "2026-01-17 03:22:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o030t86",
          "author": "Reasonable-Layer1248",
          "text": "Taking everything into account, I use warp+cli or zed, and I think it's not bad.",
          "score": 0,
          "created_utc": "2026-01-17 10:21:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qeufrc",
      "title": "One week with OpenCode Black",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qeufrc/one_week_with_opencode_black/",
      "author": "JohnnyDread",
      "created_utc": "2026-01-16 22:33:35",
      "score": 102,
      "num_comments": 71,
      "upvote_ratio": 0.97,
      "text": "Well, it finally happened. After a week of pretty heavy (but not insane) coding, I finally hit my weekly quota with OpenCode Black. Very comparable experience to Claude Code Max but with access to more models. If OpenCode can keep this up and continue providing the same level of usage, this will be one of the best subscription values out there.... if\n\nedit: lots of questions:\n\n* I am using the top-tier 20X plan ($200/mo).\n* Some days I was working all day from before dawn till well late into the night. Other days I had meetings and other distractions, so on average, about 6-8 hours a day. \n* I don't do the silly 10 agents generating tons of slop thing. I iterate with the LLM on detailed specifications and get one or two agents working on those. While those are running, I review code, test, and sometimes use a third agent for small tasks. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qeufrc/one_week_with_opencode_black/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o01gdqe",
          "author": "jovialfaction",
          "text": "I don't understand the economics of it. Anthropic can offer Claude Code at this price because they run the model and inference doesn't actually cost as much as the advertised API price. \n\nBut how can OpenCode do it? They have to pay the API provider, so the only way to make a profit is to hope the user uses less than the cost of the tokens?",
          "score": 22,
          "created_utc": "2026-01-17 02:46:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02c83j",
              "author": "whimsicaljess",
              "text": "So long as people aren't running ralph loops or other insane shit, these monthly subs are probably generally profitable or at least break even.",
              "score": 6,
              "created_utc": "2026-01-17 06:34:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o081zfi",
              "author": "philosophical_lens",
              "text": "Anomaly is backed by YC and a bunch of other big name Silicon Valley VCs. The most plausible theory is that they are burning VC money on Opencode black to gain marketshare. \n\nhttps://sst.dev/about/",
              "score": 2,
              "created_utc": "2026-01-18 02:45:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09d2xs",
                  "author": "DutyPlayful1610",
                  "text": "A lot of the companies also give out free credits, so people burn them.",
                  "score": 1,
                  "created_utc": "2026-01-18 08:26:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0akvxz",
              "author": "Ordinary-You8102",
              "text": "Thats actually the dream of every company like anthropic. they sell the API for enterprises for cheaper, they realize not everyone will use their agents but this way they get a higher share of the market.",
              "score": 1,
              "created_utc": "2026-01-18 14:19:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0n3ue8",
              "author": "sentrix_l",
              "text": "Correct",
              "score": 1,
              "created_utc": "2026-01-20 09:55:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o02bjla",
              "author": "t4a8945",
              "text": "My theory is that they're buying a bunch of Claude Max 20 and similar \"cheap\" subscriptions, and we're basically paying to access the models without having to manage the lifecycle of the accounts.\n\n\nI mean... That's actually genius.¬†\n\n\nI hope that's what they do.¬†",
              "score": -5,
              "created_utc": "2026-01-17 06:28:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o04uhn6",
                  "author": "RegrettableBiscuit",
                  "text": "Ain't no way. Anthropic would shut them down before you could say \"TOS violation.\"¬†",
                  "score": 3,
                  "created_utc": "2026-01-17 17:04:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o08f8oj",
                  "author": "AkiDenim",
                  "text": "Just how naive is this opinion? Lmao",
                  "score": 1,
                  "created_utc": "2026-01-18 04:01:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o00gpjg",
          "author": "koddajr",
          "text": "6 days using opus 4.5? how many hours for day? parallel agents or a single instance?",
          "score": 15,
          "created_utc": "2026-01-16 23:11:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01y4jv",
              "author": "JohnnyDread",
              "text": "Mostly Opus. 6-8hr/day. 1-2 agents typically , rarely 3.",
              "score": 14,
              "created_utc": "2026-01-17 04:44:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o00kxul",
          "author": "alOOshXL",
          "text": "What sub  20 or max 5 on opencode black?",
          "score": 10,
          "created_utc": "2026-01-16 23:35:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01yeve",
              "author": "JohnnyDread",
              "text": "20 ($200/mo)",
              "score": 2,
              "created_utc": "2026-01-17 04:46:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o00e6zg",
          "author": "Firm_Meeting6350",
          "text": "Interesting, thanks for sharing. Can the sub only be used for opencode?",
          "score": 17,
          "created_utc": "2026-01-16 22:58:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00fuoc",
              "author": "t4a8945",
              "text": "That's such a meta comment. Great thinking. I hope so haha¬†",
              "score": 3,
              "created_utc": "2026-01-16 23:06:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00r0x1",
                  "author": "ZeSprawl",
                  "text": "No they don‚Äôt limit where it can be used",
                  "score": 3,
                  "created_utc": "2026-01-17 00:09:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0172fp",
              "author": "anfelipegris",
              "text": "That's a loaded comment, I love it!",
              "score": 1,
              "created_utc": "2026-01-17 01:47:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o01f6gy",
          "author": "fuyao_j",
          "text": "https://preview.redd.it/2kegl65jntdg1.png?width=2474&format=png&auto=webp&s=472d382a24ea306c47cc1477049f077b199b4ec8\n\nSharing my experience. I used it with oMo.",
          "score": 7,
          "created_utc": "2026-01-17 02:38:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01y2uq",
              "author": "Background_Might_700",
              "text": "Thanks for the share. Are you using the $200 Opencode Black plan?",
              "score": 2,
              "created_utc": "2026-01-17 04:44:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0274gg",
                  "author": "fuyao_j",
                  "text": "Yup, $200 plan.  \nAs for me limits are crazy generous right now, it feels too good to last.",
                  "score": 1,
                  "created_utc": "2026-01-17 05:51:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o081hfl",
              "author": "philosophical_lens",
              "text": "How do you get this dashboard?",
              "score": 2,
              "created_utc": "2026-01-18 02:42:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0c9p7v",
                  "author": "fuyao_j",
                  "text": "From this package [https://github.com/junhoyeo/tokscale](https://github.com/junhoyeo/tokscale)",
                  "score": 2,
                  "created_utc": "2026-01-18 19:13:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o00awt7",
          "author": "jpcaparas",
          "text": "\\> Very comparable experience to Claude Code Max\n\nA bit more generous in your opinion? Or pretty much the same.",
          "score": 4,
          "created_utc": "2026-01-16 22:41:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03lrtc",
              "author": "seaweeduk",
              "text": "Not taking a shot at the black plans, I'm on the waitlist and will cancel my anthropic plan as soon as they make a $100 option available. But there is a 0% chance any black plan will come close with the amount of tokens you can get out of Anthropic's plans. I'm on 5x Pro $100 plan this month I got $1189 usage out of a $100 sub without even once hitting my 5 hour or 7 day limits. Looking at previous months 10x - 15x value has been common for me.\n\nZen cannot compete with this they would lose far too much money as they have to pay the inflated API prices that effectively subsidize these plans. \n\nhttps://preview.redd.it/22zk8ngrswdg1.png?width=1300&format=png&auto=webp&s=4b0961d2012177afe2080f4f26fa3d22509538a5",
              "score": 3,
              "created_utc": "2026-01-17 13:14:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o07gj1m",
                  "author": "lundrog",
                  "text": "What plugin or etc is that? I would like to try it",
                  "score": 3,
                  "created_utc": "2026-01-18 00:51:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o03s0w8",
                  "author": "foolsgold1",
                  "text": "What makes you think they are paying the retail API price?",
                  "score": 2,
                  "created_utc": "2026-01-17 13:52:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o01yi0s",
              "author": "JohnnyDread",
              "text": "Seemed about the same, honestly. Maybe a little more generous, but I didn't keep meticulous track of my Claude usage when I had it.",
              "score": 1,
              "created_utc": "2026-01-17 04:47:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o00j2h5",
          "author": "Lumpy-Carob",
          "text": "Thats good to know and thank you for sharing -   \nIt would be useful to share token usage with tools like  ccusage or something similar \n\n\\`npx @ ccusage/opencode@latest\\`    [https://ccusage.com/guide/opencode/](https://ccusage.com/guide/opencode/)  \n\nPS: I have no affiliation with ccusage",
          "score": 6,
          "created_utc": "2026-01-16 23:24:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00rpe1",
          "author": "SlaveZelda",
          "text": "What Opencode Black Sub? 20, 100 or 200?",
          "score": 5,
          "created_utc": "2026-01-17 00:13:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01ygyf",
              "author": "JohnnyDread",
              "text": "The highest tier - $200/mo",
              "score": 1,
              "created_utc": "2026-01-17 04:46:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o00sle3",
          "author": "Background_Might_700",
          "text": "Did you use oh-my-opencode with this?",
          "score": 5,
          "created_utc": "2026-01-17 00:18:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0888ar",
              "author": "Apart-Permission-849",
              "text": "Would like to see a config if possible",
              "score": 1,
              "created_utc": "2026-01-18 03:20:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o00trgf",
          "author": "FlyingDogCatcher",
          "text": "I hope these guys kick ass",
          "score": 5,
          "created_utc": "2026-01-17 00:25:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00kyii",
          "author": "LostLakkris",
          "text": "I signed up within 30minutes the tweet.\n\nI'm still waiting for activation :-(",
          "score": 4,
          "created_utc": "2026-01-16 23:35:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00r4au",
              "author": "ZeSprawl",
              "text": "The tweet from last week or this week?",
              "score": 1,
              "created_utc": "2026-01-17 00:10:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00vgc1",
                  "author": "LostLakkris",
                  "text": "The GA tweet, think that's this week.",
                  "score": 2,
                  "created_utc": "2026-01-17 00:35:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o00ahch",
          "author": "ReporterCalm6238",
          "text": "How much Opus 4.5 was included?",
          "score": 2,
          "created_utc": "2026-01-16 22:39:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00aot0",
              "author": "JohnnyDread",
              "text": "That's pretty much all I use. I experimented with some other models. They just added Codex 5.2 yesterday, so I did a little bit with it, but pretty much everything else was with Opus.",
              "score": 2,
              "created_utc": "2026-01-16 22:40:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o00uniq",
          "author": "Lyuseefur",
          "text": "Waiting for my CC to run out then will get this one. Going to not renew my Codex either",
          "score": 2,
          "created_utc": "2026-01-17 00:30:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00xveu",
              "author": "Fit-Palpitation-7427",
              "text": "Because opencode with opus is better then cc and opus?",
              "score": 1,
              "created_utc": "2026-01-17 00:49:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00y6jy",
                  "author": "Lyuseefur",
                  "text": "Yes",
                  "score": 3,
                  "created_utc": "2026-01-17 00:51:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o04faff",
          "author": "warner_lyricist",
          "text": "They are attracting people with higher limits but will need to adjust , there‚Äôs no way they can give same opus usage as anthropic, let‚Äôs be realistic",
          "score": 2,
          "created_utc": "2026-01-17 15:53:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08mlq3",
          "author": "jNSKkK",
          "text": "This looks very promising. Annoying that the waitlist isn't determinate though. My Claude Code runs out today and I can't afford to get on the waitlist, renew CC then a week later have to pay for Black because I got in.\n\nAnyone used the $100 plan and can comment on usage?",
          "score": 2,
          "created_utc": "2026-01-18 04:49:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00q221",
          "author": "mattparlane",
          "text": "Thanks for sharing, I'm on the waitlist.\n\nDoes anyone have any idea how long the waitlist is?\n\nI feel like this might be a tight business model for them. The model providers can spread load across their entire system and adjust limits as their hardware allows, but players like OpenCode will be paying API pricing (possibly with an enterprise discount) on every token. Hope it lasts.",
          "score": 1,
          "created_utc": "2026-01-17 00:04:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o015han",
          "author": "blu38berry",
          "text": "More details please",
          "score": 1,
          "created_utc": "2026-01-17 01:36:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o041h7q",
          "author": "Busy-Chemistry7747",
          "text": "The thing I'm missing are projects and memory for non coding actions. The whole package is pretty good for Claude. If there was an easy (and probably local?) Replacement I'd switch",
          "score": 1,
          "created_utc": "2026-01-17 14:44:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o075nxr",
          "author": "matija2209",
          "text": "How can your brains process all the code outputted?",
          "score": 1,
          "created_utc": "2026-01-17 23:53:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0kfkm3",
              "author": "Price-Visual",
              "text": "who reads code anymore",
              "score": 1,
              "created_utc": "2026-01-19 23:15:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0al423",
          "author": "Ordinary-You8102",
          "text": "is it really worth it? 200$/month sound like a lot considering you have other models with \"unlimited usage\" for 10-50$? or is it cause claude is that good?",
          "score": 1,
          "created_utc": "2026-01-18 14:20:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0as50t",
              "author": "JohnnyDread",
              "text": "There are no \"unlimited usage\" plans. All subscriptions have some sort of hourly/weekly cap or throttle. OpenCode Black and previously Claude Code Max are well worth it to me because I'm certainly going to spend at least $200/month if I were paying by the token. And if these plans give me any kind of a discount, even a small one, it's worth it.",
              "score": 1,
              "created_utc": "2026-01-18 14:59:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0beecr",
                  "author": "Ordinary-You8102",
                  "text": "GH Copilot/Codex/Gemini oauth isnt way more?",
                  "score": 1,
                  "created_utc": "2026-01-18 16:47:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0szs0y",
          "author": "iproblywontpostanywy",
          "text": "It‚Äôs a really good value. I hit it the second day. No loops, only 2-3 terminals open in different projects.\n\nFor reference I have the $200 sub for OC, CC, Cursor, Codex, & Gemini for work.\n\nPretty comparable to the $200 cursor sub in terms of usage.\n\nCC is junk and they serve you worse and worse models as you use more. You can see for yourself when you get high in usage just run a terminal using their api or vertex api and it is night and day. I use Opus in OC via Vertex and it provides the fastest and most consistent model IMO. \n\nCodex is pretty great, seems like they just progressively slow down the responses as you get up there which I personally prefer.\n\nI like the OC and if I was getting a sub personally I would get that and if I was consistently using that just use Vertex",
          "score": 1,
          "created_utc": "2026-01-21 05:16:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcsm90",
      "title": "OpenCode Black is now generally-available",
      "subreddit": "opencodeCLI",
      "url": "https://opencode.ai/black",
      "author": "JohnnyDread",
      "created_utc": "2026-01-14 16:57:42",
      "score": 71,
      "num_comments": 63,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qcsm90/opencode_black_is_now_generallyavailable/",
      "domain": "opencode.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nzkotc2",
          "author": "Fearless-Elephant-81",
          "text": "The limits are still vague",
          "score": 29,
          "created_utc": "2026-01-14 17:34:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkp4ce",
              "author": "Hauven",
              "text": "Agreed. Someone mentioned in Discord that they get over $200 per week usage allowance on the top plan I believe. But yeah, the information about these plans are extremely vague so I'll wait for now and see what happens over the coming weeks.",
              "score": 6,
              "created_utc": "2026-01-14 17:35:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqng1y",
                  "author": "edtv82",
                  "text": "I signed up, but I'm not getting charged until it goes live.",
                  "score": 1,
                  "created_utc": "2026-01-15 15:13:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzksmap",
              "author": "acmethunder",
              "text": "Yep. $100/month is 5x more usage than what, exactly?",
              "score": 6,
              "created_utc": "2026-01-14 17:51:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nznvfqt",
                  "author": "Ok_Road_8710",
                  "text": "It's 5x more than $20, trust us",
                  "score": 5,
                  "created_utc": "2026-01-15 03:01:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzqhxd8",
                  "author": "dmancilla",
                  "text": "George Washington: Nobody knows",
                  "score": 2,
                  "created_utc": "2026-01-15 14:46:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzksorp",
                  "author": "Fearless-Elephant-81",
                  "text": "Claude is the same tho just saying",
                  "score": 3,
                  "created_utc": "2026-01-14 17:51:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzkqxtr",
              "author": "markis",
              "text": "Maybe they opened this because of that post where someone found the page, and the details just aren‚Äôt figured out yet.",
              "score": 6,
              "created_utc": "2026-01-14 17:44:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzljfry",
              "author": "hexa01010",
              "text": "Totally, using the 20$ for testing for now, guess the only way is to try for ourselves",
              "score": 6,
              "created_utc": "2026-01-14 19:51:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzppjyn",
                  "author": "jorgejhms",
                  "text": "You already get it? It was fast?",
                  "score": 1,
                  "created_utc": "2026-01-15 11:59:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzn7odk",
              "author": "Ok_Shape_4863",
              "text": "industry standard lmao cant believe people are falling for it\n\n  \nthe people who say \"claude code gives you soooo much more tokens\" are my favorite (literally 0 numbers attached to any aspect of analysis you would need to do to calculate that)",
              "score": 2,
              "created_utc": "2026-01-15 00:44:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqtri9",
                  "author": "Keep-Darwin-Going",
                  "text": "No matter what it will still be cheaper than opencode, you are buying direct from supplier and it is known fact that Claude never give discount to anyone even the biggest enterprise. So this opencode black sustainability is questionable",
                  "score": 1,
                  "created_utc": "2026-01-15 15:43:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzlokda",
              "author": "jpcaparas",
              "text": "If you search Twitter, you'll get a mixed bag of responses from early adopters.",
              "score": 1,
              "created_utc": "2026-01-14 20:14:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzzzuvc",
              "author": "blankeos",
              "text": "super vague, that's why I can't buy yet. I want to support them though. Knowing Dax and the team, they're pretty public about \"experimenting\" w/ pricing and seeing where it goes, hence the \"Limits may be adjusted and plans may be discontinued in the future\"",
              "score": 1,
              "created_utc": "2026-01-16 21:46:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzmj9so",
          "author": "softboyled",
          "text": "\"a lot\"\n\"more than a lot\"\n\"way more than more than a lot\"\n\ngenius",
          "score": 12,
          "created_utc": "2026-01-14 22:34:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznbbfn",
          "author": "WHEREISMYCOFFEE_",
          "text": "I'm a big OpenCode fan but these plans are just silly. There's literally no info on what you get other than \"more usage\" and the whole waitlist thing just screams \"We're burning new subscriber's money to subsidize power users while we hope for enough whales to sign up\". This is all too vague for a tool that needs to be taken seriously.",
          "score": 6,
          "created_utc": "2026-01-15 01:04:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzngmo5",
          "author": "jNSKkK",
          "text": "Anyone tried the $100 plan yet? My Claude Max 5x sub ends in 2 days and I'm sick of it plowing through my usage limits.",
          "score": 5,
          "created_utc": "2026-01-15 01:35:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkphqz",
          "author": "ApocaIypticUtopia",
          "text": "Would be nice to know if they have ZDR with all 3rd party services, similar to Github copilot.",
          "score": 6,
          "created_utc": "2026-01-14 17:37:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzontxk",
              "author": "whamram",
              "text": "Sadly I don't think privacy is going to be a focus of Opencode in the future... I looked through their newest privacy policy and it says basically they can collect any data they want and store it as long as they want and share it with anyone. I was planning on switching to this from Claude, but until they make a statement about privacy and their privacy policy changes I'm sticking with Claude's 30-day policy. [https://opencode.ai/legal/privacy-policy](https://opencode.ai/legal/privacy-policy)",
              "score": 6,
              "created_utc": "2026-01-15 06:17:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzoz2wr",
                  "author": "trypnosis",
                  "text": "I wonder what the wider community thinks. I would put this a post.",
                  "score": 3,
                  "created_utc": "2026-01-15 07:56:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzlasf0",
              "author": "VanPepe",
              "text": "what the hell is ZDR",
              "score": 2,
              "created_utc": "2026-01-14 19:11:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzlqo85",
                  "author": "Downtown-Elevator369",
                  "text": "Zero Data Retention",
                  "score": 4,
                  "created_utc": "2026-01-14 20:24:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nznily4",
              "author": "LostLakkris",
              "text": "I think Zen's consumption list somewhere shows who claims ZDR and who doesn't.\nI think openai and anthropic were in the list as 30 day.",
              "score": 1,
              "created_utc": "2026-01-15 01:46:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzlr8v6",
          "author": "t4a8945",
          "text": "I'm in 100%, will try it out when my Claude Max ends. I'll take the $100 plan and see if it matches my use case. Well done opencode¬†",
          "score": 6,
          "created_utc": "2026-01-14 20:26:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlfpjb",
          "author": "beth_maloney",
          "text": "What's the advantage of this over copilot?",
          "score": 2,
          "created_utc": "2026-01-14 19:34:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzll66d",
              "author": "JohnnyDread",
              "text": "Presumably more usage, but because we don't have visibility into the limits, we just don't know yet.",
              "score": 2,
              "created_utc": "2026-01-14 19:58:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzlxtx5",
                  "author": "kaizoku156",
                  "text": "I don't see how opencode would be able to negotiate a better rate or provide more usage than microsoft with copilot or anthropic themselves with the claude plans, practically no other ai tool provides the same value except the big companies own subscriptions",
                  "score": 3,
                  "created_utc": "2026-01-14 20:56:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzlqj4x",
                  "author": "beth_maloney",
                  "text": "I've always thought that copilot was pretty good value. I think it'll be hard to compete on price with MS and if copilot adds support for opencode then what's the differentiator?",
                  "score": 1,
                  "created_utc": "2026-01-14 20:23:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzn4nlm",
                  "author": "Mr_Hyper_Focus",
                  "text": "Zero chance this allots more usage than copilot. Absolutely 0. I love opencode and the team but this is a pipe dream",
                  "score": 1,
                  "created_utc": "2026-01-15 00:27:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzm6no0",
              "author": "dbkblk",
              "text": "Copilot read all your prompts, there's no privacy. The same for [z.ai](http://z.ai) and Google. It's all written in the TOS.  \nClaude Pro is not supposed to do that (but given the recent decisions, I'm starting to doubt).  \nSynthetic is private, but open models only (glm 4.7 is quite good compared to sonnet 4.5).\n\nLet's wait about how opencode stands with black.",
              "score": 1,
              "created_utc": "2026-01-14 21:36:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzonzhg",
                  "author": "whamram",
                  "text": "It's really not looking too great on the privacy standpoint... [https://opencode.ai/legal/privacy-policy](https://opencode.ai/legal/privacy-policy)",
                  "score": 3,
                  "created_utc": "2026-01-15 06:18:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzth0d5",
                  "author": "touristtam",
                  "text": "Pricing pages (as of Jan 15, 2026)\n\n- [Gemini (Google)](https://gemini.google/subscriptions/)\n- [Copilot (Github)](https://github.com/features/copilot/plans)\n- [z.ai](https://z.ai/subscribe)\n- [Claude (Anthropic)](https://claude.com/pricing)\n- [Synthetic](https://synthetic.new/pricing)\n- [Minimax](https://platform.minimax.io/subscribe/coding-plan)",
                  "score": 1,
                  "created_utc": "2026-01-15 22:59:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o08j24d",
              "author": "Tenet_mma",
              "text": "Probably nothing",
              "score": 1,
              "created_utc": "2026-01-18 04:25:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzm4emn",
          "author": "dartoumi",
          "text": "How to get off the waiting list and being charged automatically?",
          "score": 2,
          "created_utc": "2026-01-14 21:26:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzp2qak",
              "author": "delusional-",
              "text": "Asking the same question. Accidentally signed up for the $200 plan, intended to sign up for the $100 plan, but there is no way to change or cancel it.\n\nUsed link for payment, but the subscription is not visible in their interface either..",
              "score": 1,
              "created_utc": "2026-01-15 08:31:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzpp2b8",
          "author": "teratron27",
          "text": "The UI of that page is horrendous",
          "score": 2,
          "created_utc": "2026-01-15 11:55:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpzst0",
              "author": "vienna_city_skater",
              "text": "Vibe coded to the max",
              "score": 1,
              "created_utc": "2026-01-15 13:09:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzvt9hw",
          "author": "Firm_Curve8659",
          "text": "Black sub is only for OC or possible to use also in other tools?",
          "score": 2,
          "created_utc": "2026-01-16 07:44:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzx9w71",
              "author": "JohnnyDread",
              "text": "That‚Äôs a good question. It would be rather ironic if they disallowed other clients.",
              "score": 2,
              "created_utc": "2026-01-16 14:19:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzksxtz",
          "author": "DasBlueEyedDevil",
          "text": "![gif](giphy|eRqxSA8uc2yas)",
          "score": 2,
          "created_utc": "2026-01-14 17:52:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzp19qb",
          "author": "theTallGiraffee",
          "text": "Will we be able to use opus 4.5, presumably through API and not the subscription?",
          "score": 1,
          "created_utc": "2026-01-15 08:16:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzppy0q",
              "author": "jorgejhms",
              "text": "You already can, with zen, Anthropic or open router.",
              "score": 1,
              "created_utc": "2026-01-15 12:01:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrb4cv",
                  "author": "vienna_city_skater",
                  "text": "Or Azure, or Github Copilot, or ‚Ä¶",
                  "score": 2,
                  "created_utc": "2026-01-15 17:00:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07sqaa",
          "author": "warpedgeoid",
          "text": "How does pricing compare to GitHub Copilot?",
          "score": 1,
          "created_utc": "2026-01-18 01:54:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bz9lu",
          "author": "lemon07r",
          "text": "So.. how much usage is the $20 plan? lmao",
          "score": 1,
          "created_utc": "2026-01-18 18:25:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0cnfpw",
          "author": "Competitive_Drive743",
          "text": "Hey guys on this plan can you use claude opus ?",
          "score": 1,
          "created_utc": "2026-01-18 20:19:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cnu39",
              "author": "JohnnyDread",
              "text": "Yes",
              "score": 1,
              "created_utc": "2026-01-18 20:21:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzp31xe",
          "author": "trypnosis",
          "text": "I liked the leaked 6x and 21x options",
          "score": 1,
          "created_utc": "2026-01-15 08:34:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08is77",
          "author": "Tenet_mma",
          "text": "What is with all these weird plans‚Ä¶ 5x more 20x more. Is this marketing or just an easy way to make money by varying rate limits??",
          "score": 0,
          "created_utc": "2026-01-18 04:23:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzktw4l",
          "author": "Hodler-mane",
          "text": "I thought this was OPEN code. an open source, community built, free harness for various AI models. sick of people selling out for this.",
          "score": -12,
          "created_utc": "2026-01-14 17:57:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkxpuc",
              "author": "JohnnyDread",
              "text": "OpenCode is still open source, and you can still use it with the models and providers of your choice.",
              "score": 10,
              "created_utc": "2026-01-14 18:14:07",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzkxyr3",
              "author": "Aggressive-Habit-698",
              "text": "It's only the zen provider. OC itself is open source - see GitHub repo. Nothing changed.\nWhat's your suggestion to earn money? At least to break even.",
              "score": 7,
              "created_utc": "2026-01-14 18:15:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzl6lvh",
                  "author": "DasBlueEyedDevil",
                  "text": "Sell t-shirts, obv",
                  "score": 1,
                  "created_utc": "2026-01-14 18:53:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzlqgnd",
          "author": "Magnus114",
          "text": "Time to stop using open code. \n\nI really liked the idea if an open ai coding software that didn‚Äôt favor any provider.",
          "score": -9,
          "created_utc": "2026-01-14 20:23:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdylr7",
      "title": "oh-my-opencode is great, just I think got a bit bloated, so here is slimmed forked",
      "subreddit": "opencodeCLI",
      "url": "https://github.com/alvinunreal/oh-my-opencode-slim",
      "author": "alvinunreal",
      "created_utc": "2026-01-15 22:52:47",
      "score": 67,
      "num_comments": 31,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qdylr7/ohmyopencode_is_great_just_i_think_got_a_bit/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzzw0ag",
          "author": "N2siyast",
          "text": "Never understood people using these bloated bullshit frameworks. Few custom agents, few custom prompts and minimum skills with some security hooks is more than enough",
          "score": 4,
          "created_utc": "2026-01-16 21:28:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0043o8",
              "author": "alvinunreal",
              "text": "https://preview.redd.it/zgqqbuaibsdg1.png?width=1600&format=png&auto=webp&s=80a7f70b2fec3dc36e57a25d7de4d17565899dd8",
              "score": 1,
              "created_utc": "2026-01-16 22:07:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzv1459",
          "author": "[deleted]",
          "text": "OMO is useless. It modifies files in planner mode.",
          "score": 8,
          "created_utc": "2026-01-16 04:12:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzz20rf",
              "author": "DirtyIlluminati",
              "text": "Name a better alternative to delegate task to sub-agents and orchestrate the  whole thing ?",
              "score": 4,
              "created_utc": "2026-01-16 19:08:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0b9w76",
                  "author": "kkordikk",
                  "text": "Isn‚Äôt OpenCode doing this on its own? Just like CC?",
                  "score": 1,
                  "created_utc": "2026-01-18 16:25:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0241cy",
                  "author": "[deleted]",
                  "text": "No, I don't know.\n\nMaybe agenticseek?",
                  "score": 0,
                  "created_utc": "2026-01-17 05:27:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzvnlp6",
          "author": "ImTheDeveloper",
          "text": "Very interesting to see this come up. \n\nI've been a big omo fan but the v3 orchestrator branch I tested out felt super heavy and bloated. I think omo pre jan was the sweet spot for me. The balance really was deep planning and simple execution, but now the planning and execution both feel bloated out and heavy with waterboarding token usage. \n\nI've since reverted back to standard open code and I'm just a bit more picky on model selection dependent on the use case. I miss the deeper planning modes but you can get around that with more explicit promoting as well as using memory plugins. \n\nI'll likely take more inspiration from it but I agree it's gone a little over the top in its most recent incarnations",
          "score": 3,
          "created_utc": "2026-01-16 06:55:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwld5d",
              "author": "alvinunreal",
              "text": "probably everyone should maintain own fork; it's worth it",
              "score": 1,
              "created_utc": "2026-01-16 11:52:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nztvujq",
          "author": "KnifeDev",
          "text": "This is a bit too barebones for my taste, so here‚Äôs my fork called oh-my-Goldilocks : \n\n\n\nKidding lol",
          "score": 6,
          "created_utc": "2026-01-16 00:19:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztk0b6",
          "author": "smile132465798",
          "text": "Is anyone else seeing oh-my-opencode constantly spawn the explore and librarian agents even when it‚Äôs idle?",
          "score": 2,
          "created_utc": "2026-01-15 23:15:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwb7uj",
              "author": "Michaeli_Starky",
              "text": "![gif](giphy|4EIOCwkztiPhS)",
              "score": 0,
              "created_utc": "2026-01-16 10:28:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzwhrqm",
          "author": "aeroumbria",
          "text": "> 5,173 lines\n\nWTF? Do people seriously pack this many information into system and agent prompts, expecting the agent to actually follow every line? At this rate we are burning like half the context window with everything loaded before even acting on anything! \n\nI put more trust into workflows that make a conscious effect to target sub-500 or even 300 line agent instruction files. Lightweight prompt and focused context IMO is much more reliable than dictionary promoting.",
          "score": 2,
          "created_utc": "2026-01-16 11:24:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwl93b",
              "author": "alvinunreal",
              "text": "agree - also steering direction too much is wrong; I get better results to leave sensible choice to AI;",
              "score": 1,
              "created_utc": "2026-01-16 11:51:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzxxkxb",
          "author": "YouTerrible3465",
          "text": "Nice \\~\\~\\~\\~",
          "score": 2,
          "created_utc": "2026-01-16 16:10:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o006p7g",
          "author": "alvinunreal",
          "text": "https://preview.redd.it/5owsbjbsdsdg1.png?width=2522&format=png&auto=webp&s=93345ba6faf682c001bcb56ddfead9f07cb4aef1\n\nTmux integration for spawned agents is just added:",
          "score": 2,
          "created_utc": "2026-01-16 22:20:07",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o05if8i",
          "author": "Mental_State1",
          "text": "Why not Gemini 3 flash high for explorer instead of glm4.6? Since you‚Äôre using antigravity anyways",
          "score": 2,
          "created_utc": "2026-01-17 18:55:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o069p0i",
              "author": "alvinunreal",
              "text": "glm in cerebras does 1k token p/s - flash would work well too",
              "score": 1,
              "created_utc": "2026-01-17 21:11:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nztxxh1",
          "author": "bazeso64",
          "text": "Nice ! Can we have a TLDR of what you slimmed down ?",
          "score": 1,
          "created_utc": "2026-01-16 00:30:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvsbss",
              "author": "alvinunreal",
              "text": "added more info",
              "score": 2,
              "created_utc": "2026-01-16 07:35:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzu87xp",
          "author": "girth_armstrong420",
          "text": "I agree, it's powerful but extremely token expensive",
          "score": 1,
          "created_utc": "2026-01-16 01:27:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvte6o",
              "author": "alvinunreal",
              "text": "Few reasons:  \n\\- [https://github.com/code-yeongyu/oh-my-opencode/blob/dev/src/agents/orchestrator-sisyphus.ts#L150](https://github.com/code-yeongyu/oh-my-opencode/blob/dev/src/agents/orchestrator-sisyphus.ts#L150)  \n\\- [https://github.com/code-yeongyu/oh-my-opencode/blob/dev/src/features/builtin-skills/skills.ts](https://github.com/code-yeongyu/oh-my-opencode/blob/dev/src/features/builtin-skills/skills.ts)  \n\\- [https://github.com/code-yeongyu/oh-my-opencode/blob/dev/src/hooks/todo-continuation-enforcer.ts](https://github.com/code-yeongyu/oh-my-opencode/blob/dev/src/hooks/todo-continuation-enforcer.ts)",
              "score": 2,
              "created_utc": "2026-01-16 07:45:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzxva4i",
          "author": "oh_my_right_leg",
          "text": "\"**Alternative: Ask any coding agent**\n\nPaste this into Claude Code, AmpCode, Cursor, or any coding agent:\" hmmmm did you forget opencode in that list by any chance?",
          "score": 1,
          "created_utc": "2026-01-16 16:00:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01ude2",
          "author": "Sizzin",
          "text": "I haven't tried omo yet, but the first thing I did after installing OpenCode was to uninstall it, download the source code and run directly from it. I created a new agent with less than 300 tokens of system prompt and modified the code to add a function that allows me to enable/disable tools on the fly like MCP. Not the cleanest way, but it works for me. It feels so wasteful asking simple questions when a \"hi\" becomes 10k+ tokens.\n\nImagine if we still had the mentality of optimizing things to the utmost, like when whole games were less than 32kb. Nowadays, the \"solution\" to every problem is to throw more RAM at it. Great initiative, OP.",
          "score": 1,
          "created_utc": "2026-01-17 04:17:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02yrpe",
          "author": "MonsieurHen",
          "text": "how did you decide what models to apply to the different agents? ive made gpt 5.2 the orchestrator for example",
          "score": 1,
          "created_utc": "2026-01-17 10:02:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a1fu6",
          "author": "Upset_Cellist6256",
          "text": "It isn‚Äôt useful as long as anthropic bans the opus usage",
          "score": 1,
          "created_utc": "2026-01-18 12:08:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c5495",
          "author": "[deleted]",
          "text": "I uninstalled Omo because it kept asking for permissions for every single bash command.",
          "score": 1,
          "created_utc": "2026-01-18 18:51:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdjils",
      "title": "OpenCode can now officially be used with your Github Copilot subscription",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qdjils/opencode_can_now_officially_be_used_with_your/",
      "author": "oronbz",
      "created_utc": "2026-01-15 13:29:02",
      "score": 64,
      "num_comments": 21,
      "upvote_ratio": 0.98,
      "text": "https://x.com/opencode/status/2011790750543983072?s=46&t=qDZ1ZcysBZTELeU-YCj3kg",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qdjils/opencode_can_now_officially_be_used_with_your/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nzq5vcc",
          "author": "t4a8945",
          "text": "Open ecosystem wins again. Anthropic L¬†",
          "score": 19,
          "created_utc": "2026-01-15 13:43:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqt6vy",
          "author": "External_Egg2098",
          "text": "Has anybody used it ?\n\n\nHow does the copilot pro+ (39 dollar) plan compare with claude code 20 dollar plan ? \n\nWill I get the same limit and the context size for sonnet-4.5 ?",
          "score": 6,
          "created_utc": "2026-01-15 15:40:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrbipl",
              "author": "vienna_city_skater",
              "text": "128k context size and a bit of slow during business hours, but else good value.\nEDIT: it was slow yesterday, but today it was fine, maybe the official support changed something¬†",
              "score": 3,
              "created_utc": "2026-01-15 17:02:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzusvin",
              "author": "mynameis_twat",
              "text": "Context size is reduced but that‚Äôs not that bad. The thing I don‚Äôt hear get talked about as often is they must do some fine tuning or temperature adjustments or something which makes it rush to a response and hallucinate more I‚Äôve noticed. At least in regards to Opus, sonnet, and gpt 5.2. I also use antigravity models in opencode and found their versions to be similarly downgraded but not as bad.",
              "score": 1,
              "created_utc": "2026-01-16 03:23:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzuzoj6",
                  "author": "toadi",
                  "text": "I have been using these github models with opencode for the last 6 months. The context size was not an issue. Also I think the cutoff date of training is different over the official models. But again not a big issue in performance.",
                  "score": 1,
                  "created_utc": "2026-01-16 04:03:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrvfxz",
          "author": "jpcaparas",
          "text": "This is a bigger deal in the enterprise than we think. I followed up with them if they would accept .ghe.com domains at some point.",
          "score": 2,
          "created_utc": "2026-01-15 18:31:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwp4ik",
          "author": "Reasonable-Tower21",
          "text": "I have used it with my copilot sub for weeks - what changed ?",
          "score": 1,
          "created_utc": "2026-01-16 12:19:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzy591h",
              "author": "cenderis",
              "text": "It's officially, publicly allowed now.",
              "score": 1,
              "created_utc": "2026-01-16 16:44:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzqhkco",
          "author": "Historical-Internal3",
          "text": "official by whose standard lol - opencode's or github's?\n\nany announcement of this from github copilot? even a tweet would work\n\nhate that I have to ask this now.",
          "score": 0,
          "created_utc": "2026-01-15 14:45:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqk3r4",
              "author": "edtv82",
              "text": "https://x.com/jaredpalmer/status/2011803160122097826?s=20\n\nJared Palmer is SVP of @GitHub and VP CoreAI @Microsoft",
              "score": 5,
              "created_utc": "2026-01-15 14:57:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqk8e1",
                  "author": "Historical-Internal3",
                  "text": "sick, ty",
                  "score": 0,
                  "created_utc": "2026-01-15 14:58:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrxd51",
              "author": "EduardoDevop",
              "text": "Both\n\n[https://x.com/opencode/status/2011790750543983072](https://x.com/opencode/status/2011790750543983072)  \n[https://x.com/github/status/2011822451613712646](https://x.com/github/status/2011822451613712646)",
              "score": 1,
              "created_utc": "2026-01-15 18:40:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzqkkk4",
              "author": "Y_ssine",
              "text": "[https://x.com/jaredpalmer/status/2011803160122097826](https://x.com/jaredpalmer/status/2011803160122097826)\n\nHere's the announcement from github",
              "score": 1,
              "created_utc": "2026-01-15 14:59:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzqyk4i",
          "author": "MissingHand",
          "text": "I‚Äôve been using it but they did make me reauthenticate yesterday.",
          "score": 0,
          "created_utc": "2026-01-15 16:04:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztgfrn",
              "author": "not-yummy-foo",
              "text": "which subscription on GH Copilot?",
              "score": 1,
              "created_utc": "2026-01-15 22:56:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzuztd3",
                  "author": "toadi",
                  "text": "I use the 19 dollar business one. I re-authenticated and it kept working,",
                  "score": 1,
                  "created_utc": "2026-01-16 04:04:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qdttn0",
      "title": "GitHub Just Made OpenCode Official. Here‚Äôs Why That‚Äôs a Bigger Deal Than You Think.",
      "subreddit": "opencodeCLI",
      "url": "https://jpcaparas.medium.com/github-just-made-opencode-official-heres-why-that-s-a-bigger-deal-than-you-think-ed1610660c40",
      "author": "jpcaparas",
      "created_utc": "2026-01-15 19:51:19",
      "score": 55,
      "num_comments": 23,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qdttn0/github_just_made_opencode_official_heres_why/",
      "domain": "jpcaparas.medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzvh1gv",
          "author": "chiroro_jr",
          "text": "This just goes to show what a mistake Anthropic made. They lose nothing by letting people use the Claude Code sub with Opencode. It's not like the person is no longer paying. They still pay the same sub. Unless maybe they are collecting data when people use Claude Code then I'd understand the incentive to keep people in there. Otherwise I don't understand it. Claude Code is just a harness for the most part. It's not like usage changes for the same plan just because you used Opencode. I am glad GitHub, OpenAI, and other companies are embracing Opencode and all the other open harnesses. It's good.",
          "score": 18,
          "created_utc": "2026-01-16 06:02:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvqlhf",
              "author": "SecureHunter3678",
              "text": "At this point I start to belive claude code is spyware, the way they are trying to push that thing on peoples computer. Hell. It is obfuscated like one for sure.",
              "score": 6,
              "created_utc": "2026-01-16 07:20:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvyord",
                  "author": "chiroro_jr",
                  "text": "Imagine. I don't think they should be doing that. Imagine paying 200$ every month and being told oh you have to use only this tool instead of having the option to use the best tool available. Arguably opencode is a better TUI than Claude Code. For me, it's a better harness too but I guess that's subjective. If I'm paying 200$ every month I need the option to choose.",
                  "score": 2,
                  "created_utc": "2026-01-16 08:32:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o067pjb",
                  "author": "rpatel09",
                  "text": "You do know Claude code is open source so you can literally see how the whole thing works‚Ä¶",
                  "score": -2,
                  "created_utc": "2026-01-17 21:00:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzwja2c",
              "author": "revilo-1988",
              "text": "Well, companies try to secure monopolies as long as things are going well; you can see that in all companies that are in such a position.",
              "score": 2,
              "created_utc": "2026-01-16 11:36:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzvs20z",
              "author": "warpedgeoid",
              "text": "Anthropic is apparently losing money on most subscribers. It‚Äôs all being subsidized by VC money.",
              "score": 2,
              "created_utc": "2026-01-16 07:33:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvyi8q",
                  "author": "chiroro_jr",
                  "text": "Yes. But do they stop losing money because it's Claude Code. No. They still lose the same money. Both Claude Code and Opencode are just harnesses. So I don't see how it matters which one you use if they are both using the same subscription.   They are killing the good faith they have with developers and other companies are taking advantage of that. Building a walled garden is a bad move in terms of AI I think.",
                  "score": 3,
                  "created_utc": "2026-01-16 08:31:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o03lgq2",
              "author": "XMojiMochiX",
              "text": "It‚Äôs because of telemetry I assume",
              "score": 1,
              "created_utc": "2026-01-17 13:12:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03nxis",
                  "author": "chiroro_jr",
                  "text": "Well that's a better reason than oh our costs and our infrastructure that I've been seeing from other users here. Fair play to them I guess even though I still think it's a mistake. Developers are probably most of their revenue. So burning any good will you have with your largest user base seems like a bad move.",
                  "score": 0,
                  "created_utc": "2026-01-17 13:28:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzw6ngj",
          "author": "getaway-3007",
          "text": "As of right now please don't use this because copilot works on the request model. I don't know how but Copilot chat does some requests batching mechanism which opencode or any other AI agent doesn't do, so you would quickly consume your usage 2-5 times faster as compared to the official Copilot chat extension. \n\nThe opencode twitter did mention they're working on it but until then it's not recommended to use copilot+opencode",
          "score": 7,
          "created_utc": "2026-01-16 09:47:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw7j82",
              "author": "jpcaparas",
              "text": "Good mention.\n\nLink to tweet: [https://x.com/opencode/status/2011871721758904782?s=20](https://x.com/opencode/status/2011871721758904782?s=20)",
              "score": 2,
              "created_utc": "2026-01-16 09:55:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzwba1s",
          "author": "Keep-Darwin-Going",
          "text": "Claude force you to use their cli because they want you to remember their presence and branding and thus justify subsidising. Most people do not understand that two things matters the model and harness, and when they see video showing opencode instead of cc they are missing the exposure.",
          "score": 5,
          "created_utc": "2026-01-16 10:29:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c686t",
          "author": "Da_ha3ker",
          "text": "Anthropic wants a walled garden. Makes sense if you think about it. Make the tool difficult to switch off of and you keep customers who would want to switch to the next best thing but don't because it is too difficult to do so. Looking at you Microsoft and Apple. The problem is they are not dealing with regular consumers, they are still in the early adoper phase, though less so now, but still early. Those same people who decided to give up their workflow and try Claude code because it was better than what they had are literally the ones who switch more often. Early adopters are flighty. Anthropic is trying to tie down early adopters, when all the early adopters care about is the next best tool, even if it can be a pain to move on. Opencode provides a platform to remove some of that pain.\n\nTLDR: Anthropic is trying to tie down the early adoper crowd by locking them to their software, which doesn't for early adopters. Opencode provides a better early adopter experience.",
          "score": 2,
          "created_utc": "2026-01-18 18:56:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qexzk7",
      "title": "I finally soft broke up with Claude Code ‚Äî and migrated everything to OpenCode (with reuse)",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qexzk7/i_finally_soft_broke_up_with_claude_code_and/",
      "author": "Tushar_BitYantriki",
      "created_utc": "2026-01-17 00:42:33",
      "score": 53,
      "num_comments": 17,
      "upvote_ratio": 0.95,
      "text": "# I wrote most of this post with opencode, as a summary of my migration. And then edited it myself.\n\nI‚Äôd been quietly annoyed at Claude Code‚Äôs arbitrary, opaque quota limits for a while. I kept tolerating not becuase I feel that I could not live without Opus or Sonnet (I feel most models have become pretty good these days, if you have slightest idea of what you are doing). But because I‚Äôd invested in custom commands, agents, and skills for months, and all of that just works for me in claude code.\n\nAnd the thought of rebuilding everything sounded painful. Then the ‚ÄúOpenCode max subscription ban‚Äù landed and that was my last straw.\n\nObviously, I had to disconnect opencode from claude sub, but it meant I had no reason left tpo keep paying them $200 (well, already reduced to $100 recently, and bought some other subscriptions with the difference)\n\nNo warning, no clarity, and were reports of accounts being banned for \"misuse\". People might justify it with \"they can do whatever they want with THEIR subscription\", but then \"customers are free to leave as well\". It felt like a toxic dependency: good when it worked, exhausting when it didn‚Äôt. I decided to start cutting the cord for good. I spent a few hours learning how OpenCode organizes commands, agents, and skills and realized I could migrate without nuking my Claude setup. That became the mission: keep my Claude assets usable while making them first‚Äëclass in OpenCode.\n\n# The three pillars I had to understand\n\nOpenCode is structured around three things, and once I understood them the migration was mostly plumbing:\n\n* **Commands**: slash commands with frontmatter\n* **Agents**: explicit roles with prompts + tool permissions\n* **Skills**: reusable instruction bundles loaded on demand\n\n# Migration strategy (keep Claude intact, add OpenCode wrappers)\n\nI wanted zero rewrites in my Claude files. The simplest path was wrappers + symlinks so Claude stays the source of truth.\n\n# 1) Skills: symlink Claude ‚Üí OpenCode\n\nThis lets both tools use the same skills.\n\n    # Project\n    ln -s .claude/skills .opencode/skill\n    \n    # User\n    ln -s ~/.claude/skills ~/.config/opencode/skill\n\n# 2) Commands: wrap Claude commands with frontmatter\n\nOpenCode needs frontmatter, Claude doesn‚Äôt. Wrappers let OpenCode read Claude commands without edits.\n\nExample wrapper:\n\n    ---\n    description: Enforce code discipline checklist\n    agent: build\n    ---\n    @.claude/commands/enforce-code-disciplines.md\n\nI did this for all project commands (including the `priming/` folder) and all user‚Äëlevel commands in `~/.claude/commands/`.\n\n# 3) Agents: wrap Claude prompts\n\nOpenCode agents can point to a prompt file, which makes them perfect wrappers for Claude agents.\n\n    ---\n    description: Senior code reviewer\n    mode: subagent\n    prompt: \"{file:~/.claude/agents/senior-code-reviewer.md}\"\n    ---\n\nI wrapped all my Claude agents as **subagents** to preserve behavior.\n\n# Verification checks (how I proved it worked)\n\nThese were the concrete checks that confirmed OpenCode was seeing everything:\n\n    opencode debug skill\n\n* Commands show up in the `/` palette\n* Agents show up in the `@` picker\n* Skills list correctly in `opencode debug skill`\n\nIf skills don‚Äôt show up, I enabled them in `opencode.json`:\n\n    \"tools\": {\n      \"read\": true,\n      \"write\": true,\n      \"edit\": true,\n      \"bash\": true,\n      \"skill\": true\n    }\n\n# Bonus: I turned the playbook into a skill\n\nI didn‚Äôt want to repeat this on every repo, so I started with asking opencode to write a migration skill that:\n\n* Scans Claude commands, agents, and skills\n* Creates OpenCode wrappers and symlinks\n* Verifies discovery\n\nNow migration is repeatable and documented instead of a one‚Äëoff bash ritual.\n\n# Tips\n\n* You can invoke skills by name in plain language. Unlike claude code, you don't have to keep asking it to \"invoke the skill properly\", and not just read a single SKILL.md file (leaving everything else). Open code invoked the skill, and read every file mentioned in it.\n* Skills can load fine even if the UI doesn‚Äôt surface them. Use `opencode debug skill`.\n* Wrappers won‚Äôt load without frontmatter.\n\n# Final take\n\nIf Claude Code‚Äôs limits are starting to feel arbitrary, there is a clean exit ramp. You don‚Äôt have to throw away your existing commands or skills. OpenCode can run them while Claude remains intact. I‚Äôm now fully migrated without losing anything, and it feels like getting my workflow back.\n\nI do plan to use Claude Code for planning at times, but now I have options.\n\nAnd honestly, I was only flirting with OpenCode for the last few months, but watching accounts being banned by Anthropic because customers didn't like their tooling, was a dic\\* move. And it made me realise that I just can't let myself be fully dependent on such a company.\n\nNow, if Anthropic suddenly decides to ban my account for some random reason, I can just walk away without being devastated.\n\nEven if Opus4.5, I have to spend time ensuring that the code is as per my preferences and standards. So for me, the loss would have been leaving behind the workflow that just worked for me. But now it seems that OpenCode is the best place for it to fit one-to-one.\n\nIf anyone wants the playbook or migration skill, here you go:\n\n[https://github.com/SmrutAI/opencode-migration](https://github.com/SmrutAI/opencode-migration)\n\nJust install it, and it migrates everything.\n\n  \nWill soon include a way to reuse Claude's settings.json and hooks, which are the last bit of attachment I have with Claude. (safety net)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qexzk7/i_finally_soft_broke_up_with_claude_code_and/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o01u5yc",
          "author": "altjx",
          "text": "Good stuff. I just did the same thing today with symlinks and some minor tweaks. Long time obsessed CC user here, but Opencode has made a lot of great progress over the last few months ago so I'm happy to be back.",
          "score": 4,
          "created_utc": "2026-01-17 04:16:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02l6dm",
          "author": "Awesomest_Maximus",
          "text": "Opencode already searches in .claude for skills. No need for linking. https://opencode.ai/docs/skills/#place-files",
          "score": 5,
          "created_utc": "2026-01-17 07:54:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02tssr",
              "author": "Tushar_BitYantriki",
              "text": "Yes, it does. I just created a common interface for all 3, as it deduplicates as well.\n\nHonestly, when I started, I was still trying to figure out skills in OpenCode.",
              "score": 2,
              "created_utc": "2026-01-17 09:15:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o041w38",
          "author": "miaowara",
          "text": "Quick tip: OC recognizes both singular & plural folder names (\"agent\" vs. \"agents\", \"command\" vs. \"commands\", \"skill\" vs. \"skills\") and will **load both** if present.  Furthermore, it seems to give priority to same-named items in the singular-named folders. This means you can keep same-named OC specific items in the singular-named folders (e.g. \"agent/cool-guy.md\") while keeping specific Claude-code ones in your symlinked folders (\"agents/cool-guy.md\"). This allows you to jump back to CC if need be relatively easily!",
          "score": 2,
          "created_utc": "2026-01-17 14:46:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o017s9o",
          "author": "raf_oh",
          "text": "Ty for this! I didn‚Äôt realize you can link the Claude files after the front matter for Opencode, great tip",
          "score": 1,
          "created_utc": "2026-01-17 01:51:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02dn2l",
          "author": "DueKaleidoscope1884",
          "text": "thank you for sharing! I am also thinking about this. I am trying different agents regularly and having some reuse would be great. (symlinking is what I rely on mostly so far)\n\n  \nFor agents, how does Opencode handle the front matter of the Claude Code agents? (since the are now part of the prompt, right?) Ignores it?\n\n  \nDid you also consider the plug-ins?",
          "score": 1,
          "created_utc": "2026-01-17 06:46:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02uhaz",
              "author": "Tushar_BitYantriki",
              "text": ">For agents, how does Opencode handle the front matter of the Claude Code agents? (since the are now part of the prompt, right?) Ignores it?\n\nSeems to pretty much ignore it. Opencode gets a wrapper of its own, with frontmatter in its format.\n\n    ---\n    description: Claude-style code reviewer\n    mode: subagent\n    model: anthropic/claude-sonnet-4-20250514\n    prompt: \"{file:./.claude/agents/review.md}\"\n    tools:\n      write: false\n      edit: false\n    ---\n    You are in review mode. Provide feedback only.\n\nThe frontmatter of the internal (claude's) file is just seen as a prompt. Seems to be working fine. (not sure if it would confuse the LLM over time.",
              "score": 2,
              "created_utc": "2026-01-17 09:21:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o032644",
          "author": "Swimming_Internet402",
          "text": "Yeah. Everyone should leave Claude",
          "score": 1,
          "created_utc": "2026-01-17 10:34:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04ccik",
          "author": "Unusual_Ring_4720",
          "text": "Hello, I'm aiming to do the same, but I relied heavily on CC being able to navigate the browser through Claude Extension + being able to look at the screenshots and use that information. Does OpenCode handle this as well? Thank you",
          "score": 1,
          "created_utc": "2026-01-17 15:39:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04ekye",
              "author": "Tushar_BitYantriki",
              "text": "I have not tried MCPs on opencode, yet. Because I am mostly doing backend work for the last 2-3 months.\n\nBut when working on frontend, I have had great success with chrome dev tools and puppeteer MCP (when working on non-chrome browsers)\n\nOpenCode does support MCPs, so would be worth trying.\n\nLately, I had removed most MCPs from my CC set up, to save on tokens.",
              "score": 1,
              "created_utc": "2026-01-17 15:50:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o04gztx",
          "author": "trypnosis",
          "text": "Well done mate",
          "score": 1,
          "created_utc": "2026-01-17 16:01:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04pr62",
          "author": "Superb_Sea_559",
          "text": "Opencode is interesting but isn't the Max subscription much cheaper than API? Or did you get the subscription working with Opencode?",
          "score": 1,
          "created_utc": "2026-01-17 16:42:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05cpnp",
              "author": "Tushar_BitYantriki",
              "text": "I am not using max sub with Opencode anymore, after the Anthropic account blocking fiasco.\n\nI don't want to get banned, just yet. But moving my workflow off claude code, and using GPT and other models.",
              "score": 1,
              "created_utc": "2026-01-17 18:29:25",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0adoz1",
              "author": "chevdor",
              "text": "OC works with CC subscriptions but Anthropic does not like it and tries to prevent it.\n\nIf CC would be on par with OC, there would be little of an issue. Yet the problem for Anthropic is that OC is much better ! And as users switch to OC while using CC, Anthropic faces a big issue: let it be and sell their great models. Or fight the users to ensure they stick with the CC CLI.\n\nThe problem is that more and more people use OC and get really pissed if they could no longer use OC and CC. Most people will drop Anthropic if they stand in front of the choice to use CC or stick with OC and leave.\n\nThis choice is a no trainer. Sticking with CC, you get a few great models and a rather poor CLI. Sure Anthropic could work on their cli but they already showed their will for an exclusive strategy. \n\nUsing OC, you can use ONE workflow and config and access plenty of models without being bound to a single vendor: no vendor lock-in.\n\nModels are racing ATM and it is not possible to say that model XYZ is \"the best\". So users will HAVE to use multiple models from multiple vendors to remain competitive. This is precisely what OC allows and CC wants to prevent.\n\nAnthropic is at a turning point and needs to make a smart choice if they want to avoid losing all their customers...\nFor now, existing customers leave or live in fear. New customers are scared to even join the battle.\n\nThis is all but healthy and ok plays strongly against Anthropic.\nTry bringing that up in their sub, you get censored. Ask me how I know.\n\nI personally don't want to \"live in fear\" **SO** I will stick with OC. \nIf Anthropic allows, I will keep paying for their models. If not, it won't change much for me and I will just switch OC to use another model or set of models. In the meantime, I am limiting the use of Anthropic only feature but honestly there is not much...",
              "score": 1,
              "created_utc": "2026-01-18 13:37:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0aj54u",
          "author": "verkavo",
          "text": "This is great. Thanks for sharing",
          "score": 1,
          "created_utc": "2026-01-18 14:09:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jk6xz",
          "author": "TheCientista",
          "text": "Please if I have to read another quietly or opaque I‚Äôm going to smash my phone over my own head. Don‚Äôt do it. Just stop",
          "score": 1,
          "created_utc": "2026-01-19 20:39:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jll6y",
              "author": "Tushar_BitYantriki",
              "text": "Sure, go ahead.\n\nBut do it quietly, and be opaque when someone asks you why you did it.",
              "score": 1,
              "created_utc": "2026-01-19 20:46:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qhvzoi",
      "title": "OpenCode‚Äôs creator on model freedom, Anthropic blocks, and the ‚Äúdouble miracle‚Äù of open source",
      "subreddit": "opencodeCLI",
      "url": "https://jpcaparas.medium.com/opencodes-creator-on-model-freedom-anthropic-blocks-and-the-double-miracle-of-open-source-bd94bd8fc763?sk=de6ec2383dae5cdd8e135a345dd2adfe",
      "author": "jpcaparas",
      "created_utc": "2026-01-20 08:52:20",
      "score": 53,
      "num_comments": 7,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qhvzoi/opencodes_creator_on_model_freedom_anthropic/",
      "domain": "jpcaparas.medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0os4m3",
          "author": "Michaeli_Starky",
          "text": "OC is plain better to that as agentic harness.",
          "score": 5,
          "created_utc": "2026-01-20 16:13:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0qatfp",
              "author": "jpcaparas",
              "text": "undeniably.",
              "score": 2,
              "created_utc": "2026-01-20 20:23:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0n4htj",
          "author": "Old-School8916",
          "text": "Streisand effect",
          "score": 4,
          "created_utc": "2026-01-20 10:02:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oeix8",
              "author": "taylorlistens",
              "text": "Don‚Äôt look that up!",
              "score": 2,
              "created_utc": "2026-01-20 15:08:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0ozmj5",
                  "author": "EmreErdoqan",
                  "text": "Haha exactly this!",
                  "score": 2,
                  "created_utc": "2026-01-20 16:47:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0om7hm",
          "author": "eMperror_",
          "text": "So, what's the current method to use the Max subscription without being blocked?",
          "score": 4,
          "created_utc": "2026-01-20 15:45:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0n06b4",
          "author": "jpcaparas",
          "text": "Yo Dax is a cool dude.",
          "score": 7,
          "created_utc": "2026-01-20 09:21:09",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfa59w",
      "title": "Love for Big Pickle",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qfa59w/love_for_big_pickle/",
      "author": "External_Ad1549",
      "created_utc": "2026-01-17 10:45:00",
      "score": 50,
      "num_comments": 37,
      "upvote_ratio": 0.96,
      "text": "disclaimer: I'm not a vibe coder. I‚Äôm a senior backend dev and I don‚Äôt code on things I don‚Äôt understand at least 70% clarity is mandatory for me.\n\nThat said, I love Big Pickle.\n\nThe response speed is insane, and more importantly, the quality doesn't degrade while being fast. I've been using it for the past hour for refactoring, debugging, and small script creation it just works. \"Great\" feels like an understatement.\n\nI don't care whether it's GLM-4.6, Opus, or something else. I only care about two things: high tokens/sec and solid output quality. Big Pickle nails both.\n\nWhoever operating this model at this speed I genuinely love you.\n\nMy only concern: it's currently free. That creates anxiety. I don‚Äôt want the model to stop working in the middle of serious work.\n\nPlease introduce clear limits or a paid coding plan (ZAI-level or slightly above).  \nIf one plan expires, I'll switch accounts or plans and continue no issue.\n\nJust give us predictability",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qfa59w/love_for_big_pickle/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0384hx",
          "author": "Erebea01",
          "text": "I think they self host their free models and say they don't cost much to host or something so they decide to provide them for free. I might be wrong tho.",
          "score": 7,
          "created_utc": "2026-01-17 11:29:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04b0wc",
              "author": "verbose-airman",
              "text": "My guess was it is smaller models that wanna market their models so they give free access for a limited time.",
              "score": 2,
              "created_utc": "2026-01-17 15:32:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o04tmqc",
              "author": "smile132465798",
              "text": "https://x.com/thdxr/status/1980317899828129992?s=46\nFor reference",
              "score": 1,
              "created_utc": "2026-01-17 17:00:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o06y98c",
                  "author": "touristtam",
                  "text": "> so our costs are 12.5x cheaper than a general purpose one\n\nThat's mental. I wonder if there is a possibility to run a similar setup locally on a consumer laptop and still get decent performances.",
                  "score": 1,
                  "created_utc": "2026-01-17 23:14:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o04catn",
          "author": "Big-Masterpiece-9581",
          "text": "The free ones on opencode zen are with clear TOS. You get free. They get your data and feedback to improve. They will all eventually move to paid only.\n\nBig Pickle is more. It‚Äôs a stealth model. That means one of the big ai companies has a new model they‚Äôre testing pre-release. There is no paid version because it‚Äôs not yet released. And we might never find out when it‚Äôs released that it was previously called big pickle.\n\nYou have to take that into account if using free models.",
          "score": 6,
          "created_utc": "2026-01-17 15:39:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04cyt8",
              "author": "seaweeduk",
              "text": "Big pickle is not a stealth model, it's glm 4.6 with a funny name hosted with one of their providers. Dax has confirmed this multiple times already.\n\nhttps://twitter.com/thdxr/status/1984090146460020966",
              "score": 3,
              "created_utc": "2026-01-17 15:42:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o05n2jl",
                  "author": "pwarnock",
                  "text": "It may have been glm-4.6 at the time he said that, but nothing prevents it from being changed. \n\nKilo has a new stealth model from a Chinese Lab called Giga Potato. Similar naming; size + food. Could be coincidence. \n\nWhen it leaked that Mistral‚Äôs model was stealth (spectre I think), they declined it and the following day announced it. \n\nSo take what you see on X with a grain of salt and assume that using Big Pickle for free means you‚Äôre helping them train, debug, and scale to get it to a state that they are confident charging for.",
                  "score": 2,
                  "created_utc": "2026-01-17 19:17:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o04cser",
              "author": "External_Ad1549",
              "text": "yeah i read it but it is being stealth for a very long time",
              "score": 1,
              "created_utc": "2026-01-17 15:41:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0360z0",
          "author": "lundrog",
          "text": "Pretty sure its k2 thinking",
          "score": 8,
          "created_utc": "2026-01-17 11:10:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03k7z9",
              "author": "seaweeduk",
              "text": "dax has confirmed multiple times before, its just glm 4.6 with a funny name",
              "score": 10,
              "created_utc": "2026-01-17 13:04:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03zrb9",
                  "author": "KnifeFed",
                  "text": "So why use it over GLM 4.7? Is it faster?",
                  "score": 4,
                  "created_utc": "2026-01-17 14:34:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o04d6u3",
                  "author": "External_Ad1549",
                  "text": "i am kind of using glm models like from 4.5 it doesn't seem like 4.6 i might be wrong when context increased it kind of behaved on it's own k2 will do that or I might be wrong",
                  "score": 4,
                  "created_utc": "2026-01-17 15:43:26",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o04qgs2",
                  "author": "minaskar",
                  "text": "It certainly used to be GLM-4.6, but I'm pretty sure it's been replaced with K2 Thinking now. If you notice at the OpenCode Desktop app, Big Pickle allows you to change the reasoning effort, just like K2 Thinking. GLM-4.6/4.7 do not have this freedom.",
                  "score": 1,
                  "created_utc": "2026-01-17 16:46:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o036ulu",
              "author": "External_Ad1549",
              "text": "can be, I completely forgot that it existed",
              "score": 1,
              "created_utc": "2026-01-17 11:17:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o03h1at",
          "author": "websitegest",
          "text": "That anxiety about ‚Äúthis is awesome AND free, so it‚Äôs probably going to vanish mid‚Äëproject‚Äù is very real. Free tiers are nice for experimentation, but for serious backend work predictability > freebies.\n\nWhat worked for me was building around a paid coding plan with known limits as the backbone, and then treating fast/free models like Big Pickle as opportunistic accelerators. Opus (or similar) sets the architecture, GLM 4.7 and Big Pickle handles the implementation and refactor loops, and anything else fast just rides on top.\n\nIf you‚Äôre looking for something closer to a predictable, paid plan rather than a gamble on a free endpoint, Zai has coding plans where you can still get 50% discount for first year + 30% discount (current offers + additional 10% coupon code) but I think it will expire soon (some offers are already gone!) > [https://z.ai/subscribe?ic=TLDEGES7AK](https://z.ai/subscribe?ic=TLDEGES7AK)",
          "score": 3,
          "created_utc": "2026-01-17 12:42:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03nx7g",
              "author": "External_Ad1549",
              "text": "thanks i have max plan zai it is my work horse, chatgpt for architectural decisions but sometimes zai goes very slow for a simple tasks glm 4.7 took 28 sec same big picke took 7.5 sec but when the depth increased big pickle kind of left me and wrote its own code despite having correct plan.md in place never happened with glm 4.7. I completely agree with u",
              "score": 3,
              "created_utc": "2026-01-17 13:28:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o048mrj",
                  "author": "ZeSprawl",
                  "text": "Try GLM 4.7 on Cerebras. You can try it out on the free tier. The speed is actually insane. Fastest response I've ever seen for a smart coding model. It's addictive and I hope they offer it on their coding plan whenever there's availability again.",
                  "score": 2,
                  "created_utc": "2026-01-17 15:21:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o04p5cc",
          "author": "psilokan",
          "text": "Interesting.  I've found big pickle to be very slow when using it. Also found it to be very buggy.  One time it just randomly switched to chinese and all the output was in chinese characters, no idea why lol.",
          "score": 2,
          "created_utc": "2026-01-17 16:40:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04s4uw",
              "author": "External_Ad1549",
              "text": "üòÇüòÇ switch to chinese happened in Antigravity as well\nwhen did you tested this?",
              "score": 1,
              "created_utc": "2026-01-17 16:53:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o04xb51",
                  "author": "psilokan",
                  "text": "This was right before Christmas.  The funny thing it still understood me and kept doing what I asked despite me having no clue what it was saying back lol",
                  "score": 2,
                  "created_utc": "2026-01-17 17:17:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o05wzoo",
          "author": "Easy_Zucchini_3529",
          "text": "Use GLM-4.7 with Fireworks or Cerebras.",
          "score": 2,
          "created_utc": "2026-01-17 20:05:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05xiov",
              "author": "External_Ad1549",
              "text": "crebras  is limited, trail version got some burst but it is always pushing 1 min break like limited tokens in 1 min. not available right now, coding plans are not available. fireworks ai is little costly need to check whether it has coding plans",
              "score": 1,
              "created_utc": "2026-01-17 20:08:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o05zbo4",
                  "author": "Easy_Zucchini_3529",
                  "text": "true, both are not the most cheapest solution, but the tokens per second are insane (specially Cerebras)",
                  "score": 2,
                  "created_utc": "2026-01-17 20:17:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0fb2vx",
          "author": "37chairs",
          "text": "Big pickle was a total joke at first. I used it again on a whim after hitting limits and was blown away. Is also possible I got better at talking to the things in the interim, but it went from trash to cash.",
          "score": 2,
          "created_utc": "2026-01-19 04:57:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qd6glz",
      "title": "Anthropic explicitly blocks OpenCode in oauth",
      "subreddit": "opencodeCLI",
      "url": "https://news.ycombinator.com/item?id=46625918",
      "author": "Old-School8916",
      "created_utc": "2026-01-15 01:52:37",
      "score": 49,
      "num_comments": 42,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qd6glz/anthropic_explicitly_blocks_opencode_in_oauth/",
      "domain": "news.ycombinator.com",
      "is_self": false,
      "comments": [
        {
          "id": "nznyhwr",
          "author": "Trustingmeerkat",
          "text": "I only found out about open code via all this drama. Glad I did",
          "score": 36,
          "created_utc": "2026-01-15 03:19:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzobkak",
              "author": "noiserr",
              "text": "The Streisand Effect strikes again.",
              "score": 21,
              "created_utc": "2026-01-15 04:44:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzpe428",
              "author": "Yarden-zamir",
              "text": "Same lol",
              "score": 3,
              "created_utc": "2026-01-15 10:21:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzt3v5e",
              "author": "BERLAUR",
              "text": "Same here and I cancelled Claude Code and went to Codex & Z.ai by recommendations of the community.¬†\n\n\nGlad I did!",
              "score": 2,
              "created_utc": "2026-01-15 21:55:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nznlxtn",
          "author": "Sensitive_Song4219",
          "text": "Frustrating but so be it. \n\nOptions:\n\nSwap to Anthropic API use and forgo your plan (this is expensive)\n\nSwap to Claude Code (have fun dealing with non-stop flicker! Though CC is still a good harness to be fair)\n\nSwap to Codex (OpenAI explicitly *allows* ChatGPT plan use in OpenCode). Codex 5.2 Medium is similar to Sonnet. Codex 5.2 High and especially x-high give Opus a run for its money. Usage limits on Codex are more generous than Anthropic's equivalent plans.\n\nThrow in something like GLM 4.7 for Sonnet-level performance for very little cash.",
          "score": 22,
          "created_utc": "2026-01-15 02:05:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznw41w",
              "author": "EnvironmentalLet9682",
              "text": "i actually only heard about opencode through the claude controversy. made me quit my max plan for now. i am testing codex right now and it seems to be pretty good.",
              "score": 12,
              "created_utc": "2026-01-15 03:05:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzo5cn7",
                  "author": "Ang_Drew",
                  "text": "Welcome aboard!\nAnthropic‚Äôs fan base is often biased and does not recognize how capable GPT-5.2 is. This may remain the case until Anthropic makes a significant mistake, at which point its market share could gradually shift toward OpenAI.",
                  "score": 7,
                  "created_utc": "2026-01-15 04:02:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzoefnw",
              "author": "james__jam",
              "text": "Swap to a different provider like Antigravity. \n\nAs far as I can tell from their [terms and conditions](https://antigravity.google/terms), there‚Äôs no mention that it‚Äôs not allowed. \n\nIm not a lawyer though",
              "score": 2,
              "created_utc": "2026-01-15 05:05:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzoshuf",
                  "author": "Top-Faithlessness758",
                  "text": "I would expect Google to not care about which harness you are using.",
                  "score": 2,
                  "created_utc": "2026-01-15 06:57:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nznth5r",
              "author": "Darth-Mary-J",
              "text": "What about nanocoder?",
              "score": 1,
              "created_utc": "2026-01-15 02:49:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzo8ikb",
              "author": "0xraghu",
              "text": "Is codex-cli that bad compared to opencode?",
              "score": 1,
              "created_utc": "2026-01-15 04:23:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzoyttb",
              "author": "Flanhare",
              "text": "I use CC a lot and have no flicker. What OS and terminal?",
              "score": 1,
              "created_utc": "2026-01-15 07:54:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqjhcm",
                  "author": "Sensitive_Song4219",
                  "text": "Happens to me about about twice-a-day under both Windows (CLI via both cmd + ps) and Linux (also CLI) but it's been [reported on Mac](https://www.reddit.com/r/ClaudeCode/comments/1mpufgs/i_think_ive_found_a_way_to_prevent_claude_codes/) as well. Most commonly happens (to me at least) after it displays a plan EDIT: or after showing a diff; and it seems more likely to happen when the term is not full screen especially if it's width-constrained. Still love CC (don't get me wrong - it's my favourite CLI) but the devs themselves have [aknowledged it](https://x.com/trq212/status/2001439019713073626), so it's not an uncommon issue.",
                  "score": 1,
                  "created_utc": "2026-01-15 14:54:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzp8kyq",
              "author": "lopydark",
              "text": "codex 20 usd plan is indeed more generous than claude 20 usd plan, but what about the 200 usd plan? I heard claude gives more value for this plan than openai",
              "score": 1,
              "created_utc": "2026-01-15 09:28:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzsvaip",
                  "author": "EnvironmentalLet9682",
                  "text": "I'm just surprised there's no 100$ plan for openai. The jump from 20 to 230 or whatever it was seems kinda extreme.",
                  "score": 1,
                  "created_utc": "2026-01-15 21:16:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzythlw",
              "author": "Yogesh991",
              "text": "I am using it with API and I don't what sorcery Opencode is, but it's so much better than Claude Code in doing stuff. \n\nBut I have spent around 300 usd this week. üòú",
              "score": 1,
              "created_utc": "2026-01-16 18:31:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzo3xa5",
              "author": "amplifyoucan",
              "text": "You spelled Gemini wrong",
              "score": 0,
              "created_utc": "2026-01-15 03:53:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzop11k",
                  "author": "warpedgeoid",
                  "text": "Honestly, you need a ensemble of models. GPT is good for big picture, Gemini for UX, and Claude for coding grunt work.",
                  "score": 1,
                  "created_utc": "2026-01-15 06:27:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsuwm9",
                  "author": "EnvironmentalLet9682",
                  "text": "Idk, i tried gemini today and it totally failed me. I asked it to write an sdl implementation of the snake game in zig, it failed 3 times, apologized and undid all its work. Not sure if i did anything wrong but the same prompt worked just fine on codex and claude.",
                  "score": 1,
                  "created_utc": "2026-01-15 21:14:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzp2jpr",
              "author": "SubjectHealthy2409",
              "text": "Swap to Zed IDE and use Claude Code via ACP",
              "score": 0,
              "created_utc": "2026-01-15 08:29:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzol1jo",
          "author": "awfulalexey",
          "text": "No no, we are not afraid of competitors, no! Such clowns\n\nhttps://preview.redd.it/nrwb83o4dgdg1.png?width=3680&format=png&auto=webp&s=013666837e43df01a41549a159d6ba48d65c1836",
          "score": 8,
          "created_utc": "2026-01-15 05:55:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzp8c2j",
              "author": "lopydark",
              "text": "atp they should let us just use the sub where we want tbh",
              "score": 4,
              "created_utc": "2026-01-15 09:25:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzuz70e",
              "author": "UnionCounty22",
              "text": "lol the last 5 characters of the request ID are D8LSD",
              "score": 1,
              "created_utc": "2026-01-16 04:00:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzopndl",
              "author": "kohlstar",
              "text": "that‚Äôs amazing, thanks",
              "score": 1,
              "created_utc": "2026-01-15 06:32:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzq5502",
          "author": "whodoneit1",
          "text": "You can use Antigravity with Opencode now, they added support yesterday.",
          "score": 4,
          "created_utc": "2026-01-15 13:39:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ivffb",
              "author": "sucksesss",
              "text": "what do you mean by \"they\"? is it officially tho?",
              "score": 1,
              "created_utc": "2026-01-19 18:46:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzpkn27",
          "author": "xmnstr",
          "text": "Honestly, I'm kinda impressed by how poorly they're handling this. If their infra was solid, this wouldn't be a problem.",
          "score": 1,
          "created_utc": "2026-01-15 11:19:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzra0jk",
              "author": "SilentDanni",
              "text": "Infra is hardly the problem in this case.",
              "score": 1,
              "created_utc": "2026-01-15 16:56:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrsdod",
                  "author": "xmnstr",
                  "text": "Why not?",
                  "score": 1,
                  "created_utc": "2026-01-15 18:18:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrsfv0",
          "author": "nsway",
          "text": "Is open code a superior harness or something? I‚Äôd heard of it prior to this drama but assumed it was a budget option.",
          "score": 1,
          "created_utc": "2026-01-15 18:18:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qimlua",
      "title": "We built Kuse Cowork: an open-source, Rust-native alternative to Claude Cowork",
      "subreddit": "opencodeCLI",
      "url": "https://v.redd.it/vl8say66emeg1",
      "author": "Loose_Kangaroo91",
      "created_utc": "2026-01-21 03:16:51",
      "score": 49,
      "num_comments": 10,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qimlua/we_built_kuse_cowork_an_opensource_rustnative/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0tcczy",
          "author": "tdi",
          "text": "will you maintain it ?",
          "score": 1,
          "created_utc": "2026-01-21 06:57:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0th6of",
              "author": "Loose_Kangaroo91",
              "text": "Absolutely!! We have always thinking about open source and this is actually a great opportunity to actually encourage us to do this, pls drop your feedback, experience, comments anytime and we would love to keep optimizing this!!",
              "score": 2,
              "created_utc": "2026-01-21 07:40:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tcywp",
          "author": "Lonely_Noyaaa",
          "text": "Cool project and thanks for sharing! It's really ambitious to build this within a weekend. Do you guys support multiple models switch for now?",
          "score": 1,
          "created_utc": "2026-01-21 07:02:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0th806",
              "author": "Loose_Kangaroo91",
              "text": "Thank you! And yes this supports most trendy LLMs",
              "score": 1,
              "created_utc": "2026-01-21 07:40:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tf7es",
          "author": "No_Point_9687",
          "text": "Haven't you recently said Claude killed your business or was it someone else. \nPromising product, will check it out. Thank you.",
          "score": 1,
          "created_utc": "2026-01-21 07:22:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0thfb2",
              "author": "Loose_Kangaroo91",
              "text": "Oh thanks! Yes I think one of our folks made that post! Please drop your feedback anytime and we would love to keep optimizing this!",
              "score": 1,
              "created_utc": "2026-01-21 07:42:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0t1ogz",
          "author": "true-though",
          "text": "Congrats, and great job!!",
          "score": 1,
          "created_utc": "2026-01-21 05:30:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0t62vd",
              "author": "Loose_Kangaroo91",
              "text": "Thanks! Feel free to try it out and let us know your feedback!!",
              "score": 2,
              "created_utc": "2026-01-21 06:04:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0t0pmz",
          "author": "Ok-Machine-8071",
          "text": "oh my god",
          "score": 0,
          "created_utc": "2026-01-21 05:23:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0t64h4",
              "author": "Loose_Kangaroo91",
              "text": "Is this omg in a good way haha?",
              "score": 1,
              "created_utc": "2026-01-21 06:04:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfzaju",
      "title": "Built a multi-agent orchestrator plugin for OpenCode after struggling with GLM-4.7",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qfzaju/built_a_multiagent_orchestrator_plugin_for/",
      "author": "ChangeDirect4762",
      "created_utc": "2026-01-18 04:50:54",
      "score": 48,
      "num_comments": 19,
      "upvote_ratio": 0.96,
      "text": "https://preview.redd.it/78u9krhyf1eg1.png?width=3826&format=png&auto=webp&s=eaa14b014a85d34823c68ff354dc998de60d8883\n\nGLM-4.7 kept hitting walls on complex tasks ‚Äî rate limits, context overflow, losing track halfway through. Got frustrated enough to build my own solution.\n\n0.9 version\n\nSo I made \\[opencode-orchestrator\\]([https://github.com/agnusdei1207/opencode-orchestrator](https://github.com/agnusdei1207/opencode-orchestrator)). It's a plugin for OpenCode that handles:\n\n\\- \\*\\*Parallel sessions\\*\\* ‚Äî up to 50 isolated sessions running simultaneously\n\n\\- \\*\\*Agent distribution\\*\\* ‚Äî Commander delegates to Planner, Workers, Reviewer\n\n\\- \\*\\*Background tasks\\*\\* ‚Äî non-blocking, async execution\n\n\\- \\*\\*Auto-retry\\*\\* ‚Äî handles crashes, rate limits, context issues automatically\n\n\\- \\*\\*Loop until done\\*\\* ‚Äî keeps going until all TODOs are complete and verified\n\nThe idea is simple: instead of one agent trying to do everything, split the work across specialized agents that run in parallel and coordinate through shared state.\n\n  \nIf you try it out and run into anything, feel free to open an issue ‚Äî or since it's open source, just fork it and tinker with it yourself. If you come up with something cool, I'd love to hear about it.\n\n\n\nI think in the AI era, we're all going to end up building our own tools anyway.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qfzaju/built_a_multiagent_orchestrator_plugin_for/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0c7ung",
          "author": "Visible_Jury_6547",
          "text": "why not just config Oh my opencode ? [https://github.com/code-yeongyu/oh-my-opencode](https://github.com/code-yeongyu/oh-my-opencode)",
          "score": 5,
          "created_utc": "2026-01-18 19:04:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0frqfi",
              "author": "splitbrainhack",
              "text": "unnecessary chaos",
              "score": 2,
              "created_utc": "2026-01-19 07:08:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0a709j",
          "author": "writing_rainbow",
          "text": "Are you able to assign specific models for each mode? Like chat 5.2 high for commander and planner and then glm for implementation and then codex 5.2 high for review?",
          "score": 3,
          "created_utc": "2026-01-18 12:52:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09gl6c",
          "author": "redoubledit",
          "text": "So frustrating. At one time, I had beautifully laid out plans with extensive todo list, broken up into execution phases. I was so ready, so it started. Finishing the first todo item, using the todo write tool to check off the item. But didn‚Äôt read the list before so now, all todos are checked and verified and it stopped. Trying to iterate, it totally messed up from there. Forgetting parts of the plan, checking off items and deleting others in the same step. \n\nMight give your project a try. See if it can help.",
          "score": 2,
          "created_utc": "2026-01-18 08:59:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08vblp",
          "author": "lundrog",
          "text": "Interesting, ill check it out",
          "score": 1,
          "created_utc": "2026-01-18 05:52:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o097hp5",
              "author": "ChangeDirect4762",
              "text": "Thx. :)",
              "score": 1,
              "created_utc": "2026-01-18 07:36:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0avr5y",
          "author": "mintybadgerme",
          "text": "I'm getting a little confused with all these new agent systems coming online. What makes them different from one another? I've got open agents installed. How is that different from this one? I'm assuming that running them all together will destroy the platform completely.",
          "score": 1,
          "created_utc": "2026-01-18 15:17:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0c2z3g",
              "author": "Zexanima",
              "text": "Its a new problem domain that people are running into around the same time. Not everyone can/wants to keep up to date with everything new that drops, so they will roll their own solution. I think its great to have all these options in the beginning. People will evetually gravitate to the best solutions, they will start to homogenize features, and those will become the go-to.",
              "score": 7,
              "created_utc": "2026-01-18 18:41:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0c4l4r",
                  "author": "mintybadgerme",
                  "text": "But how on earth do you decide what's the best solution? Seems to me that there's no benchmarks,  no quality assurance, no testing. They're just released onto the market and us poor suckers have got to make a decision. Really hard.",
                  "score": 1,
                  "created_utc": "2026-01-18 18:49:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0e7d3x",
          "author": "Redoer_7",
          "text": "Which IDE is this",
          "score": 1,
          "created_utc": "2026-01-19 01:06:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0f64g2",
              "author": "Ruin_Mediocre",
              "text": "https://zed.dev/",
              "score": 1,
              "created_utc": "2026-01-19 04:24:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0fk8dc",
          "author": "NullzeroJP",
          "text": "Wow, crazy. How long did it take you to plan and build out something like this? And did it help fix some of the issues with GLM 4.7? Having similar issues myself with GLM 4.7 and ClaudeCode. But I'm new to vibe coding, so I thought maybe it was just a \"me\" problem.",
          "score": 1,
          "created_utc": "2026-01-19 06:06:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mbifl",
          "author": "pkief",
          "text": "Maybe it's also worth checking this project: https://www.swarmtools.ai/\n\nIt does quite the same and is already a little popular. It's an open code plugin optimized for multiple agent orchestration.",
          "score": 1,
          "created_utc": "2026-01-20 05:45:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf1ydz",
      "title": "Opus 4.5 Model Alternative",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qf1ydz/opus_45_model_alternative/",
      "author": "gradedkittyfood",
      "created_utc": "2026-01-17 03:18:35",
      "score": 41,
      "num_comments": 24,
      "upvote_ratio": 0.94,
      "text": "Hey all,\n\nBeen loving opencode more than claude. But no model I have used seems to come close to opus for programming tasks.\n\nTried GLM 4.7, and it's pretty decent, and impressive, but still struggles with bigger tasks. Mini Max M2.1 is fast as hell, but lands near GLM 4.7 in terms of quality.\n\nI've heard decent things about codex-5.2-high, but I'm curious on in terms of output quality and usage. Any other models I should be aware of to scratch that Opus itch but in Opencode?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qf1ydz/opus_45_model_alternative/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o01muin",
          "author": "real_serviceloom",
          "text": "None of the models are as good as opus 4.5. Gpt 5.2 is a bit better but much slower.¬†\n\n\nMinimax m2.1 is the best bet among the free ones. Glm is also super slow for me for some reason on open code.¬†",
          "score": 19,
          "created_utc": "2026-01-17 03:27:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o029l0i",
              "author": "Charming_Support726",
              "text": "Dont confuse gpt-5.2 with gpt-5.2-codex. Codex is much faster, but lacks some analytic skills - especially in discussion. \n\nIn my experience the Gpts are very thorough and Opus wont match these. Opus get things done but lacking some perfection, while Codex tent to be overprecise, which is a real hard impediment when you are just creating a proof of concept.",
              "score": 4,
              "created_utc": "2026-01-17 06:12:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o029sdv",
                  "author": "real_serviceloom",
                  "text": "Yup I use gpt 5.2 medium for most planning and architecture and 5.2 codex medium for sniping. And high xhigh for reviews and gnarly bugs. I also have a Claude Max plan because sometime i just need speed lol.¬†",
                  "score": 1,
                  "created_utc": "2026-01-17 06:13:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o09hk70",
              "author": "websitegest",
              "text": "I can confirm that M 2.1 is really powerful, but in my opinion it's terrible when it comes to documentation! As for speed, I found GLM was slower with the Lite plan: I upgraded to the *Pro plan* and now it's quite fast, only experiencing a slight slowdown during peak hours. For others coding tests I ran identical prompts through Opus 4.5 (via *Claude Pro* plan), GLM 4.7, and Minimax. Results: Opus best at first-pass architecture, GLM best at iterative implementation (fewer context losses), Minimax faster but not cheaper as GLM. For anyone considering the GLM plans right now there is also a **50% discount** for first year **+ 30% discount** (current offers + my additional 10% coupon code) but I think it will expire soon (some offers are already gone!) >¬†[https://z.ai/subscribe?ic=TLDEGES7AK](https://z.ai/subscribe?ic=TLDEGES7AK)",
              "score": 1,
              "created_utc": "2026-01-18 09:08:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o01lygx",
          "author": "minaskar",
          "text": "For me it was Kimi K2 Thinking that took that role.",
          "score": 7,
          "created_utc": "2026-01-17 03:21:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o022ln9",
              "author": "NiceDescription804",
              "text": "Is it good at planning? I'm really happy with how glm 4.7 follows instructions but the planning is terrible. \nSo how was your experience when it comes to planning?",
              "score": 2,
              "created_utc": "2026-01-17 05:16:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03m2mo",
                  "author": "annakhouri2150",
                  "text": "Yeah, I would say that K2T is probably the best open source model I've used at planning and analyzing things and general sort of analytic skill. Whereas GLM 4.7 is better at figuring problems out debugging, strictly coding and instruction following. So that's how I would split it up.",
                  "score": 4,
                  "created_utc": "2026-01-17 13:16:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o04pjf4",
                  "author": "minaskar",
                  "text": "Yeah, that was my experience too. GLM-4.7 (and to a slightly lesser degree M2.1) is great at following instructions, but it really struggles to plan anything with even a moderate level of complexity. K2 Thinking (and DS3.2 for math/algorithm-heavy cases) if far superior in my opinion.",
                  "score": 0,
                  "created_utc": "2026-01-17 16:41:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o02jkd3",
          "author": "toadi",
          "text": "All tasks can be broken in smaller tasks. To be honest since a few months I don't see that much problem in software delivery by most models.\n\nI use opus only to provide me a larger spec. After that break it down with sonnet in small incremental task and haiku delivers the actual code. Can do the same using GLM and grok-fast for example. \n\nIt is about being precise and detailed providing input. This way it narrows down the probabilistic band making it land close to the goal you aim for.",
          "score": 2,
          "created_utc": "2026-01-17 07:39:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02k3ei",
          "author": "Michaeli_Starky",
          "text": "Even the slowest models are faster than the fastest programmer. Not sure why the speed of generation is a concern. BTW, you need to read and understand the code, so take your time.",
          "score": 2,
          "created_utc": "2026-01-17 07:44:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0g1ypu",
          "author": "No_Click_6656",
          "text": "Just use Opus 4.5 with Copilot as provider lol",
          "score": 1,
          "created_utc": "2026-01-19 08:40:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qino8",
          "author": "flexrc",
          "text": "Nothing beats opus 4.5 that is their competitive advantage. You can look at getting Google ai pro to get a better deal.",
          "score": 1,
          "created_utc": "2026-01-20 20:59:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02s4qf",
          "author": "kkordikk",
          "text": "Just break down bigger task into smaller ones. Isn‚Äôt GLM the fastest at 1000tps?",
          "score": 1,
          "created_utc": "2026-01-17 08:59:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05x83o",
          "author": "SynapticStreamer",
          "text": "> but still struggles with bigger tasks.\n\nGiving any LLMs large tasks, and they'll struggle. Create an implementation.md file (I call mine CHANGES.md) and have the LLM map out planned changes in phases and write the implementation plan to the file. Then, instead of saying \"do this thing\" say \"implement the changes in CHANGES.md. Stop between each phase for housekeeping (git, context, etc), and then touch base with me before proceeding.\"\n\nWorks for most things. With very complex changes, no matter what you do, the model will hallucinate. I haven't been able to get it to a point, even with sufficient context, to not.",
          "score": 1,
          "created_utc": "2026-01-17 20:07:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02e1ng",
          "author": "lostinmahalway",
          "text": "Have you tried Deepseek Chat? I used Opus/Deepseek Chat for planning, creating tasks and orchestrating, while Minimax to actually implement the tasks. Sometimes during the day, the Opus is even worse compared to Deepseek.",
          "score": 0,
          "created_utc": "2026-01-17 06:50:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfsg1t",
      "title": "Switch to OpenCode for Money Efficiency",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qfsg1t/switch_to_opencode_for_money_efficiency/",
      "author": "Demon-Martin",
      "created_utc": "2026-01-17 23:34:26",
      "score": 33,
      "num_comments": 50,
      "upvote_ratio": 0.97,
      "text": "Heyo devs,\n\nBeen thinking on switching to OpenCode from Cursor to save some money.\n\nCurrently I run 2 cursor ultra accounts and I am still burning though limits too quickly. Can‚Äòt afford to keep those costs tho, so I been planning on switching to OpenCode with a few chatgpt/google (maybe glm) accounts. I‚Äòm pretty Sure those would end up being was cheaper for more tokens. My biggest costs is Claude Opus 4.5.\n\nThe problem is: I love cursor‚Äòs IDE and I really got used to it. I don‚Äòt really like CLIs (didn‚Äôt like claude code too).\n\nAnd sadly I read that Anthropic is now actively attacking external usage of their subs.\n\nI want to test OpenCode (or something similar). OpenChamber is what I found, but thats more like an Chatbox than an Editor if I understood correctly.\n\nI also tried Google‚Äòs AntiGravity but it‚Äòs straight up not the level that Cursor is. And I also read last days that they also started making rate limits worse.\n\nWhat would you do in my situation? Is there a good OpenCode Extension? How good is OpenCode actually?\n\nThanks.\n\nEDIT:\n\nI forgot to mention, I currently usually work like this:\n\nI first let a cheaper model do some research in the project based on a task. Then use Opus to create a plan and iterate till it creates a plan that follows what I want. Then I execute this plan with either composer, if I want it fast, or Gemini Flash 3, if I want it cheap (there is no other cheap model on cursor that‚Äòs also good, flash is the 2nd cheapest next to GPT 5 nano on cursor, afaik). If Gemini fails, I also let it run though Gemini 3 Pro, Claude Sonnet and Opus itself, depending on the situation and project.\n\nEDIT 2 (18.01.2026):\n\nI tried OpenCode, added my ChatGPT Sub, Google Sub and GitHub Copilot Sub (got most of it for free because I am a student). It generally worked good, but I still don‚Äòt really like working in the CLI. It just doesn‚Äòt give me the User Experience and viewing that an Editor like Cursor gives me. I also tried OpenCode Desktop and that‚Äòs also not optimal.\n\nEven tho my credit usage might suggest otherwise: I am not a ‚Äûpure vibe coder‚Äú. I actively manually check all edits, fix stuff manually and code manually. I don‚Äòt let AI do everything by itself.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qfsg1t/switch_to_opencode_for_money_efficiency/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o07ig6h",
          "author": "Putrid-Pair-6194",
          "text": "I was exactly the same situation with cursor. So recently, I switched to a combination of opencode plus Antigravity. For me, the differences in antigravity from cursor for me were very small. \n\nSo now my set up is focused on opencode with the antigravity authentication extension. That gives me access to all of the opus and sonnet usage you get with antigravity. The Opus and sonnet usage you get with a single user is very limited. But, you can significantly increase that by buying a $20 a month family plan to the Google AI Pro subscription. That subscription allows you to sign up five ‚Äúfamily members‚Äù.  Every family member gets its own unique quota for antigravity Claude models. So if you set this up for $20 a month you get a fairly substantial amount of daily Claude usage. \n\nI also purchased a three dollar a month GLM 4.7 subscription for day-to-day tasks. Together the Google AI pro subscription with the ‚Äúfive family members‚Äù and the GLM 4.7  subscription give a very significant amount of usage for low cost. That‚Äôs probably enough for most people, but I also have a ChatGPT $20 a month subscription that also hooks into opencode. ChatGPT 5.2 may be slow, but I found it to be very reliable. I have plenty of horsepower for 4 to 5 hour coding sessions.\n\nThis is certainly much more complex than just paying for cursor. But my cursor bills were often exceeding $120 a month. Right now this costs me closer to $40-$50 a month and I don‚Äôt feel like I‚Äôm losing much. The extra complexity may not be right for everyone, but it works pretty well for me.",
          "score": 15,
          "created_utc": "2026-01-18 01:01:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o085r0r",
              "author": "Delicious_Ease2595",
              "text": "How do you use my multiple family accounts with OpenCode? I'm using the same setup between Antigravity and OpenCode",
              "score": 3,
              "created_utc": "2026-01-18 03:06:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o08rn9n",
                  "author": "Putrid-Pair-6194",
                  "text": "I don‚Äôt remember the details off-hand, but I think instructions were on the antigravity opencode authentication repo. I‚Äôm assuming you have setup 5 gmail accounts and added them to your family. Then if memory serves, you use the instructions for the antigravity authentication extension to log into each one. And the extension rotates across all of them automatically.",
                  "score": 1,
                  "created_utc": "2026-01-18 05:24:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o099lgn",
              "author": "pl201",
              "text": "Don‚Äôt think Google AI pro family share each gets separate quota for $20. It‚Äôs one pool shared with up to 5 people. Don‚Äôt believe it is very useful if more than one person try to use Antigravity.",
              "score": -1,
              "created_utc": "2026-01-18 07:55:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0cln4p",
                  "author": "Putrid-Pair-6194",
                  "text": "I don‚Äôt know what are you basing that view on. Here is information from Google that aligns with my personal experience. Other forums seem to concur.\n   \n\n1. Individual Quotas for Family Members\nAccording to Google One Help and official developer forum clarifications from January 2026.\n  \n\n‚Ä¢ Independent Limits: Each member of a Google Family group (up to 5 additional members) receives their own full set of daily and recurring rate limits.¬† \n‚Ä¢ Not a Shared Pool: Unlike storage (which is shared from a common pool), AI quotas for features like Antigravity are per-user. One person‚Äôs heavy usage does not deplete the quota for another family member.",
                  "score": 1,
                  "created_utc": "2026-01-18 20:10:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07qoil",
          "author": "Coldshalamov",
          "text": "[z.ai](http://z.ai) subscription (https://z.ai/subscribe?ic=QDKACAZ1KX and 3x  the usage of claude pro) $2.50 a month\n\nGithub copilot with unlimited chatgpt 4o, 4.1, 5 mini, and grok code fast: $10/m\n\nOpencode Zen: Big Pickle, GLM 4.7, Minimax 2.1, and grok code fast 1 for free\n\nMinimax subscription: $2/m\n\nMoonshot Kimi k2 thinking subscription: $3/m\n\nAll told in opencode: $14.50/m and will never ever hit my limits. I have an extensive subagent driven /build command I loop 3 times that takes 12 hours each, and a /prune command I run once or twice to trim the fat once its done, and then 90% of my projects are functional and need a few tuneups.",
          "score": 10,
          "created_utc": "2026-01-18 01:44:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08mm7s",
              "author": "GullibleDragonfly131",
              "text": "Can you share your Git repo? I'm interested to see how those LLMs compare to Opus.",
              "score": 2,
              "created_utc": "2026-01-18 04:49:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o09r38q",
              "author": "Rygel_XV",
              "text": "How did you get the Minimax and Kimi subscription so cheap? I can find both for $10 respective $9 per month.",
              "score": 1,
              "created_utc": "2026-01-18 10:37:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09rhh8",
                  "author": "Coldshalamov",
                  "text": "strangely, you have to argue with kimi for the price, there's like a promotional event but it actually seems like its response is largely uncalibrated from the price it gives, you just have to keep prompting it until it gives you the right price, I've done it multiple months in a row on the same account. It does look to me now that I checked that the $2 starter plan promo that they had has ended, I know [z.ai](http://z.ai) has theirs until the 30th so i plan on inviting myself and getting another $25 year of lite just because, who knows what i could automate with an extra key.",
                  "score": 1,
                  "created_utc": "2026-01-18 10:40:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0a1f2b",
              "author": "ekalaivan",
              "text": "How to get z ai sub so cheap? In fact except for GitHub i don't see how you get those services for that cheap!",
              "score": 1,
              "created_utc": "2026-01-18 12:08:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0a485s",
                  "author": "Rygel_XV",
                  "text": "They have a reduced price offer running until 31.01. And if you pay quarterly or yearly you get a big discount as well. On top of that they have referral codes for another 10%.\n\nFor example here is my referral :)\nhttps://z.ai/subscribe?ic=JQTB1W1M0L\n\nI think their idea is to lock in people now. If you prepaid for a whole year, will you switch to a different company with a better model if it would arrive?\n\nI myself chose to get the quarterly plan. To play it safe.",
                  "score": 2,
                  "created_utc": "2026-01-18 12:30:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07rrix",
          "author": "FlyingDogCatcher",
          "text": "What are you people doing that you burn through two premium accounts and still can't afford them?",
          "score": 6,
          "created_utc": "2026-01-18 01:49:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09bufv",
              "author": "P1zz4-T0nn0",
              "text": "I've got the same question. I'm a self-employed senior-developer coding all day and I don't hit the limits on a single Max 5x lol. Maybe that are people who don't actually know programming and try 10 workstrees at once, idk.",
              "score": 2,
              "created_utc": "2026-01-18 08:15:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09iegy",
                  "author": "Demon-Martin",
                  "text": "No I don‚Äôt run 10 work trees, and I am a Full-Stack Developer. Opus is just way too expensive. If I understood correctly, Claude Subs can‚Äòt even be compared with Cursors costs. The sub‚Äòs efficiency is way higher than cursors prices.",
                  "score": 1,
                  "created_utc": "2026-01-18 09:16:15",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o09n3uc",
                  "author": "UMANTHEGOD",
                  "text": "Power users (doing ralph loops etc) can burn through tokens pretty quickly but it depends on what you're using it for. I'm currently building a personal budget app, a personal fitness app and a refactoring app for work so I'm getting limited constantly.\n\nAll vibe coded of course because the quality of the code doesn't really matter for these apps.\n\nI've also used opus for everything and I could probably be more mindful to swap to sonnet at times.",
                  "score": 0,
                  "created_utc": "2026-01-18 10:00:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o09i6ns",
              "author": "Demon-Martin",
              "text": "My current project is a rather big turborepo with multiple packages and projects (apps) and most tasks require a big context for the produced code to be good and properly use the available packages. I am already running different methods to minimize the context usage, but still some opus requests cost like 1-3$, and when you code for like 8 hours straight a day, that adds up after time.\n\nObv running a simpler project with less context would be way cheaper.",
              "score": 1,
              "created_utc": "2026-01-18 09:14:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0730p6",
          "author": "No-Concentrate-6037",
          "text": "I would try to learn to use the CLI if I want Opus that badly",
          "score": 3,
          "created_utc": "2026-01-17 23:39:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o076fwr",
              "author": "Demon-Martin",
              "text": "I assume you are talking about Claude Code / an Anthropic Sub with OpenCode\n\nProblem is: I read a TON of negative information about Anthropic the past weeks.\n\nClaude Code is consuming an enormous big amount of tokens compared to before. They are making the ratelimits way way more harsh. And I personally don‚Äòt really like when I want to work, but can‚Äòt because the provider decided to make the model 10x dumber and make the token limit to be 1 prompt per session.\n\nAlso, read that opencode and anthropic ain‚Äòt best friends atm.\n\nhttps://www.reddit.com/r/ClaudeAI/comments/1qa50sq/anthropic_banning_thirdparty_harnesses_while/\nhttps://news.ycombinator.com/item?id=46625918\n\nInfo I was talking about with ratelimits:\nhttps://www.theregister.com/2026/01/05/claude_devs_usage_limits/\nhttps://github.com/anthropics/claude-code/issues/16157#issuecomment-3712177862\nhttps://news.ycombinator.com/item?id=46514221\n\nTheir discord also has an open thread about it with people complaining daily, but the main is probably: https://github.com/anthropics/claude-code/issues/16157",
              "score": 3,
              "created_utc": "2026-01-17 23:57:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o07kjy2",
                  "author": "Historical-Lie9697",
                  "text": "Github copilot is actually not bad for $10/month for supplementing Claude use, has unlimited use of gpt5 mini for easy stuff and 300 premium requests/month that includes a lot of models and they all work in OpenCode. I think for a budget that + Codex $20/m to use them all in OpenCode is a good option. Then if you want multimedia generation and the big context window you could add gemini",
                  "score": 3,
                  "created_utc": "2026-01-18 01:12:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o07bcr3",
                  "author": "No-Concentrate-6037",
                  "text": "No, I mean using Claude Code itself. And yes. I know about all above discussion, but hard to beat Opus as of now",
                  "score": 2,
                  "created_utc": "2026-01-18 00:23:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o08rnhh",
          "author": "NearbyBig3383",
          "text": "People use chutes.ai, it's only 20 bucks man, it's cheap and it never runs out.",
          "score": 3,
          "created_utc": "2026-01-18 05:24:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o092rn0",
              "author": "MorningFew1574",
              "text": "How does chutes compare to nanogpt?",
              "score": 1,
              "created_utc": "2026-01-18 06:54:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0fy6zf",
                  "author": "Complex-Maybe3123",
                  "text": "NanoGPT user here. I`m currently using their Subscription. Never used chutes. \n\nI believe NanoGPT uses some cheaper providers to keep their prices competitive, so I end up getting some very big token speed variation. I use mostly GLM 4.7 Thinking nowadays. Hardly for coding, but in the end, there`s not a lot of difference. Sometimes my requests start processing instantly, others times, it seems like I enter a queue. I time the whole request time (from the moment I press enter, to the moment I receive the whole response, I don`t usually use streaming), so I`m not sure of the actual TPS. But if I`d calculate the tokens per second with the whole request time, sometimes I get 100t/s, some rarer cases it`s very close to 10t/s. Usually it`s more in the middle. But I believe this variation is the delay until my request starts getting processed instead of actual TPS variation. These calcs I mentioned were usually done with around 20k~30k input context and 1k~3k output.\n\nI tried the big boys (GPT and Claude) a few times and they seem to respond the same as from the source.\nAll in all, I`m not a vibe coder, I prefer to use mostly tab-autocomplete, which is outside of what NanoGPT offers. So I don`t really mind the speed variation. At this point in time, I wouldn`t leave NanoGPT for any other provider. New released models become available almost immediately. The devs are also always listening to the users and suggestions are quickly implemented (when they make sense).\n\nSo for open source models, I`m of the opinion that it`s the best, in terms of price, available models and support. When it comes to premium models, there doesn`t seem to be much difference from other providers besides some discounts.",
                  "score": 2,
                  "created_utc": "2026-01-19 08:05:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o09zvdi",
          "author": "kkordikk",
          "text": "Actually switch your approach. Let the more expensive models do the research and plan the work out with granular tasks. Then smaller models to implement small tasks. GLM is great, cheap, fast, limits reset each 5hrs, it‚Äôs great reasoning, multimodal. I highly recommend getting quarterly plan right now, there‚Äôs a promo still going. Also free Gemini API key and if you like opus, just use it sparingly via Anthropic 100$ sub. Also, you can still use free cursor as an ide",
          "score": 2,
          "created_utc": "2026-01-18 11:55:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a2e35",
              "author": "Demon-Martin",
              "text": "I would be using other subs, but cursor itself sadly doesn‚Äôt really support it inside their built-in interface. I don‚Äòt really like CLIs/Terminals so OpenCode/Claude Code isn‚Äòt optimal for me.\n\nI was planning on getting GLM or Minimax or similar, just cursor is very annoying with only supporting ‚Äûone base url overwrite‚Äú that breaks all other models‚Ä¶",
              "score": 1,
              "created_utc": "2026-01-18 12:16:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0a6rb6",
                  "author": "jorgejhms",
                  "text": "Maybe you could try Zed then. Is a code editor written in Rust (it's not a fork of vscode) and one of their key principles is to be open. They allow you to use it's AI features with their own subscription or with any API key. I have it set with GLM currently, with also copilot free and Gemini API keys. They also developed the Agent Client Protocol (ACP) that allows third party cli agents like Claude Code or OpenCode to be used inside Zed UI, like a panel. Seems like the best option for you that don't like terminals.",
                  "score": 2,
                  "created_utc": "2026-01-18 12:50:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0b9pic",
                  "author": "kkordikk",
                  "text": "Huh? It does. Go into cursor settings -> models -> scroll down and there you can use Anthropic key, openAI endpoint / API key (this is for ChatGPT, custom gateway like z.ai) \nPersonally I‚Äôm hosting LiteLLM (alternative to OpenRouter) and using all my models through it",
                  "score": 1,
                  "created_utc": "2026-01-18 16:24:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0afs8j",
          "author": "febryanvald0",
          "text": "Try OpenCode Black\n\n\nhttps://opencode.ai/black",
          "score": 2,
          "created_utc": "2026-01-18 13:50:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0adzyz",
          "author": "Fun-Understanding862",
          "text": "would suggest you to give github copilot a try, it has upped its game, for me claude code(20$) and github copilot(10$) plan works well",
          "score": 1,
          "created_utc": "2026-01-18 13:39:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0am2px",
          "author": "PweraUsog",
          "text": "Switch to Qwen CLI",
          "score": 1,
          "created_utc": "2026-01-18 14:26:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0f900o",
          "author": "RayanAr",
          "text": "Isn't opencode slower than claudecode?",
          "score": 1,
          "created_utc": "2026-01-19 04:43:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lj9xp",
          "author": "raptor_champs",
          "text": "GitHub copilot is in VScode and has a great cli\nAnd you can chose your model",
          "score": 1,
          "created_utc": "2026-01-20 02:50:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qgnad6",
      "title": "Fix memory Leak please",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/8rc4r45sv6eg1.png",
      "author": "ZookeepergameFit4082",
      "created_utc": "2026-01-18 23:07:16",
      "score": 32,
      "num_comments": 5,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qgnad6/fix_memory_leak_please/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0er6n5",
          "author": "james__jam",
          "text": "Sounds like something that needs to be posted in github issues and not reddit üòÖ",
          "score": 20,
          "created_utc": "2026-01-19 02:54:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gaxla",
          "author": "AVX_Instructor",
          "text": "Its probably LSP, i have get simular issue, if keep long session in huge code base",
          "score": 2,
          "created_utc": "2026-01-19 10:05:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0h8wmh",
          "author": "FatherImPregnant",
          "text": "Are you using OhMyOpencode? I‚Äôve noticed the same issue",
          "score": 1,
          "created_utc": "2026-01-19 14:15:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0hbqfm",
          "author": "trypnosis",
          "text": "I use basic opencode with a few mcps and run them all day multiple instance in tmux and my memory is fine. \n\nCould it be an addon or customisation of some kind?",
          "score": 1,
          "created_utc": "2026-01-19 14:30:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lojn9",
          "author": "tripleshielded",
          "text": "It needs memory leaks to give a similar experience to gemini cli.",
          "score": 1,
          "created_utc": "2026-01-20 03:20:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qificf",
      "title": "The best CLI",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qificf/the_best_cli/",
      "author": "DreamDragonP7",
      "created_utc": "2026-01-20 22:19:24",
      "score": 27,
      "num_comments": 15,
      "upvote_ratio": 1.0,
      "text": "I am in awe. srsly fangirling. also super pissed I spent so long curating and creating custom plugins/skills/agents with claude code just to try out Opencode and spend substantially less tokens and get the same quality. \n\nNote: for anyone trying out the oh-my-opencode plugin? dont. token burner for no reason. This shit works right out of the box. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qificf/the_best_cli/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0r62v2",
          "author": "Apart-Permission-849",
          "text": "+1 on oh my open code burning tokens",
          "score": 14,
          "created_utc": "2026-01-20 22:51:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r6bj8",
          "author": "gobitpide",
          "text": "Agreed on the OmO part. The Default Plan and Build cycle is the workflow I keep returning to.",
          "score": 5,
          "created_utc": "2026-01-20 22:53:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ssywz",
          "author": "SynapticStreamer",
          "text": "> This shit works right out of the box. \n\nAnd this is why Anthropic is pissed that people like OpenCode. Ultimately it's going to decrease token usage which is less $ for them.\n\nThere's not a single thing anyone can tell me to convince me that I'm wrong.",
          "score": 2,
          "created_utc": "2026-01-21 04:29:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rzuxp",
          "author": "atkr",
          "text": "oh my anything tools are all junk, ever since any of them existed",
          "score": 4,
          "created_utc": "2026-01-21 01:35:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rdf8c",
          "author": "devdnn",
          "text": "Does the opencode cli document the plan or spec for documentation purpose?\n\nI didn‚Äôt see a way to extend the agent to make sure document the plan or specs",
          "score": 1,
          "created_utc": "2026-01-20 23:31:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rflyw",
              "author": "Hot_Dig8208",
              "text": "By default no. You need to ask the plan agent to do it. But you can use spec driven tool like [openspec](https://openspec.dev). The default workflow of openspec is to write the plan in a markdown file, so we can review it before the implementation.",
              "score": 3,
              "created_utc": "2026-01-20 23:43:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0shvqv",
          "author": "Rude-Needleworker-56",
          "text": "The same feeling I had until I tried pi",
          "score": 1,
          "created_utc": "2026-01-21 03:19:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0simm0",
              "author": "DreamDragonP7",
              "text": "Pi?",
              "score": 1,
              "created_utc": "2026-01-21 03:23:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0sll67",
                  "author": "Rude-Needleworker-56",
                  "text": "Pi coding agent. Simple and extremely hackable",
                  "score": 1,
                  "created_utc": "2026-01-21 03:41:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0sivz1",
          "author": "larowin",
          "text": "What model do you typically use?",
          "score": 1,
          "created_utc": "2026-01-21 03:25:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0sjkft",
              "author": "DreamDragonP7",
              "text": "Opus 4.5\n\nAll other models are vastly inferior. Except maybe gemini 3 pro for fast bug hunting.",
              "score": 1,
              "created_utc": "2026-01-21 03:29:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tg426",
          "author": "whimsicaljess",
          "text": "honestly same. i did a review of all the coding agents the other day and instantly switched to opencode after 1 session. it's so good!",
          "score": 1,
          "created_utc": "2026-01-21 07:30:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r1iej",
          "author": "SuccessfulScene6174",
          "text": "You mean same quality but without any commands skills etc?",
          "score": 1,
          "created_utc": "2026-01-20 22:28:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rtill",
              "author": "DreamDragonP7",
              "text": "Yes",
              "score": 1,
              "created_utc": "2026-01-21 00:59:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfnus6",
      "title": "I don‚Äôt get it",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qfnus6/i_dont_get_it/",
      "author": "Mindless_Art4177",
      "created_utc": "2026-01-17 20:26:14",
      "score": 26,
      "num_comments": 28,
      "upvote_ratio": 0.78,
      "text": "I think I‚Äôm missing something basic I don‚Äôt get the hype around open code\n\nI‚Äôm using cursor 20$ plan ( get blocked ) which I like the most in terms of ui and workflow\n\nCodex cli when I run out of credits (chat gpt 20$) which is also ok Antigravity from time to time (free)\n\nWhy should I switch to opencode ? What‚Äôs the big Change ? Should I buy 20$ plan ? From what I see the IDE extension is just running terminal in sidebar.\n\nPlease enlighten me üôè\n\n‚Äî-\n\nEdit:\n\nNow I get it, you can connect multiple accounts from multiple vendors using /connect and keep using only one tool.\n\nSupports all subagents/commnads/skills so you don‚Äôt need to rewrite them when you‚Äôre switching between models.\n\nOpen source with  big community around it with additional products such as open chamber.\n\nThanks.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qfnus6/i_dont_get_it/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o063ngn",
          "author": "Funny-Advertising238",
          "text": "First of all you can get openchamber from GitHub which is a frontend interface for opencode, I love it.\n\n\nSecond you can connect you chatgpt accounts, antigravity accounts, as well as use all the free models that opencode providers (glm 4.7, minimax etc.).\n\n\nI have 7 antigravity accounts connected and 3 chatgpt accounts. Never get rate limited and antigravity rate limits reset every 5 hours which is great.¬†\n\n\nI was tired if switching between different ones, opencode has everything you need, model agnostic, exposes a openapi server as well and sdk for automations, it has all the features you need like subagents, hooks, skills, etc.\n\n\nAnd a little trick if you feel a little bit grey hat, you can get google ai pro and chatgpt plus accounts for 1-2$ on digital goods marketplaces.",
          "score": 12,
          "created_utc": "2026-01-17 20:40:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o066hiy",
              "author": "technischer_walzer",
              "text": "How do you have 7 antigravity accounts accounts? Did you create them? And you pay for 3 chatgpt accounts?",
              "score": 3,
              "created_utc": "2026-01-17 20:54:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o067pja",
                  "author": "Funny-Advertising238",
                  "text": "Nope I buy chatgpt plus accounts for 2$ each. Same with antigravity for 3-4$. I have 3 google ai pro accounts and the rest are just my own google accounts that don't have a subscription but they still work just the rate limits are much lower.",
                  "score": -4,
                  "created_utc": "2026-01-17 21:00:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0754lb",
              "author": "matija2209",
              "text": "Can you recommend some of those digital goods markets please. Thanks",
              "score": 2,
              "created_utc": "2026-01-17 23:50:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o081soq",
                  "author": "ezhupa99",
                  "text": "plati market",
                  "score": 0,
                  "created_utc": "2026-01-18 02:44:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o064x4a",
              "author": "Mindless_Art4177",
              "text": "Thanks for explaining I‚Äôll try to figure out how to connect my other accounts and give it a chance.",
              "score": 0,
              "created_utc": "2026-01-17 20:46:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o064ksm",
          "author": "Michaeli_Starky",
          "text": "You are not obliged. \n\nTo me OC has a special place because it's open source. Also it works with multiple subs: Copilot, GPT, Antigravity... Anthropic is an exception since recently.",
          "score": 5,
          "created_utc": "2026-01-17 20:44:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o062mlr",
          "author": "No-Concentrate-6037",
          "text": "no you should not change. It's totally just hype. keep using your codex and antigravity.\n\nhappy?",
          "score": 8,
          "created_utc": "2026-01-17 20:34:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o067epv",
          "author": "trypnosis",
          "text": "It‚Äôs a weird one.\n\nI think it‚Äôs the level of customisation for terminal gremlins.\n\nIf you look at the terminal as a cool fun tool then Claude Code, codex and OpenCode fill certain holes in your work flow.\n\nIf terminal is something you see as a more complicated way of using git then. Cursor, CS code with plugins and IntelliJ IDEs are for you.\n\nAll IDEs be they TUI or App have a workflow to leverage the power of LLMs to code. You need to find the one that works for you. I would say none is better than the other. What matters is best for you.",
          "score": 2,
          "created_utc": "2026-01-17 20:59:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o06h1vf",
          "author": "Haspe",
          "text": "This is a tool firstly designed to us terminal users, something that you can use, while you don't have to switch out from the terminal - TUI was their first \"product.\" Their architectic choice of client/server model however enables different client creation, and they're now providing Web, Electron for Desktop and probably a Mobile client in the future. You can also build your own front-end to talk with the server as well and use OpenCode as part of your thing.\n\nOpenCode's another selling point is model agnosticity. You can work with every model with single tool - it's like Visual Studio Code or Neovim of the Agentic Tools. The flavor of the month on the model market will change - perhaps you want to work with OpenAI models. Perhaps you want to work it some self-hosted model as well. Perhaps your workflow consists of using multi-provider models for different things. So if your toolkit is model agnostic, swapping the models that you use does not mean that you have to change your whole workflow - thats the point. For example as a Claude user you're breaking their TOS if you're not using their own clients for their own tools (except the API option, but their API option is quite expensive)\n\nI guess Cursor does that same thing to an extend - but OpenCode is open-source and Cursor is not (this might not mean anything to you, but for other people it does). I can see what the OpenCode does under the hood - and I can even fork it and create my own version of it if I want to. In the end the value proposition of a product is also a preference thing. I prefer to work in terminal, you might not - and you don't have to. Cursor is extremely good as well.",
          "score": 2,
          "created_utc": "2026-01-17 21:48:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o06iw8b",
              "author": "Mindless_Art4177",
              "text": "Now I get it\nYou‚Äôre model agnostic, so you write your subagents/commands/skills and you don‚Äôt need to port it or switch tools when you‚Äôre running out of credits. Greet selling point.\n\nI‚Äôm used for cli tools so it‚Äôs not a problem, only when I‚Äôm developing ui I like to attach screenshots directly from clipboard to the conversion , cursor does it very well, not sure it‚Äôs will work in cli context.\n\nThanks any way üôè",
              "score": 1,
              "created_utc": "2026-01-17 21:57:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o07uxab",
                  "author": "Big_Bed_7240",
                  "text": "Opencode has image support",
                  "score": 2,
                  "created_utc": "2026-01-18 02:06:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o06305f",
          "author": "pokemonplayer2001",
          "text": "Imagine trying it and deciding for yourself!  \n\nJust imagine a modicum of effort!",
          "score": 3,
          "created_utc": "2026-01-17 20:36:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o064gl8",
              "author": "Mindless_Art4177",
              "text": "I tried and it‚Äôs felt exactly like any other cli (codex, Gemini-cli)\nThat‚Äôs why I got to feeling I‚Äôm missing something \nSometimes you might find goldmine by just asking",
              "score": 1,
              "created_utc": "2026-01-17 20:44:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o072zp3",
          "author": "Apprehensive_Half_68",
          "text": "I liked OpenCode after I gave it a shot a few weeks ago like you.  However what I wasn't ready for was \"Oh My OpenCode\" which has changed the way I develop software with most of the presets I use already built in.  It actually is TURNING me into a CLI guy as it feels just like cursor with a sidebar to chat and a file explorer open.. mcp status always visible etc but makes using Ralph Wiggum almost too easy.",
          "score": 1,
          "created_utc": "2026-01-17 23:39:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o07cxr8",
          "author": "dubh31241",
          "text": "The biggest selling points to me are the built in client/server architecture with pretty much API parity with what you can do locally as well as the ability to build literally any type of interface on top of opencode. This is now an AI compute engine. With some imagination and creativity, you can build tons of stuff on top of this. I just deployed this on a K8 cluster to interact with all of my resources; its like a bloomberg terminal for my K8 cluster.  \n\nMy next idea is to build a K8 operator for this to deploy multiple instances, because why do I need \"Agentic Frameworks\" if I can somehow orchestrate these using Skills and Agent file.",
          "score": 1,
          "created_utc": "2026-01-18 00:31:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08h31w",
          "author": "SynapticStreamer",
          "text": "> Why should I switch to opencode ?\n\nWhy are you acting like everyone here is just dying for you to swap up your workflow? You're approaching everything about this entirely wrong... A better question is why would you want to use 4 tools when you can deal with only 1.",
          "score": 1,
          "created_utc": "2026-01-18 04:12:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a5hm0",
          "author": "sbayit",
          "text": "My primary model is GLM, and DeepSeek's Opencode works best with it when running on its own server rather than through Openrouter.",
          "score": 1,
          "created_utc": "2026-01-18 12:40:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o064y2o",
          "author": "trmnl_cmdr",
          "text": "I tried vscode and it was exactly like notepad, I don‚Äôt see why I should switch",
          "score": 0,
          "created_utc": "2026-01-17 20:46:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhj9ua",
      "title": "Bringing \"Advanced Tool Use\" to OpenCode with mcpx",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qhj9ua/bringing_advanced_tool_use_to_opencode_with_mcpx/",
      "author": "vicdotso",
      "created_utc": "2026-01-19 22:41:29",
      "score": 22,
      "num_comments": 3,
      "upvote_ratio": 0.96,
      "text": "Anthropic recently published their advanced tool use - [https://www.anthropic.com/engineering/advanced-tool-use](https://www.anthropic.com/engineering/advanced-tool-use) approach. The key insight is moving tool discovery to runtime instead of loading schemas upfront.\n\nThe problem: MCP integrations are fragmented. Claude Code has native support, most other tools don't. If you switch agents, you lose access to your MCP setup.\n\nBuilt mcpx to bring this pattern to any agent with bash. OpenCode, Aider, your custom setup. If it can run bash, it can use MCP servers now.\n\n\\- brew tap cs50victor/mcpx && brew install mcpx\n\n\\- mcpx  ( list all servers/tools )\n\n\\- mcpx grep \"\\*browser\\*\"          ( search by pattern )\n\n\\- mcpx playwright/click          ( get schema )\n\n\\- mcpx playwright/click '{\"selector\": \"#submit\"}'  ( call tool )\n\nwhy this approach:\n\n\\- Works across agents - not locked to any specific tool\n\n\\- Runtime discovery - \\~400 tokens vs 47k for upfront schema loading\n\n\\- Daemon mode - keeps stateful connections alive (browser sessions, db handles)\n\n\\- Uses your existing MCP config - no migration needed\n\nIt's open source: [https://github.com/cs50victor/mcpx](https://github.com/cs50victor/mcpx)\n\nWould love feedback, especially from folks who've been switching between agents.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qhj9ua/bringing_advanced_tool_use_to_opencode_with_mcpx/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0nnkz7",
          "author": "ExtentOdd",
          "text": "Why dont you create the PR? I believe this feature should be native to Opencode",
          "score": 4,
          "created_utc": "2026-01-20 12:37:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nq76o",
          "author": "touristtam",
          "text": "Looks similar to https://github.com/kenneth-liao/mcp-launchpad?",
          "score": 2,
          "created_utc": "2026-01-20 12:55:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0o5vfv",
              "author": "vicdotso",
              "text": "just checked this out. this looks really like a solid project / alternative to mcpx.",
              "score": 1,
              "created_utc": "2026-01-20 14:24:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qi20vk",
      "title": "I built open-source Claude CoWork on OpenCode with app integrations. Works on Windows and Linux.",
      "subreddit": "opencodeCLI",
      "url": "https://github.com/ComposioHQ/open-claude-cowork",
      "author": "Gullible-Time-8816",
      "created_utc": "2026-01-20 14:08:01",
      "score": 18,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qi20vk/i_built_opensource_claude_cowork_on_opencode_with/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0qhdjo",
          "author": "Michaeli_Starky",
          "text": "Building MVP of that is trivial. Maintaining and developing it is not. Letting LLM run unrestricted on your PC is a HUGE gamble. You absolutely must build extremely intricate guardrails.",
          "score": 1,
          "created_utc": "2026-01-20 20:54:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}