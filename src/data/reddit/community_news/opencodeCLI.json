{
  "metadata": {
    "last_updated": "2026-01-23 02:26:24",
    "time_filter": "week",
    "subreddit": "opencodeCLI",
    "total_items": 20,
    "total_comments": 174,
    "file_size_bytes": 186687
  },
  "items": [
    {
      "id": "1qexcsu",
      "title": "i wanted to work 100% from the terminal",
      "subreddit": "opencodeCLI",
      "url": "https://v.redd.it/o0s0pgk9ysdg1",
      "author": "Professional_Cap3741",
      "created_utc": "2026-01-17 00:19:11",
      "score": 133,
      "num_comments": 33,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qexcsu/i_wanted_to_work_100_from_the_terminal/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o01x296",
          "author": "sudonem",
          "text": "This is rad, and itâ€™s essentially the workflow I have by pairing OpenCode with neovim & tmux. \n\nCurious to see how it shapes up (but youâ€™ll have to extricate tmux & neovim from my cold dead carcass ðŸ™ƒ)",
          "score": 15,
          "created_utc": "2026-01-17 04:37:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o049bux",
              "author": "92smola",
              "text": "Hahahah same",
              "score": 3,
              "created_utc": "2026-01-17 15:24:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o01o8up",
          "author": "Old-Sherbert-4495",
          "text": "will you be sharing this project?? or at least how you built?",
          "score": 8,
          "created_utc": "2026-01-17 03:36:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03jug0",
          "author": "verkavo",
          "text": "Tmux split screen with Lazygit and Opencode is an easy way to follow what AI had changed.",
          "score": 7,
          "created_utc": "2026-01-17 13:01:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02hx73",
          "author": "awfulalexey",
          "text": "Link?",
          "score": 3,
          "created_utc": "2026-01-17 07:24:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0332sq",
          "author": "splitbrainhack",
          "text": "linkeroo ?",
          "score": 3,
          "created_utc": "2026-01-17 10:42:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01k6pu",
          "author": "Old-Sherbert-4495",
          "text": "I wanted this all along.",
          "score": 2,
          "created_utc": "2026-01-17 03:09:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02g5qy",
          "author": "jirubizu",
          "text": "Is there a gh link dont want to lose this project",
          "score": 2,
          "created_utc": "2026-01-17 07:08:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02ya36",
          "author": "4gustaf",
          "text": "Exactly my gripe, good job!",
          "score": 2,
          "created_utc": "2026-01-17 09:57:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o034k1d",
          "author": "Embarrassed-Mail267",
          "text": "Man this is the most beautiful thing I've seen this year.... well designed!! Fluid! Beautiful.   \nthis feature alone makes me want to switch to opencode..\n\n  \ni am a cli power user through and through (see my other posts)... but I need the IDE for effective code review / checking agent work / stress testing its architecture.... Antigravity delivered what i needed.   \n\n  \nBut your thing is so clean, i want to use it just to stare at its beauty.",
          "score": 2,
          "created_utc": "2026-01-17 10:56:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03bj68",
          "author": "silopolis",
          "text": "WANT! ðŸ˜",
          "score": 2,
          "created_utc": "2026-01-17 11:58:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03gyrv",
          "author": "grepharders",
          "text": "Tried the new UI as well  itâ€™s nice but the terminal is still my go to",
          "score": 2,
          "created_utc": "2026-01-17 12:41:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o042f18",
          "author": "tkdeveloper",
          "text": "This kind of what i do with helix + zellij. Have one tab for helix, one for shell commands, one for opencode, and one for lazygit",
          "score": 2,
          "created_utc": "2026-01-17 14:49:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04ocr5",
          "author": "Ok_Proposal_1290",
          "text": "If it's possible could I get a Link? This looks AMAZING",
          "score": 2,
          "created_utc": "2026-01-17 16:36:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o055geb",
          "author": "Forgot_Password_Dude",
          "text": "Where GitHub repo for this",
          "score": 2,
          "created_utc": "2026-01-17 17:56:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05ns3f",
          "author": "anon_wick",
          "text": "Link please",
          "score": 2,
          "created_utc": "2026-01-17 19:21:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0951dc",
          "author": "Serious_Client6274",
          "text": "warp or ghostty + zellij, opening the CLI coding agent of your choice + lazygit + yazi + neovim",
          "score": 2,
          "created_utc": "2026-01-18 07:14:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02e6h9",
          "author": "garloid64",
          "text": "What are we doing here? We've had this experience for so long with so many vscode extensions, why is our hyper advanced state of the art autonomous AI agent technology regressing to the 1980s when it comes to UI?",
          "score": 3,
          "created_utc": "2026-01-17 06:51:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03tcqp",
              "author": "vienna_city_skater",
              "text": "The reality is building good desktop applications is hard and the TUI is a shortcut that devs accept. That was the reasoning behing Claude Code and many projects copied this strategy. Also the agentic future may involve less manual input than many anticipate, so why spend time building good UX?",
              "score": 2,
              "created_utc": "2026-01-17 14:00:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0btkn9",
                  "author": "[deleted]",
                  "text": "Writing graphical apps is a pain in the ass, that's true, especially ones that work on all the 58 billion edge cases of different operating systems.  I've literally built webUI's on a local system just so I didn't have to fuck with the OS.",
                  "score": 3,
                  "created_utc": "2026-01-18 17:59:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o04rtx1",
                  "author": "trypnosis",
                  "text": "That makes sense. Maybe the future will be GUI free.",
                  "score": 1,
                  "created_utc": "2026-01-17 16:52:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0bezst",
                  "author": "Maasu",
                  "text": "I just hate touching my mouse, it's a dickhead that slows me down",
                  "score": 1,
                  "created_utc": "2026-01-18 16:50:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o02ikt7",
              "author": "trypnosis",
              "text": "I spent the last 15 years going full GUI. Now i feel like Iâ€™m going before to before the GUI revolution. I spending more and more time in the terminal.",
              "score": 2,
              "created_utc": "2026-01-17 07:30:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03tnpt",
                  "author": "vienna_city_skater",
                  "text": "I feel like I'm back at university where I went all Emacs from coding to notes to email to web browsing. Not sure why I did it, but it felt L337 for sure. EDIT: That was right after my clickibunti Vista phase, so maybe a backlash from that era.",
                  "score": 2,
                  "created_utc": "2026-01-17 14:01:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0bt9yq",
              "author": "[deleted]",
              "text": "~~Regressing~~  Progressing.",
              "score": 1,
              "created_utc": "2026-01-18 17:57:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o09b7xm",
          "author": "lev400",
          "text": "Have you tried OpenCode Desktop ?",
          "score": 1,
          "created_utc": "2026-01-18 08:09:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0otz9m",
          "author": "erracode",
          "text": "Really good, what I keep struggling the most is that I really like to add images in the chats, that's why I keep having antigravity or cursor opened with a terminal of open code inside it, I wonder how can I have best of all worlds",
          "score": 1,
          "created_utc": "2026-01-20 16:21:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11823z",
          "author": "montymonro",
          "text": "Please share how you achieved this! I would love to use something like this",
          "score": 1,
          "created_utc": "2026-01-22 12:13:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01m6r1",
          "author": "Ok-Painter573",
          "text": "So recreating gh copilot/cursor in terminal?",
          "score": -1,
          "created_utc": "2026-01-17 03:22:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o030t86",
          "author": "Reasonable-Layer1248",
          "text": "Taking everything into account, I use warp+cli or zed, and I think it's not bad.",
          "score": 0,
          "created_utc": "2026-01-17 10:21:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qimlua",
      "title": "We built Kuse Cowork: an open-source, Rust-native alternative to Claude Cowork",
      "subreddit": "opencodeCLI",
      "url": "https://v.redd.it/vl8say66emeg1",
      "author": "Loose_Kangaroo91",
      "created_utc": "2026-01-21 03:16:51",
      "score": 115,
      "num_comments": 21,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qimlua/we_built_kuse_cowork_an_opensource_rustnative/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0tcczy",
          "author": "tdi",
          "text": "will you maintain it ?",
          "score": 5,
          "created_utc": "2026-01-21 06:57:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0th6of",
              "author": "Loose_Kangaroo91",
              "text": "Absolutely!! We have always thinking about open source and this is actually a great opportunity to actually encourage us to do this, pls drop your feedback, experience, comments anytime and we would love to keep optimizing this!!",
              "score": 2,
              "created_utc": "2026-01-21 07:40:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ujxoq",
          "author": "TheHeadSalad",
          "text": "I donâ€™t understand these posts sharing : â€œwe built this over last 24/48 hoursâ€, like is that supposed to be a testament?(even when we have these marvelous coding agents). \nIMO, that just screams that what you have built is still immature and bug prone. It takes time to build nice things,    \nâ€¦but anything has to start somewhere, I guess.",
          "score": 5,
          "created_utc": "2026-01-21 13:07:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0vouju",
              "author": "gottapointreally",
              "text": "I think they are trying to communicate that it is in early dev.",
              "score": 2,
              "created_utc": "2026-01-21 16:31:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tcywp",
          "author": "Lonely_Noyaaa",
          "text": "Cool project and thanks for sharing! It's really ambitious to build this within a weekend. Do you guys support multiple models switch for now?",
          "score": 2,
          "created_utc": "2026-01-21 07:02:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0th806",
              "author": "Loose_Kangaroo91",
              "text": "Thank you! And yes this supports most trendy LLMs",
              "score": 1,
              "created_utc": "2026-01-21 07:40:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tf7es",
          "author": "No_Point_9687",
          "text": "Haven't you recently said Claude killed your business or was it someone else. \nPromising product, will check it out. Thank you.",
          "score": 1,
          "created_utc": "2026-01-21 07:22:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0thfb2",
              "author": "Loose_Kangaroo91",
              "text": "Oh thanks! Yes I think one of our folks made that post! Please drop your feedback anytime and we would love to keep optimizing this!",
              "score": 1,
              "created_utc": "2026-01-21 07:42:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tvv2f",
          "author": "mintybadgerme",
          "text": "Your readme's broken. Pretty fundamental. :)\n\n# Clone the repo\ngit clone https://github.com/kuse-ai/kuse-cowork.git",
          "score": 1,
          "created_utc": "2026-01-21 10:00:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0uvdoc",
          "author": "MrChevyCeleb42",
          "text": "cant wait to try it! I built something similar and shelved it, excited to see this!!!!",
          "score": 1,
          "created_utc": "2026-01-21 14:11:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ybxfb",
              "author": "Loose_Kangaroo91",
              "text": "Thanks!! Please let us know your experience and would be excited to see your work as well!!",
              "score": 1,
              "created_utc": "2026-01-21 23:51:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0wv8zi",
          "author": "JealousBid3992",
          "text": "Nice you even implemented the Terminal scrolling / refresh bug in Claude Code, that's authentic",
          "score": 1,
          "created_utc": "2026-01-21 19:39:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o112bvy",
          "author": "Wrong_Daikon3202",
          "text": "An interesting proposal, I'm testing it right now and I come up with a couple of suggestions.\n\n\\- It would be very good if you pre-compiled each new version of the APP for the main systems.  \n\\- It would be great to have the same list of free LLM (Grok, GLM-4.7, MiniMax...) that has opencode to a clik.",
          "score": 1,
          "created_utc": "2026-01-22 11:31:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0t0pmz",
          "author": "Ok-Machine-8071",
          "text": "oh my god",
          "score": 1,
          "created_utc": "2026-01-21 05:23:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0t64h4",
              "author": "Loose_Kangaroo91",
              "text": "Is this omg in a good way haha?",
              "score": 1,
              "created_utc": "2026-01-21 06:04:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0t1ogz",
          "author": "true-though",
          "text": "Congrats, and great job!!",
          "score": 1,
          "created_utc": "2026-01-21 05:30:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0t62vd",
              "author": "Loose_Kangaroo91",
              "text": "Thanks! Feel free to try it out and let us know your feedback!!",
              "score": 2,
              "created_utc": "2026-01-21 06:04:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tovm5",
          "author": "ApprehensiveNail42",
          "text": "Iâ€™d love to know how it compares. Cowork is still in its infancy but I urgently need a tool for a dispute Iâ€™m handling with the other owners in the complex I live in, reason being that Claudeâ€™s interface is much too basic. No proper filing in projects (unlabelled thumbnails just donâ€™t cut it when you have over 50 documents), no tabs (needed with how buggy things get when switching between conversations - messages disappearing for example). Cowork has been much better as it works directly with the files on the system but yeah, itâ€™s very new and thereâ€™s room for improvement.",
          "score": 0,
          "created_utc": "2026-01-21 08:52:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0trv3e",
              "author": "Loose_Kangaroo91",
              "text": "I am so thrilled to see such a detailed and right on point user needs!! Basically we cover all capabilities that claude provide in thie open source version, and it also supports other llms switch if you have other preferences. It's totally free so pls try it out and let us know how it meets your needs!!",
              "score": 1,
              "created_utc": "2026-01-21 09:21:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0uwyyo",
                  "author": "ApprehensiveNail42",
                  "text": "Awesome, thanks. Iâ€™m a long time web designer, now product designer so pick up on product limitations quicker than most. Like so many others, AI and Claude in particular have gifted me the freedom to place a larger focus on what Iâ€™m actually good at. Itching to get some stuff built, shipped and start earning. And hopefully Iâ€™ll be able to do away with client-deadline-based work altogether someday!",
                  "score": 1,
                  "created_utc": "2026-01-21 14:19:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qeufrc",
      "title": "One week with OpenCode Black",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qeufrc/one_week_with_opencode_black/",
      "author": "JohnnyDread",
      "created_utc": "2026-01-16 22:33:35",
      "score": 104,
      "num_comments": 78,
      "upvote_ratio": 0.97,
      "text": "Well, it finally happened. After a week of pretty heavy (but not insane) coding, I finally hit my weekly quota with OpenCode Black. Very comparable experience to Claude Code Max but with access to more models. If OpenCode can keep this up and continue providing the same level of usage, this will be one of the best subscription values out there.... if\n\nedit: lots of questions:\n\n* I am using the top-tier 20X plan ($200/mo).\n* Some days I was working all day from before dawn till well late into the night. Other days I had meetings and other distractions, so on average, about 6-8 hours a day. \n* I don't do the silly 10 agents generating tons of slop thing. I iterate with the LLM on detailed specifications and get one or two agents working on those. While those are running, I review code, test, and sometimes use a third agent for small tasks. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qeufrc/one_week_with_opencode_black/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o01gdqe",
          "author": "jovialfaction",
          "text": "I don't understand the economics of it. Anthropic can offer Claude Code at this price because they run the model and inference doesn't actually cost as much as the advertised API price. \n\nBut how can OpenCode do it? They have to pay the API provider, so the only way to make a profit is to hope the user uses less than the cost of the tokens?",
          "score": 23,
          "created_utc": "2026-01-17 02:46:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02c83j",
              "author": "whimsicaljess",
              "text": "So long as people aren't running ralph loops or other insane shit, these monthly subs are probably generally profitable or at least break even.",
              "score": 7,
              "created_utc": "2026-01-17 06:34:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o081zfi",
              "author": "philosophical_lens",
              "text": "Anomaly is backed by YC and a bunch of other big name Silicon Valley VCs. The most plausible theory is that they are burning VC money on Opencode black to gain marketshare. \n\nhttps://sst.dev/about/",
              "score": 2,
              "created_utc": "2026-01-18 02:45:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09d2xs",
                  "author": "DutyPlayful1610",
                  "text": "A lot of the companies also give out free credits, so people burn them.",
                  "score": 1,
                  "created_utc": "2026-01-18 08:26:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0akvxz",
              "author": "Ordinary-You8102",
              "text": "Thats actually the dream of every company like anthropic. they sell the API for enterprises for cheaper, they realize not everyone will use their agents but this way they get a higher share of the market.",
              "score": 1,
              "created_utc": "2026-01-18 14:19:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0n3ue8",
              "author": "sentrix_l",
              "text": "Correct",
              "score": 1,
              "created_utc": "2026-01-20 09:55:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o02bjla",
              "author": "t4a8945",
              "text": "My theory is that they're buying a bunch of Claude Max 20 and similar \"cheap\" subscriptions, and we're basically paying to access the models without having to manage the lifecycle of the accounts.\n\n\nI mean... That's actually genius.Â \n\n\nI hope that's what they do.Â ",
              "score": -6,
              "created_utc": "2026-01-17 06:28:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o04uhn6",
                  "author": "RegrettableBiscuit",
                  "text": "Ain't no way. Anthropic would shut them down before you could say \"TOS violation.\"Â ",
                  "score": 3,
                  "created_utc": "2026-01-17 17:04:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o08f8oj",
                  "author": "AkiDenim",
                  "text": "Just how naive is this opinion? Lmao",
                  "score": 1,
                  "created_utc": "2026-01-18 04:01:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o00gpjg",
          "author": "koddajr",
          "text": "6 days using opus 4.5? how many hours for day? parallel agents or a single instance?",
          "score": 15,
          "created_utc": "2026-01-16 23:11:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01y4jv",
              "author": "JohnnyDread",
              "text": "Mostly Opus. 6-8hr/day. 1-2 agents typically , rarely 3.",
              "score": 12,
              "created_utc": "2026-01-17 04:44:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o00kxul",
          "author": "alOOshXL",
          "text": "What sub  20 or max 5 on opencode black?",
          "score": 10,
          "created_utc": "2026-01-16 23:35:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01yeve",
              "author": "JohnnyDread",
              "text": "20 ($200/mo)",
              "score": 2,
              "created_utc": "2026-01-17 04:46:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o00e6zg",
          "author": "Firm_Meeting6350",
          "text": "Interesting, thanks for sharing. Can the sub only be used for opencode?",
          "score": 17,
          "created_utc": "2026-01-16 22:58:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00fuoc",
              "author": "t4a8945",
              "text": "That's such a meta comment. Great thinking. I hope so hahaÂ ",
              "score": 3,
              "created_utc": "2026-01-16 23:06:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00r0x1",
                  "author": "ZeSprawl",
                  "text": "No they donâ€™t limit where it can be used",
                  "score": 3,
                  "created_utc": "2026-01-17 00:09:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0172fp",
              "author": "anfelipegris",
              "text": "That's a loaded comment, I love it!",
              "score": 1,
              "created_utc": "2026-01-17 01:47:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o01f6gy",
          "author": "fuyao_j",
          "text": "https://preview.redd.it/2kegl65jntdg1.png?width=2474&format=png&auto=webp&s=472d382a24ea306c47cc1477049f077b199b4ec8\n\nSharing my experience. I used it with oMo.",
          "score": 9,
          "created_utc": "2026-01-17 02:38:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01y2uq",
              "author": "Background_Might_700",
              "text": "Thanks for the share. Are you using the $200 Opencode Black plan?",
              "score": 2,
              "created_utc": "2026-01-17 04:44:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0274gg",
                  "author": "fuyao_j",
                  "text": "Yup, $200 plan.  \nAs for me limits are crazy generous right now, it feels too good to last.",
                  "score": 2,
                  "created_utc": "2026-01-17 05:51:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o081hfl",
              "author": "philosophical_lens",
              "text": "How do you get this dashboard?",
              "score": 2,
              "created_utc": "2026-01-18 02:42:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0c9p7v",
                  "author": "fuyao_j",
                  "text": "From this package [https://github.com/junhoyeo/tokscale](https://github.com/junhoyeo/tokscale)",
                  "score": 3,
                  "created_utc": "2026-01-18 19:13:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o101y1l",
              "author": "avg8888",
              "text": "isnt this the only way to really compare subscriptions between different providers?",
              "score": 1,
              "created_utc": "2026-01-22 06:07:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o00awt7",
          "author": "jpcaparas",
          "text": "\\> Very comparable experience to Claude Code Max\n\nA bit more generous in your opinion? Or pretty much the same.",
          "score": 5,
          "created_utc": "2026-01-16 22:41:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03lrtc",
              "author": "seaweeduk",
              "text": "Not taking a shot at the black plans, I'm on the waitlist and will cancel my anthropic plan as soon as they make a $100 option available. But there is a 0% chance any black plan will come close with the amount of tokens you can get out of Anthropic's plans. I'm on 5x Pro $100 plan this month I got $1189 usage out of a $100 sub without even once hitting my 5 hour or 7 day limits. Looking at previous months 10x - 15x value has been common for me.\n\nZen cannot compete with this they would lose far too much money as they have to pay the inflated API prices that effectively subsidize these plans. \n\nhttps://preview.redd.it/22zk8ngrswdg1.png?width=1300&format=png&auto=webp&s=4b0961d2012177afe2080f4f26fa3d22509538a5",
              "score": 3,
              "created_utc": "2026-01-17 13:14:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o07gj1m",
                  "author": "lundrog",
                  "text": "What plugin or etc is that? I would like to try it",
                  "score": 3,
                  "created_utc": "2026-01-18 00:51:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o03s0w8",
                  "author": "foolsgold1",
                  "text": "What makes you think they are paying the retail API price?",
                  "score": 2,
                  "created_utc": "2026-01-17 13:52:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o01yi0s",
              "author": "JohnnyDread",
              "text": "Seemed about the same, honestly. Maybe a little more generous, but I didn't keep meticulous track of my Claude usage when I had it.",
              "score": 1,
              "created_utc": "2026-01-17 04:47:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o00j2h5",
          "author": "Lumpy-Carob",
          "text": "Thats good to know and thank you for sharing -   \nIt would be useful to share token usage with tools like  ccusage or something similar \n\n\\`npx @ ccusage/opencode@latest\\`    [https://ccusage.com/guide/opencode/](https://ccusage.com/guide/opencode/)  \n\nPS: I have no affiliation with ccusage",
          "score": 5,
          "created_utc": "2026-01-16 23:24:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00rpe1",
          "author": "SlaveZelda",
          "text": "What Opencode Black Sub? 20, 100 or 200?",
          "score": 6,
          "created_utc": "2026-01-17 00:13:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01ygyf",
              "author": "JohnnyDread",
              "text": "The highest tier - $200/mo",
              "score": 1,
              "created_utc": "2026-01-17 04:46:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o00sle3",
          "author": "Background_Might_700",
          "text": "Did you use oh-my-opencode with this?",
          "score": 6,
          "created_utc": "2026-01-17 00:18:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0888ar",
              "author": "Apart-Permission-849",
              "text": "Would like to see a config if possible",
              "score": 1,
              "created_utc": "2026-01-18 03:20:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o00trgf",
          "author": "FlyingDogCatcher",
          "text": "I hope these guys kick ass",
          "score": 5,
          "created_utc": "2026-01-17 00:25:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00kyii",
          "author": "LostLakkris",
          "text": "I signed up within 30minutes the tweet.\n\nI'm still waiting for activation :-(",
          "score": 5,
          "created_utc": "2026-01-16 23:35:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00r4au",
              "author": "ZeSprawl",
              "text": "The tweet from last week or this week?",
              "score": 1,
              "created_utc": "2026-01-17 00:10:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00vgc1",
                  "author": "LostLakkris",
                  "text": "The GA tweet, think that's this week.",
                  "score": 2,
                  "created_utc": "2026-01-17 00:35:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o00ahch",
          "author": "ReporterCalm6238",
          "text": "How much Opus 4.5 was included?",
          "score": 2,
          "created_utc": "2026-01-16 22:39:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00aot0",
              "author": "JohnnyDread",
              "text": "That's pretty much all I use. I experimented with some other models. They just added Codex 5.2 yesterday, so I did a little bit with it, but pretty much everything else was with Opus.",
              "score": 2,
              "created_utc": "2026-01-16 22:40:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o00uniq",
          "author": "Lyuseefur",
          "text": "Waiting for my CC to run out then will get this one. Going to not renew my Codex either",
          "score": 2,
          "created_utc": "2026-01-17 00:30:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00xveu",
              "author": "Fit-Palpitation-7427",
              "text": "Because opencode with opus is better then cc and opus?",
              "score": 1,
              "created_utc": "2026-01-17 00:49:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00y6jy",
                  "author": "Lyuseefur",
                  "text": "Yes",
                  "score": 3,
                  "created_utc": "2026-01-17 00:51:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o04faff",
          "author": "warner_lyricist",
          "text": "They are attracting people with higher limits but will need to adjust , thereâ€™s no way they can give same opus usage as anthropic, letâ€™s be realistic",
          "score": 2,
          "created_utc": "2026-01-17 15:53:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08mlq3",
          "author": "jNSKkK",
          "text": "This looks very promising. Annoying that the waitlist isn't determinate though. My Claude Code runs out today and I can't afford to get on the waitlist, renew CC then a week later have to pay for Black because I got in.\n\nAnyone used the $100 plan and can comment on usage?",
          "score": 2,
          "created_utc": "2026-01-18 04:49:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0szs0y",
          "author": "iproblywontpostanywy",
          "text": "Itâ€™s a really good value. I hit it the second day. No loops, only 2-3 terminals open in different projects.\n\nFor reference I have the $200 sub for OC, CC, Cursor, Codex, & Gemini for work.\n\nPretty comparable to the $200 cursor sub in terms of usage.\n\nCC is junk and they serve you worse and worse models as you use more. You can see for yourself when you get high in usage just run a terminal using their api or vertex api and it is night and day. I use Opus in OC via Vertex and it provides the fastest and most consistent model IMO. \n\nCodex is pretty great, seems like they just progressively slow down the responses as you get up there which I personally prefer.\n\nI like the OC and if I was getting a sub personally I would get that and if I was consistently using that just use Vertex",
          "score": 2,
          "created_utc": "2026-01-21 05:16:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00q221",
          "author": "mattparlane",
          "text": "Thanks for sharing, I'm on the waitlist.\n\nDoes anyone have any idea how long the waitlist is?\n\nI feel like this might be a tight business model for them. The model providers can spread load across their entire system and adjust limits as their hardware allows, but players like OpenCode will be paying API pricing (possibly with an enterprise discount) on every token. Hope it lasts.",
          "score": 1,
          "created_utc": "2026-01-17 00:04:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o015han",
          "author": "blu38berry",
          "text": "More details please",
          "score": 1,
          "created_utc": "2026-01-17 01:36:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o041h7q",
          "author": "Busy-Chemistry7747",
          "text": "The thing I'm missing are projects and memory for non coding actions. The whole package is pretty good for Claude. If there was an easy (and probably local?) Replacement I'd switch",
          "score": 1,
          "created_utc": "2026-01-17 14:44:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o075nxr",
          "author": "matija2209",
          "text": "How can your brains process all the code outputted?",
          "score": 1,
          "created_utc": "2026-01-17 23:53:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0kfkm3",
              "author": "Price-Visual",
              "text": "who reads code anymore",
              "score": 1,
              "created_utc": "2026-01-19 23:15:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0al423",
          "author": "Ordinary-You8102",
          "text": "is it really worth it? 200$/month sound like a lot considering you have other models with \"unlimited usage\" for 10-50$? or is it cause claude is that good?",
          "score": 1,
          "created_utc": "2026-01-18 14:20:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0as50t",
              "author": "JohnnyDread",
              "text": "There are no \"unlimited usage\" plans. All subscriptions have some sort of hourly/weekly cap or throttle. OpenCode Black and previously Claude Code Max are well worth it to me because I'm certainly going to spend at least $200/month if I were paying by the token. And if these plans give me any kind of a discount, even a small one, it's worth it.",
              "score": 1,
              "created_utc": "2026-01-18 14:59:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0beecr",
                  "author": "Ordinary-You8102",
                  "text": "GH Copilot/Codex/Gemini oauth isnt way more?",
                  "score": 1,
                  "created_utc": "2026-01-18 16:47:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o101cb5",
          "author": "avg8888",
          "text": "any idea if this means the $100 and $20 plans stack up with claudes equivelant plans?",
          "score": 1,
          "created_utc": "2026-01-22 06:02:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhvzoi",
      "title": "OpenCodeâ€™s creator on model freedom, Anthropic blocks, and the â€œdouble miracleâ€ of open source",
      "subreddit": "opencodeCLI",
      "url": "https://jpcaparas.medium.com/opencodes-creator-on-model-freedom-anthropic-blocks-and-the-double-miracle-of-open-source-bd94bd8fc763?sk=de6ec2383dae5cdd8e135a345dd2adfe",
      "author": "jpcaparas",
      "created_utc": "2026-01-20 08:52:20",
      "score": 60,
      "num_comments": 7,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qhvzoi/opencodes_creator_on_model_freedom_anthropic/",
      "domain": "jpcaparas.medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0os4m3",
          "author": "Michaeli_Starky",
          "text": "OC is plain better to that as agentic harness.",
          "score": 7,
          "created_utc": "2026-01-20 16:13:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0qatfp",
              "author": "jpcaparas",
              "text": "undeniably.",
              "score": 2,
              "created_utc": "2026-01-20 20:23:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0n4htj",
          "author": "Old-School8916",
          "text": "Streisand effect",
          "score": 5,
          "created_utc": "2026-01-20 10:02:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oeix8",
              "author": "taylorlistens",
              "text": "Donâ€™t look that up!",
              "score": 2,
              "created_utc": "2026-01-20 15:08:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0ozmj5",
                  "author": "EmreErdoqan",
                  "text": "Haha exactly this!",
                  "score": 2,
                  "created_utc": "2026-01-20 16:47:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0om7hm",
          "author": "eMperror_",
          "text": "So, what's the current method to use the Max subscription without being blocked?",
          "score": 3,
          "created_utc": "2026-01-20 15:45:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0n06b4",
          "author": "jpcaparas",
          "text": "Yo Dax is a cool dude.",
          "score": 7,
          "created_utc": "2026-01-20 09:21:09",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qificf",
      "title": "The best CLI",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qificf/the_best_cli/",
      "author": "DreamDragonP7",
      "created_utc": "2026-01-20 22:19:24",
      "score": 52,
      "num_comments": 38,
      "upvote_ratio": 0.98,
      "text": "I am in awe. srsly fangirling. also super pissed I spent so long curating and creating custom plugins/skills/agents with claude code just to try out Opencode and spend substantially less tokens and get the same quality. \n\nNote: for anyone trying out the oh-my-opencode plugin? dont. token burner for no reason. This shit works right out of the box. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qificf/the_best_cli/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0r62v2",
          "author": "Apart-Permission-849",
          "text": "+1 on oh my open code burning tokens",
          "score": 21,
          "created_utc": "2026-01-20 22:51:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0trw0a",
          "author": "Familiar-Pomelo-8654",
          "text": "For me, the biggest improvement came from keeping my API specs clean. Apidog CLI alone cut a lot of token waste.\nÂ ",
          "score": 14,
          "created_utc": "2026-01-21 09:22:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11hlw8",
              "author": "tamanaga",
              "text": "Can you share a bit more, I'm interested to know how Apidog CLI can cut a lot of token waste. It is used for running api test scenarios, right?",
              "score": 1,
              "created_utc": "2026-01-22 13:15:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o125m67",
                  "author": "InternalFarmer2650",
                  "text": "I think it even creates the docs for your API? not 100% confident but i remember seeing them advertising that somewhere",
                  "score": 1,
                  "created_utc": "2026-01-22 15:19:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0r6bj8",
          "author": "gobitpide",
          "text": "Agreed on the OmO part. The Default Plan and Build cycle is the workflow I keep returning to.",
          "score": 7,
          "created_utc": "2026-01-20 22:53:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ssywz",
          "author": "SynapticStreamer",
          "text": "> This shit works right out of the box. \n\nAnd this is why Anthropic is pissed that people like OpenCode. Ultimately it's going to decrease token usage which is less $ for them.\n\nThere's not a single thing anyone can tell me to convince me that I'm wrong.",
          "score": 4,
          "created_utc": "2026-01-21 04:29:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0x3958",
              "author": "kkordikk",
              "text": "They do the work themselves to reduce the token usage - compacting, dynamically loaded skills, dynamic tool search and more!",
              "score": 1,
              "created_utc": "2026-01-21 20:15:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0rzuxp",
          "author": "atkr",
          "text": "oh my anything tools are all junk, ever since any of them existed",
          "score": 6,
          "created_utc": "2026-01-21 01:35:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tolbp",
              "author": "buggytheking",
              "text": "oh my zsh is decent",
              "score": 4,
              "created_utc": "2026-01-21 08:50:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0wwos5",
                  "author": "Silent-Tie-3683",
                  "text": "Isn't starship better?",
                  "score": 2,
                  "created_utc": "2026-01-21 19:46:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o12jx7r",
                  "author": "Real-Entertainer5379",
                  "text": "zsh4humans has been my default choice since 2021",
                  "score": 1,
                  "created_utc": "2026-01-22 16:25:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0wev82",
          "author": "alp82",
          "text": "Can you share your setup? Which rules, skills, commands? MCP, models?\n\nCurious to learn from you",
          "score": 2,
          "created_utc": "2026-01-21 18:26:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0xtnte",
              "author": "Fantastic_Grand1050",
              "text": "Up",
              "score": 1,
              "created_utc": "2026-01-21 22:16:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0rdf8c",
          "author": "devdnn",
          "text": "Does the opencode cli document the plan or spec for documentation purpose?\n\nI didnâ€™t see a way to extend the agent to make sure document the plan or specs",
          "score": 1,
          "created_utc": "2026-01-20 23:31:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rflyw",
              "author": "Hot_Dig8208",
              "text": "By default no. You need to ask the plan agent to do it. But you can use spec driven tool like [openspec](https://openspec.dev). The default workflow of openspec is to write the plan in a markdown file, so we can review it before the implementation.",
              "score": 3,
              "created_utc": "2026-01-20 23:43:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0shvqv",
          "author": "Rude-Needleworker-56",
          "text": "The same feeling I had until I tried pi",
          "score": 1,
          "created_utc": "2026-01-21 03:19:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0simm0",
              "author": "DreamDragonP7",
              "text": "Pi?",
              "score": 1,
              "created_utc": "2026-01-21 03:23:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0sll67",
                  "author": "Rude-Needleworker-56",
                  "text": "Pi coding agent. Simple and extremely hackable",
                  "score": 2,
                  "created_utc": "2026-01-21 03:41:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0sivz1",
          "author": "larowin",
          "text": "What model do you typically use?",
          "score": 1,
          "created_utc": "2026-01-21 03:25:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0sjkft",
              "author": "DreamDragonP7",
              "text": "Opus 4.5\n\nAll other models are vastly inferior. Except maybe gemini 3 pro for fast bug hunting.",
              "score": 1,
              "created_utc": "2026-01-21 03:29:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0wjy1n",
                  "author": "ganderofvenice",
                  "text": "You should try GPT-5.2-Codex-xHigh. Good to find errors made by Opus.",
                  "score": 1,
                  "created_utc": "2026-01-21 18:48:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0wyf1q",
                  "author": "Silent-Tie-3683",
                  "text": "I've recently seen this issue where gemini 3 pro goes on a loop, it outputs the same thinking multiple time!",
                  "score": 1,
                  "created_utc": "2026-01-21 19:53:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0x83nk",
                  "author": "alphaQ314",
                  "text": "Are you using it with Claude max plan ?",
                  "score": 1,
                  "created_utc": "2026-01-21 20:38:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0tg426",
          "author": "whimsicaljess",
          "text": "honestly same. i did a review of all the coding agents the other day and instantly switched to opencode after 1 session. it's so good!",
          "score": 1,
          "created_utc": "2026-01-21 07:30:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12hehs",
          "author": "SimpleG404",
          "text": "i use it with my chatgpt subscription and i donâ€™t worry about token spent with my flat monthly payer, am i just not using it enough?",
          "score": 1,
          "created_utc": "2026-01-22 16:13:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13dgqo",
          "author": "drinksbeerdaily",
          "text": "Any merit to Anthropic banning accounts that use opencode?",
          "score": 1,
          "created_utc": "2026-01-22 18:37:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13jgum",
              "author": "DreamDragonP7",
              "text": "Hasn't happened to me yet. But it could happen at anytime Im hearing?",
              "score": 1,
              "created_utc": "2026-01-22 19:03:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tqsfe",
          "author": "Cheap_Drawing4073",
          "text": "I disagree with your opinion about oMo. They are working on developing an excellent planning workflow. The 3.0 beta version is quite impressive. However, there are still some bugs that they are actively working on. I highly recommend giving it a try",
          "score": 1,
          "created_utc": "2026-01-21 09:11:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tzw6c",
              "author": "awfulalexey",
              "text": "I was shocked by the scale of Beta 3. I deleted it for now when it was at version 3.0.7, staying on the stable version for the time being. It seems to me that there is too much orchestration, and for something like that, you need the strongest models everywhere, like Opus, Sonnet, Gemini 3 Pro, Codex. If the models are smaller, they might not be able to handle such a scale of work. I really like oMo, but now I'm not sure; it seems too bulky. I'll say moreâ€”I have never worked in pure Opencode, maybe it's worth a try.",
              "score": 1,
              "created_utc": "2026-01-21 10:37:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0u0b4x",
                  "author": "Cheap_Drawing4073",
                  "text": "Beta 11 has a few issues. oMo automatically falls back to models it considers â€œperformant,â€ but you know, I set up the antigravity auth provider and configured all the agents and â€œcategoriesâ€ to flash 3. I only use that one for now, and I really like it. I donâ€™t lose anything, and itâ€™s almost free. Iâ€™ve been running it non-stop for 3 days so far. I added 5 google accounts, and it auto-switches between them. You just need to properly configure the oh-my-opencode.json file. I set flash 3 everywhere, hahaha.",
                  "score": 1,
                  "created_utc": "2026-01-21 10:41:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0r1iej",
          "author": "SuccessfulScene6174",
          "text": "You mean same quality but without any commands skills etc?",
          "score": 1,
          "created_utc": "2026-01-20 22:28:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rtill",
              "author": "DreamDragonP7",
              "text": "Yes",
              "score": 1,
              "created_utc": "2026-01-21 00:59:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qexzk7",
      "title": "I finally soft broke up with Claude Code â€” and migrated everything to OpenCode (with reuse)",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qexzk7/i_finally_soft_broke_up_with_claude_code_and/",
      "author": "Tushar_BitYantriki",
      "created_utc": "2026-01-17 00:42:33",
      "score": 51,
      "num_comments": 17,
      "upvote_ratio": 0.93,
      "text": "# I wrote most of this post with opencode, as a summary of my migration. And then edited it myself.\n\nIâ€™d been quietly annoyed at Claude Codeâ€™s arbitrary, opaque quota limits for a while. I kept tolerating not becuase I feel that I could not live without Opus or Sonnet (I feel most models have become pretty good these days, if you have slightest idea of what you are doing). But because Iâ€™d invested in custom commands, agents, and skills for months, and all of that just works for me in claude code.\n\nAnd the thought of rebuilding everything sounded painful. Then the â€œOpenCode max subscription banâ€ landed and that was my last straw.\n\nObviously, I had to disconnect opencode from claude sub, but it meant I had no reason left tpo keep paying them $200 (well, already reduced to $100 recently, and bought some other subscriptions with the difference)\n\nNo warning, no clarity, and were reports of accounts being banned for \"misuse\". People might justify it with \"they can do whatever they want with THEIR subscription\", but then \"customers are free to leave as well\". It felt like a toxic dependency: good when it worked, exhausting when it didnâ€™t. I decided to start cutting the cord for good. I spent a few hours learning how OpenCode organizes commands, agents, and skills and realized I could migrate without nuking my Claude setup. That became the mission: keep my Claude assets usable while making them firstâ€‘class in OpenCode.\n\n# The three pillars I had to understand\n\nOpenCode is structured around three things, and once I understood them the migration was mostly plumbing:\n\n* **Commands**: slash commands with frontmatter\n* **Agents**: explicit roles with prompts + tool permissions\n* **Skills**: reusable instruction bundles loaded on demand\n\n# Migration strategy (keep Claude intact, add OpenCode wrappers)\n\nI wanted zero rewrites in my Claude files. The simplest path was wrappers + symlinks so Claude stays the source of truth.\n\n# 1) Skills: symlink Claude â†’ OpenCode\n\nThis lets both tools use the same skills.\n\n    # Project\n    ln -s .claude/skills .opencode/skill\n    \n    # User\n    ln -s ~/.claude/skills ~/.config/opencode/skill\n\n# 2) Commands: wrap Claude commands with frontmatter\n\nOpenCode needs frontmatter, Claude doesnâ€™t. Wrappers let OpenCode read Claude commands without edits.\n\nExample wrapper:\n\n    ---\n    description: Enforce code discipline checklist\n    agent: build\n    ---\n    @.claude/commands/enforce-code-disciplines.md\n\nI did this for all project commands (including the `priming/` folder) and all userâ€‘level commands in `~/.claude/commands/`.\n\n# 3) Agents: wrap Claude prompts\n\nOpenCode agents can point to a prompt file, which makes them perfect wrappers for Claude agents.\n\n    ---\n    description: Senior code reviewer\n    mode: subagent\n    prompt: \"{file:~/.claude/agents/senior-code-reviewer.md}\"\n    ---\n\nI wrapped all my Claude agents as **subagents** to preserve behavior.\n\n# Verification checks (how I proved it worked)\n\nThese were the concrete checks that confirmed OpenCode was seeing everything:\n\n    opencode debug skill\n\n* Commands show up in the `/` palette\n* Agents show up in the `@` picker\n* Skills list correctly in `opencode debug skill`\n\nIf skills donâ€™t show up, I enabled them in `opencode.json`:\n\n    \"tools\": {\n      \"read\": true,\n      \"write\": true,\n      \"edit\": true,\n      \"bash\": true,\n      \"skill\": true\n    }\n\n# Bonus: I turned the playbook into a skill\n\nI didnâ€™t want to repeat this on every repo, so I started with asking opencode to write a migration skill that:\n\n* Scans Claude commands, agents, and skills\n* Creates OpenCode wrappers and symlinks\n* Verifies discovery\n\nNow migration is repeatable and documented instead of a oneâ€‘off bash ritual.\n\n# Tips\n\n* You can invoke skills by name in plain language. Unlike claude code, you don't have to keep asking it to \"invoke the skill properly\", and not just read a single SKILL.md file (leaving everything else). Open code invoked the skill, and read every file mentioned in it.\n* Skills can load fine even if the UI doesnâ€™t surface them. Use `opencode debug skill`.\n* Wrappers wonâ€™t load without frontmatter.\n\n# Final take\n\nIf Claude Codeâ€™s limits are starting to feel arbitrary, there is a clean exit ramp. You donâ€™t have to throw away your existing commands or skills. OpenCode can run them while Claude remains intact. Iâ€™m now fully migrated without losing anything, and it feels like getting my workflow back.\n\nI do plan to use Claude Code for planning at times, but now I have options.\n\nAnd honestly, I was only flirting with OpenCode for the last few months, but watching accounts being banned by Anthropic because customers didn't like their tooling, was a dic\\* move. And it made me realise that I just can't let myself be fully dependent on such a company.\n\nNow, if Anthropic suddenly decides to ban my account for some random reason, I can just walk away without being devastated.\n\nEven if Opus4.5, I have to spend time ensuring that the code is as per my preferences and standards. So for me, the loss would have been leaving behind the workflow that just worked for me. But now it seems that OpenCode is the best place for it to fit one-to-one.\n\nIf anyone wants the playbook or migration skill, here you go:\n\n[https://github.com/SmrutAI/opencode-migration](https://github.com/SmrutAI/opencode-migration)\n\nJust install it, and it migrates everything.\n\n  \nWill soon include a way to reuse Claude's settings.json and hooks, which are the last bit of attachment I have with Claude. (safety net)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qexzk7/i_finally_soft_broke_up_with_claude_code_and/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o01u5yc",
          "author": "altjx",
          "text": "Good stuff. I just did the same thing today with symlinks and some minor tweaks. Long time obsessed CC user here, but Opencode has made a lot of great progress over the last few months ago so I'm happy to be back.",
          "score": 4,
          "created_utc": "2026-01-17 04:16:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02l6dm",
          "author": "Awesomest_Maximus",
          "text": "Opencode already searches in .claude for skills. No need for linking. https://opencode.ai/docs/skills/#place-files",
          "score": 6,
          "created_utc": "2026-01-17 07:54:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02tssr",
              "author": "Tushar_BitYantriki",
              "text": "Yes, it does. I just created a common interface for all 3, as it deduplicates as well.\n\nHonestly, when I started, I was still trying to figure out skills in OpenCode.",
              "score": 2,
              "created_utc": "2026-01-17 09:15:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o041w38",
          "author": "miaowara",
          "text": "Quick tip: OC recognizes both singular & plural folder names (\"agent\" vs. \"agents\", \"command\" vs. \"commands\", \"skill\" vs. \"skills\") and will **load both** if present.  Furthermore, it seems to give priority to same-named items in the singular-named folders. This means you can keep same-named OC specific items in the singular-named folders (e.g. \"agent/cool-guy.md\") while keeping specific Claude-code ones in your symlinked folders (\"agents/cool-guy.md\"). This allows you to jump back to CC if need be relatively easily!",
          "score": 2,
          "created_utc": "2026-01-17 14:46:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o017s9o",
          "author": "raf_oh",
          "text": "Ty for this! I didnâ€™t realize you can link the Claude files after the front matter for Opencode, great tip",
          "score": 1,
          "created_utc": "2026-01-17 01:51:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02dn2l",
          "author": "DueKaleidoscope1884",
          "text": "thank you for sharing! I am also thinking about this. I am trying different agents regularly and having some reuse would be great. (symlinking is what I rely on mostly so far)\n\n  \nFor agents, how does Opencode handle the front matter of the Claude Code agents? (since the are now part of the prompt, right?) Ignores it?\n\n  \nDid you also consider the plug-ins?",
          "score": 1,
          "created_utc": "2026-01-17 06:46:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02uhaz",
              "author": "Tushar_BitYantriki",
              "text": ">For agents, how does Opencode handle the front matter of the Claude Code agents? (since the are now part of the prompt, right?) Ignores it?\n\nSeems to pretty much ignore it. Opencode gets a wrapper of its own, with frontmatter in its format.\n\n    ---\n    description: Claude-style code reviewer\n    mode: subagent\n    model: anthropic/claude-sonnet-4-20250514\n    prompt: \"{file:./.claude/agents/review.md}\"\n    tools:\n      write: false\n      edit: false\n    ---\n    You are in review mode. Provide feedback only.\n\nThe frontmatter of the internal (claude's) file is just seen as a prompt. Seems to be working fine. (not sure if it would confuse the LLM over time.",
              "score": 2,
              "created_utc": "2026-01-17 09:21:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o032644",
          "author": "Swimming_Internet402",
          "text": "Yeah. Everyone should leave Claude",
          "score": 1,
          "created_utc": "2026-01-17 10:34:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04ccik",
          "author": "Unusual_Ring_4720",
          "text": "Hello, I'm aiming to do the same, but I relied heavily on CC being able to navigate the browser through Claude Extension + being able to look at the screenshots and use that information. Does OpenCode handle this as well? Thank you",
          "score": 1,
          "created_utc": "2026-01-17 15:39:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04ekye",
              "author": "Tushar_BitYantriki",
              "text": "I have not tried MCPs on opencode, yet. Because I am mostly doing backend work for the last 2-3 months.\n\nBut when working on frontend, I have had great success with chrome dev tools and puppeteer MCP (when working on non-chrome browsers)\n\nOpenCode does support MCPs, so would be worth trying.\n\nLately, I had removed most MCPs from my CC set up, to save on tokens.",
              "score": 1,
              "created_utc": "2026-01-17 15:50:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o04gztx",
          "author": "trypnosis",
          "text": "Well done mate",
          "score": 1,
          "created_utc": "2026-01-17 16:01:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04pr62",
          "author": "Superb_Sea_559",
          "text": "Opencode is interesting but isn't the Max subscription much cheaper than API? Or did you get the subscription working with Opencode?",
          "score": 1,
          "created_utc": "2026-01-17 16:42:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05cpnp",
              "author": "Tushar_BitYantriki",
              "text": "I am not using max sub with Opencode anymore, after the Anthropic account blocking fiasco.\n\nI don't want to get banned, just yet. But moving my workflow off claude code, and using GPT and other models.",
              "score": 1,
              "created_utc": "2026-01-17 18:29:25",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0adoz1",
              "author": "chevdor",
              "text": "OC works with CC subscriptions but Anthropic does not like it and tries to prevent it.\n\nIf CC would be on par with OC, there would be little of an issue. Yet the problem for Anthropic is that OC is much better ! And as users switch to OC while using CC, Anthropic faces a big issue: let it be and sell their great models. Or fight the users to ensure they stick with the CC CLI.\n\nThe problem is that more and more people use OC and get really pissed if they could no longer use OC and CC. Most people will drop Anthropic if they stand in front of the choice to use CC or stick with OC and leave.\n\nThis choice is a no trainer. Sticking with CC, you get a few great models and a rather poor CLI. Sure Anthropic could work on their cli but they already showed their will for an exclusive strategy. \n\nUsing OC, you can use ONE workflow and config and access plenty of models without being bound to a single vendor: no vendor lock-in.\n\nModels are racing ATM and it is not possible to say that model XYZ is \"the best\". So users will HAVE to use multiple models from multiple vendors to remain competitive. This is precisely what OC allows and CC wants to prevent.\n\nAnthropic is at a turning point and needs to make a smart choice if they want to avoid losing all their customers...\nFor now, existing customers leave or live in fear. New customers are scared to even join the battle.\n\nThis is all but healthy and ok plays strongly against Anthropic.\nTry bringing that up in their sub, you get censored. Ask me how I know.\n\nI personally don't want to \"live in fear\" **SO** I will stick with OC. \nIf Anthropic allows, I will keep paying for their models. If not, it won't change much for me and I will just switch OC to use another model or set of models. In the meantime, I am limiting the use of Anthropic only feature but honestly there is not much...",
              "score": 1,
              "created_utc": "2026-01-18 13:37:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0aj54u",
          "author": "verkavo",
          "text": "This is great. Thanks for sharing",
          "score": 1,
          "created_utc": "2026-01-18 14:09:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jk6xz",
          "author": "TheCientista",
          "text": "Please if I have to read another quietly or opaque Iâ€™m going to smash my phone over my own head. Donâ€™t do it. Just stop",
          "score": 1,
          "created_utc": "2026-01-19 20:39:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jll6y",
              "author": "Tushar_BitYantriki",
              "text": "Sure, go ahead.\n\nBut do it quietly, and be opaque when someone asks you why you did it.",
              "score": 1,
              "created_utc": "2026-01-19 20:46:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfa59w",
      "title": "Love for Big Pickle",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qfa59w/love_for_big_pickle/",
      "author": "External_Ad1549",
      "created_utc": "2026-01-17 10:45:00",
      "score": 50,
      "num_comments": 37,
      "upvote_ratio": 0.96,
      "text": "disclaimer: I'm not a vibe coder. Iâ€™m a senior backend dev and I donâ€™t code on things I donâ€™t understand at least 70% clarity is mandatory for me.\n\nThat said, I love Big Pickle.\n\nThe response speed is insane, and more importantly, the quality doesn't degrade while being fast. I've been using it for the past hour for refactoring, debugging, and small script creation it just works. \"Great\" feels like an understatement.\n\nI don't care whether it's GLM-4.6, Opus, or something else. I only care about two things: high tokens/sec and solid output quality. Big Pickle nails both.\n\nWhoever operating this model at this speed I genuinely love you.\n\nMy only concern: it's currently free. That creates anxiety. I donâ€™t want the model to stop working in the middle of serious work.\n\nPlease introduce clear limits or a paid coding plan (ZAI-level or slightly above).  \nIf one plan expires, I'll switch accounts or plans and continue no issue.\n\nJust give us predictability",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qfa59w/love_for_big_pickle/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0384hx",
          "author": "Erebea01",
          "text": "I think they self host their free models and say they don't cost much to host or something so they decide to provide them for free. I might be wrong tho.",
          "score": 7,
          "created_utc": "2026-01-17 11:29:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04b0wc",
              "author": "verbose-airman",
              "text": "My guess was it is smaller models that wanna market their models so they give free access for a limited time.",
              "score": 2,
              "created_utc": "2026-01-17 15:32:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o04tmqc",
              "author": "smile132465798",
              "text": "https://x.com/thdxr/status/1980317899828129992?s=46\nFor reference",
              "score": 1,
              "created_utc": "2026-01-17 17:00:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o06y98c",
                  "author": "touristtam",
                  "text": "> so our costs are 12.5x cheaper than a general purpose one\n\nThat's mental. I wonder if there is a possibility to run a similar setup locally on a consumer laptop and still get decent performances.",
                  "score": 1,
                  "created_utc": "2026-01-17 23:14:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o04catn",
          "author": "Big-Masterpiece-9581",
          "text": "The free ones on opencode zen are with clear TOS. You get free. They get your data and feedback to improve. They will all eventually move to paid only.\n\nBig Pickle is more. Itâ€™s a stealth model. That means one of the big ai companies has a new model theyâ€™re testing pre-release. There is no paid version because itâ€™s not yet released. And we might never find out when itâ€™s released that it was previously called big pickle.\n\nYou have to take that into account if using free models.",
          "score": 6,
          "created_utc": "2026-01-17 15:39:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04cyt8",
              "author": "seaweeduk",
              "text": "Big pickle is not a stealth model, it's glm 4.6 with a funny name hosted with one of their providers. Dax has confirmed this multiple times already.\n\nhttps://twitter.com/thdxr/status/1984090146460020966",
              "score": 3,
              "created_utc": "2026-01-17 15:42:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o05n2jl",
                  "author": "pwarnock",
                  "text": "It may have been glm-4.6 at the time he said that, but nothing prevents it from being changed. \n\nKilo has a new stealth model from a Chinese Lab called Giga Potato. Similar naming; size + food. Could be coincidence. \n\nWhen it leaked that Mistralâ€™s model was stealth (spectre I think), they declined it and the following day announced it. \n\nSo take what you see on X with a grain of salt and assume that using Big Pickle for free means youâ€™re helping them train, debug, and scale to get it to a state that they are confident charging for.",
                  "score": 2,
                  "created_utc": "2026-01-17 19:17:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o04cser",
              "author": "External_Ad1549",
              "text": "yeah i read it but it is being stealth for a very long time",
              "score": 1,
              "created_utc": "2026-01-17 15:41:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0360z0",
          "author": "lundrog",
          "text": "Pretty sure its k2 thinking",
          "score": 9,
          "created_utc": "2026-01-17 11:10:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03k7z9",
              "author": "seaweeduk",
              "text": "dax has confirmed multiple times before, its just glm 4.6 with a funny name",
              "score": 9,
              "created_utc": "2026-01-17 13:04:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03zrb9",
                  "author": "KnifeFed",
                  "text": "So why use it over GLM 4.7? Is it faster?",
                  "score": 6,
                  "created_utc": "2026-01-17 14:34:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o04d6u3",
                  "author": "External_Ad1549",
                  "text": "i am kind of using glm models like from 4.5 it doesn't seem like 4.6 i might be wrong when context increased it kind of behaved on it's own k2 will do that or I might be wrong",
                  "score": 4,
                  "created_utc": "2026-01-17 15:43:26",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o04qgs2",
                  "author": "minaskar",
                  "text": "It certainly used to be GLM-4.6, but I'm pretty sure it's been replaced with K2 Thinking now. If you notice at the OpenCode Desktop app, Big Pickle allows you to change the reasoning effort, just like K2 Thinking. GLM-4.6/4.7 do not have this freedom.",
                  "score": 1,
                  "created_utc": "2026-01-17 16:46:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o036ulu",
              "author": "External_Ad1549",
              "text": "can be, I completely forgot that it existed",
              "score": 1,
              "created_utc": "2026-01-17 11:17:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o03h1at",
          "author": "websitegest",
          "text": "That anxiety about â€œthis is awesome AND free, so itâ€™s probably going to vanish midâ€‘projectâ€ is very real. Free tiers are nice for experimentation, but for serious backend work predictability > freebies.\n\nWhat worked for me was building around a paid coding plan with known limits as the backbone, and then treating fast/free models like Big Pickle as opportunistic accelerators. Opus (or similar) sets the architecture, GLM 4.7 and Big Pickle handles the implementation and refactor loops, and anything else fast just rides on top.\n\nIf youâ€™re looking for something closer to a predictable, paid plan rather than a gamble on a free endpoint, Zai has coding plans where you can still get 50% discount for first year + 30% discount (current offers + additional 10% coupon code) but I think it will expire soon (some offers are already gone!) > [https://z.ai/subscribe?ic=TLDEGES7AK](https://z.ai/subscribe?ic=TLDEGES7AK)",
          "score": 3,
          "created_utc": "2026-01-17 12:42:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03nx7g",
              "author": "External_Ad1549",
              "text": "thanks i have max plan zai it is my work horse, chatgpt for architectural decisions but sometimes zai goes very slow for a simple tasks glm 4.7 took 28 sec same big picke took 7.5 sec but when the depth increased big pickle kind of left me and wrote its own code despite having correct plan.md in place never happened with glm 4.7. I completely agree with u",
              "score": 3,
              "created_utc": "2026-01-17 13:28:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o048mrj",
                  "author": "ZeSprawl",
                  "text": "Try GLM 4.7 on Cerebras. You can try it out on the free tier. The speed is actually insane. Fastest response I've ever seen for a smart coding model. It's addictive and I hope they offer it on their coding plan whenever there's availability again.",
                  "score": 2,
                  "created_utc": "2026-01-17 15:21:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o04p5cc",
          "author": "psilokan",
          "text": "Interesting.  I've found big pickle to be very slow when using it. Also found it to be very buggy.  One time it just randomly switched to chinese and all the output was in chinese characters, no idea why lol.",
          "score": 2,
          "created_utc": "2026-01-17 16:40:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04s4uw",
              "author": "External_Ad1549",
              "text": "ðŸ˜‚ðŸ˜‚ switch to chinese happened in Antigravity as well\nwhen did you tested this?",
              "score": 1,
              "created_utc": "2026-01-17 16:53:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o04xb51",
                  "author": "psilokan",
                  "text": "This was right before Christmas.  The funny thing it still understood me and kept doing what I asked despite me having no clue what it was saying back lol",
                  "score": 2,
                  "created_utc": "2026-01-17 17:17:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o05wzoo",
          "author": "Easy_Zucchini_3529",
          "text": "Use GLM-4.7 with Fireworks or Cerebras.",
          "score": 2,
          "created_utc": "2026-01-17 20:05:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05xiov",
              "author": "External_Ad1549",
              "text": "crebras  is limited, trail version got some burst but it is always pushing 1 min break like limited tokens in 1 min. not available right now, coding plans are not available. fireworks ai is little costly need to check whether it has coding plans",
              "score": 1,
              "created_utc": "2026-01-17 20:08:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o05zbo4",
                  "author": "Easy_Zucchini_3529",
                  "text": "true, both are not the most cheapest solution, but the tokens per second are insane (specially Cerebras)",
                  "score": 2,
                  "created_utc": "2026-01-17 20:17:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0fb2vx",
          "author": "37chairs",
          "text": "Big pickle was a total joke at first. I used it again on a whim after hitting limits and was blown away. Is also possible I got better at talking to the things in the interim, but it went from trash to cash.",
          "score": 2,
          "created_utc": "2026-01-19 04:57:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjr325",
      "title": "I built a tool to use OpenCode from Mobile phone while away from my desk (With Voice input and Push Notifications).",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/gallery/1qjr325",
      "author": "LogPractical2639",
      "created_utc": "2026-01-22 10:28:45",
      "score": 49,
      "num_comments": 19,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qjr325/i_built_a_tool_to_use_opencode_from_mobile_phone/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o10x6o4",
          "author": "Tommertom2",
          "text": "Cool - so this goes via your server to connect the backend with the app, correct?",
          "score": 5,
          "created_utc": "2026-01-22 10:47:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10y26d",
              "author": "LogPractical2639",
              "text": "Yes, traffic from CLI to Mobile goes through a server in AWS. Communication is encrypted, so server can not read it.",
              "score": -1,
              "created_utc": "2026-01-22 10:55:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o12p12w",
                  "author": "Tommertom2",
                  "text": "Did you consider using your server only for setting up the connection and then handling the traffic peer to peer? Seems more efficient for your own server as well",
                  "score": 3,
                  "created_utc": "2026-01-22 16:47:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o112cmf",
          "author": "cloudsurfer48902",
          "text": "Does it support opencode sessions running with different server ports?",
          "score": 4,
          "created_utc": "2026-01-22 11:31:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1142s0",
              "author": "LogPractical2639",
              "text": "Termly works at the terminal level - it just streams what you see in your terminal to your phone. It doesn't care about OpenCode's internal servers or ports. If I got your question correctly",
              "score": 0,
              "created_utc": "2026-01-22 11:44:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o11ofjv",
          "author": "AaBJxjxO",
          "text": "How about Termux + SSH + tmux?",
          "score": 4,
          "created_utc": "2026-01-22 13:52:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11qk3t",
              "author": "LogPractical2639",
              "text": "Works, but SSH from outside your network needs port forwarding or VPN. Termly just works anywhere - scan QR and go. Plus Push notifications when AI needs your input.\n\nCLI: macOS, Windows, Linux - install via npm, runs on Node 18+\n\nMobile: native apps for iOS and Android with TUI support, touch gestures, voice input",
              "score": 3,
              "created_utc": "2026-01-22 14:03:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o12k5r3",
                  "author": "ResonantClari",
                  "text": "> SSH from outside your network needs port forwarding or VPN\n\nTailscale!!",
                  "score": 2,
                  "created_utc": "2026-01-22 16:26:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o11t3np",
                  "author": "AaBJxjxO",
                  "text": "VPN is assumed.  Voice can be done out of the box with voice input (eg from Gboard) into Termux.\n\nPush notifications are interesting though.",
                  "score": 3,
                  "created_utc": "2026-01-22 14:17:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1153yp",
          "author": "Glum-Atmosphere9248",
          "text": "But opencode already has web ui",
          "score": 3,
          "created_utc": "2026-01-22 11:52:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11yz4d",
              "author": "rothnic",
              "text": "I think the idea is it would work across any agent framework. \n\nI do think though that if you are at this level of need you'd probably build your own tool specific to your needs. This kind of tool is a pretty common thing to see launched every other day, which is kind of my biggest concern at the moment.\n\nThe moat you create by investing in software development is going to be more and more fragile. Since any service has features you don't need, you can build exactly what you want using coding agents much cheaper. I think the SAAS business as we know it is in big trouble.",
              "score": 3,
              "created_utc": "2026-01-22 14:47:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o116m7l",
              "author": "LogPractical2639",
              "text": "Yes. The question is why do you need this app? :) if you like to work on your computer, but you need to leave it sometime or often. You can not open your local session through web. And I'm still working on use cases",
              "score": 1,
              "created_utc": "2026-01-22 12:03:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o11t9e5",
          "author": "Extension-Pen-109",
          "text": "I run 8 opencode instance in diferent directories, this will work with all or just one of them?",
          "score": 2,
          "created_utc": "2026-01-22 14:17:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11u47i",
              "author": "LogPractical2639",
              "text": "Yes, you will see the list of all your connected session and you will be able to switch between them in application. I would love if you try this scenario and share your feedback.",
              "score": 2,
              "created_utc": "2026-01-22 14:22:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o13d2k8",
          "author": "blissofbeing",
          "text": "How is this different from [https://happy.engineering](https://happy.engineering) or [https://github.com/tiann/hapi](https://github.com/tiann/hapi) ?",
          "score": 2,
          "created_utc": "2026-01-22 18:35:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13iw4j",
              "author": "LogPractical2639",
              "text": "It works with Open Code",
              "score": 1,
              "created_utc": "2026-01-22 19:00:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o12nm84",
          "author": "robberviet",
          "text": "So like https://github.com/slopus/happy?",
          "score": 1,
          "created_utc": "2026-01-22 16:41:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13evc4",
          "author": "blissofbeing",
          "text": "Be very careful using this, it looks to be a vibe coded clone of [https://github.com/slopus/happy](https://github.com/slopus/happy) and all your data will travel through the devs relay server.",
          "score": 1,
          "created_utc": "2026-01-22 18:43:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14hsdo",
          "author": "drinksbeerdaily",
          "text": "I'd be interested if I could run it without involving any remote server out of my control. Most people who use opencode is very likely also using Wireguard, Tailscale or similar..",
          "score": 1,
          "created_utc": "2026-01-22 21:43:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfzaju",
      "title": "Built a multi-agent orchestrator plugin for OpenCode after struggling with GLM-4.7",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qfzaju/built_a_multiagent_orchestrator_plugin_for/",
      "author": "ChangeDirect4762",
      "created_utc": "2026-01-18 04:50:54",
      "score": 47,
      "num_comments": 19,
      "upvote_ratio": 0.94,
      "text": "https://preview.redd.it/78u9krhyf1eg1.png?width=3826&format=png&auto=webp&s=eaa14b014a85d34823c68ff354dc998de60d8883\n\nGLM-4.7 kept hitting walls on complex tasks â€” rate limits, context overflow, losing track halfway through. Got frustrated enough to build my own solution.\n\n0.9 version\n\nSo I made \\[opencode-orchestrator\\]([https://github.com/agnusdei1207/opencode-orchestrator](https://github.com/agnusdei1207/opencode-orchestrator)). It's a plugin for OpenCode that handles:\n\n\\- \\*\\*Parallel sessions\\*\\* â€” up to 50 isolated sessions running simultaneously\n\n\\- \\*\\*Agent distribution\\*\\* â€” Commander delegates to Planner, Workers, Reviewer\n\n\\- \\*\\*Background tasks\\*\\* â€” non-blocking, async execution\n\n\\- \\*\\*Auto-retry\\*\\* â€” handles crashes, rate limits, context issues automatically\n\n\\- \\*\\*Loop until done\\*\\* â€” keeps going until all TODOs are complete and verified\n\nThe idea is simple: instead of one agent trying to do everything, split the work across specialized agents that run in parallel and coordinate through shared state.\n\n  \nIf you try it out and run into anything, feel free to open an issue â€” or since it's open source, just fork it and tinker with it yourself. If you come up with something cool, I'd love to hear about it.\n\n\n\nI think in the AI era, we're all going to end up building our own tools anyway.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qfzaju/built_a_multiagent_orchestrator_plugin_for/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0c7ung",
          "author": "Visible_Jury_6547",
          "text": "why not just config Oh my opencode ? [https://github.com/code-yeongyu/oh-my-opencode](https://github.com/code-yeongyu/oh-my-opencode)",
          "score": 5,
          "created_utc": "2026-01-18 19:04:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0frqfi",
              "author": "splitbrainhack",
              "text": "unnecessary chaos",
              "score": 2,
              "created_utc": "2026-01-19 07:08:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0a709j",
          "author": "writing_rainbow",
          "text": "Are you able to assign specific models for each mode? Like chat 5.2 high for commander and planner and then glm for implementation and then codex 5.2 high for review?",
          "score": 4,
          "created_utc": "2026-01-18 12:52:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09gl6c",
          "author": "redoubledit",
          "text": "So frustrating. At one time, I had beautifully laid out plans with extensive todo list, broken up into execution phases. I was so ready, so it started. Finishing the first todo item, using the todo write tool to check off the item. But didnâ€™t read the list before so now, all todos are checked and verified and it stopped. Trying to iterate, it totally messed up from there. Forgetting parts of the plan, checking off items and deleting others in the same step. \n\nMight give your project a try. See if it can help.",
          "score": 2,
          "created_utc": "2026-01-18 08:59:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08vblp",
          "author": "lundrog",
          "text": "Interesting, ill check it out",
          "score": 1,
          "created_utc": "2026-01-18 05:52:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o097hp5",
              "author": "ChangeDirect4762",
              "text": "Thx. :)",
              "score": 1,
              "created_utc": "2026-01-18 07:36:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0avr5y",
          "author": "mintybadgerme",
          "text": "I'm getting a little confused with all these new agent systems coming online. What makes them different from one another? I've got open agents installed. How is that different from this one? I'm assuming that running them all together will destroy the platform completely.",
          "score": 1,
          "created_utc": "2026-01-18 15:17:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0c2z3g",
              "author": "Zexanima",
              "text": "Its a new problem domain that people are running into around the same time. Not everyone can/wants to keep up to date with everything new that drops, so they will roll their own solution. I think its great to have all these options in the beginning. People will evetually gravitate to the best solutions, they will start to homogenize features, and those will become the go-to.",
              "score": 6,
              "created_utc": "2026-01-18 18:41:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0c4l4r",
                  "author": "mintybadgerme",
                  "text": "But how on earth do you decide what's the best solution? Seems to me that there's no benchmarks,  no quality assurance, no testing. They're just released onto the market and us poor suckers have got to make a decision. Really hard.",
                  "score": 1,
                  "created_utc": "2026-01-18 18:49:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0e7d3x",
          "author": "Redoer_7",
          "text": "Which IDE is this",
          "score": 1,
          "created_utc": "2026-01-19 01:06:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0f64g2",
              "author": "Ruin_Mediocre",
              "text": "https://zed.dev/",
              "score": 1,
              "created_utc": "2026-01-19 04:24:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0fk8dc",
          "author": "NullzeroJP",
          "text": "Wow, crazy. How long did it take you to plan and build out something like this? And did it help fix some of the issues with GLM 4.7? Having similar issues myself with GLM 4.7 and ClaudeCode. But I'm new to vibe coding, so I thought maybe it was just a \"me\" problem.",
          "score": 1,
          "created_utc": "2026-01-19 06:06:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mbifl",
          "author": "pkief",
          "text": "Maybe it's also worth checking this project: https://www.swarmtools.ai/\n\nIt does quite the same and is already a little popular. It's an open code plugin optimized for multiple agent orchestration.",
          "score": 1,
          "created_utc": "2026-01-20 05:45:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf1ydz",
      "title": "Opus 4.5 Model Alternative",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qf1ydz/opus_45_model_alternative/",
      "author": "gradedkittyfood",
      "created_utc": "2026-01-17 03:18:35",
      "score": 41,
      "num_comments": 26,
      "upvote_ratio": 0.94,
      "text": "Hey all,\n\nBeen loving opencode more than claude. But no model I have used seems to come close to opus for programming tasks.\n\nTried GLM 4.7, and it's pretty decent, and impressive, but still struggles with bigger tasks. Mini Max M2.1 is fast as hell, but lands near GLM 4.7 in terms of quality.\n\nI've heard decent things about codex-5.2-high, but I'm curious on in terms of output quality and usage. Any other models I should be aware of to scratch that Opus itch but in Opencode?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qf1ydz/opus_45_model_alternative/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o01muin",
          "author": "real_serviceloom",
          "text": "None of the models are as good as opus 4.5. Gpt 5.2 is a bit better but much slower.Â \n\n\nMinimax m2.1 is the best bet among the free ones. Glm is also super slow for me for some reason on open code.Â ",
          "score": 20,
          "created_utc": "2026-01-17 03:27:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o029l0i",
              "author": "Charming_Support726",
              "text": "Dont confuse gpt-5.2 with gpt-5.2-codex. Codex is much faster, but lacks some analytic skills - especially in discussion. \n\nIn my experience the Gpts are very thorough and Opus wont match these. Opus get things done but lacking some perfection, while Codex tent to be overprecise, which is a real hard impediment when you are just creating a proof of concept.",
              "score": 4,
              "created_utc": "2026-01-17 06:12:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o029sdv",
                  "author": "real_serviceloom",
                  "text": "Yup I use gpt 5.2 medium for most planning and architecture and 5.2 codex medium for sniping. And high xhigh for reviews and gnarly bugs. I also have a Claude Max plan because sometime i just need speed lol.Â ",
                  "score": 1,
                  "created_utc": "2026-01-17 06:13:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o09hk70",
              "author": "websitegest",
              "text": "I can confirm that M 2.1 is really powerful, but in my opinion it's terrible when it comes to documentation! As for speed, I found GLM was slower with the Lite plan: I upgraded to the *Pro plan* and now it's quite fast, only experiencing a slight slowdown during peak hours. For others coding tests I ran identical prompts through Opus 4.5 (via *Claude Pro* plan), GLM 4.7, and Minimax. Results: Opus best at first-pass architecture, GLM best at iterative implementation (fewer context losses), Minimax faster but not cheaper as GLM. For anyone considering the GLM plans right now there is also a **50% discount** for first year **+ 30% discount** (current offers + my additional 10% coupon code) but I think it will expire soon (some offers are already gone!) >Â [https://z.ai/subscribe?ic=TLDEGES7AK](https://z.ai/subscribe?ic=TLDEGES7AK)",
              "score": 1,
              "created_utc": "2026-01-18 09:08:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0vbdx6",
              "author": "DistinctWay9169",
              "text": "MIniMax is fast but stupid. The best open weight model currently is GLM 4.7. I am using the max plan and it is fast and reliable 24/7. I am using Claude code though. Opencode is not as good to use GLM IMO.",
              "score": 1,
              "created_utc": "2026-01-21 15:30:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o01lygx",
          "author": "minaskar",
          "text": "For me it was Kimi K2 Thinking that took that role.",
          "score": 7,
          "created_utc": "2026-01-17 03:21:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o022ln9",
              "author": "NiceDescription804",
              "text": "Is it good at planning? I'm really happy with how glm 4.7 follows instructions but the planning is terrible. \nSo how was your experience when it comes to planning?",
              "score": 2,
              "created_utc": "2026-01-17 05:16:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03m2mo",
                  "author": "annakhouri2150",
                  "text": "Yeah, I would say that K2T is probably the best open source model I've used at planning and analyzing things and general sort of analytic skill. Whereas GLM 4.7 is better at figuring problems out debugging, strictly coding and instruction following. So that's how I would split it up.",
                  "score": 4,
                  "created_utc": "2026-01-17 13:16:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o04pjf4",
                  "author": "minaskar",
                  "text": "Yeah, that was my experience too. GLM-4.7 (and to a slightly lesser degree M2.1) is great at following instructions, but it really struggles to plan anything with even a moderate level of complexity. K2 Thinking (and DS3.2 for math/algorithm-heavy cases) if far superior in my opinion.",
                  "score": 0,
                  "created_utc": "2026-01-17 16:41:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o02jkd3",
          "author": "toadi",
          "text": "All tasks can be broken in smaller tasks. To be honest since a few months I don't see that much problem in software delivery by most models.\n\nI use opus only to provide me a larger spec. After that break it down with sonnet in small incremental task and haiku delivers the actual code. Can do the same using GLM and grok-fast for example. \n\nIt is about being precise and detailed providing input. This way it narrows down the probabilistic band making it land close to the goal you aim for.",
          "score": 2,
          "created_utc": "2026-01-17 07:39:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02k3ei",
          "author": "Michaeli_Starky",
          "text": "Even the slowest models are faster than the fastest programmer. Not sure why the speed of generation is a concern. BTW, you need to read and understand the code, so take your time.",
          "score": 2,
          "created_utc": "2026-01-17 07:44:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0g1ypu",
          "author": "No_Click_6656",
          "text": "Just use Opus 4.5 with Copilot as provider lol",
          "score": 1,
          "created_utc": "2026-01-19 08:40:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qino8",
          "author": "flexrc",
          "text": "Nothing beats opus 4.5 that is their competitive advantage. You can look at getting Google ai pro to get a better deal.",
          "score": 1,
          "created_utc": "2026-01-20 20:59:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0yt7c2",
          "author": "TradeViewr",
          "text": "Just get a Github Copilot or Antigravity sub and use them in opencode.",
          "score": 1,
          "created_utc": "2026-01-22 01:26:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02s4qf",
          "author": "kkordikk",
          "text": "Just break down bigger task into smaller ones. Isnâ€™t GLM the fastest at 1000tps?",
          "score": 1,
          "created_utc": "2026-01-17 08:59:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05x83o",
          "author": "SynapticStreamer",
          "text": "> but still struggles with bigger tasks.\n\nGiving any LLMs large tasks, and they'll struggle. Create an implementation.md file (I call mine CHANGES.md) and have the LLM map out planned changes in phases and write the implementation plan to the file. Then, instead of saying \"do this thing\" say \"implement the changes in CHANGES.md. Stop between each phase for housekeeping (git, context, etc), and then touch base with me before proceeding.\"\n\nWorks for most things. With very complex changes, no matter what you do, the model will hallucinate. I haven't been able to get it to a point, even with sufficient context, to not.",
          "score": 1,
          "created_utc": "2026-01-17 20:07:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02e1ng",
          "author": "lostinmahalway",
          "text": "Have you tried Deepseek Chat? I used Opus/Deepseek Chat for planning, creating tasks and orchestrating, while Minimax to actually implement the tasks. Sometimes during the day, the Opus is even worse compared to Deepseek.",
          "score": 0,
          "created_utc": "2026-01-17 06:50:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qigg6v",
      "title": "Vercel just launched skills.sh, and it already has 20K installs",
      "subreddit": "opencodeCLI",
      "url": "https://jpcaparas.medium.com/vercel-just-launched-skills-sh-and-it-already-has-20k-installs-c07e6da7e29e?sk=98a3faa46bb67d1e492d6a8361f36dd1",
      "author": "jpcaparas",
      "created_utc": "2026-01-20 22:55:40",
      "score": 41,
      "num_comments": 5,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qigg6v/vercel_just_launched_skillssh_and_it_already_has/",
      "domain": "jpcaparas.medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0re79u",
          "author": "Nexmean",
          "text": "I decided to open source my own billion dollars skills tool, there it is:\n\n```bash\nwhile getopts \"a:\" o; do\n  case \"$o\" in\n    a) AGENT=\"$OPTARG\" ;;\n  esac\ndone\nshift $((OPTIND - 1))\n\nREPO=\"$1\"\n: \"${AGENT:?}\" \"${REPO:?}\"\n\ngit clone --depth=1 \"https://github.com/$REPO.git\" \"/tmp/$REPO\"\n\nmkdir -p \"$PWD/.$AGENT/skills\"\n\nfind \"/tmp/$REPO\" -name SKILL.md -type f | while read -r f; do\n  d=\"$(dirname \"$f\")\"\n  cp -R \"$d\" \"$PWD/.$AGENT/skills/$(basename \"$d\")\"\ndone\n```",
          "score": 14,
          "created_utc": "2026-01-20 23:35:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0sjtqg",
              "author": "Enesce",
              "text": "I'm gonna wrap your tool and make a TWO billion dollar skills tool",
              "score": 4,
              "created_utc": "2026-01-21 03:30:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0tyapp",
              "author": "rmaxdev",
              "text": "Vercel is on drugs releasing ideas that EVERYONE has \n\nThey just piggyback on their reputation, but they are not doing anything exceptional and likely will become irrelevant soon",
              "score": 2,
              "created_utc": "2026-01-21 10:22:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0tk516",
              "author": "Coded_Kaa",
              "text": "What is this ðŸ˜‚",
              "score": 1,
              "created_utc": "2026-01-21 08:07:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tykpy",
          "author": "rmaxdev",
          "text": "You donâ€™t needs to install skills, your agent can write their own skills for your specific problem \n\nThe agentic space is become very BLOATED because code is cheap \n\nIt takes me longer to understand how to reuse what others have done than to ask implement the same for my specific needs",
          "score": 7,
          "created_utc": "2026-01-21 10:25:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qj2qjc",
      "title": "I experimented with an open source Figma-style spatial canvas to run Coding Agents in parallel. Implementing Opencode rn. What do you think?",
      "subreddit": "opencodeCLI",
      "url": "https://v.redd.it/gbr9sv2hcqeg1",
      "author": "DistanceOpen7845",
      "created_utc": "2026-01-21 16:35:06",
      "score": 34,
      "num_comments": 13,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qj2qjc/i_experimented_with_an_open_source_figmastyle/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0xbmwa",
          "author": "typescape_",
          "text": "The spatial component is underrated. Most agent orchestration tools treat parallel workflows as a list, but the Figma-style canvas lets you visually group related agents and see the branching structure. That's genuinely useful when you're running 5-10 agents and need to remember what each one is doing.The reactflow + embedded terminals approach is clever. I've been using Claude Code and OpenCode heavily, and the biggest friction is context-switching between sessions. Having them all visible on a canvas with decision nodes surfaced would save real time.The JSONL file structure that Claude Code uses is surprisingly hackable. You're right that the clean separation between tool calls and messages makes it easy to build secondary interfaces. The session awareness via tagged IDs is a nice touch for handling highlighted text [context.One](http://context.One) thing i'd want: persistent state between canvas sessions. When you close and reopen, do the agent sessions restore with their full history, or do you need to restart from scratch? The worst part of the current IDE experience is losing context when you close a tab.Curious what the memory footprint looks like running multiple terminal instances. Electron apps can get heavy.",
          "score": 3,
          "created_utc": "2026-01-21 20:53:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0y8ku2",
              "author": "DistanceOpen7845",
              "text": "awesome to hear, and super happy if you try it :)\n\nThey get restored and are stored from session to session so the consistency is there. It is all having the JSONls as a backbone so that sticks around.\n\nWith memory it never got too bloated for me and I was running some 5-6 branches together, but fair to observe.\n\nlet me know if you checked it out",
              "score": 1,
              "created_utc": "2026-01-21 23:33:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0x3b7c",
          "author": "gottapointreally",
          "text": "Very interesting concept. Will try",
          "score": 1,
          "created_utc": "2026-01-21 20:16:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0x5ndp",
              "author": "DistanceOpen7845",
              "text": "awesome, let me know what you think :)",
              "score": 2,
              "created_utc": "2026-01-21 20:26:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0y7xle",
          "author": "0b_1000101",
          "text": "I had the exact same idea. I just don't have that much frontend experience. Looks good!",
          "score": 1,
          "created_utc": "2026-01-21 23:29:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0y8vwo",
              "author": "DistanceOpen7845",
              "text": "haha, thanks! then I'd be super happy if you contribute to the backend :) be my guest u/0b_1000101",
              "score": 1,
              "created_utc": "2026-01-21 23:34:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o102mzg",
          "author": "Cultural-Match1529",
          "text": "Looks awesome will give it a shot.",
          "score": 1,
          "created_utc": "2026-01-22 06:12:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o102p77",
              "author": "Cultural-Match1529",
              "text": "can't give it a shot windows :(",
              "score": 1,
              "created_utc": "2026-01-22 06:13:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o10kt1o",
                  "author": "DistanceOpen7845",
                  "text": "oh no, sorry about that :( thought about working on windows later",
                  "score": 1,
                  "created_utc": "2026-01-22 08:53:07",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o109kjd",
          "author": "PassengerLatter8",
          "text": "This looks indeed pretty cool, unfortunately a windows / wsl user. But I like the idea",
          "score": 1,
          "created_utc": "2026-01-22 07:10:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10kuw5",
              "author": "DistanceOpen7845",
              "text": "thanks! Happy about anyone who wants to support with the windows version :)",
              "score": 1,
              "created_utc": "2026-01-22 08:53:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1146ci",
          "author": "Wrong_Daikon3202",
          "text": "It looks really good.\n\nIt would be nice if you pre-compiled it for Linux.",
          "score": 1,
          "created_utc": "2026-01-22 11:45:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11z32o",
              "author": "DistanceOpen7845",
              "text": "awesome, yeah we focused mostly on macOS but more might come soon",
              "score": 1,
              "created_utc": "2026-01-22 14:47:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfsg1t",
      "title": "Switch to OpenCode for Money Efficiency",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qfsg1t/switch_to_opencode_for_money_efficiency/",
      "author": "Demon-Martin",
      "created_utc": "2026-01-17 23:34:26",
      "score": 33,
      "num_comments": 51,
      "upvote_ratio": 0.95,
      "text": "Heyo devs,\n\nBeen thinking on switching to OpenCode from Cursor to save some money.\n\nCurrently I run 2 cursor ultra accounts and I am still burning though limits too quickly. Canâ€˜t afford to keep those costs tho, so I been planning on switching to OpenCode with a few chatgpt/google (maybe glm) accounts. Iâ€˜m pretty Sure those would end up being was cheaper for more tokens. My biggest costs is Claude Opus 4.5.\n\nThe problem is: I love cursorâ€˜s IDE and I really got used to it. I donâ€˜t really like CLIs (didnâ€™t like claude code too).\n\nAnd sadly I read that Anthropic is now actively attacking external usage of their subs.\n\nI want to test OpenCode (or something similar). OpenChamber is what I found, but thats more like an Chatbox than an Editor if I understood correctly.\n\nI also tried Googleâ€˜s AntiGravity but itâ€˜s straight up not the level that Cursor is. And I also read last days that they also started making rate limits worse.\n\nWhat would you do in my situation? Is there a good OpenCode Extension? How good is OpenCode actually?\n\nThanks.\n\nEDIT:\n\nI forgot to mention, I currently usually work like this:\n\nI first let a cheaper model do some research in the project based on a task. Then use Opus to create a plan and iterate till it creates a plan that follows what I want. Then I execute this plan with either composer, if I want it fast, or Gemini Flash 3, if I want it cheap (there is no other cheap model on cursor thatâ€˜s also good, flash is the 2nd cheapest next to GPT 5 nano on cursor, afaik). If Gemini fails, I also let it run though Gemini 3 Pro, Claude Sonnet and Opus itself, depending on the situation and project.\n\nEDIT 2 (18.01.2026):\n\nI tried OpenCode, added my ChatGPT Sub, Google Sub and GitHub Copilot Sub (got most of it for free because I am a student). It generally worked good, but I still donâ€˜t really like working in the CLI. It just doesnâ€˜t give me the User Experience and viewing that an Editor like Cursor gives me. I also tried OpenCode Desktop and thatâ€˜s also not optimal.\n\nEven tho my credit usage might suggest otherwise: I am not a â€žpure vibe coderâ€œ. I actively manually check all edits, fix stuff manually and code manually. I donâ€˜t let AI do everything by itself.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qfsg1t/switch_to_opencode_for_money_efficiency/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o07ig6h",
          "author": "Putrid-Pair-6194",
          "text": "I was exactly the same situation with cursor. So recently, I switched to a combination of opencode plus Antigravity. For me, the differences in antigravity from cursor for me were very small. \n\nSo now my set up is focused on opencode with the antigravity authentication extension. That gives me access to all of the opus and sonnet usage you get with antigravity. The Opus and sonnet usage you get with a single user is very limited. But, you can significantly increase that by buying a $20 a month family plan to the Google AI Pro subscription. That subscription allows you to sign up five â€œfamily membersâ€.  Every family member gets its own unique quota for antigravity Claude models. So if you set this up for $20 a month you get a fairly substantial amount of daily Claude usage. \n\nI also purchased a three dollar a month GLM 4.7 subscription for day-to-day tasks. Together the Google AI pro subscription with the â€œfive family membersâ€ and the GLM 4.7  subscription give a very significant amount of usage for low cost. Thatâ€™s probably enough for most people, but I also have a ChatGPT $20 a month subscription that also hooks into opencode. ChatGPT 5.2 may be slow, but I found it to be very reliable. I have plenty of horsepower for 4 to 5 hour coding sessions.\n\nThis is certainly much more complex than just paying for cursor. But my cursor bills were often exceeding $120 a month. Right now this costs me closer to $40-$50 a month and I donâ€™t feel like Iâ€™m losing much. The extra complexity may not be right for everyone, but it works pretty well for me.",
          "score": 14,
          "created_utc": "2026-01-18 01:01:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o085r0r",
              "author": "Delicious_Ease2595",
              "text": "How do you use my multiple family accounts with OpenCode? I'm using the same setup between Antigravity and OpenCode",
              "score": 3,
              "created_utc": "2026-01-18 03:06:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o08rn9n",
                  "author": "Putrid-Pair-6194",
                  "text": "I donâ€™t remember the details off-hand, but I think instructions were on the antigravity opencode authentication repo. Iâ€™m assuming you have setup 5 gmail accounts and added them to your family. Then if memory serves, you use the instructions for the antigravity authentication extension to log into each one. And the extension rotates across all of them automatically.",
                  "score": 1,
                  "created_utc": "2026-01-18 05:24:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o099lgn",
              "author": "pl201",
              "text": "Donâ€™t think Google AI pro family share each gets separate quota for $20. Itâ€™s one pool shared with up to 5 people. Donâ€™t believe it is very useful if more than one person try to use Antigravity.",
              "score": -1,
              "created_utc": "2026-01-18 07:55:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0cln4p",
                  "author": "Putrid-Pair-6194",
                  "text": "I donâ€™t know what are you basing that view on. Here is information from Google that aligns with my personal experience. Other forums seem to concur.\n   \n\n1. Individual Quotas for Family Members\nAccording to Google One Help and official developer forum clarifications from January 2026.\n  \n\nâ€¢ Independent Limits: Each member of a Google Family group (up to 5 additional members) receives their own full set of daily and recurring rate limits.Â  \nâ€¢ Not a Shared Pool: Unlike storage (which is shared from a common pool), AI quotas for features like Antigravity are per-user. One personâ€™s heavy usage does not deplete the quota for another family member.",
                  "score": 1,
                  "created_utc": "2026-01-18 20:10:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07qoil",
          "author": "Coldshalamov",
          "text": "[z.ai](http://z.ai) subscription (https://z.ai/subscribe?ic=QDKACAZ1KX and 3x  the usage of claude pro) $2.50 a month\n\nGithub copilot with unlimited chatgpt 4o, 4.1, 5 mini, and grok code fast: $10/m\n\nOpencode Zen: Big Pickle, GLM 4.7, Minimax 2.1, and grok code fast 1 for free\n\nMinimax subscription: $2/m\n\nMoonshot Kimi k2 thinking subscription: $3/m\n\nAll told in opencode: $14.50/m and will never ever hit my limits. I have an extensive subagent driven /build command I loop 3 times that takes 12 hours each, and a /prune command I run once or twice to trim the fat once its done, and then 90% of my projects are functional and need a few tuneups.",
          "score": 10,
          "created_utc": "2026-01-18 01:44:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08mm7s",
              "author": "GullibleDragonfly131",
              "text": "Can you share your Git repo? I'm interested to see how those LLMs compare to Opus.",
              "score": 2,
              "created_utc": "2026-01-18 04:49:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o09r38q",
              "author": "Rygel_XV",
              "text": "How did you get the Minimax and Kimi subscription so cheap? I can find both for $10 respective $9 per month.",
              "score": 1,
              "created_utc": "2026-01-18 10:37:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09rhh8",
                  "author": "Coldshalamov",
                  "text": "strangely, you have to argue with kimi for the price, there's like a promotional event but it actually seems like its response is largely uncalibrated from the price it gives, you just have to keep prompting it until it gives you the right price, I've done it multiple months in a row on the same account. It does look to me now that I checked that the $2 starter plan promo that they had has ended, I know [z.ai](http://z.ai) has theirs until the 30th so i plan on inviting myself and getting another $25 year of lite just because, who knows what i could automate with an extra key.",
                  "score": 1,
                  "created_utc": "2026-01-18 10:40:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0a1f2b",
              "author": "ekalaivan",
              "text": "How to get z ai sub so cheap? In fact except for GitHub i don't see how you get those services for that cheap!",
              "score": 1,
              "created_utc": "2026-01-18 12:08:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0a485s",
                  "author": "Rygel_XV",
                  "text": "They have a reduced price offer running until 31.01. And if you pay quarterly or yearly you get a big discount as well. On top of that they have referral codes for another 10%.\n\nFor example here is my referral :)\nhttps://z.ai/subscribe?ic=JQTB1W1M0L\n\nI think their idea is to lock in people now. If you prepaid for a whole year, will you switch to a different company with a better model if it would arrive?\n\nI myself chose to get the quarterly plan. To play it safe.",
                  "score": 2,
                  "created_utc": "2026-01-18 12:30:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07rrix",
          "author": "FlyingDogCatcher",
          "text": "What are you people doing that you burn through two premium accounts and still can't afford them?",
          "score": 6,
          "created_utc": "2026-01-18 01:49:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09bufv",
              "author": "P1zz4-T0nn0",
              "text": "I've got the same question. I'm a self-employed senior-developer coding all day and I don't hit the limits on a single Max 5x lol. Maybe that are people who don't actually know programming and try 10 workstrees at once, idk.",
              "score": 2,
              "created_utc": "2026-01-18 08:15:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09iegy",
                  "author": "Demon-Martin",
                  "text": "No I donâ€™t run 10 work trees, and I am a Full-Stack Developer. Opus is just way too expensive. If I understood correctly, Claude Subs canâ€˜t even be compared with Cursors costs. The subâ€˜s efficiency is way higher than cursors prices.",
                  "score": 1,
                  "created_utc": "2026-01-18 09:16:15",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o09n3uc",
                  "author": "UMANTHEGOD",
                  "text": "Power users (doing ralph loops etc) can burn through tokens pretty quickly but it depends on what you're using it for. I'm currently building a personal budget app, a personal fitness app and a refactoring app for work so I'm getting limited constantly.\n\nAll vibe coded of course because the quality of the code doesn't really matter for these apps.\n\nI've also used opus for everything and I could probably be more mindful to swap to sonnet at times.",
                  "score": 0,
                  "created_utc": "2026-01-18 10:00:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o09i6ns",
              "author": "Demon-Martin",
              "text": "My current project is a rather big turborepo with multiple packages and projects (apps) and most tasks require a big context for the produced code to be good and properly use the available packages. I am already running different methods to minimize the context usage, but still some opus requests cost like 1-3$, and when you code for like 8 hours straight a day, that adds up after time.\n\nObv running a simpler project with less context would be way cheaper.",
              "score": 1,
              "created_utc": "2026-01-18 09:14:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0730p6",
          "author": "No-Concentrate-6037",
          "text": "I would try to learn to use the CLI if I want Opus that badly",
          "score": 3,
          "created_utc": "2026-01-17 23:39:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o076fwr",
              "author": "Demon-Martin",
              "text": "I assume you are talking about Claude Code / an Anthropic Sub with OpenCode\n\nProblem is: I read a TON of negative information about Anthropic the past weeks.\n\nClaude Code is consuming an enormous big amount of tokens compared to before. They are making the ratelimits way way more harsh. And I personally donâ€˜t really like when I want to work, but canâ€˜t because the provider decided to make the model 10x dumber and make the token limit to be 1 prompt per session.\n\nAlso, read that opencode and anthropic ainâ€˜t best friends atm.\n\nhttps://www.reddit.com/r/ClaudeAI/comments/1qa50sq/anthropic_banning_thirdparty_harnesses_while/\nhttps://news.ycombinator.com/item?id=46625918\n\nInfo I was talking about with ratelimits:\nhttps://www.theregister.com/2026/01/05/claude_devs_usage_limits/\nhttps://github.com/anthropics/claude-code/issues/16157#issuecomment-3712177862\nhttps://news.ycombinator.com/item?id=46514221\n\nTheir discord also has an open thread about it with people complaining daily, but the main is probably: https://github.com/anthropics/claude-code/issues/16157",
              "score": 3,
              "created_utc": "2026-01-17 23:57:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o07kjy2",
                  "author": "Historical-Lie9697",
                  "text": "Github copilot is actually not bad for $10/month for supplementing Claude use, has unlimited use of gpt5 mini for easy stuff and 300 premium requests/month that includes a lot of models and they all work in OpenCode. I think for a budget that + Codex $20/m to use them all in OpenCode is a good option. Then if you want multimedia generation and the big context window you could add gemini",
                  "score": 3,
                  "created_utc": "2026-01-18 01:12:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o07bcr3",
                  "author": "No-Concentrate-6037",
                  "text": "No, I mean using Claude Code itself. And yes. I know about all above discussion, but hard to beat Opus as of now",
                  "score": 2,
                  "created_utc": "2026-01-18 00:23:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o08rnhh",
          "author": "NearbyBig3383",
          "text": "People use chutes.ai, it's only 20 bucks man, it's cheap and it never runs out.",
          "score": 3,
          "created_utc": "2026-01-18 05:24:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o092rn0",
              "author": "MorningFew1574",
              "text": "How does chutes compare to nanogpt?",
              "score": 1,
              "created_utc": "2026-01-18 06:54:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0fy6zf",
                  "author": "Complex-Maybe3123",
                  "text": "NanoGPT user here. I`m currently using their Subscription. Never used chutes. \n\nI believe NanoGPT uses some cheaper providers to keep their prices competitive, so I end up getting some very big token speed variation. I use mostly GLM 4.7 Thinking nowadays. Hardly for coding, but in the end, there`s not a lot of difference. Sometimes my requests start processing instantly, others times, it seems like I enter a queue. I time the whole request time (from the moment I press enter, to the moment I receive the whole response, I don`t usually use streaming), so I`m not sure of the actual TPS. But if I`d calculate the tokens per second with the whole request time, sometimes I get 100t/s, some rarer cases it`s very close to 10t/s. Usually it`s more in the middle. But I believe this variation is the delay until my request starts getting processed instead of actual TPS variation. These calcs I mentioned were usually done with around 20k~30k input context and 1k~3k output.\n\nI tried the big boys (GPT and Claude) a few times and they seem to respond the same as from the source.\nAll in all, I`m not a vibe coder, I prefer to use mostly tab-autocomplete, which is outside of what NanoGPT offers. So I don`t really mind the speed variation. At this point in time, I wouldn`t leave NanoGPT for any other provider. New released models become available almost immediately. The devs are also always listening to the users and suggestions are quickly implemented (when they make sense).\n\nSo for open source models, I`m of the opinion that it`s the best, in terms of price, available models and support. When it comes to premium models, there doesn`t seem to be much difference from other providers besides some discounts.",
                  "score": 2,
                  "created_utc": "2026-01-19 08:05:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o09zvdi",
          "author": "kkordikk",
          "text": "Actually switch your approach. Let the more expensive models do the research and plan the work out with granular tasks. Then smaller models to implement small tasks. GLM is great, cheap, fast, limits reset each 5hrs, itâ€™s great reasoning, multimodal. I highly recommend getting quarterly plan right now, thereâ€™s a promo still going. Also free Gemini API key and if you like opus, just use it sparingly via Anthropic 100$ sub. Also, you can still use free cursor as an ide",
          "score": 2,
          "created_utc": "2026-01-18 11:55:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a2e35",
              "author": "Demon-Martin",
              "text": "I would be using other subs, but cursor itself sadly doesnâ€™t really support it inside their built-in interface. I donâ€˜t really like CLIs/Terminals so OpenCode/Claude Code isnâ€˜t optimal for me.\n\nI was planning on getting GLM or Minimax or similar, just cursor is very annoying with only supporting â€žone base url overwriteâ€œ that breaks all other modelsâ€¦",
              "score": 1,
              "created_utc": "2026-01-18 12:16:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0a6rb6",
                  "author": "jorgejhms",
                  "text": "Maybe you could try Zed then. Is a code editor written in Rust (it's not a fork of vscode) and one of their key principles is to be open. They allow you to use it's AI features with their own subscription or with any API key. I have it set with GLM currently, with also copilot free and Gemini API keys. They also developed the Agent Client Protocol (ACP) that allows third party cli agents like Claude Code or OpenCode to be used inside Zed UI, like a panel. Seems like the best option for you that don't like terminals.",
                  "score": 2,
                  "created_utc": "2026-01-18 12:50:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0b9pic",
                  "author": "kkordikk",
                  "text": "Huh? It does. Go into cursor settings -> models -> scroll down and there you can use Anthropic key, openAI endpoint / API key (this is for ChatGPT, custom gateway like z.ai) \nPersonally Iâ€™m hosting LiteLLM (alternative to OpenRouter) and using all my models through it",
                  "score": 1,
                  "created_utc": "2026-01-18 16:24:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0afs8j",
          "author": "febryanvald0",
          "text": "Try OpenCode Black\n\n\nhttps://opencode.ai/black",
          "score": 2,
          "created_utc": "2026-01-18 13:50:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0adzyz",
          "author": "Fun-Understanding862",
          "text": "would suggest you to give github copilot a try, it has upped its game, for me claude code(20$) and github copilot(10$) plan works well",
          "score": 1,
          "created_utc": "2026-01-18 13:39:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0am2px",
          "author": "PweraUsog",
          "text": "Switch to Qwen CLI",
          "score": 1,
          "created_utc": "2026-01-18 14:26:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0f900o",
          "author": "RayanAr",
          "text": "Isn't opencode slower than claudecode?",
          "score": 1,
          "created_utc": "2026-01-19 04:43:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lj9xp",
          "author": "raptor_champs",
          "text": "GitHub copilot is in VScode and has a great cli\nAnd you can chose your model",
          "score": 1,
          "created_utc": "2026-01-20 02:50:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qgnad6",
      "title": "Fix memory Leak please",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/8rc4r45sv6eg1.png",
      "author": "ZookeepergameFit4082",
      "created_utc": "2026-01-18 23:07:16",
      "score": 32,
      "num_comments": 5,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qgnad6/fix_memory_leak_please/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0er6n5",
          "author": "james__jam",
          "text": "Sounds like something that needs to be posted in github issues and not reddit ðŸ˜…",
          "score": 21,
          "created_utc": "2026-01-19 02:54:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gaxla",
          "author": "AVX_Instructor",
          "text": "Its probably LSP, i have get simular issue, if keep long session in huge code base",
          "score": 2,
          "created_utc": "2026-01-19 10:05:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0h8wmh",
          "author": "FatherImPregnant",
          "text": "Are you using OhMyOpencode? Iâ€™ve noticed the same issue",
          "score": 1,
          "created_utc": "2026-01-19 14:15:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0hbqfm",
          "author": "trypnosis",
          "text": "I use basic opencode with a few mcps and run them all day multiple instance in tmux and my memory is fine. \n\nCould it be an addon or customisation of some kind?",
          "score": 1,
          "created_utc": "2026-01-19 14:30:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lojn9",
          "author": "tripleshielded",
          "text": "It needs memory leaks to give a similar experience to gemini cli.",
          "score": 1,
          "created_utc": "2026-01-20 03:20:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfnus6",
      "title": "I donâ€™t get it",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qfnus6/i_dont_get_it/",
      "author": "Mindless_Art4177",
      "created_utc": "2026-01-17 20:26:14",
      "score": 25,
      "num_comments": 28,
      "upvote_ratio": 0.77,
      "text": "I think Iâ€™m missing something basic I donâ€™t get the hype around open code\n\nIâ€™m using cursor 20$ plan ( get blocked ) which I like the most in terms of ui and workflow\n\nCodex cli when I run out of credits (chat gpt 20$) which is also ok Antigravity from time to time (free)\n\nWhy should I switch to opencode ? Whatâ€™s the big Change ? Should I buy 20$ plan ? From what I see the IDE extension is just running terminal in sidebar.\n\nPlease enlighten me ðŸ™\n\nâ€”-\n\nEdit:\n\nNow I get it, you can connect multiple accounts from multiple vendors using /connect and keep using only one tool.\n\nSupports all subagents/commnads/skills so you donâ€™t need to rewrite them when youâ€™re switching between models.\n\nOpen source with  big community around it with additional products such as open chamber.\n\nThanks.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qfnus6/i_dont_get_it/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o063ngn",
          "author": "Funny-Advertising238",
          "text": "First of all you can get openchamber from GitHub which is a frontend interface for opencode, I love it.\n\n\nSecond you can connect you chatgpt accounts, antigravity accounts, as well as use all the free models that opencode providers (glm 4.7, minimax etc.).\n\n\nI have 7 antigravity accounts connected and 3 chatgpt accounts. Never get rate limited and antigravity rate limits reset every 5 hours which is great.Â \n\n\nI was tired if switching between different ones, opencode has everything you need, model agnostic, exposes a openapi server as well and sdk for automations, it has all the features you need like subagents, hooks, skills, etc.\n\n\nAnd a little trick if you feel a little bit grey hat, you can get google ai pro and chatgpt plus accounts for 1-2$ on digital goods marketplaces.",
          "score": 11,
          "created_utc": "2026-01-17 20:40:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o066hiy",
              "author": "technischer_walzer",
              "text": "How do you have 7 antigravity accounts accounts? Did you create them? And you pay for 3 chatgpt accounts?",
              "score": 3,
              "created_utc": "2026-01-17 20:54:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o067pja",
                  "author": "Funny-Advertising238",
                  "text": "Nope I buy chatgpt plus accounts for 2$ each. Same with antigravity for 3-4$. I have 3 google ai pro accounts and the rest are just my own google accounts that don't have a subscription but they still work just the rate limits are much lower.",
                  "score": -5,
                  "created_utc": "2026-01-17 21:00:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0754lb",
              "author": "matija2209",
              "text": "Can you recommend some of those digital goods markets please. Thanks",
              "score": 2,
              "created_utc": "2026-01-17 23:50:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o081soq",
                  "author": "ezhupa99",
                  "text": "plati market",
                  "score": 0,
                  "created_utc": "2026-01-18 02:44:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o064x4a",
              "author": "Mindless_Art4177",
              "text": "Thanks for explaining Iâ€™ll try to figure out how to connect my other accounts and give it a chance.",
              "score": 0,
              "created_utc": "2026-01-17 20:46:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o064ksm",
          "author": "Michaeli_Starky",
          "text": "You are not obliged. \n\nTo me OC has a special place because it's open source. Also it works with multiple subs: Copilot, GPT, Antigravity... Anthropic is an exception since recently.",
          "score": 5,
          "created_utc": "2026-01-17 20:44:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o062mlr",
          "author": "No-Concentrate-6037",
          "text": "no you should not change. It's totally just hype. keep using your codex and antigravity.\n\nhappy?",
          "score": 8,
          "created_utc": "2026-01-17 20:34:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o067epv",
          "author": "trypnosis",
          "text": "Itâ€™s a weird one.\n\nI think itâ€™s the level of customisation for terminal gremlins.\n\nIf you look at the terminal as a cool fun tool then Claude Code, codex and OpenCode fill certain holes in your work flow.\n\nIf terminal is something you see as a more complicated way of using git then. Cursor, CS code with plugins and IntelliJ IDEs are for you.\n\nAll IDEs be they TUI or App have a workflow to leverage the power of LLMs to code. You need to find the one that works for you. I would say none is better than the other. What matters is best for you.",
          "score": 2,
          "created_utc": "2026-01-17 20:59:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o06h1vf",
          "author": "Haspe",
          "text": "This is a tool firstly designed to us terminal users, something that you can use, while you don't have to switch out from the terminal - TUI was their first \"product.\" Their architectic choice of client/server model however enables different client creation, and they're now providing Web, Electron for Desktop and probably a Mobile client in the future. You can also build your own front-end to talk with the server as well and use OpenCode as part of your thing.\n\nOpenCode's another selling point is model agnosticity. You can work with every model with single tool - it's like Visual Studio Code or Neovim of the Agentic Tools. The flavor of the month on the model market will change - perhaps you want to work with OpenAI models. Perhaps you want to work it some self-hosted model as well. Perhaps your workflow consists of using multi-provider models for different things. So if your toolkit is model agnostic, swapping the models that you use does not mean that you have to change your whole workflow - thats the point. For example as a Claude user you're breaking their TOS if you're not using their own clients for their own tools (except the API option, but their API option is quite expensive)\n\nI guess Cursor does that same thing to an extend - but OpenCode is open-source and Cursor is not (this might not mean anything to you, but for other people it does). I can see what the OpenCode does under the hood - and I can even fork it and create my own version of it if I want to. In the end the value proposition of a product is also a preference thing. I prefer to work in terminal, you might not - and you don't have to. Cursor is extremely good as well.",
          "score": 2,
          "created_utc": "2026-01-17 21:48:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o06iw8b",
              "author": "Mindless_Art4177",
              "text": "Now I get it\nYouâ€™re model agnostic, so you write your subagents/commands/skills and you donâ€™t need to port it or switch tools when youâ€™re running out of credits. Greet selling point.\n\nIâ€™m used for cli tools so itâ€™s not a problem, only when Iâ€™m developing ui I like to attach screenshots directly from clipboard to the conversion , cursor does it very well, not sure itâ€™s will work in cli context.\n\nThanks any way ðŸ™",
              "score": 1,
              "created_utc": "2026-01-17 21:57:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o07uxab",
                  "author": "Big_Bed_7240",
                  "text": "Opencode has image support",
                  "score": 2,
                  "created_utc": "2026-01-18 02:06:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o06305f",
          "author": "pokemonplayer2001",
          "text": "Imagine trying it and deciding for yourself!  \n\nJust imagine a modicum of effort!",
          "score": 4,
          "created_utc": "2026-01-17 20:36:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o064gl8",
              "author": "Mindless_Art4177",
              "text": "I tried and itâ€™s felt exactly like any other cli (codex, Gemini-cli)\nThatâ€™s why I got to feeling Iâ€™m missing something \nSometimes you might find goldmine by just asking",
              "score": 1,
              "created_utc": "2026-01-17 20:44:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o072zp3",
          "author": "Apprehensive_Half_68",
          "text": "I liked OpenCode after I gave it a shot a few weeks ago like you.  However what I wasn't ready for was \"Oh My OpenCode\" which has changed the way I develop software with most of the presets I use already built in.  It actually is TURNING me into a CLI guy as it feels just like cursor with a sidebar to chat and a file explorer open.. mcp status always visible etc but makes using Ralph Wiggum almost too easy.",
          "score": 1,
          "created_utc": "2026-01-17 23:39:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o07cxr8",
          "author": "dubh31241",
          "text": "The biggest selling points to me are the built in client/server architecture with pretty much API parity with what you can do locally as well as the ability to build literally any type of interface on top of opencode. This is now an AI compute engine. With some imagination and creativity, you can build tons of stuff on top of this. I just deployed this on a K8 cluster to interact with all of my resources; its like a bloomberg terminal for my K8 cluster.  \n\nMy next idea is to build a K8 operator for this to deploy multiple instances, because why do I need \"Agentic Frameworks\" if I can somehow orchestrate these using Skills and Agent file.",
          "score": 1,
          "created_utc": "2026-01-18 00:31:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08h31w",
          "author": "SynapticStreamer",
          "text": "> Why should I switch to opencode ?\n\nWhy are you acting like everyone here is just dying for you to swap up your workflow? You're approaching everything about this entirely wrong... A better question is why would you want to use 4 tools when you can deal with only 1.",
          "score": 1,
          "created_utc": "2026-01-18 04:12:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a5hm0",
          "author": "sbayit",
          "text": "My primary model is GLM, and DeepSeek's Opencode works best with it when running on its own server rather than through Openrouter.",
          "score": 1,
          "created_utc": "2026-01-18 12:40:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o064y2o",
          "author": "trmnl_cmdr",
          "text": "I tried vscode and it was exactly like notepad, I donâ€™t see why I should switch",
          "score": 0,
          "created_utc": "2026-01-17 20:46:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhj9ua",
      "title": "Bringing \"Advanced Tool Use\" to OpenCode with mcpx",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qhj9ua/bringing_advanced_tool_use_to_opencode_with_mcpx/",
      "author": "vicdotso",
      "created_utc": "2026-01-19 22:41:29",
      "score": 22,
      "num_comments": 3,
      "upvote_ratio": 0.93,
      "text": "Anthropic recently published their advanced tool use - [https://www.anthropic.com/engineering/advanced-tool-use](https://www.anthropic.com/engineering/advanced-tool-use) approach. The key insight is moving tool discovery to runtime instead of loading schemas upfront.\n\nThe problem: MCP integrations are fragmented. Claude Code has native support, most other tools don't. If you switch agents, you lose access to your MCP setup.\n\nBuilt mcpx to bring this pattern to any agent with bash. OpenCode, Aider, your custom setup. If it can run bash, it can use MCP servers now.\n\n\\- brew tap cs50victor/mcpx && brew install mcpx\n\n\\- mcpx  ( list all servers/tools )\n\n\\- mcpx grep \"\\*browser\\*\"          ( search by pattern )\n\n\\- mcpx playwright/click          ( get schema )\n\n\\- mcpx playwright/click '{\"selector\": \"#submit\"}'  ( call tool )\n\nwhy this approach:\n\n\\- Works across agents - not locked to any specific tool\n\n\\- Runtime discovery - \\~400 tokens vs 47k for upfront schema loading\n\n\\- Daemon mode - keeps stateful connections alive (browser sessions, db handles)\n\n\\- Uses your existing MCP config - no migration needed\n\nIt's open source: [https://github.com/cs50victor/mcpx](https://github.com/cs50victor/mcpx)\n\nWould love feedback, especially from folks who've been switching between agents.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qhj9ua/bringing_advanced_tool_use_to_opencode_with_mcpx/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0nnkz7",
          "author": "ExtentOdd",
          "text": "Why dont you create the PR? I believe this feature should be native to Opencode",
          "score": 6,
          "created_utc": "2026-01-20 12:37:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nq76o",
          "author": "touristtam",
          "text": "Looks similar to https://github.com/kenneth-liao/mcp-launchpad?",
          "score": 2,
          "created_utc": "2026-01-20 12:55:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0o5vfv",
              "author": "vicdotso",
              "text": "just checked this out. this looks really like a solid project / alternative to mcpx.",
              "score": 1,
              "created_utc": "2026-01-20 14:24:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qixs8i",
      "title": "Super simple way to migrate your Claude Code configs to OpenCode",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/5lybeqq8apeg1.png",
      "author": "hyericlee",
      "created_utc": "2026-01-21 13:24:04",
      "score": 22,
      "num_comments": 6,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qixs8i/super_simple_way_to_migrate_your_claude_code/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0ushkb",
          "author": "buggytheking",
          "text": "My G thank you so much for this. I just built an agent to do this but this is so much better.",
          "score": 2,
          "created_utc": "2026-01-21 13:55:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0utdgn",
              "author": "hyericlee",
              "text": "Glad it helped! Yeah as a CLI tool it doesnâ€™t use up any of your tokens, so thatâ€™s a plus.",
              "score": 1,
              "created_utc": "2026-01-21 14:00:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uvdbd",
          "author": "raydou",
          "text": "Do you know if there's a compatibility in OpenCode to Claude Code rules which are markdown files in  /rules folder (project or user's home)\nIf they exists is opkg compatible with them?",
          "score": 2,
          "created_utc": "2026-01-21 14:11:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0uxqlb",
              "author": "hyericlee",
              "text": "Great question actually, OpenCode rules works a bit different than Claude, Cursor, etc. as it needs to be mapped via opencode.json and not individual files, so Iâ€™m working on a mapping feature that will allow OpenPackage to map these file names to opencode.json â€œinstructionsâ€ field. This should be ready in one of the next few updates.",
              "score": 2,
              "created_utc": "2026-01-21 14:23:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0wfk06",
          "author": "Heavy-Focus-1964",
          "text": "I just cobbled together a much worse version of this out of symlinks yesterday, but this is much better. A star and an upvote for you.\n\n  \nAre claude hooks/opencode plugins on your radar at all? Even though they do almost the same thing, I know the implementation of each is very different. I know this doesn't have an easy answer, just wondering what your thoughts are",
          "score": 2,
          "created_utc": "2026-01-21 18:29:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0yyg71",
              "author": "hyericlee",
              "text": "Yeah itâ€™s precisely that the two systems are quite different that it hasnâ€™t been implemented so far.\n\nThe primary reason is that the two systems are using different â€œenginesâ€, Claude hooks using bash commands while OpenCode plugins using JS/TS runtime. This leads to a very large set of differences to map.\n\nHowever thereâ€™s a direction that Iâ€™m looking at where we may be able to wrap JS code into files for CC to run via bash, and for the other direction run bash commands to invoke JS code. Not an easy task to unify though!\n\nIâ€™m glad OpenPackage has been useful, thanks for the suggestion and your support! This is great food for thought.",
              "score": 2,
              "created_utc": "2026-01-22 01:56:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qho03o",
      "title": "Happy Coder for OpenCode",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qho03o/happy_coder_for_opencode/",
      "author": "opus-sophont",
      "created_utc": "2026-01-20 01:59:54",
      "score": 21,
      "num_comments": 18,
      "upvote_ratio": 0.92,
      "text": "Iâ€™ve been using OpenCode for my agentic coding workflows and I really like it, but managing it on mobile is a pain.\n\nI know I can SSH into my remote server (using Termius, etc.), but text-based terminal interactions on a phone screen are clunky compared to a proper chat interface. I recently saw [**Happy.engineering**](http://Happy.engineering) (for Claude Code) and the UX is exactly what I wantâ€”a clean, mobile-friendly chat UI that connects to my agent without needing to fiddle with raw SSH commands every time.\n\nDoes anyone know if a similar wrapper or mobile-first UI exists for OpenCode? I know `opencode-web` exists, but I'm looking for something that feels more like a native app or a smoother relay service.\n\nHas anyone solved this mobile workflow yet?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qho03o/happy_coder_for_opencode/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0lmvnr",
          "author": "Open_Scallion9015",
          "text": "Yep thereâ€™s OpenChamber. It works great on mobile. https://github.com/btriapitsyn/openchamber",
          "score": 10,
          "created_utc": "2026-01-20 03:10:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ml1eu",
              "author": "opus-sophont",
              "text": "Thanks for sharing this, this is actually great.\n\nFor those who might not know this, you could fire up a local host login and then set up a cloudflared tunnel with your own domain to access the host from anywhere. Make sure to have some appropriate security measures other than just the password protect that OpenChamber provides, though.",
              "score": 2,
              "created_utc": "2026-01-20 07:02:26",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0mh21w",
              "author": "WholesomeGMNG",
              "text": "Thanks for sharing this!",
              "score": 1,
              "created_utc": "2026-01-20 06:29:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0llxw3",
          "author": "lundrog",
          "text": "So your saying we should vibe code something?",
          "score": 6,
          "created_utc": "2026-01-20 03:05:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0o5mm7",
              "author": "TopSimple3181",
              "text": "already on it ( [X](https://x.com/devmuzzammil/status/2013502484518457530) ), building [broski](https://broskiapp.com)",
              "score": 2,
              "created_utc": "2026-01-20 14:23:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ll0bz",
          "author": "woundedknee_x2",
          "text": "Opencode has a built in web client (opencode web --port 3000), but itâ€™s not very mobile friendly. Would love something like this.",
          "score": 4,
          "created_utc": "2026-01-20 03:00:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0o5xnf",
              "author": "TopSimple3181",
              "text": "already on it ( [X](https://x.com/devmuzzammil/status/2013502484518457530) ), building [broski](https://broskiapp.com)",
              "score": 1,
              "created_utc": "2026-01-20 14:24:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0lmb50",
          "author": "skinnydill",
          "text": "Mac only: https://vibetunnel.sh/",
          "score": 3,
          "created_utc": "2026-01-20 03:07:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mthwi",
              "author": "maxz2040",
              "text": "What a mad soundtrack. Bring back chip tunes to vibe coded apps",
              "score": 1,
              "created_utc": "2026-01-20 08:18:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0lazsj",
          "author": "Dudmaster",
          "text": "Happy coder supports codex, so my first instinct would be to write the integration with AI or at least gauge difficulty. It is open source so I'd hope the framework is fairly extensible",
          "score": 2,
          "created_utc": "2026-01-20 02:05:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mlqpx",
          "author": "Recent-Success-1520",
          "text": "https://github.com/NeuralNomadsAI/CodeNomad allows you to remote handover",
          "score": 1,
          "created_utc": "2026-01-20 07:08:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nm4x9",
              "author": "opus-sophont",
              "text": "That's interesting, thanks for sharing. I looked at the project and it looks neat. One question I have though is, is the experience much better than just using the given OpenCode webui? One thing I like about OpenChamber that another guy mentioned in the comments is that the mobile UI is extremely friendly, so I was wondering what about CodeNomad appeals to you personally.",
              "score": 1,
              "created_utc": "2026-01-20 12:27:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0nmq98",
                  "author": "Recent-Success-1520",
                  "text": "Disclaimer - I built CodeNomad.\n\nThe reason I built it was that opencode webui or Desktop app is more geared towards making it an easy to use tool without looking at what's happening under the hood.\n\nIt supports Desktop app mode, web ui mode, remote server mode and easy handover to phone from desktop mode and server modes.\nTry it out, it's easy to try.",
                  "score": 1,
                  "created_utc": "2026-01-20 12:32:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0n6t6a",
          "author": "sentrix_l",
          "text": "I've faced the same problem; most tools arent good enough for this.\n\nCursor solved it with their cloud agents. Downside: leave it for too long and you can't continue the conversation. But you can comment on github and mention cursor and it'll do it. It's finicky imo. As setup of the cloud agent makes it use a large portion of the context window. ON SETUP...\n\nClaude solved this too and their ecosystem is a bit better, similar approach to cursor.\n\nOpencode should have a github mention integration where AI does its thing. Pretty sure you can set this up using GH Actions.\n\nBut... all of them miss critical infrastructure.\n\nI built SprintFlint, a tool similar to Linear but you can autoplay issues and AI creates PRs for you, utilising what you give it; skills, mcps, plugins, agent browser and so on. No vendor lock in so you can use any AI with it (as long as it runs in the terminal). Utilising GH Actions.\n\nI started using this to further develop SprintFlint, needless to say this AI feature is still a work in progress. The agent asks questions in issue comments if it has any and creates the PR if it has enough clarity.\n\nI want to improve it further so you can see what's going on and chat with the AI properly in SprintFlint, but that'll take some time.",
          "score": 1,
          "created_utc": "2026-01-20 10:23:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0o5elu",
          "author": "TopSimple3181",
          "text": "Yes Iâ€™m building [broski](https://broskiapp.com) for that, about to ship to app store and excited. Just preparing final screenshots and all",
          "score": 1,
          "created_utc": "2026-01-20 14:21:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qx3fu",
          "author": "pRizzAtGitHub",
          "text": "Iâ€™ll throw my hat in the ring and also mention Iâ€™m building something somewhat similar to what youâ€™re asking for. I wasnâ€™t aware of all these other projects when I started building it, but I feel itâ€™s kinda similar to CodeNomad in spirit, except closer to being an opencode mod + cockpit. Hereâ€™s my repo: https://github.com/pRizz/opencode-cloud",
          "score": 1,
          "created_utc": "2026-01-20 22:06:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wirph",
          "author": "TheHeadSalad",
          "text": "Thereâ€™s also opencode-manager. Works like a charm. I use it on mobile every day. \n\nhttps://github.com/chriswritescode-dev/opencode-manager",
          "score": 1,
          "created_utc": "2026-01-21 18:43:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qeq8fw",
      "title": "i built openwork - an open-source claude cowork alternative  (built on and by opencode)",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qeq8fw/i_built_openwork_an_opensource_claude_cowork/",
      "author": "Outrageous_Client272",
      "created_utc": "2026-01-16 19:50:46",
      "score": 21,
      "num_comments": 5,
      "upvote_ratio": 0.84,
      "text": "hey !\n\n  \nstarted building openwork a few days back and it got picked up by the hackernews algo made it to #1 of show hn and top 10 of front page  ðŸ˜€\n\n  \nopenwork is a local-first system inspired by claude cowork.\n\nhttps://preview.redd.it/9jyfe9s1nrdg1.png?width=2584&format=png&auto=webp&s=f0a3e2b57e7f228df68d4c67205692cd34b8fe10\n\n  \ni built it entirely with opencode in just a couple days. (happy to share workflow)\n\n  \ni had a few design principle in mind when i built it:\n\n\\- non-tech friendly, but tinkerer as power users: should be easily used by \"susan in accounting\" and \"bob in it\" should be able to extend susan's capabilities by creating its own agents skills etc.\n\n\\- opencode-first approach: wanted to use the same primitives as opencode and not re-invent the wheel. \n\n\\- extensibility: should be easy to extend via skills and opencode plugins (all within the ui)\n\n  \nnow did i reach all these goals today? no.\n\n  \nthis is aspirational not the status quo.\n\n  \nhowever, i was able to pack a few cool things for the current release:\n\n\\- you can already head to the openwork dot software website\n\n\\- you can use it locally, or connect to a server  \n\n\nour github repo just reached 700 stars in just 3 days ðŸ¥³\n\n  \nwould appreciate feedback or if you feel like it a star to support this.\n\nPS: i'm still fighting some bugs today! but don't hesitate to share issues you encounter",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qeq8fw/i_built_openwork_an_opensource_claude_cowork/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nzzc88x",
          "author": "rayfin",
          "text": "Awesome. I built the same thing about a week ago. I actually started on it before Claude Cowork was even announced. I've been using it for over a week for my personal (business) daily tasks. I'm gearing up to launch it when I return from traveling next week.",
          "score": 4,
          "created_utc": "2026-01-16 19:55:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzhv1p",
          "author": "Outrageous_Client272",
          "text": "oh forgot to share the github\n\n[github.com/different-ai/openwork](http://github.com/different-ai/openwork)",
          "score": 4,
          "created_utc": "2026-01-16 20:22:08",
          "is_submitter": true,
          "replies": [
            {
              "id": "nzzkupo",
              "author": "t4a8945",
              "text": "awesome stuff ; one downside of Claude Cowork is that it's currently a MacOS app only, I think if you address that by telling what OS is supported, you could ease adoption.",
              "score": 5,
              "created_utc": "2026-01-16 20:36:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00bhl5",
                  "author": "xmnstr",
                  "text": "Looks like this is built for macOS primarily, but could probably fairly easily be built for other operating systems too.",
                  "score": 2,
                  "created_utc": "2026-01-16 22:44:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o000yej",
              "author": "Designer-Change978",
              "text": "[https://github.com/eigent-ai/eigent](https://github.com/eigent-ai/eigent)  \nThis one too. Saw them on the GitHub Trending list yesterday",
              "score": 2,
              "created_utc": "2026-01-16 21:52:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qin7zr",
      "title": "Best plugins, AI agents and workflows 2025",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qin7zr/best_plugins_ai_agents_and_workflows_2025/",
      "author": "joshuajm01",
      "created_utc": "2026-01-21 03:44:52",
      "score": 20,
      "num_comments": 5,
      "upvote_ratio": 0.95,
      "text": "Hi All \n\nWhen I say \"best\" I mean for you and your workflow. What has been tried and tested by you or your company personally.\n\nI'm wanting to know what are everyones plugins or agents being used in Opencode right now? What is your workflow with those plugins or agents? \n\n  \nI've tried using oh my opencode and I have to say it takes way too long to do anything. I've seen others say the same. So I'm curious to know what everyone's setup is. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qin7zr/best_plugins_ai_agents_and_workflows_2025/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0sntxu",
          "author": "jhartumc",
          "text": "antigravity auth  \ndynamic context pruning  \nsuperpowers",
          "score": 3,
          "created_utc": "2026-01-21 03:55:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0x0q96",
          "author": "Practical_Oil_1312",
          "text": "Definitely antigravity auth",
          "score": 2,
          "created_utc": "2026-01-21 20:04:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o14v1lm",
              "author": "joshuajm01",
              "text": "Why is that",
              "score": 1,
              "created_utc": "2026-01-22 22:52:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0syq62",
          "author": "Kitchen_Fix1464",
          "text": "I built some custom tools to add mem0 support. That has been the most noticeable extension I've used so far.",
          "score": 1,
          "created_utc": "2026-01-21 05:08:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tq43b",
          "author": "bebenzer",
          "text": "I am trying openspec, it seems nice, in my experience it adds strong guardrails to the model and the work done is good, obviously sometimes I may need to adjust the spec created or I need to chat a bit to guide the llm for the feature.\n\nI don't know if it's overkill yet, and maybe in a near future this tool will be obsolete because opencode will add a similar feature (I saw a tweet or on the discord their next plan mode based on cursor one or something similar).\n\nhowever there is something annoying, I dont know what should I do with all the markdowns generated, should I commit them or add them in the gitignore. I'm not sure about what is the right workflow when you work in a team as some colleagues may use openspec or other similar tools or none, what if we have the same spec names etc.",
          "score": 0,
          "created_utc": "2026-01-21 09:04:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}