{
  "metadata": {
    "last_updated": "2026-01-20 02:29:03",
    "time_filter": "week",
    "subreddit": "opencodeCLI",
    "total_items": 20,
    "total_comments": 208,
    "file_size_bytes": 243335
  },
  "items": [
    {
      "id": "1qbqn96",
      "title": "OpenPackage - A better, universal, open source version of Claude Code Plugins",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/rs91y5xa44dg1.png",
      "author": "hyericlee",
      "created_utc": "2026-01-13 12:59:05",
      "score": 157,
      "num_comments": 25,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qbqn96/openpackage_a_better_universal_open_source/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzcgdeh",
          "author": "lifeisgoodlabs",
          "text": "strange there are no upvotes, I think it's super interesting project where you are trying to standardize the differences between the setup into different AI tools.\n\nThanks!",
          "score": 12,
          "created_utc": "2026-01-13 13:05:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzch5d8",
              "author": "hyericlee",
              "text": "There are so so many AI coding platforms out there.\n\nFor OpenPackage, I‚Äôve laid out a foundation that allows for declaration of file path and key value mappings per platform. This was definitely a challenge to design.\n\nGlad you found this interesting!\n(Low upvotes probably bc just posted this a few minutes ago, hopefully doesn‚Äôt stay this way haha)",
              "score": 9,
              "created_utc": "2026-01-13 13:10:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzctxs8",
          "author": "ProfessionalAd8199",
          "text": "Bro you found a pain point for a lot of us people. If your project becomes stable, i will use it!",
          "score": 6,
          "created_utc": "2026-01-13 14:21:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzcuxo6",
              "author": "hyericlee",
              "text": "Glad to hear! I‚Äôll make it my top priority.",
              "score": 5,
              "created_utc": "2026-01-13 14:26:45",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzd8eab",
              "author": "jovialfaction",
              "text": "+1\n\nI will however wait a couple of months and revisit it. There are a lot of release-and-abandon projects around here (because it's so easy to write something but harder to maintain), so I've become wary of new releases",
              "score": 3,
              "created_utc": "2026-01-13 15:33:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzgh782",
                  "author": "hyericlee",
                  "text": "Valid concern, no worries, I‚Äôll keep at it.\n\nI genuinely think OpenPackage can grow to the scale of NPM and GitHub, that makes me very excited for the opportunity it entails.\n\nThank you for the interest, every bit helps!",
                  "score": 3,
                  "created_utc": "2026-01-14 01:02:51",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzy4gzs",
          "author": "dyzhdyzh",
          "text": "Does it translate tool names across harnesses? For example, Claude Code's `AskUserQuestion` to OpenCode's `question`.",
          "score": 3,
          "created_utc": "2026-01-16 16:40:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o025rhm",
              "author": "hyericlee",
              "text": "Great question!\n\nI‚Äôve laid out the foundation for this already in OpenPackage in the root `platforms.jsonc` file, where per platform mappings are declared. \n\nThere are so so many detailed mappings that needs to be delared and I haven‚Äôt declared them all yet, will be adding them in as time goes by.\n\nWould love everyone‚Äôs support via pull requests to expand the mapping files to cover these platform differences!",
              "score": 3,
              "created_utc": "2026-01-17 05:40:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzcxlzt",
          "author": "Mellowh",
          "text": "Really awesome idea & impressive project. \n\nI‚Äôm working on a universal agent client and have been thinking about how I could support Claude Code plugins, but for all agents.\n\nThis seems like what I would want to support in my project eventually",
          "score": 2,
          "created_utc": "2026-01-13 14:40:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzczy2g",
              "author": "hyericlee",
              "text": "Thank you!\n\nIt took a lot of tweaking and so many iterations haha, need to thank my early users for the great feedback as well. \n\nA universal agent client sounds really cool, would love to know more about it, feel free to DM me if you need any help with integrating OpenPackage!",
              "score": 2,
              "created_utc": "2026-01-13 14:52:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzdfath",
          "author": "lukaboulpaep",
          "text": "Really cool project, going to try it out. It‚Äôs what our team was looking for.\n\nI had a small question, although I quickly scimmed through the docs so might need to look further.\n\nMost example showcase installing it in an existing codebase, is it also possible to install globally? Let‚Äôs say I use OpenCode and my team member Claude Code. Can we install the plugin we defined within our team (from a private repo) for platform specific globally?",
          "score": 2,
          "created_utc": "2026-01-13 16:05:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzgjiws",
              "author": "hyericlee",
              "text": "I‚Äôm glad OpenPackage has been helpful!\n\nRegarding global level installations, not integrated yet but I‚Äôm working to get this implemented soon (should be in the next update).\n\nFoundationally, OpenPackage is able to accomplish this via the `‚Äîcwd` flag, but many platforms have different configs between local and global, and this is what I need to sort out.\n\nThere‚Äôs a related open issue actually: https://github.com/enulus/OpenPackage/issues/7\n\nWill DM you when this is ready, would love to understand what your team needs and see how I can help!",
              "score": 2,
              "created_utc": "2026-01-14 01:16:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzi0xc0",
                  "author": "lukaboulpaep",
                  "text": "We‚Äôre mainly looking for shareable agents/commands/skills/etc. without enforcing a tool for our team. A lot of people like cursor, a lot like claude code and I personally don‚Äôt want to move away from open code.\n\nWe currently have a repo for a claude plugin, but this tool would be very handy since we can just reuse the claude plugin we already have. Kind of like a plug and play which I really like.\n\nWe also have around 70 repositories so mostly our setup is globally so we can reuse these without needing to install it in every repository",
                  "score": 2,
                  "created_utc": "2026-01-14 07:10:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzfj1t3",
          "author": "Outrageous_Client272",
          "text": "love it!",
          "score": 2,
          "created_utc": "2026-01-13 22:03:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzgjl35",
              "author": "hyericlee",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2026-01-14 01:16:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzgz5cm",
                  "author": "Outrageous_Client272",
                  "text": "BTW I'm using it in OpenWork (an open-source alternative to Claude Cowork fully built on opencode). \n\n\n\nI integrated OpenPackage as a native way to manage skills within the app(will improve the integration soon) would love to talk more for deeper integration.\n\nhttps://preview.redd.it/8d6dj2dz98dg1.png?width=2584&format=png&auto=webp&s=28bbbb61c7c62e8ce746444da4e49fc55c7ae14f",
                  "score": 5,
                  "created_utc": "2026-01-14 02:44:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzgh13q",
          "author": "Hairy_Improvement_90",
          "text": "what is your most useful skill guys ?",
          "score": 1,
          "created_utc": "2026-01-14 01:01:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o07okr0",
          "author": "Devcomeups",
          "text": "Anyone vot a plugin to make it run remotely through slack? Telegram?  Watsapp ?",
          "score": 1,
          "created_utc": "2026-01-18 01:32:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdo24d",
      "title": "Opencode Privacy Policy is Concerning",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qdo24d/opencode_privacy_policy_is_concerning/",
      "author": "whamram",
      "created_utc": "2026-01-15 16:24:44",
      "score": 143,
      "num_comments": 30,
      "upvote_ratio": 0.97,
      "text": "Opencode's newest [privacy policy](https://opencode.ai/legal/privacy-policy), which went into effect December 16th, is extremely concerning. It is the polar opposite of their previous stance with not holding any data except for Anthropic and OpenAI's 30-day retention period, and should be especially concerning to all users who use zen or are planning to use the new black subscription.\n\nIt basically states that they collect all usage data, can store it \"as long as necessary,\" and they can share it with service providers, business partners, authorized third parties, government/law encforcement when required, and explicitly state that they will use it for marketing purposes. I was actually planning on switching to Opencode black from my Claude Pro plan, but at the very least Claude gives you a very clear 30-day retention number and provide *some* protections against using the data for marketing purposes. If you care about privacy at all, please spread the word and urge the Opencode team to at least make more clear their data retention policies or even try to change their stance on privacy completely.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qdo24d/opencode_privacy_policy_is_concerning/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nzrx5ko",
          "author": "digibioburden",
          "text": "Do they collect all of this kinda stuff if you're not using their models?",
          "score": 20,
          "created_utc": "2026-01-15 18:39:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwspwd",
              "author": "debian3",
              "text": "It's opensource, it's not like you can't look at the code to see what is happening. \n\nI just checked with opencode and the answer is no.",
              "score": 4,
              "created_utc": "2026-01-16 12:43:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrn69o",
          "author": "apodlesny",
          "text": "I have found some strange behaviour in terms of privacy in opencode CLI\n\nhttps://github.com/anomalyco/opencode/issues/8609\n\nI was really surprised seeing how my session data was sent to opencode servers for literally no reason.",
          "score": 15,
          "created_utc": "2026-01-15 17:55:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztlseu",
              "author": "touristtam",
              "text": "There is no step to reproduce the alleged observed behaviour, so I would take that with a grain of salt at first glance. I am not saying it isn't true, but the reporter doesn't provide enough evidences to definitely conclude this is the case.",
              "score": 2,
              "created_utc": "2026-01-15 23:25:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzur717",
                  "author": "mynameis_twat",
                  "text": "If you read the issue though you can easily recreate it and in the code it shows the mismatch. While explicit steps to reproduce should be included, if you‚Äôre not to see the issue or reproduce it with that info that‚Äôs on the reader not the reporter.",
                  "score": 1,
                  "created_utc": "2026-01-16 03:13:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzs3sp2",
          "author": "ori_303",
          "text": "I am honestly pretty shocked this happens‚Ä¶ really concerning",
          "score": 8,
          "created_utc": "2026-01-15 19:08:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzr8ozs",
          "author": "deegwaren",
          "text": "One thing I don't fully understand: is this about using opencode (the tool), or about using their Zen service?",
          "score": 17,
          "created_utc": "2026-01-15 16:50:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzr9s6n",
              "author": "whamram",
              "text": "I‚Äôm really not sure, but you can assume both since this is their overall privacy policy for the whole of ‚ÄúOpencode‚Äù",
              "score": 8,
              "created_utc": "2026-01-15 16:55:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzr5y8j",
          "author": "VerbaGPT",
          "text": "One great thing they did (kudos to Dax and team) - is to make it MIT. I think better privacy, especially as local models become more feasible, will be increasingly attractive vs claudecode. If they don't do it, maybe someone can fork and do it. I understand not easy.",
          "score": 11,
          "created_utc": "2026-01-15 16:37:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05fym4",
              "author": "Original_Finding2212",
              "text": "Codex is as well, no?",
              "score": 1,
              "created_utc": "2026-01-17 18:44:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzstmtn",
          "author": "kpetrovsky",
          "text": "From what I can see, privacy policy covers how they handle personal data - i.e. name, email, phone number etc. The Content (Inputs + Outputs) are described in Terms and conditions, and I don't see anything alarming there (so far) - as long as you use third-party or local services, no content is retained by Opencode.",
          "score": 4,
          "created_utc": "2026-01-15 21:08:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvfk8p",
              "author": "whamram",
              "text": "\"Other Identifying Information that You Voluntarily Choose to Provide such as information included in conversations or prompts that you submit to AI.\"\n\nThat reads to me like all conversation data is fair game, but let me know if I'm wrong there",
              "score": 5,
              "created_utc": "2026-01-16 05:51:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzvzfk2",
          "author": "rm-rf-rm",
          "text": "Theyre trending in the same trajectory as \"Open\"AI, Cline etc. Just call it \"open\" to get community momentum and the once there is sufficient traction, start the fuckery to maximize profits, appease investors etc.",
          "score": 3,
          "created_utc": "2026-01-16 08:39:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0cj3sc",
          "author": "PandaJunk",
          "text": "I had similar concerns reading the ToS, so I had Claude Code do a security audit on the actual code base (2026/01/18), focusing on CLI use. Specifically, I wanted to know if prompts or data were either directly or indirectly being sent anywhere besides the underlying model provider I am using.  \n  \nTL;DR: No, when using a third party LLM (i.e., not opencode's LLM) via the CLI, opencode doesn't access any prompts or data unless you use the /share command, or have set a key environmental variable, OPENCODE\\_AUTO\\_SHARE; Any stored states, prompts, or data are local to your machine (e.g., \\~/<user>/.opencaude/)",
          "score": 3,
          "created_utc": "2026-01-18 19:58:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0csy4i",
              "author": "whamram",
              "text": "Thanks, at least we know that! I am still concerned about black/zen as the idea of these services is great and fills a great niche to be able to keep up with whoever has the best/most token efficient model, but I really need it to have low or zero data retention.",
              "score": 1,
              "created_utc": "2026-01-18 20:46:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0cy7dt",
                  "author": "PandaJunk",
                  "text": "For me, we are looking at an agreement with Claude that basically says they will never use our data or any PII that gets sent to Anthropic for training or any kind of third party exposure. That opens up the potential to use otherodels for non-PII stuff, but then we can use specific models for any code that has more security issues associated with it, which is great, because then we're not locked into a single ecosystem.",
                  "score": 1,
                  "created_utc": "2026-01-18 21:15:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrhlm7",
          "author": "Puzzleheaded-Two7047",
          "text": "Unlike Claude Code, you can see the source of OpenCode and exactly what they‚Äôre collecting. \n\nUnlike Claude Code, you‚Äôre not locked into their policies at all. It‚Äôs MIT and you can fork it if you want.",
          "score": 9,
          "created_utc": "2026-01-15 17:30:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzripan",
              "author": "whamram",
              "text": "Is opencode black open source?",
              "score": 1,
              "created_utc": "2026-01-15 17:35:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzrjcku",
                  "author": "Puzzleheaded-Two7047",
                  "text": "I was referring to if this policy applies to opencode broadly. No idea re: black.\n\nhttps://www.reddit.com/r/opencodeCLI/s/MO4mwGECH5\n\nI use opencode strictly because I don‚Äôt want my local developer tooling to come with vendor / model lock in.",
                  "score": 6,
                  "created_utc": "2026-01-15 17:38:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrq4ww",
          "author": "rmaxdev",
          "text": "Data is gold",
          "score": 2,
          "created_utc": "2026-01-15 18:08:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs5o5p",
              "author": "Fickle_Degree_2728",
              "text": "Diamond",
              "score": 1,
              "created_utc": "2026-01-15 19:17:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nztj8g4",
          "author": "kgoncharuk",
          "text": "but it seems they collect only personal tracking data (like user with this IP has N agents and used M features) rather storing the source code. Last one would be very worrying indeed, but it's not listed in privacy policy as data they collect. \n\nAlso as you normally do not login in the OpenCode itself, imo it's not a massive risk that they store some usage analytics. Would make sense for them to have some expiration for that data, but I guess it will come with time.",
          "score": 1,
          "created_utc": "2026-01-15 23:11:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuywaa",
          "author": "zhambe",
          "text": "I mean, it's open source, right? You can literally use it to castrate its own code base, and tear out whatever snitch code they put in there.",
          "score": 1,
          "created_utc": "2026-01-16 03:59:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzveiug",
              "author": "xmnstr",
              "text": "The opencode zen platform isn't open source, is it? Kinda hard to tell what of our queries they save from looking at the client source code.",
              "score": 2,
              "created_utc": "2026-01-16 05:43:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzvsb79",
          "author": "chevdor",
          "text": "I did not dig but the change may be for a few simple reasons:\n- opencode uses the model of sessions so it may indeed to keep data for a while until the session is close. In theory that could be months. That being said, this is mostly local but that means that months after you started your session, the session's context will still be sent\n- since opencode uses multiple models, their term probably also need to match the weakest and the real conditions depend on the underlying model(s) you are using.\n\nTo clarify, they probably should clearly explain the diff between opencode the cli, the data they may gather from the cli and the data related to the models used for the processing.",
          "score": 1,
          "created_utc": "2026-01-16 07:35:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0itekq",
          "author": "elissaxy",
          "text": "Time to use OpenClone",
          "score": 0,
          "created_utc": "2026-01-19 18:37:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv6k4w",
          "author": "Lyuseefur",
          "text": "Ok I read all this and IDK. Legal buzzwords don‚Äôt mean shit. Code is where it is. All the closed providers of course dgaf. \n\nNow opencode by being a provider probably had some lawyer draft shit to say whatever so they can sell black for $200 a month.\n\nThat said, if someone can cite anything reasonable-and that GitHub comment above I couldn‚Äôt replicate, then we can do pitchfork sales too.\n\nMeanwhile, grains of salt is warranted at this time‚Ä¶",
          "score": -1,
          "created_utc": "2026-01-16 04:48:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qexcsu",
      "title": "i wanted to work 100% from the terminal",
      "subreddit": "opencodeCLI",
      "url": "https://v.redd.it/o0s0pgk9ysdg1",
      "author": "Professional_Cap3741",
      "created_utc": "2026-01-17 00:19:11",
      "score": 123,
      "num_comments": 31,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qexcsu/i_wanted_to_work_100_from_the_terminal/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o01x296",
          "author": "sudonem",
          "text": "This is rad, and it‚Äôs essentially the workflow I have by pairing OpenCode with neovim & tmux. \n\nCurious to see how it shapes up (but you‚Äôll have to extricate tmux & neovim from my cold dead carcass üôÉ)",
          "score": 14,
          "created_utc": "2026-01-17 04:37:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o049bux",
              "author": "92smola",
              "text": "Hahahah same",
              "score": 3,
              "created_utc": "2026-01-17 15:24:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o01o8up",
          "author": "Old-Sherbert-4495",
          "text": "will you be sharing this project?? or at least how you built?",
          "score": 7,
          "created_utc": "2026-01-17 03:36:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03jug0",
          "author": "verkavo",
          "text": "Tmux split screen with Lazygit and Opencode is an easy way to follow what AI had changed.",
          "score": 7,
          "created_utc": "2026-01-17 13:01:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02hx73",
          "author": "awfulalexey",
          "text": "Link?",
          "score": 2,
          "created_utc": "2026-01-17 07:24:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0332sq",
          "author": "splitbrainhack",
          "text": "linkeroo ?",
          "score": 2,
          "created_utc": "2026-01-17 10:42:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03gyrv",
          "author": "grepharders",
          "text": "Tried the new UI as well  it‚Äôs nice but the terminal is still my go to",
          "score": 2,
          "created_utc": "2026-01-17 12:41:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02e6h9",
          "author": "garloid64",
          "text": "What are we doing here? We've had this experience for so long with so many vscode extensions, why is our hyper advanced state of the art autonomous AI agent technology regressing to the 1980s when it comes to UI?",
          "score": 2,
          "created_utc": "2026-01-17 06:51:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02ikt7",
              "author": "trypnosis",
              "text": "I spent the last 15 years going full GUI. Now i feel like I‚Äôm going before to before the GUI revolution. I spending more and more time in the terminal.",
              "score": 2,
              "created_utc": "2026-01-17 07:30:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03tnpt",
                  "author": "vienna_city_skater",
                  "text": "I feel like I'm back at university where I went all Emacs from coding to notes to email to web browsing. Not sure why I did it, but it felt L337 for sure. EDIT: That was right after my clickibunti Vista phase, so maybe a backlash from that era.",
                  "score": 2,
                  "created_utc": "2026-01-17 14:01:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o03tcqp",
              "author": "vienna_city_skater",
              "text": "The reality is building good desktop applications is hard and the TUI is a shortcut that devs accept. That was the reasoning behing Claude Code and many projects copied this strategy. Also the agentic future may involve less manual input than many anticipate, so why spend time building good UX?",
              "score": 1,
              "created_utc": "2026-01-17 14:00:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0btkn9",
                  "author": "SquareAbrocoma2203",
                  "text": "Writing graphical apps is a pain in the ass, that's true, especially ones that work on all the 58 billion edge cases of different operating systems.  I've literally built webUI's on a local system just so I didn't have to fuck with the OS.",
                  "score": 2,
                  "created_utc": "2026-01-18 17:59:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o04rtx1",
                  "author": "trypnosis",
                  "text": "That makes sense. Maybe the future will be GUI free.",
                  "score": 1,
                  "created_utc": "2026-01-17 16:52:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0bezst",
                  "author": "Maasu",
                  "text": "I just hate touching my mouse, it's a dickhead that slows me down",
                  "score": 1,
                  "created_utc": "2026-01-18 16:50:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0bt9yq",
              "author": "SquareAbrocoma2203",
              "text": "~~Regressing~~  Progressing.",
              "score": 0,
              "created_utc": "2026-01-18 17:57:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o01k6pu",
          "author": "Old-Sherbert-4495",
          "text": "I wanted this all along.",
          "score": 1,
          "created_utc": "2026-01-17 03:09:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02g5qy",
          "author": "jirubizu",
          "text": "Is there a gh link dont want to lose this project",
          "score": 1,
          "created_utc": "2026-01-17 07:08:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02ya36",
          "author": "4gustaf",
          "text": "Exactly my gripe, good job!",
          "score": 1,
          "created_utc": "2026-01-17 09:57:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o034k1d",
          "author": "Embarrassed-Mail267",
          "text": "Man this is the most beautiful thing I've seen this year.... well designed!! Fluid! Beautiful.   \nthis feature alone makes me want to switch to opencode..\n\n  \ni am a cli power user through and through (see my other posts)... but I need the IDE for effective code review / checking agent work / stress testing its architecture.... Antigravity delivered what i needed.   \n\n  \nBut your thing is so clean, i want to use it just to stare at its beauty.",
          "score": 1,
          "created_utc": "2026-01-17 10:56:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03bj68",
          "author": "silopolis",
          "text": "WANT! üòç",
          "score": 1,
          "created_utc": "2026-01-17 11:58:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o042f18",
          "author": "tkdeveloper",
          "text": "This kind of what i do with helix + zellij. Have one tab for helix, one for shell commands, one for opencode, and one for lazygit",
          "score": 1,
          "created_utc": "2026-01-17 14:49:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04ocr5",
          "author": "Ok_Proposal_1290",
          "text": "If it's possible could I get a Link? This looks AMAZING",
          "score": 1,
          "created_utc": "2026-01-17 16:36:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o055geb",
          "author": "Forgot_Password_Dude",
          "text": "Where GitHub repo for this",
          "score": 1,
          "created_utc": "2026-01-17 17:56:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05ns3f",
          "author": "anon_wick",
          "text": "Link please",
          "score": 1,
          "created_utc": "2026-01-17 19:21:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0951dc",
          "author": "Serious_Client6274",
          "text": "warp or ghostty + zellij, opening the CLI coding agent of your choice + lazygit + yazi + neovim",
          "score": 1,
          "created_utc": "2026-01-18 07:14:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09b7xm",
          "author": "lev400",
          "text": "Have you tried OpenCode Desktop ?",
          "score": 1,
          "created_utc": "2026-01-18 08:09:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01m6r1",
          "author": "Ok-Painter573",
          "text": "So recreating gh copilot/cursor in terminal?",
          "score": -2,
          "created_utc": "2026-01-17 03:22:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o030t86",
          "author": "Reasonable-Layer1248",
          "text": "Taking everything into account, I use warp+cli or zed, and I think it's not bad.",
          "score": 0,
          "created_utc": "2026-01-17 10:21:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qeufrc",
      "title": "One week with OpenCode Black",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qeufrc/one_week_with_opencode_black/",
      "author": "JohnnyDread",
      "created_utc": "2026-01-16 22:33:35",
      "score": 98,
      "num_comments": 69,
      "upvote_ratio": 0.97,
      "text": "Well, it finally happened. After a week of pretty heavy (but not insane) coding, I finally hit my weekly quota with OpenCode Black. Very comparable experience to Claude Code Max but with access to more models. If OpenCode can keep this up and continue providing the same level of usage, this will be one of the best subscription values out there.... if\n\nedit: lots of questions:\n\n* I am using the top-tier 20X plan ($200/mo).\n* Some days I was working all day from before dawn till well late into the night. Other days I had meetings and other distractions, so on average, about 6-8 hours a day. \n* I don't do the silly 10 agents generating tons of slop thing. I iterate with the LLM on detailed specifications and get one or two agents working on those. While those are running, I review code, test, and sometimes use a third agent for small tasks. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qeufrc/one_week_with_opencode_black/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o01gdqe",
          "author": "jovialfaction",
          "text": "I don't understand the economics of it. Anthropic can offer Claude Code at this price because they run the model and inference doesn't actually cost as much as the advertised API price. \n\nBut how can OpenCode do it? They have to pay the API provider, so the only way to make a profit is to hope the user uses less than the cost of the tokens?",
          "score": 22,
          "created_utc": "2026-01-17 02:46:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02c83j",
              "author": "whimsicaljess",
              "text": "So long as people aren't running ralph loops or other insane shit, these monthly subs are probably generally profitable or at least break even.",
              "score": 6,
              "created_utc": "2026-01-17 06:34:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o081zfi",
              "author": "philosophical_lens",
              "text": "Anomaly is backed by YC and a bunch of other big name Silicon Valley VCs. The most plausible theory is that they are burning VC money on Opencode black to gain marketshare. \n\nhttps://sst.dev/about/",
              "score": 2,
              "created_utc": "2026-01-18 02:45:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09d2xs",
                  "author": "DutyPlayful1610",
                  "text": "A lot of the companies also give out free credits, so people burn them.",
                  "score": 1,
                  "created_utc": "2026-01-18 08:26:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0akvxz",
              "author": "Ordinary-You8102",
              "text": "Thats actually the dream of every company like anthropic. they sell the API for enterprises for cheaper, they realize not everyone will use their agents but this way they get a higher share of the market.",
              "score": 1,
              "created_utc": "2026-01-18 14:19:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o02bjla",
              "author": "t4a8945",
              "text": "My theory is that they're buying a bunch of Claude Max 20 and similar \"cheap\" subscriptions, and we're basically paying to access the models without having to manage the lifecycle of the accounts.\n\n\nI mean... That's actually genius.¬†\n\n\nI hope that's what they do.¬†",
              "score": -5,
              "created_utc": "2026-01-17 06:28:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o04uhn6",
                  "author": "RegrettableBiscuit",
                  "text": "Ain't no way. Anthropic would shut them down before you could say \"TOS violation.\"¬†",
                  "score": 3,
                  "created_utc": "2026-01-17 17:04:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o08f8oj",
                  "author": "AkiDenim",
                  "text": "Just how naive is this opinion? Lmao",
                  "score": 1,
                  "created_utc": "2026-01-18 04:01:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o00gpjg",
          "author": "koddajr",
          "text": "6 days using opus 4.5? how many hours for day? parallel agents or a single instance?",
          "score": 14,
          "created_utc": "2026-01-16 23:11:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01y4jv",
              "author": "JohnnyDread",
              "text": "Mostly Opus. 6-8hr/day. 1-2 agents typically , rarely 3.",
              "score": 12,
              "created_utc": "2026-01-17 04:44:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o00kxul",
          "author": "alOOshXL",
          "text": "What sub  20 or max 5 on opencode black?",
          "score": 10,
          "created_utc": "2026-01-16 23:35:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01yeve",
              "author": "JohnnyDread",
              "text": "20 ($200/mo)",
              "score": 2,
              "created_utc": "2026-01-17 04:46:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o00e6zg",
          "author": "Firm_Meeting6350",
          "text": "Interesting, thanks for sharing. Can the sub only be used for opencode?",
          "score": 16,
          "created_utc": "2026-01-16 22:58:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00fuoc",
              "author": "t4a8945",
              "text": "That's such a meta comment. Great thinking. I hope so haha¬†",
              "score": 3,
              "created_utc": "2026-01-16 23:06:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00r0x1",
                  "author": "ZeSprawl",
                  "text": "No they don‚Äôt limit where it can be used",
                  "score": 3,
                  "created_utc": "2026-01-17 00:09:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0172fp",
              "author": "anfelipegris",
              "text": "That's a loaded comment, I love it!",
              "score": 1,
              "created_utc": "2026-01-17 01:47:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o01f6gy",
          "author": "fuyao_j",
          "text": "https://preview.redd.it/2kegl65jntdg1.png?width=2474&format=png&auto=webp&s=472d382a24ea306c47cc1477049f077b199b4ec8\n\nSharing my experience. I used it with oMo.",
          "score": 7,
          "created_utc": "2026-01-17 02:38:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01y2uq",
              "author": "Background_Might_700",
              "text": "Thanks for the share. Are you using the $200 Opencode Black plan?",
              "score": 2,
              "created_utc": "2026-01-17 04:44:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0274gg",
                  "author": "fuyao_j",
                  "text": "Yup, $200 plan.  \nAs for me limits are crazy generous right now, it feels too good to last.",
                  "score": 1,
                  "created_utc": "2026-01-17 05:51:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o081hfl",
              "author": "philosophical_lens",
              "text": "How do you get this dashboard?",
              "score": 2,
              "created_utc": "2026-01-18 02:42:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0c9p7v",
                  "author": "fuyao_j",
                  "text": "From this package [https://github.com/junhoyeo/tokscale](https://github.com/junhoyeo/tokscale)",
                  "score": 2,
                  "created_utc": "2026-01-18 19:13:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o00awt7",
          "author": "jpcaparas",
          "text": "\\> Very comparable experience to Claude Code Max\n\nA bit more generous in your opinion? Or pretty much the same.",
          "score": 4,
          "created_utc": "2026-01-16 22:41:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03lrtc",
              "author": "seaweeduk",
              "text": "Not taking a shot at the black plans, I'm on the waitlist and will cancel my anthropic plan as soon as they make a $100 option available. But there is a 0% chance any black plan will come close with the amount of tokens you can get out of Anthropic's plans. I'm on 5x Pro $100 plan this month I got $1189 usage out of a $100 sub without even once hitting my 5 hour or 7 day limits. Looking at previous months 10x - 15x value has been common for me.\n\nZen cannot compete with this they would lose far too much money as they have to pay the inflated API prices that effectively subsidize these plans. \n\nhttps://preview.redd.it/22zk8ngrswdg1.png?width=1300&format=png&auto=webp&s=4b0961d2012177afe2080f4f26fa3d22509538a5",
              "score": 3,
              "created_utc": "2026-01-17 13:14:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o07gj1m",
                  "author": "lundrog",
                  "text": "What plugin or etc is that? I would like to try it",
                  "score": 3,
                  "created_utc": "2026-01-18 00:51:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o03s0w8",
                  "author": "foolsgold1",
                  "text": "What makes you think they are paying the retail API price?",
                  "score": 2,
                  "created_utc": "2026-01-17 13:52:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o01yi0s",
              "author": "JohnnyDread",
              "text": "Seemed about the same, honestly. Maybe a little more generous, but I didn't keep meticulous track of my Claude usage when I had it.",
              "score": 1,
              "created_utc": "2026-01-17 04:47:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o00j2h5",
          "author": "Lumpy-Carob",
          "text": "Thats good to know and thank you for sharing -   \nIt would be useful to share token usage with tools like  ccusage or something similar \n\n\\`npx @ ccusage/opencode@latest\\`    [https://ccusage.com/guide/opencode/](https://ccusage.com/guide/opencode/)  \n\nPS: I have no affiliation with ccusage",
          "score": 4,
          "created_utc": "2026-01-16 23:24:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00rpe1",
          "author": "SlaveZelda",
          "text": "What Opencode Black Sub? 20, 100 or 200?",
          "score": 5,
          "created_utc": "2026-01-17 00:13:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01ygyf",
              "author": "JohnnyDread",
              "text": "The highest tier - $200/mo",
              "score": 1,
              "created_utc": "2026-01-17 04:46:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o00sle3",
          "author": "Background_Might_700",
          "text": "Did you use oh-my-opencode with this?",
          "score": 5,
          "created_utc": "2026-01-17 00:18:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0888ar",
              "author": "Apart-Permission-849",
              "text": "Would like to see a config if possible",
              "score": 1,
              "created_utc": "2026-01-18 03:20:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o00trgf",
          "author": "FlyingDogCatcher",
          "text": "I hope these guys kick ass",
          "score": 5,
          "created_utc": "2026-01-17 00:25:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00kyii",
          "author": "LostLakkris",
          "text": "I signed up within 30minutes the tweet.\n\nI'm still waiting for activation :-(",
          "score": 5,
          "created_utc": "2026-01-16 23:35:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00r4au",
              "author": "ZeSprawl",
              "text": "The tweet from last week or this week?",
              "score": 1,
              "created_utc": "2026-01-17 00:10:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00vgc1",
                  "author": "LostLakkris",
                  "text": "The GA tweet, think that's this week.",
                  "score": 2,
                  "created_utc": "2026-01-17 00:35:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o00ahch",
          "author": "ReporterCalm6238",
          "text": "How much Opus 4.5 was included?",
          "score": 2,
          "created_utc": "2026-01-16 22:39:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00aot0",
              "author": "JohnnyDread",
              "text": "That's pretty much all I use. I experimented with some other models. They just added Codex 5.2 yesterday, so I did a little bit with it, but pretty much everything else was with Opus.",
              "score": 2,
              "created_utc": "2026-01-16 22:40:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o00uniq",
          "author": "Lyuseefur",
          "text": "Waiting for my CC to run out then will get this one. Going to not renew my Codex either",
          "score": 2,
          "created_utc": "2026-01-17 00:30:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00xveu",
              "author": "Fit-Palpitation-7427",
              "text": "Because opencode with opus is better then cc and opus?",
              "score": 1,
              "created_utc": "2026-01-17 00:49:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00y6jy",
                  "author": "Lyuseefur",
                  "text": "Yes",
                  "score": 3,
                  "created_utc": "2026-01-17 00:51:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o04faff",
          "author": "warner_lyricist",
          "text": "They are attracting people with higher limits but will need to adjust , there‚Äôs no way they can give same opus usage as anthropic, let‚Äôs be realistic",
          "score": 2,
          "created_utc": "2026-01-17 15:53:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08mlq3",
          "author": "jNSKkK",
          "text": "This looks very promising. Annoying that the waitlist isn't determinate though. My Claude Code runs out today and I can't afford to get on the waitlist, renew CC then a week later have to pay for Black because I got in.\n\nAnyone used the $100 plan and can comment on usage?",
          "score": 2,
          "created_utc": "2026-01-18 04:49:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00q221",
          "author": "mattparlane",
          "text": "Thanks for sharing, I'm on the waitlist.\n\nDoes anyone have any idea how long the waitlist is?\n\nI feel like this might be a tight business model for them. The model providers can spread load across their entire system and adjust limits as their hardware allows, but players like OpenCode will be paying API pricing (possibly with an enterprise discount) on every token. Hope it lasts.",
          "score": 1,
          "created_utc": "2026-01-17 00:04:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o015han",
          "author": "blu38berry",
          "text": "More details please",
          "score": 1,
          "created_utc": "2026-01-17 01:36:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o041h7q",
          "author": "Busy-Chemistry7747",
          "text": "The thing I'm missing are projects and memory for non coding actions. The whole package is pretty good for Claude. If there was an easy (and probably local?) Replacement I'd switch",
          "score": 1,
          "created_utc": "2026-01-17 14:44:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o075nxr",
          "author": "matija2209",
          "text": "How can your brains process all the code outputted?",
          "score": 1,
          "created_utc": "2026-01-17 23:53:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0kfkm3",
              "author": "Price-Visual",
              "text": "who reads code anymore",
              "score": 1,
              "created_utc": "2026-01-19 23:15:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0al423",
          "author": "Ordinary-You8102",
          "text": "is it really worth it? 200$/month sound like a lot considering you have other models with \"unlimited usage\" for 10-50$? or is it cause claude is that good?",
          "score": 1,
          "created_utc": "2026-01-18 14:20:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0as50t",
              "author": "JohnnyDread",
              "text": "There are no \"unlimited usage\" plans. All subscriptions have some sort of hourly/weekly cap or throttle. OpenCode Black and previously Claude Code Max are well worth it to me because I'm certainly going to spend at least $200/month if I were paying by the token. And if these plans give me any kind of a discount, even a small one, it's worth it.",
              "score": 1,
              "created_utc": "2026-01-18 14:59:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0beecr",
                  "author": "Ordinary-You8102",
                  "text": "GH Copilot/Codex/Gemini oauth isnt way more?",
                  "score": 1,
                  "created_utc": "2026-01-18 16:47:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qcsm90",
      "title": "OpenCode Black is now generally-available",
      "subreddit": "opencodeCLI",
      "url": "https://opencode.ai/black",
      "author": "JohnnyDread",
      "created_utc": "2026-01-14 16:57:42",
      "score": 71,
      "num_comments": 63,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qcsm90/opencode_black_is_now_generallyavailable/",
      "domain": "opencode.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nzkotc2",
          "author": "Fearless-Elephant-81",
          "text": "The limits are still vague",
          "score": 27,
          "created_utc": "2026-01-14 17:34:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkp4ce",
              "author": "Hauven",
              "text": "Agreed. Someone mentioned in Discord that they get over $200 per week usage allowance on the top plan I believe. But yeah, the information about these plans are extremely vague so I'll wait for now and see what happens over the coming weeks.",
              "score": 7,
              "created_utc": "2026-01-14 17:35:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqng1y",
                  "author": "edtv82",
                  "text": "I signed up, but I'm not getting charged until it goes live.",
                  "score": 1,
                  "created_utc": "2026-01-15 15:13:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzkqxtr",
              "author": "markis",
              "text": "Maybe they opened this because of that post where someone found the page, and the details just aren‚Äôt figured out yet.",
              "score": 6,
              "created_utc": "2026-01-14 17:44:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzksmap",
              "author": "acmethunder",
              "text": "Yep. $100/month is 5x more usage than what, exactly?",
              "score": 5,
              "created_utc": "2026-01-14 17:51:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nznvfqt",
                  "author": "Ok_Road_8710",
                  "text": "It's 5x more than $20, trust us",
                  "score": 5,
                  "created_utc": "2026-01-15 03:01:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzqhxd8",
                  "author": "dmancilla",
                  "text": "George Washington: Nobody knows",
                  "score": 2,
                  "created_utc": "2026-01-15 14:46:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzksorp",
                  "author": "Fearless-Elephant-81",
                  "text": "Claude is the same tho just saying",
                  "score": 2,
                  "created_utc": "2026-01-14 17:51:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzljfry",
              "author": "hexa01010",
              "text": "Totally, using the 20$ for testing for now, guess the only way is to try for ourselves",
              "score": 6,
              "created_utc": "2026-01-14 19:51:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzppjyn",
                  "author": "jorgejhms",
                  "text": "You already get it? It was fast?",
                  "score": 1,
                  "created_utc": "2026-01-15 11:59:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzn7odk",
              "author": "Ok_Shape_4863",
              "text": "industry standard lmao cant believe people are falling for it\n\n  \nthe people who say \"claude code gives you soooo much more tokens\" are my favorite (literally 0 numbers attached to any aspect of analysis you would need to do to calculate that)",
              "score": 2,
              "created_utc": "2026-01-15 00:44:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqtri9",
                  "author": "Keep-Darwin-Going",
                  "text": "No matter what it will still be cheaper than opencode, you are buying direct from supplier and it is known fact that Claude never give discount to anyone even the biggest enterprise. So this opencode black sustainability is questionable",
                  "score": 1,
                  "created_utc": "2026-01-15 15:43:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzlokda",
              "author": "jpcaparas",
              "text": "If you search Twitter, you'll get a mixed bag of responses from early adopters.",
              "score": 1,
              "created_utc": "2026-01-14 20:14:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzzzuvc",
              "author": "blankeos",
              "text": "super vague, that's why I can't buy yet. I want to support them though. Knowing Dax and the team, they're pretty public about \"experimenting\" w/ pricing and seeing where it goes, hence the \"Limits may be adjusted and plans may be discontinued in the future\"",
              "score": 1,
              "created_utc": "2026-01-16 21:46:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzmj9so",
          "author": "softboyled",
          "text": "\"a lot\"\n\"more than a lot\"\n\"way more than more than a lot\"\n\ngenius",
          "score": 11,
          "created_utc": "2026-01-14 22:34:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznbbfn",
          "author": "WHEREISMYCOFFEE_",
          "text": "I'm a big OpenCode fan but these plans are just silly. There's literally no info on what you get other than \"more usage\" and the whole waitlist thing just screams \"We're burning new subscriber's money to subsidize power users while we hope for enough whales to sign up\". This is all too vague for a tool that needs to be taken seriously.",
          "score": 7,
          "created_utc": "2026-01-15 01:04:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzngmo5",
          "author": "jNSKkK",
          "text": "Anyone tried the $100 plan yet? My Claude Max 5x sub ends in 2 days and I'm sick of it plowing through my usage limits.",
          "score": 6,
          "created_utc": "2026-01-15 01:35:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkphqz",
          "author": "ApocaIypticUtopia",
          "text": "Would be nice to know if they have ZDR with all 3rd party services, similar to Github copilot.",
          "score": 6,
          "created_utc": "2026-01-14 17:37:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzontxk",
              "author": "whamram",
              "text": "Sadly I don't think privacy is going to be a focus of Opencode in the future... I looked through their newest privacy policy and it says basically they can collect any data they want and store it as long as they want and share it with anyone. I was planning on switching to this from Claude, but until they make a statement about privacy and their privacy policy changes I'm sticking with Claude's 30-day policy. [https://opencode.ai/legal/privacy-policy](https://opencode.ai/legal/privacy-policy)",
              "score": 5,
              "created_utc": "2026-01-15 06:17:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzoz2wr",
                  "author": "trypnosis",
                  "text": "I wonder what the wider community thinks. I would put this a post.",
                  "score": 3,
                  "created_utc": "2026-01-15 07:56:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzlasf0",
              "author": "VanPepe",
              "text": "what the hell is ZDR",
              "score": 2,
              "created_utc": "2026-01-14 19:11:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzlqo85",
                  "author": "Downtown-Elevator369",
                  "text": "Zero Data Retention",
                  "score": 4,
                  "created_utc": "2026-01-14 20:24:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nznily4",
              "author": "LostLakkris",
              "text": "I think Zen's consumption list somewhere shows who claims ZDR and who doesn't.\nI think openai and anthropic were in the list as 30 day.",
              "score": 1,
              "created_utc": "2026-01-15 01:46:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzlr8v6",
          "author": "t4a8945",
          "text": "I'm in 100%, will try it out when my Claude Max ends. I'll take the $100 plan and see if it matches my use case. Well done opencode¬†",
          "score": 6,
          "created_utc": "2026-01-14 20:26:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlfpjb",
          "author": "beth_maloney",
          "text": "What's the advantage of this over copilot?",
          "score": 2,
          "created_utc": "2026-01-14 19:34:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzll66d",
              "author": "JohnnyDread",
              "text": "Presumably more usage, but because we don't have visibility into the limits, we just don't know yet.",
              "score": 2,
              "created_utc": "2026-01-14 19:58:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzlxtx5",
                  "author": "kaizoku156",
                  "text": "I don't see how opencode would be able to negotiate a better rate or provide more usage than microsoft with copilot or anthropic themselves with the claude plans, practically no other ai tool provides the same value except the big companies own subscriptions",
                  "score": 3,
                  "created_utc": "2026-01-14 20:56:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzlqj4x",
                  "author": "beth_maloney",
                  "text": "I've always thought that copilot was pretty good value. I think it'll be hard to compete on price with MS and if copilot adds support for opencode then what's the differentiator?",
                  "score": 1,
                  "created_utc": "2026-01-14 20:23:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzn4nlm",
                  "author": "Mr_Hyper_Focus",
                  "text": "Zero chance this allots more usage than copilot. Absolutely 0. I love opencode and the team but this is a pipe dream",
                  "score": 1,
                  "created_utc": "2026-01-15 00:27:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzm6no0",
              "author": "dbkblk",
              "text": "Copilot read all your prompts, there's no privacy. The same for [z.ai](http://z.ai) and Google. It's all written in the TOS.  \nClaude Pro is not supposed to do that (but given the recent decisions, I'm starting to doubt).  \nSynthetic is private, but open models only (glm 4.7 is quite good compared to sonnet 4.5).\n\nLet's wait about how opencode stands with black.",
              "score": 1,
              "created_utc": "2026-01-14 21:36:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzonzhg",
                  "author": "whamram",
                  "text": "It's really not looking too great on the privacy standpoint... [https://opencode.ai/legal/privacy-policy](https://opencode.ai/legal/privacy-policy)",
                  "score": 3,
                  "created_utc": "2026-01-15 06:18:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzth0d5",
                  "author": "touristtam",
                  "text": "Pricing pages (as of Jan 15, 2026)\n\n- [Gemini (Google)](https://gemini.google/subscriptions/)\n- [Copilot (Github)](https://github.com/features/copilot/plans)\n- [z.ai](https://z.ai/subscribe)\n- [Claude (Anthropic)](https://claude.com/pricing)\n- [Synthetic](https://synthetic.new/pricing)\n- [Minimax](https://platform.minimax.io/subscribe/coding-plan)",
                  "score": 1,
                  "created_utc": "2026-01-15 22:59:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o08j24d",
              "author": "Tenet_mma",
              "text": "Probably nothing",
              "score": 1,
              "created_utc": "2026-01-18 04:25:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzm4emn",
          "author": "dartoumi",
          "text": "How to get off the waiting list and being charged automatically?",
          "score": 2,
          "created_utc": "2026-01-14 21:26:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzp2qak",
              "author": "delusional-",
              "text": "Asking the same question. Accidentally signed up for the $200 plan, intended to sign up for the $100 plan, but there is no way to change or cancel it.\n\nUsed link for payment, but the subscription is not visible in their interface either..",
              "score": 1,
              "created_utc": "2026-01-15 08:31:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzpp2b8",
          "author": "teratron27",
          "text": "The UI of that page is horrendous",
          "score": 2,
          "created_utc": "2026-01-15 11:55:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpzst0",
              "author": "vienna_city_skater",
              "text": "Vibe coded to the max",
              "score": 1,
              "created_utc": "2026-01-15 13:09:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzvt9hw",
          "author": "Firm_Curve8659",
          "text": "Black sub is only for OC or possible to use also in other tools?",
          "score": 2,
          "created_utc": "2026-01-16 07:44:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzx9w71",
              "author": "JohnnyDread",
              "text": "That‚Äôs a good question. It would be rather ironic if they disallowed other clients.",
              "score": 2,
              "created_utc": "2026-01-16 14:19:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzksxtz",
          "author": "DasBlueEyedDevil",
          "text": "![gif](giphy|eRqxSA8uc2yas)",
          "score": 2,
          "created_utc": "2026-01-14 17:52:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzp19qb",
          "author": "theTallGiraffee",
          "text": "Will we be able to use opus 4.5, presumably through API and not the subscription?",
          "score": 1,
          "created_utc": "2026-01-15 08:16:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzppy0q",
              "author": "jorgejhms",
              "text": "You already can, with zen, Anthropic or open router.",
              "score": 1,
              "created_utc": "2026-01-15 12:01:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrb4cv",
                  "author": "vienna_city_skater",
                  "text": "Or Azure, or Github Copilot, or ‚Ä¶",
                  "score": 2,
                  "created_utc": "2026-01-15 17:00:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07sqaa",
          "author": "warpedgeoid",
          "text": "How does pricing compare to GitHub Copilot?",
          "score": 1,
          "created_utc": "2026-01-18 01:54:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bz9lu",
          "author": "lemon07r",
          "text": "So.. how much usage is the $20 plan? lmao",
          "score": 1,
          "created_utc": "2026-01-18 18:25:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0cnfpw",
          "author": "Competitive_Drive743",
          "text": "Hey guys on this plan can you use claude opus ?",
          "score": 1,
          "created_utc": "2026-01-18 20:19:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cnu39",
              "author": "JohnnyDread",
              "text": "Yes",
              "score": 1,
              "created_utc": "2026-01-18 20:21:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzp31xe",
          "author": "trypnosis",
          "text": "I liked the leaked 6x and 21x options",
          "score": 1,
          "created_utc": "2026-01-15 08:34:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08is77",
          "author": "Tenet_mma",
          "text": "What is with all these weird plans‚Ä¶ 5x more 20x more. Is this marketing or just an easy way to make money by varying rate limits??",
          "score": 0,
          "created_utc": "2026-01-18 04:23:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzktw4l",
          "author": "Hodler-mane",
          "text": "I thought this was OPEN code. an open source, community built, free harness for various AI models. sick of people selling out for this.",
          "score": -11,
          "created_utc": "2026-01-14 17:57:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkxpuc",
              "author": "JohnnyDread",
              "text": "OpenCode is still open source, and you can still use it with the models and providers of your choice.",
              "score": 9,
              "created_utc": "2026-01-14 18:14:07",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzkxyr3",
              "author": "Aggressive-Habit-698",
              "text": "It's only the zen provider. OC itself is open source - see GitHub repo. Nothing changed.\nWhat's your suggestion to earn money? At least to break even.",
              "score": 7,
              "created_utc": "2026-01-14 18:15:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzl6lvh",
                  "author": "DasBlueEyedDevil",
                  "text": "Sell t-shirts, obv",
                  "score": 2,
                  "created_utc": "2026-01-14 18:53:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzlqgnd",
          "author": "Magnus114",
          "text": "Time to stop using open code. \n\nI really liked the idea if an open ai coding software that didn‚Äôt favor any provider.",
          "score": -9,
          "created_utc": "2026-01-14 20:23:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdylr7",
      "title": "oh-my-opencode is great, just I think got a bit bloated, so here is slimmed forked",
      "subreddit": "opencodeCLI",
      "url": "https://github.com/alvinunreal/oh-my-opencode-slim",
      "author": "alvinunreal",
      "created_utc": "2026-01-15 22:52:47",
      "score": 64,
      "num_comments": 31,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qdylr7/ohmyopencode_is_great_just_i_think_got_a_bit/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzzw0ag",
          "author": "N2siyast",
          "text": "Never understood people using these bloated bullshit frameworks. Few custom agents, few custom prompts and minimum skills with some security hooks is more than enough",
          "score": 3,
          "created_utc": "2026-01-16 21:28:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0043o8",
              "author": "alvinunreal",
              "text": "https://preview.redd.it/zgqqbuaibsdg1.png?width=1600&format=png&auto=webp&s=80a7f70b2fec3dc36e57a25d7de4d17565899dd8",
              "score": 1,
              "created_utc": "2026-01-16 22:07:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzv1459",
          "author": "[deleted]",
          "text": "OMO is useless. It modifies files in planner mode.",
          "score": 6,
          "created_utc": "2026-01-16 04:12:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzz20rf",
              "author": "DirtyIlluminati",
              "text": "Name a better alternative to delegate task to sub-agents and orchestrate the  whole thing ?",
              "score": 4,
              "created_utc": "2026-01-16 19:08:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0b9w76",
                  "author": "kkordikk",
                  "text": "Isn‚Äôt OpenCode doing this on its own? Just like CC?",
                  "score": 1,
                  "created_utc": "2026-01-18 16:25:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0241cy",
                  "author": "[deleted]",
                  "text": "No, I don't know.\n\nMaybe agenticseek?",
                  "score": 0,
                  "created_utc": "2026-01-17 05:27:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzvnlp6",
          "author": "ImTheDeveloper",
          "text": "Very interesting to see this come up. \n\nI've been a big omo fan but the v3 orchestrator branch I tested out felt super heavy and bloated. I think omo pre jan was the sweet spot for me. The balance really was deep planning and simple execution, but now the planning and execution both feel bloated out and heavy with waterboarding token usage. \n\nI've since reverted back to standard open code and I'm just a bit more picky on model selection dependent on the use case. I miss the deeper planning modes but you can get around that with more explicit promoting as well as using memory plugins. \n\nI'll likely take more inspiration from it but I agree it's gone a little over the top in its most recent incarnations",
          "score": 3,
          "created_utc": "2026-01-16 06:55:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwld5d",
              "author": "alvinunreal",
              "text": "probably everyone should maintain own fork; it's worth it",
              "score": 1,
              "created_utc": "2026-01-16 11:52:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nztvujq",
          "author": "KnifeDev",
          "text": "This is a bit too barebones for my taste, so here‚Äôs my fork called oh-my-Goldilocks : \n\n\n\nKidding lol",
          "score": 7,
          "created_utc": "2026-01-16 00:19:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztk0b6",
          "author": "smile132465798",
          "text": "Is anyone else seeing oh-my-opencode constantly spawn the explore and librarian agents even when it‚Äôs idle?",
          "score": 2,
          "created_utc": "2026-01-15 23:15:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwb7uj",
              "author": "Michaeli_Starky",
              "text": "![gif](giphy|4EIOCwkztiPhS)",
              "score": 0,
              "created_utc": "2026-01-16 10:28:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzwhrqm",
          "author": "aeroumbria",
          "text": "> 5,173 lines\n\nWTF? Do people seriously pack this many information into system and agent prompts, expecting the agent to actually follow every line? At this rate we are burning like half the context window with everything loaded before even acting on anything! \n\nI put more trust into workflows that make a conscious effect to target sub-500 or even 300 line agent instruction files. Lightweight prompt and focused context IMO is much more reliable than dictionary promoting.",
          "score": 2,
          "created_utc": "2026-01-16 11:24:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwl93b",
              "author": "alvinunreal",
              "text": "agree - also steering direction too much is wrong; I get better results to leave sensible choice to AI;",
              "score": 1,
              "created_utc": "2026-01-16 11:51:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzxxkxb",
          "author": "YouTerrible3465",
          "text": "Nice \\~\\~\\~\\~",
          "score": 2,
          "created_utc": "2026-01-16 16:10:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o006p7g",
          "author": "alvinunreal",
          "text": "https://preview.redd.it/5owsbjbsdsdg1.png?width=2522&format=png&auto=webp&s=93345ba6faf682c001bcb56ddfead9f07cb4aef1\n\nTmux integration for spawned agents is just added:",
          "score": 2,
          "created_utc": "2026-01-16 22:20:07",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o05if8i",
          "author": "Mental_State1",
          "text": "Why not Gemini 3 flash high for explorer instead of glm4.6? Since you‚Äôre using antigravity anyways",
          "score": 2,
          "created_utc": "2026-01-17 18:55:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o069p0i",
              "author": "alvinunreal",
              "text": "glm in cerebras does 1k token p/s - flash would work well too",
              "score": 1,
              "created_utc": "2026-01-17 21:11:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nztxxh1",
          "author": "bazeso64",
          "text": "Nice ! Can we have a TLDR of what you slimmed down ?",
          "score": 1,
          "created_utc": "2026-01-16 00:30:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvsbss",
              "author": "alvinunreal",
              "text": "added more info",
              "score": 2,
              "created_utc": "2026-01-16 07:35:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzu87xp",
          "author": "girth_armstrong420",
          "text": "I agree, it's powerful but extremely token expensive",
          "score": 1,
          "created_utc": "2026-01-16 01:27:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvte6o",
              "author": "alvinunreal",
              "text": "Few reasons:  \n\\- [https://github.com/code-yeongyu/oh-my-opencode/blob/dev/src/agents/orchestrator-sisyphus.ts#L150](https://github.com/code-yeongyu/oh-my-opencode/blob/dev/src/agents/orchestrator-sisyphus.ts#L150)  \n\\- [https://github.com/code-yeongyu/oh-my-opencode/blob/dev/src/features/builtin-skills/skills.ts](https://github.com/code-yeongyu/oh-my-opencode/blob/dev/src/features/builtin-skills/skills.ts)  \n\\- [https://github.com/code-yeongyu/oh-my-opencode/blob/dev/src/hooks/todo-continuation-enforcer.ts](https://github.com/code-yeongyu/oh-my-opencode/blob/dev/src/hooks/todo-continuation-enforcer.ts)",
              "score": 2,
              "created_utc": "2026-01-16 07:45:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzxva4i",
          "author": "oh_my_right_leg",
          "text": "\"**Alternative: Ask any coding agent**\n\nPaste this into Claude Code, AmpCode, Cursor, or any coding agent:\" hmmmm did you forget opencode in that list by any chance?",
          "score": 1,
          "created_utc": "2026-01-16 16:00:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01ude2",
          "author": "Sizzin",
          "text": "I haven't tried omo yet, but the first thing I did after installing OpenCode was to uninstall it, download the source code and run directly from it. I created a new agent with less than 300 tokens of system prompt and modified the code to add a function that allows me to enable/disable tools on the fly like MCP. Not the cleanest way, but it works for me. It feels so wasteful asking simple questions when a \"hi\" becomes 10k+ tokens.\n\nImagine if we still had the mentality of optimizing things to the utmost, like when whole games were less than 32kb. Nowadays, the \"solution\" to every problem is to throw more RAM at it. Great initiative, OP.",
          "score": 1,
          "created_utc": "2026-01-17 04:17:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02yrpe",
          "author": "MonsieurHen",
          "text": "how did you decide what models to apply to the different agents? ive made gpt 5.2 the orchestrator for example",
          "score": 1,
          "created_utc": "2026-01-17 10:02:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a1fu6",
          "author": "Upset_Cellist6256",
          "text": "It isn‚Äôt useful as long as anthropic bans the opus usage",
          "score": 1,
          "created_utc": "2026-01-18 12:08:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c5495",
          "author": "[deleted]",
          "text": "I uninstalled Omo because it kept asking for permissions for every single bash command.",
          "score": 1,
          "created_utc": "2026-01-18 18:51:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdjils",
      "title": "OpenCode can now officially be used with your Github Copilot subscription",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qdjils/opencode_can_now_officially_be_used_with_your/",
      "author": "oronbz",
      "created_utc": "2026-01-15 13:29:02",
      "score": 62,
      "num_comments": 21,
      "upvote_ratio": 0.97,
      "text": "https://x.com/opencode/status/2011790750543983072?s=46&t=qDZ1ZcysBZTELeU-YCj3kg",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qdjils/opencode_can_now_officially_be_used_with_your/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nzq5vcc",
          "author": "t4a8945",
          "text": "Open ecosystem wins again. Anthropic L¬†",
          "score": 19,
          "created_utc": "2026-01-15 13:43:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqt6vy",
          "author": "External_Egg2098",
          "text": "Has anybody used it ?\n\n\nHow does the copilot pro+ (39 dollar) plan compare with claude code 20 dollar plan ? \n\nWill I get the same limit and the context size for sonnet-4.5 ?",
          "score": 6,
          "created_utc": "2026-01-15 15:40:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrbipl",
              "author": "vienna_city_skater",
              "text": "128k context size and a bit of slow during business hours, but else good value.\nEDIT: it was slow yesterday, but today it was fine, maybe the official support changed something¬†",
              "score": 4,
              "created_utc": "2026-01-15 17:02:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzusvin",
              "author": "mynameis_twat",
              "text": "Context size is reduced but that‚Äôs not that bad. The thing I don‚Äôt hear get talked about as often is they must do some fine tuning or temperature adjustments or something which makes it rush to a response and hallucinate more I‚Äôve noticed. At least in regards to Opus, sonnet, and gpt 5.2. I also use antigravity models in opencode and found their versions to be similarly downgraded but not as bad.",
              "score": 1,
              "created_utc": "2026-01-16 03:23:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzuzoj6",
                  "author": "toadi",
                  "text": "I have been using these github models with opencode for the last 6 months. The context size was not an issue. Also I think the cutoff date of training is different over the official models. But again not a big issue in performance.",
                  "score": 1,
                  "created_utc": "2026-01-16 04:03:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrvfxz",
          "author": "jpcaparas",
          "text": "This is a bigger deal in the enterprise than we think. I followed up with them if they would accept .ghe.com domains at some point.",
          "score": 2,
          "created_utc": "2026-01-15 18:31:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwp4ik",
          "author": "Reasonable-Tower21",
          "text": "I have used it with my copilot sub for weeks - what changed ?",
          "score": 1,
          "created_utc": "2026-01-16 12:19:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzy591h",
              "author": "cenderis",
              "text": "It's officially, publicly allowed now.",
              "score": 1,
              "created_utc": "2026-01-16 16:44:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzqhkco",
          "author": "Historical-Internal3",
          "text": "official by whose standard lol - opencode's or github's?\n\nany announcement of this from github copilot? even a tweet would work\n\nhate that I have to ask this now.",
          "score": 0,
          "created_utc": "2026-01-15 14:45:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqk3r4",
              "author": "edtv82",
              "text": "https://x.com/jaredpalmer/status/2011803160122097826?s=20\n\nJared Palmer is SVP of @GitHub and VP CoreAI @Microsoft",
              "score": 4,
              "created_utc": "2026-01-15 14:57:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqk8e1",
                  "author": "Historical-Internal3",
                  "text": "sick, ty",
                  "score": 0,
                  "created_utc": "2026-01-15 14:58:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrxd51",
              "author": "EduardoDevop",
              "text": "Both\n\n[https://x.com/opencode/status/2011790750543983072](https://x.com/opencode/status/2011790750543983072)  \n[https://x.com/github/status/2011822451613712646](https://x.com/github/status/2011822451613712646)",
              "score": 1,
              "created_utc": "2026-01-15 18:40:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzqkkk4",
              "author": "Y_ssine",
              "text": "[https://x.com/jaredpalmer/status/2011803160122097826](https://x.com/jaredpalmer/status/2011803160122097826)\n\nHere's the announcement from github",
              "score": 1,
              "created_utc": "2026-01-15 14:59:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzqyk4i",
          "author": "MissingHand",
          "text": "I‚Äôve been using it but they did make me reauthenticate yesterday.",
          "score": 0,
          "created_utc": "2026-01-15 16:04:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztgfrn",
              "author": "not-yummy-foo",
              "text": "which subscription on GH Copilot?",
              "score": 1,
              "created_utc": "2026-01-15 22:56:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzuztd3",
                  "author": "toadi",
                  "text": "I use the 19 dollar business one. I re-authenticated and it kept working,",
                  "score": 1,
                  "created_utc": "2026-01-16 04:04:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qdttn0",
      "title": "GitHub Just Made OpenCode Official. Here‚Äôs Why That‚Äôs a Bigger Deal Than You Think.",
      "subreddit": "opencodeCLI",
      "url": "https://jpcaparas.medium.com/github-just-made-opencode-official-heres-why-that-s-a-bigger-deal-than-you-think-ed1610660c40",
      "author": "jpcaparas",
      "created_utc": "2026-01-15 19:51:19",
      "score": 53,
      "num_comments": 23,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qdttn0/github_just_made_opencode_official_heres_why/",
      "domain": "jpcaparas.medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzvh1gv",
          "author": "chiroro_jr",
          "text": "This just goes to show what a mistake Anthropic made. They lose nothing by letting people use the Claude Code sub with Opencode. It's not like the person is no longer paying. They still pay the same sub. Unless maybe they are collecting data when people use Claude Code then I'd understand the incentive to keep people in there. Otherwise I don't understand it. Claude Code is just a harness for the most part. It's not like usage changes for the same plan just because you used Opencode. I am glad GitHub, OpenAI, and other companies are embracing Opencode and all the other open harnesses. It's good.",
          "score": 19,
          "created_utc": "2026-01-16 06:02:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvqlhf",
              "author": "SecureHunter3678",
              "text": "At this point I start to belive claude code is spyware, the way they are trying to push that thing on peoples computer. Hell. It is obfuscated like one for sure.",
              "score": 7,
              "created_utc": "2026-01-16 07:20:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvyord",
                  "author": "chiroro_jr",
                  "text": "Imagine. I don't think they should be doing that. Imagine paying 200$ every month and being told oh you have to use only this tool instead of having the option to use the best tool available. Arguably opencode is a better TUI than Claude Code. For me, it's a better harness too but I guess that's subjective. If I'm paying 200$ every month I need the option to choose.",
                  "score": 2,
                  "created_utc": "2026-01-16 08:32:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o067pjb",
                  "author": "rpatel09",
                  "text": "You do know Claude code is open source so you can literally see how the whole thing works‚Ä¶",
                  "score": -2,
                  "created_utc": "2026-01-17 21:00:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzwja2c",
              "author": "revilo-1988",
              "text": "Well, companies try to secure monopolies as long as things are going well; you can see that in all companies that are in such a position.",
              "score": 2,
              "created_utc": "2026-01-16 11:36:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzvs20z",
              "author": "warpedgeoid",
              "text": "Anthropic is apparently losing money on most subscribers. It‚Äôs all being subsidized by VC money.",
              "score": 2,
              "created_utc": "2026-01-16 07:33:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvyi8q",
                  "author": "chiroro_jr",
                  "text": "Yes. But do they stop losing money because it's Claude Code. No. They still lose the same money. Both Claude Code and Opencode are just harnesses. So I don't see how it matters which one you use if they are both using the same subscription.   They are killing the good faith they have with developers and other companies are taking advantage of that. Building a walled garden is a bad move in terms of AI I think.",
                  "score": 3,
                  "created_utc": "2026-01-16 08:31:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o03lgq2",
              "author": "XMojiMochiX",
              "text": "It‚Äôs because of telemetry I assume",
              "score": 1,
              "created_utc": "2026-01-17 13:12:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03nxis",
                  "author": "chiroro_jr",
                  "text": "Well that's a better reason than oh our costs and our infrastructure that I've been seeing from other users here. Fair play to them I guess even though I still think it's a mistake. Developers are probably most of their revenue. So burning any good will you have with your largest user base seems like a bad move.",
                  "score": 0,
                  "created_utc": "2026-01-17 13:28:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzw6ngj",
          "author": "getaway-3007",
          "text": "As of right now please don't use this because copilot works on the request model. I don't know how but Copilot chat does some requests batching mechanism which opencode or any other AI agent doesn't do, so you would quickly consume your usage 2-5 times faster as compared to the official Copilot chat extension. \n\nThe opencode twitter did mention they're working on it but until then it's not recommended to use copilot+opencode",
          "score": 7,
          "created_utc": "2026-01-16 09:47:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw7j82",
              "author": "jpcaparas",
              "text": "Good mention.\n\nLink to tweet: [https://x.com/opencode/status/2011871721758904782?s=20](https://x.com/opencode/status/2011871721758904782?s=20)",
              "score": 2,
              "created_utc": "2026-01-16 09:55:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzwba1s",
          "author": "Keep-Darwin-Going",
          "text": "Claude force you to use their cli because they want you to remember their presence and branding and thus justify subsidising. Most people do not understand that two things matters the model and harness, and when they see video showing opencode instead of cc they are missing the exposure.",
          "score": 7,
          "created_utc": "2026-01-16 10:29:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c686t",
          "author": "Da_ha3ker",
          "text": "Anthropic wants a walled garden. Makes sense if you think about it. Make the tool difficult to switch off of and you keep customers who would want to switch to the next best thing but don't because it is too difficult to do so. Looking at you Microsoft and Apple. The problem is they are not dealing with regular consumers, they are still in the early adoper phase, though less so now, but still early. Those same people who decided to give up their workflow and try Claude code because it was better than what they had are literally the ones who switch more often. Early adopters are flighty. Anthropic is trying to tie down early adopters, when all the early adopters care about is the next best tool, even if it can be a pain to move on. Opencode provides a platform to remove some of that pain.\n\nTLDR: Anthropic is trying to tie down the early adoper crowd by locking them to their software, which doesn't for early adopters. Opencode provides a better early adopter experience.",
          "score": 2,
          "created_utc": "2026-01-18 18:56:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qd6glz",
      "title": "Anthropic explicitly blocks OpenCode in oauth",
      "subreddit": "opencodeCLI",
      "url": "https://news.ycombinator.com/item?id=46625918",
      "author": "Old-School8916",
      "created_utc": "2026-01-15 01:52:37",
      "score": 52,
      "num_comments": 42,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qd6glz/anthropic_explicitly_blocks_opencode_in_oauth/",
      "domain": "news.ycombinator.com",
      "is_self": false,
      "comments": [
        {
          "id": "nznyhwr",
          "author": "Trustingmeerkat",
          "text": "I only found out about open code via all this drama. Glad I did",
          "score": 37,
          "created_utc": "2026-01-15 03:19:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzobkak",
              "author": "noiserr",
              "text": "The Streisand Effect strikes again.",
              "score": 21,
              "created_utc": "2026-01-15 04:44:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzpe428",
              "author": "Yarden-zamir",
              "text": "Same lol",
              "score": 3,
              "created_utc": "2026-01-15 10:21:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzt3v5e",
              "author": "BERLAUR",
              "text": "Same here and I cancelled Claude Code and went to Codex & Z.ai by recommendations of the community.¬†\n\n\nGlad I did!",
              "score": 2,
              "created_utc": "2026-01-15 21:55:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nznlxtn",
          "author": "Sensitive_Song4219",
          "text": "Frustrating but so be it. \n\nOptions:\n\nSwap to Anthropic API use and forgo your plan (this is expensive)\n\nSwap to Claude Code (have fun dealing with non-stop flicker! Though CC is still a good harness to be fair)\n\nSwap to Codex (OpenAI explicitly *allows* ChatGPT plan use in OpenCode). Codex 5.2 Medium is similar to Sonnet. Codex 5.2 High and especially x-high give Opus a run for its money. Usage limits on Codex are more generous than Anthropic's equivalent plans.\n\nThrow in something like GLM 4.7 for Sonnet-level performance for very little cash.",
          "score": 21,
          "created_utc": "2026-01-15 02:05:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznw41w",
              "author": "EnvironmentalLet9682",
              "text": "i actually only heard about opencode through the claude controversy. made me quit my max plan for now. i am testing codex right now and it seems to be pretty good.",
              "score": 11,
              "created_utc": "2026-01-15 03:05:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzo5cn7",
                  "author": "Ang_Drew",
                  "text": "Welcome aboard!\nAnthropic‚Äôs fan base is often biased and does not recognize how capable GPT-5.2 is. This may remain the case until Anthropic makes a significant mistake, at which point its market share could gradually shift toward OpenAI.",
                  "score": 9,
                  "created_utc": "2026-01-15 04:02:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzoefnw",
              "author": "james__jam",
              "text": "Swap to a different provider like Antigravity. \n\nAs far as I can tell from their [terms and conditions](https://antigravity.google/terms), there‚Äôs no mention that it‚Äôs not allowed. \n\nIm not a lawyer though",
              "score": 2,
              "created_utc": "2026-01-15 05:05:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzoshuf",
                  "author": "Top-Faithlessness758",
                  "text": "I would expect Google to not care about which harness you are using.",
                  "score": 2,
                  "created_utc": "2026-01-15 06:57:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nznth5r",
              "author": "Darth-Mary-J",
              "text": "What about nanocoder?",
              "score": 1,
              "created_utc": "2026-01-15 02:49:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzo8ikb",
              "author": "0xraghu",
              "text": "Is codex-cli that bad compared to opencode?",
              "score": 1,
              "created_utc": "2026-01-15 04:23:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzoyttb",
              "author": "Flanhare",
              "text": "I use CC a lot and have no flicker. What OS and terminal?",
              "score": 1,
              "created_utc": "2026-01-15 07:54:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqjhcm",
                  "author": "Sensitive_Song4219",
                  "text": "Happens to me about about twice-a-day under both Windows (CLI via both cmd + ps) and Linux (also CLI) but it's been [reported on Mac](https://www.reddit.com/r/ClaudeCode/comments/1mpufgs/i_think_ive_found_a_way_to_prevent_claude_codes/) as well. Most commonly happens (to me at least) after it displays a plan; and it seems more likely to happen when the term is not full screen especially if it's width-constrained. Still love CC (don't get me wrong - it's my favourite CLI) but the devs themselves have [aknowledged it](https://x.com/trq212/status/2001439019713073626), so it's not an uncommon issue.",
                  "score": 1,
                  "created_utc": "2026-01-15 14:54:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzp8kyq",
              "author": "lopydark",
              "text": "codex 20 usd plan is indeed more generous than claude 20 usd plan, but what about the 200 usd plan? I heard claude gives more value for this plan than openai",
              "score": 1,
              "created_utc": "2026-01-15 09:28:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzsvaip",
                  "author": "EnvironmentalLet9682",
                  "text": "I'm just surprised there's no 100$ plan for openai. The jump from 20 to 230 or whatever it was seems kinda extreme.",
                  "score": 1,
                  "created_utc": "2026-01-15 21:16:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzythlw",
              "author": "Yogesh991",
              "text": "I am using it with API and I don't what sorcery Opencode is, but it's so much better than Claude Code in doing stuff. \n\nBut I have spent around 300 usd this week. üòú",
              "score": 1,
              "created_utc": "2026-01-16 18:31:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzo3xa5",
              "author": "amplifyoucan",
              "text": "You spelled Gemini wrong",
              "score": 0,
              "created_utc": "2026-01-15 03:53:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzop11k",
                  "author": "warpedgeoid",
                  "text": "Honestly, you need a ensemble of models. GPT is good for big picture, Gemini for UX, and Claude for coding grunt work.",
                  "score": 1,
                  "created_utc": "2026-01-15 06:27:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsuwm9",
                  "author": "EnvironmentalLet9682",
                  "text": "Idk, i tried gemini today and it totally failed me. I asked it to write an sdl implementation of the snake game in zig, it failed 3 times, apologized and undid all its work. Not sure if i did anything wrong but the same prompt worked just fine on codex and claude.",
                  "score": 1,
                  "created_utc": "2026-01-15 21:14:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzp2jpr",
              "author": "SubjectHealthy2409",
              "text": "Swap to Zed IDE and use Claude Code via ACP",
              "score": 0,
              "created_utc": "2026-01-15 08:29:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzol1jo",
          "author": "awfulalexey",
          "text": "No no, we are not afraid of competitors, no! Such clowns\n\nhttps://preview.redd.it/nrwb83o4dgdg1.png?width=3680&format=png&auto=webp&s=013666837e43df01a41549a159d6ba48d65c1836",
          "score": 8,
          "created_utc": "2026-01-15 05:55:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzp8c2j",
              "author": "lopydark",
              "text": "atp they should let us just use the sub where we want tbh",
              "score": 4,
              "created_utc": "2026-01-15 09:25:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzuz70e",
              "author": "UnionCounty22",
              "text": "lol the last 5 characters of the request ID are D8LSD",
              "score": 1,
              "created_utc": "2026-01-16 04:00:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzopndl",
              "author": "kohlstar",
              "text": "that‚Äôs amazing, thanks",
              "score": 1,
              "created_utc": "2026-01-15 06:32:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzq5502",
          "author": "whodoneit1",
          "text": "You can use Antigravity with Opencode now, they added support yesterday.",
          "score": 5,
          "created_utc": "2026-01-15 13:39:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ivffb",
              "author": "sucksesss",
              "text": "what do you mean by \"they\"? is it officially tho?",
              "score": 1,
              "created_utc": "2026-01-19 18:46:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzpkn27",
          "author": "xmnstr",
          "text": "Honestly, I'm kinda impressed by how poorly they're handling this. If their infra was solid, this wouldn't be a problem.",
          "score": 1,
          "created_utc": "2026-01-15 11:19:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzra0jk",
              "author": "SilentDanni",
              "text": "Infra is hardly the problem in this case.",
              "score": 1,
              "created_utc": "2026-01-15 16:56:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrsdod",
                  "author": "xmnstr",
                  "text": "Why not?",
                  "score": 1,
                  "created_utc": "2026-01-15 18:18:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrsfv0",
          "author": "nsway",
          "text": "Is open code a superior harness or something? I‚Äôd heard of it prior to this drama but assumed it was a budget option.",
          "score": 1,
          "created_utc": "2026-01-15 18:18:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qexzk7",
      "title": "I finally soft broke up with Claude Code ‚Äî and migrated everything to OpenCode (with reuse)",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qexzk7/i_finally_soft_broke_up_with_claude_code_and/",
      "author": "Tushar_BitYantriki",
      "created_utc": "2026-01-17 00:42:33",
      "score": 51,
      "num_comments": 17,
      "upvote_ratio": 0.95,
      "text": "# I wrote most of this post with opencode, as a summary of my migration. And then edited it myself.\n\nI‚Äôd been quietly annoyed at Claude Code‚Äôs arbitrary, opaque quota limits for a while. I kept tolerating not becuase I feel that I could not live without Opus or Sonnet (I feel most models have become pretty good these days, if you have slightest idea of what you are doing). But because I‚Äôd invested in custom commands, agents, and skills for months, and all of that just works for me in claude code.\n\nAnd the thought of rebuilding everything sounded painful. Then the ‚ÄúOpenCode max subscription ban‚Äù landed and that was my last straw.\n\nObviously, I had to disconnect opencode from claude sub, but it meant I had no reason left tpo keep paying them $200 (well, already reduced to $100 recently, and bought some other subscriptions with the difference)\n\nNo warning, no clarity, and were reports of accounts being banned for \"misuse\". People might justify it with \"they can do whatever they want with THEIR subscription\", but then \"customers are free to leave as well\". It felt like a toxic dependency: good when it worked, exhausting when it didn‚Äôt. I decided to start cutting the cord for good. I spent a few hours learning how OpenCode organizes commands, agents, and skills and realized I could migrate without nuking my Claude setup. That became the mission: keep my Claude assets usable while making them first‚Äëclass in OpenCode.\n\n# The three pillars I had to understand\n\nOpenCode is structured around three things, and once I understood them the migration was mostly plumbing:\n\n* **Commands**: slash commands with frontmatter\n* **Agents**: explicit roles with prompts + tool permissions\n* **Skills**: reusable instruction bundles loaded on demand\n\n# Migration strategy (keep Claude intact, add OpenCode wrappers)\n\nI wanted zero rewrites in my Claude files. The simplest path was wrappers + symlinks so Claude stays the source of truth.\n\n# 1) Skills: symlink Claude ‚Üí OpenCode\n\nThis lets both tools use the same skills.\n\n    # Project\n    ln -s .claude/skills .opencode/skill\n    \n    # User\n    ln -s ~/.claude/skills ~/.config/opencode/skill\n\n# 2) Commands: wrap Claude commands with frontmatter\n\nOpenCode needs frontmatter, Claude doesn‚Äôt. Wrappers let OpenCode read Claude commands without edits.\n\nExample wrapper:\n\n    ---\n    description: Enforce code discipline checklist\n    agent: build\n    ---\n    @.claude/commands/enforce-code-disciplines.md\n\nI did this for all project commands (including the `priming/` folder) and all user‚Äëlevel commands in `~/.claude/commands/`.\n\n# 3) Agents: wrap Claude prompts\n\nOpenCode agents can point to a prompt file, which makes them perfect wrappers for Claude agents.\n\n    ---\n    description: Senior code reviewer\n    mode: subagent\n    prompt: \"{file:~/.claude/agents/senior-code-reviewer.md}\"\n    ---\n\nI wrapped all my Claude agents as **subagents** to preserve behavior.\n\n# Verification checks (how I proved it worked)\n\nThese were the concrete checks that confirmed OpenCode was seeing everything:\n\n    opencode debug skill\n\n* Commands show up in the `/` palette\n* Agents show up in the `@` picker\n* Skills list correctly in `opencode debug skill`\n\nIf skills don‚Äôt show up, I enabled them in `opencode.json`:\n\n    \"tools\": {\n      \"read\": true,\n      \"write\": true,\n      \"edit\": true,\n      \"bash\": true,\n      \"skill\": true\n    }\n\n# Bonus: I turned the playbook into a skill\n\nI didn‚Äôt want to repeat this on every repo, so I started with asking opencode to write a migration skill that:\n\n* Scans Claude commands, agents, and skills\n* Creates OpenCode wrappers and symlinks\n* Verifies discovery\n\nNow migration is repeatable and documented instead of a one‚Äëoff bash ritual.\n\n# Tips\n\n* You can invoke skills by name in plain language. Unlike claude code, you don't have to keep asking it to \"invoke the skill properly\", and not just read a single SKILL.md file (leaving everything else). Open code invoked the skill, and read every file mentioned in it.\n* Skills can load fine even if the UI doesn‚Äôt surface them. Use `opencode debug skill`.\n* Wrappers won‚Äôt load without frontmatter.\n\n# Final take\n\nIf Claude Code‚Äôs limits are starting to feel arbitrary, there is a clean exit ramp. You don‚Äôt have to throw away your existing commands or skills. OpenCode can run them while Claude remains intact. I‚Äôm now fully migrated without losing anything, and it feels like getting my workflow back.\n\nI do plan to use Claude Code for planning at times, but now I have options.\n\nAnd honestly, I was only flirting with OpenCode for the last few months, but watching accounts being banned by Anthropic because customers didn't like their tooling, was a dic\\* move. And it made me realise that I just can't let myself be fully dependent on such a company.\n\nNow, if Anthropic suddenly decides to ban my account for some random reason, I can just walk away without being devastated.\n\nEven if Opus4.5, I have to spend time ensuring that the code is as per my preferences and standards. So for me, the loss would have been leaving behind the workflow that just worked for me. But now it seems that OpenCode is the best place for it to fit one-to-one.\n\nIf anyone wants the playbook or migration skill, here you go:\n\n[https://github.com/SmrutAI/opencode-migration](https://github.com/SmrutAI/opencode-migration)\n\nJust install it, and it migrates everything.\n\n  \nWill soon include a way to reuse Claude's settings.json and hooks, which are the last bit of attachment I have with Claude. (safety net)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qexzk7/i_finally_soft_broke_up_with_claude_code_and/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o01u5yc",
          "author": "altjx",
          "text": "Good stuff. I just did the same thing today with symlinks and some minor tweaks. Long time obsessed CC user here, but Opencode has made a lot of great progress over the last few months ago so I'm happy to be back.",
          "score": 4,
          "created_utc": "2026-01-17 04:16:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02l6dm",
          "author": "Awesomest_Maximus",
          "text": "Opencode already searches in .claude for skills. No need for linking. https://opencode.ai/docs/skills/#place-files",
          "score": 5,
          "created_utc": "2026-01-17 07:54:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02tssr",
              "author": "Tushar_BitYantriki",
              "text": "Yes, it does. I just created a common interface for all 3, as it deduplicates as well.\n\nHonestly, when I started, I was still trying to figure out skills in OpenCode.",
              "score": 2,
              "created_utc": "2026-01-17 09:15:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o041w38",
          "author": "miaowara",
          "text": "Quick tip: OC recognizes both singular & plural folder names (\"agent\" vs. \"agents\", \"command\" vs. \"commands\", \"skill\" vs. \"skills\") and will **load both** if present.  Furthermore, it seems to give priority to same-named items in the singular-named folders. This means you can keep same-named OC specific items in the singular-named folders (e.g. \"agent/cool-guy.md\") while keeping specific Claude-code ones in your symlinked folders (\"agents/cool-guy.md\"). This allows you to jump back to CC if need be relatively easily!",
          "score": 2,
          "created_utc": "2026-01-17 14:46:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o017s9o",
          "author": "raf_oh",
          "text": "Ty for this! I didn‚Äôt realize you can link the Claude files after the front matter for Opencode, great tip",
          "score": 1,
          "created_utc": "2026-01-17 01:51:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02dn2l",
          "author": "DueKaleidoscope1884",
          "text": "thank you for sharing! I am also thinking about this. I am trying different agents regularly and having some reuse would be great. (symlinking is what I rely on mostly so far)\n\n  \nFor agents, how does Opencode handle the front matter of the Claude Code agents? (since the are now part of the prompt, right?) Ignores it?\n\n  \nDid you also consider the plug-ins?",
          "score": 1,
          "created_utc": "2026-01-17 06:46:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02uhaz",
              "author": "Tushar_BitYantriki",
              "text": ">For agents, how does Opencode handle the front matter of the Claude Code agents? (since the are now part of the prompt, right?) Ignores it?\n\nSeems to pretty much ignore it. Opencode gets a wrapper of its own, with frontmatter in its format.\n\n    ---\n    description: Claude-style code reviewer\n    mode: subagent\n    model: anthropic/claude-sonnet-4-20250514\n    prompt: \"{file:./.claude/agents/review.md}\"\n    tools:\n      write: false\n      edit: false\n    ---\n    You are in review mode. Provide feedback only.\n\nThe frontmatter of the internal (claude's) file is just seen as a prompt. Seems to be working fine. (not sure if it would confuse the LLM over time.",
              "score": 2,
              "created_utc": "2026-01-17 09:21:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o032644",
          "author": "Swimming_Internet402",
          "text": "Yeah. Everyone should leave Claude",
          "score": 1,
          "created_utc": "2026-01-17 10:34:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04ccik",
          "author": "Unusual_Ring_4720",
          "text": "Hello, I'm aiming to do the same, but I relied heavily on CC being able to navigate the browser through Claude Extension + being able to look at the screenshots and use that information. Does OpenCode handle this as well? Thank you",
          "score": 1,
          "created_utc": "2026-01-17 15:39:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04ekye",
              "author": "Tushar_BitYantriki",
              "text": "I have not tried MCPs on opencode, yet. Because I am mostly doing backend work for the last 2-3 months.\n\nBut when working on frontend, I have had great success with chrome dev tools and puppeteer MCP (when working on non-chrome browsers)\n\nOpenCode does support MCPs, so would be worth trying.\n\nLately, I had removed most MCPs from my CC set up, to save on tokens.",
              "score": 1,
              "created_utc": "2026-01-17 15:50:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o04gztx",
          "author": "trypnosis",
          "text": "Well done mate",
          "score": 1,
          "created_utc": "2026-01-17 16:01:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04pr62",
          "author": "Superb_Sea_559",
          "text": "Opencode is interesting but isn't the Max subscription much cheaper than API? Or did you get the subscription working with Opencode?",
          "score": 1,
          "created_utc": "2026-01-17 16:42:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05cpnp",
              "author": "Tushar_BitYantriki",
              "text": "I am not using max sub with Opencode anymore, after the Anthropic account blocking fiasco.\n\nI don't want to get banned, just yet. But moving my workflow off claude code, and using GPT and other models.",
              "score": 1,
              "created_utc": "2026-01-17 18:29:25",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0adoz1",
              "author": "chevdor",
              "text": "OC works with CC subscriptions but Anthropic does not like it and tries to prevent it.\n\nIf CC would be on par with OC, there would be little of an issue. Yet the problem for Anthropic is that OC is much better ! And as users switch to OC while using CC, Anthropic faces a big issue: let it be and sell their great models. Or fight the users to ensure they stick with the CC CLI.\n\nThe problem is that more and more people use OC and get really pissed if they could no longer use OC and CC. Most people will drop Anthropic if they stand in front of the choice to use CC or stick with OC and leave.\n\nThis choice is a no trainer. Sticking with CC, you get a few great models and a rather poor CLI. Sure Anthropic could work on their cli but they already showed their will for an exclusive strategy. \n\nUsing OC, you can use ONE workflow and config and access plenty of models without being bound to a single vendor: no vendor lock-in.\n\nModels are racing ATM and it is not possible to say that model XYZ is \"the best\". So users will HAVE to use multiple models from multiple vendors to remain competitive. This is precisely what OC allows and CC wants to prevent.\n\nAnthropic is at a turning point and needs to make a smart choice if they want to avoid losing all their customers...\nFor now, existing customers leave or live in fear. New customers are scared to even join the battle.\n\nThis is all but healthy and ok plays strongly against Anthropic.\nTry bringing that up in their sub, you get censored. Ask me how I know.\n\nI personally don't want to \"live in fear\" **SO** I will stick with OC. \nIf Anthropic allows, I will keep paying for their models. If not, it won't change much for me and I will just switch OC to use another model or set of models. In the meantime, I am limiting the use of Anthropic only feature but honestly there is not much...",
              "score": 1,
              "created_utc": "2026-01-18 13:37:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0aj54u",
          "author": "verkavo",
          "text": "This is great. Thanks for sharing",
          "score": 1,
          "created_utc": "2026-01-18 14:09:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jk6xz",
          "author": "TheCientista",
          "text": "Please if I have to read another quietly or opaque I‚Äôm going to smash my phone over my own head. Don‚Äôt do it. Just stop",
          "score": 1,
          "created_utc": "2026-01-19 20:39:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jll6y",
              "author": "Tushar_BitYantriki",
              "text": "Sure, go ahead.\n\nBut do it quietly, and be opaque when someone asks you why you did it.",
              "score": 1,
              "created_utc": "2026-01-19 20:46:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfa59w",
      "title": "Love for Big Pickle",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qfa59w/love_for_big_pickle/",
      "author": "External_Ad1549",
      "created_utc": "2026-01-17 10:45:00",
      "score": 50,
      "num_comments": 37,
      "upvote_ratio": 0.96,
      "text": "disclaimer: I'm not a vibe coder. I‚Äôm a senior backend dev and I don‚Äôt code on things I don‚Äôt understand at least 70% clarity is mandatory for me.\n\nThat said, I love Big Pickle.\n\nThe response speed is insane, and more importantly, the quality doesn't degrade while being fast. I've been using it for the past hour for refactoring, debugging, and small script creation it just works. \"Great\" feels like an understatement.\n\nI don't care whether it's GLM-4.6, Opus, or something else. I only care about two things: high tokens/sec and solid output quality. Big Pickle nails both.\n\nWhoever operating this model at this speed I genuinely love you.\n\nMy only concern: it's currently free. That creates anxiety. I don‚Äôt want the model to stop working in the middle of serious work.\n\nPlease introduce clear limits or a paid coding plan (ZAI-level or slightly above).  \nIf one plan expires, I'll switch accounts or plans and continue no issue.\n\nJust give us predictability",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qfa59w/love_for_big_pickle/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0384hx",
          "author": "Erebea01",
          "text": "I think they self host their free models and say they don't cost much to host or something so they decide to provide them for free. I might be wrong tho.",
          "score": 6,
          "created_utc": "2026-01-17 11:29:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04b0wc",
              "author": "verbose-airman",
              "text": "My guess was it is smaller models that wanna market their models so they give free access for a limited time.",
              "score": 2,
              "created_utc": "2026-01-17 15:32:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o04tmqc",
              "author": "smile132465798",
              "text": "https://x.com/thdxr/status/1980317899828129992?s=46\nFor reference",
              "score": 1,
              "created_utc": "2026-01-17 17:00:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o06y98c",
                  "author": "touristtam",
                  "text": "> so our costs are 12.5x cheaper than a general purpose one\n\nThat's mental. I wonder if there is a possibility to run a similar setup locally on a consumer laptop and still get decent performances.",
                  "score": 1,
                  "created_utc": "2026-01-17 23:14:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o04catn",
          "author": "Big-Masterpiece-9581",
          "text": "The free ones on opencode zen are with clear TOS. You get free. They get your data and feedback to improve. They will all eventually move to paid only.\n\nBig Pickle is more. It‚Äôs a stealth model. That means one of the big ai companies has a new model they‚Äôre testing pre-release. There is no paid version because it‚Äôs not yet released. And we might never find out when it‚Äôs released that it was previously called big pickle.\n\nYou have to take that into account if using free models.",
          "score": 6,
          "created_utc": "2026-01-17 15:39:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04cyt8",
              "author": "seaweeduk",
              "text": "Big pickle is not a stealth model, it's glm 4.6 with a funny name hosted with one of their providers. Dax has confirmed this multiple times already.\n\nhttps://twitter.com/thdxr/status/1984090146460020966",
              "score": 3,
              "created_utc": "2026-01-17 15:42:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o05n2jl",
                  "author": "pwarnock",
                  "text": "It may have been glm-4.6 at the time he said that, but nothing prevents it from being changed. \n\nKilo has a new stealth model from a Chinese Lab called Giga Potato. Similar naming; size + food. Could be coincidence. \n\nWhen it leaked that Mistral‚Äôs model was stealth (spectre I think), they declined it and the following day announced it. \n\nSo take what you see on X with a grain of salt and assume that using Big Pickle for free means you‚Äôre helping them train, debug, and scale to get it to a state that they are confident charging for.",
                  "score": 2,
                  "created_utc": "2026-01-17 19:17:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o04cser",
              "author": "External_Ad1549",
              "text": "yeah i read it but it is being stealth for a very long time",
              "score": 1,
              "created_utc": "2026-01-17 15:41:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0360z0",
          "author": "lundrog",
          "text": "Pretty sure its k2 thinking",
          "score": 9,
          "created_utc": "2026-01-17 11:10:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03k7z9",
              "author": "seaweeduk",
              "text": "dax has confirmed multiple times before, its just glm 4.6 with a funny name",
              "score": 10,
              "created_utc": "2026-01-17 13:04:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03zrb9",
                  "author": "KnifeFed",
                  "text": "So why use it over GLM 4.7? Is it faster?",
                  "score": 4,
                  "created_utc": "2026-01-17 14:34:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o04d6u3",
                  "author": "External_Ad1549",
                  "text": "i am kind of using glm models like from 4.5 it doesn't seem like 4.6 i might be wrong when context increased it kind of behaved on it's own k2 will do that or I might be wrong",
                  "score": 4,
                  "created_utc": "2026-01-17 15:43:26",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o04qgs2",
                  "author": "minaskar",
                  "text": "It certainly used to be GLM-4.6, but I'm pretty sure it's been replaced with K2 Thinking now. If you notice at the OpenCode Desktop app, Big Pickle allows you to change the reasoning effort, just like K2 Thinking. GLM-4.6/4.7 do not have this freedom.",
                  "score": 1,
                  "created_utc": "2026-01-17 16:46:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o036ulu",
              "author": "External_Ad1549",
              "text": "can be, I completely forgot that it existed",
              "score": 1,
              "created_utc": "2026-01-17 11:17:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o03h1at",
          "author": "websitegest",
          "text": "That anxiety about ‚Äúthis is awesome AND free, so it‚Äôs probably going to vanish mid‚Äëproject‚Äù is very real. Free tiers are nice for experimentation, but for serious backend work predictability > freebies.\n\nWhat worked for me was building around a paid coding plan with known limits as the backbone, and then treating fast/free models like Big Pickle as opportunistic accelerators. Opus (or similar) sets the architecture, GLM 4.7 and Big Pickle handles the implementation and refactor loops, and anything else fast just rides on top.\n\nIf you‚Äôre looking for something closer to a predictable, paid plan rather than a gamble on a free endpoint, Zai has coding plans where you can still get 50% discount for first year + 30% discount (current offers + additional 10% coupon code) but I think it will expire soon (some offers are already gone!) > [https://z.ai/subscribe?ic=TLDEGES7AK](https://z.ai/subscribe?ic=TLDEGES7AK)",
          "score": 3,
          "created_utc": "2026-01-17 12:42:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03nx7g",
              "author": "External_Ad1549",
              "text": "thanks i have max plan zai it is my work horse, chatgpt for architectural decisions but sometimes zai goes very slow for a simple tasks glm 4.7 took 28 sec same big picke took 7.5 sec but when the depth increased big pickle kind of left me and wrote its own code despite having correct plan.md in place never happened with glm 4.7. I completely agree with u",
              "score": 3,
              "created_utc": "2026-01-17 13:28:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o048mrj",
                  "author": "ZeSprawl",
                  "text": "Try GLM 4.7 on Cerebras. You can try it out on the free tier. The speed is actually insane. Fastest response I've ever seen for a smart coding model. It's addictive and I hope they offer it on their coding plan whenever there's availability again.",
                  "score": 2,
                  "created_utc": "2026-01-17 15:21:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o04p5cc",
          "author": "psilokan",
          "text": "Interesting.  I've found big pickle to be very slow when using it. Also found it to be very buggy.  One time it just randomly switched to chinese and all the output was in chinese characters, no idea why lol.",
          "score": 2,
          "created_utc": "2026-01-17 16:40:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04s4uw",
              "author": "External_Ad1549",
              "text": "üòÇüòÇ switch to chinese happened in Antigravity as well\nwhen did you tested this?",
              "score": 1,
              "created_utc": "2026-01-17 16:53:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o04xb51",
                  "author": "psilokan",
                  "text": "This was right before Christmas.  The funny thing it still understood me and kept doing what I asked despite me having no clue what it was saying back lol",
                  "score": 2,
                  "created_utc": "2026-01-17 17:17:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o05wzoo",
          "author": "Easy_Zucchini_3529",
          "text": "Use GLM-4.7 with Fireworks or Cerebras.",
          "score": 2,
          "created_utc": "2026-01-17 20:05:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05xiov",
              "author": "External_Ad1549",
              "text": "crebras  is limited, trail version got some burst but it is always pushing 1 min break like limited tokens in 1 min. not available right now, coding plans are not available. fireworks ai is little costly need to check whether it has coding plans",
              "score": 1,
              "created_utc": "2026-01-17 20:08:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o05zbo4",
                  "author": "Easy_Zucchini_3529",
                  "text": "true, both are not the most cheapest solution, but the tokens per second are insane (specially Cerebras)",
                  "score": 2,
                  "created_utc": "2026-01-17 20:17:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0fb2vx",
          "author": "37chairs",
          "text": "Big pickle was a total joke at first. I used it again on a whim after hitting limits and was blown away. Is also possible I got better at talking to the things in the interim, but it went from trash to cash.",
          "score": 2,
          "created_utc": "2026-01-19 04:57:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfzaju",
      "title": "Built a multi-agent orchestrator plugin for OpenCode after struggling with GLM-4.7",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qfzaju/built_a_multiagent_orchestrator_plugin_for/",
      "author": "ChangeDirect4762",
      "created_utc": "2026-01-18 04:50:54",
      "score": 42,
      "num_comments": 18,
      "upvote_ratio": 0.93,
      "text": "https://preview.redd.it/78u9krhyf1eg1.png?width=3826&format=png&auto=webp&s=eaa14b014a85d34823c68ff354dc998de60d8883\n\nGLM-4.7 kept hitting walls on complex tasks ‚Äî rate limits, context overflow, losing track halfway through. Got frustrated enough to build my own solution.\n\n0.9 version\n\nSo I made \\[opencode-orchestrator\\]([https://github.com/agnusdei1207/opencode-orchestrator](https://github.com/agnusdei1207/opencode-orchestrator)). It's a plugin for OpenCode that handles:\n\n\\- \\*\\*Parallel sessions\\*\\* ‚Äî up to 50 isolated sessions running simultaneously\n\n\\- \\*\\*Agent distribution\\*\\* ‚Äî Commander delegates to Planner, Workers, Reviewer\n\n\\- \\*\\*Background tasks\\*\\* ‚Äî non-blocking, async execution\n\n\\- \\*\\*Auto-retry\\*\\* ‚Äî handles crashes, rate limits, context issues automatically\n\n\\- \\*\\*Loop until done\\*\\* ‚Äî keeps going until all TODOs are complete and verified\n\nThe idea is simple: instead of one agent trying to do everything, split the work across specialized agents that run in parallel and coordinate through shared state.\n\n  \nIf you try it out and run into anything, feel free to open an issue ‚Äî or since it's open source, just fork it and tinker with it yourself. If you come up with something cool, I'd love to hear about it.\n\n\n\nI think in the AI era, we're all going to end up building our own tools anyway.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qfzaju/built_a_multiagent_orchestrator_plugin_for/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o0c7ung",
          "author": "Visible_Jury_6547",
          "text": "why not just config Oh my opencode ? [https://github.com/code-yeongyu/oh-my-opencode](https://github.com/code-yeongyu/oh-my-opencode)",
          "score": 5,
          "created_utc": "2026-01-18 19:04:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0frqfi",
              "author": "splitbrainhack",
              "text": "unnecessary chaos",
              "score": 1,
              "created_utc": "2026-01-19 07:08:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0a709j",
          "author": "writing_rainbow",
          "text": "Are you able to assign specific models for each mode? Like chat 5.2 high for commander and planner and then glm for implementation and then codex 5.2 high for review?",
          "score": 5,
          "created_utc": "2026-01-18 12:52:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09gl6c",
          "author": "redoubledit",
          "text": "So frustrating. At one time, I had beautifully laid out plans with extensive todo list, broken up into execution phases. I was so ready, so it started. Finishing the first todo item, using the todo write tool to check off the item. But didn‚Äôt read the list before so now, all todos are checked and verified and it stopped. Trying to iterate, it totally messed up from there. Forgetting parts of the plan, checking off items and deleting others in the same step. \n\nMight give your project a try. See if it can help.",
          "score": 2,
          "created_utc": "2026-01-18 08:59:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08vblp",
          "author": "lundrog",
          "text": "Interesting, ill check it out",
          "score": 1,
          "created_utc": "2026-01-18 05:52:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o097hp5",
              "author": "ChangeDirect4762",
              "text": "Thx. :)",
              "score": 1,
              "created_utc": "2026-01-18 07:36:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0avr5y",
          "author": "mintybadgerme",
          "text": "I'm getting a little confused with all these new agent systems coming online. What makes them different from one another? I've got open agents installed. How is that different from this one? I'm assuming that running them all together will destroy the platform completely.",
          "score": 1,
          "created_utc": "2026-01-18 15:17:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0c2z3g",
              "author": "Zexanima",
              "text": "Its a new problem domain that people are running into around the same time. Not everyone can/wants to keep up to date with everything new that drops, so they will roll their own solution. I think its great to have all these options in the beginning. People will evetually gravitate to the best solutions, they will start to homogenize features, and those will become the go-to.",
              "score": 5,
              "created_utc": "2026-01-18 18:41:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0c4l4r",
                  "author": "mintybadgerme",
                  "text": "But how on earth do you decide what's the best solution? Seems to me that there's no benchmarks,  no quality assurance, no testing. They're just released onto the market and us poor suckers have got to make a decision. Really hard.",
                  "score": 1,
                  "created_utc": "2026-01-18 18:49:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0e7d3x",
          "author": "Redoer_7",
          "text": "Which IDE is this",
          "score": 1,
          "created_utc": "2026-01-19 01:06:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0f64g2",
              "author": "Ruin_Mediocre",
              "text": "https://zed.dev/",
              "score": 1,
              "created_utc": "2026-01-19 04:24:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0fk8dc",
          "author": "NullzeroJP",
          "text": "Wow, crazy. How long did it take you to plan and build out something like this? And did it help fix some of the issues with GLM 4.7? Having similar issues myself with GLM 4.7 and ClaudeCode. But I'm new to vibe coding, so I thought maybe it was just a \"me\" problem.",
          "score": 1,
          "created_utc": "2026-01-19 06:06:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcf9hy",
      "title": "I Found OpenCode‚Äôs Unannounced Pricing Page. Here‚Äôs What It Reveals.",
      "subreddit": "opencodeCLI",
      "url": "https://jpcaparas.medium.com/i-found-opencodes-unannounced-pricing-page-here-s-what-it-reveals-5793c8f8e1ef",
      "author": "jpcaparas",
      "created_utc": "2026-01-14 05:46:37",
      "score": 41,
      "num_comments": 37,
      "upvote_ratio": 0.8,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qcf9hy/i_found_opencodes_unannounced_pricing_page_heres/",
      "domain": "jpcaparas.medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzi4wsy",
          "author": "Charming_Support726",
          "text": "I am quite curious, if this is gonna happen or if it is some kind of guerilla marketing. Fake announcements are seen quite often these days. Claude API pricing is extremely expensive because Claude is using tokens like nothing. If I am using Opus only I easily spend 50-90 a day. \n\nMany people write about changing to GPT or Opencode, at least that what I read, so this move could be an idea from Anthropic to keep developers. If it's gonna be a real offer or not. \n\nI personally would go for one of these subscription, maybe a smaller one, same as I do for Codex ( because Codex-5.2 is not available on API )",
          "score": 11,
          "created_utc": "2026-01-14 07:46:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzicrrr",
              "author": "Keep-Darwin-Going",
              "text": "They are unlikely to give opus, Claude charge us at 10% for max 20 now. If they do that they will bleed to death unless they get enough low volume unlimited user.",
              "score": 5,
              "created_utc": "2026-01-14 09:02:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzifv6p",
                  "author": "warpedgeoid",
                  "text": "Copilot includes Opus 4.5, so this will likely also include Opus.",
                  "score": 1,
                  "created_utc": "2026-01-14 09:32:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzi2gzn",
          "author": "KHALIMER0",
          "text": "\nThanks for sharing. For everyone else not wanting to scroll through a huge medium post based on fiction and written by AI, Here‚Äôs the direct link\n\nhttps://opencode.ai/black\n\nTL;DR: the only info available is on this link. Subject to change. Unlinked anywhere.",
          "score": 29,
          "created_utc": "2026-01-14 07:24:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzimtfx",
              "author": "goddy666",
              "text": "üíØ üëè",
              "score": 2,
              "created_utc": "2026-01-14 10:38:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzj2gmq",
              "author": "gpt872323",
              "text": "Interesting. Looking to hear from people who tried. Data privacy is still a big concern. Hope this does but doubt the opus 4.5 will be high limit.",
              "score": 2,
              "created_utc": "2026-01-14 12:40:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzjzbts",
              "author": "Gargle-Loaf-Spunk",
              "text": "Man that‚Äôs been my problem with the llm-explorer news aggregation too, I wrote a quick user script to hide all medium and substack articles.¬†\n\nJust tons and tons of AI slop about AI",
              "score": 1,
              "created_utc": "2026-01-14 15:38:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nziile1",
          "author": "philosophical_lens",
          "text": "I can‚Äôt understand how they can offer Claude models usage at a price that‚Äôs competitive with Claude‚Äôs own subscription. My guess is that using Claude models will burn through your Opencode subscription at a ridiculously fast rate compared to Claude subscriptions.\n\nI was expecting their subscription offering to focus on models like GLM, MiniMax, Grok, etc. This is surprising.",
          "score": 6,
          "created_utc": "2026-01-14 09:58:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzizwg1",
              "author": "ezhupa99",
              "text": "ain't nobody paying 200$ for glm",
              "score": 3,
              "created_utc": "2026-01-14 12:23:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzj5x4l",
                  "author": "philosophical_lens",
                  "text": "Haha, that‚Äôs true! I still don‚Äôt think what they‚Äôre doing makes sense, but curious to see how this pans out!",
                  "score": 1,
                  "created_utc": "2026-01-14 13:03:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzijzki",
              "author": "mustafamohsen",
              "text": "They're not",
              "score": 1,
              "created_utc": "2026-01-14 10:12:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzj2jxs",
          "author": "Codemonkeyzz",
          "text": "I don't understand how this pricing works. If i subscribe to 20  USD model,  will i get the same amount of limit/usage that i get from the original provider ? Or will it be less, if less, how much less ?",
          "score": 3,
          "created_utc": "2026-01-14 12:41:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzk8bsn",
              "author": "warpedgeoid",
              "text": "If it‚Äôs like GH Copilot, metering will be request based and not token based. In that scenario some models have a higher multiplier than others and so they burn credits faster when used.",
              "score": 2,
              "created_utc": "2026-01-14 16:19:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzj5x6a",
          "author": "jovialfaction",
          "text": "I wished they'd offer a $50 tier. Nobody offers anything in that range.",
          "score": 3,
          "created_utc": "2026-01-14 13:03:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzi5ln8",
          "author": "Extension-Pen-109",
          "text": "Well, we all like to eat every day. \nProgrammers included\n\nThey had to monetize their work somehow.\n\nLet‚Äôs hope they at least leave a self-hosted option (like other open-source services) so things can continue as they are.",
          "score": 2,
          "created_utc": "2026-01-14 07:53:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzht5gx",
          "author": "Dry_Pay6651",
          "text": "nice catch. any idea what will happen to Zen offering?",
          "score": 1,
          "created_utc": "2026-01-14 06:04:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzhy2q9",
              "author": "martinffx",
              "text": "It‚Äôll definitely stay around, black is just a Claude Max/ChatGPT pro alternative. Especially after Claude rug pull. \n\nPaying per token is just not viable for individual users, I tried to switch to zen and easily spent the $100 I paid for Claude max in a week. Those pro/max plans are an absolute steal if you are really using these tools.",
              "score": 9,
              "created_utc": "2026-01-14 06:45:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzhy6qr",
                  "author": "Ok_Road_8710",
                  "text": "That's the problem. They win by subsidizing.",
                  "score": 1,
                  "created_utc": "2026-01-14 06:46:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzhxpi9",
              "author": "oknowton",
              "text": "Nobody knows anything, but it would be weird for OpenCode Zen to change.  Most companies with LLM subscription plans also have a pay per token API.",
              "score": 4,
              "created_utc": "2026-01-14 06:42:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzilbjt",
          "author": "Wurrsin",
          "text": "Where did you get anything about a Windsurf Ultimate subscription plan? From what I saw this doesn't exist. I only see a Free, Pro, Teams and Enterprise plan.",
          "score": 1,
          "created_utc": "2026-01-14 10:24:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzimkea",
              "author": "jpcaparas",
              "text": "Seems like the plan has been retired now. I was previously on it. I've amended the chart, thanks!",
              "score": 1,
              "created_utc": "2026-01-14 10:35:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzj8wcb",
          "author": "Nexmean",
          "text": "Cursor is cooked",
          "score": 1,
          "created_utc": "2026-01-14 13:21:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjuedl",
          "author": "rm-rf-rm",
          "text": "So is this project just another one of the \"open\" primarily for top of the funnel marketing?",
          "score": 1,
          "created_utc": "2026-01-14 15:15:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkttnl",
          "author": "jpcaparas",
          "text": "Plans are now live",
          "score": 1,
          "created_utc": "2026-01-14 17:56:53",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nzl4oa6",
          "author": "Amazing_Ad9369",
          "text": "I know this is about opencode\n\nBut for those on a budget\n\nHowever theres several ways to get opus pretty cheap.\n\nRovo dev cli. I pay $9 for jira and get 20m tokens per day\n\nAlso github copilot cli\n\nAlso antigravity (chat, not cli)\n\nTo name a few",
          "score": 1,
          "created_utc": "2026-01-14 18:44:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznzqty",
          "author": "axlalucard",
          "text": "gos forbid developer trying to get a meal a day, hard enuf with ai around",
          "score": 1,
          "created_utc": "2026-01-15 03:27:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpor8i",
          "author": "Specific-Night-4668",
          "text": "That's good news. They'll do what all companies that use APIs with high usage demand do: get good volume discounts.\n\nIn the documentation, Claude:  \n\"For high-volume agent applications, consider contacting our¬†[enterprise sales team](https://claude.com/contact-sales)¬†for custom pricing arrangements.\"  \n  \nand further down:  \n  \n\\*\\* Volume discounts \\*\\*  \nVolume discounts may be available for high-volume users. These are negotiated on a case-by-case basis.\n\nThat's normal. If you show up at Anthropics and say, \"I need 10 billion tokens per month,\" you're far from getting the base rate.",
          "score": 1,
          "created_utc": "2026-01-15 11:52:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09cxxm",
          "author": "blankeos",
          "text": "How is this \"unannounced\" Dax tweeted this so many times now",
          "score": 1,
          "created_utc": "2026-01-18 08:25:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nziuhgb",
          "author": "kgoncharuk",
          "text": "it's not really a secret, Dax announced on X a closed beta couple of weeks ago.",
          "score": 1,
          "created_utc": "2026-01-14 11:42:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzk7yon",
              "author": "warpedgeoid",
              "text": "Not sure why the downvotes. This has been public knowledge for a while with many already signed up for the $200/month plan",
              "score": 1,
              "created_utc": "2026-01-14 16:17:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qbt6l4",
      "title": "I got tired of hitting Antigravity rate limits in OpenCode blindly, so I built a tool to track them",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qbt6l4/i_got_tired_of_hitting_antigravity_rate_limits_in/",
      "author": "frieserpaldi",
      "created_utc": "2026-01-13 14:45:55",
      "score": 39,
      "num_comments": 16,
      "upvote_ratio": 0.94,
      "text": "Hey everyone,\n\nI've been using the Antigravity setup within OpenCode for a while, but one thing always annoyed me: I never knew exactly how much quota I had left until I hit the limit. I prefer to know if I have 5 minutes or 5 hours of coding left before the reset.\n\nSo, I built [opencode-antigravity-quota](https://github.com/frieser/opencode-antigravity-quota).\n\nhttps://preview.redd.it/3novpv0yp4dg1.png?width=773&format=png&auto=webp&s=da012cf14f4a65e9c2a73ba20e0ffc8a6c084aa3\n\nIt‚Äôs a plugin that hooks into your authenticated accounts and gives you the option to visualize your current quotas and exact reset times directly in the terminal.\n\nWhat it does:\n\n\\*   Visual Status: ASCII-style progress bars showing usage for models like Gemini 1.5 Pro, Flash, and Claude.\n\n\\*   Multi-Account: Checks all accounts configured via the auth plugin at once.\n\n\\*   Reset Timers: Tells you exactly when your quota resets (e.g., \"Reset in: 2h 15m\").\n\n\\*   Local Cache: Lets you see if you are being throttled locally vs the server.\n\nIt requires opencode-antigravity-auth to work. It‚Äôs been a lifesaver for my workflow, so I figured I‚Äôd share it.\n\nRepo/Install: [https://github.com/frieser/opencode-antigravity-quota](https://github.com/frieser/opencode-antigravity-quota)\n\nLet me know if you find it useful",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qbt6l4/i_got_tired_of_hitting_antigravity_rate_limits_in/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nzhg5j8",
          "author": "taoalpha",
          "text": "This is awesome! I actually used your repo as a reference for OpenCode and had it generate a custom skill to check status using just¬†`curl`. It worked flawlessly!\n\nGist:¬†[https://gist.github.com/taoalpha/22773d2132519e55a4c7427fd3e96d8e](https://gist.github.com/taoalpha/22773d2132519e55a4c7427fd3e96d8e)",
          "score": 3,
          "created_utc": "2026-01-14 04:28:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzljvlm",
              "author": "virtualhenry",
              "text": "this is cool. does it show the private auth tokens to the model when you use the skill?",
              "score": 1,
              "created_utc": "2026-01-14 19:53:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o069dyi",
                  "author": "taoalpha",
                  "text": "depends on skill, i think the above one probably will, but if you tell it to always run script (and include read token + curl), then it should not, since the model should just see instruction and run the [xxx.py](http://xxx.py) or [xxx.sh](http://xxx.sh) script, and the output, what happens within the script I believe is not exposed to the model",
                  "score": 2,
                  "created_utc": "2026-01-17 21:09:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzdt1vq",
          "author": "oldassveteran",
          "text": "I‚Äôve never used antigravity before. Are you using the Ultra plan? Whats your opinion of it? Seems nice being able to use all the models.",
          "score": 2,
          "created_utc": "2026-01-13 17:20:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzljp0p",
          "author": "virtualhenry",
          "text": "i turned it into a script to be used in tmux staus bar: \\`userName C:96% ‚Ä¢ G:100%\\`\n\n[https://gist.github.com/iamhenry/4bacd34baf742563d4dc839fd04b4882](https://gist.github.com/iamhenry/4bacd34baf742563d4dc839fd04b4882)",
          "score": 2,
          "created_utc": "2026-01-14 19:52:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsmwb5",
          "author": "bitkarma77",
          "text": "Any idea why i got on all accounts all quota exceeded? Accounts were few years old. I added a new account, also the quota was full instantly after first login.",
          "score": 2,
          "created_utc": "2026-01-15 20:37:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdijzp",
          "author": "[deleted]",
          "text": "Super helpful!",
          "score": 1,
          "created_utc": "2026-01-13 16:20:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdlq0r",
          "author": "Popeluxe",
          "text": "Nice work!  \nI took a shot at this aswell, i archived mine since yours seem a bit further developed for antigravity. see [https://github.com/PhilippPolterauer/opencode-antigravity-quota](https://github.com/PhilippPolterauer/opencode-antigravity-quota)\n\nI am also working on a more generic opencode-quotas package, if you would like to join forces. See [https://github.com/PhilippPolterauer/opencode-quotas](https://github.com/PhilippPolterauer/opencode-quotas)",
          "score": 1,
          "created_utc": "2026-01-13 16:34:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdrm0d",
          "author": "RedParaglider",
          "text": "How do you know what the quota is, do you check to see what plan someone is using?",
          "score": 1,
          "created_utc": "2026-01-13 17:12:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdtfjo",
          "author": "Emotional_Note_2557",
          "text": "Exactly what I needed. But it doesn't work for me.\n\nBoth¬†plugin works but i can't enter the command /antigravity-quota. I don't have antigravity-accounts.json maybe that's why ?",
          "score": 1,
          "created_utc": "2026-01-13 17:21:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nze3ead",
              "author": "Emotional_Note_2557",
              "text": "Apparently my antigravity-accounts.json is in \\~\\\\AppData\\\\Roaming\\\\opencode and when i moved it where it should be then another one was created here again. So I don't know what happened...",
              "score": 1,
              "created_utc": "2026-01-13 18:07:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nze8dmt",
              "author": "timmyjl12",
              "text": "Same, the command is not showing for me.\n\nEdit: Did the same. Moved the command from AppData/Roaming/opencode/command -> \\~/.opencode/command\n\nWorking now! Thank you!",
              "score": 1,
              "created_utc": "2026-01-13 18:29:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzio3qe",
          "author": "tibn4",
          "text": "Really cool ! Any way to make this work with the [gemini-auth](https://github.com/jenslys/opencode-gemini-auth) plugin ?",
          "score": 1,
          "created_utc": "2026-01-14 10:49:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzk6vdn",
          "author": "mnismt18",
          "text": "this is super cool!",
          "score": 1,
          "created_utc": "2026-01-14 16:13:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuraud",
          "author": "Jason-JXM",
          "text": "Awesome! I am considering whether there is such a tool.",
          "score": 1,
          "created_utc": "2026-01-16 03:14:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvzpys",
          "author": "rtyu1120",
          "text": "I'm a simple man and I just use CodexBar: https://codexbar.app",
          "score": 1,
          "created_utc": "2026-01-16 08:42:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf1ydz",
      "title": "Opus 4.5 Model Alternative",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qf1ydz/opus_45_model_alternative/",
      "author": "gradedkittyfood",
      "created_utc": "2026-01-17 03:18:35",
      "score": 37,
      "num_comments": 23,
      "upvote_ratio": 0.91,
      "text": "Hey all,\n\nBeen loving opencode more than claude. But no model I have used seems to come close to opus for programming tasks.\n\nTried GLM 4.7, and it's pretty decent, and impressive, but still struggles with bigger tasks. Mini Max M2.1 is fast as hell, but lands near GLM 4.7 in terms of quality.\n\nI've heard decent things about codex-5.2-high, but I'm curious on in terms of output quality and usage. Any other models I should be aware of to scratch that Opus itch but in Opencode?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qf1ydz/opus_45_model_alternative/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o01muin",
          "author": "real_serviceloom",
          "text": "None of the models are as good as opus 4.5. Gpt 5.2 is a bit better but much slower.¬†\n\n\nMinimax m2.1 is the best bet among the free ones. Glm is also super slow for me for some reason on open code.¬†",
          "score": 21,
          "created_utc": "2026-01-17 03:27:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o029l0i",
              "author": "Charming_Support726",
              "text": "Dont confuse gpt-5.2 with gpt-5.2-codex. Codex is much faster, but lacks some analytic skills - especially in discussion. \n\nIn my experience the Gpts are very thorough and Opus wont match these. Opus get things done but lacking some perfection, while Codex tent to be overprecise, which is a real hard impediment when you are just creating a proof of concept.",
              "score": 4,
              "created_utc": "2026-01-17 06:12:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o029sdv",
                  "author": "real_serviceloom",
                  "text": "Yup I use gpt 5.2 medium for most planning and architecture and 5.2 codex medium for sniping. And high xhigh for reviews and gnarly bugs. I also have a Claude Max plan because sometime i just need speed lol.¬†",
                  "score": 1,
                  "created_utc": "2026-01-17 06:13:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o09hk70",
              "author": "websitegest",
              "text": "I can confirm that M 2.1 is really powerful, but in my opinion it's terrible when it comes to documentation! As for speed, I found GLM was slower with the Lite plan: I upgraded to the *Pro plan* and now it's quite fast, only experiencing a slight slowdown during peak hours. For others coding tests I ran identical prompts through Opus 4.5 (via *Claude Pro* plan), GLM 4.7, and Minimax. Results: Opus best at first-pass architecture, GLM best at iterative implementation (fewer context losses), Minimax faster but not cheaper as GLM. For anyone considering the GLM plans right now there is also a **50% discount** for first year **+ 30% discount** (current offers + my additional 10% coupon code) but I think it will expire soon (some offers are already gone!) >¬†[https://z.ai/subscribe?ic=TLDEGES7AK](https://z.ai/subscribe?ic=TLDEGES7AK)",
              "score": 1,
              "created_utc": "2026-01-18 09:08:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o01lygx",
          "author": "minaskar",
          "text": "For me it was Kimi K2 Thinking that took that role.",
          "score": 7,
          "created_utc": "2026-01-17 03:21:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o022ln9",
              "author": "NiceDescription804",
              "text": "Is it good at planning? I'm really happy with how glm 4.7 follows instructions but the planning is terrible. \nSo how was your experience when it comes to planning?",
              "score": 2,
              "created_utc": "2026-01-17 05:16:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03m2mo",
                  "author": "annakhouri2150",
                  "text": "Yeah, I would say that K2T is probably the best open source model I've used at planning and analyzing things and general sort of analytic skill. Whereas GLM 4.7 is better at figuring problems out debugging, strictly coding and instruction following. So that's how I would split it up.",
                  "score": 2,
                  "created_utc": "2026-01-17 13:16:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o04pjf4",
                  "author": "minaskar",
                  "text": "Yeah, that was my experience too. GLM-4.7 (and to a slightly lesser degree M2.1) is great at following instructions, but it really struggles to plan anything with even a moderate level of complexity. K2 Thinking (and DS3.2 for math/algorithm-heavy cases) if far superior in my opinion.",
                  "score": 0,
                  "created_utc": "2026-01-17 16:41:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o02jkd3",
          "author": "toadi",
          "text": "All tasks can be broken in smaller tasks. To be honest since a few months I don't see that much problem in software delivery by most models.\n\nI use opus only to provide me a larger spec. After that break it down with sonnet in small incremental task and haiku delivers the actual code. Can do the same using GLM and grok-fast for example. \n\nIt is about being precise and detailed providing input. This way it narrows down the probabilistic band making it land close to the goal you aim for.",
          "score": 2,
          "created_utc": "2026-01-17 07:39:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02k3ei",
          "author": "Michaeli_Starky",
          "text": "Even the slowest models are faster than the fastest programmer. Not sure why the speed of generation is a concern. BTW, you need to read and understand the code, so take your time.",
          "score": 2,
          "created_utc": "2026-01-17 07:44:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0g1ypu",
          "author": "No_Click_6656",
          "text": "Just use Opus 4.5 with Copilot as provider lol",
          "score": 1,
          "created_utc": "2026-01-19 08:40:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02s4qf",
          "author": "kkordikk",
          "text": "Just break down bigger task into smaller ones. Isn‚Äôt GLM the fastest at 1000tps?",
          "score": 1,
          "created_utc": "2026-01-17 08:59:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05x83o",
          "author": "SynapticStreamer",
          "text": "> but still struggles with bigger tasks.\n\nGiving any LLMs large tasks, and they'll struggle. Create an implementation.md file (I call mine CHANGES.md) and have the LLM map out planned changes in phases and write the implementation plan to the file. Then, instead of saying \"do this thing\" say \"implement the changes in CHANGES.md. Stop between each phase for housekeeping (git, context, etc), and then touch base with me before proceeding.\"\n\nWorks for most things. With very complex changes, no matter what you do, the model will hallucinate. I haven't been able to get it to a point, even with sufficient context, to not.",
          "score": 1,
          "created_utc": "2026-01-17 20:07:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02e1ng",
          "author": "lostinmahalway",
          "text": "Have you tried Deepseek Chat? I used Opus/Deepseek Chat for planning, creating tasks and orchestrating, while Minimax to actually implement the tasks. Sometimes during the day, the Opus is even worse compared to Deepseek.",
          "score": 0,
          "created_utc": "2026-01-17 06:50:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qc9zs0",
      "title": "opencode studio v1.3.3: usage dashboard, presets, and google account pool",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qc9zs0/opencode_studio_v133_usage_dashboard_presets_and/",
      "author": "MicrockYT",
      "created_utc": "2026-01-14 01:34:20",
      "score": 33,
      "num_comments": 4,
      "upvote_ratio": 0.91,
      "text": "hey!\n\nanother update on [opencode studio](https://github.com/Microck/opencode-studio). ive been busy with other projects but havent stopped working on it. lots of new QoL and Antigravity/Google related stuff! trying to keep up to date (id want the same antigravity rotation system but for openai's new specific support) but there's an overwhelming amount of stuff coming every day :P\n\nits probably filled with bugs that I havent discovered myself so let me know anything that you find or that you want added!\n\n# what's new:\n\n**usage dashboard (new tab: /usage)**\n\nv1.0.5 had no usage page. now there‚Äôs a full usage dashboard that pulls from your local opencode message logs and turns it into token + cost stats.\n\nwhat you get:\n\n* summary cards for total cost, input tokens, output tokens.\n* usage timeline (stacked bars) broken down by model. hover a segment and it shows input vs output cost for that model.\n* cost breakdown pie chart with a legend (and a view toggle when you have lots of models).\n* top projects table. click a project row to instantly filter the whole page to that project.\n* model performance table with input/output tokens + estimated cost.\n\nfilters + exports:\n\n* range presets: 24h, 7d, 30d, 3m, 6m, 1y\n* custom range actually prompts for start + end dates and filters server-side using from/to timestamps\n* project dropdown: all projects or one project\n* export csv (model, input, output, total, cost)\n* save screenshot (exports the whole dashboard) pricing model:\n* studio includes a small pricing table (per 1m tokens) for common models (claude, gpt, gemini, etc).\n* anything unknown falls back to a default rate so you still get estimates instead of blanks.\n\nhttps://preview.redd.it/2g7ppot4w7dg1.png?width=1920&format=png&auto=webp&s=317837cc180e09c5ce42d1b75409b2fac5eef167\n\n**google auth got split into gemini vs antigravity**\n\nif you have both google auth plugins installed, studio treats them as two modes:\n\n* gemini auth: simple, single-account flow\n* antigravity auth: multi-account pooling and rotation\n\nyou can switch the active mode from the auth page. it updates which google namespace is active and keeps the rest of your config intact.\n\n**google account pool + quota tracking (auth page)**\n\nthis is the big new auth feature since v1.0.5.\n\n* add multiple google accounts into a pool (oauth in browser)\n* each account gets a status: active, ready, cooldown, expired\n* rotate to the next available account when you get rate limited\n* activate a specific account manually\n* cooldown an account for an hour if it‚Äôs currently burned\n* quota bar shows daily usage %, remaining, and reset timer\n\nthis is built for people who have work + personal accounts, or multiple paid seats, and don‚Äôt want to keep re-logging.\n\nhttps://preview.redd.it/i4y3qnibw7dg1.png?width=1920&format=png&auto=webp&s=825615b3137da115b44a077687838de4cabecb35\n\n**auth tutorial (first visit)**\n\n/auth can be a lot when you first land there. there‚Äôs now a short first-time walkthrough, plus a help button to reopen it later.\n\nhttps://preview.redd.it/buk47rxfw7dg1.png?width=1002&format=png&auto=webp&s=c760e1567c13fbb3ac6d7d4c8a37e84ab06baab2\n\n**one-click profile switching (auth)**\n\nprofiles are still there, but switching is now just a click. it‚Äôs the kind of thing you only notice when it‚Äôs gone.\n\nhttps://preview.redd.it/0ps29alkw7dg1.png?width=581&format=png&auto=webp&s=19279a8da39f864a572502cc5752c93a9833abff\n\n**presets (new feature)**\n\npresets are basically save-bundles and apply it when I need to.\n\n* open presets from skills, plugins, or mcp\n* create a preset with:\n   * name + description\n   * skills list\n   * plugins list\n   * mcp servers list\n* partial selection is supported. you can pick exactly which items are included.\n* apply modes:\n   * exclusive: apply preset and disable everything else\n   * additive: apply preset and keep other items enabled\n\nthe create preset dialog also starts preselected with whatever you currently have enabled, so it‚Äôs fast to capture your current setup.\n\nhttps://preview.redd.it/wqqhs7c3x7dg1.png?width=1920&format=png&auto=webp&s=b1ff2e341292e0286be235eab6a9bf1083bc2069\n\n**mcp editing in-place**\n\nmcp management isn‚Äôt add/toggle/delete anymore. mcp cards support editing the config in place (command/args/env style changes), so you don‚Äôt need to round-trip through raw json for common tweaks.\n\nhttps://preview.redd.it/t5hx9mh6x7dg1.png?width=1919&format=png&auto=webp&s=db944f0686f8216b6f05af71822ba95e78e85302\n\n**disconnected landing is more guided**\n\nwhen the frontend can‚Äôt see the backend, it now shows:\n\n* explicit setup steps (install opencode-ai, install studio server)\n* a reminder to run opencode --version once to initialize config\n* after \\~10s, it shows an update hint: npm install -g opencode-studio-server@latest\n* quick links to github and npm\n\nhttps://preview.redd.it/kt62mivmx7dg1.png?width=1920&format=png&auto=webp&s=0ef0fb3223871eade1e093f547a209a1c1b2418f\n\n**protocol handler: local open mode + queued actions**\n\n* opencodestudio://launch?open=local starts the backend and opens http://localhost:3000\n* deep links now create a pending action that studio asks you to confirm (import skill, import plugin, etc)\n* mcp deep links are treated more cautiously now (the app won‚Äôt blindly execute arbitrary command strings from a url)\n\n**ui + site basics**\n\n* updated app icons/favicons\n* added robots.txt + sitemap for the hosted site\n\n# update (hosted frontend mode)\n\nif you‚Äôre coming from v1.0.5, you mainly just update the backend:\n\n`npm install -g opencode-studio-server@latest`\n\nrepo: [https://github.com/Microck/opencode-studio](https://github.com/Microck/opencode-studio)  \nsite: [https://opencode-studio.micr.dev](https://opencode-studio.micr.dev)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qc9zs0/opencode_studio_v133_usage_dashboard_presets_and/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nzhei74",
          "author": "toadi",
          "text": "Think this is awesome. Not for my local workflow but more for when I am going to run it on a server. \n\nOnly downside I see is that opencode config is version managed and that seems to get lost with this.",
          "score": 2,
          "created_utc": "2026-01-14 04:17:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzhfvd4",
              "author": "MicrockYT",
              "text": "Could you go a bit more indepth as to what do you mean? All of your settings still live in your opencode.json, this just manages the settings via other files/temp files and such",
              "score": 1,
              "created_utc": "2026-01-14 04:26:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzhzt4c",
                  "author": "toadi",
                  "text": "Was maybe too short on it.\n\nLocally I don't see any reason to run your system. Text files are much easier to manage and edit.\n\nI would look into using it server side where I run opencode 24/7. This way it would be easier to edit the config without logging into the server itself. But I still need to login because each time I use your ui to edit it I need to login and git commit it anyway. Maybe that could be a feature to git commit it from the UI too :)",
                  "score": 1,
                  "created_utc": "2026-01-14 07:00:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qgnad6",
      "title": "Fix memory Leak please",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/8rc4r45sv6eg1.png",
      "author": "ZookeepergameFit4082",
      "created_utc": "2026-01-18 23:07:16",
      "score": 31,
      "num_comments": 4,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qgnad6/fix_memory_leak_please/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0er6n5",
          "author": "james__jam",
          "text": "Sounds like something that needs to be posted in github issues and not reddit üòÖ",
          "score": 16,
          "created_utc": "2026-01-19 02:54:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0h8wmh",
          "author": "FatherImPregnant",
          "text": "Are you using OhMyOpencode? I‚Äôve noticed the same issue",
          "score": 1,
          "created_utc": "2026-01-19 14:15:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0hbqfm",
          "author": "trypnosis",
          "text": "I use basic opencode with a few mcps and run them all day multiple instance in tmux and my memory is fine. \n\nCould it be an addon or customisation of some kind?",
          "score": 1,
          "created_utc": "2026-01-19 14:30:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gaxla",
          "author": "AVX_Instructor",
          "text": "Its probably LSP, i have get simular issue, if keep long session in huge code base",
          "score": 1,
          "created_utc": "2026-01-19 10:05:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfsg1t",
      "title": "Switch to OpenCode for Money Efficiency",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qfsg1t/switch_to_opencode_for_money_efficiency/",
      "author": "Demon-Martin",
      "created_utc": "2026-01-17 23:34:26",
      "score": 30,
      "num_comments": 48,
      "upvote_ratio": 0.95,
      "text": "Heyo devs,\n\nBeen thinking on switching to OpenCode from Cursor to save some money.\n\nCurrently I run 2 cursor ultra accounts and I am still burning though limits too quickly. Can‚Äòt afford to keep those costs tho, so I been planning on switching to OpenCode with a few chatgpt/google (maybe glm) accounts. I‚Äòm pretty Sure those would end up being was cheaper for more tokens. My biggest costs is Claude Opus 4.5.\n\nThe problem is: I love cursor‚Äòs IDE and I really got used to it. I don‚Äòt really like CLIs (didn‚Äôt like claude code too).\n\nAnd sadly I read that Anthropic is now actively attacking external usage of their subs.\n\nI want to test OpenCode (or something similar). OpenChamber is what I found, but thats more like an Chatbox than an Editor if I understood correctly.\n\nI also tried Google‚Äòs AntiGravity but it‚Äòs straight up not the level that Cursor is. And I also read last days that they also started making rate limits worse.\n\nWhat would you do in my situation? Is there a good OpenCode Extension? How good is OpenCode actually?\n\nThanks.\n\nEDIT:\n\nI forgot to mention, I currently usually work like this:\n\nI first let a cheaper model do some research in the project based on a task. Then use Opus to create a plan and iterate till it creates a plan that follows what I want. Then I execute this plan with either composer, if I want it fast, or Gemini Flash 3, if I want it cheap (there is no other cheap model on cursor that‚Äòs also good, flash is the 2nd cheapest next to GPT 5 nano on cursor, afaik). If Gemini fails, I also let it run though Gemini 3 Pro, Claude Sonnet and Opus itself, depending on the situation and project.\n\nEDIT 2 (18.01.2026):\n\nI tried OpenCode, added my ChatGPT Sub, Google Sub and GitHub Copilot Sub (got most of it for free because I am a student). It generally worked good, but I still don‚Äòt really like working in the CLI. It just doesn‚Äòt give me the User Experience and viewing that an Editor like Cursor gives me. I also tried OpenCode Desktop and that‚Äòs also not optimal.\n\nEven tho my credit usage might suggest otherwise: I am not a ‚Äûpure vibe coder‚Äú. I actively manually check all edits, fix stuff manually and code manually. I don‚Äòt let AI do everything by itself.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qfsg1t/switch_to_opencode_for_money_efficiency/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "o07ig6h",
          "author": "Putrid-Pair-6194",
          "text": "I was exactly the same situation with cursor. So recently, I switched to a combination of opencode plus Antigravity. For me, the differences in antigravity from cursor for me were very small. \n\nSo now my set up is focused on opencode with the antigravity authentication extension. That gives me access to all of the opus and sonnet usage you get with antigravity. The Opus and sonnet usage you get with a single user is very limited. But, you can significantly increase that by buying a $20 a month family plan to the Google AI Pro subscription. That subscription allows you to sign up five ‚Äúfamily members‚Äù.  Every family member gets its own unique quota for antigravity Claude models. So if you set this up for $20 a month you get a fairly substantial amount of daily Claude usage. \n\nI also purchased a three dollar a month GLM 4.7 subscription for day-to-day tasks. Together the Google AI pro subscription with the ‚Äúfive family members‚Äù and the GLM 4.7  subscription give a very significant amount of usage for low cost. That‚Äôs probably enough for most people, but I also have a ChatGPT $20 a month subscription that also hooks into opencode. ChatGPT 5.2 may be slow, but I found it to be very reliable. I have plenty of horsepower for 4 to 5 hour coding sessions.\n\nThis is certainly much more complex than just paying for cursor. But my cursor bills were often exceeding $120 a month. Right now this costs me closer to $40-$50 a month and I don‚Äôt feel like I‚Äôm losing much. The extra complexity may not be right for everyone, but it works pretty well for me.",
          "score": 13,
          "created_utc": "2026-01-18 01:01:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o085r0r",
              "author": "Delicious_Ease2595",
              "text": "How do you use my multiple family accounts with OpenCode? I'm using the same setup between Antigravity and OpenCode",
              "score": 3,
              "created_utc": "2026-01-18 03:06:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o08rn9n",
                  "author": "Putrid-Pair-6194",
                  "text": "I don‚Äôt remember the details off-hand, but I think instructions were on the antigravity opencode authentication repo. I‚Äôm assuming you have setup 5 gmail accounts and added them to your family. Then if memory serves, you use the instructions for the antigravity authentication extension to log into each one. And the extension rotates across all of them automatically.",
                  "score": 1,
                  "created_utc": "2026-01-18 05:24:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o099lgn",
              "author": "pl201",
              "text": "Don‚Äôt think Google AI pro family share each gets separate quota for $20. It‚Äôs one pool shared with up to 5 people. Don‚Äôt believe it is very useful if more than one person try to use Antigravity.",
              "score": -1,
              "created_utc": "2026-01-18 07:55:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0cln4p",
                  "author": "Putrid-Pair-6194",
                  "text": "I don‚Äôt know what are you basing that view on. Here is information from Google that aligns with my personal experience. Other forums seem to concur.\n   \n\n1. Individual Quotas for Family Members\nAccording to Google One Help and official developer forum clarifications from January 2026.\n  \n\n‚Ä¢ Independent Limits: Each member of a Google Family group (up to 5 additional members) receives their own full set of daily and recurring rate limits.¬† \n‚Ä¢ Not a Shared Pool: Unlike storage (which is shared from a common pool), AI quotas for features like Antigravity are per-user. One person‚Äôs heavy usage does not deplete the quota for another family member.",
                  "score": 1,
                  "created_utc": "2026-01-18 20:10:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07qoil",
          "author": "Coldshalamov",
          "text": "[z.ai](http://z.ai) subscription (https://z.ai/subscribe?ic=QDKACAZ1KX and 3x  the usage of claude pro) $2.50 a month\n\nGithub copilot with unlimited chatgpt 4o, 4.1, 5 mini, and grok code fast: $10/m\n\nOpencode Zen: Big Pickle, GLM 4.7, Minimax 2.1, and grok code fast 1 for free\n\nMinimax subscription: $2/m\n\nMoonshot Kimi k2 thinking subscription: $3/m\n\nAll told in opencode: $14.50/m and will never ever hit my limits. I have an extensive subagent driven /build command I loop 3 times that takes 12 hours each, and a /prune command I run once or twice to trim the fat once its done, and then 90% of my projects are functional and need a few tuneups.",
          "score": 9,
          "created_utc": "2026-01-18 01:44:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08mm7s",
              "author": "GullibleDragonfly131",
              "text": "Can you share your Git repo? I'm interested to see how those LLMs compare to Opus.",
              "score": 2,
              "created_utc": "2026-01-18 04:49:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o09r38q",
              "author": "Rygel_XV",
              "text": "How did you get the Minimax and Kimi subscription so cheap? I can find both for $10 respective $9 per month.",
              "score": 1,
              "created_utc": "2026-01-18 10:37:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09rhh8",
                  "author": "Coldshalamov",
                  "text": "strangely, you have to argue with kimi for the price, there's like a promotional event but it actually seems like its response is largely uncalibrated from the price it gives, you just have to keep prompting it until it gives you the right price, I've done it multiple months in a row on the same account. It does look to me now that I checked that the $2 starter plan promo that they had has ended, I know [z.ai](http://z.ai) has theirs until the 30th so i plan on inviting myself and getting another $25 year of lite just because, who knows what i could automate with an extra key.",
                  "score": 1,
                  "created_utc": "2026-01-18 10:40:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0a1f2b",
              "author": "ekalaivan",
              "text": "How to get z ai sub so cheap? In fact except for GitHub i don't see how you get those services for that cheap!",
              "score": 1,
              "created_utc": "2026-01-18 12:08:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0a485s",
                  "author": "Rygel_XV",
                  "text": "They have a reduced price offer running until 31.01. And if you pay quarterly or yearly you get a big discount as well. On top of that they have referral codes for another 10%.\n\nFor example here is my referral :)\nhttps://z.ai/subscribe?ic=JQTB1W1M0L\n\nI think their idea is to lock in people now. If you prepaid for a whole year, will you switch to a different company with a better model if it would arrive?\n\nI myself chose to get the quarterly plan. To play it safe.",
                  "score": 2,
                  "created_utc": "2026-01-18 12:30:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07rrix",
          "author": "FlyingDogCatcher",
          "text": "What are you people doing that you burn through two premium accounts and still can't afford them?",
          "score": 5,
          "created_utc": "2026-01-18 01:49:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09bufv",
              "author": "P1zz4-T0nn0",
              "text": "I've got the same question. I'm a self-employed senior-developer coding all day and I don't hit the limits on a single Max 5x lol. Maybe that are people who don't actually know programming and try 10 workstrees at once, idk.",
              "score": 2,
              "created_utc": "2026-01-18 08:15:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09iegy",
                  "author": "Demon-Martin",
                  "text": "No I don‚Äôt run 10 work trees, and I am a Full-Stack Developer. Opus is just way too expensive. If I understood correctly, Claude Subs can‚Äòt even be compared with Cursors costs. The sub‚Äòs efficiency is way higher than cursors prices.",
                  "score": 1,
                  "created_utc": "2026-01-18 09:16:15",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o09n3uc",
                  "author": "UMANTHEGOD",
                  "text": "Power users (doing ralph loops etc) can burn through tokens pretty quickly but it depends on what you're using it for. I'm currently building a personal budget app, a personal fitness app and a refactoring app for work so I'm getting limited constantly.\n\nAll vibe coded of course because the quality of the code doesn't really matter for these apps.\n\nI've also used opus for everything and I could probably be more mindful to swap to sonnet at times.",
                  "score": 0,
                  "created_utc": "2026-01-18 10:00:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o09i6ns",
              "author": "Demon-Martin",
              "text": "My current project is a rather big turborepo with multiple packages and projects (apps) and most tasks require a big context for the produced code to be good and properly use the available packages. I am already running different methods to minimize the context usage, but still some opus requests cost like 1-3$, and when you code for like 8 hours straight a day, that adds up after time.\n\nObv running a simpler project with less context would be way cheaper.",
              "score": 1,
              "created_utc": "2026-01-18 09:14:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0730p6",
          "author": "No-Concentrate-6037",
          "text": "I would try to learn to use the CLI if I want Opus that badly",
          "score": 3,
          "created_utc": "2026-01-17 23:39:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o076fwr",
              "author": "Demon-Martin",
              "text": "I assume you are talking about Claude Code / an Anthropic Sub with OpenCode\n\nProblem is: I read a TON of negative information about Anthropic the past weeks.\n\nClaude Code is consuming an enormous big amount of tokens compared to before. They are making the ratelimits way way more harsh. And I personally don‚Äòt really like when I want to work, but can‚Äòt because the provider decided to make the model 10x dumber and make the token limit to be 1 prompt per session.\n\nAlso, read that opencode and anthropic ain‚Äòt best friends atm.\n\nhttps://www.reddit.com/r/ClaudeAI/comments/1qa50sq/anthropic_banning_thirdparty_harnesses_while/\nhttps://news.ycombinator.com/item?id=46625918\n\nInfo I was talking about with ratelimits:\nhttps://www.theregister.com/2026/01/05/claude_devs_usage_limits/\nhttps://github.com/anthropics/claude-code/issues/16157#issuecomment-3712177862\nhttps://news.ycombinator.com/item?id=46514221\n\nTheir discord also has an open thread about it with people complaining daily, but the main is probably: https://github.com/anthropics/claude-code/issues/16157",
              "score": 3,
              "created_utc": "2026-01-17 23:57:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o07kjy2",
                  "author": "Historical-Lie9697",
                  "text": "Github copilot is actually not bad for $10/month for supplementing Claude use, has unlimited use of gpt5 mini for easy stuff and 300 premium requests/month that includes a lot of models and they all work in OpenCode. I think for a budget that + Codex $20/m to use them all in OpenCode is a good option. Then if you want multimedia generation and the big context window you could add gemini",
                  "score": 3,
                  "created_utc": "2026-01-18 01:12:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o07bcr3",
                  "author": "No-Concentrate-6037",
                  "text": "No, I mean using Claude Code itself. And yes. I know about all above discussion, but hard to beat Opus as of now",
                  "score": 2,
                  "created_utc": "2026-01-18 00:23:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o08rnhh",
          "author": "NearbyBig3383",
          "text": "People use chutes.ai, it's only 20 bucks man, it's cheap and it never runs out.",
          "score": 3,
          "created_utc": "2026-01-18 05:24:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o092rn0",
              "author": "MorningFew1574",
              "text": "How does chutes compare to nanogpt?",
              "score": 1,
              "created_utc": "2026-01-18 06:54:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0fy6zf",
                  "author": "Complex-Maybe3123",
                  "text": "NanoGPT user here. I`m currently using their Subscription. Never used chutes. \n\nI believe NanoGPT uses some cheaper providers to keep their prices competitive, so I end up getting some very big token speed variation. I use mostly GLM 4.7 Thinking nowadays. Hardly for coding, but in the end, there`s not a lot of difference. Sometimes my requests start processing instantly, others times, it seems like I enter a queue. I time the whole request time (from the moment I press enter, to the moment I receive the whole response, I don`t usually use streaming), so I`m not sure of the actual TPS. But if I`d calculate the tokens per second with the whole request time, sometimes I get 100t/s, some rarer cases it`s very close to 10t/s. Usually it`s more in the middle. But I believe this variation is the delay until my request starts getting processed instead of actual TPS variation. These calcs I mentioned were usually done with around 20k~30k input context and 1k~3k output.\n\nI tried the big boys (GPT and Claude) a few times and they seem to respond the same as from the source.\nAll in all, I`m not a vibe coder, I prefer to use mostly tab-autocomplete, which is outside of what NanoGPT offers. So I don`t really mind the speed variation. At this point in time, I wouldn`t leave NanoGPT for any other provider. New released models become available almost immediately. The devs are also always listening to the users and suggestions are quickly implemented (when they make sense).\n\nSo for open source models, I`m of the opinion that it`s the best, in terms of price, available models and support. When it comes to premium models, there doesn`t seem to be much difference from other providers besides some discounts.",
                  "score": 2,
                  "created_utc": "2026-01-19 08:05:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o09zvdi",
          "author": "kkordikk",
          "text": "Actually switch your approach. Let the more expensive models do the research and plan the work out with granular tasks. Then smaller models to implement small tasks. GLM is great, cheap, fast, limits reset each 5hrs, it‚Äôs great reasoning, multimodal. I highly recommend getting quarterly plan right now, there‚Äôs a promo still going. Also free Gemini API key and if you like opus, just use it sparingly via Anthropic 100$ sub. Also, you can still use free cursor as an ide",
          "score": 2,
          "created_utc": "2026-01-18 11:55:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a2e35",
              "author": "Demon-Martin",
              "text": "I would be using other subs, but cursor itself sadly doesn‚Äôt really support it inside their built-in interface. I don‚Äòt really like CLIs/Terminals so OpenCode/Claude Code isn‚Äòt optimal for me.\n\nI was planning on getting GLM or Minimax or similar, just cursor is very annoying with only supporting ‚Äûone base url overwrite‚Äú that breaks all other models‚Ä¶",
              "score": 1,
              "created_utc": "2026-01-18 12:16:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0a6rb6",
                  "author": "jorgejhms",
                  "text": "Maybe you could try Zed then. Is a code editor written in Rust (it's not a fork of vscode) and one of their key principles is to be open. They allow you to use it's AI features with their own subscription or with any API key. I have it set with GLM currently, with also copilot free and Gemini API keys. They also developed the Agent Client Protocol (ACP) that allows third party cli agents like Claude Code or OpenCode to be used inside Zed UI, like a panel. Seems like the best option for you that don't like terminals.",
                  "score": 2,
                  "created_utc": "2026-01-18 12:50:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0b9pic",
                  "author": "kkordikk",
                  "text": "Huh? It does. Go into cursor settings -> models -> scroll down and there you can use Anthropic key, openAI endpoint / API key (this is for ChatGPT, custom gateway like z.ai) \nPersonally I‚Äôm hosting LiteLLM (alternative to OpenRouter) and using all my models through it",
                  "score": 1,
                  "created_utc": "2026-01-18 16:24:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0afs8j",
          "author": "febryanvald0",
          "text": "Try OpenCode Black\n\n\nhttps://opencode.ai/black",
          "score": 2,
          "created_utc": "2026-01-18 13:50:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0adzyz",
          "author": "Fun-Understanding862",
          "text": "would suggest you to give github copilot a try, it has upped its game, for me claude code(20$) and github copilot(10$) plan works well",
          "score": 1,
          "created_utc": "2026-01-18 13:39:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0am2px",
          "author": "PweraUsog",
          "text": "Switch to Qwen CLI",
          "score": 1,
          "created_utc": "2026-01-18 14:26:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0f900o",
          "author": "RayanAr",
          "text": "Isn't opencode slower than claudecode?",
          "score": 1,
          "created_utc": "2026-01-19 04:43:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qci8r0",
      "title": "GLM-4.7 is performing much better after updating my orchestrator to v0.2.0.",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qci8r0/glm47_is_performing_much_better_after_updating_my/",
      "author": "ChangeDirect4762",
      "created_utc": "2026-01-14 08:43:23",
      "score": 25,
      "num_comments": 20,
      "upvote_ratio": 0.89,
      "text": "[https://www.npmjs.com/package/opencode-orchestrator](https://www.npmjs.com/package/opencode-orchestrator)\n\nI‚Äôve been testing GLM-4.7 for complex coding tasks, but I used to struggle with its instability‚Äîspecifically, it often outputted gibberish or got stuck in reasoning loops during heavy refactoring missions.\n\nHowever, since I updated my project (**opencode-orchestrator**) to v0.2.0 about an hour ago, the model's performance has significantly stabilized. It's handling \"Full Refactor\" tasks with much higher reliability and fewer refusals than before.\n\nI'm not sure if there was a silent update on the model's side or if the improved environment scanning/context management in my v0.2.0 update finally clicked with GLM's architecture, but the difference is night and day.\n\nIf you were disappointed with GLM-4.7's consistency before, it might be worth giving it another shot with a better orchestration layer.\n\nnew post:  \n[https://www.reddit.com/r/opencodeCLI/comments/1qfzaju/built\\_a\\_multiagent\\_orchestrator\\_plugin\\_for/](https://www.reddit.com/r/opencodeCLI/comments/1qfzaju/built_a_multiagent_orchestrator_plugin_for/)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qci8r0/glm47_is_performing_much_better_after_updating_my/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nzigh99",
          "author": "Emotional_Note_2557",
          "text": "I tried this kind of subagents configuration in many different ways to try to optimize opencode. But nothing ever beats the workflow Plan -> Build that is native in opencode. I think subagents are not efficient yet.",
          "score": 10,
          "created_utc": "2026-01-14 09:38:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nziy8i6",
              "author": "aeroumbria",
              "text": "I've tried many setups and almost all orchestrator setups are worse than naive workflow. However this one https://github.com/rokicool/gsd-opencode posted a few days ago does seem to work. My theory is that any handover is lossy and error-prone, regardless of whether it is context compression or subagent delegation (similar principle to the paper about most LLMs can't solve long tasks because even a 1% failure rate adds up over hundreds of thousands of turns). Typical orchestrator workflows have more handovers than context compressions if it were a naive workflow, so there are more likely to accumulate error. However, if you very carefully keep persistent records, gradually build up process memories, constantly validate them, and use these records in place of adhoc handover messages, subagents will be closer to pure state machines and may actually work.",
              "score": 3,
              "created_utc": "2026-01-14 12:11:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzjmrms",
              "author": "juanloco",
              "text": "Been doing a lot of experimentation myself and I have to agree. Plan/Build iterations with human in the loop + Sonnet/Opus 4.5. Cannot get better results than this no matter what I try. Not that I'm complaining but I do wish I was not locked into anthropic models. That is the reason I keep searching for alternatives.",
              "score": 2,
              "created_utc": "2026-01-14 14:37:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzjn5cl",
          "author": "Codemonkeyzz",
          "text": "a noob question : why is it an NPM package ? Why not just  MD files ?",
          "score": 2,
          "created_utc": "2026-01-14 14:39:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvkzey",
              "author": "awfulalexey",
              "text": "Using a MD, it is difficult to control the logic of how the agent will interact with the context - which context is better to delete now, and which one is better to add. It is the logic of calling tools, and everything else. This should be described directly in the code.\n\nMD files are like clothes, you can change them, change them, take them off. And here, apparently, we are talking about the very inside.",
              "score": 1,
              "created_utc": "2026-01-16 06:33:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzjdny5",
          "author": "Pleasant_Thing_2874",
          "text": "There was something done on the model side within the last couple days imo.  One thing I've also noticed with my orchestrators that GLM breaks on tool calls once the token count gets too high.   Also the rate limits for GLM 4.7 change based on time of day which can get super annoying.  There are times it'll allow up to 10 calls at a time, then 5, then 3, sometimes even 2.  I'm guessing it auto adjusts based on load on the servers but it can really be annoying trying to plan out sprints at the wrong time of day",
          "score": 1,
          "created_utc": "2026-01-14 13:48:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzk4ub5",
          "author": "icaruk",
          "text": "What's the difference between this and Sisyphus?\n\nhttps://github.com/code-yeongyu/oh-my-opencode",
          "score": 1,
          "created_utc": "2026-01-14 16:03:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkze24",
          "author": "bazeso64",
          "text": "This looks good, like a lighter Sisyphus.\n\nI think you should make it a \"real\" opencode plugin with an installation wizard maybe so we can have a config file where we can change models for each subagent, it would be pretty neat !",
          "score": 1,
          "created_utc": "2026-01-14 18:21:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwex0p",
          "author": "fasti-au",
          "text": "Not sure if applicable but in my view the way this shit is being done is only good if you can cut out think responses better.   \n\nSee if there‚Äôs an error the think area is actually where all the debug concepts come but it‚Äôs not learnt as logic it‚Äôs boilerplating so there is this issue of it gets really bad at something they api it think allows boiler plate to replace previous failing.   Solves the problem.   Unless you want to use say open ai api v1.  \n\nWhen 3.5 and 4 were released OpenAI couldn‚Äôt get their own api to stick.  They had it in prompts but it still wasn‚Äôt loud enough gb for new reasoners to learn.    They force fed it v2 and it now works but you can‚Äôt really find OpenAI api v1 original without specific amount of force or they use internal code forces in prompting control.  \n\n\nThis means that the ‚Äúthink‚Äù part is a overrule to the modes or user layered system prompt so by the time you get back to response create your not even looking at the tokens you gave but what it decided suited its training.   Your prompt meant nothing. Until it gets a reject or stop and acknowledge it‚Äôs basically not your prompt but it‚Äôs own self direction to do what it insists is the way.   \n\nThings like <> style and xml messaging seems to have a different effect and if you actually lead with the steps to use to debug ie if it fails look at this file for the solution.  And then put new debug messages in there will route better than redirecting so when orchestrator rolls forward it can‚Äôt really pull the reigns \n\nHow it it‚Äôs changing its own prompting might have been a bigger effect.  Even if it‚Äôs just a few things like an extra filenames referenced like debugtools being in context as available vs no file name can flip that debug paths chain elsewhere.  \n\nWhy dead files andb vscode make Claude remake files that it just deleted if you cancele and redo because of ghosting\n\nLong message to say.   Your prompting only works if it decides you gave it a direction not self guess mode",
          "score": 1,
          "created_utc": "2026-01-16 11:00:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nziik2r",
          "author": "Federal_Spend2412",
          "text": "Glm 4.7 + cc much better then glm 4.7 + opencode",
          "score": -2,
          "created_utc": "2026-01-14 09:58:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzn3vqp",
              "author": "iwearcr0wns",
              "text": "Unfortunately (I feel like) this is the truth. I've been using OpenCode a lot with my GLM coding plan but have been disappointed with the output. I'm very patient with these tools and I honestly love OpenCode altogether. The problem I have is that more often than not, the output needs to be cleaned up just to get it to compile and trial what it did (rinse and repeat). On the other hand with Claude Code, the same exact workflow ATLEAST compiles the first time around and I can iterate a lot quicker. I'm certain that it's just GLM with OpenCode as its harness. If I use OpenCode with other models like Sonnet, it feels good again. \n\nThis is just my subjective experience, and i've been looking around online for more discussion about it. The quality of the output is one thing, and we know that's inconsistent at best by nature of LLMs, but it actually feels like something just isn't working well between GLM + OpenCode. It's really a bummer because i prefer to use OpenCode, but for now I'm using Claude Code for better reliability",
              "score": 3,
              "created_utc": "2026-01-15 00:23:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzoxjwf",
              "author": "BuildAISkills",
              "text": "I'm not sure why you're getting down voted - Z.ai specially designed it for Claude Code, so it figures it would perform best there.",
              "score": 2,
              "created_utc": "2026-01-15 07:42:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzoztky",
                  "author": "Federal_Spend2412",
                  "text": "Glm 4.7 + cc is very close to 4.5 sonnet. I just telling the truth.",
                  "score": 1,
                  "created_utc": "2026-01-15 08:03:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nziolro",
              "author": "lundrog",
              "text": "But uses more tokens",
              "score": 1,
              "created_utc": "2026-01-14 10:53:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzk5xf7",
                  "author": "Royal-Huckleberry943",
                  "text": "Tokens dont matter with GLM though its really cheap. Glm 4.7 needs more detailed plan and handholding. Budget worthy. Tried it out with claude code, Its pretty good, I got the Max plan, mainly use it as the workhorse with other models for planning, reviewing. Its for people who want to conserve their budget, might need a stronger model to break through some complex places where it loops and gets stuck. But look out for the concurrency limit per plan for glm coding plans: lite - 2, pro - 5, max - 40 (concurrent requests limit) . Join their discord, discuss with other people then buy if you feel its worth it.\n\nMake sure to ask it to do: Round 1: Detailed Plan -> Verify Plan (Web search MCP/ Docs MCP) -> Write Code -> Run and Test. Next Round 2 do the same and write out the tests and ask it to run tests. Repeat. Works well for me. If you get stuck with a bug, clear context, ask it to run sub agents to explore and find the issue. Pretty much works all the time.\n\nGet a 60% Christmas Offer an extra 10% discount on top of that. Hurry before it expires!:  \n[https://z.ai/subscribe?ic=AJJOVACC4X](https://z.ai/subscribe?ic=AJJOVACC4X)",
                  "score": 1,
                  "created_utc": "2026-01-14 16:08:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzieqif",
          "author": "deadman87",
          "text": "I have opencode installed globally. I ran the \\`npm install -g opencode-orchestrator\\` and I am not seeing Commander agent or /task in opencode",
          "score": 0,
          "created_utc": "2026-01-14 09:21:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzixhgv",
              "author": "ChangeDirect4762",
              "text": "please tap key push",
              "score": 1,
              "created_utc": "2026-01-14 12:05:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzixmka",
                  "author": "ChangeDirect4762",
                  "text": "is that 0.2.0? please tab key push\n\nhttps://preview.redd.it/a9tiawqh2bdg1.png?width=1740&format=png&auto=webp&s=47acb9f6dfa494cc6ac3a5d08c960c315420eb2a\n\nd",
                  "score": 1,
                  "created_utc": "2026-01-14 12:06:43",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qchuz3",
      "title": "Ghostty + OpenCode CLI: Way Better Than IDE Terminals",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1qchuz3/ghostty_opencode_cli_way_better_than_ide_terminals/",
      "author": "0xraghu",
      "created_utc": "2026-01-14 08:18:14",
      "score": 24,
      "num_comments": 30,
      "upvote_ratio": 0.9,
      "text": "Hey r/opencodeCLI folks,\n\nI switched to running OpenCode CLI in Ghostty instead of the built-in terminals in Antigravity/Cursor/VSCode. Huge upgrade for responsiveness and daily use.\n\nWhat I liked:\n\n* Blazing fast & responsive ‚Äì GPU acceleration kills any lag during heavy OpenCode output or Claude queries.\n* Smooth scrolling ‚Äì No jitter or catch-up when flying through long logs, code blocks, or errors.\n* Clean & eye-friendly ‚Äì Crisp fonts, perfect rendering, less strain during long sessions.\n* Native feel & features ‚Äì Built-in splits/tabs work great for multitasking without tmux hassle.\n* Native MacOS feel\n\nMy setup now: Antigravity for quick auto-completions/references, Ghostty on the side for actual OpenCode + Claude work. Simple split-screen magic.\n\nEveryone should try this combo at least once ‚Äì it's free and feels so much nicer. \n\nAny other tweaks I should try for this setup?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1qchuz3/ghostty_opencode_cli_way_better_than_ide_terminals/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nzikn5x",
          "author": "vsilv",
          "text": "tweak: Remove antigravity and grab Neovim in ghosty.",
          "score": 8,
          "created_utc": "2026-01-14 10:18:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzmq5y8",
              "author": "larowin",
              "text": "ghostty + zellij + agent(s) + neovim | helix is the way",
              "score": 3,
              "created_utc": "2026-01-14 23:09:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzmtxxm",
                  "author": "girouxc",
                  "text": "I‚Äôm a tmux convert‚Ä¶ Zellij is amazing. \n\nI‚Äôm a Neovim convert‚Ä¶ Helix is amazing.",
                  "score": 3,
                  "created_utc": "2026-01-14 23:29:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o024blj",
                  "author": "eXoRt0",
                  "text": "Would replace neovim with fresh",
                  "score": 1,
                  "created_utc": "2026-01-17 05:29:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzintih",
          "author": "Recent-Success-1520",
          "text": "Just wait till you try CodeNomad OpenCode UI https://github.com/NeuralNomadsAI/CodeNomad",
          "score": 8,
          "created_utc": "2026-01-14 10:47:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkkfzo",
              "author": "Ang_Drew",
              "text": "not working on windows. tried to install but it cant open",
              "score": 1,
              "created_utc": "2026-01-14 17:14:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzklm6q",
                  "author": "Recent-Success-1520",
                  "text": "Tauri or Electron?\nWorks on Windows, used by many users.\nI can support if you ping me on Discord Opencode server.",
                  "score": 1,
                  "created_utc": "2026-01-14 17:19:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzkk18i",
          "author": "bigh-aus",
          "text": "I'm a big fan of the neovim + ghostty + tmux + opencode stack running on a local server (so you can ssh in and set things running from anywhere).    \n  \nI also have slack setup and the ability to send notifications to that when commands finish (honestly haven't tried this on opencode yet but works well on claude).\n\nI just wish:   \n1. local models were better for my usecase.   \n2. neovim had more stuff built in (or built with a compiled language)  (plugins shouldn't require npm on the machine).",
          "score": 3,
          "created_utc": "2026-01-14 17:12:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nziazn6",
          "author": "Soft_Syllabub_3772",
          "text": "Anyway for this to work in windows?",
          "score": 2,
          "created_utc": "2026-01-14 08:44:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzie1r9",
              "author": "tibn4",
              "text": "I‚Äôm using the same setup on my mbp and tried to implement something similar on my windows machine. \n\nThere are a few terminal options, didn‚Äôt tried them all but in the end I found that Windows Terminal does a great job and with a few custom settings you can really come close to the Ghostty UI",
              "score": 1,
              "created_utc": "2026-01-14 09:14:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nziemwt",
                  "author": "Soft_Syllabub_3772",
                  "text": "Im my laptop i notice claude cli lags in the terminal. I got better usability in vscode.",
                  "score": 2,
                  "created_utc": "2026-01-14 09:20:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzinl71",
              "author": "LabImpossible828",
              "text": "Does this require having my own ChatGPT account? so where can i find cheapest gpt plusÔºü",
              "score": 1,
              "created_utc": "2026-01-14 10:45:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzistgu",
              "author": "FlyingDogCatcher",
              "text": "wsl, but you will have to screw with it to get it to look right",
              "score": 1,
              "created_utc": "2026-01-14 11:29:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzkboma",
              "author": "Michaeli_Starky",
              "text": "Windows Terminal from the Store. Multiplexing, themes, GPU acceleration, image protocol etc.",
              "score": 1,
              "created_utc": "2026-01-14 16:34:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzismtz",
          "author": "FlyingDogCatcher",
          "text": "When you think about it running a TUI in a Terminal in an IDE is a bit of a hat on a hat. What you really want is to drive the IDE from opencode.",
          "score": 1,
          "created_utc": "2026-01-14 11:28:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzissg1",
          "author": "0sko59fds24",
          "text": "Agreed",
          "score": 1,
          "created_utc": "2026-01-14 11:29:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvplm8",
          "author": "RainScum6677",
          "text": "I use OpenCode +  Wave. It's ridiculous how much better it is than any IDE",
          "score": 1,
          "created_utc": "2026-01-16 07:12:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvpnng",
          "author": "byungsker",
          "text": "Oh! How does it compare to Warp?",
          "score": 1,
          "created_utc": "2026-01-16 07:12:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwte4g",
              "author": "0xraghu",
              "text": "Warp is fully featured and focuses on AI development with their own subscription plans. Ghostty is the alternative to native terminal with high levels of customization and speed.   \nI've heard their AI harness is good but I don't want to pay another subscription.",
              "score": 1,
              "created_utc": "2026-01-16 12:47:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzikcqg",
          "author": "typeof_goodidea",
          "text": "just wait until you try vim",
          "score": 1,
          "created_utc": "2026-01-14 10:15:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzib56s",
          "author": "adelope",
          "text": "if you like ghostty (me too), i build some extra stuff around it to make it more suitable for CLI agents (work-tree sidebars, split terminal/file-view, diffs, etc). I would love to get your feedback on it: [www.agentastic.dev](http://www.agentastic.dev)\n\ngoes without saying Opencode is supported.",
          "score": 0,
          "created_utc": "2026-01-14 08:46:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nziveje",
              "author": "0xraghu",
              "text": "Oh that‚Äôs interesting.. will check now üëçüèª",
              "score": 1,
              "created_utc": "2026-01-14 11:50:03",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzj94tb",
              "author": "Enesce",
              "text": "Wezterm support? That's my favourite terminal.",
              "score": 1,
              "created_utc": "2026-01-14 13:22:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzmk0qo",
                  "author": "adelope",
                  "text": "not yet, i'll add the support next week",
                  "score": 1,
                  "created_utc": "2026-01-14 22:38:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzvo3wg",
              "author": "dartoumi",
              "text": "I like to work in opencode cli with auth login to my subscriptions and switch between models in the same chat. Will i be able to do so in agentastic as wel?",
              "score": 1,
              "created_utc": "2026-01-16 06:59:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvofuf",
                  "author": "adelope",
                  "text": "it's a terminal, so the experience is exactly the same as running opencode cli in say ghostty. (as a matter of fact, it will load your ghostty/terminal configs too)  \nthe cherry on top is the sidebar to make work-tree switching easier.",
                  "score": 1,
                  "created_utc": "2026-01-16 07:02:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}