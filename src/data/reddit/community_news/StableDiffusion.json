{
  "metadata": {
    "last_updated": "2026-03-02 02:56:22",
    "time_filter": "week",
    "subreddit": "StableDiffusion",
    "total_items": 20,
    "total_comments": 426,
    "file_size_bytes": 420976
  },
  "items": [
    {
      "id": "1rdnz57",
      "title": "Open source Virtual Try-On LoRA for Flux Klein 9b Edit, hyper precise",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/z8mnc5rwghlg1",
      "author": "Affectionate-Map1163",
      "created_utc": "2026-02-24 18:16:58",
      "score": 751,
      "num_comments": 79,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rdnz57/open_source_virtual_tryon_lora_for_flux_klein_9b/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o76wtwl",
          "author": "Toclick",
          "text": "It would be interesting to see a comparison WITHOUT LoRA and WITH LoRA, because Klein can do this out of the box.",
          "score": 117,
          "created_utc": "2026-02-24 19:28:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o79moqz",
              "author": "DigThatData",
              "text": "The LoRA is so effective, you don't even need to plug the LoRA in!",
              "score": 36,
              "created_utc": "2026-02-25 03:57:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7ekbdo",
                  "author": "IrisColt",
                  "text": "HEH!",
                  "score": 3,
                  "created_utc": "2026-02-25 21:48:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7987ei",
              "author": "berlinbaer",
              "text": "sums up 90% of the posts on this sub.",
              "score": 46,
              "created_utc": "2026-02-25 02:33:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o782n0o",
              "author": "Dogluvr2905",
              "text": "Yeh I had the same question.  I have a workflow now that does this perfectly and LORA is no required.",
              "score": 10,
              "created_utc": "2026-02-24 22:44:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o78oqln",
                  "author": "Vakhoris",
                  "text": "Would you mind sharing that workflow, please?",
                  "score": 9,
                  "created_utc": "2026-02-25 00:43:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7e33i8",
              "author": "ZerOne82",
              "text": "I posted one using Klein 4B no LoRA no magic prompt.  \n[https://www.reddit.com/r/StableDiffusion/comments/1reorcq/tryon\\_klein\\_4b\\_no\\_lora\\_odd\\_poses\\_impressive](https://www.reddit.com/r/StableDiffusion/comments/1reorcq/tryon_klein_4b_no_lora_odd_poses_impressive)",
              "score": 4,
              "created_utc": "2026-02-25 20:28:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7a45ks",
              "author": "Icy_Till3223",
              "text": "Agreed",
              "score": 3,
              "created_utc": "2026-02-25 06:00:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o76y9gv",
          "author": "Legendary_Kapik",
          "text": "Do you really need a LoRA for this? Klein 4B + masking works fine.",
          "score": 12,
          "created_utc": "2026-02-24 19:35:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77rl1s",
              "author": "cderm",
              "text": "Got a Workflow? Would like to try that",
              "score": 1,
              "created_utc": "2026-02-24 21:50:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o77ss40",
                  "author": "Legendary_Kapik",
                  "text": "not mine - [https://civitai.com/models/2336342/comfyui-beginner-friendly-flux2-klein-4b-gguf-simple-cloth-swap-workflow-by-sarcastic-tofu](https://civitai.com/models/2336342/comfyui-beginner-friendly-flux2-klein-4b-gguf-simple-cloth-swap-workflow-by-sarcastic-tofu)",
                  "score": 4,
                  "created_utc": "2026-02-24 21:56:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o843135",
                  "author": "ZerOne82",
                  "text": "I posted one using Klein 4B no LoRA no magic prompt.  \n[https://www.reddit.com/r/StableDiffusion/comments/1reorcq/tryon\\_klein\\_4b\\_no\\_lora\\_odd\\_poses\\_impressive](https://www.reddit.com/r/StableDiffusion/comments/1reorcq/tryon_klein_4b_no_lora_odd_poses_impressive)",
                  "score": 1,
                  "created_utc": "2026-03-01 20:28:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o76pdnw",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 15,
          "created_utc": "2026-02-24 18:54:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76xir0",
              "author": "Mountain-Grade-1365",
              "text": "Fuck body shape this workflow will never show proper fit of the clothes, only perfect fit.",
              "score": 39,
              "created_utc": "2026-02-24 19:31:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o779cxm",
                  "author": "jrox",
                  "text": "is there ANY work flow that can do that?  seems like you’d need a new model and detailed measurements of the person and the clothing or images with scale references",
                  "score": 3,
                  "created_utc": "2026-02-24 20:26:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o77ej9k",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 1,
                  "created_utc": "2026-02-24 20:50:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o77qkkq",
              "author": "sishgupta",
              "text": "Forget body shape, what about knowing the actual shape of the clothes when it rests on a body. It's different from the cutout shape.",
              "score": 8,
              "created_utc": "2026-02-24 21:45:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7a56lr",
                  "author": "Lightspeedius",
                  "text": "You'd need the actual pattern that was used to produce the clothing.\n\nWhich is an interesting idea really. But much more than something StableDiffusion alone can produce.",
                  "score": 1,
                  "created_utc": "2026-02-25 06:09:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o77i6zj",
              "author": "realityconfirmed",
              "text": "Yes. Asking the real question. A lot of these try on models work great with a generic body shape. You really have to fight with the model, checkpoint, Lora to get it to adhere to having a normal garment on a big person. \n\nIn saying that there are consistency Lora's that can help for Qwen and Flux Klein that help sometimes.\n\nThanks OP creator. I will try this anyway. It looks interesting.",
              "score": 2,
              "created_utc": "2026-02-24 21:07:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o79jjmq",
                  "author": "orangeflyingmonkey_",
                  "text": "flux 2 klein edit does a decent job with different body shapes\n\nhttps://imgur.com/xhAZWqF",
                  "score": 1,
                  "created_utc": "2026-02-25 03:37:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o76mibd",
          "author": "techma2019",
          "text": "Is there a comfyUI workflow to try this locally?",
          "score": 15,
          "created_utc": "2026-02-24 18:42:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o786hzk",
              "author": "FreezaSama",
              "text": "This",
              "score": 6,
              "created_utc": "2026-02-24 23:04:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o76kruu",
          "author": "mordin1428",
          "text": "Decent, but it seems to have a bias to longer, baggier T-shirts, even though the specific item shown looks a regular cut",
          "score": 8,
          "created_utc": "2026-02-24 18:34:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7dnb3o",
              "author": "Cheesuasion",
              "text": "There've been uncountable numbers of \"virtual try-on\" posts here, every one of which it seems to me survives about 20 seconds of looking at the examples.\n\nVirtual try-on people (person?): perhaps come back when it works rather than every month or so?",
              "score": 2,
              "created_utc": "2026-02-25 19:14:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o76sl3n",
              "author": "Dzugavili",
              "text": "That might be something you can fix in prompting: you can see it handles folded clothing, so it's probably trying to apply the object against some kind of template in its knowledge. Once you tell it what the clothing item is, there's less guesswork in putting it on the model.",
              "score": 1,
              "created_utc": "2026-02-24 19:09:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o76zntn",
          "author": "rnd_2387478",
          "text": "Are you sure its hyper precise and not ultra precise? Its confusing. /s",
          "score": 9,
          "created_utc": "2026-02-24 19:41:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76w2xt",
          "author": "MudMain7218",
          "text": "Do you need a lora for the edit? Qwen image edit has been doing this without one",
          "score": 3,
          "created_utc": "2026-02-24 19:25:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o773id5",
              "author": "Toclick",
              "text": "When Klein hadn’t even been released yet, Civitai was already flooded with Try-On LoRAs for Qwen, which you can still easily find now.",
              "score": 3,
              "created_utc": "2026-02-24 19:59:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o774ut0",
                  "author": "MudMain7218",
                  "text": "I mean 2511 can already swap clothing",
                  "score": 1,
                  "created_utc": "2026-02-24 20:05:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o76lx3h",
          "author": "Canchito",
          "text": "This is not open source, but open weights.",
          "score": 10,
          "created_utc": "2026-02-24 18:39:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76j4ky",
          "author": "switch2stock",
          "text": "What did you use for video?",
          "score": 9,
          "created_utc": "2026-02-24 18:27:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o781jgj",
              "author": "TinySmugCNuts",
              "text": "pay attention. it literally says 'grok video' at the bottom of each video.",
              "score": 6,
              "created_utc": "2026-02-24 22:38:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o76nhmp",
              "author": "Affectionate-Map1163",
              "text": "grok image to video",
              "score": 0,
              "created_utc": "2026-02-24 18:46:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o76q9sh",
                  "author": "switch2stock",
                  "text": "Ahh okay",
                  "score": 4,
                  "created_utc": "2026-02-24 18:58:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o76qlq6",
                  "author": "Hefty_Development813",
                  "text": "I would think similar could be done with wan, just not so quick. Is this being done on the fly or you run them all and store? How much is grok img to vid api?",
                  "score": 5,
                  "created_utc": "2026-02-24 19:00:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o777jx9",
          "author": "Life_Acanthaceae_748",
          "text": "where I can find workflow for local machine?\n\n",
          "score": 3,
          "created_utc": "2026-02-24 20:18:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77erhf",
          "author": "Snoo_64233",
          "text": "upload it to Civit?",
          "score": 3,
          "created_utc": "2026-02-24 20:51:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76xljk",
          "author": "thisiztrash02",
          "text": "im going to remake this with ltx2 and wan variants for the community since we are open source only but thanks for the idea",
          "score": 3,
          "created_utc": "2026-02-24 19:32:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o770ak0",
          "author": "Possible-Machine864",
          "text": "I always wish that these virtual try on models had some kind of grounding process so that you know that the size of the garment is accurate on the person.",
          "score": 2,
          "created_utc": "2026-02-24 19:44:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79abc1",
          "author": "CodeCarnival-666",
          "text": "Klein can do this out of the box",
          "score": 2,
          "created_utc": "2026-02-25 02:44:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7fr46o",
          "author": "creuton22",
          "text": "Klein is not open to commercial use.  \nTheres another pipeline using commercial use free?",
          "score": 2,
          "created_utc": "2026-02-26 01:36:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7hm8zm",
              "author": "stephen370",
              "text": "The 4B one is apache 2.0 so you could use that one",
              "score": 1,
              "created_utc": "2026-02-26 09:54:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7w9dyt",
                  "author": "creuton22",
                  "text": "But the quality is similar?",
                  "score": 0,
                  "created_utc": "2026-02-28 15:51:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o76oedo",
          "author": "Eisegetical",
          "text": "great - but useless due to the license. \n\nthis type of tool is oriented to be used as a commercial product tool, but the Klein9B license kills that. ",
          "score": 6,
          "created_utc": "2026-02-24 18:50:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7amy8h",
              "author": "Ok-Reporter-6255",
              "text": "Who cares about this?",
              "score": 2,
              "created_utc": "2026-02-25 08:47:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o76vqcq",
              "author": "One-Security-8742",
              "text": "This isn't useless. The license still allows for usage of images generated by 9B. You just can't monetize the model directly or provide a service that uses the model.",
              "score": 1,
              "created_utc": "2026-02-24 19:23:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o78bpyv",
                  "author": "andy_potato",
                  "text": "> or provide a service that uses the model\n\nwhich is exactly what an e-commerce website with try-on function is doing. That's why the 9b variants of Klein are useless for such purposes.",
                  "score": 4,
                  "created_utc": "2026-02-24 23:32:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o76xqow",
                  "author": "Luckyrabbit-1",
                  "text": "it's useless if it doesn't provide value,  it's not virtual try on if it just using generated images.",
                  "score": 1,
                  "created_utc": "2026-02-24 19:32:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7chs85",
              "author": "Subject-Pineapple837",
              "text": "New here. They guy says its open source. Whats the catch? Like can i use this to offer services for my local clothing stores? Genuine question",
              "score": 1,
              "created_utc": "2026-02-25 16:06:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7cno7x",
                  "author": "Eisegetical",
                  "text": "you can use it freely but you cant use it to make money as a service. thats what the license says. \n\nso your exact scenario is a no go. ",
                  "score": 3,
                  "created_utc": "2026-02-25 16:33:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o78bwlm",
              "author": "andy_potato",
              "text": "I wish people would not downvote you for this because it is true.",
              "score": 1,
              "created_utc": "2026-02-24 23:33:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o76jzdo",
          "author": "Enshitification",
          "text": "Nice. Is the LoRA flexible? Does it require white backgrounds and standing subjects?",
          "score": 1,
          "created_utc": "2026-02-24 18:30:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76kdur",
              "author": "Affectionate-Map1163",
              "text": "yes it is",
              "score": 1,
              "created_utc": "2026-02-24 18:32:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o778i92",
          "author": "3Fatboy3",
          "text": "This is great. \n\nHave you considered doing this with someone you know and clopth they already own? You could compare AI wiht real results.",
          "score": 1,
          "created_utc": "2026-02-24 20:22:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77hs8g",
          "author": "calvin-n-hobz",
          "text": "What's the difference between the model and the \"comfyui\" model in the repo?",
          "score": 1,
          "created_utc": "2026-02-24 21:05:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77hwkk",
          "author": "terrariyum",
          "text": "For Klein 9B **Base**, not distill",
          "score": 1,
          "created_utc": "2026-02-24 21:06:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o784e8w",
          "author": "Upper_Dependent1860",
          "text": "Does this work with non-white backgrounds?\n\n\nIf it's say a room, will it edit the background as well? ",
          "score": 1,
          "created_utc": "2026-02-24 22:53:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78ot2p",
          "author": "newaccount47",
          "text": "Can it do silly high fashion \"art as clothes\"? ",
          "score": 1,
          "created_utc": "2026-02-25 00:43:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78pnso",
          "author": "Loose_Object_8311",
          "text": "What happens if you provide no reference images for the clothes?",
          "score": 1,
          "created_utc": "2026-02-25 00:48:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79b4e7",
          "author": "Colon",
          "text": "wow. all this is telling me is i have no style",
          "score": 1,
          "created_utc": "2026-02-25 02:49:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79o1yh",
          "author": "MediocreInside8628",
          "text": "Holy moly, its my first time seeing this, since I don't have a beefy gpu enough to run this, waiting for z image edit to come out.",
          "score": 1,
          "created_utc": "2026-02-25 04:05:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7azuap",
          "author": "Difficult_Total_104",
          "text": "Where was this created?",
          "score": 1,
          "created_utc": "2026-02-25 10:46:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7cjmy7",
          "author": "IllRecommendation144",
          "text": "good",
          "score": 1,
          "created_utc": "2026-02-25 16:14:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7cuna3",
          "author": "CupBig7438",
          "text": "Is there a comfyUI workflow? Please :(",
          "score": 1,
          "created_utc": "2026-02-25 17:04:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7il4yd",
          "author": "Foyxal",
          "text": "Is there any model which can change the shoe instead of clothes? I'm looking gor something similar for a while but instead of clothing i want to do it with shoe keeping the shoe design and logo properly constant.",
          "score": 1,
          "created_utc": "2026-02-26 14:06:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7w5fd2",
          "author": "johnbrunder",
          "text": "It would be great to have comfyui workflow",
          "score": 1,
          "created_utc": "2026-02-28 15:31:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7w8cwz",
          "author": "Infinite_Selection47",
          "text": "Why a lora is needed? any idea about collage view?",
          "score": 1,
          "created_utc": "2026-02-28 15:46:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o770lt2",
          "author": "AcePilot01",
          "text": "Def shouldn't open source this, package it and sell it to clothing sites. Licensed. the end.",
          "score": 0,
          "created_utc": "2026-02-24 19:45:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o78c09y",
              "author": "shewel_item",
              "text": "It would be smart to strike while the iron is hot but something like this will be *fully* open source, which I guess *this isn't*, sooner than later. The company you sell to would have to be really in the dark to bite.",
              "score": 2,
              "created_utc": "2026-02-24 23:33:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o78ff0t",
                  "author": "AcePilot01",
                  "text": "Yeah bubble or not, early is rewarded more than perfection. And not true, that's not how open source works tbh, and you can copyright and trade mark many things.  There are open source options of professional software or services (I work in tech sales, SaaS included) and even then, there are very few companies who choose the open source route... Open source is for you and I. There are some exceptions. \n\nThat said, sometimes it's better to outsource things that a company COULD do itself because a company may not be an AI company. If they sell clothes, they generally aren't interested in being THAT vertical tbh. Some very large conglomerates are vertical, but there are plenty who are not tbh. \n\nLike I said, you are rewarded in start ups for being one of the first to get a foot hold more than you are for being technically accurate.\n\nYou could package this as an easy deployable workflow, local or hosted. And if it's easy and have some proven points (do some pilots for free for some to get feedback, data, and work out kinks etc) and sell them to companies. Even if it's not something that will be a billion dollar idea, it's something you could sell and make some money on in the mean time, or sell the business or look to get acquired etc.\n\nOr, his own service, that uses this, on a website that takes say links from shien or amazon or other store sites, and allows this for free, but then the links to the clothes are linked with referral/partner links. etc.  I would say, TryOn.com but that's taken lol\n\nAnd even if 80% of the prospects out there agree with you, the fashion industry is 359 Billion dollars, so I would NOT mind taking some scraps of 360 billion dollars  even if only 1% might be customers, that's still 360 million. Just in the US. lmfao\n\n\nOf course, Now that I mentioned this now here, any further use of this business model will of course need to be licensed from me. hahah ;)\n\n\nEDIT:  Looks like at least one other is already doing it (fyi, there are many business that are still very successful even in fairly flooded markets) https://try-on.io/ (not a promotion, idk anything about that site other than they are doing something similar. (Op's looks better tbh)",
                  "score": 1,
                  "created_utc": "2026-02-24 23:52:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rhx4s5",
      "title": "QR Code ControlNet",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/feymu0nnpfmg1.jpeg",
      "author": "flasticpeet",
      "created_utc": "2026-03-01 13:20:39",
      "score": 703,
      "num_comments": 71,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rhx4s5/qr_code_controlnet/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o81r7ej",
          "author": "lucassuave15",
          "text": "oh i remember seeing these all over the place back in 2023",
          "score": 417,
          "created_utc": "2026-03-01 13:24:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o820o9g",
              "author": "Adkit",
              "text": "Oh, those were the days. A simpler time 'twas.",
              "score": 81,
              "created_utc": "2026-03-01 14:21:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o8398uo",
                  "author": "m79plus4",
                  "text": "For real...I still have a bookmark folder called \"disco diffusion\" which I refuse to change. I kind of miss the heavily abstract generations we used to get. when coherence is now king, I hope we get back to the abstract.",
                  "score": 35,
                  "created_utc": "2026-03-01 18:03:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o84q4nn",
                  "author": "Vampire_who_draws",
                  "text": "That can't be so long ago. It was just....3 YEARS ALREADY? Where did the time go?",
                  "score": 4,
                  "created_utc": "2026-03-01 22:28:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o81smoe",
              "author": "vladlearns",
              "text": "same here",
              "score": 9,
              "created_utc": "2026-03-01 13:33:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o84gxs6",
              "author": "Situati0nist",
              "text": "Back when you could just share and laugh about these. Now people do nothing but whine and bicker about anything AI ;V",
              "score": 3,
              "created_utc": "2026-03-01 21:39:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o81sc2i",
          "author": "Apprehensive_Yard778",
          "text": "I was literally just playing with this and wondering the same thing. I would also love an img2img workflow so I could add a QR Monster to another image.",
          "score": 47,
          "created_utc": "2026-03-01 13:31:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o84fgne",
              "author": "Mammoth_Example_289",
              "text": "an img2img with basic mask and blend controls would be mint so you can drop a QR Monster into a clean product shot without wrecking the light.",
              "score": 3,
              "created_utc": "2026-03-01 21:32:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o84gs4a",
                  "author": "Apprehensive_Yard778",
                  "text": "yeah I'm sure it isn't hard to do but I'm a newb who uses premade workflows as a crutch",
                  "score": 1,
                  "created_utc": "2026-03-01 21:38:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o81wnwm",
          "author": "Myg0t_0",
          "text": "I miss these, has there been an update?",
          "score": 43,
          "created_utc": "2026-03-01 13:58:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o839l2r",
              "author": "SteelRoninTT",
              "text": "Is it not just any control net? Pretty sure this works with new models",
              "score": 11,
              "created_utc": "2026-03-01 18:04:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o83zoey",
          "author": "WhyYouMadBro_",
          "text": "https://preview.redd.it/czvc5kmuqhmg1.png?width=1024&format=png&auto=webp&s=9f4135ccd1311dbca507f418af23f34d42417639",
          "score": 16,
          "created_utc": "2026-03-01 20:10:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o84ot95",
              "author": "Maskwi2",
              "text": "That's awesome :D How do I make these in Comfy? ",
              "score": 2,
              "created_utc": "2026-03-01 22:21:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o859fu1",
              "author": "AcePilot01",
              "text": "How do you do those?",
              "score": 1,
              "created_utc": "2026-03-02 00:18:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o81tzat",
          "author": "Enshitification",
          "text": "I bet if you made a big enough dataset of paired images from the original QR Monster, a Flux2.Klein LoRA could do it just fine.",
          "score": 31,
          "created_utc": "2026-03-01 13:42:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o84mrjw",
              "author": "cranpeach69",
              "text": "I actually had a pretty crappy dataset lying around, decided to train one: https://civitai.com/models/2432921?modelVersionId=2735539",
              "score": 10,
              "created_utc": "2026-03-01 22:10:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o84u1t9",
                  "author": "Enshitification",
                  "text": "You rock.",
                  "score": 4,
                  "created_utc": "2026-03-01 22:49:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o85la6k",
                  "author": "terrariyum",
                  "text": "Those images, lol",
                  "score": 2,
                  "created_utc": "2026-03-02 01:29:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o85su09",
                  "author": "Thou-Art-Barracuda",
                  "text": "Do you mind if I ask how you train an edit Lora like this?\n\nI’ve only ever trained characters, concepts and styles, wondering how you do a before and after Lora",
                  "score": 2,
                  "created_utc": "2026-03-02 02:16:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o81zi9e",
          "author": "WantAllMyGarmonbozia",
          "text": "I keep meaning to check this out when I'm on the big computer, but I have a link saved\n\nhttps://huggingface.co/spaces/Oysiyl/AI-QR-code-generator\n\nSupposed to make artsy/illustrative QR codes",
          "score": 21,
          "created_utc": "2026-03-01 14:15:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o82f4os",
          "author": "Ugleh",
          "text": "Hey I made that image! It really did blow up after mine went viral.",
          "score": 34,
          "created_utc": "2026-03-01 15:38:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o83q3au",
              "author": "Arendyl",
              "text": "I actually started a small business based initially on QRcode monster and examples like these.\n\nThanks for your service.",
              "score": 5,
              "created_utc": "2026-03-01 19:22:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o83y52v",
                  "author": "NarrativeNode",
                  "text": "I’m curious, how have you had to change that business? Is a variation of it still around?",
                  "score": 6,
                  "created_utc": "2026-03-01 20:03:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o848t6l",
          "author": "lxe",
          "text": "![gif](giphy|wJD3qiNjSeHS0dP28T|downsized)",
          "score": 8,
          "created_utc": "2026-03-01 20:57:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o84q6vd",
              "author": "AcePilot01",
              "text": "God, the ways this meme has been used are always top kek lol.",
              "score": 1,
              "created_utc": "2026-03-01 22:28:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o81yb9p",
          "author": "Mylaptopisburningme",
          "text": "This was a thing a couple years ago.  I think they were not always accurate.\n\n2+ years ago, Nov 2023: https://civitai.com/models/197247/qr-code-monster-sdxl",
          "score": 15,
          "created_utc": "2026-03-01 14:08:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o82z519",
              "author": "Winter_unmuted",
              "text": "> I think they were not always accurate.\n\nfeature not a bug.\n\nQR controlnet gives me the most artistic freedom to compose light in shadow in whatever I'm working on. The four models for 1.5 and the one for SDXL still get heavy rotation for me.",
              "score": 9,
              "created_utc": "2026-03-01 17:15:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o83dv0p",
                  "author": "Apprehensive_Yard778",
                  "text": ">feature not a bug.\n\nI'm of the school of thought that \"bad\" AI is more aesthetically interesting.\n\nTo quote Brian Eno:\n\n>Whatever you now find weird, ugly, uncomfortable and nasty about a new medium will surely become its signature. CD distortion, the jitteriness of digital video, the crap sound of 8-bit - all of these will be cherished and emulated as soon as they can be avoided.",
                  "score": 11,
                  "created_utc": "2026-03-01 18:24:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o81zkar",
          "author": "KURD_1_STAN",
          "text": "I feel like QIE and klein should be able to do it without CN",
          "score": 4,
          "created_utc": "2026-03-01 14:15:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o823uqp",
          "author": "WHALE_PHYSICIST",
          "text": "anyone got a workflow or tutorial about how to make these(OP image)? i wanna make some.",
          "score": 5,
          "created_utc": "2026-03-01 14:39:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o83ezyv",
              "author": "Arendyl",
              "text": "[https://antfu.me/posts/ai-qrcode-101](https://antfu.me/posts/ai-qrcode-101)\n\nThe original guide",
              "score": 7,
              "created_utc": "2026-03-01 18:29:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o82zv55",
              "author": "Winter_unmuted",
              "text": "It's literally a controlnet. That's it. Source image is a black and white (or grayscale) image. The controlnets are called QRcode monster, light and dark, and a couple others.",
              "score": 3,
              "created_utc": "2026-03-01 17:18:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o83yv7x",
              "author": "Apprehensive_Yard778",
              "text": "You can drag and drop [this](https://files.catbox.moe/6hz2cs.png) into ComfyUI for a basic workflow. [Here](https://civitai.com/models/161132/sdxl-controlnet-opticalpattern-optical-illusions) is the Controlnet. Look up \"squint\" and \"QR\" models on CivitAI for more.",
              "score": 2,
              "created_utc": "2026-03-01 20:06:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o844mwi",
                  "author": "WHALE_PHYSICIST",
                  "text": "thank you!",
                  "score": 2,
                  "created_utc": "2026-03-01 20:36:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o828or7",
          "author": "Sugary_Plumbs",
          "text": "I believe Flux union cnet has a Value mode that should be able to do it with some tweaking on the strength.",
          "score": 3,
          "created_utc": "2026-03-01 15:06:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o8407lw",
              "author": "Winter_unmuted",
              "text": "I don't see them listed:\n\nhttps://huggingface.co/InstantX/FLUX.1-dev-Controlnet-Union\n\nhttps://huggingface.co/Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro\n\nThey have grayscale modes for colorizing, but I don't know that these work for QR code-like functions.",
              "score": 2,
              "created_utc": "2026-03-01 20:13:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o82ggqx",
          "author": "m477_",
          "text": "You could probably train a lora for Qwen Image Edit or Flux Klein that does the same thing.\n\nControlNet's were add on adaptors to SD (similar to LoRA's and Hypernetworks) but newer models come with similar capabilities built in to the base model now. I'm sure someone could train a control net for something like z-image but it would be a bit of an engineering challenge (you'd need to build the tools to train the control net, actually train it, then you'd probably need to build or modify existing tools to use it since the controlnet plugins/nodes probably won't work on your new model type)",
          "score": 2,
          "created_utc": "2026-03-01 15:45:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o84bbpr",
          "author": "bloke_pusher",
          "text": "I really miss it and I never had the patience to create a comfyui workflow for illustrious. Apparently the SDXL version isn't even as good as the SD1.5 one used to be.",
          "score": 2,
          "created_utc": "2026-03-01 21:10:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o84h9y1",
              "author": "Apprehensive_Yard778",
              "text": "I've been having more fun with SD15 Animatediff than Wan22 and LTX2 lately.",
              "score": 1,
              "created_utc": "2026-03-01 21:41:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o84z6cy",
          "author": "purcupine",
          "text": "Is this 2022",
          "score": 2,
          "created_utc": "2026-03-01 23:18:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o82juc1",
          "author": "Stunning_Macaron6133",
          "text": ">Why has no one created a QR Monster ControlNet for any of the newer models?\n\nBe the change you want to see. Grab the papers for ControlNet, ControlNet++, QR Code Monster v2, and whichever open source model you're trying to add this capability to. Open a text editor or a Jupyter notebook, and get ready to write some Python.\n\nClaude is actually really good at tutoring you on how to get where you want to go.\n\nBut don't expect the world to hand you everything on a silver plate.",
          "score": 3,
          "created_utc": "2026-03-01 16:01:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o82zipj",
              "author": "Winter_unmuted",
              "text": "I went down this road. Turns out it takes hardware beyond consumer stock. \n\n10^4 to 10^5 images, many days of constant computing to get an SDXL controlnet by my estimates, and that's on multi GPU machines. \n\nSo someone with industry level tools needs to spearhead this. My 4090 wasn't going to cut it.",
              "score": 10,
              "created_utc": "2026-03-01 17:17:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o83a2kv",
                  "author": "DigThatData",
                  "text": "nah.\n\nhttps://github.com/xyfJASON/ctrlora",
                  "score": 2,
                  "created_utc": "2026-03-01 18:07:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o81sbvu",
          "author": "TogoMojoBoboRobo",
          "text": "It is pretty niche and screams AI.  You can just reprocess the image on the right with a newer model.",
          "score": 1,
          "created_utc": "2026-03-01 13:31:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o82ewpt",
              "author": "Zealousideal7801",
              "text": "\"it screams AI\" only tells of a ghost mindset where AI assisted creation wasn't the norm. All major creative actors have AI powered systems that don't claim to make \"non-AI\". \n\nPut it to rest, it had its days.\n\nUnless someone is willfully trying to deceit of course, but that's another story and more values related.",
              "score": 17,
              "created_utc": "2026-03-01 15:37:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o8411yi",
                  "author": "TogoMojoBoboRobo",
                  "text": "Most players in major commercial creative industries still have to duck/hide and or apologize over AI use.  I assume more advanced models are more difficult and time consuming to make control nets for so any sort of clout or profit motive would come from developing things more widely used.  So things that serve the open users and the covert ones will likely win out.",
                  "score": 2,
                  "created_utc": "2026-03-01 20:17:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o82ok0n",
              "author": "aseichter2007",
              "text": "No qr monster was incredibly impossibly useful. You could use it to control the whole composition of the scene by changing the weight and steps around.  \n\nIt changed the dynamic color range in a particular way rather than hard black and white unless you turned the strength to 11. \n\nYou could basically paint up your composition in a way that canny and the rest just don't quite.",
              "score": 7,
              "created_utc": "2026-03-01 16:24:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o841gsu",
                  "author": "TogoMojoBoboRobo",
                  "text": "sounds like few people went deep with it and just did the obvious effect.  Not saying it may not be popular, just not as in demand",
                  "score": 3,
                  "created_utc": "2026-03-01 20:20:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o829a40",
          "author": "ZenEngineer",
          "text": "I wonder if you could do the same thing with regional prompting nowadays.",
          "score": 1,
          "created_utc": "2026-03-01 15:09:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o82lri1",
          "author": "CellKey7668",
          "text": "PalLalslslsal",
          "score": 1,
          "created_utc": "2026-03-01 16:10:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o83ajux",
          "author": "agent_wolfe",
          "text": "Man those shadows are weird. Some indicate the sun is at ground level, others are like it’s up on the side somewhere.",
          "score": 1,
          "created_utc": "2026-03-01 18:09:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o84q1k6",
          "author": "AcePilot01",
          "text": "Am I seeing this right?  An image that's full color but is a qr code? Or are you saying it just makes an image based on the data FROM one?",
          "score": 1,
          "created_utc": "2026-03-01 22:27:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o84umwz",
              "author": "Apprehensive_Yard778",
              "text": "It is a controlnet used to embed QR codes in images but people just started applying stencils and vector art to make AI art where like... you squint and there's Jesus, know what I'm talking about?",
              "score": 3,
              "created_utc": "2026-03-01 22:52:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o858tds",
                  "author": "AcePilot01",
                  "text": "I ve seen those, but I am not sure what you mean, I know what you are referring to, but how does that work? lol",
                  "score": 1,
                  "created_utc": "2026-03-02 00:15:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o85rwn9",
          "author": "kngzero",
          "text": "They didn't work that well.",
          "score": 1,
          "created_utc": "2026-03-02 02:10:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o85ulee",
          "author": "mimitasangyou",
          "text": "This is pure eye candy.",
          "score": 1,
          "created_utc": "2026-03-02 02:27:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o81xfwi",
          "author": "Dishankdayal",
          "text": "What's the point when you have kontext and qwen edit.",
          "score": 0,
          "created_utc": "2026-03-01 14:03:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o82d8wc",
          "author": "Grindora",
          "text": "Now u dont actually need control net for that, ai models currently are smart enough to",
          "score": -2,
          "created_utc": "2026-03-01 15:29:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o81t5ls",
          "author": "NetrunnerCardAccount",
          "text": "To use them effectively you not only needed a Control Net, but you had to rerender multiple subsection until they worked, which was hard to automate.\n\nThey were actually quite difficult to read with most phones.\n\nThere were only a small submit of design that could work.\n\nThere are actually better ways of storing URL in an Image which also use AI, and aren't done at the generation stage.",
          "score": -12,
          "created_utc": "2026-03-01 13:36:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o81tpn8",
              "author": "Enshitification",
              "text": "I think very few were using QR Monster to actually make QR codes. It was much more interesting as an artistic tool.",
              "score": 17,
              "created_utc": "2026-03-01 13:40:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o81ucuk",
                  "author": "NetrunnerCardAccount",
                  "text": "No argument, \n\nHere a great site for information (https://antfu.me/posts/ai-qrcode-101)\n\nHere a library for what most people want (https://github.com/x-hw/amazing-qr)\n\nThis library especially the older versions are great for getting you most of the way there (https://github.com/latentcat/qrbtf)\n\nAnd if your a Super Programmer this is what the C2PA guys are using (https://github.com/adobe/trustmark)",
                  "score": 1,
                  "created_utc": "2026-03-01 13:44:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o81tkt0",
              "author": "NomeJaExiste",
              "text": "ok chatGPT but thats not the point",
              "score": 7,
              "created_utc": "2026-03-01 13:39:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o8257sm",
                  "author": "NetrunnerCardAccount",
                  "text": "ChatGPT would have lied to you.",
                  "score": -1,
                  "created_utc": "2026-03-01 14:47:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rfm605",
      "title": "Image upscale with Klein 9B",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1rfm605",
      "author": "CutLongjumping8",
      "created_utc": "2026-02-26 20:56:48",
      "score": 472,
      "num_comments": 87,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rfm605/image_upscale_with_klein_9b/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7lfaeg",
          "author": "DrinksAtTheSpaceBar",
          "text": "Wow, what's with all the hate in here? I see this and think, \"if I'm feeling lazy and I'm already running a Klein workflow, I'll keep in mind that some level of upscaling is possible with this model.\" Take the information and move on with your lives JFC.",
          "score": 107,
          "created_utc": "2026-02-26 22:10:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7m72zd",
              "author": "Fit-Pattern-2724",
              "text": "The hate comes from folks spending weeks learning obsolete workflows that’s now completely useless. They need to spit on new models to justify the sunken time cost lol",
              "score": 38,
              "created_utc": "2026-02-27 00:39:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7nvokj",
                  "author": "Specialist-Chain-369",
                  "text": "or maybe hate comes from folks spending weeks learning sophisticated workflows that actually improve quality without modifying original photo ;)",
                  "score": -1,
                  "created_utc": "2026-02-27 07:19:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7letx3",
          "author": "nncyberpunk",
          "text": "So many unnecessary comments. Pretty good. thanks for sharing. Been thinking a lot about upscaling 80s and 90s photos so I dig these.",
          "score": 48,
          "created_utc": "2026-02-26 22:08:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lgh3p",
          "author": "blastcat4",
          "text": "I think this is neat. Sure, it's not perfect, but if you want something quick and dirty, this is a super easy option. Sometimes the shortest path from point A to point B is worth taking even if it doesn't get you all the way to point B.",
          "score": 13,
          "created_utc": "2026-02-26 22:16:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lsb4a",
          "author": "Trendingmar",
          "text": "I can appreciate the sentiment of \"it changes image too much\". Although people complaining  make me confused because SEEDVR can absolutely change an image too much by introducing weird artifacts.\n\nSometimes dedicated upscalers fail altogether on things like compressed video screencaps. For situations like that klein and qwen are really your only choices for upscaling.\n\nIn some other applications (like my amateur level editing) the image only needs to be close enough to the original.\n\nBut I would agree for particular up-scaling tasks like this, where you start with medium resolution photographs of faces, seedvr will probably do better overall.",
          "score": 6,
          "created_utc": "2026-02-26 23:17:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ld2p0",
          "author": "gelatinous_pellicle",
          "text": "From my experience this is my fav upscaler, better than SEEDVR2 because it can fix anatomy and do all kinds of subtle or not subtle editing.",
          "score": 14,
          "created_utc": "2026-02-26 21:59:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7oac5u",
              "author": "Synor",
              "text": "These discussions would benefit from people differentiating \"upscaling\" and \"redreaming\"/\"remastering\".\n\nIf the process changes the picture significantly, its not an upscale IMO.",
              "score": 7,
              "created_utc": "2026-02-27 09:35:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7ovdp3",
              "author": "SomeoneSimple",
              "text": "Yeah, having more good options is always better. While I like seedvr2 **a lot**, it absolutely mangles some natural things that could be confused with high frequency noise like sand or textured walls.",
              "score": 2,
              "created_utc": "2026-02-27 12:32:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7le6sx",
          "author": "mintybadgerme",
          "text": "Wow such a lot of hostility in this thread. Weird.",
          "score": 20,
          "created_utc": "2026-02-26 22:05:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7mfyxh",
              "author": "radioOCTAVE",
              "text": "Shut up! Sorry I mean yes, I noticed this too. Interesting..",
              "score": 11,
              "created_utc": "2026-02-27 01:29:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7o7cxm",
                  "author": "mintybadgerme",
                  "text": "Isn't it? :)",
                  "score": 2,
                  "created_utc": "2026-02-27 09:06:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7lh6gj",
          "author": "No_Writing_3179",
          "text": "Opinions are like assholes, everyone's got one, and most of them in here stink.",
          "score": 9,
          "created_utc": "2026-02-26 22:19:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7n00nf",
              "author": "ThePoetPyronius",
              "text": "I prefer to think assholes are like opinions; important for release, but overwhelming when you're confronted by them en masse. But that's just one man's asshole. 🤷‍♂️",
              "score": 1,
              "created_utc": "2026-02-27 03:27:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7lsukg",
          "author": "meisterwolf",
          "text": "totally amazing. naysayers post your upscales if you think you know better.",
          "score": 3,
          "created_utc": "2026-02-26 23:20:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nn6fu",
              "author": "DanceTube",
              "text": "A few have and they are complete trash.",
              "score": 1,
              "created_utc": "2026-02-27 06:08:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7lwy0d",
          "author": "Lucaspittol",
          "text": "I posted virtually the same stuff a few weeks back ([here](https://www.reddit.com/r/StableDiffusion/comments/1p9795k/flux_2_is_amazing_at_image_restoration/) and [here](https://www.reddit.com/r/StableDiffusion/comments/1qesy1c/4b_x_9b_x_32b_flux_2_image_restoration_comparison/)) when I noticed these models are good at image restoration, and got a lot of hate as well. I then tried SeedVR2 and Qwen edit AS PEOPLE SAID and just got frustrated.",
          "score": 3,
          "created_utc": "2026-02-26 23:43:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lp3rs",
          "author": "jvcraft87",
          "text": "No hostility ... but the scaled versions remind me of the earlier years digital portraiture where the photographer \"improved\" skin, eyes, and teeth, in Photoshop.  The common error was in smoothing out skin defects to the point where pores disappeared, and eyes and teeth became brilliant white.  If often gave the subject a plastic \"Barbie\" look.",
          "score": 7,
          "created_utc": "2026-02-26 23:00:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7obri6",
          "author": "Kumimono",
          "text": "Heh, these are Playmates, I think. Seems to work well.",
          "score": 2,
          "created_utc": "2026-02-27 09:49:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7oqj9z",
          "author": "PestBoss",
          "text": "I'll be honest these are staying very faithful to the original appearance of the subjects. It's still not perfect, but it's very close. The actual images change quite a bit but then that is no bad thing either and they equally stay faithful in general apperance, just that it looks like it was taken on modern imaging gear and not an old film camera on faded paper.\n\nI've never generally wanted to use one of these as they always change things, or don't truly refine it properly, but this is the first one I've seen where I actually fancy getting some old family photos out to improve!",
          "score": 2,
          "created_utc": "2026-02-27 11:57:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lepq2",
          "author": "VelvetSinclair",
          "text": "Hey, I recognise these photos! \n\nI know what you are!\n\nDo you have the full image upscaled somewhere?",
          "score": 2,
          "created_utc": "2026-02-26 22:07:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7lf02x",
              "author": "CutLongjumping8",
              "text": "And I know how old we are as you remember July of 1958 :) and I am sure that it is against rules to post full images like this..",
              "score": 2,
              "created_utc": "2026-02-26 22:09:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7lfq2m",
                  "author": "VelvetSinclair",
                  "text": "Didn't ask you to post it...",
                  "score": 3,
                  "created_utc": "2026-02-26 22:12:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7le20m",
          "author": "RetroGazzaSpurs",
          "text": "classic flux skin",
          "score": 6,
          "created_utc": "2026-02-26 22:04:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7lipun",
              "author": "ready-eddy",
              "text": "What, you don’t like shiny spots everywhere?",
              "score": 3,
              "created_utc": "2026-02-26 22:27:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7o0bll",
              "author": "inddiepack",
              "text": "Did you use the model? After experimenting with all the models, to me Klein 9B distilled is producing the best natural skin out of the box, of all models. And I don't mean \"perfect\"skin, I mean realistic skin, pores and imperfections.",
              "score": 1,
              "created_utc": "2026-02-27 08:00:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7m4p1r",
          "author": "Calm_Mix_3776",
          "text": "I'm not sure what BFL did with Flux.2 Klein, but they really kneecapped the model's capability to do microdetails which is quite important for realistic skin. Even Z-Image Base and Chroma, both based on Flux.1 which is an older architecture, beat it in terms of [detail and texture capabilities](https://www.reddit.com/r/StableDiffusion/comments/1ramrmr/comment/o6mu7kl/). It's a shame since it's a really good edit model.\n\nFlux.2 Dev on the other hand does [amazing detail](https://i.postimg.cc/zqWv3g8z/Comfy-UI-Flux-2-Dev-02.jpg) (example below) - you can practically see the skin pores, tiny hairs, peach fuzz etc., but it's a nightmare to run on casual hardware, unless you use the NVFP4 version which works only on RTX50 cards. Flux.2 Dev uses the same VAE as Klein so it seems that the issue is with the model itself. Probably Klein didn't get enough hi-res training?\n\nhttps://preview.redd.it/zhja9rvglxlg1.jpeg?width=1024&format=pjpg&auto=webp&s=e52f3b27c857647371218cd6cd5b615247f74469",
          "score": 4,
          "created_utc": "2026-02-27 00:26:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qapkj",
              "author": "music2169",
              "text": "How did you do the upscale here with flux.2 dev?",
              "score": 1,
              "created_utc": "2026-02-27 17:01:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7rppuu",
                  "author": "Calm_Mix_3776",
                  "text": "Here's a screenshot of the workflow:\n\nhttps://preview.redd.it/0z5lqon8r3mg1.png?width=2829&format=png&auto=webp&s=94b28a1063af79ceb086f1e1362912c36c3e62b9\n\n",
                  "score": 3,
                  "created_utc": "2026-02-27 21:09:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7tllt1",
              "author": "Colon",
              "text": "z-image is not based on Flux anything - nothing to do with BFL or its models. at least it looks like you’re claiming that..?",
              "score": 1,
              "created_utc": "2026-02-28 03:43:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7lkqyp",
          "author": "HollowAbsence",
          "text": "Thw upscale shifted red hue for yellowish hue. the pictures lost their original warmt.",
          "score": 4,
          "created_utc": "2026-02-26 22:37:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7la2c5",
          "author": "Freshly-Juiced",
          "text": "turns them into different people though ",
          "score": 4,
          "created_utc": "2026-02-26 21:45:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ntaej",
              "author": "GoofAckYoorsElf",
              "text": "I wonder how. If you look at specific details it's almost perfect. But the overall face is indeed different. That's... a strange effect.",
              "score": 1,
              "created_utc": "2026-02-27 06:58:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7nx6po",
                  "author": "Freshly-Juiced",
                  "text": "because AI upscaling basically repaints the entire image to what the model thinks it should look like, nothing from the original is retained, it's only used as a guide to lean the model in the right direction. ",
                  "score": 1,
                  "created_utc": "2026-02-27 07:32:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7n2l3m",
          "author": "grabber4321",
          "text": "Gooners will always find a way!",
          "score": 2,
          "created_utc": "2026-02-27 03:43:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7l5irq",
          "author": "lebrandmanager",
          "text": "TBH to this day there is nothing beating SEEDVR2 for upscaling images. Maybe using ZIT as a second pass, if someone needs it. But this is a joke.",
          "score": 3,
          "created_utc": "2026-02-26 21:23:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7lcui1",
              "author": "MrFlores94",
              "text": "You can use this to remaster the image before upscaling it with SeedVR. This is just another very useful tool.",
              "score": 13,
              "created_utc": "2026-02-26 21:58:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7lpq2u",
              "author": "Fit-Pattern-2724",
              "text": "This is a lot faster than SEEDVR2. Also avoided model loading unloading",
              "score": 8,
              "created_utc": "2026-02-26 23:03:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7llh7r",
              "author": "ScumLikeWuertz",
              "text": "how do I use it?  im still trying to figure comfyui out",
              "score": 2,
              "created_utc": "2026-02-26 22:41:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7m2jvp",
              "author": "BluetownA1",
              "text": "Really? Would love to see you attempt with seedvr2. ",
              "score": 2,
              "created_utc": "2026-02-27 00:14:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7nujyf",
                  "author": "lebrandmanager",
                  "text": "Not sure, if the advanced workflow still works, but I usually use this node and workflow and get stunning results up to 8k+\n\nhttps://github.com/moonwhaler/comfyui-seedvr2-tilingupscaler",
                  "score": 0,
                  "created_utc": "2026-02-27 07:09:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7ljbzw",
              "author": "Danmoreng",
              "text": "If only there was a way to run it without Python and comfy…",
              "score": 1,
              "created_utc": "2026-02-26 22:30:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7lf1ec",
          "author": "SweptThatLeg",
          "text": "I get the worst results using the comfyUI template for Flux2 Klein9B. Like, I’ll swap a face or change an outfit and what it kicks back has awful resolution compared to the starting image. \n\nWhat am I missing?",
          "score": 1,
          "created_utc": "2026-02-26 22:09:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lvpjn",
          "author": "VirusCharacter",
          "text": "I have the same problem getting good hair and usually Klein favors plastic skin... Unfortunately. Other than that  it's a fantasticly flexible model!",
          "score": 1,
          "created_utc": "2026-02-26 23:36:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lwhyx",
          "author": "Fast_Situation4509",
          "text": "Interesting",
          "score": 1,
          "created_utc": "2026-02-26 23:40:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7m0lpz",
          "author": "comfyui_user_999",
          "text": "It's really not bad, and so, so fast.",
          "score": 1,
          "created_utc": "2026-02-27 00:03:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7m6x54",
          "author": "johndrake666",
          "text": "Need to be added on tv's\n\n![gif](giphy|ohRB7lodHJobrD5WNd)",
          "score": 1,
          "created_utc": "2026-02-27 00:38:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7me05m",
          "author": "Srapture",
          "text": "Neat! I'm not really sure how to add additional upscalers in Forge.",
          "score": 1,
          "created_utc": "2026-02-27 01:18:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7mk0ue",
          "author": "Merchant_Lawrence",
          "text": "are it good on upscaling anime image ?",
          "score": 1,
          "created_utc": "2026-02-27 01:53:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7mo4zu",
          "author": "MrWeirdoFace",
          "text": "What is your latent resolution? I imagine you are using an upscale node first?",
          "score": 1,
          "created_utc": "2026-02-27 02:17:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7mt1oo",
              "author": "CutLongjumping8",
              "text": "yes - start images were from 350x350px to 412x412px and upscale node make it 1024x1024 before everything",
              "score": 1,
              "created_utc": "2026-02-27 02:45:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7mupaq",
          "author": "Fast-Visual",
          "text": "Now it's Groß 9B",
          "score": 1,
          "created_utc": "2026-02-27 02:55:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7n2jqp",
          "author": "RangeImaginary2395",
          "text": "Never thought I could use it this way, thank you for opening up my new perspective",
          "score": 1,
          "created_utc": "2026-02-27 03:42:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7n8g3i",
          "author": "Shockbum",
          "text": "There's something called DyPE for Flux 1 that allows the model to generate in 4k without distortion. Could it be applied to Klein 9b? [https://github.com/guyyariv/DyPE](https://github.com/guyyariv/DyPE)",
          "score": 1,
          "created_utc": "2026-02-27 04:20:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7nk1v3",
          "author": "RepresentativeRude63",
          "text": "Upscale to 4 mp with seedvr (seedvr looks digital too) than pass it to Klein with denoise value between 0.12 - 0.27 depending on the camera focus to capture realism again",
          "score": 1,
          "created_utc": "2026-02-27 05:43:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7nydjh",
          "author": "avalon_edge",
          "text": "Would appreciate the Workflow?",
          "score": 1,
          "created_utc": "2026-02-27 07:43:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nys2g",
              "author": "CutLongjumping8",
              "text": "apologize - after yesterday I’m kind of nervous about posting links here…\n\nBut on the other hand, I do have a universal workflow on Civitai that I maintain and personally use — the link is in my previous threads.",
              "score": 1,
              "created_utc": "2026-02-27 07:46:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ozulv",
          "author": "juguLator01",
          "text": "Impressive. I found it odd that the window framing kept kinda lo-res still",
          "score": 1,
          "created_utc": "2026-02-27 13:02:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ptqjk",
          "author": "Jetsprint_Racer",
          "text": "F.2K really got some hair issues... It looks almost like videogame hair with mediocre antialiasing. Far from what the best SDXL checkpoints were able to do.",
          "score": 1,
          "created_utc": "2026-02-27 15:41:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7qacog",
          "author": "music2169",
          "text": "Workflow?",
          "score": 1,
          "created_utc": "2026-02-27 16:59:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7raay9",
          "author": "VasaFromParadise",
          "text": "In fact, Klein does not do upscaling, it does image reconstruction.",
          "score": 1,
          "created_utc": "2026-02-27 19:51:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7tktdj",
          "author": "CalvinBuild",
          "text": "I don’t think you mentioned it in the post, but I’m curious too. Which Klein 9B build + quant are you running (fp16/bf16, or GGUF like Q8\\_0 / Q6\\_K)? Also what was your denoise/strength and did you tile? That combo is usually what decides whether it stays “true upscale” vs detail re-render.",
          "score": 1,
          "created_utc": "2026-02-28 03:37:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o80al0t",
              "author": "CutLongjumping8",
              "text": "I used FP16 version and as it was in edit mode, denoise was set to 1",
              "score": 1,
              "created_utc": "2026-03-01 05:39:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o818kgt",
          "author": "Inevitable-Boat-4711",
          "text": "while i see those as impressive upscales, the ai nature of it is very visible. i mostly work with videos not photos, so i often have an easier time, and sometimes, i prefer non-upscaled visuals even if they are not perfect",
          "score": 1,
          "created_utc": "2026-03-01 10:52:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7l4pic",
          "author": "tomuco",
          "text": "Nope. Unnatural subpatterns, harsher lighting, DOF is all over the place. Might as well use an ESRGAN model. We already had better solutions for this years ago.",
          "score": -1,
          "created_utc": "2026-02-26 21:19:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7lpmdj",
              "author": "Fit-Pattern-2724",
              "text": "ESRGAN performs way worse than this. Did you actually use it?v",
              "score": 10,
              "created_utc": "2026-02-26 23:03:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7m0nwf",
                  "author": "tomuco",
                  "text": "I did and still do. Just not for the last step.",
                  "score": -3,
                  "created_utc": "2026-02-27 00:04:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7ml70t",
              "author": "moofunk",
              "text": "> Unnatural subpatterns, harsher lighting, DOF is all over the place.\n\nMost of these can be controlled through prompting. Klein is decently good in many things, except upscaling hair and reproducing particular types of skin.\n\nTreating this as a one-shot workflow doesn't do the model any favors.",
              "score": 3,
              "created_utc": "2026-02-27 02:00:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7lpc3z",
          "author": "Fit-Pattern-2724",
          "text": "klein is such a magical model that can easily do almost everything",
          "score": 1,
          "created_utc": "2026-02-26 23:01:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7l55fr",
          "author": "xrionitx",
          "text": "Is there any deformation corrector node..? Like when there are extra limbs generated, bad eyes and so on... Plus to enhance the resolution to 4k",
          "score": 1,
          "created_utc": "2026-02-26 21:21:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7m8av5",
              "author": "kayteee1995",
              "text": "add neg prompt + NAG (if you set cfg1 on distilled)",
              "score": 1,
              "created_utc": "2026-02-27 00:45:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7l4lv1",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -3,
          "created_utc": "2026-02-26 21:19:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7l5p8t",
              "author": "CutLongjumping8",
              "text": "sorry for that :) I just found it strange that many people include upscalers like SeedVR2 in their workflows, while the model itself can practically do the same thing. And I am sure that with more smart prompts or may be some lora it is possible to make results better. And yes - my fault again, I’ve removed the link.",
              "score": 2,
              "created_utc": "2026-02-26 21:24:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7l94ur",
                  "author": "rolens184",
                  "text": "To be honest, I find it strange too. I don't really like Seedvr2 as an upscaler. Also because I can't use it in a single workflow with other models because it crashes my PC.",
                  "score": 4,
                  "created_utc": "2026-02-26 21:40:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7lb2vm",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": -1,
                  "created_utc": "2026-02-26 21:50:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7lhx7d",
          "author": "meikerandrew",
          "text": "https://preview.redd.it/btb5uindzwlg1.png?width=3072&format=png&auto=webp&s=1f630dcb2d1b48e935d802e37feead32ca372c6b\n\nI use qwen image 2511 for upscale. I like quality. Maybe some face anatomy changed but its not critical.",
          "score": -1,
          "created_utc": "2026-02-26 22:23:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7n0nzw",
              "author": "Snoo_64233",
              "text": "Looks like wax doll\n\nhttps://preview.redd.it/l901kzvmiylg1.png?width=672&format=png&auto=webp&s=7447db18a81b2fa2d22fb8e789cd420f76708d3f\n\n",
              "score": 6,
              "created_utc": "2026-02-27 03:31:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7pfc01",
                  "author": "ronbere13",
                  "text": "wax doll is good",
                  "score": 1,
                  "created_utc": "2026-02-27 14:30:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7lk4h9",
              "author": "rm_rf_all_files",
              "text": "Plastic skin textures. SeedVR2 is night and day vs this.",
              "score": 5,
              "created_utc": "2026-02-26 22:34:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7mb6g7",
                  "author": "meikerandrew",
                  "text": "Nope. qwen better. Maybe need try on 2512. \n\nhttps://preview.redd.it/lmaoe6k2sxlg1.jpeg?width=760&format=pjpg&auto=webp&s=8e8a2a18e7da2a1e99b6fcbd959433f51e78fcea",
                  "score": -1,
                  "created_utc": "2026-02-27 01:02:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7ls0ta",
          "author": "vacon04",
          "text": "The teeth are very different. It's like an upscale with a strange beautify filter.",
          "score": -7,
          "created_utc": "2026-02-26 23:16:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rh2890",
      "title": "[Final Update] Anima 2B Style Explorer: 20,000+ Danbooru Artists, Swipe Mode, and Uniqueness Rank",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1rh2890",
      "author": "ThetaCursed",
      "created_utc": "2026-02-28 13:08:29",
      "score": 455,
      "num_comments": 44,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rh2890/final_update_anima_2b_style_explorer_20000/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7vrhl8",
          "author": "Dezordan",
          "text": "Styles ranked by uniqueness really do look interesting",
          "score": 30,
          "created_utc": "2026-02-28 14:15:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7z9eeh",
              "author": "LocoMod",
              "text": "Best artist is mettaflix. Change my mind.",
              "score": 2,
              "created_utc": "2026-03-01 01:31:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7vljho",
          "author": "MrGood23",
          "text": "Any news about when Anima will be updated?",
          "score": 24,
          "created_utc": "2026-02-28 13:40:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o813l1a",
              "author": "Late_Pirate_5112",
              "text": "Probably another month or two if everything goes well.",
              "score": 4,
              "created_utc": "2026-03-01 10:04:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7vqt1d",
          "author": "Expert-Bell-3566",
          "text": "Thanks bro, was on a gooning drought with all the same styles",
          "score": 33,
          "created_utc": "2026-02-28 14:11:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7w9vod",
          "author": "VasaFromParadise",
          "text": "You should have made it so the artist could copy it in this format. I think it's more convenient, but maybe it's just my taste. Overall, thanks for the work, I gave it a star.\n\n\"@artist\\_name\" or \"(@artist\\_name:1.1)\"",
          "score": 8,
          "created_utc": "2026-02-28 15:54:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7wg0bo",
              "author": "ThetaCursed",
              "text": "Thanks for the helpful suggestion, I've made some changes to make it work.",
              "score": 7,
              "created_utc": "2026-02-28 16:24:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7vk7d6",
          "author": "AvailableProcess2059",
          "text": "This is so cool - but I do feel like global favorites or something else where you can see what people are upvoting would be really helpful. Either way keep up the good work!",
          "score": 16,
          "created_utc": "2026-02-28 13:31:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7vm6k9",
              "author": "ThetaCursed",
              "text": "I appreciate the idea, but global voting is too risky right now. My project already got picked up by some hostile communities on Twitter, and they've turned it into a target.\n\nIf I added global favorites, it would be immediately review-bombed and manipulated by people who want to see the project fail. Keeping it serverless and algorithmic (Uniqueness Rank) is the only way to ensure the data stays objective.\n\nhttps://preview.redd.it/sjb8u1bvo8mg1.png?width=703&format=png&auto=webp&s=52bc19c43b3b4c027b331afd7926287cec5757cf\n\n",
              "score": 63,
              "created_utc": "2026-02-28 13:44:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o80ng19",
                  "author": "Barafu",
                  "text": "Somebody needs to develop an AI that will help people ignore other people. ",
                  "score": 3,
                  "created_utc": "2026-03-01 07:30:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7vz2kz",
                  "author": "BigNaturalTilts",
                  "text": "You know, I feel terrible for artists. In their point of view, they’re being targeted by software developers which must feel cold and relentless in categorizing and breaking down the intuition that they’ve honed their whole lives. They’re used to scummy untalented people stealing and trying to resell their works. But not programmers. They don’t understand programmers. They must think programmers like a disease with one goal.",
                  "score": 14,
                  "created_utc": "2026-02-28 14:58:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7wd8zj",
                  "author": "beryugyo619",
                  "text": "> If I added global favorites, it would be immediately review-bombed and manipulated by people who want to see the project fail. \n\nI think what actually happens would be that it will uncover extreme favoritism towards anime styles and away from Western styles, and that'll piss off rich people to get you deplatformed while artists provide baseline rage fuels. Artists rarely do statistical manipulations.",
                  "score": 2,
                  "created_utc": "2026-02-28 16:10:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7vr3vf",
          "author": "TekeshiX",
          "text": "GG. That's useful for Illustrious/NoobAI too until the final release of anima will get released.",
          "score": 5,
          "created_utc": "2026-02-28 14:13:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7vrrmo",
          "author": "NeonEdgeGames",
          "text": "Cool project!",
          "score": 4,
          "created_utc": "2026-02-28 14:17:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o809rio",
          "author": "Rough-Copy-5611",
          "text": "I don't know if this is out of scope of the project or not but it would be cool if you could upload a reference photo of an anime image and it could tell you which artists in the database has a similar style. Would help a lot of people who come here asking for prompt advice and which model to use to get X image. ",
          "score": 4,
          "created_utc": "2026-03-01 05:32:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7w6rmj",
          "author": "LincolnShow",
          "text": "brother, you've done the god's work. thank you king!",
          "score": 3,
          "created_utc": "2026-02-28 15:38:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7wbdr1",
          "author": "Choowkee",
          "text": "Really useful, used it the other day to help test my anima lora.\n\nWhat I would suggest tho is make it so the copy feature always appends a \"@\" at the start so \"@yalmyu\". I just dont see why you would need to copy the artist name into your prompt without the required @",
          "score": 3,
          "created_utc": "2026-02-28 16:01:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7vxytg",
          "author": "UnicornJoe42",
          "text": "Cool work.\n\nI hope in future someone makes explorer like this, but with search by diffetrnt elements of style. Like Flat shding, or line thickness.. ",
          "score": 2,
          "created_utc": "2026-02-28 14:52:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7wdsbn",
          "author": "kabachuha",
          "text": "Awesome work! Though I have a concern it will be used to harass Circlestone labs and tdrussel by the artists (tdrussel responded to the comments asking for the artists list that he cannot list them because of legal reasons) and ultimately something bad might happen to the authors or to the dataset (like artist exclusion or cease and desist)",
          "score": 2,
          "created_utc": "2026-02-28 16:13:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7y0ece",
          "author": "terrariyum",
          "text": "Uniqueness rank is a game changer!  As someone who doesn't follow anime to understand the nuances, before all the artists looked the same to me.  But the most unique ones really are unique.  \n\nAlso looking at the ground truth artwork, now I can see how well Anima has learned styles in general.",
          "score": 2,
          "created_utc": "2026-02-28 21:13:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7vpsqr",
          "author": "Quiet-Educator-98",
          "text": "The project is really cool and with this you can find artists you like the work and follow them that's nice. \nBut the first thing that came to my mind was the backlash you will get for stealing art from artists😩peoples are angry. Always. \nAmazing stuff still👌",
          "score": 4,
          "created_utc": "2026-02-28 14:05:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7vwzpm",
          "author": "blastcat4",
          "text": "Thank you for making and updating this. It's been fun using it to explore the different styles that Anima trained on!\n\nHope you'll pick this up again when the full version of Anima releases.",
          "score": 1,
          "created_utc": "2026-02-28 14:46:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7w71mj",
          "author": "jrdidriks",
          "text": "Thanks for this",
          "score": 1,
          "created_utc": "2026-02-28 15:39:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7wamos",
          "author": "CommitteeInfamous973",
          "text": "Awesome addition! Though it seems it have bias towards images with signatures? Is there no way to make tweak settings to lower the priority of it in the ranking? Either way, you are awesome!",
          "score": 1,
          "created_utc": "2026-02-28 15:57:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7we2lz",
          "author": "princess_daphie",
          "text": "Nice work! Always like tools to see different styles clearly!!!",
          "score": 1,
          "created_utc": "2026-02-28 16:15:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7wluh8",
          "author": "tamal4444",
          "text": "thanks",
          "score": 1,
          "created_utc": "2026-02-28 16:53:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7wsn2r",
          "author": "gary25566",
          "text": "Was there a cutoff date on when the images were trained? In case in future there is a new or recently added artist that is not in the database/Anima Checkpoints.",
          "score": 1,
          "created_utc": "2026-02-28 17:27:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7wt4mu",
              "author": "Dezordan",
              "text": "HF page says \"The knowledge cut-off date for the anime training data is September 2025.\"",
              "score": 1,
              "created_utc": "2026-02-28 17:30:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7wzeah",
          "author": "StoneCypher",
          "text": "Really wish it had other demo images",
          "score": 1,
          "created_utc": "2026-02-28 18:01:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7x5f1m",
          "author": "gruevy",
          "text": "great work, thx!",
          "score": 1,
          "created_utc": "2026-02-28 18:31:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7xm2so",
          "author": "SpezsFavoriteBull",
          "text": ">Uniqueness Rank: My alternative to \"global favorites.\" Since this is a serverless tool, I’ve used CLIP embeddings and KNN to rank artists by their stylistic impact. It’s the fastest way to find \"hidden gems\" that truly stand out.  \n\nIt seems to have worked well. Thanks a lot. Would it be possible for you to share the code that you used to calculate \"uniqueness_score\" for images?",
          "score": 1,
          "created_utc": "2026-02-28 19:56:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7y9k04",
          "author": "dawavve",
          "text": "Please add a \"sort by random\" to help us find new styles in the dataset.",
          "score": 1,
          "created_utc": "2026-02-28 22:02:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7yatyj",
          "author": "RaspberryV",
          "text": "Uniqueness Rank is a GOAT! i got so tired sifting through endless pages of styles that look almost exactly like their neighbor!  Colossal work, thank you!",
          "score": 1,
          "created_utc": "2026-02-28 22:09:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7yyjca",
          "author": "WhatIs115",
          "text": "Is there a base image with no style?",
          "score": 1,
          "created_utc": "2026-03-01 00:26:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7z3yo8",
          "author": "izidre2019",
          "text": "😮",
          "score": 1,
          "created_utc": "2026-03-01 00:57:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7zjahq",
          "author": "PropagandaOfTheDude",
          "text": "> *Uniqueness Rank:* My alternative to \"global favorites.\" Since this is a serverless tool, I’ve used CLIP embeddings and KNN to rank artists by their stylistic impact. It’s the fastest way to find \"hidden gems\" that truly stand out.\n\n[I feel seen](https://www.reddit.com/r/StableDiffusion/comments/1qyk4fd/anima_2b_style_explorer_visual_database_of_900/o44vv17/).  Love it.",
          "score": 1,
          "created_utc": "2026-03-01 02:31:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o80ub2a",
          "author": "Sacriven",
          "text": "Is this the showcase for the latest Anima base model?",
          "score": 1,
          "created_utc": "2026-03-01 08:35:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o82f4ft",
          "author": "beardobreado",
          "text": "Thats exactly what i wanted to do with image galery addon. Thanks a lot",
          "score": 1,
          "created_utc": "2026-03-01 15:38:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o82yrv0",
          "author": "Profanion",
          "text": "You know, if this had been released in 2020, it would actually be more appreciated. Shame though how there's so much backlash now.",
          "score": 1,
          "created_utc": "2026-03-01 17:13:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o84wje6",
          "author": "lexix2020",
          "text": "Merci, c’est genial",
          "score": 1,
          "created_utc": "2026-03-01 23:03:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7x8idz",
          "author": "DjSaKaS",
          "text": "I was trying to use anima but prompting is so difficult I only get super bad quality child drawing...",
          "score": 1,
          "created_utc": "2026-02-28 18:47:08",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rfwdwy",
      "title": "A BETTER way to upscale with Flux 2 Klein 9B (stay with me)",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1rfwdwy",
      "author": "YentaMagenta",
      "created_utc": "2026-02-27 04:04:34",
      "score": 420,
      "num_comments": 104,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rfwdwy/a_better_way_to_upscale_with_flux_2_klein_9b_stay/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7o3ft2",
          "author": "Glove5751",
          "text": "Try using the word \"subtle\" in your prompt, so \"subtle high resolution\", \"subtle enhanced\" and etc.\nExample:\n\"Subtle high resolution, subtle color correction, subtle denoise\" is what I used last.\n\n\nThat gave me better results. I also used low steps, 4 to 8.\n\n\nSeedVR2 still is better since it looks more authentic, but this is better at adding artificial detail.",
          "score": 42,
          "created_utc": "2026-02-27 08:29:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7o3ozl",
              "author": "YentaMagenta",
              "text": "Thank you for the tip!",
              "score": 4,
              "created_utc": "2026-02-27 08:32:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7nuhu2",
          "author": "Stevie2k8",
          "text": "Just a tip from my findings... If you have another high resolution images of the person you try to upscale you can pass it in as second reference image and tell Klein to use the facial expressions from reference image 2. It really helped a LOT if the resolution is too low to really create the person and faces you want. ",
          "score": 16,
          "created_utc": "2026-02-27 07:08:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nv1de",
              "author": "lebrandmanager",
              "text": "Could you share an example workflow for that?",
              "score": 3,
              "created_utc": "2026-02-27 07:13:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7o035n",
                  "author": "Stevie2k8",
                  "text": "I just used the the flux 2 klein template from comfyui which already has 2 reference Images. The only thing I change is the target resolution... ",
                  "score": 9,
                  "created_utc": "2026-02-27 07:58:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7nvh1r",
          "author": "CutLongjumping8",
          "text": "Thank you for such a detailed analysis. In fact, when I created that previous thread about upscaling, I was actually hoping to read something exactly like this in the comments.\n\nEdit: here is my last try with linear upscale to 1.5 megapixels and prompt \"high resolution. refine image and remove jpeg compression artifacts. retain facial details, facial expression, objects position, color, gamma and lighting\"\n\n[https://imgsli.com/NDUyMzY1](https://imgsli.com/NDUyMzY1)",
          "score": 13,
          "created_utc": "2026-02-27 07:17:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7p10n8",
          "author": "Ok_Cauliflower_6926",
          "text": "\"upscaled\"\n\nhttps://preview.redd.it/ka1ck0aud1mg1.jpeg?width=483&format=pjpg&auto=webp&s=78e538e1ff3fc3a9bb0ddb074a18f262cab7d7c9\n\n",
          "score": 18,
          "created_utc": "2026-02-27 13:09:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7nf6f6",
          "author": "grundlegawd",
          "text": "Only issue is the artifacts still present in the skin. It’s so strange because Klein gets the skin about 90% right then sprinkles in some very strange looking wrinkles and discoloration.",
          "score": 10,
          "created_utc": "2026-02-27 05:06:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ntgan",
              "author": "TheSlateGray",
              "text": "I think it's Klein's built in bias to age up people. BFL just tweeted about it recently as a safety feature.\n\n\nIt adds wrinkles to smooth skin, so you have to balance between the plastic old flux skin and wrinkly new flux skin. ",
              "score": 6,
              "created_utc": "2026-02-27 06:59:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7ophfm",
                  "author": "Nexustar",
                  "text": "And this is why people hate safety features... It fucks up the model. The first thing I noticed was the guy aged 15 years.",
                  "score": 13,
                  "created_utc": "2026-02-27 11:49:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7nfmsg",
              "author": "YentaMagenta",
              "text": "At native resolution I'm not seeing it so much, but some of it is probably due to artifacts in the original. Also, if skin is too smooth, people complain about plastic.\n\nIt's always going to be a balancing act between fidelity, detail, and flawless skin.",
              "score": 2,
              "created_utc": "2026-02-27 05:10:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7ngk41",
                  "author": "grundlegawd",
                  "text": "I mean yes, clearly a lot of artifcating in the originals, but it’s very clear to my eyes that image one is displaying a very soft even tone, for example. Beauty filter like. Seems like Klein is picking up JPG artifacts and converting that into discoloration in the skin. There’s definitely a limit to how smooth you want skin to be to maintain some level of realism, but I’m confident that’s not what that woman’s skin looked like during that shoot is all I’m saying.\n\nThat said, I think Klein is fine for upscaling. A much faster solution than SeedVR2. But I still think SeedVR2 is superior in that domain. Which makes sense as that’s its entire purpose for existing.",
                  "score": 4,
                  "created_utc": "2026-02-27 05:16:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7u0vmh",
                  "author": "mariokartmta",
                  "text": "I use the base version with the turbo Lora set at 0.6, 4 steps of res_6s_ode and some Lora that adds back a little of sensor noise gives me the best results so far. The distilled model has overcooked skin and hair details. I can give you my prompt if you're interested when I'm on my computer.",
                  "score": 1,
                  "created_utc": "2026-02-28 05:33:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7od90d",
          "author": "Few-Term-3563",
          "text": "To me upscales always look off because it also tries to sharpen background blur that should be there, the focus is all over the place because of that and instantly looks AI.",
          "score": 3,
          "created_utc": "2026-02-27 10:03:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7v9atj",
              "author": "Colon",
              "text": "this is another case where an image editor comes in handy. flood select the background and add a light blur back in. including launching the program, might take like 2 minutes.\n\ni ‘get’ AI purism, but i also really don’t get it.\n",
              "score": 2,
              "created_utc": "2026-02-28 12:14:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7ojynd",
              "author": "addandsubtract",
              "text": "Why did I have to read this? Now I can't unsee it :(",
              "score": 1,
              "created_utc": "2026-02-27 11:04:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7oegga",
          "author": "takayatodoroki",
          "text": "I also did a lot of experiments.\n\nIn my opinion, there is not a best method for all kind of images.\n\nSome workflows work better with very low res or blurred images.\n\nFor 'normal' images i use 3 models in a row:\n\n1. SeedVR2 to upscale to the desired final size. In my test is the model that better keeps biometry. But it does not make HQ textures or other refinements. Sometimes I avoid this model if the image is too ruined.\n\nthe output image is passed to\n\n2) Qwen Edit with \"Qwen-Image-Edit-Unblur-Upscale\\_10\" lora  and the prompt:\n\n    remove watermarks. change image 1 to realistic photograph. Flash photography.  Neutral and perfectly tuned color.  unblur image 1. keep people, identity, facial features, expressions, skin texture, hair, clothing, pose, proportions. make face detailed. keep face consistent. make mouth detailed. keep mouth consistent. make eyes detailed. keep eyes consistent. make hair detailed. keep hair consistent. keep original colors. keep original light. \n\nNow the image has major defects cleaned, richer texture, better light and such, normally without losing people identity. what is missing is a better skin texture, so the output is passed to \n\n3) z\\_image\\_turbo\\_bf16 (with very low denoise such 0.1) with the  \"skin texture v2.1\" lora  (also the strength is reduced around 0.1 to avoid the risk of ruined skin). \n\n\n\nUsing 3 models It's a long task (i use two different workflows to make images in series and keep each workflow in my VRAM) but i have good results. A screenshot of an old VHS can become like a photo taken on the set.\n\nI probably could avoid the z\\_image pass and search for a skin texture lora for Qwen that works as well.",
          "score": 2,
          "created_utc": "2026-02-27 10:14:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7otnjc",
              "author": "Calm_Mix_3776",
              "text": ">I probably could avoid the z\\_image pass and search for a skin texture lora for Qwen that works as well.\n\nQwen Image is *terrible* with details and textures, almost SDXL level. No LoRA can salvage a flawed architecture. You'd definitely want an additional pass after that with another model that does good details and textures such as SeedVR2 or a model based on Flux.1/Flux.2.",
              "score": 2,
              "created_utc": "2026-02-27 12:19:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7q3hrh",
          "author": "takayatodoroki",
          "text": "https://preview.redd.it/ehy3yn2tc2mg1.jpeg?width=1024&format=pjpg&auto=webp&s=04fdfe081e41e28781786a964e9090c1a0b406ff\n\nFlux.2 dev... always adds some skin impurity and it's hard to keep the original lights.",
          "score": 2,
          "created_utc": "2026-02-27 16:27:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7q49tf",
              "author": "YentaMagenta",
              "text": "Are you using the same workflow just with Dev swapped in and the steps and guidance adjusted?",
              "score": 1,
              "created_utc": "2026-02-27 16:31:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7qa65o",
                  "author": "takayatodoroki",
                  "text": "I've uploaded the workflow here: [https://pastebin.com/W5D23GjV](https://pastebin.com/W5D23GjV)\n\nrename the extension from txt to json\n\nI rarely use custom nodes, so it should work for everyone.",
                  "score": 1,
                  "created_utc": "2026-02-27 16:59:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7riorv",
          "author": "ArsInvictus",
          "text": "I’ve been trying to upscale a difficult image of an old painting and every model I tried would add strange distortions and textures to the paint and canvas texture.  Just tried your workflow and it worked perfectly.  I was then able to scale with siax and with the higher res base got a much better high res outcome.  Thank you!",
          "score": 2,
          "created_utc": "2026-02-27 20:34:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7rlrer",
              "author": "YentaMagenta",
              "text": "Amazing! I'm so glad it worked well for you. \n\nAnother commenter recommended using the word subtle sometimes if you find the effects too strong, just as an FYI. \n\nAlso, depending on the nature of the painting, I have also found that adding prompting about impasto, craquelure, canvas texture, and varnish can all be helpful.",
              "score": 2,
              "created_utc": "2026-02-27 20:49:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7rs3gt",
                  "author": "ArsInvictus",
                  "text": "Yep!  I added even canvas texture and that repaired some areas that were blurred in the low res source.  I'll experiment with this for some other artwork too.  Thanks again!",
                  "score": 2,
                  "created_utc": "2026-02-27 21:21:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7w3isa",
          "author": "appioclaud",
          "text": "In general, yes: a **Klein low-denoise refine pass → then SeedVR2 for the “real” upscale** often gives the best balance.\n\n* **Klein (low denoise)** cleans micro-artifacts, skin/texture, and edges while keeping composition stable.\n* **SeedVR2** is usually stronger for **true high-res / 4MP+ / tiled** detail recovery.\n* Doing **SeedVR2 first then Klein** can make Klein “re-interpret” SeedVR2’s invented details (plastic/AI patterns).\n* Skip Klein if the image is already clean or if even low denoise causes drift.",
          "score": 2,
          "created_utc": "2026-02-28 15:22:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7z5kgz",
          "author": "xhox2ye",
          "text": "No, these prompts will all lead to distortion.Use \"remove blur and noise\", distortion is the minimum.\n\ndenoise 1.0\n\nhttps://preview.redd.it/mvnpr7yk2cmg1.jpeg?width=1024&format=pjpg&auto=webp&s=5d70e4d755998121f2b70a603c9777e43a9932cd\n\n",
          "score": 2,
          "created_utc": "2026-03-01 01:07:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7z8hem",
              "author": "YentaMagenta",
              "text": "This is another great tip! What happens if you say \"remove pixelation?\"\n\nEither way, these are all much better than \"upscale\"",
              "score": 1,
              "created_utc": "2026-03-01 01:25:31",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o81e4fc",
              "author": "Eminence_grizzly",
              "text": "I think there is no universal solution for every image. For example, your prompt did absolutely nothing to my image, and \"high resolution\" worked.",
              "score": 1,
              "created_utc": "2026-03-01 11:43:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7nq8gh",
          "author": "skk80",
          "text": "After trying multiple upscaling by various sdxl models, I figured flux. 2 klein 9B distilled provides the best upscaling! Everything else has upscale artifacts like you mentioned.\n\nSeedVR2 simply crashes on my system (5070 ti + 64GB ddr5) while doing any upscaling beyond 2mp. May be I don't know how to use it with it's million parameters!",
          "score": 2,
          "created_utc": "2026-02-27 06:32:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nupxc",
              "author": "psychicEgg",
              "text": "Hiya, try these settings:\n\nhttps://preview.redd.it/c3b6nkt5lzlg1.png?width=1128&format=png&auto=webp&s=572095eb54883d5a22df010c5ca6442042b1246e\n\nIf you have sage attention 2 installed then change the 'attention\\_mode', but I don't find it makes much difference. \n\nAlso, if you're still having any issues, drop the encode and decode tile size from 1024 down to 512. And also both tile overlaps to 64. If you're pixel peeping you'll see a tiny drop in detail zoomed in (more tiles means more blurring the edges).\n\nBut most important is the 'blocks\\_to\\_swap' (max is 36) and all three 'offload\\_device' to cpu.",
              "score": 4,
              "created_utc": "2026-02-27 07:10:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7nuwmc",
              "author": "lebrandmanager",
              "text": "Then try this node and workflows. It seems to work better for lower VRAM \n\nhttps://github.com/moonwhaler/comfyui-seedvr2-tilingupscaler",
              "score": 5,
              "created_utc": "2026-02-27 07:12:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7og0ud",
              "author": "its_witty",
              "text": "5070 Ti + 16GB (DDR4 ;])\n\nTo go beyond 2mp simply bump the 'blocks to swap' and enable tiled encode, or encode and decode. Also, I recommend going with the q6 quants for both the normal and sharp version. \n\n>May be I don't know how to use it with it's million parameters!\n\nEither GitHub or hover on the setting, everything is explained there. Give yourself 5 minutes to learn it and you'll get it, trust me!",
              "score": 2,
              "created_utc": "2026-02-27 10:29:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7nyekh",
              "author": "YentaMagenta",
              "text": "I don't blame you at all, that's one more reason I don't use it. I've simply never needed its performance to the point that that effort felt justified. What's more, at least some of the results from it that I've seen have had some issues that I felt were inconsistent with its level of hype.",
              "score": 1,
              "created_utc": "2026-02-27 07:43:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7otcs5",
          "author": "Allseeing_Argos",
          "text": "Anyone else thinks most AI upscalers tend to make the people look older?",
          "score": 4,
          "created_utc": "2026-02-27 12:17:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7va7ui",
              "author": "Great-Ad-4598",
              "text": "I asked Gemini about that - it reckons the upscalers think slight shadows and stray hair should be wrinkles. It suggested using the detailer node with its own prompt to emphasise the skin is youthful/young/not aged/wrinkle free. Plus any other photographic terms you fancy.",
              "score": 1,
              "created_utc": "2026-02-28 12:22:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7pgppu",
          "author": "ZerOne82",
          "text": "https://preview.redd.it/fsd7gy0ms1mg1.jpeg?width=5120&format=pjpg&auto=webp&s=2fbfe40c023ea041e410c5dbd6f4b23dffc1171c\n\nIf you choose a very low res input image and the person is not known to you, it would impossible to evaluate which method/model/wf does better. So to avoid that, I used this input image from well-known Comfyanonymous to evaluate the likeliness. In my test, Klein 9B applied on the pre-upscaled input image using nearest method seems the best.  \nprompt: \"enhance it. add microdetails, keep it natural.\"",
          "score": 3,
          "created_utc": "2026-02-27 14:37:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7pptb4",
              "author": "sishgupta",
              "text": "> If you choose a very low res input image and the person is not known to you, it would impossible to evaluate which method/model/wf does better.\n\n1000000%",
              "score": 2,
              "created_utc": "2026-02-27 15:22:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7nv530",
          "author": "fauni-7",
          "text": "That beige hue filter that Klein adds isn't going away. That's a defect in the model.",
          "score": 2,
          "created_utc": "2026-02-27 07:14:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nyzwh",
              "author": "YentaMagenta",
              "text": "I do notice that especially when doing a reference there is a bit of a bias toward warmer tones, but I think this is a think with nearly all models because images are biased toward warm tones in general. People tend to prefer warmer images, so both in terms of training data and any sort of aesthetic training, it's going to push the model in that direction. But this can be corrected with prompting or a very simple white balance adjustment.",
              "score": 2,
              "created_utc": "2026-02-27 07:48:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7o05fz",
                  "author": "fauni-7",
                  "text": "It's a defect, and very easy to prove: create a 4 img2img loop in the same workflow (I did), by the 4th ksampler the image is as yellow as a banana. No amount of prompting will fix that.  \nKrea has a similar issue.",
                  "score": 0,
                  "created_utc": "2026-02-27 07:59:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7ol1x4",
          "author": "Coven_Evelynn_LoL",
          "text": "Imagine one day DLSS Ultra Performance looks identical to native 4k",
          "score": 1,
          "created_utc": "2026-02-27 11:13:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7orsh6",
          "author": "kng_arthur",
          "text": "how well does it perform with 256x144 resolutions? or is it way to small for it?",
          "score": 1,
          "created_utc": "2026-02-27 12:06:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7qbo03",
          "author": "Loose_Object_8311",
          "text": "Damn. After some iterating with this workflow on some ancient grainy-ass 200 \\~ 300 pixel images with tonnes of artifacts that traditional upscalers have always failed me on, I found the prompt below at 6 steps on both passes, at a denoise strength of between 0.85 \\~ 0.95 produces crazy results. So long as you don't mind the image changing a bit.\n\n\"high resolution image 1. Give her beautiful, clean, skin. Retain the same exposure, and lighting from image 1. Retain same facial expression from image 1. Retain the same shadows from image 1.\"\n\n  \nEdit: after much testing - another poster gave a tip to simply use \"Subtle high resolution, subtle color correction, subtle denoise\" and I've found sometimes that gives me my preferred result, and sometimes my version gives me preferred result depending on the source image. So, my workflow is now to A/B test them and pick the one I like best.",
          "score": 1,
          "created_utc": "2026-02-27 17:06:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7skxri",
          "author": "mimitasangyou",
          "text": "Such a clean and vibrant piece.",
          "score": 1,
          "created_utc": "2026-02-27 23:56:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7o8kci",
          "author": "Synor",
          "text": "\"using Klein is simpler and faster than something like SeedVR2\"\n\nAbsolutely not.\n\n\"I have not done a direct comparison to SeedVR2 because, candidly, I don't use it.\"\n\nYou should. It's worth it.",
          "score": 1,
          "created_utc": "2026-02-27 09:18:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7o9d1l",
              "author": "YentaMagenta",
              "text": "I would welcome you to offer comparisons, as I noted in my post.\n\nI rarely if ever have a need for an upscaler better than the processes I already use, and with my work on perfecting Flux Klein Upscaling today, it's hard for me to see myself wanting to deal with custom nodes and an additional longer step.\n\nI have seen what the SeedVR2 workflows look like and they are absolutely more complicated than what I shared. The node alone has a ton of settings.\n\nBut here's your chance. show me some comparisons to my method and persuade me :)",
              "score": 2,
              "created_utc": "2026-02-27 09:26:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7odq0v",
                  "author": "SvenVargHimmel",
                  "text": "I'm not sure why some people are being so combative. I love SeedVR2 but it's expensive for what it is. Let's say Flux Klein isn't *as* good, it keeps your whole inference pipeline around a single model.  That is a good thing in my book. \n\nOn the color shift in skin tones, I think that is a thing with *all* models. Remember GPT4o , the joke was that it had a \"piss\" filter because of the *strong* yellow cast. It's not a strong with later models but it is there. I don't think that is an issue. Most images with a human subject almost always have to go through a color correction phase anyway and it's asking too much to expect our magical image models to understand a skin surface from different ethnicities in different lighting conditions under   \ndifferent white balance settings and color temperatures.",
                  "score": 2,
                  "created_utc": "2026-02-27 10:08:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7o9ugm",
                  "author": "Synor",
                  "text": "You are the one making the claims here.",
                  "score": -5,
                  "created_utc": "2026-02-27 09:31:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7nxiqh",
          "author": "po_stulate",
          "text": "I don't know, in the first pic the iron mesh becomes hemp rope and everything looks over sharpened.",
          "score": 1,
          "created_utc": "2026-02-27 07:35:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nzpfc",
              "author": "Fuzzyfaraway",
              "text": "I'm pretty sure that's a fiber net of some kind, attached to a bamboo pole/post/stick.",
              "score": 1,
              "created_utc": "2026-02-27 07:55:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7o00cs",
                  "author": "YentaMagenta",
                  "text": "Could someone call her up and ask her WTF that was?",
                  "score": 3,
                  "created_utc": "2026-02-27 07:58:02",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o7o0wh5",
                  "author": "po_stulate",
                  "text": "fibers do not curve like that.",
                  "score": -2,
                  "created_utc": "2026-02-27 08:06:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7su4w8",
              "author": "IndependenceNo783",
              "text": "It seems not every seed leads to a good generation. I changed the seed from fixed to increment, and submit 8 batches per image. Usually, 1 or 2 of them are great.",
              "score": 1,
              "created_utc": "2026-02-28 00:50:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7nxy77",
              "author": "YentaMagenta",
              "text": "Looks still like overexposed oxidized metal to me, but applying a blur to that area would be trivial. \n\nNo upscaling process is going to be perfect, but I daresay this one is still rather good.",
              "score": 1,
              "created_utc": "2026-02-27 07:39:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7rnrts",
          "author": "Expicot",
          "text": "For drawings/clean lines, SeedVR2 is unbeatable (so far).\n\n[https://imgur.com/a/pAyBF8q](https://imgur.com/a/pAyBF8q)",
          "score": 1,
          "created_utc": "2026-02-27 20:59:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ohob1",
          "author": "baddorox",
          "text": "Why not SEEDVR2?\n\nAm I missing something?",
          "score": 0,
          "created_utc": "2026-02-27 10:44:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7pxq2r",
          "author": "KS-Wolf-1978",
          "text": "I am sorry, but the upscale you posted looks like she has 40 years of smoking and suntanning without any UV protection on.\n\nIt is not your fault, Klein just does that.\n\nFlux 1 Dev with controlnet: https://postimg.cc/WF8LFj1j\n\nThe only problem i see in my upscale is the hair strand on top right that looks bent at unnatural angles (inpaint easily fixes that).",
          "score": 0,
          "created_utc": "2026-02-27 16:00:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7pyf1m",
              "author": "YentaMagenta",
              "text": "People have skin details and imperfections and often want their upscalers to add them. But if you don't like them, it's very fixable:\n\nhttps://www.reddit.com/r/StableDiffusion/s/wR9yZqGkzi",
              "score": 1,
              "created_utc": "2026-02-27 16:03:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7pyu34",
                  "author": "YentaMagenta",
                  "text": "Also, using a control net is not apples to apples.\n\nI would be very excited to see Klein's performance with an analogous control net.",
                  "score": 1,
                  "created_utc": "2026-02-27 16:05:57",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o7q2l7b",
                  "author": "KS-Wolf-1978",
                  "text": "I see big blobs of same color on her skin like old people have or maybe some heavy jpg compression distortion.",
                  "score": 0,
                  "created_utc": "2026-02-27 16:23:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7ppl9v",
          "author": "sishgupta",
          "text": "The original was intentionally shot with a soft focus on the model, which is common in modeling shots. Unfortunately this is not just an upscale but a re-interpretation of the shot as it has completely robbed the original of it's artistic intent.",
          "score": -1,
          "created_utc": "2026-02-27 15:21:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7py1hb",
              "author": "YentaMagenta",
              "text": "The photo is from a 1950s copy of Playboy apparently, so separating artistic intent from the technical limitations of the medium is rather difficult. \n\nPeople generally want their upscalers to add detail and not adding detail is trivial.\n\nIf you look through the other comments you'll see that all I had to do was add soft focus and decrease the step count slightly to get a soft focus version.",
              "score": 1,
              "created_utc": "2026-02-27 16:02:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7q58aw",
                  "author": "sishgupta",
                  "text": "> The photo is from a 1950s copy of Playboy apparently, so separating artistic intent from the technical limitations of the medium is rather difficult. \n\nTell me you dont understand photography without telling me you dont understand photography.\n\n>People generally want their upscalers to add detail and not adding detail is trivial.\n\npeople generally dont want their upscalers to invent details that werent supposed to be there",
                  "score": -1,
                  "created_utc": "2026-02-27 16:36:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7otm99",
          "author": "lazystingray",
          "text": "Are you de-blurring or up scaling ...?  The outputs are impressive but we need to remember that it's not the original content.  Not a dig, just a comment - these kind of images should never be passed as original.",
          "score": 0,
          "created_utc": "2026-02-27 12:19:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7pjsjk",
          "author": "nopalitzin",
          "text": "I think it turned jpeg artifacts into skin tone and texture, a lot of unusual colors in the face",
          "score": 0,
          "created_utc": "2026-02-27 14:52:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ueqas",
          "author": "PhoenixxBR",
          "text": "eu ja consegui criar upscaler melhores do que esse, problema que o melhor upscaler possivel que voce consiga com flux Klein 9b, ao fazer o mesmo usando nanobanana2, voce percebe que so perdeu tempo configurando prompts no Klein 9B, eu estou esperando sair alguma versao atualizada do modelo por algum usuario, pq eu ja fiz condiguracoes ao extremo para manter a consistencia mais fiel possivel de uma pessoa, e ainda assim os resultados só sao satisfatorios.\nMas isso so uma dica de alguem que ja ficou muitas horas testando prompts, loras, modelos, peso e todas configuraçoes possiveis no Flux 2 Klein.",
          "score": 0,
          "created_utc": "2026-02-28 07:32:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7uvmsm",
              "author": "YentaMagenta",
              "text": "Nanobanana2 não é de código aberto e, portanto, não é o que as pessoas neste subreddit estão procurando.",
              "score": 1,
              "created_utc": "2026-02-28 10:12:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7nza24",
          "author": "tomuco",
          "text": "https://preview.redd.it/72tymomenzlg1.png?width=2048&format=png&auto=webp&s=ec0b89d532ab05274799d88928cdd424ef36d415\n\nJust cobbled this together in 10 minutes. Took the left image from the previous post (which might've even degraded it a bit more, I'm not too familiar with webp). Flux.1 Dev, absolute minimal workflow, no prompt, 32 steps, 1024x1024, otherwise default settings, Euler simple, seed:1. Added flux.1-dev-controlnet-upscaler. Set strength to 0.9, as default brought a bit too much grain, but it did come at the cost of losing a little bit of her facial likeness. Done. \n\nJust to be clear, if I tasked a professional with the job and this is what I'd receive, I'd want my money back. But that's not the point. This isn't just upscaling, it's also a fair bit of restauration. Even with AI, this requires much more work and multiple passes. Also, this was a VERY quick and dirty job, I didn't even try higher resolutions. However, I believe with some careful SDE noise scheduling, I could achieve even an better result in one pass. \n\nThe point however is, Klein can't do everything equally good, or even better than previous models (in this case F1 + a controlnet tailored to the task) and there's simply no perfect one-pass solution.",
          "score": -4,
          "created_utc": "2026-02-27 07:51:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nzton",
              "author": "YentaMagenta",
              "text": "I'm not sure I'm understanding you correctly. Are you suggesting that your result o the right is better than the one from Flux 2 Klein?",
              "score": 1,
              "created_utc": "2026-02-27 07:56:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7o10n0",
                  "author": "tomuco",
                  "text": "Yes. In terms of fidelity, defintely. But to reitereate, I'm not saying it's good as a final result, just as a first pass.",
                  "score": -1,
                  "created_utc": "2026-02-27 08:07:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7odmqp",
          "author": "HollowAbsence",
          "text": "why is everything greener after ?",
          "score": -2,
          "created_utc": "2026-02-27 10:07:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7nqfrg",
          "author": "devilish-lavanya",
          "text": "Don’t worry, We are not gonna leave you unless you fall for api trap.",
          "score": -4,
          "created_utc": "2026-02-27 06:34:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nxiog",
              "author": "YentaMagenta",
              "text": "Come again?",
              "score": 2,
              "created_utc": "2026-02-27 07:35:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rckeon",
      "title": "Fine-tuning SDXL with childhood pictures → audio-reactive geometries - [Experiment]",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/4s7zdq75i9lg1",
      "author": "Real-Philosopher-895",
      "created_utc": "2026-02-23 15:26:51",
      "score": 315,
      "num_comments": 21,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Animation - Video",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rckeon/finetuning_sdxl_with_childhood_pictures/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6ze7of",
          "author": "ThatOneDerpyDinosaur",
          "text": "Creative use of AI tools with zero bouncing anatomy. Have an upvote",
          "score": 15,
          "created_utc": "2026-02-23 17:16:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75m2oy",
              "author": "Real-Philosopher-895",
              "text": "♥",
              "score": 3,
              "created_utc": "2026-02-24 15:58:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6z3gcw",
          "author": "repezdem",
          "text": "It's nice to see some actually good art made with AI tools. Great job",
          "score": 30,
          "created_utc": "2026-02-23 16:26:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zbxhl",
              "author": "zackmophobes",
              "text": "Agreed this is really cool and a fun use case. Thanks for sharing OP.",
              "score": 9,
              "created_utc": "2026-02-23 17:05:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o75lppv",
                  "author": "Real-Philosopher-895",
                  "text": "Thank you guys ♥",
                  "score": 3,
                  "created_utc": "2026-02-24 15:57:17",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6zr77c",
          "author": "Tyler_Zoro",
          "text": "Hope you don't mind, but I've uploaded this video to the aiwars sub [here](/r/aiwars/comments/1rcp4rv/this_is_what_creative_people_do_with_new/). Sadly, that sub doesn't let me link to your post or mention you by name, but if you want to poke your head in and claim credit, please do!",
          "score": 4,
          "created_utc": "2026-02-23 18:16:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o722ng3",
          "author": "Itiiip",
          "text": "finally, introspective diffusion",
          "score": 4,
          "created_utc": "2026-02-24 01:18:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75m5nt",
              "author": "Real-Philosopher-895",
              "text": "I like that name. Thanks for the idea.",
              "score": 3,
              "created_utc": "2026-02-24 15:59:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o702pwa",
          "author": "bigman11",
          "text": "good experiment",
          "score": 3,
          "created_utc": "2026-02-23 19:09:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o707gde",
          "author": "Mid-Pri6170",
          "text": "needs to be in a gallery.",
          "score": 3,
          "created_utc": "2026-02-23 19:31:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75m7it",
              "author": "Real-Philosopher-895",
              "text": "I'd love that.",
              "score": 2,
              "created_utc": "2026-02-24 15:59:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6zkoav",
          "author": "raulsestao",
          "text": "Where can I find the first song from the video? It's very pretty, is it AI too?",
          "score": 2,
          "created_utc": "2026-02-23 17:46:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75m1zy",
              "author": "Real-Philosopher-895",
              "text": "Hey, thank you. No, no. It's composed by me. If I recall correctly I used my Osmose + Cosmos \\[SOMA\\] synths.",
              "score": 3,
              "created_utc": "2026-02-24 15:58:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6zwd76",
          "author": "mcpoiseur",
          "text": "I like the wobbly ness",
          "score": 2,
          "created_utc": "2026-02-23 18:40:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o750y81",
          "author": "Weak-Abbreviations15",
          "text": "Bro just made a Flashbacks before you die simulator. ",
          "score": 2,
          "created_utc": "2026-02-24 14:16:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70kg8m",
          "author": "jefharris",
          "text": "Very cool.",
          "score": 1,
          "created_utc": "2026-02-23 20:32:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o72coxd",
          "author": "diarrheahegao",
          "text": "Nice, what songs did you use for the video?",
          "score": 1,
          "created_utc": "2026-02-24 02:16:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75m9te",
              "author": "Real-Philosopher-895",
              "text": "None, it's a little something composed by me. ",
              "score": 2,
              "created_utc": "2026-02-24 15:59:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o73bxrx",
          "author": "Wormri",
          "text": "It's like something straight out of Control.",
          "score": 1,
          "created_utc": "2026-02-24 06:14:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76obc0",
          "author": "Professional-Alps479",
          "text": "Very nice.",
          "score": 1,
          "created_utc": "2026-02-24 18:50:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ys4hn",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -12,
          "created_utc": "2026-02-23 15:33:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rgovde",
      "title": "For very low resolution videos restoration, SeedVR2 is better than FlashVSR+ like 256px to 1024px",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/qj8otka2y4mg1",
      "author": "CeFurkan",
      "created_utc": "2026-02-28 01:08:47",
      "score": 290,
      "num_comments": 38,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rgovde/for_very_low_resolution_videos_restoration/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7t09e6",
          "author": "Ooze3d",
          "text": "Wow! That’s one of the best examples I’ve seen so far. Is it a standard workflow or is it tuned in some way to achieve these results? I see it’s adding frame interpolation too.",
          "score": 28,
          "created_utc": "2026-02-28 01:28:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7t59ko",
              "author": "CeFurkan",
              "text": "this is my custom implementation into a gradio app. yes i added 2x RIFE it helps a lot",
              "score": 10,
              "created_utc": "2026-02-28 01:59:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7tes9e",
                  "author": "TheDuneedon",
                  "text": "You posting it anywhere? My experience with SeedVR2 has been mediocre at best. ",
                  "score": 12,
                  "created_utc": "2026-02-28 02:59:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7u5ycl",
          "author": "newaccount47",
          "text": "This is gonna do wonders to my vintage porn collection. ",
          "score": 46,
          "created_utc": "2026-02-28 06:15:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ufbos",
              "author": "gmgladi007",
              "text": "![gif](giphy|11mwI67GLeMvgA)\n\nThis is the comment I was looking for.",
              "score": 15,
              "created_utc": "2026-02-28 07:38:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7ugymw",
                  "author": "mitchins-au",
                  "text": "This is the reply I was looking for",
                  "score": 4,
                  "created_utc": "2026-02-28 07:53:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7ytxmg",
              "author": "NineThreeTilNow",
              "text": "> This is gonna do wonders to my vintage porn collection. \n\nI'm waiting until we can take ~1080p to 4k x 2 w/ VR.\n\nThat's a proper Video to Video model. \n\nIf I had the money to train that...",
              "score": 1,
              "created_utc": "2026-02-28 23:59:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7tauof",
          "author": "Dr-Moth",
          "text": "I like SeedVR2 for images, but when I tried on video the patterned wallpaper in the background became jittery to the point of being unwatchable. It seemed like it couldn't agree a consistent way to upscale the pattern and it changed every frame.",
          "score": 12,
          "created_utc": "2026-02-28 02:34:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7tknqr",
              "author": "FantasticFeverDream",
              "text": "Same, I think, the picture \"blooms\" in and out. ",
              "score": 6,
              "created_utc": "2026-02-28 03:36:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7v1rr1",
              "author": "wywywywy",
              "text": "What batch size are you using? The higher it is, the more stable it becomes in theory. With 32GB VRAM it can do batch size of about 45.\n\nEDIT: For 720p I mean.",
              "score": 2,
              "created_utc": "2026-02-28 11:10:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7v9isc",
                  "author": "Dr-Moth",
                  "text": "Batch size 8, because I'm only on 12gb vram. I'll try dropping the resolution and increasing the batch size.",
                  "score": 1,
                  "created_utc": "2026-02-28 12:16:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7twhgm",
          "author": "Emotional-Sundae4075",
          "text": "Ahh, regardless of the cool model, I am just remembering how nice it was to have my music offline on my mp3 device, no need a subscription to f-ing apple music, no ads on YouTube. That was fun",
          "score": 9,
          "created_utc": "2026-02-28 04:59:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ucnfn",
              "author": "brown_felt_hat",
              "text": "I recently just turned an old cellphone (oneplus 6t) of mine into an mp3 player.  HIGHLY recommend giving it a go.  My spotify annual runs out in 2 months, and I'm making it a goal to be completely divorced of it by then.  Synced my spotify playlists through an app that shares a name with Light Detection and Ranging so I can track artists albums.  Bought a bunch of my fave music off artists bandcamps, ripped a ton of my *old* CDs (rediscovered a bunch of bands too, so that was sick as fuck).  Synced through mediamonkey.  I'm using Symfonium as the player, which is super customizable, and can sync with my Jellyfin music so if I run out of space I can still stream whatever using wifi.  It's not a perfect replacement, Spotify still has the best auto playlist/radio generator for on the fly sets, and I'll probably keep the app for music discovery cause it's pretty OK for that, but other than that, the transition's been *pretty* smooth.",
              "score": 6,
              "created_utc": "2026-02-28 07:14:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7tzy5i",
              "author": "SpaceNinjaDino",
              "text": "Or age verification at the OS level. (Damn new 2027 California law!)",
              "score": 5,
              "created_utc": "2026-02-28 05:26:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7up981",
          "author": "Ill_Ease_6749",
          "text": "only guy that makes simple things confusing and free thing paid lol",
          "score": 7,
          "created_utc": "2026-02-28 09:09:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7t56en",
          "author": "Pase4nik_Fedot",
          "text": "Not bad, but I prefer the same thing in comfyui 😂",
          "score": 13,
          "created_utc": "2026-02-28 01:59:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7t14or",
          "author": "jordek",
          "text": "Wow that's pretty good, I think with a LTX2 lora of Steve the face could also be fixed even at the further away shots, including lip sync (only inpainting the head).",
          "score": 3,
          "created_utc": "2026-02-28 01:33:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7t5baj",
              "author": "CeFurkan",
              "text": "i am hoping such model hopefully soon that can further improve as you said",
              "score": 2,
              "created_utc": "2026-02-28 02:00:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7t7mqp",
                  "author": "jordek",
                  "text": "It's already possible, but requires quite some work. Mainly making the lora. In this case since the voice is already existing a lora trained with images should be sufficient.",
                  "score": 2,
                  "created_utc": "2026-02-28 02:14:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7t1745",
          "author": "InvisGhost",
          "text": "Looks great! How long did it take and what specs were you working with?",
          "score": 2,
          "created_utc": "2026-02-28 01:34:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7t57nf",
              "author": "CeFurkan",
              "text": "i have rtx 5090 it took 6 minutes. i can go faster but i didnt optimize",
              "score": 5,
              "created_utc": "2026-02-28 01:59:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7xf89u",
                  "author": "DjSaKaS",
                  "text": "for 59 second and only 6 minute? I have 5090 but take much more for just 20 sec it takes 15 min",
                  "score": 1,
                  "created_utc": "2026-02-28 19:21:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7vrgyf",
          "author": "Nexustar",
          "text": "It's good, but his lips aren't moving enough - a lipreader would get nothing from this.",
          "score": 2,
          "created_utc": "2026-02-28 14:15:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7yt0s4",
          "author": "IronLover64",
          "text": "Why is the high res version gone?",
          "score": 2,
          "created_utc": "2026-02-28 23:53:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7tcxd4",
          "author": "Turbulent_Corner9895",
          "text": "do you please provide its workflow.",
          "score": 3,
          "created_utc": "2026-02-28 02:47:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7tk2xd",
          "author": "chut_has_no_religion",
          "text": "Doesn’t look like Jobs in some angles",
          "score": 2,
          "created_utc": "2026-02-28 03:33:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7tne9w",
              "author": "its_witty",
              "text": "Well... considering the input quality...",
              "score": 8,
              "created_utc": "2026-02-28 03:55:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7tp3hk",
                  "author": "chut_has_no_religion",
                  "text": "Yeah that keeping in mind it’s prettyy nice",
                  "score": 1,
                  "created_utc": "2026-02-28 04:06:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7t5d9y",
          "author": "Dead_Internet_Theory",
          "text": "That's fantastic. Have you tried BasicVSR++? I noticed it's the model used for uhh for the, pixelated eggplant emojis in various Japanese films. But it does such an impressive job at \"absolute crap resolution\", I wonder if it does much better when the source resolution is larger than a favicon.",
          "score": 1,
          "created_utc": "2026-02-28 02:00:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7tpx90",
              "author": "michaelsoft__binbows",
              "text": "I've never seen a single pixelated eggplant reversal job that I liked better than to just leave it pixelated... At best it turns it into an explicit horror movie nobody asked for.",
              "score": 2,
              "created_utc": "2026-02-28 04:12:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7t5ir7",
              "author": "CeFurkan",
              "text": "I so far compared with FlashVSR+. FlashVSR+ is better at higher resolution definitely. Will check BasicVSR++ thank you",
              "score": 1,
              "created_utc": "2026-02-28 02:01:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7unty6",
          "author": "djnorthstar",
          "text": "Nice , next step Stargate and Voyager upscales....",
          "score": 1,
          "created_utc": "2026-02-28 08:55:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7y96c9",
          "author": "Gamerboi276",
          "text": "https://preview.redd.it/33tghfih5bmg1.png?width=862&format=png&auto=webp&s=e5cf1da8c1cd9ae6db4753fafee416cb98052e62\n\nyeah but the frame interpolation sucks",
          "score": 1,
          "created_utc": "2026-02-28 22:00:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rg7cpj",
      "title": "How to make multiple character on same image, but keep this level of accuracy and details?",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/u54ahlr7l1mg1.png",
      "author": "goku58s",
      "created_utc": "2026-02-27 13:56:06",
      "score": 273,
      "num_comments": 156,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Question - Help",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rg7cpj/how_to_make_multiple_character_on_same_image_but/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7pauy8",
          "author": "XpPillow",
          "text": "You are gonna need to do them one by one with inpaint. If you write them in the same prompt they’d mix up elements and lose details. So basically you need to generate a picture with one girl in it, and re-create the picture partially to get another one.",
          "score": 80,
          "created_utc": "2026-02-27 14:05:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7pxtmp",
              "author": "ayu-ya",
              "text": "You can generate two from the start and then correct the mixed up stuff with the inpaint, too - I found this easier when trying to make images where the characters interact with each other, so I have something with the right poses and composition as a base. I was told to use BREAK between the characters' prompts in the original gen and I have no idea how valid it is, but I didn't have to correct THAT much in the end",
              "score": 27,
              "created_utc": "2026-02-27 16:01:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7r2un1",
                  "author": "Caesar_Blanchard",
                  "text": "It's basically random. See, I've been using Illustrious for years and honestly, BREAK doesn't really help, at least not for the purpose of avoid characters to mingle each other.\n\nWhat I've recently noticed when trying to do 2 or 3 characters from the go, is to avoid over prompting, and if the model knows the characters without LoRa, don't prompt their traits. Name and or franchise is enough, i.e. “Makima (chainsaw man), Power (chainsaw man)”, no specify “red horns”, because there's a high chance that Makima will also have the horns when that's incorrect.",
                  "score": 16,
                  "created_utc": "2026-02-27 19:15:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7rizjf",
                  "author": "-_Weltschmerz_-",
                  "text": "What's a good inpainting tool for Comfy?",
                  "score": 3,
                  "created_utc": "2026-02-27 20:35:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7rq47x",
                  "author": "soldierswitheggs",
                  "text": "BREAK isn't supported by default in Comfy. There's some nodes from [ComfyUI Prompt Control](https://github.com/asagi4/comfyui-prompt-control) that can enable it. It's definitely useful for keeping disparate elements of the prompt separate.",
                  "score": 1,
                  "created_utc": "2026-02-27 21:11:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7pbcsf",
              "author": "goku58s",
              "text": "I have been reading some about it, but didn't figure it out at all. Also it's not only about a girl, I mean I want to make a picture that can later be photshoped in manga or something like that. But that is less important. I had a workflow with 2 different prompts for 2 characters, but that is not giving me not even slightly close detail to the referenced pic above (example pic, I didn't have any other on hand)",
              "score": 3,
              "created_utc": "2026-02-27 14:08:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7pcc0y",
                  "author": "XpPillow",
                  "text": "well you can try the Qwen Edit workflow which is basically an AI photo editor like a low version of nano-banana. Feed it with 2 pictures of the 2 girls of yours, and then ask the model to \"put them together in one picture\" with whatever pose you want.",
                  "score": 5,
                  "created_utc": "2026-02-27 14:13:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7pl99n",
          "author": "Geritas",
          "text": "I did it with regional prompting on forge ui back in the day, it worked okay, but not 100% of time. Sometimes I had to roll 100s of images before getting exactly what i want in terms of two characters interacting with each other.",
          "score": 11,
          "created_utc": "2026-02-27 15:00:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7pm3sq",
              "author": "goku58s",
              "text": "Oh man... so I shouldn't use a forge, thanks for letting me know",
              "score": -2,
              "created_utc": "2026-02-27 15:04:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7pmg0p",
                  "author": "Geritas",
                  "text": "I didn't mean to say that forge is bad. It is arguably better if you don't need all the control that comfyui gives you, because it is way easier to just start doing shit in Forge, while in comfy simple things take way more time normally.",
                  "score": 7,
                  "created_utc": "2026-02-27 15:06:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7upgv6",
                  "author": "Unusual-Marzipan5465",
                  "text": "If you want the simplicity of Forge with a great deal more power and control, just use Invoke. I have no idea why people use a1111/Forge these days unless there's a very specific mod you need",
                  "score": 1,
                  "created_utc": "2026-02-28 09:11:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7peeds",
          "author": "Comprehensive-Pea250",
          "text": "You could use the Anima model it does this pretty well",
          "score": 28,
          "created_utc": "2026-02-27 14:24:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7peki1",
              "author": "goku58s",
              "text": "I will sound stupid now... but what is that? I am not some genius for this things and I am honest about it",
              "score": 7,
              "created_utc": "2026-02-27 14:25:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7pi9ev",
                  "author": "Comprehensive-Pea250",
                  "text": "https://huggingface.co/circlestone-labs/Anima it’s a model sponsored by comfyui that is made for Anime it’s also on civitai",
                  "score": 22,
                  "created_utc": "2026-02-27 14:45:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7se4cb",
              "author": "Areinu",
              "text": "You're right, Anima does it pretty well, but not perfect.\n\nI love anima and I've been using it basically since it came out, but it still mingles characters up to certain extend. I follow all guidelines on the hugginsface, order of tags, way to describe characters, steps, cfg and so on, and usually results are good...\n\nThat said some traits are \"stronger\" than others and seem to \"leak\" into other characters more than others. For example \"overweight\" seems to make everyone chubbier, even if you used it to describe only one person.\n\nAnd once you go above 3 characters all hell might break loose. \n\nStill... 0-4 rerolls usually gets me results I want (with 2 characters), so it's not bad. \n\nIf you have some tricks or suggestions how to decrease leaking in Anima even more I'd like to hear them!",
              "score": 1,
              "created_utc": "2026-02-27 23:17:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7u0ptj",
                  "author": "LawfulnessBig1703",
                  "text": "probably because of the te, on the other hand, clip would have turned everything into a complete mess",
                  "score": 1,
                  "created_utc": "2026-02-28 05:32:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7r7wh8",
          "author": "darktaylor93",
          "text": "I believe you're looking for this     \nhttps://github.com/yaoliliu/FreeFuse",
          "score": 6,
          "created_utc": "2026-02-27 19:40:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7r88i6",
              "author": "goku58s",
              "text": "Someone did send me this, but I am not good with making workflows, that is my issue. So I am also looking for a workflow, but thank you as well!",
              "score": 1,
              "created_utc": "2026-02-27 19:41:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7rraso",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 1,
                  "created_utc": "2026-02-27 21:17:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7pj19t",
          "author": "Aplakka",
          "text": "I don't think there's any silver bullet, but I've had reasonably good luck with Illustrious based models, though it doesn't work nearly every time. Here is a quick example with Tifa and Aerith, I tried to make something with different expressions and poses per character. I was able to make a few different images with pretty similar style, but looks like I can't attach more than one image per comment.\n\nThe more popular characters the more likely it is that the model will know them well enough, but still it's likely you'll need to create multiple images to get one where most things look good enough. You may still need some inpainting, e.g. eye colors changing is a common issue and often you will get reversed poses or clothes. Forge has the \"variation seed\" option which can be useful if you get something that's pretty close but not quite what you want. ComfyUI most likely has something similar in some suitable node.\n\nI don't know how much effect the BREAK and () have in practice, but at least they make the prompt clearer to me. I use \"Stable Diffusion WebUI Forge - Classic\" so e.g. ComfyUI might not use similar syntax.\n\nmasterpiece, best quality, amazing quality, 4k, very aesthetic, high resolution, ultra-detailed, absurdres, newest, scenery, general,  \n2girls, tifa lockhart and aerith gainsborough, final fantasy, nightclub, looking at each other, side view,  \nBREAK (tifa lockhart, leaning back on wall, mischievous grin)  \nBREAK (aerith gainsborough, pointing at another, pout)  \nBREAK, depth of field, volumetric lighting  \nNegative prompt: modern, recent, old, oldest, cartoon, graphic, text, painting, crayon, graphite, abstract, glitch, deformed, mutated, ugly, disfigured, long body, lowres, bad anatomy, bad hands, missing fingers, extra digits, fewer digits, cropped, very displeasing, (worst quality, bad quality:1.2), bad anatomy, sketch, jpeg artifacts, signature, watermark, username, signature, simple background, conjoined,bad ai-generated  \nSteps: 30, Sampler: Euler a, Schedule type: Simple, CFG scale: 5, Seed: 3762178807, Size: 1024x1024, Model hash: 463eddd5b3, Model: novaAnimeXL\\_ilV160, Denoising strength: 0.2, Clip skip: 2, Hires Module 1: Use same choices, Hires CFG Scale: 4, Hires upscale: 2, Hires steps: 10, Hires upscaler: 4x-AnimeSharp, Version: neo\n\nhttps://preview.redd.it/36ro4sgru1mg1.png?width=2048&format=png&auto=webp&s=2b3405b6f35123b585ea7bb065b97e28209097e1\n\n  \n",
          "score": 13,
          "created_utc": "2026-02-27 14:49:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7pm9kr",
              "author": "Jaune_Anonyme",
              "text": "FYI BREAK does not have the effect you think it has unless you have a regional prompting extension (like https://github.com/Haoming02/sd-forge-couple) \n\nHere is what BREAK does exactly by default without the extension enable (and the default syntax is the same across most forks)\n https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/features#break-keyword\n\n\nIn other words, SD older models (SD 1.x, SDXL) have a limit of ~75 tokens.\nA workaround was implemented to get more tokens in your prompts.\nPass the first chunk (beyond the 75 tokens limits) a second chunk will be created and embedded back into the first one.\n\n\nProblem is, if ever you have a word half assed between the two chunks it could lead to undesired results (or content). So to avoid that happening, you can manually use the syntax BREAK to create manually the cutoff/2nd chunk.\n\n\nOne bad example of undesired content would be, you're prompting some NSFW spicy content, you soon reach the token limit almost creating a 2nd one. And the word falling perfectly between the two chunks is babydoll (a clothing/lingerie). Oops it got cut off as baby/doll. And you're in a bad jailbait surprise if ever your model is dumb enough.\n\nOf course, with more recent models that can handle hundreds of tokens out of the box, the BREAK syntax is totally useless (or detrimental to use).",
              "score": 12,
              "created_utc": "2026-02-27 15:05:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7rzf6m",
                  "author": "KadahCoba",
                  "text": "> FYI BREAK does not have the effect you think it has unless you have a regional prompting extension\n\nI know you are talking about A1111 forks and OP is using ComfyUI, so I'll give some translation.\n\nThe `BREAK` keyword does not work in ComfyUI core conditional processing. A close approximation of `BREAK` with only core nodes would be to use multiple conditional prompts, one for each `BREAK` block, and combine the conds with a cond concat node. The other option is to use a custom cond node that has `BREAK` support.\n\nWhat `BREAK` does is allow you to control where in the prompt the conditioning is wrapped to the next layer. This only applies to models that use CLIP, which has a limit of 77 input tokens (effectively 75 because of start/end tokens). Generally I think the idea was to have complete ideas per CLIP chunk that would become the conditioning.\n\nEmbeddings are/were also a good way to control prompt length, a whole series of tokens can become one set of vectors to save prompt space. There was also magic with embeddings since you can compute those vectors via other means than just combining tokens.\n\nControlling these chunks boundaries and prompt length was more important in SD1 and early SDXL models. By late stage Pony finetunes/merges and modem Illus merges, it has become mostly unnecessary to worry about the 75 token thing. And almosy every model since SDXL (that matters), CLIP stuff is either mostly or entirely a non-factor.",
                  "score": 3,
                  "created_utc": "2026-02-27 21:58:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7pocb2",
                  "author": "Aplakka",
                  "text": "Yeah I know about the 75 token per chunk limit, though I've never really understood what the effect is in practice. It makes sense that there would be issues when words are near the chunk boundary though. With some Pony based models I remember getting really weird results sometimes if the positive and negative prompts didn't have the same amount of chunks.\n\nThanks for the recommendation for the regional prompting, that sounds like a useful plugin. I tried something similar with A1111 ages ago but didn't realize there was something compatible with Forge Classic.",
                  "score": 1,
                  "created_utc": "2026-02-27 15:15:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7pohhk",
                  "author": "x11iyu",
                  "text": "even without regional prompting, tags between chunks wont have attention between them. this in my experience does help with concept bleed somewhat and can serve as a quick and dirty solution in emergencies, though obviously regional prompting of whatever flavor you like is more effective",
                  "score": 1,
                  "created_utc": "2026-02-27 15:16:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7pkstb",
              "author": "NorthernRealmJackal",
              "text": "Just wanted to say thanks for the comprehensive tip! What a great example image - amazing style, really sharp, and no artifacts or \"AI giveaways\".",
              "score": 6,
              "created_utc": "2026-02-27 14:58:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7pmy2c",
                  "author": "Aplakka",
                  "text": "Thanks! Hope it was helpful.",
                  "score": 1,
                  "created_utc": "2026-02-27 15:08:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7qu6ti",
                  "author": "Kazeshiki",
                  "text": "I think the model already have information about Tifa and Aerith already. You can use loras to force the subjects into who you want.",
                  "score": 1,
                  "created_utc": "2026-02-27 18:33:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7putfj",
              "author": "goku58s",
              "text": "Okay, I have read it this time. Unfortunately, BREAK seems to do nothing for me even though I have installed something that should make it work...",
              "score": 2,
              "created_utc": "2026-02-27 15:46:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7pywbs",
                  "author": "Aplakka",
                  "text": "I'm not sure how much effect BREAK has even if it's working, at least Jaune\\_Anomyne claimed it only has effect in very specific cases. Even with it in Forge it's pretty common to get the wrong character doing the thing the other one is supposed to be doing based on the prompt. I think it would require a different base model than Illustrious to get more consistent results.\n\nWith Illustrious your best bet is probably to make a reasonable prompt, generate e.g. 8 images, see if any match the prompt, then adjust the prompt if necessary.",
                  "score": 1,
                  "created_utc": "2026-02-27 16:06:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7pj6vo",
              "author": "goku58s",
              "text": "Ou huge text, reading it as soon as I can. Thanks in advance!",
              "score": 1,
              "created_utc": "2026-02-27 14:49:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7r7q2n",
          "author": "ToasterLoverDeluxe",
          "text": "you can make illustrious create 2 different characters in the same picture with just prompting, no need for any fancy workflows...\n\nhttps://preview.redd.it/z78rrjh2b3mg1.png?width=1200&format=png&auto=webp&s=0d0260841264544cb90c0cbba7ef022ca5522c86\n\n;(Hyuuga\\_Hinata is a woman+(chubby:0.6), Hyuuga\\_Hinata has large\\_breasts+wide\\_hips+black\\_hair+purple\\_eyes, Hyuuga\\_Hinata is wearing high\\_heels+white\\_high\\_heels+suit+mini skirt);\n\n;(Uzumaki\\_Boruto is a boy, Uzumaki\\_Boruto has blonde\\_hair+blue\\_eyes, Uzumaki\\_Boruto is wearing a suit);\n\n;Hyuuga\\_Hinata is at the side of Uzumaki\\_Boruto, office\n\nkeep in mind that some models understand better than others",
          "score": 6,
          "created_utc": "2026-02-27 19:39:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7r81ri",
              "author": "goku58s",
              "text": "Yeah, I believe that checkpoint that I am using is not good with this typenof prompt. Because I always had to use tags for it",
              "score": 1,
              "created_utc": "2026-02-27 19:40:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7rsnta",
                  "author": "ToasterLoverDeluxe",
                  "text": "The \"nova\" models have good adherence to prompts probably the best at that... also do not use lora's if the model already know the characters, also remember that most illustrious models can do several styles, you dont really need a whole model for a style",
                  "score": 1,
                  "created_utc": "2026-02-27 21:24:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7uytrt",
              "author": "Amra72a",
              "text": "It's very cool. I also want to ask what model is generated by the picture. I like its style.",
              "score": 1,
              "created_utc": "2026-02-28 10:42:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7qcgg1",
          "author": "waynenors",
          "text": "Based Kohaku enjoyer",
          "score": 8,
          "created_utc": "2026-02-27 17:09:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qovlb",
              "author": "goku58s",
              "text": "Well I am glad someone likes the image :)",
              "score": 2,
              "created_utc": "2026-02-27 18:08:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7s65j2",
                  "author": "Brigapes",
                  "text": "no worries, you're not alone \n\nshe's top tier",
                  "score": 3,
                  "created_utc": "2026-02-27 22:33:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7qkrxz",
          "author": "SweetGale",
          "text": "* **Known characters** – If it's a character the model knows about or you have a LoRA for each one, Stable Diffusion XL is usually quite good at keeping them apart. If they're your own OCs, then you'll have to train a LoRA for each one.\n* **Inpainting** – Create an image with two (or more) generic characters and then use inpainting to replace each one in turn.\n* **Cut and paste** – Just generate each character against a simple background, try to make the style and lighting match and then cut them out and edit them together.\n* **Regional prompting** – The *Comfy Couple* node for ComfyUI offers an easy way to split an image in two and provide a separate prompt for each half. Just remember that each side can see the whole image. Use \"duo\" in each prompt rather than \"solo\" and try to make the characters as different as possible. (I'm a heavy user of Illustrious-based models and regional prompting myself.)\n* **Newer models** – SDXL models like Illustrious are good enough in a lot of situations. But handling multiple characters is one area they're quite bad at. Try the fp8 version of *Z-Image-Turbo*. It has similar system requirements and generation speed as SDXL but handles multiple characters without problems. I can name the characters in my prompt, provide a description for each and then position them relative to each other. Z-Image-Turbo is focused on photo realism though. There are some anime fine-tunes and LoRAs but I haven't spent that much time trying them out yet. *Anima* is a new anime model with relatively low system requirements. From my brief experiments it seems to handle multiple characters quite well. You can also try *Flux*, *Chroma*, *Qwen-Image* or *Flux.2 Klein*. Try quantised versions if your computer can't handle the full models.",
          "score": 6,
          "created_utc": "2026-02-27 17:49:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qnqpl",
              "author": "goku58s",
              "text": "Hi, I have 5070ti so I don't PC will be an issue. Can you maybe share the link towards workflow or something because I am quite big of a noob when it comes to making my own workflow. Anyway, thank you for reply",
              "score": 1,
              "created_utc": "2026-02-27 18:03:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7r4y42",
                  "author": "SweetGale",
                  "text": "I'm also fairly new to ComfyUI. I try to build the simplest workflows I can from scratch in order to learn how it works. Pre-made workflows tend to cover multiple use cases, be over-complicated and be hard to understand. *Comfy Couple* is a very simple node. It sits just before the *KSampler* node. Beyond that, you just need an extra *CLIP Text Encode (Prompt)* node for a total of three: positive\\_1, positive\\_2 and negative. For newer models, it's mostly a matter of figuring out which text encoder and VAE to use.\n\nYou can find the Comfy Couple node and an example workflow on this page: [https://github.com/Danand/ComfyUI-ComfyCouple](https://github.com/Danand/ComfyUI-ComfyCouple)",
                  "score": 1,
                  "created_utc": "2026-02-27 19:25:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7pstud",
          "author": "truci",
          "text": "You can use the couples setup where you prompt left and right separately. \n\nYou can make them separately then throw them into like flux Kontext to merge them then upscale or resample the result with a medium denoise using your illustrious model. \n\nYou can use anima or z image to get the prompt adherence then feed that back into as latent or upscale with the illustrious again. \n\nMany ways but none are perfect and they all have pro and cons.",
          "score": 2,
          "created_utc": "2026-02-27 15:37:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7pud1x",
              "author": "goku58s",
              "text": "Oh man, as someone who is noob in all of this, I am so confused by all of this🤯",
              "score": 1,
              "created_utc": "2026-02-27 15:44:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7qbht0",
                  "author": "truci",
                  "text": "There is just so much to learn. And being at the cutting edge of all this things change faster than you can keep up. I’ve basically just decided to skip every other major model because it’s just too much. \n\nFind 1 thing you wana do and study that one thing.",
                  "score": 2,
                  "created_utc": "2026-02-27 17:05:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7q507p",
          "author": "Corgiboom2",
          "text": "I use Regional Prompter with hires.fix, then go into Img2Img for upscale and denoise, then inpaint where needed.",
          "score": 2,
          "created_utc": "2026-02-27 16:35:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qnzvq",
              "author": "goku58s",
              "text": "Yeah, that is the part where I have given up on like 2 workflows, because if I make over 500 images per day, then going through each is just not doable",
              "score": 1,
              "created_utc": "2026-02-27 18:04:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7qzriu",
                  "author": "Corgiboom2",
                  "text": "https://preview.redd.it/u7g66k3843mg1.png?width=1496&format=png&auto=webp&s=adb2b120519bda02a3221f107fccdeb35fb761fe\n\nYou gotta find the few pics you like the most and want to present, and then give those your attention. It is a method I've had quite a bit of success with.",
                  "score": 2,
                  "created_utc": "2026-02-27 19:00:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7qjm2m",
          "author": "featherless_fiend",
          "text": "Using a more intelligent/slower sampler like res_2s and the right amount of steps helps a little.\n\nBasically if two characters have the same face it's an intelligence problem, like having an extra arm or leg. So it does help to cook it a little more.",
          "score": 2,
          "created_utc": "2026-02-27 17:44:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7qpywt",
          "author": "Direct_Effort_4892",
          "text": "Can give [FreeFuse](https://github.com/yaoliliu/FreeFuse) a shot; you'll require each of your characters to have a LoRa though. Can't vouch for its success as haven't tried it myself, but worth a shot nonetheless.",
          "score": 2,
          "created_utc": "2026-02-27 18:14:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qqdwr",
              "author": "goku58s",
              "text": "I will have to see if there are any workflows with this. It looks good on git.\nMaybe if you know of any, I would be grateful. Thanks for this too ",
              "score": 2,
              "created_utc": "2026-02-27 18:16:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7qqxm8",
                  "author": "Direct_Effort_4892",
                  "text": "They do seem to have demo comfy workflows in their [repo](https://github.com/yaoliliu/FreeFuse/tree/master/freefuse_comfyui/workflows)\n\nEdit: This link links directly to their workflow directory BTW",
                  "score": 2,
                  "created_utc": "2026-02-27 18:18:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7wkccm",
          "author": "krigeta1",
          "text": "This could stop lora bleeding and make lora specific to a region and combining it with controlnet do wonders and then you can refine not too much hassle.\n\nhttps://blog.comfy.org/p/masking-and-scheduling-lora-and-model-weights",
          "score": 2,
          "created_utc": "2026-02-28 16:46:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7pvtqs",
          "author": "woffle39",
          "text": "[https://www.youtube.com/watch?v=Ly6USRwTHe0](https://www.youtube.com/watch?v=Ly6USRwTHe0)",
          "score": 1,
          "created_utc": "2026-02-27 15:51:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7q60h9",
          "author": "seniorfrito",
          "text": "This is something I've thought about on and off since the beginning of Stable Diffusion. But, couldn't you just create LoRA that can handle both of the characters (or more)? Just be very specific about which side of the image each character is on. Essentially create your own dataset initially with inpaint, and have your characters in all sorts of different arrangements and then come out with a LoRA that can just do it without the inpainting?",
          "score": 1,
          "created_utc": "2026-02-27 16:39:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qolok",
              "author": "goku58s",
              "text": "I have tried multiple Loras for that, but none really worked beside one (that one was also relying a lot on luck) and also when you have to include over 100s of characters... making Lora for all of that is... well... you know already ",
              "score": 1,
              "created_utc": "2026-02-27 18:07:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7qc3gg",
          "author": "diogovk",
          "text": "In Krita + AI plugin, you can assign prompts that apply to different parts of the image (i.e. prompts associated with image layers).\n\nAnd after upscaling, you can do generations of only part of the image. \n\nIf you're generating part of the image that only includes one character, I still think it's best to *remove* the prompts related to other characters. My experience it's not so much that other regional prompts \"leak\", but that it still affects generation quality.\n\nWithout using those regional prompts, prompts \"leak\" like crazy, so I think it's definitely worth a try.",
          "score": 1,
          "created_utc": "2026-02-27 17:08:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qou3z",
              "author": "goku58s",
              "text": "For me the issue is that I have to make over 500 images per day, so having to upscale each manually is a big pain...",
              "score": 2,
              "created_utc": "2026-02-27 18:08:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7qtbgy",
                  "author": "osirixart",
                  "text": "Why do you have to make so many images and upscale each one? You should just upscale the ones that you know you're going to use/keep.",
                  "score": 2,
                  "created_utc": "2026-02-27 18:29:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7qx7ng",
                  "author": "diogovk",
                  "text": "You could still use Krita, save all images in a directory and then batch-upscale using ComfyUI or a script.\n\nBut the whole point of Krita is that you're trading time for quality/control.\n\nIt's gonna be difficult to make a workflow that generates 500 non-slop images.",
                  "score": 1,
                  "created_utc": "2026-02-27 18:48:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7qene4",
          "author": "Gemaye",
          "text": "You can cheat by creating each character you want with an even coloured (black) background, then create the background you prefer for your final image, then merge the three characters into one image using a graphics editor and then add the created background using qwen image edit or the same graphics editor.  \nFrom then use the edit model to change poses.\n\nEdit: You could use [paint.net](http://paint.net) for merging the images, that is what I use at least.",
          "score": 1,
          "created_utc": "2026-02-27 17:20:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qp276",
              "author": "goku58s",
              "text": "That is the issue for me because I have to make over 500 images per day, feom which like 380 are good, so it's massive pain to do...",
              "score": 0,
              "created_utc": "2026-02-27 18:09:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7u3f2z",
                  "author": "Gemaye",
                  "text": "Alright, I did not get that from your description.\n\nThen everything needs to be done in a workflow I guess.\n\nCheck those workflows for influencer creation, these workflows grab a character from an image, monetize the background, change the image size and create like a dozen or so images of the character in different poses.  \nThese are not the fastest workflows as they also do a lot of upscaling but you might not need that for your images.\n\nFrom there I guess its a simple inpainting job to get two or three images with monetized background into one image and add a background.  \nThis part is theoretical for me though.\n\nSomething else that occurs to me is that you could use an vlm to describe an image with three characters and use that description for your prompt.  \nThe detail of those prompts far surpass at least what I can come up with for a prompt and might give your better looking characters.",
                  "score": 1,
                  "created_utc": "2026-02-28 05:53:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7qoixw",
          "author": "Maskwi2",
          "text": "Yeah, this has been the major pain for me. I don't know how models like Seedance do it so that they have 2 characters interact with each other like Brad Pitt and Tom Cruise fighting and not have one's face affect the other. ",
          "score": 1,
          "created_utc": "2026-02-27 18:07:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qp8t2",
              "author": "goku58s",
              "text": "If only I knew.... ",
              "score": 1,
              "created_utc": "2026-02-27 18:10:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7r2z47",
          "author": "Caesar_Blanchard",
          "text": "I know it's unrelated but is she from some anime? or she's a character you created?",
          "score": 1,
          "created_utc": "2026-02-27 19:15:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7r3fdg",
              "author": "goku58s",
              "text": "Kohaku from dr stone anime",
              "score": 2,
              "created_utc": "2026-02-27 19:17:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7r4kzs",
          "author": "HashTagSendNudes",
          "text": "Use InvokeAi Regional guidance easy work",
          "score": 1,
          "created_utc": "2026-02-27 19:23:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7r4q5n",
              "author": "goku58s",
              "text": "If you can tell me, what is InvokeAI? I haven't tried it",
              "score": 1,
              "created_utc": "2026-02-27 19:24:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7rarc0",
          "author": "Madlyaza",
          "text": "I would personally just generate them separately completely and then just edit in a photo editing program and cut one into the others. Then use inpaint to work out some rough edges",
          "score": 1,
          "created_utc": "2026-02-27 19:54:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7rf1x5",
          "author": "TekeshiX",
          "text": "Just use the A1111 with the regional prompting extension, the best!",
          "score": 1,
          "created_utc": "2026-02-27 20:15:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7rfkw8",
              "author": "goku58s",
              "text": "I am actually thinking of returning to that one to try it",
              "score": 1,
              "created_utc": "2026-02-27 20:18:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7rftji",
                  "author": "TekeshiX",
                  "text": "Yea, do that. Also inpainting is better sometimes too.",
                  "score": 1,
                  "created_utc": "2026-02-27 20:19:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7rst9x",
          "author": "Goldkoron",
          "text": "You can reliably do 2 characters with no leakage, and sometimes 3 if you have a lot of multi-character images in your training dataset that are consistently captioned eg \"Kohaku and Senku in forest\"\n\nUntrained models are a bit harder to deal with though.",
          "score": 1,
          "created_utc": "2026-02-27 21:24:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7s0183",
              "author": "goku58s",
              "text": "Well, I Don't have all the multi character models for over 200 characters... and more... so yeah, I can't rely on those types of loras",
              "score": 1,
              "created_utc": "2026-02-27 22:01:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7rvbvl",
          "author": "KadahCoba",
          "text": "Use regional prompting.\n\nThere are multiple custom nodes for this, the ones I've run use masks and work in the magical realm of the fuckery that ComfyUI conditionals datatype. ComfyUI core has something similar that also support regional lora application and even more fuckery with conds, but it also increases the timestep (ie. slower gen, by 1.5-2x).\n\nBasics workflow with the ones I've used: Base prompt is for the overall image minus the specifics that will apply only within the regions, like background, overall scene, style, maybe details that apply to all regions within the context of being in the same composition (eg. pose). The masked regions will have additional prompts that essentially layer over the base prompt for that region.  As for where to put the masks, I would either gen most of the combined whole prompt to find a seed with composition I wanted to use, then used that as the input for making the masks, or do a more img2img inputs to the first stage, possibly with control nets.\n\nIt'll work for one-shot gens without having to go full effort inpainting from the start, but a good inpainting on the output of that is still likely going to provide a more preferable result.",
          "score": 1,
          "created_utc": "2026-02-27 21:37:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7s0aoe",
              "author": "goku58s",
              "text": "Do you maybe have the link or something that can show me what it looks like? I have tried regional prompting before, but nothing got this level of quality like on image above.",
              "score": 1,
              "created_utc": "2026-02-27 22:02:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7sj21k",
                  "author": "KadahCoba",
                  "text": "Which did you try?\n\nI'm not in a place right this moment where I can check my old workflows, but I think I was using [A8R8](https://github.com/ramyma/A8R8_ComfyUI_nodes) or some fork of it.\n\nCan you pastebin the workflow for the op image so I can test around with it if I have this weekend?",
                  "score": 1,
                  "created_utc": "2026-02-27 23:46:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7rwhyr",
          "author": "FluidEngine369",
          "text": "I believe if you use the PNG tab drag the image in there and then send all the info and most importantly the original seed into txt2img, you can easily swap out the characters in the prompt and generally keep the same pose and style. But if you change too many of the original parameters like overall image size, the sampler, CFG, then the end result will start to vary.",
          "score": 1,
          "created_utc": "2026-02-27 21:43:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7rxnj4",
          "author": "Sudden_List_2693",
          "text": "Generate image, send to inpaint, loop through all characters, crop them one by one possibly upscaled for the inpaint, automatically tag (if they need lora, it's best in my opinion to trigger the separate lora for each character), let the inpaint do its job on each character separately. ",
          "score": 1,
          "created_utc": "2026-02-27 21:49:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7s0hrx",
              "author": "goku58s",
              "text": "Well unless inpaint is automatic... this is quite much of a labour because I am making over 200-500 images per day....\nFrom which like 380 are what I am using....",
              "score": 1,
              "created_utc": "2026-02-27 22:03:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7sfsax",
                  "author": "Sudden_List_2693",
                  "text": "I meant totally automatic.  \nI can't even imagine inpainting manually unless I'm making something very specific - a very rare case.",
                  "score": 2,
                  "created_utc": "2026-02-27 23:26:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7s8wv4",
          "author": "Expicot",
          "text": "Just wondering... what about using a more 'modern' AI that has stronger prompt adherence. Klein4B for fast iterations by ex. Then finish the image with a img2img with your Illustrious model ? It will take more time for sure but there would be less waste (?).",
          "score": 1,
          "created_utc": "2026-02-27 22:48:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7s94kp",
              "author": "goku58s",
              "text": "Well simple answer is when you make a lot of images in one day, img2img for every and each one is pain... (over 200 images per day...]",
              "score": 1,
              "created_utc": "2026-02-27 22:49:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7sqcjf",
          "author": "Velvet-Vision",
          "text": "The easiest way that i know, u should build simple comfyui workflow with auto detector characters, and do auto inpaint with 0.6-0.9 denoise. And after one more Ksampler to remove artifacts.\nSo u generate just a 2+ persons, with masks inpaint it to characters that u need, and fix light artifacts, and u get good quality images with multichar",
          "score": 1,
          "created_utc": "2026-02-28 00:28:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7u91ub",
              "author": "goku58s",
              "text": "Is this doable if they have to hug, fight, or interact with each other?\n\n",
              "score": 1,
              "created_utc": "2026-02-28 06:42:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7uk1nj",
                  "author": "Velvet-Vision",
                  "text": "I think yea, bcs much easier for SD draw a random girls or boys, and after u generated scene, u just change random persons to ur characters.\n\nAnd u can try some loras with multi char, but i think variant above better",
                  "score": 1,
                  "created_utc": "2026-02-28 08:21:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7st79v",
          "author": "vamprobozombie",
          "text": "I prefer making each one then use QWEN edit to put them all on one image.  I run it with Wan2gp works even with 8GB vram if have enough ram.",
          "score": 1,
          "created_utc": "2026-02-28 00:45:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7u95iq",
              "author": "goku58s",
              "text": "For me Vram is not issue because I have 16 and 32 of normal ram. (should have bought 64...)",
              "score": 1,
              "created_utc": "2026-02-28 06:43:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7t4mz2",
          "author": "tO_ott",
          "text": "Op, when you say illustrio do you mean illustrious?",
          "score": 1,
          "created_utc": "2026-02-28 01:55:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7u96ue",
              "author": "goku58s",
              "text": "Yes. Bad spelling. Sorry about that",
              "score": 2,
              "created_utc": "2026-02-28 06:43:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7taexa",
          "author": "coscib",
          "text": "regional prompt and inpainting",
          "score": 1,
          "created_utc": "2026-02-28 02:31:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7u9ff0",
              "author": "goku58s",
              "text": "Tried couple of regional prompt workflows, only 2 I think worked, but didn't give me quality that I need",
              "score": 1,
              "created_utc": "2026-02-28 06:45:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7tl4ha",
          "author": "killphp",
          "text": "I was able to do that with z-image turbo AIO, with 2 character loras, trained by myself, with the loras sharing a total weight of 1, and clearly specifying which character is which in the image. Up to 3 characters worked fairly consistently.",
          "score": 1,
          "created_utc": "2026-02-28 03:39:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7u9i9r",
              "author": "goku58s",
              "text": "Does z image turbo support iLL based models?",
              "score": 1,
              "created_utc": "2026-02-28 06:46:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7vsff8",
                  "author": "killphp",
                  "text": "nope, but depending on the character, you dont even need a lora, perhaps the same is true for anima. But I can't say for sure, since I never used anima.",
                  "score": 1,
                  "created_utc": "2026-02-28 14:20:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7tq0b3",
          "author": "kidian_tecun",
          "text": "1) you need to draw a sigil or diagram on your floor\n2) place your pc and monitor in the middle\n3)place the candles at the approlriate locations. (And near curtian or other flamable material)\n4)turn the pc\n5)recite the incantation. you'll know when its working because your GPU will start sounding like a boeing 747 struggling to take off because its past it max capacity.\n6) you'll feel some heat and the lights will flicker and your summoned demon will appear.\n7) have that mofo do it because it eithee he does it or youre going to have to use img2img and inpaint.",
          "score": 1,
          "created_utc": "2026-02-28 04:13:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7u9mgb",
              "author": "goku58s",
              "text": "Comment of the year :) I feel like even that demon will tell me \"No, good luck buddy\"",
              "score": 1,
              "created_utc": "2026-02-28 06:47:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7v5ilk",
          "author": "Jealous_Piece_1703",
          "text": "Use comfyui lora hook. Just search about it there is an article on Comfyui website",
          "score": 1,
          "created_utc": "2026-02-28 11:43:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7v5m1b",
              "author": "goku58s",
              "text": "Hm... Okay, I will try to find it. Thank you",
              "score": 1,
              "created_utc": "2026-02-28 11:44:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7v5s2z",
                  "author": "Jealous_Piece_1703",
                  "text": "This [one](https://blog.comfy.org/p/masking-and-scheduling-lora-and-model-weights)\n\nLemme tell you it is by far the best one, only struggle when there is overlap, but easily fixable with manual work and upscale.",
                  "score": 3,
                  "created_utc": "2026-02-28 11:45:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7vdpwy",
          "author": "AfterschoolSine",
          "text": "How did you get such a great quality? So much detail? This looks like a proper anime. Mine look like drawings",
          "score": 1,
          "created_utc": "2026-02-28 12:48:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7x2puf",
              "author": "goku58s",
              "text": "That's what I am talking about, I need workflow that can pull this off, but with 2 or 3 characters. Also if I knew myself how this worked out, I would explain it... sorry... :'(",
              "score": 1,
              "created_utc": "2026-02-28 18:18:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7wkf0i",
          "author": "Threatening-Sack369",
          "text": "Try regional prompt",
          "score": 1,
          "created_utc": "2026-02-28 16:46:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7xo444",
          "author": "tacothedeeper",
          "text": "1) download Gimp (open source image editor)\n2) generate image of character 1\n3) generate image of character 2\n4) open both in gimp. Outline character 2. Control + C, Control + V on image of character 1.\n5) export image, put it in comyui or whatever, img2img. Inpaint slightly to smooth any weirdness.",
          "score": 1,
          "created_utc": "2026-02-28 20:07:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7z3m9q",
          "author": "MaximuzX-",
          "text": "Can I ask which checkpoint you used for this image?",
          "score": 1,
          "created_utc": "2026-03-01 00:55:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o80avp8",
          "author": "Cultural-Broccoli-41",
          "text": "1. Export two detailed character images separately in SDXL (plus one background image, if desired).\n\n\n2. Arrange them as desired using Qwen-Image-EDIT or Flux.2-Klein (you'll need to act as the director and provide natural language prompts).",
          "score": 1,
          "created_utc": "2026-03-01 05:41:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7un1li",
          "author": "OkayTheCamelisCrying",
          "text": "A pony model can help.",
          "score": 0,
          "created_utc": "2026-02-28 08:48:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7uusvv",
              "author": "goku58s",
              "text": "I was thinking about that, but I don't think pony models can match what iLL does now. But iLL is really heavy on tags unlike pony...",
              "score": 1,
              "created_utc": "2026-02-28 10:04:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7q9ygl",
          "author": "Zack_spiral",
          "text": "In my opinion the best and easiest way is to use a high end image editing model like nano banana or qwen image edit but don't forget the rtx to buy",
          "score": -3,
          "created_utc": "2026-02-27 16:58:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qa6jw",
              "author": "goku58s",
              "text": "When you say rtx to buy, do you Gpu or something else? Because I have 5070ti, so I guess that's not the issue",
              "score": 1,
              "created_utc": "2026-02-27 16:59:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7qck81",
                  "author": "Zack_spiral",
                  "text": "If you say so the best model for you to download I recommend qwen image edit 2511 Q5 good enough for you with maximum image uploading of 3 character if you make it 4k it will be better there is also 2512 but it's larger and requires rtx 5090",
                  "score": 1,
                  "created_utc": "2026-02-27 17:10:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rfvx7c",
      "title": "WAN 2.2's 4X frame interpolation capability surpasses that of commercial closed-source software.",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/z4tiu9waiylg1",
      "author": "Some_Smile5927",
      "created_utc": "2026-02-27 03:42:03",
      "score": 266,
      "num_comments": 43,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rfvx7c/wan_22s_4x_frame_interpolation_capability/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7n3aji",
          "author": "Shifty_13",
          "text": "Workflow for WAN interpolation???",
          "score": 31,
          "created_utc": "2026-02-27 03:47:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nsilz",
              "author": "nsfwVariant",
              "text": "OP linked it in another comment: [https://huggingface.co/hyutsa/some\\_useful\\_workflows/resolve/main/wan22\\_4frames\\_interp.json](https://huggingface.co/hyutsa/some_useful_workflows/resolve/main/wan22_4frames_interp.json)",
              "score": 26,
              "created_utc": "2026-02-27 06:52:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7oeo8j",
                  "author": "FoxTrotte",
                  "text": "From what I can see this worflow doesn't allow for full video interpolation, only four frames",
                  "score": 3,
                  "created_utc": "2026-02-27 10:16:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7n3rkn",
          "author": "teekay_1994",
          "text": "You could have used a video with more movement...\n\nBut still, will have to try this. So far RIFE has been working pretty nicely for me.",
          "score": 23,
          "created_utc": "2026-02-27 03:50:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7n5y4p",
              "author": "AwesomeAkash47",
              "text": "And Rife is going to be fast as well, making it more practical",
              "score": 9,
              "created_utc": "2026-02-27 04:04:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7n6h56",
                  "author": "teekay_1994",
                  "text": "Yeah it's very fast actually. Nice to have a second alternative either way.",
                  "score": 5,
                  "created_utc": "2026-02-27 04:07:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7p9qc4",
                  "author": "Nevaditew",
                  "text": ">",
                  "score": 1,
                  "created_utc": "2026-02-27 13:59:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7n94e1",
              "author": "Some_Smile5927",
              "text": "RIFE is really good; I use it frequently. However, it does have frame repetition and artifacts above 3x.",
              "score": 4,
              "created_utc": "2026-02-27 04:25:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7noxxt",
                  "author": "teekay_1994",
                  "text": "I usually take 16fps videos from wan, convert them to 30fps and then I run them through a second RIFE pass for 60fps. So far I have had no issues.",
                  "score": 4,
                  "created_utc": "2026-02-27 06:22:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7nprl5",
                  "author": "Stepfunction",
                  "text": "Doing repeated 2x passes has always given me the best results.",
                  "score": 3,
                  "created_utc": "2026-02-27 06:29:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7r883j",
                  "author": "foxdit",
                  "text": "I've been a RIFE hater since early days. For me, it's Film VFI all day every day. No jerky/janky issues.",
                  "score": 2,
                  "created_utc": "2026-02-27 19:41:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7narjl",
          "author": "Stepfunction",
          "text": "I mean it may be marginally better than RIFE, but RIFE is blazingly fast, low in resource requirements, and also not closed-source or commercial.",
          "score": 21,
          "created_utc": "2026-02-27 04:36:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nbcca",
              "author": "Some_Smile5927",
              "text": "U are right ！",
              "score": 1,
              "created_utc": "2026-02-27 04:40:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ni1zh",
          "author": "mobani",
          "text": "Seems WAN changed the eyes to focus on the viewer. They are looking beyond the camera on the other examples, because WAN is not interpolating, it's creating basically. (but that can be good if you want that).",
          "score": 6,
          "created_utc": "2026-02-27 05:28:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7p9nai",
              "author": "Cequejedisestvrai",
              "text": "not only that, it’s created 4 new white balls under her arm",
              "score": 3,
              "created_utc": "2026-02-27 13:58:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7pfij1",
                  "author": "necile",
                  "text": "those are pearls 😂 you're totally right tho, didn't even notice",
                  "score": 2,
                  "created_utc": "2026-02-27 14:30:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7qru3b",
              "author": "_half_real_",
              "text": "Wan with VACE isn't supposed to do that, it _should_ keep the original frames unchanged if the masks are correct. I use VACE a lot so I'll need to look into this.",
              "score": 1,
              "created_utc": "2026-02-27 18:22:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7qwnf2",
                  "author": "mobani",
                  "text": "The problem is not the start and end frame, it's the generated frames between. Anything is up for change when you use diffusion to make the next frame. ",
                  "score": 1,
                  "created_utc": "2026-02-27 18:45:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7o38lt",
          "author": "krautnelson",
          "text": "the problem is that WAN doesn't just interpolate. it actually changes the video.\n\nlook at the eyes of the model.",
          "score": 6,
          "created_utc": "2026-02-27 08:27:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7o5my1",
              "author": "Some_Smile5927",
              "text": "This is likely related to the prompt. I should have emphasized slow motion, otherwise the blinking issue would occur. It's not the slow-motion model's inference that causes it to blink, but rather the duration of the time.",
              "score": 1,
              "created_utc": "2026-02-27 08:50:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7nelt1",
          "author": "Boysen_berry42",
          "text": "Nice comparison. I like that you showed the hair strands and the fan, that made it easier to see the differences. RIFE is still hard to beat for speed, but the artifacts above 3x are real. WAN 2.2 handling longer clips without the 8-frame limit is interesting though. Thanks for sharing",
          "score": 3,
          "created_utc": "2026-02-27 05:02:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nnt72",
              "author": "Life_Yesterday_5529",
              "text": "You could do 2000 frames with Wan if it only has to fill the blank frames between existing frames via Vace.",
              "score": 1,
              "created_utc": "2026-02-27 06:13:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7n33gq",
          "author": "Some_Smile5927",
          "text": "Wan Vace's frame interpolation effect is also good, but it's limited to 8 frames , and there will be color deviation.",
          "score": 3,
          "created_utc": "2026-02-27 03:46:13",
          "is_submitter": true,
          "replies": [
            {
              "id": "o7n4zjx",
              "author": "nsfwVariant",
              "text": "Is this not also using VACE?",
              "score": 1,
              "created_utc": "2026-02-27 03:58:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7n9bg1",
                  "author": "Some_Smile5927",
                  "text": "Not yet. This I use WAN 2.2 i2v + context, so it can deal any long time video.",
                  "score": 0,
                  "created_utc": "2026-02-27 04:26:41",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7nj0uu",
          "author": "acamas",
          "text": "Would this be true for animation too or just realism?",
          "score": 1,
          "created_utc": "2026-02-27 05:35:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7opgsx",
          "author": "polawiaczperel",
          "text": "I was really curious how WAN would work with JAV decensoring and thought that it kinda obvious to use it in this case, but nobody was trying?",
          "score": 1,
          "created_utc": "2026-02-27 11:49:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7t5exi",
              "author": "Some_Smile5927",
              "text": "I've tried it in my previous post, and with the current technology, I'm confident it will be more realistic and stable, especially for JAV.",
              "score": 2,
              "created_utc": "2026-02-28 02:00:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7otz2o",
          "author": "Grindora",
          "text": "Wait what! Never heard of RIFE, how do i use it on windows?",
          "score": 1,
          "created_utc": "2026-02-27 12:22:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qtmbi",
              "author": "Conscious_Arrival635",
              "text": "\\+1 for linux",
              "score": 0,
              "created_utc": "2026-02-27 18:31:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7qtj3s",
          "author": "sandshrew69",
          "text": "Waiting until someone runs all of naruto through that. I remember there was a frame interpolator for anime but it kinda sucked.",
          "score": 1,
          "created_utc": "2026-02-27 18:30:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7sux5a",
          "author": "jowala1",
          "text": "How about including the run time as well? Quality is less of a factor if it takes 10x longer to achieve it.",
          "score": 1,
          "created_utc": "2026-02-28 00:55:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7t6buc",
          "author": "Dead_Internet_Theory",
          "text": "whatever happened to FILM?  \n[https://film-net.github.io/](https://film-net.github.io/)  \nit's old but so is RIFE and back then I thought \"FILM is too slow and memory hungry\" but it's gotta be much less tough to run than Wan2.2.",
          "score": 1,
          "created_utc": "2026-02-28 02:06:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7tbg4l",
              "author": "Some_Smile5927",
              "text": "RIFE is better.",
              "score": 1,
              "created_utc": "2026-02-28 02:38:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7p1kze",
          "author": "Ok_Cauliflower_6926",
          "text": "Some of the results are a waste of time, you can use FSR Frame Gen with Lossles Scaling.",
          "score": 1,
          "created_utc": "2026-02-27 13:12:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qh7f3",
              "author": "raysar",
              "text": "Visual quality is NOT AT ALL the same as RIFE. Do the test, FSR is crap. (it's usable but not at all the same quality.)",
              "score": 1,
              "created_utc": "2026-02-27 17:32:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7nl6f5",
          "author": "hidden2u",
          "text": "I just came here to say I can’t believe how fast FL RIFE has gotten, 81 frames x3 in about 2 seconds",
          "score": 0,
          "created_utc": "2026-02-27 05:52:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7qy3kz",
          "author": "Technical_Ad_440",
          "text": "i feel like wan has become really fractured with how you need to set it up. we really need some opensource video suite that has the image editing upscaling and such all in 1. i was working with opensource but google flow just kills it. like we really need accessible 96gb cards cause quantizing models making them understand less but be able to run at lower quality really isn't it. its useless being able to run models but quality nosedives and jumping through 20hoops to get full veo3 or seadance quality isnt it. opensource is for sure massively fractured",
          "score": 0,
          "created_utc": "2026-02-27 18:52:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rf7d1d",
      "title": "🎬 Big Update for Yedp Action Director: Multi-characters setup+camera animation to render Pose, Depth, Normal, and Canny batches from FBX/GLB/BHV animations files (Mixamo)",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/d0157859ntlg1",
      "author": "shamomylle",
      "created_utc": "2026-02-26 11:08:06",
      "score": 258,
      "num_comments": 36,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rf7d1d/big_update_for_yedp_action_director/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7hwg17",
          "author": "Candid-Station-1235",
          "text": "![gif](giphy|D3RDJy8gFPDnv8J6OQ)\n\n",
          "score": 13,
          "created_utc": "2026-02-26 11:26:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hx43q",
          "author": "Hearcharted",
          "text": "![gif](giphy|xT8qAY7e9If38xkrIY)\n\nAmazing!",
          "score": 4,
          "created_utc": "2026-02-26 11:31:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7idu09",
          "author": "devilish-lavanya",
          "text": "I can feel it in my bones, new era of AI VFX is coming….I slowly passed away",
          "score": 5,
          "created_utc": "2026-02-26 13:26:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7iio2o",
              "author": "shamomylle",
              "text": "Don't worry, I didn't create anything new, I'm simply trying to bring the 3D pipeline everyone was already using in blender or any other 3D software, into ComfyUI in an intuitive way!\nYour bones are still fine :)",
              "score": 8,
              "created_utc": "2026-02-26 13:53:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7i4pey",
          "author": "nutrunner365",
          "text": "Any workflows?",
          "score": 3,
          "created_utc": "2026-02-26 12:28:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7i55e9",
              "author": "shamomylle",
              "text": "My bad, this is the one I used for my demo, it's very basic sorry, I'm still new to comfyUI :)\n\n[workflow](https://drive.google.com/file/d/1EBxUSrMS5WXK1iZYY0xLAcs-mpMc_V1a/view?usp=drive_link)",
              "score": 3,
              "created_utc": "2026-02-26 12:31:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7idy93",
                  "author": "devilish-lavanya",
                  "text": "I don’t believe you are new to comfyui",
                  "score": 1,
                  "created_utc": "2026-02-26 13:27:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7voxid",
          "author": "Born_Word854",
          "text": "First of all, thank you for this amazing node and the massive update! It is incredibly helpful.\n\nI am currently using your node as the core of my 2D character sprite generation pipeline for game development. My specific workflow involves loading animations, baking Normal map batches (since Normal maps provide much better volume and rotational tracking than OpenPose), and feeding them directly into AnimateDiff to generate fluid, frame-by-frame 2D animation sprites.\n\nWhile this workflow is incredibly powerful, AnimateDiff is highly sensitive to input consistency. Because the camera can currently only be controlled via mouse, it is extremely difficult to maintain the exact same camera angle across different animation sequences (e.g., switching from an \"Idle\" animation to an \"Attack\" animation). Even a slight shift in the manual mouse angle causes perspective inconsistencies in the final AnimateDiff output, making it hard to compile a unified sprite sheet.\n\nWould it be possible to consider adding the following features in a future update to make this the ultimate tool for 2D sprite generation workflows?\n\n* Numerical Inputs for Camera: The ability to set the exact Position (X, Y, Z) and Rotation/Angle of the camera via number fields. This would guarantee perfect front, side, or isometric views across multiple animation files without relying on manual mouse adjustments.\n* Orthographic Camera Mode: A toggle to switch the camera from Perspective to Orthographic projection. This is essential for rendering 2D game sprites without perspective distortion.\n* Focal Length / FOV Adjustment: The ability to adjust the camera's focal length for perspective shots.\n* Preset System: A feature to save the current camera and scene setup as a custom preset. Having a few built-in default presets for 2D sprites (like \"Perfect Front\" or \"Isometric\") would be a massive game-changer for AnimateDiff users.",
          "score": 3,
          "created_utc": "2026-02-28 14:00:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7vs722",
              "author": "shamomylle",
              "text": "First of all, thank you so much for sharing your workflow! Using this node for 2D sprite generation with Normal maps and AnimateDiff is brilliant!\n\nYou bring up some very good points! An Orthographic camera toggle, FOV sliders, and strict numerical X/Y/Z camera inputs make complete sense for creating consistent isometric or flat 2D sprite angles and sounds like a very natural evolution for the tool!\n\nThanks for the great ideas, I will definitely work on these in the near future, I will let you know when I make that update! \n\nThanks again for the amazing feedback!",
              "score": 3,
              "created_utc": "2026-02-28 14:19:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7vt48r",
                  "author": "Born_Word854",
                  "text": "Thank you so much for the quick and positive reply! I'm thrilled to hear that you liked the 2D sprite workflow idea.\n\nYour node is already a game-changer for my pipeline, and those camera features will make it absolutely perfect.  \nI'll be eagerly looking forward to the update!",
                  "score": 1,
                  "created_utc": "2026-02-28 14:24:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7iac6h",
          "author": "Brilliant-Station500",
          "text": "Holy shit! This is so fkin good !",
          "score": 2,
          "created_utc": "2026-02-26 13:05:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ioj0h",
              "author": "shamomylle",
              "text": "Thanks for the kind words :)",
              "score": 1,
              "created_utc": "2026-02-26 14:24:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o81kbwd",
          "author": "Born_Word854",
          "text": "Hello again. Thank you for your amazing work on the Yedp Action Director.\n\nActually, I felt a bit guilty just asking for things without contributing. So, I went ahead and created a mockup extension myself as a Proof of Concept. My goal was to build a practical foundation for 2D sprite generation based on your awesome node. I'm sharing it here in hopes that it might be helpful for your development.\n\n(I apologize for reaching out again so soon after submitting those feature requests the other day. I really hope posting something like this isn't considered bad manners...)\n\nRepository:[https://github.com/mizumori-bit/ComfyUI-Yedp-ActionDirector-Extensions](https://github.com/mizumori-bit/ComfyUI-Yedp-ActionDirector-Extensions)\n\nAdded Features in this Mockup:\n\n* FEAT-01: Camera Numeric Control + Orthographic\n   * Perspective / Orthographic toggle with instant camera switching.\n   * Focal Length (mm) to FOV conversion for Perspective mode.\n   * Ortho Scale for Orthographic mode (ideal for 2D sprite generation).\n   * Position XYZ and Target XYZ numeric inputs with bidirectional OrbitControls sync.\n   * All values update in real-time as you orbit the camera.\n* FEAT-02: Camera Presets\n   * 7 Built-in Presets: Front, Front 45°, Side, Top-Down, 3/4 RPG, Front Ortho, Side Ortho.\n   * Save/Load/Delete custom presets stored as JSON in ComfyUI/input/yedp\\_camera\\_presets/.\n   * Presets persist across ComfyUI restarts.\n* FEAT-03: Lighting Control\n   * DirectionalLight: Direction XYZ + Intensity.\n   * AmbientLight: Intensity control.\n   * HemisphereLight: Intensity control (sky/ground colors).\n   * Defaults tuned for Normal map generation (dir=1.2, amb=0.4, hemi=0.3).\n* FEAT-04: Native Bone Retargeting (JSON Maps) \n   * Select a retarget map directly from the Action Director UI dropdown.\n   * Maps are automatically loaded from ComfyUI-Yedp-ActionDirector-Extensions/retarget\\_maps/.\n   * ⚠️ Important Limitation: This retargeting feature performs *simple string replacement of bone names* (e.g., renaming chest\\_fk to Spine1). It does *not* perform IK recalculations, roll angle correction, or rest pose (T-Pose vs A-Pose) alignment.\n   * 💡 Best Practice: For pristine animation results, we strongly recommend using FBX/GLB files exported with a Mixamo-based bone structure and standard T-Pose. The built-in semantic normalizer will automatically map Mixamo bones correctly without needing a JSON file. If using non-Mixamo rigs (like Rigify), you will likely experience mangled skeletons due to differing axis orientations and rest poses.\n* FEAT-05: 5th \"Shaded\" Render Pass\n   * Adds a shaded output pin to the node alongside Pose, Depth, Canny, and Normal passes.\n   * Renders the model using its original materials combined with the custom lighting setup (FEAT-03), perfect for ControlNet (e.g., recolor) or direct composite reference.\n* FEAT-06: Direct Numeric Gizmo Manipulation\n   * Adds a direct \"Gizmo Tools\" UI allowing users to move, rotate, and scale characters precisely.\n   * Includes numerical input fields for Pos XYZ and Rot Y on the character card, which instantly sync with the 3D viewport.\n* FEAT-07: Payload Memory Caching (Anti-Crash)\n   * Replaces standard ComfyUI frontend-to-backend base64 string passing with a robust Python-side dictionary cache (YEDP\\_PAYLOAD\\_CACHE).\n   * Prevents the browser from freezing or ComfyUI from crashing when baking long animations that generate hundreds of megabytes of image data.\n* FEAT-08: Lossless PNG Output\n   * Upgrades all render passes from lossy JPEG compression to pristine, lossless PNG format directly in the Three.js extraction loop.\n   * Significantly improves the accuracy and edge-quality of Depth, Canny, and Normal maps fed into ControlNet.\n\nBy integrating these features, I believe Yedp could practically function as an \"animation-supported version of VNCCS,\" which would be incredibly powerful.\n\nJust a quick disclaimer: Please keep in mind that this is purely a mockup intended to assist with your development. I'm not completely confident in its overall stability, so please don't expect it to work perfectly or flawlessly.\n\nPlease feel completely free to use, copy, modify, or even ignore any part of this code for your official updates. My main goal was just to provide a working PoC to make integrating these ideas a bit easier for you.\n\nGood luck with your continued development! I am totally rooting for you.\n\nThanks again for your time and the fantastic node!",
          "score": 2,
          "created_utc": "2026-03-01 12:35:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o81w8lp",
              "author": "shamomylle",
              "text": "Hello! Please don't feel guilty at all! \nI am so incredibly grateful that you took the time to build this Proof of Concept! You've done a colossal work and have given me a solid foundation, I didn't have time to check it yet but I'll take a closer look at this and try to integrate it properly in the next version thanks!",
              "score": 1,
              "created_utc": "2026-03-01 13:55:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7hxhe8",
          "author": "GarudoGAI",
          "text": "This looks amazing, gonna give this a try",
          "score": 1,
          "created_utc": "2026-02-26 11:35:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7iij9u",
          "author": "devilish-lavanya",
          "text": "How to load mesh model? Can you support xnalara xps models?",
          "score": 1,
          "created_utc": "2026-02-26 13:52:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ilmjg",
              "author": "shamomylle",
              "text": "Hi! This node isn't a general 3D model importer. It actually uses a specifically engineered, built-in base rig (Yedp_Rig.glb) that contains a precise 56-color OpenPose skeleton and male/female Depth meshes required for ControlNet.\n\nThe dropdown menu in the UI is for loading MoCap animations (.fbx, .bvh, .glb) from Mixamo for instance, to animate the built-in actors, not for loading custom character meshes like XPS.\n\nIf you want to use custom meshes or props, you need to open the Yedp_Rig.glb file in Blender, attach your custom models to it, follow the same naming convention and overwrite the file, I hope it answers your questions :)",
              "score": 2,
              "created_utc": "2026-02-26 14:09:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7j3vne",
          "author": "LowYak7176",
          "text": "Noticed you were using Wan 2.1 Fun Control in your basic workflow, will this work with Wan 2.2 Fun Control?",
          "score": 1,
          "created_utc": "2026-02-26 15:40:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7j5xil",
              "author": "shamomylle",
              "text": "I use wan 2.1 because it is easy and fast for my low 8GB vram setup but if anything wan 2.2 would outperform 2.1 in both camera movement understanding and quality. It takes the same openPose/depth/canny inputs too (although I cheated my canny render with a rim light type of material so it might not be the best, better stick with openPose/depth).\n\nSo long story short, it should work fine :)",
              "score": 3,
              "created_utc": "2026-02-26 15:49:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7jubl5",
                  "author": "LowYak7176",
                  "text": "Thank you!\n\n",
                  "score": 1,
                  "created_utc": "2026-02-26 17:41:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7jypwc",
          "author": "serjuiced",
          "text": "https://preview.redd.it/025dxdz1pvlg1.png?width=182&format=png&auto=webp&s=5ae80f94398d16dcaba6474f76da87dd8776f278\n\n",
          "score": 1,
          "created_utc": "2026-02-26 18:01:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7myc3j",
              "author": "shamomylle",
              "text": "Thanks for your interest :)",
              "score": 1,
              "created_utc": "2026-02-27 03:16:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7l6bhp",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-02-26 21:27:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7mih4b",
              "author": "shamomylle",
              "text": "Yes, what you are describing is called Video-to-Video (V2V) generation.\nIt uses a different workflow than my 3D node. Keeping things 100% consistent (without flickering) is still the biggest challenge in AI, but you could try 2 things right now:\n\n1. ComfyUI direct workflow:\nAnimateDiff + ControlNet: You feed your smartphone video into ComfyUI. ControlNet extracts the 2D poses and depth from your video frame-by-frame, and AnimateDiff forces Stable Diffusion to keep the generated frames consistent over time. It requires tweaking to stop flickering, but it can be done.\n\n2. The 3D route :\nUsing Andrea Pozzetti [ComfyUI-MotionCapture](https://github.com/PozzettiAndrea/ComfyUI-MotionCapture) to extract 3D motion as FBX + my node. I didn't test it but it should technically work. The advantage is being able to change the camera angle of your scene.\n\nHope it answers your question :)",
              "score": 3,
              "created_utc": "2026-02-27 01:44:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7n99rw",
          "author": "StacksGrinder",
          "text": "Wow this is amazing, I'm guessing this will really refine the fight sequences in a clip, a precise punch and a hit movement. :D Thanks for brining it to ComfyUI, You're amazing!  ",
          "score": 1,
          "created_utc": "2026-02-27 04:26:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7naad1",
              "author": "shamomylle",
              "text": "You're welcome! I can't wait to see what people can do with it or improve it :)",
              "score": 2,
              "created_utc": "2026-02-27 04:33:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7pkrlk",
          "author": "M4xs0n",
          "text": "Can it also generate an Animation from video to fbx?",
          "score": 1,
          "created_utc": "2026-02-27 14:57:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7q1oip",
              "author": "shamomylle",
              "text": "Hello! Thanks, that's a great question:\n\nSo there are a couple ways to do it, I haven't tested it yet but Andrea Pozzetti did release a great node for ComfyUI doing just that:\n[ComfyUI-MotionCapture](https://github.com/PozzettiAndrea/ComfyUI-MotionCapture)\n\nOther online solutions exist such as: [Rokoko](https://www.rokoko.com/products/video) and [Deepmotion](https://www.deepmotion.com/)\n\nFinally for another direction also directly inside ComfyUI, you can go the route of prompt-to-3D animation with [HY-MOTION](https://github.com/jtydhr88/ComfyUI-HY-Motion1) which also have an option to save FBX animations compatible with Mixamo.\n\nI hope these will help you :)\n\n\nAs a bonus, (if you want to go experimental!) I designed a suite of nodes for MoCap directly inside ComfyUI, which exports 3D data using mediapipe as a json file, you'd need to go through some process to get some conversion going and redirect that 3D data to a 3D rig.\nOr you can experiment with my MoCap nodes to directly use the output (openpose skeleton), here's the link in case : \n[ComfyUI-Yedp-Mocap](https://github.com/yedp123/ComfyUI-Yedp-Mocap)",
              "score": 1,
              "created_utc": "2026-02-27 16:19:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7syzvn",
          "author": "Optimal_Map_5236",
          "text": "is there a way to use controlnet vid with t2v workflow? like you make t2v vid using depth ref vid. all those animate vace scail are made for i2v",
          "score": 1,
          "created_utc": "2026-02-28 01:20:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7t267m",
              "author": "shamomylle",
              "text": "You should be able to do this! In fact, guiding a T2V (Text-to-Video) workflow can be done with my node.\n\nI think if you use AnimateDiff inside ComfyUI, as it is a native T2V model it will work.\n\nBasically using my node and passing it through an \"apply controlnet\" node then using AnimateDiff in theory ( you'd have to research it)\n\nAnimateDiff should generate the video completely from scratch (T2V) using your text, while being 100% physically guided by the 3D Depth/Pose sequence you created in the viewport.",
              "score": 2,
              "created_utc": "2026-02-28 01:40:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7txur5",
                  "author": "Optimal_Map_5236",
                  "text": "thanks for the response. do you have workflow for this? I wanna use character lora guided by openpose vid using T2V workflow because only t2v+lora can deliver character consistency. I tried what you said. but didn't understand animatediff part.",
                  "score": 1,
                  "created_utc": "2026-02-28 05:09:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o836aqu",
              "author": "PeterDMB1",
              "text": "> vace \n\nVace is actually a T2V model. (have no idea on the rest of your question/discussion but did want to mention that)",
              "score": 1,
              "created_utc": "2026-03-01 17:49:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o85685t",
                  "author": "Optimal_Map_5236",
                  "text": "if you connect Wan2.2 14B T2V lora to vace model, output would be mess because the lora wasn't trained on vace model. Thats why those loras should be used on what trained lora with. I want to use T2V character lora while having the video guided by controlnet just like flux1 + controlnet combo but in this case its video. I searched the whole internet and it seems theres no way to achieve this. ",
                  "score": 1,
                  "created_utc": "2026-03-01 23:59:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o834d7s",
          "author": "PeterDMB1",
          "text": "Hey! This looks really cool so I'm looking forward to trying it. I cloned the repo and my firewall blocked it calling out on first launch. I was 99% sure this wasn't anything malicious due to this popular thread and your activity on GH but I did have Claude review the repo before I let the node call out.  \"He\" explained it's all good just goes to a legit site to fetch a few .js dependencies. I asked if that is done once (first load), but he said no it appears to do that every time the cache is cleared (or semi-frequently). Oddly we noticed that the files the node was fetching (aside from a couple) were already provided in the web folder, but they're not being used. Maybe this is an oversight? I'm able w/ his help to sort my own local version out, but I wanted to provide a link to our conversation which includes his solution to keep the node 100% local in case it's of interest: https://claude.ai/share/f33d6960-841c-46b8-a98e-cbca85333b8c   \n  \nThanks a lot for your work!",
          "score": 1,
          "created_utc": "2026-03-01 17:40:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o838xsm",
              "author": "shamomylle",
              "text": "Hello! Thanks for the feedback, I will try to fix it soon! sorry for the trouble!",
              "score": 2,
              "created_utc": "2026-03-01 18:01:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1re4vo2",
      "title": "Berserk Dark Fantasy Concept – Why Art Direction Matters More Than Prompting [Workflow Included]",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/3p30stckoklg1",
      "author": "Feisty-Turnover9243",
      "created_utc": "2026-02-25 05:45:23",
      "score": 250,
      "num_comments": 57,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1re4vo2/berserk_dark_fantasy_concept_why_art_direction/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7a5mlq",
          "author": "TopTippityTop",
          "text": "Agree. AI has no sense of \"taste\", it simply tries to follow what the words say in a way which is consistent with its training data given the initial noise patter given. It doesn't understand shape language, identity, storytelling and design, etc.\n\nThat taste has to come from the human element. The ideas and taste the human imbues AI with, is what can turn the tool's craft into art.\n\nThe people who seek a one stop shop in prompting will find themselves amidst a wave of generic lookalikes. Those who use unique workflows, including manual work, won't save as much time, but can create a better sense of identity, stand out, and resonate more with a chosen audience.\n\nThere is a place for craft. We're surrounded by useful but forgettable things. However powerful AI as a crafting tool is, humans love novelty and surprise. It's often those who push boundaries which stand a greater chance at succeeding in those areas where this human desire shows up the most, such as in films, games, shows, marketing, etc. Whenever there's a need to get more eyeballs pointed someplace, higher engagement, talent will be requested.\n\nThen again, I could be wrong. Who knows, perhaps our future overlord Stable Diffusion XXL 20 will be superintelligent, have taste, be truly creative, and come up with beautiful ideas, unprompted, on its own.",
          "score": 35,
          "created_utc": "2026-02-25 06:12:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7a8ou5",
              "author": "Feisty-Turnover9243",
              "text": "100% spot on, man. I feel like treating AI as an all-in-one slot machine—just pulling the prompt lever and praying for something usable—is a race to the absolute bottom rn. Everything just ends up looking like that same generic AI plastic.\n\nThe real moat is definitely *curation and intent*. Knowing exactly what frame you need for the cut, and literally forcing the model to spit it out so it matches your composition. It takes way more manual work in After Effects to glue it all together (the grain, the crushed blacks), but at least it actually has an identity.\n\nAs for SD XXL 20 turning into some super-intelligent art director… honestly, with how fast this tech moves, I wouldn't even be mad lmao. But until an algorithm can actually *feel* the tension of a 24fps cut-to-black, I think us manual editors are safe for a bit. Appreciate the insight!",
              "score": 8,
              "created_utc": "2026-02-25 06:38:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7a9maa",
          "author": "Nobodyss_Business",
          "text": "Hard  agree 👍 \n\nAs a graphic designer myself I treat AI as a tool first and foremost,  which needs a lot of time and effort to master, just like any tool for any professional use. When I look at any AI image or video I first acknowledge the mistakes or any details that look or feel wrong to my professional \"eye\" and then the work as a whole and the idea or style behind it. \n\nSo the digital editor in me treats the \"piece of art\" (though being AI generated or assisted) as I would  pre-AI works. It should have some idea or concept behind, taste, story, style, it should feel \"crafted\" in the sense of both effort and skill put into it - so all the elements of real art should be present.",
          "score": 6,
          "created_utc": "2026-02-25 06:46:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7aau1i",
          "author": "Feisty-Turnover9243",
          "text": "A lot of people think the AIGC era made creating easy—just type a prompt and boom, you have a film. But tbh, as someone actually in the trenches doing this, I gotta say: **the technical barrier dropped to zero, but the aesthetic barrier just shot through the roof.**\n\nAI is an insanely powerful brush, but it’s not a brain. Without a solid foundation in visual storytelling, generated clips are just a random pile of footage with zero narrative breathing room. You literally have to think like a director: *How does this shot transition? How does the lighting serve the emotional undertone? How are you controlling the pacing?* You can’t outsource that to an algorithm. Without an overarching structure, your video just falls into disconnected logic and a fractured art style.\n\nNow that \"1-click generation\" is the norm, we're absolutely drowning in homogenous AI slop. **Your only real moat right now is your unique taste and your understanding of human emotion.** Don't let the tool box you in. In this human-AI collab, you *must* maintain your agency as the creator. You use your aesthetic judgment to ruthlessly curate and reconstruct what the AI spits out, making sure every single frame actually serves the theme.\n\n**TL;DR:** Tech empowers the narrative, but it can never replace the soul. Be the director who controls the vision, not just a \"prompt jockey\" moving text from one box to another. In an era where everyone has access to the exact same tools, your taste and creativity are literally the only things they can't automate.",
          "score": 11,
          "created_utc": "2026-02-25 06:56:37",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o7ak89m",
          "author": "murderopolis",
          "text": "Agreed. Just weird that you also had an AI write your post",
          "score": 11,
          "created_utc": "2026-02-25 08:21:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7akqnc",
              "author": "Feisty-Turnover9243",
              "text": "Haha, nope, I just made that up myself.",
              "score": -11,
              "created_utc": "2026-02-25 08:26:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7akzhn",
                  "author": "murderopolis",
                  "text": "Wow. You must be the guy chapgpt is learning how to type and format from.",
                  "score": 10,
                  "created_utc": "2026-02-25 08:28:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7amvyg",
                  "author": "suspicious_Jackfruit",
                  "text": "Lol, no you didn't. Be honest, you aren't fooling a community who use AI regularly, it's obviously an AI generated post. You may have fed it your own thoughts but an AI made that text.\n\nThat aside, good video and much better than regular slop. But from a personal preference its not quite right for berserk, it's too fun and soft aesthetically for the brand imo",
                  "score": 11,
                  "created_utc": "2026-02-25 08:46:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7agpi1",
          "author": "ArtificialAnaleptic",
          "text": "Firstly, I wan't to say 100% that I agree. I try to do the same thing with my digital art. I've moved to a good 50-75% split of effort with that majority being AI but with tightly bound requirements in terms of target/end result. It works great and I'm very happy with my results.\n\nBut one thing I will say is that AI is also just very good at certain things and occasionally people (even those familiar with AI) ***don't*** recognize the difference between something that required deliberate thought/effort and something that was simply prompt/seed-luck. You do even see this with traditional artists occasionally getting mistakenly labelled as AI and it's a similar phenomenon.\n\nFor instance, I was initially unimpressed with this: https://v.redd.it/bi449b91u1zf1\n\nI assumed it was simply img2vid+prompt+some masking of the original video around the subject. In reality it's a much more complex and deliberate workflow.\n\nMore recently, I've tried to be a little less quick to jump to conclusion. If a piece is good, it's good. If a creator is ***consistent*** then they are good.",
          "score": 3,
          "created_utc": "2026-02-25 07:49:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ail6f",
              "author": "Feisty-Turnover9243",
              "text": "This is a brilliantly nuanced take. The 'prompt/seed-luck' phenomenon is incredibly real—sometimes the algorithm just hands you a miracle frame on a silver platter. And because of that, the line between an accidental good shot and deliberate art direction gets blurry to the general audience.\n\nYou nailed the ultimate truth at the end: **Consistency**.\n\nAnyone can get lucky once and generate a cool generic 5-second clip. But dictating a specific, cohesive aesthetic across an entire sequence, or tailoring it to a strict brand brief—that’s where the 'lucky prompters' fall off and the actual directors take over. That's the exact reason I'm building out a portfolio of these. Really appreciate the deep dive here.",
              "score": 0,
              "created_utc": "2026-02-25 08:06:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7b3n55",
          "author": "ukpanik",
          "text": "If you are going to lecture everyone about \"100% human-controlled rhythm\", at least choose music that vibes with Berserk.",
          "score": 6,
          "created_utc": "2026-02-25 11:19:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7cm0rb",
              "author": "SymphonyofForm",
              "text": "Have you even heard the 80's intro song? ",
              "score": 3,
              "created_utc": "2026-02-25 16:25:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7aa1po",
          "author": "story_of_the_beer",
          "text": "This goes hard, well done! Prime example of great composition, style consistency and cadence. I'd love to see more, also Glass Animals 10/10",
          "score": 2,
          "created_utc": "2026-02-25 06:49:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bcdad",
          "author": "addandsubtract",
          "text": ">AI generated the pixels, but the newsletter, the pacing, and the vibe are mine  \n  \nNewsletter?",
          "score": 2,
          "created_utc": "2026-02-25 12:26:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7aklk3",
          "author": "AnOnlineHandle",
          "text": "> AI should strictly be treated as a rendering engine\n\nIMO This is the key thing which is desperately needed for ML based image generation to be useful for creative purposes. It needs to behave more like a traditional 3D rendering engine, given locations, rotations, scalars, material properties, etc, in precise values rather than the vagueness of natural language descriptions. An ML tool could still be used to generate that from text, but the actual rendering stage should be precisely definable.",
          "score": 1,
          "created_utc": "2026-02-25 08:25:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ammvi",
              "author": "Feisty-Turnover9243",
              "text": "Totally agree. AI should absolutely be treated as a proper rendering engine.  \nNatural language prompts are way too vague and messy—it’s less directing a scene, more negotiating with a hyperactive kid.\n\nTools like ComfyUI and ControlNets are moving us closer to 3D-engine precision, letting us lock in exact depth, position, and orientation.  \nThe end goal is exactly what you said: a node-based workflow where we set precise values for lighting, rotation, and materials, with zero guesswork. That’s the only way this becomes truly useful for serious creative work.",
              "score": 2,
              "created_utc": "2026-02-25 08:44:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7al20p",
          "author": "joeyz550",
          "text": "Nice",
          "score": 1,
          "created_utc": "2026-02-25 08:29:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7aobld",
          "author": "lucassuave15",
          "text": "Looks really good, AI on the hands of someone who is already an artist can do wonders",
          "score": 1,
          "created_utc": "2026-02-25 09:00:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7aoo5i",
          "author": "JoelMahon",
          "text": "AI slop is made by the same humans that made \"organic\" slop before AI slop was an option.\n\nthose with taste vs those without taste will exist for a few more years at least.\n\nalthough I do think eventually AI will be far more proactive with shutting the tasteless down and being more proactively tasteful, but for now at least the difference is night and day between your quality work vs the crap some people shovel out using the same tools",
          "score": 1,
          "created_utc": "2026-02-25 09:03:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7cinw1",
              "author": "EducationalWeird5204",
              "text": "excellent！",
              "score": 2,
              "created_utc": "2026-02-25 16:10:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7auk7w",
          "author": "Sleepy_Bandit",
          "text": "Agreed, but how do you “hand apply” film grain? 😅",
          "score": 1,
          "created_utc": "2026-02-25 09:58:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7avnbm",
          "author": "NineThreeTilNow",
          "text": ">AI generated the pixels, but the newsletter, the pacing, and the vibe are mine. Curious to hear what other motion designers think about this approach to workflow!\n\nThank fuck. I have so many brain dead friends that think AI motion looks \"good\".\n\nSomehow they think swapping a ChatGPT generated image and prompt in to Wan 2.2 makes them an artist.\n\nCreative work is hard and they're lazy. I don't think some people understand that part.",
          "score": 1,
          "created_utc": "2026-02-25 10:08:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7b7b21",
          "author": "K0owa",
          "text": "The sentiment is great. However, the concept for Berserk doesn’t match the tone/mood of the manga or anime.",
          "score": 1,
          "created_utc": "2026-02-25 11:49:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7b81mv",
          "author": "Boogooooooo",
          "text": "It is prompt engineering. I am producing very similar vibe and pacing for my channel (arguebly even better sometimes). All scripting done automatically via automation flow.\n35mm film grain included :D",
          "score": 1,
          "created_utc": "2026-02-25 11:54:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bkjjb",
          "author": "Grand_Bobcat_Ohio",
          "text": "Art direction is prompting...",
          "score": 1,
          "created_utc": "2026-02-25 13:18:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bpecs",
          "author": "Sioluishere",
          "text": ">I’m a motion designer\n\nMakes sense",
          "score": 1,
          "created_utc": "2026-02-25 13:45:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bqiv6",
          "author": "switch2stock",
          "text": "Where is the workflow tough?",
          "score": 1,
          "created_utc": "2026-02-25 13:51:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bsvev",
          "author": "PwanaZana",
          "text": "True, though your post was written by an AI, so it is ironic. :P",
          "score": 1,
          "created_utc": "2026-02-25 14:04:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7byu28",
          "author": "RebelRoundeye",
          "text": "I have been wanting to experiment with gen ai video motion graphics. I planned on beginning with my own vector artwork then straight to Kling and LTX2 without attempting to t2i anything. I am curious how the video models would handle it. I haven’t seen anyone else attempt like you have. I suppose it should do well enough. Surely the video models have training on motion elements and not just motion photography. Ty for sharing!",
          "score": 1,
          "created_utc": "2026-02-25 14:35:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7coz4s",
              "author": "EducationalWeird5204",
              "text": "Bro, you’re deadass right!  \nUsing vector graphics paired with AI to polish the motion work?  \nThat’s the real secret sauce here—aside from OP’s insane aesthetic and the video’s tight audio-visual structure.",
              "score": 1,
              "created_utc": "2026-02-25 16:39:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7bzpa7",
          "author": "KleaningGuy",
          "text": "Nice ! I can't prompt better myself, but i want to point out that choice of music is questionable.",
          "score": 1,
          "created_utc": "2026-02-25 14:40:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7c56st",
          "author": "UnrelaxedToken",
          "text": "Can you share your premiere pro and after affect projects? lol",
          "score": 1,
          "created_utc": "2026-02-25 15:07:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7cf9yr",
          "author": "xdozex",
          "text": "Its really no different from what we're seeing happening with code, just a bit slower. Anyone can pop open Cursor or Claude Code and vibe code a quick semi-functional frontend that technically 'works'. But when the rubber meets the road, these apps won't scale, they won't be able to handle anything that wasn't specifically prompted for, and they tend to be security nightmares most of the time. Give the same tools to an experienced engineer, and they can use natural language to steer the models in the right direction. They understand the underlying architecture, they know where bugs or security issues could pose bigger problems later, and they know how to use the tools to work around them and produce a more legit end result. \n\nAll the lifeless slop you're seeing is posted by people who had a passion or desire to make mograph, but never really had the skills to pull it off using traditional software. These tools give them a way to achieve results that far exceed anything they could make themselves in After Effects, so for those people the lifeless slop feels like a big win. You, with your motion graphics background know what to look out for, know how to take what looks like a set of student b-roll graphics and coax more out of them. \n\nI also work in the industry and while you're results did look better than most AI motion graphics I've seen, it's still falling a bit short when you compare it to professional mograph. Another few model iterations and these artificial barriers will break down. ",
          "score": 1,
          "created_utc": "2026-02-25 15:55:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7cpjo4",
              "author": "EducationalWeird5204",
              "text": "As AI keeps advancing, it’ll continue to lower the barrier and cost of manual content creation.  \nGoing forward, what truly matters in content creation won’t just be production speed or technical skill—it’ll be your taste, original ideas, and a deep understanding of brand identity and film storytelling.  \nCreators like you and the OP, with real insight, are the ones who truly deserve all the respect.",
              "score": 1,
              "created_utc": "2026-02-25 16:41:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ck3b5",
          "author": "TogoMojoBoboRobo",
          "text": "Yah, it bugs me, working in games how company execs think it is about 'not knowing the right words' holding them back from being good at AI or thinking that a magic prompt will get them what they want.  No, the problem is the exec themselves being a dumbass who actually needs people, but their cheap ass egos won't allow them to see that.",
          "score": 1,
          "created_utc": "2026-02-25 16:16:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7cq04v",
              "author": "EducationalWeird5204",
              "text": "You’re totally right. A lot of game company executives fall into a common misconception. They assume AI isn’t delivering the results they want just because “the right prompts aren’t being used,” and even hope a single magic prompt will make everything work perfectly. This is a huge misunderstanding of AI-driven creation and content production.  \nThe core issue has never been the prompts themselves. What truly matters is the **creative vision, overall planning, narrative logic, and professional visual-audio expression** behind the work. AI is only a tool from start to finish—what defines the quality and soul of a project is human aesthetics, original ideas, deep understanding of content, and a complete creative framework.  \nWhat they actually need is professional creators to guide the direction, define the vision, and execute the expression. Unfortunately, many fail to recognize the true nature of AI tools and overlook the essential value of creation itself.",
              "score": 1,
              "created_utc": "2026-02-25 16:43:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ctktv",
          "author": "Silly-Dingo-7086",
          "text": "At I 100% believe that the future of AI generated movies will still be a production of a very small team of people. One who traditionally was a director and had an overall dream of pacing camera location angle etc. Someone that can prompt properly and generate what is needed and keep the consistency there. And like you said somebody who can mix it all together and make it work. Maybe and eventually will get to the point where you are people are needed but I think in the next five years these tools will be available for anybody with a creative mind to be able to start making their own beautiful creations of full-like TV shows or movies. Kind of like how the music industry is very easy to get into now because kids can mix music themselves and create whatever they want without needing a big studio. We will just see this for TV and movies. \n\nWhat's great about it is that we can see multiple takes on classics",
          "score": 1,
          "created_utc": "2026-02-25 16:59:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7cu95d",
              "author": "EducationalWeird5204",
              "text": "I fully believe the next five years will bring a “renaissance” in filmmaking, but it won’t be a victory for technology—it’ll be a victory for people. Our job as creators is to use our expertise to define what “great work” means, and turn AI into an amplifier for our ideas, not a machine for churning out mediocre content. I can’t wait to see more people use these tools to reimagine classic works in entirely new ways! 🤍",
              "score": 1,
              "created_utc": "2026-02-25 17:03:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7cuplx",
                  "author": "Silly-Dingo-7086",
                  "text": "It's going to change everything and not for good or bad. A lot of people that put a lot of time and money and that person of things will lose out. I can only imagine all of the works of fiction and nonfiction that have been done over the last thousand years can now be done in a digital media where we can view it and enjoy it in a new life. But the authors who are writing these now won't be getting paid because that's just not how online streaming pirating and self-generated fanfic works. But how many shows and movies have they attempted to make into a series that sloppy because the director in the show runners suck. Now I can finally see wheel of Time done in the right way",
                  "score": 1,
                  "created_utc": "2026-02-25 17:05:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7abfan",
          "author": "FreezaSama",
          "text": "Great video and not to be rude but. I thought what you said was obvious to everyone? AI is a tool.",
          "score": 1,
          "created_utc": "2026-02-25 07:01:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ad08t",
              "author": "Feisty-Turnover9243",
              "text": "You’d assume it’s obvious. But when 90% of the AI videos flooding the internet still look like thoughtless, un-curated slop, it clearly isn't being practiced. Knowing a hammer is a tool is easy; actually building a house with it is what's missing right now. Just stating the reality of the space.",
              "score": 10,
              "created_utc": "2026-02-25 07:15:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7aoyg6",
                  "author": "ThePoetPyronius",
                  "text": "Everyone's got a hammer since Big Hammer opened up a franchise in every 2-bit town this side of the Rio Grande. We, the masons, are still with you bud. 🤍",
                  "score": 1,
                  "created_utc": "2026-02-25 09:06:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7c0h0n",
                  "author": "ExplanationAway672",
                  "text": "To be fair 90% of everything on the internet is thoughtless, un-curated slop.  Is it really a problem though?  Same as with all the new tools we've had since computers have been easily accessible and that lower the barrier of entry to creating, a lot of people will just have a play, or use them to make memes, rag on mates etc.  A few will practice and learn the skills, and make the other 10%. - and that stuff surfaces very easily.",
                  "score": 1,
                  "created_utc": "2026-02-25 14:44:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7ahcg3",
                  "author": "FreezaSama",
                  "text": "It's definitely true! Most stuff is slop that, in the beginning could shine on its own but with the democratization of these tools they are easily forgettable and even here on reddit people are starting to call it off. That is undeniable. What I challenged was the conclusion you shared on \"AD matters more than promoting\" that's the part I would say is obvious. Either way not to pee on the parade. The work is great and I'm all for the argument. That's exactly what I do day to day",
                  "score": 1,
                  "created_utc": "2026-02-25 07:55:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7b6ls3",
          "author": "aastle",
          "text": "Downvoted for the music choice.",
          "score": 1,
          "created_utc": "2026-02-25 11:43:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7bamaf",
              "author": "lucak5s",
              "text": "put your grasses on",
              "score": 0,
              "created_utc": "2026-02-25 12:13:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ai9js",
          "author": "ScienceAlien",
          "text": "^^this",
          "score": 0,
          "created_utc": "2026-02-25 08:03:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7b83yd",
          "author": "Alisomarc",
          "text": "100% that's the only way to avoid the a.i slop era\n\n![gif](giphy|RrVzUOXldFe8M)\n\n",
          "score": 0,
          "created_utc": "2026-02-25 11:55:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7cq4h9",
              "author": "EducationalWeird5204",
              "text": "nb！",
              "score": 1,
              "created_utc": "2026-02-25 16:44:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7b9cvs",
          "author": "Stunning_Macaron6133",
          "text": "Nuance? On Reddit? And with helpful tips on top of that!\n\nOh, how can this be?",
          "score": 0,
          "created_utc": "2026-02-25 12:04:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1revwgq",
      "title": "CLIP is back on Anima, because CLIP is eternal.",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1revwgq/clip_is_back_on_anima_because_clip_is_eternal/",
      "author": "Anzhc",
      "created_utc": "2026-02-26 00:58:35",
      "score": 234,
      "num_comments": 30,
      "upvote_ratio": 0.94,
      "text": "You thought you can get away from it? Never.\n\nhttps://preview.redd.it/ucku0gzegqlg1.png?width=743&format=png&auto=webp&s=2f349550205028c6e18e4b72aa9144304d2c1e75\n\nGuys at Yandex and Adobe implemented CLIP for bunch of models that don't use it - [https://github.com/quickjkee/modulation-guidance](https://github.com/quickjkee/modulation-guidance)\n\nI made it into ComfyUI node for Anima - [https://github.com/Anzhc/Anima-Mod-Guidance-ComfyUI-Node](https://github.com/Anzhc/Anima-Mod-Guidance-ComfyUI-Node)\n\nFor images above and below i used CLIP L from here - [https://huggingface.co/Anzhc/Noobai11-CLIP-L-and-BigG-Anime-Text-Encoders](https://huggingface.co/Anzhc/Noobai11-CLIP-L-and-BigG-Anime-Text-Encoders)\n\nBasic CLIP L also works, but your mileage may vary, every CLIP has different effect.\n\n\\---\n\nUnfortunately it won't let you use weighting as on SDXL, but from what i tested that also was a bit better at least.\n\nSo what are the benefits anyway?\n\nFrom what i tested(Left is base Anima, right with Modulation Guidance):\n\n\\- Can reduce color leaks\n\nhttps://preview.redd.it/ush1cgt9hqlg1.png?width=2501&format=png&auto=webp&s=968ea21bdbf5a89648c04502bb391965d9640151\n\n(necktie is not even prompted)\n\n\\- Improve composition and stability\n\nhttps://preview.redd.it/67a60iirhqlg1.png?width=2070&format=png&auto=webp&s=8268d0c1cbc3b4c95f44e091fc44e0a5864c7529\n\n(Yes, i picked the funniest example, sue me)  \nThat particular prompt i ran like 10 times, few of them it would show another issue:\n\n\\- Beach\n\nhttps://preview.redd.it/efvihns8iqlg1.png?width=2067&format=png&auto=webp&s=c61db50a509ab6772b74e60fb4834f0784dc7750\n\nFor no reason whatsoever, Anima LOVES to default to ocean or beach, that effect is reduced with CLIP.\n\n\\- Less unprompted horny (I know for most of you this is a negative though)\n\nhttps://preview.redd.it/b9byqkhkiqlg1.png?width=2286&format=png&auto=webp&s=800d55d03dcbe5a53d403b6b6a310e826bc5a25e\n\n(Afterimages prompted, i just wanted her to sweep floors...)\n\n\\- Little bit better (from what i tested) character separation, and adherence to character look\n\nhttps://preview.redd.it/hk1ye4pviqlg1.png?width=2507&format=png&auto=webp&s=6452c13d141cc1cf4c738c8c7d055cce3288c7e5\n\nBut it still largely relies on base model understanding in this aspect.\n\n\\- Can also improve quality in general (subjective)\n\nhttps://preview.redd.it/yhlkikw6jqlg1.png?width=1827&format=png&auto=webp&s=bd80337bb128773a19c9825cb426d7900272dd55\n\n\\- Less 1girl bias (prompt is just \\`masterpiece, best quality, scenery\\`)\n\nhttps://preview.redd.it/h681h5jnjqlg1.png?width=2588&format=png&auto=webp&s=df37a3c08f320d5a6877b28b13e2349f71a6a358\n\nhttps://preview.redd.it/elapkpktjqlg1.png?width=2112&format=png&auto=webp&s=f0d0aefda7ae627a3afba40a20695b296a8e0e9f\n\nhttps://preview.redd.it/9gdbycuyjqlg1.png?width=2114&format=png&auto=webp&s=0e749ae327f2390d762d165d6fe9c240374cdfd6\n\n  \nI primarily tested with tags only, while i did test with some NL, i generally don't have much luck with it on Anima, for me it's unstable and inconsistent, so i'll leave it to you to find if CLIP is helping there or not.\n\nP.S. All girls in images are clothed/in bikini, i just censored them to keep it safe. But i really can't emphasize how horny Anima is by default...\n\n  \nIt's easy to use, and i've included prepared workflow for you to compare both results for yourself:\n\nhttps://preview.redd.it/u6bue5hulqlg1.png?width=2742&format=png&auto=webp&s=2fbead9bb4da338312d1055b3e16de4a12bce2c4\n\nYou can find it in repo. To use it, you don't need to write a prompt for it every time, generally you just use it as secondary quality tags, and wire negative and base in from main prompts.\n\nBased on official repo, you can tune it to affect different things, but i haven't tried using it like that, so up to you to test it.\n\nThat's it. Have fun. Till next time.\n\n\n\nAlso\n\n  \nShe's just like me frfr\n\nhttps://preview.redd.it/7r0b9lx8kqlg1.png?width=555&format=png&auto=webp&s=f375ad6d8b5bf587f876416d5bd8193af0ba11fd\n\nIf you're here, here are links from the top of post so you don't have to scroll:\n\n  \nOriginal implementation - [https://github.com/quickjkee/modulation-guidance](https://github.com/quickjkee/modulation-guidance)\n\nComfyUI node for Anima - [https://github.com/Anzhc/Anima-Mod-Guidance-ComfyUI-Node](https://github.com/Anzhc/Anima-Mod-Guidance-ComfyUI-Node)\n\nWorkflows also can be found right in node repo.\n\nFor images above i used CLIP L from here - [https://huggingface.co/Anzhc/Noobai11-CLIP-L-and-BigG-Anime-Text-Encoders](https://huggingface.co/Anzhc/Noobai11-CLIP-L-and-BigG-Anime-Text-Encoders)",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1revwgq/clip_is_back_on_anima_because_clip_is_eternal/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "o7gdmes",
          "author": "comfyanonymous",
          "text": "Since anima is based on cosmos you can also use t5xxl 1.0 with it.\n\nJust use the native workflow with this file instead of qwen_0.6b: https://huggingface.co/comfyanonymous/cosmos_1.0_text_encoder_and_VAE_ComfyUI/tree/main/text_encoders",
          "score": 21,
          "created_utc": "2026-02-26 03:46:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7gogyq",
              "author": "ZootAllures9111",
              "text": "Is there any benefit to this?",
              "score": 10,
              "created_utc": "2026-02-26 04:58:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7h00eh",
                  "author": "comfyanonymous",
                  "text": "I don't think so but it's interesting.",
                  "score": 8,
                  "created_utc": "2026-02-26 06:27:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7jcyxo",
          "author": "Viktor_smg",
          "text": "Man it's so refreshing seeing actual anime on this sub again and not just the normie slop that normie models pump out. And featuring some pretty good shows at that.",
          "score": 11,
          "created_utc": "2026-02-26 16:21:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hea72",
          "author": "EirikurG",
          "text": "you're gonna need bigger grids with more images for your comparisons if we are to see a meaningful difference between the two  \n  \nshowing us just 1 seed of each and saying \"oh yeah, this looks better\" is not a very good comparison",
          "score": 18,
          "created_utc": "2026-02-26 08:36:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7j5dja",
              "author": "NanoSputnik",
              "text": "Amen. ",
              "score": 3,
              "created_utc": "2026-02-26 15:46:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7j6sz5",
              "author": "Choowkee",
              "text": "Yeah...Anima outputs can vary widely from seed to seen (for better or worse).\n\nStill I am gonna give OP the benefit of the doubt and assume it helps.",
              "score": 3,
              "created_utc": "2026-02-26 15:53:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7jz1if",
              "author": "Ok-Category-642",
              "text": "Yeah I tested this for a little bit and I have my doubts that it's actually better and not just different. The outputs ended up being very similar (even pure NL) including artist mixing too. Prompt weighting changes a little more, but it doesn't work too well either. It doesn't seem to be strictly better either; sometimes it's better and sometimes it's worse, sometimes they both make the same error, but overall it's not consistent. If you use a style Lora the difference becomes even smaller, it doesn't seem worth it overall as it just seems to make styles and NL slightly weaker with not much benefit.\n\nGranted I haven't done a lot of testing either but it doesn't seem to have the benefits I would've hoped for.",
              "score": 2,
              "created_utc": "2026-02-26 18:03:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7kqp4j",
              "author": "Anzhc",
              "text": "I obviously did gen many seeds per prompt, but it's not really good for reddit post. \n\nIn my experience, i preferred CLIP output in about 60 to 80% cases, depending on prompt. In post i just shown specific examples of what using it can result into.",
              "score": 1,
              "created_utc": "2026-02-26 20:12:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7fx8c7",
          "author": "Only4uArt",
          "text": "I was doubting the usability when reading the title but the results really point towards certain pain points one can have with anima preview and the clip results are great in the examples.\n\n\nI would say clip can elevate the floor of what the model can do in the average hands of a user.\n\nIt will be interesting to see what happens with the base model and fine-tunes on top of it. I can still see a lot of potential in using qwen . But no one would miss it currently in the status quo.",
          "score": 17,
          "created_utc": "2026-02-26 02:11:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7gocsy",
              "author": "ZootAllures9111",
              "text": "This node only works alongside Qwen, it doesn't work by itself.",
              "score": 3,
              "created_utc": "2026-02-26 04:58:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7g3fn8",
          "author": "Normal_Border_3398",
          "text": "I love your adetailers yolos with all my heart. <3",
          "score": 8,
          "created_utc": "2026-02-26 02:46:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7g15de",
          "author": "devilish-lavanya",
          "text": "Nooo, please Nooooo, i can’t take CLIP Anymore. Please",
          "score": 24,
          "created_utc": "2026-02-26 02:33:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7g2iyt",
              "author": "Anzhc",
              "text": "CLIP is eternal. Accept CLIP. Everyone needs CLIP in their life. Do not resist.",
              "score": 41,
              "created_utc": "2026-02-26 02:41:16",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o7hgkar",
              "author": "nicman24",
              "text": "clip might make cancer drugs think about that lol",
              "score": 2,
              "created_utc": "2026-02-26 08:58:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7fwh80",
          "author": "nsfwkorea",
          "text": "Nice work there mate. Thank you for making a post showing the comparisons.",
          "score": 8,
          "created_utc": "2026-02-26 02:07:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7h7j7z",
          "author": "NotSuluX",
          "text": "Super interesting thanks for this. The method implemented seems like a great way to get the upsides of clip (prompt adherence and styles), without the downsides (poor spatial awareness)",
          "score": 2,
          "created_utc": "2026-02-26 07:33:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ha9z6",
              "author": "Anzhc",
              "text": "Poor spatial awareness is an issue of datasets, not CLIP. It just so happens that old models that primarily use CLIP are also models that had poor datasets. There are some papers that train spatiality into sd1.5/sdxl just fine.",
              "score": 6,
              "created_utc": "2026-02-26 07:58:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7h8wmu",
          "author": "doomed151",
          "text": "All praise the CLIP",
          "score": 2,
          "created_utc": "2026-02-26 07:45:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hdxsv",
          "author": "Sugarcube-",
          "text": "I'm a CLIP enjoyer. This new gen of no negative prompts, ultra verbose and borderline philosophical positive prompts has been a pain in the ass",
          "score": 6,
          "created_utc": "2026-02-26 08:33:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7hke95",
              "author": "shapic",
              "text": "1. This is not true for anima and even z-image\n2. Title is a bit misleading, it is not clip as openai product that is being used here",
              "score": 7,
              "created_utc": "2026-02-26 09:36:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7kb6e0",
                  "author": "shapic",
                  "text": "I think I should clarify my comment after reading the paper. They did attach clip to non-clip model, and had to to additional finetuning, \"Specifically, we train a small MLP on top of the pooled text embedding and add it to the timestep embedding,\"",
                  "score": 1,
                  "created_utc": "2026-02-26 18:58:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7hm0r1",
          "author": "net_tribe24",
          "text": "Thank you for sharing this, I have been using Anima and would like to try your CLIP. I am fairly new to ComfyUI and the world of anime and am struggling to implement this. I have try to drag the base json in to comfyui, it hangs, then an image no embedded workflow. I can see you are an advance practitioner, but could you create a simple step guide for implementation for those like me that would like to try this, where this is not so obvious. Thanks in advance.",
          "score": 1,
          "created_utc": "2026-02-26 09:52:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7i8b4b",
              "author": "net_tribe24",
              "text": "Hi, it was user error on my part, I DL the WF in html not raw json, duh! Once I had the work flow, everything else installed okay. I have to agree with the OP, The final composition showing before and after, the latter is a better composition and has improved colours. A much more mature result. Thank you for sharing your WF, multiline input is new for me, and for not using subgraphs! lol ",
              "score": 2,
              "created_utc": "2026-02-26 12:52:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7tuwcv",
          "author": "AlternativePurpose63",
          "text": "There is still room for further research regarding text encoders, but I’m curious if you have ever delved into their spatial structures. \n\nI've found that LLMs are incredibly chaotic beyond imagination; the spatial curvature distribution is highly complex, and the sequence order exerts a massive influence. \n\nIn such scenarios, if one doesn't employ a dual-stream design or similar architectures—and instead blindly applies data augmentation (like image augmentation techniques) or regularization—it often leads to convergence difficulties. \n\nIn fact, sample inspections often reveal sources of distortion where the model fails to truly generalize, resulting in a degradation of overall quality.",
          "score": 1,
          "created_utc": "2026-02-28 04:48:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rego9t",
      "title": "Latent Library v1.0.2 Released (formerly AI Toolbox)",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/vl5w7g5avnlg1.png",
      "author": "error_alex",
      "created_utc": "2026-02-25 15:43:04",
      "score": 219,
      "num_comments": 80,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rego9t/latent_library_v102_released_formerly_ai_toolbox/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7cha25",
          "author": "TopTippityTop",
          "text": "What is it?",
          "score": 12,
          "created_utc": "2026-02-25 16:04:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ci6l4",
              "author": "error_alex",
              "text": "It's a free, open-source desktop asset manager built specifically for organizing massive collections of AI-generated images (Stable Diffusion, Flux, etc.).\n\nThink of it like Adobe Bridge, but specialized for AI:\n\n* **Metadata Search:** It indexes your images so you can instantly search by prompt, seed, model, or LoRA (supports A1111, ComfyUI, Invoke, etc.).\n* **Local & Private:** It runs 100% offline on your machine—no cloud sync or telemetry.\n* **Workflow Tools:** Includes a duplicate finder, AI auto-tagging (running locally), and a \"speed sorter\" for cleaning up bad generations quickly.\n\nSee the [original post](https://www.reddit.com/r/StableDiffusion/comments/1r65bnh/i_built_a_free_localfirst_desktop_asset_manager/) or the [GitHub](https://github.com/erroralex/Latent-Library) for more info. Thank you!",
              "score": 23,
              "created_utc": "2026-02-25 16:08:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7cij1w",
                  "author": "TopTippityTop",
                  "text": "Got it, that's what it appeared to be from your image. I'd suggest making it front and center in GitHub and your marketing, whenever you post. Perhaps you did, but I glanced at it, saw release notes, but no clear explanation at the top. Good luck and thank you for sharing!",
                  "score": 17,
                  "created_utc": "2026-02-25 16:09:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7e9j9h",
                  "author": "victorc25",
                  "text": "So nothing related to latents? ",
                  "score": 7,
                  "created_utc": "2026-02-25 20:58:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7ha31u",
                  "author": "Head-Vast-4669",
                  "text": "Well organization is an excellent idea indeed. I already built a similar thing for myself in Notion.",
                  "score": 1,
                  "created_utc": "2026-02-26 07:56:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7csm9f",
          "author": "GroovynBiscuits",
          "text": "Ill check this out. Sounds exactly like something ive needed",
          "score": 5,
          "created_utc": "2026-02-25 16:55:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7g4772",
          "author": "sheepdog2142",
          "text": "Doesn't seem to be a way to set a networked folder to be a collection. I even tried running it exe off the networked folder and still no luck. \n\nWould be really nice to be able to pull from a nas or server storage inside my secure home network.",
          "score": 3,
          "created_utc": "2026-02-26 02:50:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7q87sp",
              "author": "error_alex",
              "text": "In the latest release, v1.1.0, you can manually browse and add a pinned folder (just press the + button above the Library folder tree). This should let you add network folders that is not recognized by the folder tree as directories.",
              "score": 1,
              "created_utc": "2026-02-27 16:50:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7qp1e3",
                  "author": "sheepdog2142",
                  "text": "Awesome thank you. Great work btw!",
                  "score": 2,
                  "created_utc": "2026-02-27 18:09:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7dep7w",
          "author": "grebenshyo",
          "text": "macos yay!\n\nheads up: to get it up you need to recursively clear quarantine on the entire bundle:  \nsudo xattr -cr \"/Applications/Latent Library.app\"\n\nIf the app is still in your Downloads or wherever you mounted it from, adjust the path accordingly. After running that, try opening it normally.",
          "score": 2,
          "created_utc": "2026-02-25 18:35:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7dq6lq",
              "author": "error_alex",
              "text": "Huge thanks for testing this! Since I don't own a Mac, I was flying completely blind on that build, so this confirmation is super helpful.\n\nYou hit the nail on the head—it's the standard Gatekeeper quarantine blocking it because I haven't paid the Apple Developer fee to get the app officially notarized yet.\n\nTo try and make this slightly smoother for the next patch, I’ve just updated the build config to:\n\n**Ad-Hoc Signing:** I added `identity: null` to the build process, which ensures it at least has the pseudo-signature required to launch on Apple Silicon (M1/M2/M3) chips without crashing instantly.\n\nI’ve added your `xattr` command to the main README troubleshooting section so others don't get stuck. Thanks again!",
              "score": 1,
              "created_utc": "2026-02-25 19:27:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7ds4xk",
                  "author": "grebenshyo",
                  "text": "my pleasure! i'm actively using this, so your work is much appreciated!  \nsince my install is in place now, i'll keep running that for the moment being. however, since we're at it, i can report another behavior i encountered, which i'm not quite sure if it's personal or general: having little snitch installed, i have the app being signaled on \"wants to connect to fd97:1a08:b277:db2b:1437:ef65:6726:22a0 in the local network\", from time to time, — not sure if it's getting blocked \\*before\\* or \\*because\\* of this. approving solves, but it keeps reappearing, so this will need to get addressed. on this note: i was already planning to fork the project for this exact purpose of porting, but you beat me on time :D so i'd be glad to help in any way if i can! i'll add you here on reddit, so we keep posted! ✌🏾",
                  "score": 2,
                  "created_utc": "2026-02-25 19:37:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7e7rhm",
          "author": "sixstringnerd",
          "text": "Thank you for creating this! I'm getting \"Back-end is Unreachable\" shortly after opening it. I remember now that I got the same message with the last version.\n\nI'm on Windows 11 Pro. Do you have any quick thoughts on this?",
          "score": 2,
          "created_utc": "2026-02-25 20:50:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ei8wl",
              "author": "grebenshyo",
              "text": "i assume this is an error that can appear because of a few different reasons. one of them seems to be the indexing overload: i noticed that if i use recursive indexing and go to huge folders, that error is more prone to appear, so it's just a matter of adjusting the pace with which one navigates the directories, at least in this specific case.",
              "score": 2,
              "created_utc": "2026-02-25 21:38:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7evhdh",
                  "author": "sixstringnerd",
                  "text": "Actually, through lots of trial and error, my issue was caused by 3 or 4 mapped, but disconnected, drives.",
                  "score": 2,
                  "created_utc": "2026-02-25 22:42:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7eargk",
          "author": "RebootBoys",
          "text": "I've been trying out something similar: https://github.com/LuqP2/Image-MetaHub\n\nHow does your tool differ from that?",
          "score": 2,
          "created_utc": "2026-02-25 21:03:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7eqaai",
          "author": "roculus",
          "text": "can you go into where and how the data is stored locally for windows? or providing a setting for choosing where to store the data?",
          "score": 2,
          "created_utc": "2026-02-25 22:16:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7hgt7m",
              "author": "error_alex",
              "text": "The data (thumbnails, database, logs etc) is all stored in a /data folder next to your executable. It's created on the first start of the application.\n\nIn settings there is a button to open data folder, as well as several data-related commands (clear database, clear thumbnails etc).",
              "score": 1,
              "created_utc": "2026-02-26 09:01:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7gzhoc",
          "author": "Passable_Funf",
          "text": "I like the new name! It sounds good.",
          "score": 2,
          "created_utc": "2026-02-26 06:23:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7jyvdp",
              "author": "error_alex",
              "text": "Thank you! :)",
              "score": 1,
              "created_utc": "2026-02-26 18:02:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7kdtei",
          "author": "Gerweldig",
          "text": "Will check it out! I hope It will have a hot folder.. So you can see the enlarged view of latest images during generation..  It's a rare feature and very handy during a generation run",
          "score": 2,
          "created_utc": "2026-02-26 19:11:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7l6bs4",
              "author": "error_alex",
              "text": "It does soon! I am implementing this as I write because it's an awesome idea that I did not think of!",
              "score": 2,
              "created_utc": "2026-02-26 21:27:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7m41up",
                  "author": "Gerweldig",
                  "text": "You are a hero, sir",
                  "score": 2,
                  "created_utc": "2026-02-27 00:22:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7n0pzd",
          "author": "story_of_the_beer",
          "text": "Does this do recursive folder searches? Or is it mainly for people who dump all their outputs in a single or few folders?",
          "score": 2,
          "created_utc": "2026-02-27 03:31:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nl3mi",
              "author": "error_alex",
              "text": "It can do, yes! There is a toggle to include subfolders.",
              "score": 1,
              "created_utc": "2026-02-27 05:51:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7g5xs2",
          "author": "Far_Let_5678",
          "text": "I like the rebrand. Now it has a unique identity. Less confusing. I actually clicked here out of confusion thinking that the LoRA training AI Toolkit had changed. LOL. Impressive what you've done. Way better than my attempts. Keep building!",
          "score": 3,
          "created_utc": "2026-02-26 03:00:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7jytmj",
              "author": "error_alex",
              "text": "Thank you, glad you like it!",
              "score": 1,
              "created_utc": "2026-02-26 18:02:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7cvbxw",
          "author": "SvenVargHimmel",
          "text": "This looks so much better than the vibecoded slop people have thrown over the fence lately. This code base actually has tests in it.\n\nHere's a tip, the UI looks vibe coded.  I strongly suspect that you leaned on AI for that part. Use the frontend skill from Anthropic, it helps with some of the lazy choices that Gemini,Oput , GPT 5.3 tend to make. \n\nAlso a \"getting started\" section  that gets the user from zero-to-hero will go a long way. ",
          "score": 3,
          "created_utc": "2026-02-25 17:08:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7deq7i",
              "author": "error_alex",
              "text": "Thanks! That really means a lot.\n\nI’m actually a system development student, so I built this on the side specifically to apply what I’ve been learning in class (hence the tests and structure!).\n\nYou totally called it on the UI—this is my first ever project with Vue, so I definitely leaned on AI to help get the frontend off the ground. I’ll check out that Anthropic skill, thanks for the tip! A \"Zero-to-Hero\" guide is a great idea, I'll add that to the roadmap.",
              "score": 3,
              "created_utc": "2026-02-25 18:35:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7dgt6v",
          "author": "Erasmion",
          "text": "keeps getting better - metadata-ai-toolbox-latent-viewer!  best of the bunch.  thank you",
          "score": 2,
          "created_utc": "2026-02-25 18:44:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7dgz3b",
              "author": "error_alex",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2026-02-25 18:45:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7dmjvi",
          "author": "teadog24",
          "text": "Would you consider adding a feature to include custom \"metadata\" in the form of a comment or note? Nano banana doesn't include metadata with the prompt. It would be great to have everything in one place and not rely on Google Sheets.",
          "score": 2,
          "created_utc": "2026-02-25 19:10:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7dms1y",
              "author": "error_alex",
              "text": "That is a great idea! I will add it to the road map.",
              "score": 2,
              "created_utc": "2026-02-25 19:12:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7cyqmk",
          "author": "Justify_87",
          "text": "Does it do image to image compare? Even when zoomed in?",
          "score": 1,
          "created_utc": "2026-02-25 17:23:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7cyvsk",
              "author": "error_alex",
              "text": "Yes it does!",
              "score": 1,
              "created_utc": "2026-02-25 17:24:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7d08u8",
          "author": "the_bollo",
          "text": "Does this support things like filtering a library of images/videos to show just those that used a certain LoRA?",
          "score": 1,
          "created_utc": "2026-02-25 17:30:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7d0tmk",
              "author": "error_alex",
              "text": "Yes it does! You can quickly select a LoRA and filter by it. And you can also make custom Collections with certain filters that will auto-populate with images matching the filters and future images will be added as well. Images only at this moment.",
              "score": 2,
              "created_utc": "2026-02-25 17:33:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7d1y0p",
                  "author": "the_bollo",
                  "text": "I just went to install it on windows - why is it requesting a firewall exception on first run?",
                  "score": 1,
                  "created_utc": "2026-02-25 17:38:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7d18mh",
          "author": "ignorethecirclejerk",
          "text": "Thanks to the OP for creating this, certainly a lot of people could use this tool.\n\n\\-EDITED- I'm assuming this runs entirely locally?",
          "score": 1,
          "created_utc": "2026-02-25 17:35:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7d2g0u",
              "author": "error_alex",
              "text": "Thanks for the kind words!\n\nNo, I have never had \"telemetry\" or any issues like that. It has always been private and local. This is the 4th iteration of this application, and the second one that I've released.\n\nThe first released one is the one I mention in the original release post (link in this post above) which was named \"Metadata Viewer\".",
              "score": 2,
              "created_utc": "2026-02-25 17:40:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7e73ex",
          "author": "VirusCharacter",
          "text": "Downloading....",
          "score": 1,
          "created_utc": "2026-02-25 20:46:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ez2d2",
          "author": "sixstringnerd",
          "text": "Overall, I like it, but would it be possible to add directories or pin directories instead of just defaulting to \"This PC\" and everything under it? My output directories are in a couple of places and at least one is 7 levels down. I don't need/want every directory on my computer to be part of this.\n\nThanks!",
          "score": 1,
          "created_utc": "2026-02-25 23:00:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7hgjqi",
              "author": "error_alex",
              "text": "You can right-click a folder in the Folder tree to pin it!",
              "score": 2,
              "created_utc": "2026-02-26 08:58:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7jlss3",
                  "author": "sixstringnerd",
                  "text": "Thanks! I see that now. I could have sworn I tried, but obviously not.",
                  "score": 1,
                  "created_utc": "2026-02-26 17:02:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7g86eo",
          "author": "Space_Objective",
          "text": "https://preview.redd.it/t480q0klarlg1.png?width=1795&format=png&auto=webp&s=a4cdc615caa46f4d4d94dec6894257251efde030\n\n like this?",
          "score": 1,
          "created_utc": "2026-02-26 03:13:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7g8740",
          "author": "StuccoGecko",
          "text": "waxy skin, yummmm",
          "score": 1,
          "created_utc": "2026-02-26 03:13:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7i4jch",
          "author": "wam_bam_mam",
          "text": "Can this parse invoke and comfy ui meta data. The previous one can do comfy but not income which is a problem for me",
          "score": 1,
          "created_utc": "2026-02-26 12:27:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ifn2r",
              "author": "error_alex",
              "text": "It should! If it is failing to parse your Invoke metadata, I would deeply appreciate it if you could open an issue on the Github with one of the images attached and/or the raw metadata. Thank you!",
              "score": 1,
              "created_utc": "2026-02-26 13:36:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7igytz",
                  "author": "wam_bam_mam",
                  "text": "I will do so",
                  "score": 1,
                  "created_utc": "2026-02-26 13:43:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7rdbph",
          "author": "DawaForensics",
          "text": "The application is not Supported on Mac Intel machines, OS says DMG is not supported.  \nPlease add support for Intel mac !",
          "score": 1,
          "created_utc": "2026-02-27 20:07:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7rdk4e",
              "author": "error_alex",
              "text": "Have you tried the workaround for macOS mentioned in the Readme?",
              "score": 2,
              "created_utc": "2026-02-27 20:08:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7rf18n",
                  "author": "DawaForensics",
                  "text": "I did and it wont launch, but I download the Source Code and I am going to try and compile and run it here. Well done on making it, !!!  its very impressive !\n\n",
                  "score": 2,
                  "created_utc": "2026-02-27 20:15:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7sqe7k",
          "author": "tommyjohn81",
          "text": "How does it compare to Image Metahub which seems to do the same thing and also open-source?\n\nhttps://github.com/LuqP2/Image-MetaHub",
          "score": 1,
          "created_utc": "2026-02-28 00:28:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7utkoy",
              "author": "error_alex",
              "text": "I honestly had no idea Image-MetaHub existed while I was building Latent Library! Looking at it now, they are both great but focus on different workflows. MetaHub looks fantastic if you want to trigger new generations directly from the app or need video/GIF support. \n\nI built my app strictly as a 100% free, lightning-fast organizer for people dealing with massive (10k+) image dumps. If you want a remote-control workflow, MetaHub is a solid choice; if your priority is offline AI-tagging, custom metadata overrides, and pure sorting speed, I'd love for you to give mine a try.",
              "score": 1,
              "created_utc": "2026-02-28 09:51:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7xh5rd",
                  "author": "tommyjohn81",
                  "text": "I've downloaded yours and will give it a spin. I have a 50k+ library of images so I'll see how they compare.",
                  "score": 1,
                  "created_utc": "2026-02-28 19:31:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7fdwe6",
          "author": "VRAMFucker",
          "text": "Im using Stability Matrix is something like that? can I Generate inside the app?",
          "score": 0,
          "created_utc": "2026-02-26 00:22:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7jypvt",
              "author": "error_alex",
              "text": "This application is not for generating images, but instead for organizing your generated images into collections, compare and search for prompts or models you've used.\n\nIt should be compatible with Metadata from Stability Matrix.",
              "score": 2,
              "created_utc": "2026-02-26 18:01:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rhvhmc",
      "title": "[CVPR 2026] ImageCritic: Correcting Inconsistencies in Generated Images!",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1rhvhmc",
      "author": "Creepy_Astronomer_83",
      "created_utc": "2026-03-01 11:55:16",
      "score": 218,
      "num_comments": 32,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rhvhmc/cvpr_2026_imagecritic_correcting_inconsistencies/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o81xrjj",
          "author": "hystericalyouth",
          "text": "Can it fix hands and... other body parts? Asking for a friend",
          "score": 20,
          "created_utc": "2026-03-01 14:05:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o82gcjc",
              "author": "Creepy_Astronomer_83",
              "text": "Our method requires a reference image; given the reference, it can perform local corrections or refinements accordingly.",
              "score": 14,
              "created_utc": "2026-03-01 15:44:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o859kgx",
                  "author": "thrownawaymane",
                  "text": "word choice: level 100",
                  "score": 5,
                  "created_utc": "2026-03-02 00:19:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o821s27",
              "author": "Symbiote69",
              "text": "This is what I want to know",
              "score": 6,
              "created_utc": "2026-03-01 14:28:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o85raqg",
              "author": "KillerX629",
              "text": "\"it's a cylinder\"",
              "score": 1,
              "created_utc": "2026-03-02 02:07:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o81hv3x",
          "author": "Calm_Mix_3776",
          "text": "Does this work in ComfyUI?",
          "score": 24,
          "created_utc": "2026-03-01 12:15:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o81jnha",
              "author": "Creepy_Astronomer_83",
              "text": "We’ll support ComfyUI soon.",
              "score": 55,
              "created_utc": "2026-03-01 12:30:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o81mhb2",
          "author": "Enshitification",
          "text": "Interesting. Is this like Omini-Kontext with a custom LoRA?",
          "score": 6,
          "created_utc": "2026-03-01 12:51:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o81pidn",
              "author": "Creepy_Astronomer_83",
              "text": "yes 🥰",
              "score": 7,
              "created_utc": "2026-03-01 13:12:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o81qr2b",
                  "author": "Enshitification",
                  "text": "Nice. Maybe this project could be modified a bit to run it in ComfyUI?     \nhttps://github.com/tercumantanumut/ComfyUI-Omini-Kontext",
                  "score": 6,
                  "created_utc": "2026-03-01 13:21:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o81mhf7",
          "author": "Occsan",
          "text": "Would that also work with Klein 4B/9B ?",
          "score": 6,
          "created_utc": "2026-03-01 12:51:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o81n6g3",
              "author": "Enshitification",
              "text": "It seems to work as a post process using Flux Kontext with a custom image encoder and Kontext LoRA. It should work with anything.",
              "score": 10,
              "created_utc": "2026-03-01 12:56:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o81pdyz",
                  "author": "Creepy_Astronomer_83",
                  "text": "Yes — this can be used as a post-processor for reference-image-based outputs from any model.",
                  "score": 10,
                  "created_utc": "2026-03-01 13:12:09",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o81v3ok",
          "author": "silver_404",
          "text": "Really nice, I was looking for this :) can't wait for a comfyui integration ! Thank you",
          "score": 5,
          "created_utc": "2026-03-01 13:49:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o825hz9",
          "author": "Aromatic-Word5492",
          "text": "waiting for comfyui support",
          "score": 8,
          "created_utc": "2026-03-01 14:49:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o81qmhz",
          "author": "Damilino",
          "text": "Does it also correct for example backgrounds to look consistant?",
          "score": 2,
          "created_utc": "2026-03-01 13:20:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o81qzdi",
              "author": "Creepy_Astronomer_83",
              "text": "https://preview.redd.it/00stqlpxpfmg1.png?width=1615&format=png&auto=webp&s=4196c4dfd241f89b70b2a7e232f8777d3809caf1\n\nYes, you can check the example in the second figure.",
              "score": 6,
              "created_utc": "2026-03-01 13:22:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o81u69v",
          "author": "anitman",
          "text": "Pretty sweet, it seems that I can use it to fix the deteriorated texts or patterns generated by sdxl or illustrious. ",
          "score": 2,
          "created_utc": "2026-03-01 13:43:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o84d8ll",
              "author": "Winter_unmuted",
              "text": "Or SeedVR2, hopefully. I've been using that to restore really old photos from the mid-00s early social media days and the biggest downside has been completely garbled text.",
              "score": 1,
              "created_utc": "2026-03-01 21:20:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o8516vc",
          "author": "Both-Rub5248",
          "text": "Is it possible to run this instrument based on Flux 2 Klein 9B instead of Flux 1 Kontext?\n\nThis would allow the instrument to run on weaker hardware and presumably speed up generation time if Flux 2 Klein Distill is used. ",
          "score": 2,
          "created_utc": "2026-03-01 23:30:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o85b8ry",
              "author": "Both-Rub5248",
              "text": "Is it possible to configure the tool so that it works with standard compressed Text Encoder and Diffuser Model as we are used to in ComfyUi, conditionally working through the collected Flux\\_2\\_Klein\\_9b.Safetensors files?",
              "score": 1,
              "created_utc": "2026-03-02 00:29:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o834et1",
          "author": "New-Addition8535",
          "text": "Looks great.. Please add comfyui support",
          "score": 3,
          "created_utc": "2026-03-01 17:40:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o82mk9b",
          "author": "Plane-Marionberry380",
          "text": "The hand question in the comments is the real test. Most post-processing approaches work great for lighting/color inconsistencies but structural stuff like extra fingers is harder because it requires understanding the original intent. Does ImageCritic use the prompt as a reference when making corrections, or is it purely visual?",
          "score": 1,
          "created_utc": "2026-03-01 16:14:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o82q67o",
              "author": "Creepy_Astronomer_83",
              "text": "Not only lighting/color is involved — we mainly focus on ***consistency*** **issues** from the reference image (logos, characters, and so on). Also, our method is a reference-image-based consistency repair approach: as long as a reference image is provided, it can fix hands or other specific regions.",
              "score": 1,
              "created_utc": "2026-03-01 16:32:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o8361ej",
          "author": "VasaFromParadise",
          "text": "Where are the normal models?)) Now, for models with 30 billion parameters, they should also use lore for clarity))",
          "score": 1,
          "created_utc": "2026-03-01 17:48:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o84c7f6",
          "author": "bloke_pusher",
          "text": "Underrated, I think this would be quite useful in comfyui. Hopefully I don't miss it when someone managed to integrate it.",
          "score": 1,
          "created_utc": "2026-03-01 21:15:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o84guze",
          "author": "fewjative2",
          "text": "Cool idea, thanks for sharing!",
          "score": 1,
          "created_utc": "2026-03-01 21:39:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o81qq01",
          "author": "InoSim",
          "text": "Easy way: promptiong errors  \nDifficult way: Using a Qwen image edit like workflow.  \nOriginal way: correct it yourself with right tools.",
          "score": 0,
          "created_utc": "2026-03-01 13:21:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o81sqog",
              "author": "Creepy_Astronomer_83",
              "text": "Haha, you’re more than welcome to try it out.",
              "score": 1,
              "created_utc": "2026-03-01 13:34:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rhysnd",
      "title": "I need to buy 5090... for games...",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/bxvh10juqfmg1.png",
      "author": "SecureLevel5657",
      "created_utc": "2026-03-01 14:35:54",
      "score": 212,
      "num_comments": 31,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rhysnd/i_need_to_buy_5090_for_games/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o82j0nk",
          "author": "cookieGaboo24",
          "text": "Just saying, you can get the same images n comfy on something like a 3060 12gh in 3 sec too. But game is game, and I like the way you think.",
          "score": 35,
          "created_utc": "2026-03-01 15:57:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o848w1t",
              "author": "Temporary_Maybe11",
              "text": "But wan..",
              "score": 4,
              "created_utc": "2026-03-01 20:58:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o8499bl",
                  "author": "cookieGaboo24",
                  "text": "480p, 2s + X2 Interpolation Takes me 80 seconds with wan2.2. For that specific use case yes, go for it.",
                  "score": 1,
                  "created_utc": "2026-03-01 21:00:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o82f2r4",
          "author": "Top_Effect_5109",
          "text": "Huh, games would also be a evolutionary trap.",
          "score": 26,
          "created_utc": "2026-03-01 15:38:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o82fvre",
              "author": "Zealousideal7801",
              "text": "I can confirm they are, but to the limit that their dopamine release potential isn't exceeded by user consumption, or by developper stupidity.\n\nNSFW SDXL on the other hand, is forever.\n\n(Pun not intended with \"the other hand\" but still think it's funny)",
              "score": 9,
              "created_utc": "2026-03-01 15:42:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o8326ib",
              "author": "SecureLevel5657",
              "text": "at least in games i can interact with others with voice chat, join local communities, go outside and maybe find a partner who also likes games. I don't think that is possible with 1TB of thousands of waifus and sdxl models",
              "score": 2,
              "created_utc": "2026-03-01 17:29:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o83loyp",
                  "author": "Top_Effect_5109",
                  "text": ">I don't think that is possible with 1TB of thousands of waifus and sdxl models\n\nYou could do that like in the movie Her, but imo for me to comment on that would be like a neanderthal commenting on geopolitics of today. But I will go ahead anyways, looking at it unvigorously, its seems both systems have the same pull rates for happiness and depression. And the faux empathy self-aggrandizing horde makes any conversation about this insufferable. Thoughts and prayers! 😘\n\nI critize games a lot. We know the [number of close friends](https://www.statista.com/statistics/1358672/number-of-close-friends-us-adults/?utm_source=chatgpt.com) has been declining sharply while the number of games look like they have been increasing exponentially. So either its impact of games on relationships are negative, nuetral, or so low other aspects are blowing its benefits out of the water. If you look how shit people its clear people will use anything as canon fodder for emotional abuse. Console wars is a tame example and I have seen worse. On the bus I overheard two  alt rock girls say they should start rumours of a girl because she liked  a specfic subgenre of punk they did not. It was the most brain dead High School crap ever.\n\nBut this converation has gone way past about stable diffusion.",
                  "score": 3,
                  "created_utc": "2026-03-01 19:00:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o82qia4",
          "author": "LostGeezer2025",
          "text": "We've solved the Fermi Paradox :(",
          "score": 20,
          "created_utc": "2026-03-01 16:33:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o84garm",
              "author": "ILikeChilis",
              "text": "I know this is a joke comment, but a virtual reality \"pleasure dome\" kind of civilisation dead-end was proposed as one of the possible solutions to the paradox.",
              "score": 6,
              "created_utc": "2026-03-01 21:36:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o82o3xr",
          "author": "Equal_Passenger9791",
          "text": "You don't really need to go all the way to a 5090 if you're just doing boner pleasing image gen with how the local ecosystem is today. Maybe more useful for video gen.",
          "score": 16,
          "created_utc": "2026-03-01 16:22:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o832t2x",
              "author": "SecureLevel5657",
              "text": "I got bored of simple ai pics. Need detailer, face and hand fix and llm model that generates prompts. All this increased generation time from 20 sec to 5 mins :D",
              "score": 8,
              "created_utc": "2026-03-01 17:32:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o83agzd",
          "author": "Maleficent_Ad5697",
          "text": "I use 5060Ti and also got addicted to NSFW SDXL xd hell of a drug",
          "score": 5,
          "created_utc": "2026-03-01 18:08:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o82rai8",
          "author": "BogusIsMyName",
          "text": "I was more than happy with my 3080ti.... But then i got comfyui.",
          "score": 8,
          "created_utc": "2026-03-01 16:37:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o83crjw",
          "author": "tr-otaku-tr",
          "text": "Try sam3 + sdxl inpaint nsfw, You won't regret it",
          "score": 3,
          "created_utc": "2026-03-01 18:19:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o851j2q",
              "author": "nognig6969",
              "text": "Please elaborate, what does that do?",
              "score": 2,
              "created_utc": "2026-03-01 23:32:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o85uzsc",
                  "author": "tr-otaku-tr",
                  "text": "Selects clothes with most powerfull SegmentAnything Model (SAM3 is absolutely powerfull, I'm just using \"clothes\"), and with Nsfw sdxl inpaint (I'm using cyberrealistic XL V8.0 inpaint) it makes it nude, for real it deletes clothes, it's too realistic at reccomending settings, I got best results in 832x1216 photos, I even used DMD2 and no value loss at all",
                  "score": 1,
                  "created_utc": "2026-03-02 02:29:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o83cukg",
          "author": "Succubus-Empress",
          "text": "Can i suggust B200?",
          "score": 2,
          "created_utc": "2026-03-01 18:19:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o842157",
          "author": "d20diceman",
          "text": "[If I don't keep my eyes closed, all I see are the walls](https://qchu.substack.com/p/slaanesh) \n\n\nThe prequel, [Pygma Male](https://substack.com/@qchu/p-150396223), is even more on-the-nose. ",
          "score": 2,
          "created_utc": "2026-03-01 20:22:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o84m6qb",
          "author": "BM09",
          "text": "\"Beetle beer goggles\"\n\n🤣😂🤣😂🤣😂🤣😂",
          "score": 2,
          "created_utc": "2026-03-01 22:06:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o84v2xy",
          "author": "Significant-Baby-690",
          "text": "Guy cries for help, all he gets is bros flexing their HW specs.",
          "score": 2,
          "created_utc": "2026-03-01 22:55:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o854mjl",
          "author": "NockBreaker",
          "text": "Train a Lora\n\nGenerate a million images of that NSFW\n\nGrant an AI access to that folder\n\nHave AI adopt persona of that NSFW\n\nHook AI replies to a text-to-voice\n\nHave AI choose image to show that closely matches it's reply\n\nTranscribe your reply through voice-to-text entered as response to the AI",
          "score": 2,
          "created_utc": "2026-03-01 23:50:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o83a3e1",
          "author": "jib_reddit",
          "text": "You don't really need a 5090 for SDXL (my 3090 is plenty fast enough for that) , WAN 2.2 videos? now we are talking...",
          "score": 3,
          "created_utc": "2026-03-01 18:07:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o83yyjp",
              "author": "BaronVonAwesome007",
              "text": "My 3080ti manages WAN 2.2 no issues, usually takes around 250 seconds to generate 201 frames",
              "score": 0,
              "created_utc": "2026-03-01 20:07:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o843i8u",
                  "author": "jib_reddit",
                  "text": "Waiting nearly 5 mins for 7 seconds of video just seems like a long time to me, I don't like using any of the speed loras as they effect movement and I like to use high steps and resolution so it ends up taking a lot longer.",
                  "score": 3,
                  "created_utc": "2026-03-01 20:30:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o83mj8e",
          "author": "ByIeth",
          "text": "Honestly I’d only get a 5090 if you seriously want to do video generation. But my 4080 could generate something like this extremely fast",
          "score": 2,
          "created_utc": "2026-03-01 19:04:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o85a7io",
          "author": "Shopping_Temporary",
          "text": "i dont see the prompt...",
          "score": 1,
          "created_utc": "2026-03-02 00:23:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o85lqt5",
          "author": "blastcat4",
          "text": "The junk food picture is really doing me in. Is it showing the insides of a bird and what it ate?",
          "score": 1,
          "created_utc": "2026-03-02 01:32:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o85u99y",
          "author": "JMpickles",
          "text": "Ive been out of the game for a while is sdxl still top nsfw?? Have we not advanced",
          "score": 1,
          "created_utc": "2026-03-02 02:25:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1re4rp8",
      "title": "Last week in Image & Video Generation",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1re4rp8/last_week_in_image_video_generation/",
      "author": "Vast_Yak_4147",
      "created_utc": "2026-02-25 05:39:40",
      "score": 207,
      "num_comments": 14,
      "upvote_ratio": 0.99,
      "text": "I curate a weekly multimodal AI roundup, here are the open-source image & video highlights from last week(a day late but still good):\n\n**BiTDance - 14B Autoregressive Image Model**\n\n* A 14B parameter autoregressive image generation model.\n* [Hugging Face](https://huggingface.co/shallowdream204/BitDance-14B-16x/tree/main)\n\nhttps://preview.redd.it/8snkdmimtklg1.png?width=2500&format=png&auto=webp&s=53636075d9f8232ab06b54e085c6392b81c82e7e\n\nhttps://preview.redd.it/grmzd9hltklg1.png?width=5209&format=png&auto=webp&s=8a68e7aa408dfa2a9bfe752c0f2457ec2c364269\n\n**LTX-2 Inpaint - Custom Crop and Stitch Node**\n\n* New node from jordek that simplifies the inpainting workflow for LTX-2 video, making it easier to fix specific regions in a generated clip.\n* [Pos](https://www.reddit.com/r/StableDiffusion/comments/1r6s2f7/ltx2_inpaint_update_new_custom_crop_and_stitch/)t\n\nhttps://reddit.com/link/1re4rp8/video/5u115igwuklg1/player\n\n**LoRA Forensic Copycat Detector**\n\n* JackFry22 updated their LoRA analysis tool with forensic detection to identify model copies.\n* [Post](https://www.reddit.com/r/StableDiffusion/comments/1r8clyn/i_updated_my_lora_analysis_tool_with_a_forensic/)\n\nhttps://preview.redd.it/x17l4hrmuklg1.png?width=1080&format=png&auto=webp&s=aa99fe291d683d848eaff85943d2d9086cc7bbaf\n\n**ZIB vs ZIT vs Flux 2 Klein - Side-by-Side Comparison**\n\n* Both-Rub5248 ran a direct comparison of three current models. Worth reading before you decide what to run next.\n* [Post](https://www.reddit.com/r/StableDiffusion/comments/1rboeta/zib_vs_zit_vs_flux_2_klein/)\n\nhttps://preview.redd.it/iwqpwnbluklg1.png?width=1080&format=png&auto=webp&s=f362ed3d469cfe7d8ad0c5c1e8ff4a451dc17ec7\n\n**AudioX - Open Research: Anything-to-Audio**\n\n* Unified model that generates audio from any input modality: text, video, image, or existing audio.\n* Full paper and project demo available.\n* [Project Page](https://zeyuet.github.io/AudioX/)\n\nhttps://reddit.com/link/1re4rp8/video/53lw9bdjuklg1/player\n\n# Honorable mention:\n\n**DreamDojo - Open-Source Robot World Model (NVIDIA)**\n\n* NVIDIA released this open-source world model that takes motor controls and generates the corresponding visual output.\n* Robots practice tasks in a simulated visual environment before real-world deployment, no physical hardware needed for training.\n* [Project Page](https://dreamdojo-world.github.io)\n\nhttps://reddit.com/link/1re4rp8/video/35ibi7mhvklg1/player\n\n**Vec2Pix - Edit Photos via Vector Shapes(\"Code Coming Soon\")**\n\n* Edit images by manipulating vector shapes instead of working at the pixel level.\n* [Project Page](https://guolanqing.github.io/Vec2Pix/)\n\nhttps://preview.redd.it/iun918s1uklg1.jpg?width=2072&format=pjpg&auto=webp&s=7ddd6061a9c60512a068839df73fd94b53239952\n\nCheckout the [full roundup](https://open.substack.com/pub/thelivingedge/p/last-week-in-multimodal-ai-46-thinking?utm_campaign=post-expanded-share&utm_medium=post%20viewer) for more demos, papers, and resources.",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1re4rp8/last_week_in_image_video_generation/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "o7ak8o3",
          "author": "Gh0stbacks",
          "text": "Will you do this for every week?",
          "score": 15,
          "created_utc": "2026-02-25 08:21:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ba3bl",
              "author": "Vast_Yak_4147",
              "text": "Yep, I usually post these roundups every Monday but was delayed this week. ",
              "score": 29,
              "created_utc": "2026-02-25 12:10:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7eyqhl",
                  "author": "Erasmion",
                  "text": "great read - thank you",
                  "score": 4,
                  "created_utc": "2026-02-25 22:59:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7ajwci",
          "author": "LSI_CZE",
          "text": "Thank's for report",
          "score": 8,
          "created_utc": "2026-02-25 08:18:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7b8xmg",
          "author": "Alisomarc",
          "text": "![gif](giphy|OKvq25SbsTURpQOSWS)\n\nwe need things like that, thankyou",
          "score": 8,
          "created_utc": "2026-02-25 12:01:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ddwwj",
          "author": "ANR2ME",
          "text": "That AudioX looks interesting 😯 unfortunately, the license is for non-commercial only.",
          "score": 6,
          "created_utc": "2026-02-25 18:32:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7avrkq",
          "author": "Lazy_Lime419",
          "text": "Thank's for report",
          "score": 3,
          "created_utc": "2026-02-25 10:09:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bqpx5",
          "author": "Motor_Mix2389",
          "text": "Very nice work. Keep at it. Always good to have a short summary of the latest and greatest, its all moving so fast, its really hard to keep track of it all.",
          "score": 3,
          "created_utc": "2026-02-25 13:52:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7c58qd",
          "author": "KillerX629",
          "text": "how does BiTDance compare to flux2?",
          "score": 3,
          "created_utc": "2026-02-25 15:07:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7gmbvy",
          "author": "TopTippityTop",
          "text": "Doing God's work here — thank you!",
          "score": 3,
          "created_utc": "2026-02-26 04:44:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7i96pw",
          "author": "Hearcharted",
          "text": "**Waiting for AudioX - Anything-to-Audio on ComfyUI / Google Colab...**",
          "score": 3,
          "created_utc": "2026-02-26 12:58:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7c3dad",
          "author": "fluce13",
          "text": "Thank you!",
          "score": 2,
          "created_utc": "2026-02-25 14:58:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7k5jgp",
          "author": "lynch1986",
          "text": "noice, thanks.",
          "score": 2,
          "created_utc": "2026-02-26 18:33:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7a6dup",
          "author": "YeahlDid",
          "text": "Interesting stuff!",
          "score": 2,
          "created_utc": "2026-02-25 06:18:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rdgeam",
      "title": "Wan 2.2 Video Reasoning Model (Apache 2.0)",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1rdgeam/wan_22_video_reasoning_model_apache_20/",
      "author": "LowYak7176",
      "created_utc": "2026-02-24 13:35:26",
      "score": 204,
      "num_comments": 78,
      "upvote_ratio": 0.99,
      "text": "[https://huggingface.co/Video-Reason/VBVR-Wan2.2](https://huggingface.co/Video-Reason/VBVR-Wan2.2)  \n[https://huggingface.co/Kijai/WanVideo\\_comfy/tree/main/LoRAs/VBVR](https://huggingface.co/Kijai/WanVideo_comfy/tree/main/LoRAs/VBVR)  \n[https://video-reason.com/](https://video-reason.com/)  \nBenji AI Playground explaining it:  \n[https://www.youtube.com/watch?v=kFgU0tgYUl8](https://www.youtube.com/watch?v=kFgU0tgYUl8)",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rdgeam/wan_22_video_reasoning_model_apache_20/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "o74tudo",
          "author": "martinerous",
          "text": "Interesting stuff. I wish there was also an LTX2 reasoning LoRA. It needs reasoning improvement so badly. Wan2.2 is better by default already.\n\nHowever, their demo website examples are too abstract - only diagrams and drawings. No good tests to see how it affects real-life awareness (walking through doors, putting on clothes etc.)",
          "score": 41,
          "created_utc": "2026-02-24 13:38:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o762i60",
              "author": "Eisegetical",
              "text": "![gif](giphy|e87a8PIiFU03nleRsz)\n\n\"pulling on clothes\" ",
              "score": 58,
              "created_utc": "2026-02-24 17:12:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o76pb1r",
                  "author": "No_Boysenberry4825",
                  "text": "https://www.theguardian.com/politics/shortcuts/2017/jun/27/whats-in-a-wink-lessons-from-clinton-corbyn-and-rihanna#img-3",
                  "score": -5,
                  "created_utc": "2026-02-24 18:54:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o760msx",
              "author": "Dzugavili",
              "text": "Yeah, LTX has fantastic motion and the quality is stellar; but you need to prompt the hell out of it and it will begin to blend actions together if you need a complex sequence. Reducing the prompt load with internal reasoning could be the key to solving a lot of LTX's misfires.\n\nThe WAN base model seems to have a greater understanding of scenario, where as LTX seems to have been trained on actions. But that also means it tends to tunnel to solutions more aggressively, which this lora hopes to fix.",
              "score": 2,
              "created_utc": "2026-02-24 17:04:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o77gg15",
                  "author": "deadsoulinside",
                  "text": "> Yeah, LTX has fantastic motion and the quality is stellar; but you need to prompt the hell out of it and it will begin to blend actions together if you need a complex sequence. \n\nI need to figure out that kungfu then. Seems I cannot have camera rotation or human rotation without it blending across things.",
                  "score": 3,
                  "created_utc": "2026-02-24 20:59:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7aep2g",
              "author": "Infninfn",
              "text": "It's specifically for screen display awareness in 2d. ",
              "score": 1,
              "created_utc": "2026-02-25 07:30:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o771cwg",
          "author": "Cultural-Team9235",
          "text": "Didn't test it thoroughly but it's definitely smarter, it seems to understand the consequences of the actions better, even with a small prompt.\n\nI had a picture of someone on the couch, with a cup of coffee in front of her on a news paper. My prompt was to pick it us as the coffee fell over. Without reasoning the spoon on the table was stuck to the paper, with reasoning it fell off the paper. \n\nSmall stuff but very cool to see these kind of improvements are possible. Just wow. I'm very curious where it leads from here. ",
          "score": 8,
          "created_utc": "2026-02-24 19:49:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77hues",
              "author": "Cultural-Team9235",
              "text": "A few tests later... Sometimes it's get better, sometimes it gets worse with reasoning. Will test more, fun stuff!",
              "score": 5,
              "created_utc": "2026-02-24 21:06:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o758agm",
          "author": "kkb294",
          "text": "Can someone ELI5.?",
          "score": 12,
          "created_utc": "2026-02-24 14:54:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75faae",
              "author": "YeahlDid",
              "text": "Smart people make video moving better maybe.",
              "score": 36,
              "created_utc": "2026-02-24 15:27:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o85rq3b",
                  "author": "itchy_buthole",
                  "text": "Thanks for this",
                  "score": 1,
                  "created_utc": "2026-03-02 02:09:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o76yguh",
                  "author": "alb5357",
                  "text": "Nice so is wan better than ltx again?",
                  "score": 1,
                  "created_utc": "2026-02-24 19:36:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o764kzg",
              "author": "tankdoom",
              "text": "A first frame last frame video model that takes an input and expected result. The video output attempts to obey physics and follow logical rules to get to the desired output. \n\nIt seems potentially like it was trained on simple logic puzzles. But the model could help generate outputs that better obey the laws of physics. \n\nFor instance, you might say “solve the maze” with a first and last frame. One where the maze is unsolved and another where the maze is solved. And the video will show the correct path through the maze.",
              "score": 12,
              "created_utc": "2026-02-24 17:22:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o752rvw",
          "author": "tcdoey",
          "text": "That 'person' in the corner, and the not good AI voice.\n\nI don't get it, why do that? It just makes the whole video, which was interesting, instead really hard to watch. It kind of made me nauseous.",
          "score": 10,
          "created_utc": "2026-02-24 14:26:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o757jy9",
              "author": "ThatsALovelyShirt",
              "text": "Pretty sure they guy is 'real', but they don't speak english, so they used one of those (bad) AI translating/dubbing services or models to convert their speech into english.",
              "score": 3,
              "created_utc": "2026-02-24 14:50:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o75ar1g",
                  "author": "Famous-Sport7862",
                  "text": "Benji  is Chinese, he doesn't speak English, that's why the ai voice. But his videos are really good. And that person is not him, that's just an avatar, he uses different avatar in other videos",
                  "score": 15,
                  "created_utc": "2026-02-24 15:06:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o75vgr2",
                  "author": "Timboman2000",
                  "text": "I'd kind of just prefer text on the screen over the AI dubbed voice and fake avatar in the corner, it basically made me close the video after listening to it for 10 seconds.",
                  "score": 2,
                  "created_utc": "2026-02-24 16:41:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o75cbbi",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 1,
                  "created_utc": "2026-02-24 15:13:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o75zoqg",
                  "author": "Grand0rk",
                  "text": "Which is ironic. Using shit AI voice on video about AI Video.",
                  "score": 1,
                  "created_utc": "2026-02-24 16:59:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o77l2ql",
              "author": "terrariyum",
              "text": "agree, but youtube algo demand face.  creators gotta do what they gotta do",
              "score": 1,
              "created_utc": "2026-02-24 21:20:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o78rpcm",
                  "author": "tcdoey",
                  "text": "Thanks, didn't know that.",
                  "score": 2,
                  "created_utc": "2026-02-25 00:59:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o77thzd",
          "author": "cavaliersolitaire",
          "text": "Benji DO NOT use the ai avatar",
          "score": 3,
          "created_utc": "2026-02-24 21:59:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7846dd",
          "author": "MartinByde",
          "text": "Can I run it in a 4080? \nAnd can it make porn?",
          "score": 3,
          "created_utc": "2026-02-24 22:52:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74wmu1",
          "author": "Time-Teaching1926",
          "text": "Genuine question, could we get a LORA like this but for image models like Z image, Flux and Anima and Illustrious... And would it even work?\n\nLooks really interesting.",
          "score": 5,
          "created_utc": "2026-02-24 13:53:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76q2w3",
              "author": "Tyler_Zoro",
              "text": "> could we get a LORA like this\n\nYou can't implement reasoning capabilities as a LoRA.",
              "score": 3,
              "created_utc": "2026-02-24 18:57:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o773n6j",
                  "author": "JazzlikeLeave5530",
                  "text": "https://www.reddit.com/r/StableDiffusion/comments/1rdkr3n/kijais_lora_for_wan22_video_reasoning_model\n\n🤔",
                  "score": 3,
                  "created_utc": "2026-02-24 19:59:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o75zklt",
              "author": "COMPLOGICGADH",
              "text": "It's a ongoing research field and experimental,few latest examples of new local image models are omnigen2 and deepgen1 (high experimental 5B model),lora is most likely not possible to achieve this it is it's own diffrent architecture...",
              "score": 1,
              "created_utc": "2026-02-24 16:59:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o765019",
          "author": "broadwayallday",
          "text": "Wow at all these noobs complaining about Benji who has been a mainstay in learning this stuff for years now. Lame",
          "score": 6,
          "created_utc": "2026-02-24 17:23:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75v0tj",
          "author": "Justify_87",
          "text": "[https://huggingface.co/Kijai/WanVideo\\_comfy/tree/main/LoRAs/VBVR](https://huggingface.co/Kijai/WanVideo_comfy/tree/main/LoRAs/VBVR)",
          "score": 4,
          "created_utc": "2026-02-24 16:39:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7657ru",
              "author": "LowYak7176",
              "text": "Thanks, added it to the main body ",
              "score": 1,
              "created_utc": "2026-02-24 17:24:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7uc509",
          "author": "No_Progress_5160",
          "text": "Very interesting. I see that the model benchmarks really stands out.\n\nCan i use only lora on the classic WAN2.2 I2V model?",
          "score": 2,
          "created_utc": "2026-02-28 07:09:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o754crl",
          "author": "pmp22",
          "text": "Very cool! Visual reasoning and world models were both big advancements, this feels like a logical direction to go. At some point, surely, all modalities will converge.",
          "score": 2,
          "created_utc": "2026-02-24 14:34:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74ym80",
          "author": "Dzugavili",
          "text": "The AI guy in the bottom right is a hat-on-a-hat.",
          "score": 4,
          "created_utc": "2026-02-24 14:04:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o764v17",
          "author": "Grand0rk",
          "text": "So... Is this better than default Wan 2.2?",
          "score": 2,
          "created_utc": "2026-02-24 17:23:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7554l0",
          "author": "Violent_Walrus",
          "text": "TIL to never try to watch another video from Benji’s AI Playground.",
          "score": 3,
          "created_utc": "2026-02-24 14:38:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74zov2",
          "author": "Dirty_Dragons",
          "text": "What I really want is for the first frame last frame model to determine when a change isn't important and just gloss over it.\n\nRight now if a bedroom scene has a lamp on a nightstand on the last frame and it's not there on the first, the model will go as far as generating a random person to walk into the room and place a lamp down and then leave. Or if the wall color is different, it will have somebody throw paint. I've seen the weirdest reasons to justify a minor change I just don't care about.",
          "score": 2,
          "created_utc": "2026-02-24 14:10:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7541a7",
              "author": "altoiddealer",
              "text": "Could probably avoid these things by just prompting a bit better like, the camera pans right revealing lamp on dresser etc",
              "score": 2,
              "created_utc": "2026-02-24 14:32:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o754nf8",
                  "author": "Dirty_Dragons",
                  "text": "The thing is I don't care about the lamp. I wasn't even aware of it's existence until Wan made it dramatically appear.",
                  "score": 3,
                  "created_utc": "2026-02-24 14:36:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o77ud5r",
          "author": "EternalBidoof",
          "text": "So does this only work with FFLF? I never use last frame in my workflows, I like to start with a single frame and let the AI do what it will with the prompt. Will this lora have any effect without a last frame?",
          "score": 1,
          "created_utc": "2026-02-24 22:03:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7cglxt",
          "author": "MahaVakyas001",
          "text": "how do we use this in ComfyUI? Just download the LoRA? can it do I2V properly?",
          "score": 1,
          "created_utc": "2026-02-25 16:01:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7yi5bg",
          "author": "Extension_Affect_483",
          "text": "Bear sorting marbles using Wan reasoning model\n\nhttps://preview.redd.it/7uo54t2hebmg1.jpeg?width=1024&format=pjpg&auto=webp&s=a8a026ecc85efc68f8fc6ee741e8c72c8b5c87f4\n\n[https://x.com/GKArtist\\_/status/2027870075202502888?s=20](https://x.com/GKArtist_/status/2027870075202502888?s=20)\n\n[https://youtube.com/shorts/jb\\_mVmfhVAs?feature=share](https://youtube.com/shorts/jb_mVmfhVAs?feature=share)",
          "score": 1,
          "created_utc": "2026-02-28 22:50:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o85usok",
          "author": "ShimmerMeNutz",
          "text": "Great leap forward for wan 2.2, but I won't support any of that Benji guys content.  I joined his patreon and left like a month and half later because I had to purge a lot of accounts I wasn't using.  I went back to join his patreon when I had a new project I was working on and it said \"user has blocked you\".  Like who does that?  Joining and leaving patreons is really common.  What a big ass baby.",
          "score": 1,
          "created_utc": "2026-03-02 02:28:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7609w8",
          "author": "Valtared",
          "text": "So does it have practical use for us in comfyUI workflows ? If I add the high Lora to my wf it will get better results ? Only in FL2LF ?",
          "score": 1,
          "created_utc": "2026-02-24 17:02:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77aj0s",
              "author": "Front_Eagle739",
              "text": "Seems to give me better prompt adherence in wan t2i, t2v and i2v without a last frame. Just add the Kijai lora to the high noise side, maybe increase the high steps and see what happens",
              "score": 1,
              "created_utc": "2026-02-24 20:32:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o760lg6",
          "author": "Odd-Mirror-2412",
          "text": "It's interesting!",
          "score": 1,
          "created_utc": "2026-02-24 17:03:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o761734",
          "author": "z3rO_1",
          "text": "Is there a not huggingface link to this? I want to try it, but huggingface is the Cruelty Squad of AI, and it isn't on CivitAI, yet.",
          "score": 1,
          "created_utc": "2026-02-24 17:06:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76xndl",
              "author": "Toclick",
              "text": ">huggingface is the Cruelty Squad of AI,\n\nWhy?",
              "score": 2,
              "created_utc": "2026-02-24 19:32:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o779rpj",
                  "author": "z3rO_1",
                  "text": "It is incomprehensible to anyone who isn't \"in the club\" already.",
                  "score": 0,
                  "created_utc": "2026-02-24 20:28:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o769uxr",
          "author": "hidden2u",
          "text": "interested to see how this turns out, but I Iike that their VBVR model is top ranked in their own VBVR benchmark lmao",
          "score": 1,
          "created_utc": "2026-02-24 17:46:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75jz1f",
          "author": "GifCo_2",
          "text": "a Lora can not add reasoning to a non reasoning model. This seems stupid",
          "score": -2,
          "created_utc": "2026-02-24 15:49:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77levt",
              "author": "terrariyum",
              "text": "Are you sure that you're smarter than all of these actual scientists?\n\nMaijunxian Wang, Ruisi Wang, Juyi Lin, Ran Ji, Thaddäus Wiedemer, Qingying Gao, Dezhi Luo, Yaoyao Qian, Lianyu Huang, Zelong Hong, Jiahui Ge, Qianli Ma, Hang He, Yifan Zhou, Lingzi Guo, Lantao Mei, Jiachen Li, Hanwen Xing, Tianqi Zhao, Fengyuan Yu, Weihang Xiao, Yizheng Jiao, Jianheng Hou, Danyang Zhang, Pengcheng Xu, Boyang Zhong, Zehong Zhao, Gaoyun Fang, John Kitaoka, Yile Xu, Hua Xu, Kenton Blacutt, Tin Nguyen, Siyuan Song, Haoran Sun, Shaoyue Wen, Linyang He, Runming Wang, Yanzhi Wang, Mengyue Yang, Ziqiao Ma, Raphaël Millière, Freda Shi, Nuno Vasconcelos, Daniel Khashabi, Alan Yuille, Yilun Du, Ziming Liu, Bo Li, Dahua Lin, Ziwei Liu, Vikash Kumar, Yijiang Li, Lei Yang, Zhongang Cai, Hokin Deng",
              "score": 16,
              "created_utc": "2026-02-24 21:22:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o780ilb",
                  "author": "GifCo_2",
                  "text": "Did you read the paper those names are attached to?",
                  "score": 1,
                  "created_utc": "2026-02-24 22:33:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7507w0",
          "author": "repezdem",
          "text": "Ugh we cant even get a video of a human being explaining this? I can't handle the fake dude in the corner with the horrible AI voice.",
          "score": -6,
          "created_utc": "2026-02-24 14:13:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75ib7s",
              "author": "Choowkee",
              "text": "There are two websites linked explaining the concept. Reading is really not that hard.",
              "score": 4,
              "created_utc": "2026-02-24 15:41:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o754gnr",
              "author": "klop2031",
              "text": "Yeah that voice made me turn it off. Also they should write more on their organization card",
              "score": 0,
              "created_utc": "2026-02-24 14:35:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7625bf",
              "author": "Naive-Kick-9765",
              "text": "Ask your mama.",
              "score": -1,
              "created_utc": "2026-02-24 17:10:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o75735o",
          "author": "tcdoey",
          "text": "Test comment, something's not working on my reddit.\n\nAlso couldn't stand watching that video, it was interesting stuff, but that AI person made me feel nauseous.",
          "score": 0,
          "created_utc": "2026-02-24 14:48:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rfijze",
      "title": "Our next open source AI art competition will begin this Sunday; deadline March 31 - you have a month to push yourself + open models to their limits!",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/h3typhohwvlg1",
      "author": "PetersOdyssey",
      "created_utc": "2026-02-26 18:43:39",
      "score": 175,
      "num_comments": 11,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rfijze/our_next_open_source_ai_art_competition_will/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7kdvtv",
          "author": "KayBro",
          "text": "Who needs $50K when you have 10lbs of Tolblerone!? Looking forward to it!",
          "score": 8,
          "created_utc": "2026-02-26 19:11:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ke9vn",
              "author": "PetersOdyssey",
              "text": "This has always been my philosophy and it's served me well",
              "score": 6,
              "created_utc": "2026-02-26 19:13:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7lr1gg",
          "author": "yeahwhynot_",
          "text": "> Community members: Banodoco owners (long-time contributors to the open source AI art community) receive a 3× voting multiplier to reward those who've been building this ecosystem\n\nwhat?",
          "score": 5,
          "created_utc": "2026-02-26 23:10:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7lrsuh",
              "author": "PetersOdyssey",
              "text": "What do you mean?",
              "score": 1,
              "created_utc": "2026-02-26 23:15:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7m2jt4",
                  "author": "PetersOdyssey",
                  "text": "Oh, that's poorly phrased!\n\nIt actually means that Banodoco owners get a 3x voting multiplier when voting on entries - not on their entries.\n\nUpdating",
                  "score": 3,
                  "created_utc": "2026-02-27 00:14:26",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o81z0jl",
          "author": "Psi-Clone",
          "text": "I just on my edge now waiting patiently till the themes are announced!!!",
          "score": 2,
          "created_utc": "2026-03-01 14:12:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7kixy0",
          "author": "Motor_Mix2389",
          "text": "What do themes mean? As in, the movie has to follow a strict theme? Do we have to use ltx or any open model?",
          "score": 1,
          "created_utc": "2026-02-26 19:35:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7kjovr",
              "author": "PetersOdyssey",
              "text": "You can use any open model but there will be themes to direct at a high level what the video should be about",
              "score": 2,
              "created_utc": "2026-02-26 19:39:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7px9mk",
          "author": "halpmeowtbruv",
          "text": "Is there a sign up, or do we just submit on deadline date?",
          "score": 1,
          "created_utc": "2026-02-27 15:58:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rdkr3n",
      "title": "Kijai's LoRA for WAN2.2 Video Reasoning Model",
      "subreddit": "StableDiffusion",
      "url": "https://huggingface.co/Kijai/WanVideo_comfy/tree/main/LoRAs/VBVR",
      "author": "switch2stock",
      "created_utc": "2026-02-24 16:23:06",
      "score": 148,
      "num_comments": 29,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rdkr3n/kijais_lora_for_wan22_video_reasoning_model/",
      "domain": "huggingface.co",
      "is_self": false,
      "comments": [
        {
          "id": "o75ukvi",
          "author": "Cequejedisestvrai",
          "text": "Can someone explain what is does? ELI5?",
          "score": 24,
          "created_utc": "2026-02-24 16:37:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75vsr4",
              "author": "Dzugavili",
              "text": "https://www.reddit.com/r/StableDiffusion/comments/1rdgeam/wan_22_video_reasoning_model_apache_20/\n\nI believe the concept is that you can get far greater prompt compliance: you won't need to be as specific, it will begin to look inside the generation for solutions.\n\nEdit:\n\nDoing some same-seed testing, I'm getting very promising results. Very subtle changes in motion, but it seems to be following my prompts more.\n\nI'm going to try adding this to my SVI workflow, see how it does there.",
              "score": 18,
              "created_utc": "2026-02-24 16:42:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o768yuy",
                  "author": "bigman11",
                  "text": "What a fascinating concept that I don't understand at all.",
                  "score": 23,
                  "created_utc": "2026-02-24 17:42:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7af7y1",
                  "author": "xb1n0ry",
                  "text": "It was trained on IQ-Test-like data. How can it potentially affect human motion?",
                  "score": 1,
                  "created_utc": "2026-02-25 07:35:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7bkg2p",
                  "author": "switch2stock",
                  "text": "Cool. Keep us posted on the results.",
                  "score": 1,
                  "created_utc": "2026-02-25 13:17:28",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o763wzh",
          "author": "Derispan",
          "text": "Any one have comparision video?",
          "score": 5,
          "created_utc": "2026-02-24 17:19:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7b07nm",
              "author": "Tremolo28",
              "text": "Used the Lora together with Wan smoothmix model on this 20sec clip. First half of the clip has the Lora applied, 2nd half without the Lora. [https://civitai.com/images/122286483](https://civitai.com/images/122286483)",
              "score": 4,
              "created_utc": "2026-02-25 10:50:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7de8o0",
                  "author": "BigFuckingStonk",
                  "text": "Could you please share your workflow and gpu as well as rendering time? I'm getting weird results on my side ..",
                  "score": 0,
                  "created_utc": "2026-02-25 18:33:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o79s5w2",
          "author": "Ok-Prize-7458",
          "text": "Looks promising, I hope LTX2 gets its own lora, thats been my daily driver as ive left wan behind.",
          "score": 5,
          "created_utc": "2026-02-25 04:32:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76kxkd",
          "author": "Consistent-Mastodon",
          "text": "Is it high noise only?",
          "score": 2,
          "created_utc": "2026-02-24 18:35:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77gevl",
              "author": "Life_Yesterday_5529",
              "text": "Yes. Only the structure of the video needs reasoning.",
              "score": 2,
              "created_utc": "2026-02-24 20:59:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o76fjv5",
          "author": "BiceBolje_",
          "text": "Stupid question maybe, but does it work with lightx2v LORA? \n\nTo be more precise: Does it have any effect on the actual video when using lightx2v?",
          "score": 2,
          "created_utc": "2026-02-24 18:11:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77nolb",
              "author": "terrariyum",
              "text": "In this [vid](https://www.youtube.com/watch?v=kFgU0tgYUl8), they use lightx2v on the high pass.  And it makes sense that full reasoning would only be needed for the movement pass.  However, their results are pretty bad",
              "score": 1,
              "created_utc": "2026-02-24 21:32:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o76irpy",
              "author": "switch2stock",
              "text": "Im new as well, so take it with a grain of salt.\nLightx2v is for speeding up the process right, and this model is for reasoning. So I'm assuming that if the model does not have enough time to reason then the output might not be ideal.",
              "score": 0,
              "created_utc": "2026-02-24 18:25:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7bykaq",
                  "author": "diogodiogogod",
                  "text": "I don't think this is a \"traditional\" thinking. But to be honest, I'm still confused by this.",
                  "score": 0,
                  "created_utc": "2026-02-25 14:34:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7sfl5x",
          "author": "Nikoviking",
          "text": "Is this just a LoRA or do I need a special workflow?",
          "score": 1,
          "created_utc": "2026-02-27 23:25:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o80n9e8",
              "author": "lolo780",
              "text": "Just a lora, works great in any workflow.\n\n",
              "score": 2,
              "created_utc": "2026-03-01 07:29:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rh8aza",
      "title": "Fast Flux2K inpainting on 8+ mp images without upscale",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1rh8aza",
      "author": "Winter_unmuted",
      "created_utc": "2026-02-28 17:21:51",
      "score": 144,
      "num_comments": 30,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rh8aza/fast_flux2k_inpainting_on_8_mp_images_without/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7zatv9",
          "author": "RickDripps",
          "text": "Okay, this is a really dumb question but it's kind of awkward to search and find...\n\nDo people just slop a grey blob overtop of the image in paint and then save it and use that?  Or is there like some official tool that does this or at least a specific color value needed for the grey?\n\nBasically, am I making it overly complicated or is it really as easy as putting a grey(-ish) blob on the image?",
          "score": 5,
          "created_utc": "2026-03-01 01:40:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7zgxto",
              "author": "Winter_unmuted",
              "text": "Right click on the load image node, then select Open in Mask Editor. You can paint the mask there and save it for use, easy as that. \n\nDon't worry, dude. We were all there once.",
              "score": 6,
              "created_utc": "2026-03-01 02:17:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7zm9ju",
                  "author": "RickDripps",
                  "text": "Hoooooly shit, I am glad I asked.  Thanks man, now it all clicks into place...  haha",
                  "score": 3,
                  "created_utc": "2026-03-01 02:49:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7wvuuq",
          "author": "Sudden_List_2693",
          "text": "Here:  \n[https://civitai.com/models/2390013/flux2-klein-ultimate-aio-pro-t2i-i2i-inpaint-replace-remove-swap-edit-segment-manual-auto-none](https://civitai.com/models/2390013/flux2-klein-ultimate-aio-pro-t2i-i2i-inpaint-replace-remove-swap-edit-segment-manual-auto-none)\n\nYou can use multiple masks either manually or using SAM3, the workflow will do just that going through the masks one by one.  \nNot only that, but you can select reference images and define which mask to use which one - like use the reference hat on mask 1 and 3, use the shoes reference on mask 1 and 2, and so on.  \nYou can even copy paste those reference image nodes, and use SAM3 to segment people, and use your class of 2000 photo to swap 22 Avangers for your class one by one.",
          "score": 9,
          "created_utc": "2026-02-28 17:44:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7x6w7u",
              "author": "Winter_unmuted",
              "text": "To each their own, but I am not a fan of a big square of packed up nodes. \n\nI like to see what my workflow is doing, start to finish, and have the dials to tweak as the job requires.  \n\nI appreciate your info though. I might download this wf and pick it apart to learn something about it.",
              "score": 7,
              "created_utc": "2026-02-28 18:39:04",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o7xskk5",
              "author": "Commercial_Talk6537",
              "text": "Love this workflow, been using it exclusively since it came out",
              "score": 3,
              "created_utc": "2026-02-28 20:31:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7y4a0t",
          "author": "addandsubtract",
          "text": "When doing selective inpaints like this, is the model aware of the entire image's lighting and color tone? Because some of the edits still feel \"off\" – especially the LotR ones.",
          "score": 2,
          "created_utc": "2026-02-28 21:34:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7yd1eg",
              "author": "Winter_unmuted",
              "text": "You can expand the area for context using the node I included. That's what the factor calculation is (1.1 means 10% larger mask for context, 1.2 is 20% larger, etc). \n\nThe denoising area is still limited to the mask, but the context can be made larger and larger. The bigger the area, the larger the conditioning and therefore the slower the denoising, so you need to do a balance depending on what you're doing. \n\nThese were non-optimized one offs, so I went for some of the first outputs. They don't look perfect, you're right. But some look great - the pixar one for example, looks like it's straight out of the movie. \n\nThe darker and grainier the source, the more turning of the knobs you'll need to do. \n\nOh, and you can also manually mask the context area for even more control. This works for, say, making sure the bricks in a wall match other parts of a wall that aren't directly attached to the masked area.",
              "score": 6,
              "created_utc": "2026-02-28 22:21:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7yftir",
                  "author": "addandsubtract",
                  "text": "Nice, thanks for the info and thanks for sharing!",
                  "score": 1,
                  "created_utc": "2026-02-28 22:37:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o8040ag",
          "author": "traithanhnam90",
          "text": "Thank you, your workflow is a lifesaver for me!",
          "score": 2,
          "created_utc": "2026-03-01 04:49:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7xqk14",
          "author": "Z3ROCOOL22",
          "text": "https://preview.redd.it/rc5h62clnamg1.png?width=699&format=png&auto=webp&s=0bbcc9d08ca756d17c2a4df9783e64aba37d4762\n\nCan't find these nodes.",
          "score": 1,
          "created_utc": "2026-02-28 20:20:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7xteil",
              "author": "Winter_unmuted",
              "text": "https://github.com/scraed/LanPaint install that with a git clone if it isn't in the node browser. You can try it with a regular KSampler too, but it won't look quite as good.\n\nYou can delete the Timer nodes. Those are just for the output for this post, showing that the edits can be pretty fast despite the huge images. \n\nThose are from Img Label Tools, https://github.com/rjgoif/ComfyUI-Img-Label-Tools (that's in the browser). \n\nImageMaskCrop is just a node that crops the image to the mask. You can delete that whole section and just enter a value that works in the  cropandstitch node (1.1 or 1.2 work well unless your inpaint area is small, then go like 2.0).",
              "score": 4,
              "created_utc": "2026-02-28 20:35:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7xv1fp",
                  "author": "Z3ROCOOL22",
                  "text": "Thx.",
                  "score": 1,
                  "created_utc": "2026-02-28 20:44:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7xzkv9",
                  "author": "Z3ROCOOL22",
                  "text": "Working, it works fucking great and i love you use crop and stitch node, it's so useful for inpaint and only few ppl do WK's including it! 👏",
                  "score": 1,
                  "created_utc": "2026-02-28 21:09:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o80owjr",
          "author": "traithanhnam90",
          "text": "Thank you, your simple and highly effective workflow! May I ask for more? If possible, could you provide a reference image to use for coloring the mask area? For example, if my child has a toy robot friend, could I use a picture of that robot to insert into a photo of my child's outing?",
          "score": 1,
          "created_utc": "2026-03-01 07:44:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o82xx40",
              "author": "Winter_unmuted",
              "text": "You can use whatever you want. \n\nIt's just a color space balancer. It won't restyle the image entirely.",
              "score": 1,
              "created_utc": "2026-03-01 17:09:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o811anc",
          "author": "Lower-Cap7381",
          "text": "crazy good workflow",
          "score": 1,
          "created_utc": "2026-03-01 09:42:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o8128ti",
          "author": "RepresentativeRude63",
          "text": "Workflow is clean 👍 the only difference I see is math node from standard inpaint workflows. Title is misleading you are not editing 4K plus images, classic you feed the mask resolution which is around 1K and Klein is super fast at 1K",
          "score": 1,
          "created_utc": "2026-03-01 09:51:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o82yuh1",
              "author": "Winter_unmuted",
              "text": "No, that's not the only difference.\n\nThe finding is that the inpaint crop node has two different resolutions: one for the inpaint itself (pretty standard), and the other for model context (not standard). \n\nEdit models are not simple denoising models and are not typically used for inpainting with mask. People usually use prompting to let the LLM decide the mask. But the conditioning and editing thus consider the whole image, even if not deciding to edit the whole image.\n\nThis shows that the context area can be limited to decrease conditioning size while constraining the model to editing an even smaller size. This may have been known to some, but it was not widely known, and certainly wasn't known to me.",
              "score": 1,
              "created_utc": "2026-03-01 17:14:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7zgscj",
          "author": "Brainibeep",
          "text": "This is a lifesaver! Using Flux 9B for high-res inpainting without tiling is exactly what the community needed. The Bruce Willis 'clown' transformation looks incredibly seamless; the way the makeup textures blend without losing his original likeness is top-tier work.\n\nIn my project Brainibeep, I’m constantly exploring the duality of AI: my optimistic side (Alpha) 🔵 loves the 'wholesome' use case of saving those wedding photos by removing the ex—it’s like digital magic for memories! Meanwhile, my skeptic side (Omega) 🔴 is already zooming in on the nodes to see how that color matcher handled the skin tones so perfectly.\n\nSince you mentioned avoiding tiling to prevent seams, did you notice any significant VRAM spikes when hitting those 8MP targets with the Lanpaint Ksampler? Great job on keeping the workflow clean!",
          "score": 1,
          "created_utc": "2026-03-01 02:16:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7zhfms",
              "author": "Winter_unmuted",
              "text": "The Ksampler is only working on the masked area, hence why the denoising times are so short. Look at the bottom of my images for the timings. The Skibidi beanie took 10 seconds!\n\nYou can specify a lookaround area that is used to supply Flux2 with context (see the stitch node in the upper left) but it doesn't denoise that area, only feeds it to the model to determine color and texture and stuff.",
              "score": 2,
              "created_utc": "2026-03-01 02:20:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o82pg0b",
                  "author": "red__dragon",
                  "text": "> You can specify a lookaround area that is used to supply Flux2 with context \n\nHow do you do this?",
                  "score": 2,
                  "created_utc": "2026-03-01 16:28:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o80qzis",
                  "author": "eagledoto",
                  "text": "Haven't checked the wf but what is the reso for the Inpainted area",
                  "score": 1,
                  "created_utc": "2026-03-01 08:04:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}