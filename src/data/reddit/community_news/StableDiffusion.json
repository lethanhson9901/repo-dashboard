{
  "metadata": {
    "last_updated": "2026-02-28 02:40:16",
    "time_filter": "week",
    "subreddit": "StableDiffusion",
    "total_items": 20,
    "total_comments": 425,
    "file_size_bytes": 472305
  },
  "items": [
    {
      "id": "1rdnz57",
      "title": "Open source Virtual Try-On LoRA for Flux Klein 9b Edit, hyper precise",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/z8mnc5rwghlg1",
      "author": "Affectionate-Map1163",
      "created_utc": "2026-02-24 18:16:58",
      "score": 726,
      "num_comments": 75,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rdnz57/open_source_virtual_tryon_lora_for_flux_klein_9b/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o76wtwl",
          "author": "Toclick",
          "text": "It would be interesting to see a comparison WITHOUT LoRA and WITH LoRA, because Klein can do this out of the box.",
          "score": 116,
          "created_utc": "2026-02-24 19:28:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o79moqz",
              "author": "DigThatData",
              "text": "The LoRA is so effective, you don't even need to plug the LoRA in!",
              "score": 32,
              "created_utc": "2026-02-25 03:57:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7ekbdo",
                  "author": "IrisColt",
                  "text": "HEH!",
                  "score": 2,
                  "created_utc": "2026-02-25 21:48:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7987ei",
              "author": "berlinbaer",
              "text": "sums up 90% of the posts on this sub.",
              "score": 42,
              "created_utc": "2026-02-25 02:33:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o782n0o",
              "author": "Dogluvr2905",
              "text": "Yeh I had the same question.  I have a workflow now that does this perfectly and LORA is no required.",
              "score": 8,
              "created_utc": "2026-02-24 22:44:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o78oqln",
                  "author": "Vakhoris",
                  "text": "Would you mind sharing that workflow, please?",
                  "score": 11,
                  "created_utc": "2026-02-25 00:43:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7e33i8",
              "author": "ZerOne82",
              "text": "I posted one using Klein 4B no LoRA no magic prompt.  \n[https://www.reddit.com/r/StableDiffusion/comments/1reorcq/tryon\\_klein\\_4b\\_no\\_lora\\_odd\\_poses\\_impressive](https://www.reddit.com/r/StableDiffusion/comments/1reorcq/tryon_klein_4b_no_lora_odd_poses_impressive)",
              "score": 5,
              "created_utc": "2026-02-25 20:28:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7a45ks",
              "author": "Icy_Till3223",
              "text": "Agreed",
              "score": 3,
              "created_utc": "2026-02-25 06:00:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o76y9gv",
          "author": "Legendary_Kapik",
          "text": "Do you really need a LoRA for this? Klein 4B + masking works fine.",
          "score": 8,
          "created_utc": "2026-02-24 19:35:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77rl1s",
              "author": "cderm",
              "text": "Got a Workflow? Would like to try that",
              "score": 1,
              "created_utc": "2026-02-24 21:50:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o77ss40",
                  "author": "Legendary_Kapik",
                  "text": "not mine - [https://civitai.com/models/2336342/comfyui-beginner-friendly-flux2-klein-4b-gguf-simple-cloth-swap-workflow-by-sarcastic-tofu](https://civitai.com/models/2336342/comfyui-beginner-friendly-flux2-klein-4b-gguf-simple-cloth-swap-workflow-by-sarcastic-tofu)",
                  "score": 5,
                  "created_utc": "2026-02-24 21:56:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o76pdnw",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 15,
          "created_utc": "2026-02-24 18:54:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76xir0",
              "author": "Mountain-Grade-1365",
              "text": "Fuck body shape this workflow will never show proper fit of the clothes, only perfect fit.",
              "score": 40,
              "created_utc": "2026-02-24 19:31:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o779cxm",
                  "author": "jrox",
                  "text": "is there ANY work flow that can do that?  seems like you‚Äôd need a new model and detailed measurements of the person and the clothing or images with scale references",
                  "score": 3,
                  "created_utc": "2026-02-24 20:26:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o77ej9k",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 1,
                  "created_utc": "2026-02-24 20:50:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o77qkkq",
              "author": "sishgupta",
              "text": "Forget body shape, what about knowing the actual shape of the clothes when it rests on a body. It's different from the cutout shape.",
              "score": 7,
              "created_utc": "2026-02-24 21:45:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7a56lr",
                  "author": "Lightspeedius",
                  "text": "You'd need the actual pattern that was used to produce the clothing.\n\nWhich is an interesting idea really. But much more than something StableDiffusion alone can produce.",
                  "score": 1,
                  "created_utc": "2026-02-25 06:09:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o77i6zj",
              "author": "realityconfirmed",
              "text": "Yes. Asking the real question. A lot of these try on models work great with a generic body shape. You really have to fight with the model, checkpoint, Lora to get it to adhere to having a normal garment on a big person. \n\nIn saying that there are consistency Lora's that can help for Qwen and Flux Klein that help sometimes.\n\nThanks OP creator. I will try this anyway. It looks interesting.",
              "score": 2,
              "created_utc": "2026-02-24 21:07:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o79jjmq",
                  "author": "orangeflyingmonkey_",
                  "text": "flux 2 klein edit does a decent job with different body shapes\n\nhttps://imgur.com/xhAZWqF",
                  "score": 1,
                  "created_utc": "2026-02-25 03:37:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o76mibd",
          "author": "techma2019",
          "text": "Is there a comfyUI workflow to try this locally?",
          "score": 13,
          "created_utc": "2026-02-24 18:42:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o786hzk",
              "author": "FreezaSama",
              "text": "This",
              "score": 4,
              "created_utc": "2026-02-24 23:04:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o76kruu",
          "author": "mordin1428",
          "text": "Decent, but it seems to have a bias to longer, baggier T-shirts, even though the specific item shown looks a regular cut",
          "score": 9,
          "created_utc": "2026-02-24 18:34:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76sl3n",
              "author": "Dzugavili",
              "text": "That might be something you can fix in prompting: you can see it handles folded clothing, so it's probably trying to apply the object against some kind of template in its knowledge. Once you tell it what the clothing item is, there's less guesswork in putting it on the model.",
              "score": 1,
              "created_utc": "2026-02-24 19:09:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7dnb3o",
              "author": "Cheesuasion",
              "text": "There've been uncountable numbers of \"virtual try-on\" posts here, every one of which it seems to me survives about 20 seconds of looking at the examples.\n\nVirtual try-on people (person?): perhaps come back when it works rather than every month or so?",
              "score": 1,
              "created_utc": "2026-02-25 19:14:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o76w2xt",
          "author": "MudMain7218",
          "text": "Do you need a lora for the edit? Qwen image edit has been doing this without one",
          "score": 4,
          "created_utc": "2026-02-24 19:25:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o773id5",
              "author": "Toclick",
              "text": "When Klein hadn‚Äôt even been released yet, Civitai was already flooded with Try-On LoRAs for Qwen, which you can still easily find now.",
              "score": 3,
              "created_utc": "2026-02-24 19:59:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o774ut0",
                  "author": "MudMain7218",
                  "text": "I mean 2511 can already swap clothing",
                  "score": 1,
                  "created_utc": "2026-02-24 20:05:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o76zntn",
          "author": "rnd_2387478",
          "text": "Are you sure its hyper precise and not ultra precise? Its confusing. /s",
          "score": 9,
          "created_utc": "2026-02-24 19:41:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76lx3h",
          "author": "Canchito",
          "text": "This is not open source, but open weights.",
          "score": 9,
          "created_utc": "2026-02-24 18:39:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76j4ky",
          "author": "switch2stock",
          "text": "What did you use for video?",
          "score": 7,
          "created_utc": "2026-02-24 18:27:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o781jgj",
              "author": "TinySmugCNuts",
              "text": "pay attention. it literally says 'grok video' at the bottom of each video.",
              "score": 4,
              "created_utc": "2026-02-24 22:38:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o76nhmp",
              "author": "Affectionate-Map1163",
              "text": "grok image to video",
              "score": -1,
              "created_utc": "2026-02-24 18:46:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o76q9sh",
                  "author": "switch2stock",
                  "text": "Ahh okay",
                  "score": 5,
                  "created_utc": "2026-02-24 18:58:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o76qlq6",
                  "author": "Hefty_Development813",
                  "text": "I would think similar could be done with wan, just not so quick. Is this being done on the fly or you run them all and store? How much is grok img to vid api?",
                  "score": 5,
                  "created_utc": "2026-02-24 19:00:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o777jx9",
          "author": "Life_Acanthaceae_748",
          "text": "where I can find workflow for local machine?\n\n",
          "score": 3,
          "created_utc": "2026-02-24 20:18:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77erhf",
          "author": "Snoo_64233",
          "text": "upload it to Civit?",
          "score": 3,
          "created_utc": "2026-02-24 20:51:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76xljk",
          "author": "thisiztrash02",
          "text": "im going to remake this with ltx2 and wan variants for the community since we are open source only but thanks for the idea",
          "score": 4,
          "created_utc": "2026-02-24 19:32:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o770ak0",
          "author": "Possible-Machine864",
          "text": "I always wish that these virtual try on models had some kind of grounding process so that you know that the size of the garment is accurate on the person.",
          "score": 2,
          "created_utc": "2026-02-24 19:44:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76oedo",
          "author": "Eisegetical",
          "text": "great - but useless due to the license. \n\nthis type of tool is oriented to be used as a commercial product tool, but the Klein9B license kills that. ",
          "score": 3,
          "created_utc": "2026-02-24 18:50:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76vqcq",
              "author": "One-Security-8742",
              "text": "This isn't useless. The license still allows for usage of images generated by 9B. You just can't monetize the model directly or provide a service that uses the model.",
              "score": 2,
              "created_utc": "2026-02-24 19:23:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o78bpyv",
                  "author": "andy_potato",
                  "text": ">¬†or provide a service that uses the model\n\nwhich is exactly what an e-commerce website with try-on function is doing. That's why the 9b variants of Klein are useless for such purposes.",
                  "score": 3,
                  "created_utc": "2026-02-24 23:32:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o76xqow",
                  "author": "Luckyrabbit-1",
                  "text": "it's useless if it doesn't provide value,  it's not virtual try on if it just using generated images.",
                  "score": -2,
                  "created_utc": "2026-02-24 19:32:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7amy8h",
              "author": "Ok-Reporter-6255",
              "text": "Who cares about this?",
              "score": 1,
              "created_utc": "2026-02-25 08:47:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7chs85",
              "author": "Subject-Pineapple837",
              "text": "New here. They guy says its open source. Whats the catch? Like can i use this to offer services for my local clothing stores? Genuine question",
              "score": 1,
              "created_utc": "2026-02-25 16:06:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7cno7x",
                  "author": "Eisegetical",
                  "text": "you can use it freely but you cant use it to make money as a service. thats what the license says. \n\nso your exact scenario is a no go. ",
                  "score": 2,
                  "created_utc": "2026-02-25 16:33:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o78bwlm",
              "author": "andy_potato",
              "text": "I wish people would not downvote you for this because it is true.",
              "score": 1,
              "created_utc": "2026-02-24 23:33:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o76jzdo",
          "author": "Enshitification",
          "text": "Nice. Is the LoRA flexible? Does it require white backgrounds and standing subjects?",
          "score": 1,
          "created_utc": "2026-02-24 18:30:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76kdur",
              "author": "Affectionate-Map1163",
              "text": "yes it is",
              "score": 1,
              "created_utc": "2026-02-24 18:32:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o778i92",
          "author": "3Fatboy3",
          "text": "This is great. \n\nHave you considered doing this with someone you know and clopth they already own? You could compare AI wiht real results.",
          "score": 1,
          "created_utc": "2026-02-24 20:22:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77hs8g",
          "author": "calvin-n-hobz",
          "text": "What's the difference between the model and the \"comfyui\" model in the repo?",
          "score": 1,
          "created_utc": "2026-02-24 21:05:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77hwkk",
          "author": "terrariyum",
          "text": "For Klein 9B **Base**, not distill",
          "score": 1,
          "created_utc": "2026-02-24 21:06:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o784e8w",
          "author": "Upper_Dependent1860",
          "text": "Does this work with non-white backgrounds?\n\n\nIf it's say a room, will it edit the background as well?¬†",
          "score": 1,
          "created_utc": "2026-02-24 22:53:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78ot2p",
          "author": "newaccount47",
          "text": "Can it do silly high fashion \"art as clothes\"?¬†",
          "score": 1,
          "created_utc": "2026-02-25 00:43:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78pnso",
          "author": "Loose_Object_8311",
          "text": "What happens if you provide no reference images for the clothes?",
          "score": 1,
          "created_utc": "2026-02-25 00:48:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79abc1",
          "author": "CodeCarnival-666",
          "text": "Klein can do this out of the box",
          "score": 1,
          "created_utc": "2026-02-25 02:44:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79b4e7",
          "author": "Colon",
          "text": "wow. all this is telling me is i have no style",
          "score": 1,
          "created_utc": "2026-02-25 02:49:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79o1yh",
          "author": "MediocreInside8628",
          "text": "Holy moly, its my first time seeing this, since I don't have a beefy gpu enough to run this, waiting for z image edit to come out.",
          "score": 1,
          "created_utc": "2026-02-25 04:05:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7azuap",
          "author": "Difficult_Total_104",
          "text": "Where was this created?",
          "score": 1,
          "created_utc": "2026-02-25 10:46:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7cjmy7",
          "author": "IllRecommendation144",
          "text": "good",
          "score": 1,
          "created_utc": "2026-02-25 16:14:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7cuna3",
          "author": "CupBig7438",
          "text": "Is there a comfyUI workflow? Please :(",
          "score": 1,
          "created_utc": "2026-02-25 17:04:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7fr46o",
          "author": "creuton22",
          "text": "Klein is not open to commercial use.  \nTheres another pipeline using commercial use free?",
          "score": 1,
          "created_utc": "2026-02-26 01:36:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7hm8zm",
              "author": "stephen370",
              "text": "The 4B one is apache 2.0 so you could use that one",
              "score": 1,
              "created_utc": "2026-02-26 09:54:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7il4yd",
          "author": "Foyxal",
          "text": "Is there any model which can change the shoe instead of clothes? I'm looking gor something similar for a while but instead of clothing i want to do it with shoe keeping the shoe design and logo properly constant.",
          "score": 1,
          "created_utc": "2026-02-26 14:06:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o770lt2",
          "author": "AcePilot01",
          "text": "Def shouldn't open source this, package it and sell it to clothing sites. Licensed. the end.",
          "score": -2,
          "created_utc": "2026-02-24 19:45:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o78c09y",
              "author": "shewel_item",
              "text": "It would be smart to strike while the iron is hot but something like this will be *fully* open source, which I guess *this isn't*, sooner than later. The company you sell to would have to be really in the dark to bite.",
              "score": 1,
              "created_utc": "2026-02-24 23:33:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o78ff0t",
                  "author": "AcePilot01",
                  "text": "Yeah bubble or not, early is rewarded more than perfection. And not true, that's not how open source works tbh, and you can copyright and trade mark many things.  There are open source options of professional software or services (I work in tech sales, SaaS included) and even then, there are very few companies who choose the open source route... Open source is for you and I. There are some exceptions. \n\nThat said, sometimes it's better to outsource things that a company COULD do itself because a company may not be an AI company. If they sell clothes, they generally aren't interested in being THAT vertical tbh. Some very large conglomerates are vertical, but there are plenty who are not tbh. \n\nLike I said, you are rewarded in start ups for being one of the first to get a foot hold more than you are for being technically accurate.\n\nYou could package this as an easy deployable workflow, local or hosted. And if it's easy and have some proven points (do some pilots for free for some to get feedback, data, and work out kinks etc) and sell them to companies. Even if it's not something that will be a billion dollar idea, it's something you could sell and make some money on in the mean time, or sell the business or look to get acquired etc.\n\nOr, his own service, that uses this, on a website that takes say links from shien or amazon or other store sites, and allows this for free, but then the links to the clothes are linked with referral/partner links. etc.  I would say, TryOn.com but that's taken lol\n\nAnd even if 80% of the prospects out there agree with you, the fashion industry is 359 Billion dollars, so I would NOT mind taking some scraps of 360 billion dollars  even if only 1% might be customers, that's still 360 million. Just in the US. lmfao\n\n\nOf course, Now that I mentioned this now here, any further use of this business model will of course need to be licensed from me. hahah ;)\n\n\nEDIT:  Looks like at least one other is already doing it (fyi, there are many business that are still very successful even in fairly flooded markets) https://try-on.io/ (not a promotion, idk anything about that site other than they are doing something similar. (Op's looks better tbh)",
                  "score": 1,
                  "created_utc": "2026-02-24 23:52:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rfm605",
      "title": "Image upscale with Klein 9B",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1rfm605",
      "author": "CutLongjumping8",
      "created_utc": "2026-02-26 20:56:48",
      "score": 429,
      "num_comments": 81,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rfm605/image_upscale_with_klein_9b/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7lfaeg",
          "author": "DrinksAtTheSpaceBar",
          "text": "Wow, what's with all the hate in here? I see this and think, \"if I'm feeling lazy and I'm already running a Klein workflow, I'll keep in mind that some level of upscaling is possible with this model.\" Take the information and move on with your lives JFC.",
          "score": 97,
          "created_utc": "2026-02-26 22:10:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7m72zd",
              "author": "Fit-Pattern-2724",
              "text": "The hate comes from folks spending weeks learning obsolete workflows that‚Äôs now completely useless. They need to spit on new models to justify the sunken time cost lol",
              "score": 35,
              "created_utc": "2026-02-27 00:39:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7nvokj",
                  "author": "Specialist-Chain-369",
                  "text": "or maybe hate comes from folks spending weeks learning¬†sophisticated workflows that actually improve quality without modifying original photo ;)",
                  "score": 0,
                  "created_utc": "2026-02-27 07:19:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7letx3",
          "author": "nncyberpunk",
          "text": "So many unnecessary comments. Pretty good. thanks for sharing. Been thinking a lot about upscaling 80s and 90s photos so I dig these.",
          "score": 47,
          "created_utc": "2026-02-26 22:08:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lgh3p",
          "author": "blastcat4",
          "text": "I think this is neat. Sure, it's not perfect, but if you want something quick and dirty, this is a super easy option. Sometimes the shortest path from point A to point B is worth taking even if it doesn't get you all the way to point B.",
          "score": 12,
          "created_utc": "2026-02-26 22:16:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ld2p0",
          "author": "gelatinous_pellicle",
          "text": "From my experience this is my fav upscaler, better than SEEDVR2 because it can fix anatomy and do all kinds of subtle or not subtle editing.",
          "score": 15,
          "created_utc": "2026-02-26 21:59:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7oac5u",
              "author": "Synor",
              "text": "These discussions would benefit from people differentiating \"upscaling\" and \"redreaming\"/\"remastering\".\n\nIf the process changes the picture significantly, its not an upscale IMO.",
              "score": 3,
              "created_utc": "2026-02-27 09:35:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7ovdp3",
              "author": "SomeoneSimple",
              "text": "Yeah, having more good options is always better. While I like seedvr2 **a lot**, it absolutely mangles some natural things that could be confused with high frequency noise like sand or textured walls.",
              "score": 1,
              "created_utc": "2026-02-27 12:32:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7lsb4a",
          "author": "Trendingmar",
          "text": "I can appreciate the sentiment of \"it changes image too much\". Although people complaining  make me confused because SEEDVR can absolutely change an image too much by introducing weird artifacts.\n\nSometimes dedicated upscalers fail altogether on things like compressed video screencaps. For situations like that klein and qwen are really your only choices for upscaling.\n\nIn some other applications (like my amateur level editing) the image only needs to be close enough to the original.\n\nBut I would agree for particular up-scaling tasks like this, where you start with medium resolution photographs of faces, seedvr will probably do better overall.",
          "score": 5,
          "created_utc": "2026-02-26 23:17:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7le6sx",
          "author": "mintybadgerme",
          "text": "Wow such a lot of hostility in this thread. Weird.",
          "score": 20,
          "created_utc": "2026-02-26 22:05:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7mfyxh",
              "author": "radioOCTAVE",
              "text": "Shut up! Sorry I mean yes, I noticed this too. Interesting..",
              "score": 10,
              "created_utc": "2026-02-27 01:29:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7o7cxm",
                  "author": "mintybadgerme",
                  "text": "Isn't it? :)",
                  "score": 2,
                  "created_utc": "2026-02-27 09:06:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7lh6gj",
          "author": "No_Writing_3179",
          "text": "Opinions are like assholes, everyone's got one, and most of them in here stink.",
          "score": 9,
          "created_utc": "2026-02-26 22:19:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7n00nf",
              "author": "ThePoetPyronius",
              "text": "I prefer to think assholes are like opinions; important for release, but overwhelming when you're confronted by them en masse. But that's just one man's asshole. ü§∑‚Äç‚ôÇÔ∏è",
              "score": 1,
              "created_utc": "2026-02-27 03:27:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7lp3rs",
          "author": "jvcraft87",
          "text": "No hostility ... but the scaled versions remind me of the earlier years digital portraiture where the photographer \"improved\" skin, eyes, and teeth, in Photoshop.  The common error was in smoothing out skin defects to the point where pores disappeared, and eyes and teeth became brilliant white.  If often gave the subject a plastic \"Barbie\" look.",
          "score": 6,
          "created_utc": "2026-02-26 23:00:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lsukg",
          "author": "meisterwolf",
          "text": "totally amazing. naysayers post your upscales if you think you know better.",
          "score": 2,
          "created_utc": "2026-02-26 23:20:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nn6fu",
              "author": "DanceTube",
              "text": "A few have and they are complete trash.",
              "score": 1,
              "created_utc": "2026-02-27 06:08:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7lwy0d",
          "author": "Lucaspittol",
          "text": "I posted virtually the same stuff a few weeks back ([here](https://www.reddit.com/r/StableDiffusion/comments/1p9795k/flux_2_is_amazing_at_image_restoration/) and [here](https://www.reddit.com/r/StableDiffusion/comments/1qesy1c/4b_x_9b_x_32b_flux_2_image_restoration_comparison/)) when I noticed these models are good at image restoration, and got a lot of hate as well. I then tried SeedVR2 and Qwen edit AS PEOPLE SAID and just got frustrated.",
          "score": 2,
          "created_utc": "2026-02-26 23:43:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7obri6",
          "author": "Kumimono",
          "text": "Heh, these are Playmates, I think. Seems to work well.",
          "score": 2,
          "created_utc": "2026-02-27 09:49:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lepq2",
          "author": "VelvetSinclair",
          "text": "Hey, I recognise these photos! \n\nI know what you are!\n\nDo you have the full image upscaled somewhere?",
          "score": 3,
          "created_utc": "2026-02-26 22:07:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7lf02x",
              "author": "CutLongjumping8",
              "text": "And I know how old we are as you remember July of 1958 :) and I am sure that it is against rules to post full images like this..",
              "score": 2,
              "created_utc": "2026-02-26 22:09:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7lfq2m",
                  "author": "VelvetSinclair",
                  "text": "Didn't ask you to post it...",
                  "score": 2,
                  "created_utc": "2026-02-26 22:12:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7le20m",
          "author": "RetroGazzaSpurs",
          "text": "classic flux skin",
          "score": 6,
          "created_utc": "2026-02-26 22:04:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7lipun",
              "author": "ready-eddy",
              "text": "What, you don‚Äôt like shiny spots everywhere?",
              "score": 4,
              "created_utc": "2026-02-26 22:27:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7o0bll",
              "author": "inddiepack",
              "text": "Did you use the model? After experimenting with all the models, to me Klein 9B distilled is producing the best natural skin out of the box, of all models. And I don't mean \"perfect\"skin, I mean realistic skin, pores and imperfections.",
              "score": 1,
              "created_utc": "2026-02-27 08:00:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7m4p1r",
          "author": "Calm_Mix_3776",
          "text": "I'm not sure what BFL did with Flux.2 Klein, but they really kneecapped the model's capability to do microdetails which is quite important for realistic skin. Even Z-Image Base and Chroma, both based on Flux.1 which is an older architecture, beat it in terms of [detail and texture capabilities](https://www.reddit.com/r/StableDiffusion/comments/1ramrmr/comment/o6mu7kl/). It's a shame since it's a really good edit model.\n\nFlux.2 Dev on the other hand does [amazing detail](https://i.postimg.cc/zqWv3g8z/Comfy-UI-Flux-2-Dev-02.jpg) (example below) - you can practically see the skin pores, tiny hairs, peach fuzz etc., but it's a nightmare to run on casual hardware, unless you use the NVFP4 version which works only on RTX50 cards. Flux.2 Dev uses the same VAE as Klein so it seems that the issue is with the model itself. Probably Klein didn't get enough hi-res training?\n\nhttps://preview.redd.it/zhja9rvglxlg1.jpeg?width=1024&format=pjpg&auto=webp&s=e52f3b27c857647371218cd6cd5b615247f74469",
          "score": 4,
          "created_utc": "2026-02-27 00:26:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qapkj",
              "author": "music2169",
              "text": "How did you do the upscale here with flux.2 dev?",
              "score": 1,
              "created_utc": "2026-02-27 17:01:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7rppuu",
                  "author": "Calm_Mix_3776",
                  "text": "Here's a screenshot of the workflow:\n\nhttps://preview.redd.it/0z5lqon8r3mg1.png?width=2829&format=png&auto=webp&s=94b28a1063af79ceb086f1e1362912c36c3e62b9\n\n",
                  "score": 1,
                  "created_utc": "2026-02-27 21:09:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7la2c5",
          "author": "Freshly-Juiced",
          "text": "turns them into different people though ",
          "score": 3,
          "created_utc": "2026-02-26 21:45:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ntaej",
              "author": "GoofAckYoorsElf",
              "text": "I wonder how. If you look at specific details it's almost perfect. But the overall face is indeed different. That's... a strange effect.",
              "score": 1,
              "created_utc": "2026-02-27 06:58:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7nx6po",
                  "author": "Freshly-Juiced",
                  "text": "because AI upscaling basically repaints the entire image to what the model thinks it should look like, nothing from the original is retained, it's only used as a guide to lean the model in the right direction. ",
                  "score": 0,
                  "created_utc": "2026-02-27 07:32:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7n2l3m",
          "author": "grabber4321",
          "text": "Gooners will always find a way!",
          "score": 2,
          "created_utc": "2026-02-27 03:43:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7l5irq",
          "author": "lebrandmanager",
          "text": "TBH to this day there is nothing beating SEEDVR2 for upscaling images. Maybe using ZIT as a second pass, if someone needs it. But this is a joke.",
          "score": 1,
          "created_utc": "2026-02-26 21:23:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7lcui1",
              "author": "MrFlores94",
              "text": "You can use this to remaster the image before upscaling it with SeedVR. This is just another very useful tool.",
              "score": 13,
              "created_utc": "2026-02-26 21:58:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7lpq2u",
              "author": "Fit-Pattern-2724",
              "text": "This is a lot faster than SEEDVR2. Also avoided model loading unloading",
              "score": 8,
              "created_utc": "2026-02-26 23:03:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7llh7r",
              "author": "ScumLikeWuertz",
              "text": "how do I use it?  im still trying to figure comfyui out",
              "score": 2,
              "created_utc": "2026-02-26 22:41:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7m2jvp",
              "author": "BluetownA1",
              "text": "Really? Would love to see you attempt with seedvr2. ",
              "score": 2,
              "created_utc": "2026-02-27 00:14:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7nujyf",
                  "author": "lebrandmanager",
                  "text": "Not sure, if the advanced workflow still works, but I usually use this node and workflow and get stunning results up to 8k+\n\nhttps://github.com/moonwhaler/comfyui-seedvr2-tilingupscaler",
                  "score": 0,
                  "created_utc": "2026-02-27 07:09:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7ljbzw",
              "author": "Danmoreng",
              "text": "If only there was a way to run it without Python and comfy‚Ä¶",
              "score": 1,
              "created_utc": "2026-02-26 22:30:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7lf1ec",
          "author": "SweptThatLeg",
          "text": "I get the worst results using the comfyUI template for Flux2 Klein9B. Like, I‚Äôll swap a face or change an outfit and what it kicks back has awful resolution compared to the starting image. \n\nWhat am I missing?",
          "score": 1,
          "created_utc": "2026-02-26 22:09:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lvpjn",
          "author": "VirusCharacter",
          "text": "I have the same problem getting good hair and usually Klein favors plastic skin... Unfortunately. Other than that  it's a fantasticly flexible model!",
          "score": 1,
          "created_utc": "2026-02-26 23:36:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lwhyx",
          "author": "Fast_Situation4509",
          "text": "Interesting",
          "score": 1,
          "created_utc": "2026-02-26 23:40:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7m0lpz",
          "author": "comfyui_user_999",
          "text": "It's really not bad, and so, so fast.",
          "score": 1,
          "created_utc": "2026-02-27 00:03:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7m6x54",
          "author": "johndrake666",
          "text": "Need to be added on tv's\n\n![gif](giphy|ohRB7lodHJobrD5WNd)",
          "score": 1,
          "created_utc": "2026-02-27 00:38:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7me05m",
          "author": "Srapture",
          "text": "Neat! I'm not really sure how to add additional upscalers in Forge.",
          "score": 1,
          "created_utc": "2026-02-27 01:18:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7mk0ue",
          "author": "Merchant_Lawrence",
          "text": "are it good on upscaling anime image ?",
          "score": 1,
          "created_utc": "2026-02-27 01:53:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7mo4zu",
          "author": "MrWeirdoFace",
          "text": "What is your latent resolution? I imagine you are using an upscale node first?",
          "score": 1,
          "created_utc": "2026-02-27 02:17:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7mt1oo",
              "author": "CutLongjumping8",
              "text": "yes - start images were from 350x350px to 412x412px and upscale node make it 1024x1024 before everything",
              "score": 1,
              "created_utc": "2026-02-27 02:45:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7mupaq",
          "author": "Fast-Visual",
          "text": "Now it's Gro√ü 9B",
          "score": 1,
          "created_utc": "2026-02-27 02:55:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7n2jqp",
          "author": "RangeImaginary2395",
          "text": "Never thought I could use it this way, thank you for opening up my new perspective",
          "score": 1,
          "created_utc": "2026-02-27 03:42:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7n8g3i",
          "author": "Shockbum",
          "text": "There's something called DyPE for Flux 1 that allows the model to generate in 4k without distortion. Could it be applied to Klein 9b? [https://github.com/guyyariv/DyPE](https://github.com/guyyariv/DyPE)",
          "score": 1,
          "created_utc": "2026-02-27 04:20:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7nk1v3",
          "author": "RepresentativeRude63",
          "text": "Upscale to 4 mp with seedvr (seedvr looks digital too) than pass it to Klein with denoise value between 0.12 - 0.27 depending on the camera focus to capture realism again",
          "score": 1,
          "created_utc": "2026-02-27 05:43:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7nydjh",
          "author": "avalon_edge",
          "text": "Would appreciate the Workflow?",
          "score": 1,
          "created_utc": "2026-02-27 07:43:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nys2g",
              "author": "CutLongjumping8",
              "text": "apologize - after yesterday I‚Äôm kind of nervous about posting links here‚Ä¶\n\nBut on the other hand, I do have a universal workflow on Civitai that I maintain and personally use ‚Äî the link is in my previous threads.",
              "score": 1,
              "created_utc": "2026-02-27 07:46:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7oqj9z",
          "author": "PestBoss",
          "text": "I'll be honest these are staying very faithful to the original appearance of the subjects. It's still not perfect, but it's very close. The actual images change quite a bit but then that is no bad thing either and they equally stay faithful in general apperance, just that it looks like it was taken on modern imaging gear and not an old film camera on faded paper.\n\nI've never generally wanted to use one of these as they always change things, or don't truly refine it properly, but this is the first one I've seen where I actually fancy getting some old family photos out to improve!",
          "score": 1,
          "created_utc": "2026-02-27 11:57:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ozulv",
          "author": "juguLator01",
          "text": "Impressive. I found it odd that the window framing kept kinda lo-res still",
          "score": 1,
          "created_utc": "2026-02-27 13:02:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ptqjk",
          "author": "Jetsprint_Racer",
          "text": "F.2K really got some hair issues... It looks almost like videogame hair with mediocre antialiasing. Far from what the best SDXL checkpoints were able to do.",
          "score": 1,
          "created_utc": "2026-02-27 15:41:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7qacog",
          "author": "music2169",
          "text": "Workflow?",
          "score": 1,
          "created_utc": "2026-02-27 16:59:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7raay9",
          "author": "VasaFromParadise",
          "text": "In fact, Klein does not do upscaling, it does image reconstruction.",
          "score": 1,
          "created_utc": "2026-02-27 19:51:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7l4pic",
          "author": "tomuco",
          "text": "Nope. Unnatural subpatterns, harsher lighting, DOF is all over the place. Might as well use an ESRGAN model. We already had better solutions for this years ago.",
          "score": -2,
          "created_utc": "2026-02-26 21:19:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7lpmdj",
              "author": "Fit-Pattern-2724",
              "text": "ESRGAN performs way worse than this. Did you actually use it?v",
              "score": 10,
              "created_utc": "2026-02-26 23:03:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7m0nwf",
                  "author": "tomuco",
                  "text": "I did and still do. Just not for the last step.",
                  "score": -4,
                  "created_utc": "2026-02-27 00:04:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7ml70t",
              "author": "moofunk",
              "text": "> Unnatural subpatterns, harsher lighting, DOF is all over the place.\n\nMost of these can be controlled through prompting. Klein is decently good in many things, except upscaling hair and reproducing particular types of skin.\n\nTreating this as a one-shot workflow doesn't do the model any favors.",
              "score": 3,
              "created_utc": "2026-02-27 02:00:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7lkqyp",
          "author": "HollowAbsence",
          "text": "Thw upscale shifted red hue for yellowish hue. the pictures lost their original warmt.",
          "score": 1,
          "created_utc": "2026-02-26 22:37:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lpc3z",
          "author": "Fit-Pattern-2724",
          "text": "klein is such a magical model that can easily do almost everything",
          "score": 1,
          "created_utc": "2026-02-26 23:01:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7l55fr",
          "author": "xrionitx",
          "text": "Is there any deformation corrector node..? Like when there are extra limbs generated, bad eyes and so on... Plus to enhance the resolution to 4k",
          "score": 1,
          "created_utc": "2026-02-26 21:21:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7m8av5",
              "author": "kayteee1995",
              "text": "add neg prompt + NAG (if you set cfg1 on distilled)",
              "score": 1,
              "created_utc": "2026-02-27 00:45:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7l4lv1",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -2,
          "created_utc": "2026-02-26 21:19:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7l5p8t",
              "author": "CutLongjumping8",
              "text": "sorry for that :) I just found it strange that many people include upscalers like SeedVR2 in their workflows, while the model itself can practically do the same thing. And I am sure that with more smart prompts or may be some lora it is possible to make results better. And yes - my fault again, I‚Äôve removed the link.",
              "score": 3,
              "created_utc": "2026-02-26 21:24:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7l94ur",
                  "author": "rolens184",
                  "text": "To be honest, I find it strange too. I don't really like Seedvr2 as an upscaler. Also because I can't use it in a single workflow with other models because it crashes my PC.",
                  "score": 4,
                  "created_utc": "2026-02-26 21:40:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7lb2vm",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": -1,
                  "created_utc": "2026-02-26 21:50:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7lhx7d",
          "author": "meikerandrew",
          "text": "https://preview.redd.it/btb5uindzwlg1.png?width=3072&format=png&auto=webp&s=1f630dcb2d1b48e935d802e37feead32ca372c6b\n\nI use qwen image 2511 for upscale. I like quality. Maybe some face anatomy changed but its not critical.",
          "score": -1,
          "created_utc": "2026-02-26 22:23:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7n0nzw",
              "author": "Snoo_64233",
              "text": "Looks like wax doll\n\nhttps://preview.redd.it/l901kzvmiylg1.png?width=672&format=png&auto=webp&s=7447db18a81b2fa2d22fb8e789cd420f76708d3f\n\n",
              "score": 5,
              "created_utc": "2026-02-27 03:31:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7pfc01",
                  "author": "ronbere13",
                  "text": "wax doll is good",
                  "score": 1,
                  "created_utc": "2026-02-27 14:30:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7lk4h9",
              "author": "rm_rf_all_files",
              "text": "Plastic skin textures. SeedVR2 is night and day vs this.",
              "score": 4,
              "created_utc": "2026-02-26 22:34:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7mb6g7",
                  "author": "meikerandrew",
                  "text": "Nope. qwen better. Maybe need try on 2512. \n\nhttps://preview.redd.it/lmaoe6k2sxlg1.jpeg?width=760&format=pjpg&auto=webp&s=8e8a2a18e7da2a1e99b6fcbd959433f51e78fcea",
                  "score": -1,
                  "created_utc": "2026-02-27 01:02:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7ls0ta",
          "author": "vacon04",
          "text": "The teeth are very different. It's like an upscale with a strange beautify filter.",
          "score": -7,
          "created_utc": "2026-02-26 23:16:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rc2fgr",
      "title": "I love local image generation so much it's unreal",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1rc2fgr/i_love_local_image_generation_so_much_its_unreal/",
      "author": "SlapMyOwnNuts",
      "created_utc": "2026-02-23 00:19:44",
      "score": 383,
      "num_comments": 116,
      "upvote_ratio": 0.89,
      "text": "Now if you'll excuse me, I'm going to generate about 400 smut images of characters from Blue Archive to goon my brains to. Peace",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rc2fgr/i_love_local_image_generation_so_much_its_unreal/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "o6v9uk5",
          "author": "lacerating_aura",
          "text": "Username checks out.",
          "score": 146,
          "created_utc": "2026-02-23 00:22:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o70z865",
              "author": "BitCloud25",
              "text": "Slap em! Slap em good!",
              "score": 5,
              "created_utc": "2026-02-23 21:45:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vgbid",
          "author": "unltdhuevo",
          "text": "Ok imagine that but with video",
          "score": 74,
          "created_utc": "2026-02-23 00:59:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xdiaw",
              "author": "Spamuelow",
              "text": "And now imagine that video is vr",
              "score": 28,
              "created_utc": "2026-02-23 09:48:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6wvog3",
              "author": "desktop4070",
              "text": "LTX 2 is more fun to play with than most games I've played in the past decade. I still can't believe that they released it, and that I can run it locally.",
              "score": 28,
              "created_utc": "2026-02-23 06:55:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o743w7h",
                  "author": "KomaKiley",
                  "text": "How do you run it locally? I know I could probably google this question, but do you have suggestions for a good starting point?",
                  "score": 1,
                  "created_utc": "2026-02-24 10:31:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6xbqma",
              "author": "RO4DHOG",
              "text": "Imagine that butt with video.\n\n![gif](giphy|8qABb3dgjun8PdNirg)\n\n",
              "score": 26,
              "created_utc": "2026-02-23 09:30:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6zyk5p",
                  "author": "_half_real_",
                  "text": "Rose from Zaiyuki if she real.",
                  "score": 1,
                  "created_utc": "2026-02-23 18:50:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6w73tt",
          "author": "Initial-Cherry-3457",
          "text": "May I suggest /r/unstable_diffusion",
          "score": 49,
          "created_utc": "2026-02-23 03:45:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6w7rf9",
              "author": "dipshit_loser",
              "text": "I have seen the top of the mountain",
              "score": 22,
              "created_utc": "2026-02-23 03:49:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6wyjcy",
                  "author": "TooManiEmails",
                  "text": "üé∂And I ain‚Äôt comin downüé∂",
                  "score": 12,
                  "created_utc": "2026-02-23 07:21:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6x2l6d",
              "author": "StrongZeroSinger",
              "text": "Their wiki seems 2 years outdated or is it the mobile view?",
              "score": 12,
              "created_utc": "2026-02-23 08:00:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o75v4u5",
              "author": "sphynxcolt",
              "text": "Despite the topic here, I was naive enough to click while I am at work right now.",
              "score": 2,
              "created_utc": "2026-02-24 16:39:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7bqmag",
              "author": "SynxLake",
              "text": "damn, you ruined my life,i hate u!",
              "score": 1,
              "created_utc": "2026-02-25 13:52:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6xemde",
          "author": "bickid",
          "text": "Ngl: Ever since I started doing AI stuff, I've consumed LESS porn, because knowing that I could CREATE ANYTHING just puts so much peace on my mind, it's like I don't need to see stuff, because I know I \"could\" see if I wanted to. AI is amazing. <3",
          "score": 45,
          "created_utc": "2026-02-23 09:59:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6z3h9i",
              "author": "mca1169",
              "text": "this, it's so much more reassuring to have the ability to create what in a world where the internet is getting locked down more by the day. plus it can be a fun process to have something as simple as a setting or outfit in mind and steadily build on the idea into something completely new.",
              "score": 8,
              "created_utc": "2026-02-23 16:26:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6zgv00",
              "author": "timbocf",
              "text": "Porn is so fake and created to cater to our fantasies but its not like real sex at all, quite the opposite. I just wanna reimagine times I've had with my wife that we didn't get on video",
              "score": 2,
              "created_utc": "2026-02-23 17:28:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7mnxcw",
                  "author": "Dense-Celebration815",
                  "text": "wholesome",
                  "score": 2,
                  "created_utc": "2026-02-27 02:16:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6whby4",
          "author": "wyc603",
          "text": "I buy powerful GPU to game? No, I buy powerful GPU to goon.",
          "score": 80,
          "created_utc": "2026-02-23 04:57:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ww16o",
              "author": "Loose_Object_8311",
              "text": "Gooner Processing Unit :P",
              "score": 91,
              "created_utc": "2026-02-23 06:58:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6zpemc",
                  "author": "Koalateka",
                  "text": "Very accurate",
                  "score": 5,
                  "created_utc": "2026-02-23 18:08:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6ww7xb",
              "author": "desktop4070",
              "text": "I bought a 3060 at launch with the sole purpose of playing games.  \n  \nI'm not the same man I was before September 2022.  \n  \nI ended up buying a 5070 Ti pretty much entirely for running local models.",
              "score": 31,
              "created_utc": "2026-02-23 07:00:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6w3bsb",
          "author": "Neggy5",
          "text": "ai saved me from spending thousands on commissions for specific smut no one was making enough of. ",
          "score": 84,
          "created_utc": "2026-02-23 03:20:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x42p9",
              "author": "Loose_Object_8311",
              "text": "Call me silly, but I didn't realise that was a thing people did... no less spent thousands on. I won't ask, but then again rule 34 is a thing, so I can imagine.",
              "score": 18,
              "created_utc": "2026-02-23 08:14:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6y3we7",
                  "author": "SalsaRice",
                  "text": "I think it's primarily a furry thing, but it's been pretty widely known for a while from artists that furries are willing to pay well, tip generously, and (usually) treat artists well. \n\nFor whatever reason, it's really common for furries to work in IT and computer science, so they seem to have a higher than average income than most Fandoms.",
                  "score": 11,
                  "created_utc": "2026-02-23 13:22:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o70fpwa",
              "author": "SpaceNinjaDino",
              "text": "I paid for one commissioned custom video. She didn't follow the script at all or even use the Amazon wishlist item bought. (Before gen AI existed.) Now I can generate impossible things. Like sex in crowded public settings (subway, stadium, restaurants/cages, theater, park, space station, etc). Magic, medieval, future, robots, zombie, under water ... real goon material can't compete. No more worries that girls were tricked like in the girlsdoporn case.",
              "score": 2,
              "created_utc": "2026-02-23 20:09:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wynts",
          "author": "necrophagist087",
          "text": "Next stage: condensing your fetish in the form of lora and sharing with others.",
          "score": 16,
          "created_utc": "2026-02-23 07:23:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6x9wzq",
          "author": "fugogugo",
          "text": "![gif](giphy|YmQLj2KxaNz58g7Ofg)\n\n400?",
          "score": 16,
          "created_utc": "2026-02-23 09:12:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vt903",
          "author": "ModFrenzyAI",
          "text": "Why stop with images? As long as you have 8GB VRAM, you can use WAN2.2 to animate whatever image you create! ",
          "score": 41,
          "created_utc": "2026-02-23 02:17:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xa8a0",
              "author": "fugogugo",
              "text": "I have tried setting up WAN workflow , it worked but ...  \n  \nI honestly still don't understand what or how to prompt . haha \n\nI am already 1girl, solo brained \n\n",
              "score": 20,
              "created_utc": "2026-02-23 09:15:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6yz1cv",
                  "author": "Unambiguous-Doughnut",
                  "text": "Ok ok I gotchu.\n\nUse ChatGPT to assist in setting up a 70b parameter LLM Using LMStudio or Ollama. If the LLM allows it can allow for NSFW Prompts bonus points if its vision enabled. \n\nThough you will 100% be using a quantanized model unless your running a supercomputer or ram only.\n\n\nAsk ChatGPT to come up with a system prompt that will ensure the model acts as a prompt assistant for video models (like want2.2 etc) you need to be specific its for video models because image and video generation can be different.\n\nWith vision enabled you could also ask it to prompt for image2video. \n\n\nWan2.2 workflow, powerloader lora. Goon to your hearts content <3 \n\nHell LLMS are significantly more powerful than image and video generation like you want it to act as a editorial assistant for documents ask for a system prompt so it does just that. \n\nYou want it to assist in coding hell yeah it can. You need it to write a detailed scene for your t2i flux/wan2.2 model runs locally no need for Internet comectivity or sign in.",
                  "score": 14,
                  "created_utc": "2026-02-23 16:05:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6wmegt",
              "author": "rafaelbittmira",
              "text": "I have tried the 5B wan 2.2 for anime generation and have had very little success, it works great for realistic generation though",
              "score": 4,
              "created_utc": "2026-02-23 05:36:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6wzgez",
                  "author": "King__Ragnar",
                  "text": "5b sucks. Use 14b with a quant model and lightning lora. I only have 8gb vram and can create videos in 6 - 10 min",
                  "score": 13,
                  "created_utc": "2026-02-23 07:30:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6vvqf2",
              "author": "Esquilax21",
              "text": "Is there a guide how to set it up? Would love to generate videos",
              "score": 7,
              "created_utc": "2026-02-23 02:33:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6vwn8x",
                  "author": "ModFrenzyAI",
                  "text": "Yeah! I've made one for GPU poor folks like me. It might not be the best one but worked great for my purposes. It's on CivitAI (you might need to turn-on your NSFW settings): [https://civitai.com/models/2272369/wan22-i2v-gguf-nsfw-8gb-vram-32gb-ram-workflow](https://civitai.com/models/2272369/wan22-i2v-gguf-nsfw-8gb-vram-32gb-ram-workflow)",
                  "score": 31,
                  "created_utc": "2026-02-23 02:38:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6xri2j",
                  "author": "Bietooeffin",
                  "text": "https://civitai.com/models/1824962/torstens-wan-22-14b-i2v-low-vram-workflow-with-added-features\n\nThis one is also pretty neat, using that one with q4 quants and 8gb vram and 16gb system ram and a 48gb page file. 480p 5 second videos will take you around 4-5 minutes with e.g. 40 or 50 series cards with 8gb, lighting lora (baked in or not) and sage attention.",
                  "score": 4,
                  "created_utc": "2026-02-23 11:55:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6z3syo",
              "author": "mca1169",
              "text": "you forgot to mention the multiple hours of generation time for a 5 second or longer \"video\".",
              "score": 2,
              "created_utc": "2026-02-23 16:28:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o70aha4",
                  "author": "megacewl",
                  "text": "3080ti 12GB can do a 5 second 1240x1080 WAN 2.2 img2vid generation in 4.5 minutes",
                  "score": 1,
                  "created_utc": "2026-02-23 19:45:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6z7gy6",
                  "author": "ModFrenzyAI",
                  "text": "Not really, I can generate 576p in 5 minutes or less. 720p takes 40-50 minutes, so I'm not even trying that with my PC. I started using RunPod for those kinda generations, not much to do :(",
                  "score": 0,
                  "created_utc": "2026-02-23 16:44:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6zbe18",
              "author": "Magnar0",
              "text": "Same for AMD?",
              "score": 1,
              "created_utc": "2026-02-23 17:03:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7ibbje",
              "author": "The-FrozN",
              "text": "At this point you‚Äôre not generating images, you‚Äôre running a whole studio out your GPU üò≠",
              "score": 1,
              "created_utc": "2026-02-26 13:11:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6x4aje",
          "author": "EirikurG",
          "text": "based",
          "score": 12,
          "created_utc": "2026-02-23 08:16:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6z1g3g",
              "author": "foxontheroof",
              "text": "on what? ü§ì",
              "score": 3,
              "created_utc": "2026-02-23 16:17:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6veypo",
          "author": "Enshitification",
          "text": "![gif](giphy|Ki9S8uve2xWx2)\n\nI salute you.",
          "score": 50,
          "created_utc": "2026-02-23 00:51:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6w4itb",
          "author": "No-Expression6444",
          "text": "give the man credit, he knows what he wants.",
          "score": 21,
          "created_utc": "2026-02-23 03:28:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xiggm",
              "author": "asianjapnina",
              "text": "lol",
              "score": 1,
              "created_utc": "2026-02-23 10:35:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wufrn",
          "author": "Jealous_Piece_1703",
          "text": "Based game. Hopefully no one know the reference",
          "score": 10,
          "created_utc": "2026-02-23 06:44:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6wx7qt",
              "author": "wyc603",
              "text": "üò≠üò≠üò≠",
              "score": 9,
              "created_utc": "2026-02-23 07:09:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6xmfpu",
              "author": "BELLVH3ART",
              "text": "lol",
              "score": 1,
              "created_utc": "2026-02-23 11:12:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o761j7v",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": -1,
              "created_utc": "2026-02-24 17:08:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o76ap8w",
                  "author": "Jealous_Piece_1703",
                  "text": "You better believe BA players are not there for ‚Äúthick‚Äù students. Only maybe 1% if them",
                  "score": 2,
                  "created_utc": "2026-02-24 17:49:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6wvcdl",
          "author": "Upper-Reflection7997",
          "text": "you will eventually have periods of boredom from generating 1girls and run out of ideas. Lately I've been spending too much time on Instagram and Twitter hunting for images and captioning text prompts through qwen3 vl.\n\nhttps://preview.redd.it/6wkkb24zy6lg1.jpeg?width=1440&format=pjpg&auto=webp&s=8d9f8c63fb77716dad0bc9dd6973bef42755ce50\n\n",
          "score": 6,
          "created_utc": "2026-02-23 06:52:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x05ol",
              "author": "ArtificialAnaleptic",
              "text": "Can you explain more about what you just said and how it relates to the image?",
              "score": 7,
              "created_utc": "2026-02-23 07:37:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6x9xhg",
                  "author": "Upper-Reflection7997",
                  "text": "It's simple. Find a image I like. copy and paste it to qwen3 vl. Ask qwen for long description of the image. Copy and paste description as prompt to forge neo/wan2gp for image generation with z image and qwen image 2512.",
                  "score": 9,
                  "created_utc": "2026-02-23 09:12:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6xdp1k",
          "author": "SirCrest_YT",
          "text": "It's what truly drives the industry.",
          "score": 7,
          "created_utc": "2026-02-23 09:50:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yt8dt",
          "author": "shitlord_god",
          "text": "I wasn't expecting OP's level of honesty and candor. \n\nFive stars.",
          "score": 6,
          "created_utc": "2026-02-23 15:38:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vsyl8",
          "author": "Loose_Object_8311",
          "text": "Mildly hilarious this is being upvoted because I'm sure the anti-gooner, anti-1girl crowd must be downvoting it too. The Goon squad making a strong showing today.¬†",
          "score": 30,
          "created_utc": "2026-02-23 02:16:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ycvds",
              "author": "negrote1000",
              "text": "Those are way worse than the ones that just do it.",
              "score": 2,
              "created_utc": "2026-02-23 14:14:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wzufg",
          "author": "TurnOffAutoCorrect",
          "text": "From 2017 to summer 2022 I had an Nvidia 1070 because I don't game that hard. Then I discovered local AI and less than a year later I bought a 4090.",
          "score": 8,
          "created_utc": "2026-02-23 07:34:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x4bed",
              "author": "Loose_Object_8311",
              "text": "When SD1.5 first came out I bought an RTX 3060 12GB VRAM, 3 weeks later I had a 4090. Sadly I had to get rid of it, now I'm back on a 5060 Ti and scheming about how I can RTX 6000 Pro.",
              "score": 7,
              "created_utc": "2026-02-23 08:17:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vj17g",
          "author": "Baddabgames",
          "text": "Came here to goon assume and OP beat me to it. I feel like Papa Doc right after B Rabbit‚Äôs battle rap.",
          "score": 4,
          "created_utc": "2026-02-23 01:16:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yftql",
          "author": "SweetGale",
          "text": "My 1050 Ti 4 GB was more than enough for the retro indie games that I tend to play. I upgraded to a 3060 12 GB when SDXL was released in 2023 and pretty much stopped gaming altogether. Generative AI is so damn addictive! It is the tool I've always wanted. It lets me turn my daydreams into images. It's also the ultimate character creator that lets me find the perfect mix of human, animal, male and female traits that my weird bisexual furry brain finds attractive.",
          "score": 5,
          "created_utc": "2026-02-23 14:30:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vldnn",
          "author": "Both-Rub5248",
          "text": "Good luck, mate!\n\n![gif](giphy|HHzBaXsra2MHciRNQr)\n\n",
          "score": 8,
          "created_utc": "2026-02-23 01:30:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zv67w",
          "author": "Salnder12",
          "text": "Same, I was really disappointed with online gen AI, ones that could do NSFW were super expensive and had shit prompt adhesion. Once I realized local was a thing I completely understood the hype.\n\n\nBonus that I don't have to destroy the environment to goon",
          "score": 3,
          "created_utc": "2026-02-23 18:34:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yhzzp",
          "author": "Murder_Teddy_Bear",
          "text": "THIS man has the RIGHT IDEA!!",
          "score": 2,
          "created_utc": "2026-02-23 14:42:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yy835",
          "author": "Sushiki",
          "text": "Just wish the newer software worked on amd 6950...   all the amd guide ones just fail. Comfy doesn't want to work. Made me give up after four failed attempts so i went back to using the only thing that does work for me and that is Automatic1111.",
          "score": 2,
          "created_utc": "2026-02-23 16:02:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75pc5f",
              "author": "TheRealCorwii",
              "text": "Have you tried any of the models on Pinokio? Z-Image says it works on AMD cards though I have no idea about the speeds you'll see.\n\nIf you do try Pinokio, you can search for Z-Fusion which offers both Z-Image and Flux modes.\n\nMy times for my RTX 4070 8gb VRAM and 64gb RAM laptop:\n\n1024 resolution - easy 20-25 seconds per image\n\n1280 resolution - roughly 30-45 seconds per image\n\n1536 resolution - roughly 45-55 seconds per image",
              "score": 1,
              "created_utc": "2026-02-24 16:13:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7g9mwt",
                  "author": "sdozzo",
                  "text": "And SDXL with DMD is blazing fast!",
                  "score": 1,
                  "created_utc": "2026-02-26 03:22:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o732vtg",
          "author": "thevegit0",
          "text": "bluuuu archivuuuuuu",
          "score": 2,
          "created_utc": "2026-02-24 05:03:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73geji",
          "author": "RBriart",
          "text": "what is the best realism nsfw model rn to train on specific smut lora",
          "score": 1,
          "created_utc": "2026-02-24 06:52:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o753hkz",
          "author": "ConferenceIll417",
          "text": "![gif](giphy|8hsIwPLIGnZ1C)\n\n",
          "score": 1,
          "created_utc": "2026-02-24 14:30:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75mrtz",
          "author": "Velocita84",
          "text": ">blue archive\n\n![gif](giphy|21VTFJTEr1x9ortvO3|downsized)",
          "score": 1,
          "created_utc": "2026-02-24 16:02:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o780587",
          "author": "jmbbao",
          "text": "Post here the 400 images later",
          "score": 1,
          "created_utc": "2026-02-24 22:31:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7aj2wo",
          "author": "kirjolohi69",
          "text": "![gif](giphy|qLXHSdsiNWDTL4XHMi|downsized)",
          "score": 1,
          "created_utc": "2026-02-25 08:10:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7g6usa",
          "author": "sdozzo",
          "text": "What's Blue Archive?",
          "score": 1,
          "created_utc": "2026-02-26 03:05:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7g7heh",
          "author": "OohFekm",
          "text": "I look at my VR headset and untouched PC games with guilt...why? AI hath consumed me and with no shame, I say: \"Guilt be Damned\"",
          "score": 1,
          "created_utc": "2026-02-26 03:09:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7h8004",
          "author": "carbon_dating_broken",
          "text": "please teach me I have no idea how in stable difussion ,please\n\n",
          "score": 1,
          "created_utc": "2026-02-26 07:37:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7mn9l0",
          "author": "Dense-Celebration815",
          "text": "bro is down bad",
          "score": 1,
          "created_utc": "2026-02-27 02:12:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7mtzlp",
          "author": "SMPTHEHEDGEHOG",
          "text": "Mose sane Blue Archive player ever. Welcome!",
          "score": 1,
          "created_utc": "2026-02-27 02:51:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6wkwho",
          "author": "tac0catzzz",
          "text": "oh that is so cool.",
          "score": 1,
          "created_utc": "2026-02-23 05:24:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7846b3",
          "author": "Reasonable-Pay-336",
          "text": "I too loved it until a weird lora generated distorted genitalia and it's horrible now",
          "score": 0,
          "created_utc": "2026-02-24 22:52:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7g89wu",
          "author": "StuccoGecko",
          "text": "there he is officer.",
          "score": 0,
          "created_utc": "2026-02-26 03:14:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6x79jc",
          "author": "jonbristow",
          "text": "ew",
          "score": -10,
          "created_utc": "2026-02-23 08:46:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rfwdwy",
      "title": "A BETTER way to upscale with Flux 2 Klein 9B (stay with me)",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1rfwdwy",
      "author": "YentaMagenta",
      "created_utc": "2026-02-27 04:04:34",
      "score": 336,
      "num_comments": 95,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rfwdwy/a_better_way_to_upscale_with_flux_2_klein_9b_stay/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7o3ft2",
          "author": "Glove5751",
          "text": "Try using the word \"subtle\" in your prompt, so \"subtle high resolution\", \"subtle enhanced\" and etc.\nExample:\n\"Subtle high resolution, subtle color correction, subtle denoise\" is what I used last.\n\n\nThat gave me better results. I also used low steps, 4 to 8.\n\n\nSeedVR2 still is better since it looks more authentic, but this is better at adding artificial detail.",
          "score": 35,
          "created_utc": "2026-02-27 08:29:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7o3ozl",
              "author": "YentaMagenta",
              "text": "Thank you for the tip!",
              "score": 5,
              "created_utc": "2026-02-27 08:32:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7nuhu2",
          "author": "Stevie2k8",
          "text": "Just a tip from my findings... If you have another high resolution images of the person you try to upscale you can pass it in as second reference image and tell Klein to use the facial expressions from reference image 2. It really helped a LOT if the resolution is too low to really create the person and faces you want. ",
          "score": 12,
          "created_utc": "2026-02-27 07:08:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nv1de",
              "author": "lebrandmanager",
              "text": "Could you share an example workflow for that?",
              "score": 3,
              "created_utc": "2026-02-27 07:13:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7o035n",
                  "author": "Stevie2k8",
                  "text": "I just used the the flux 2 klein template from comfyui which already has 2 reference Images. The only thing I change is the target resolution... ",
                  "score": 9,
                  "created_utc": "2026-02-27 07:58:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7nvh1r",
          "author": "CutLongjumping8",
          "text": "Thank you for such a detailed analysis. In fact, when I created that previous thread about upscaling, I was actually hoping to read something exactly like this in the comments.\n\nEdit: here is my last try with linear upscale to 1.5 megapixels and prompt \"high resolution. refine image and remove jpeg compression artifacts. retain facial details, facial expression, objects position, color, gamma and lighting\"\n\n[https://imgsli.com/NDUyMzY1](https://imgsli.com/NDUyMzY1)",
          "score": 11,
          "created_utc": "2026-02-27 07:17:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7nf6f6",
          "author": "grundlegawd",
          "text": "Only issue is the artifacts still present in the skin. It‚Äôs so strange because Klein gets the skin about 90% right then sprinkles in some very strange looking wrinkles and discoloration.",
          "score": 10,
          "created_utc": "2026-02-27 05:06:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ntgan",
              "author": "TheSlateGray",
              "text": "I think it's Klein's built in bias to age up people. BFL just tweeted about it recently as a safety feature.\n\n\nIt adds wrinkles to smooth skin, so you have to balance between the plastic old flux skin and wrinkly new flux skin.¬†",
              "score": 6,
              "created_utc": "2026-02-27 06:59:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7ophfm",
                  "author": "Nexustar",
                  "text": "And this is why people hate safety features... It fucks up the model. The first thing I noticed was the guy aged 15 years.",
                  "score": 10,
                  "created_utc": "2026-02-27 11:49:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7nfmsg",
              "author": "YentaMagenta",
              "text": "At native resolution I'm not seeing it so much, but some of it is probably due to artifacts in the original. Also, if skin is too smooth, people complain about plastic.\n\nIt's always going to be a balancing act between fidelity, detail, and flawless skin.",
              "score": 2,
              "created_utc": "2026-02-27 05:10:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7ngk41",
                  "author": "grundlegawd",
                  "text": "I mean yes, clearly a lot of artifcating in the originals, but it‚Äôs very clear to my eyes that image one is displaying a very soft even tone, for example. Beauty filter like. Seems like Klein is picking up JPG artifacts and converting that into discoloration in the skin. There‚Äôs definitely a limit to how smooth you want skin to be to maintain some level of realism, but I‚Äôm confident that‚Äôs not what that woman‚Äôs skin looked like during that shoot is all I‚Äôm saying.\n\nThat said, I think Klein is fine for upscaling. A much faster solution than SeedVR2. But I still think SeedVR2 is superior in that domain. Which makes sense as that‚Äôs its entire purpose for existing.",
                  "score": 3,
                  "created_utc": "2026-02-27 05:16:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7p10n8",
          "author": "Ok_Cauliflower_6926",
          "text": "\"upscaled\"\n\nhttps://preview.redd.it/ka1ck0aud1mg1.jpeg?width=483&format=pjpg&auto=webp&s=78e538e1ff3fc3a9bb0ddb074a18f262cab7d7c9\n\n",
          "score": 8,
          "created_utc": "2026-02-27 13:09:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7od90d",
          "author": "Few-Term-3563",
          "text": "To me upscales always look off because it also tries to sharpen background blur that should be there, the focus is all over the place because of that and instantly looks AI.",
          "score": 2,
          "created_utc": "2026-02-27 10:03:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ojynd",
              "author": "addandsubtract",
              "text": "Why did I have to read this? Now I can't unsee it :(",
              "score": 1,
              "created_utc": "2026-02-27 11:04:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7riorv",
          "author": "ArsInvictus",
          "text": "I‚Äôve been trying to upscale a difficult image of an old painting and every model I tried would add strange distortions and textures to the paint and canvas texture.  Just tried your workflow and it worked perfectly.  I was then able to scale with siax and with the higher res base got a much better high res outcome.  Thank you!",
          "score": 2,
          "created_utc": "2026-02-27 20:34:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7rlrer",
              "author": "YentaMagenta",
              "text": "Amazing! I'm so glad it worked well for you. \n\nAnother commenter recommended using the word subtle sometimes if you find the effects too strong, just as an FYI. \n\nAlso, depending on the nature of the painting, I have also found that adding prompting about impasto, craquelure, canvas texture, and varnish can all be helpful.",
              "score": 2,
              "created_utc": "2026-02-27 20:49:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7rs3gt",
                  "author": "ArsInvictus",
                  "text": "Yep!  I added even canvas texture and that repaired some areas that were blurred in the low res source.  I'll experiment with this for some other artwork too.  Thanks again!",
                  "score": 2,
                  "created_utc": "2026-02-27 21:21:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7nq8gh",
          "author": "skk80",
          "text": "After trying multiple upscaling by various sdxl models, I figured flux. 2 klein 9B distilled provides the best upscaling! Everything else has upscale artifacts like you mentioned.\n\nSeedVR2 simply crashes on my system (5070 ti + 64GB ddr5) while doing any upscaling beyond 2mp. May be I don't know how to use it with it's million parameters!",
          "score": 3,
          "created_utc": "2026-02-27 06:32:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nupxc",
              "author": "psychicEgg",
              "text": "Hiya, try these settings:\n\nhttps://preview.redd.it/c3b6nkt5lzlg1.png?width=1128&format=png&auto=webp&s=572095eb54883d5a22df010c5ca6442042b1246e\n\nIf you have sage attention 2 installed then change the 'attention\\_mode', but I don't find it makes much difference. \n\nAlso, if you're still having any issues, drop the encode and decode tile size from 1024 down to 512. And also both tile overlaps to 64. If you're pixel peeping you'll see a tiny drop in detail zoomed in (more tiles means more blurring the edges).\n\nBut most important is the 'blocks\\_to\\_swap' (max is 36) and all three 'offload\\_device' to cpu.",
              "score": 5,
              "created_utc": "2026-02-27 07:10:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7nuwmc",
              "author": "lebrandmanager",
              "text": "Then try this node and workflows. It seems to work better for lower VRAM \n\nhttps://github.com/moonwhaler/comfyui-seedvr2-tilingupscaler",
              "score": 3,
              "created_utc": "2026-02-27 07:12:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7og0ud",
              "author": "its_witty",
              "text": "5070 Ti + 16GB (DDR4 ;])\n\nTo go beyond 2mp simply bump the 'blocks to swap' and enable tiled encode, or encode and decode. Also, I recommend going with the q6 quants for both the normal and sharp version. \n\n>May be I don't know how to use it with it's million parameters!\n\nEither GitHub or hover on the setting, everything is explained there. Give yourself 5 minutes to learn it and you'll get it, trust me!",
              "score": 2,
              "created_utc": "2026-02-27 10:29:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7nyekh",
              "author": "YentaMagenta",
              "text": "I don't blame you at all, that's one more reason I don't use it. I've simply never needed its performance to the point that that effort felt justified. What's more, at least some of the results from it that I've seen have had some issues that I felt were inconsistent with its level of hype.",
              "score": 0,
              "created_utc": "2026-02-27 07:43:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7otcs5",
          "author": "Allseeing_Argos",
          "text": "Anyone else thinks most AI upscalers tend to make the people look older?",
          "score": 2,
          "created_utc": "2026-02-27 12:17:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7oegga",
          "author": "takayatodoroki",
          "text": "I also did a lot of experiments.\n\nIn my opinion, there is not a best method for all kind of images.\n\nSome workflows work better with very low res or blurred images.\n\nFor 'normal' images i use 3 models in a row:\n\n1. SeedVR2 to upscale to the desired final size. In my test is the model that better keeps biometry. But it does not make HQ textures or other refinements. Sometimes I avoid this model if the image is too ruined.\n\nthe output image is passed to\n\n2) Qwen Edit with \"Qwen-Image-Edit-Unblur-Upscale\\_10\" lora  and the prompt:\n\n    remove watermarks. change image 1 to realistic photograph. Flash photography.  Neutral and perfectly tuned color.  unblur image 1. keep people, identity, facial features, expressions, skin texture, hair, clothing, pose, proportions. make face detailed. keep face consistent. make mouth detailed. keep mouth consistent. make eyes detailed. keep eyes consistent. make hair detailed. keep hair consistent. keep original colors. keep original light. \n\nNow the image has major defects cleaned, richer texture, better light and such, normally without losing people identity. what is missing is a better skin texture, so the output is passed to \n\n3) z\\_image\\_turbo\\_bf16 (with very low denoise such 0.1) with the  \"skin texture v2.1\" lora  (also the strength is reduced around 0.1 to avoid the risk of ruined skin). \n\n\n\nUsing 3 models It's a long task (i use two different workflows to make images in series and keep each workflow in my VRAM) but i have good results. A screenshot of an old VHS can become like a photo taken on the set.\n\nI probably could avoid the z\\_image pass and search for a skin texture lora for Qwen that works as well.",
          "score": 1,
          "created_utc": "2026-02-27 10:14:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7otnjc",
              "author": "Calm_Mix_3776",
              "text": ">I probably could avoid the z\\_image pass and search for a skin texture lora for Qwen that works as well.\n\nQwen Image is *terrible* with details and textures, almost SDXL level. No LoRA can salvage a flawed architecture. You'd definitely want an additional pass after that with another model that does good details and textures such as SeedVR2 or a model based on Flux.1/Flux.2.",
              "score": 2,
              "created_utc": "2026-02-27 12:19:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ol1x4",
          "author": "Coven_Evelynn_LoL",
          "text": "Imagine one day DLSS Ultra Performance looks identical to native 4k",
          "score": 1,
          "created_utc": "2026-02-27 11:13:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7orsh6",
          "author": "kng_arthur",
          "text": "how well does it perform with 256x144 resolutions? or is it way to small for it?",
          "score": 1,
          "created_utc": "2026-02-27 12:06:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7q3hrh",
          "author": "takayatodoroki",
          "text": "https://preview.redd.it/ehy3yn2tc2mg1.jpeg?width=1024&format=pjpg&auto=webp&s=04fdfe081e41e28781786a964e9090c1a0b406ff\n\nFlux.2 dev... always adds some skin impurity and it's hard to keep the original lights.",
          "score": 1,
          "created_utc": "2026-02-27 16:27:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7q49tf",
              "author": "YentaMagenta",
              "text": "Are you using the same workflow just with Dev swapped in and the steps and guidance adjusted?",
              "score": 1,
              "created_utc": "2026-02-27 16:31:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7qa65o",
                  "author": "takayatodoroki",
                  "text": "I've uploaded the workflow here: [https://pastebin.com/W5D23GjV](https://pastebin.com/W5D23GjV)\n\nrename the extension from txt to json\n\nI rarely use custom nodes, so it should work for everyone.",
                  "score": 1,
                  "created_utc": "2026-02-27 16:59:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7qbo03",
          "author": "Loose_Object_8311",
          "text": "Damn. After some iterating with this workflow on some ancient grainy-ass 200 \\~ 300 pixel images with tonnes of artifacts that traditional upscalers have always failed me on, I found the prompt below at 6 steps on both passes, at a denoise strength of between 0.85 \\~ 0.95 produces crazy results. So long as you don't mind the image changing a bit.\n\n\"high resolution image 1. Give her beautiful, clean, skin. Retain the same exposure, and lighting from image 1. Retain same facial expression from image 1. Retain the same shadows from image 1.\"\n\n  \nEdit: after much testing - another poster gave a tip to simply use \"Subtle high resolution, subtle color correction, subtle denoise\" and I've found sometimes that gives me my preferred result, and sometimes my version gives me preferred result depending on the source image. So, my workflow is now to A/B test them and pick the one I like best.",
          "score": 1,
          "created_utc": "2026-02-27 17:06:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7rnrts",
          "author": "Expicot",
          "text": "For drawings/clean lines, SeedVR2 is unbeatable (so far).\n\n[https://imgur.com/a/pAyBF8q](https://imgur.com/a/pAyBF8q)",
          "score": 1,
          "created_utc": "2026-02-27 20:59:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7skxri",
          "author": "mimitasangyou",
          "text": "Such a clean and vibrant piece.",
          "score": 1,
          "created_utc": "2026-02-27 23:56:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7o8kci",
          "author": "Synor",
          "text": "\"using Klein is simpler and faster than something like SeedVR2\"\n\nAbsolutely not.\n\n\"I have not done a direct comparison to SeedVR2 because, candidly, I don't use it.\"\n\nYou should. It's worth it.",
          "score": 1,
          "created_utc": "2026-02-27 09:18:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7o9d1l",
              "author": "YentaMagenta",
              "text": "I would welcome you to offer comparisons, as I noted in my post.\n\nI rarely if ever have a need for an upscaler better than the processes I already use, and with my work on perfecting Flux Klein Upscaling today, it's hard for me to see myself wanting to deal with custom nodes and an additional longer step.\n\nI have seen what the SeedVR2 workflows look like and they are absolutely more complicated than what I shared. The node alone has a ton of settings.\n\nBut here's your chance. show me some comparisons to my method and persuade me :)",
              "score": 1,
              "created_utc": "2026-02-27 09:26:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7odq0v",
                  "author": "SvenVargHimmel",
                  "text": "I'm not sure why some people are being so combative. I love SeedVR2 but it's expensive for what it is. Let's say Flux Klein isn't *as* good, it keeps your whole inference pipeline around a single model.  That is a good thing in my book. \n\nOn the color shift in skin tones, I think that is a thing with *all* models. Remember GPT4o , the joke was that it had a \"piss\" filter because of the *strong* yellow cast. It's not a strong with later models but it is there. I don't think that is an issue. Most images with a human subject almost always have to go through a color correction phase anyway and it's asking too much to expect our magical image models to understand a skin surface from different ethnicities in different lighting conditions under   \ndifferent white balance settings and color temperatures.",
                  "score": 2,
                  "created_utc": "2026-02-27 10:08:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7o9ugm",
                  "author": "Synor",
                  "text": "You are the one making the claims here.",
                  "score": -4,
                  "created_utc": "2026-02-27 09:31:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7nv530",
          "author": "fauni-7",
          "text": "That beige hue filter that Klein adds isn't going away. That's a defect in the model.",
          "score": 1,
          "created_utc": "2026-02-27 07:14:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nyzwh",
              "author": "YentaMagenta",
              "text": "I do notice that especially when doing a reference there is a bit of a bias toward warmer tones, but I think this is a think with nearly all models because images are biased toward warm tones in general. People tend to prefer warmer images, so both in terms of training data and any sort of aesthetic training, it's going to push the model in that direction. But this can be corrected with prompting or a very simple white balance adjustment.",
              "score": 1,
              "created_utc": "2026-02-27 07:48:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7o05fz",
                  "author": "fauni-7",
                  "text": "It's a defect, and very easy to prove: create a 4 img2img loop in the same workflow (I did), by the 4th ksampler the image is as yellow as a banana. No amount of prompting will fix that.  \nKrea has a similar issue.",
                  "score": -1,
                  "created_utc": "2026-02-27 07:59:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7nxiqh",
          "author": "po_stulate",
          "text": "I don't know, in the first pic the iron mesh becomes hemp rope and everything looks over sharpened.",
          "score": 1,
          "created_utc": "2026-02-27 07:35:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nzpfc",
              "author": "Fuzzyfaraway",
              "text": "I'm pretty sure that's a fiber net of some kind, attached to a bamboo pole/post/stick.",
              "score": 1,
              "created_utc": "2026-02-27 07:55:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7o00cs",
                  "author": "YentaMagenta",
                  "text": "Could someone call her up and ask her WTF that was?",
                  "score": 3,
                  "created_utc": "2026-02-27 07:58:02",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o7o0wh5",
                  "author": "po_stulate",
                  "text": "fibers do not curve like that.",
                  "score": -2,
                  "created_utc": "2026-02-27 08:06:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7su4w8",
              "author": "IndependenceNo783",
              "text": "It seems not every seed leads to a good generation. I changed the seed from fixed to increment, and submit 8 batches per image. Usually, 1 or 2 of them are great.",
              "score": 1,
              "created_utc": "2026-02-28 00:50:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7nxy77",
              "author": "YentaMagenta",
              "text": "Looks still like overexposed oxidized metal to me, but applying a blur to that area would be trivial. \n\nNo upscaling process is going to be perfect, but I daresay this one is still rather good.",
              "score": 0,
              "created_utc": "2026-02-27 07:39:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7pgppu",
          "author": "ZerOne82",
          "text": "https://preview.redd.it/fsd7gy0ms1mg1.jpeg?width=5120&format=pjpg&auto=webp&s=2fbfe40c023ea041e410c5dbd6f4b23dffc1171c\n\nIf you choose a very low res input image and the person is not known to you, it would impossible to evaluate which method/model/wf does better. So to avoid that, I used this input image from well-known Comfyanonymous to evaluate the likeliness. In my test, Klein 9B applied on the pre-upscaled input image using nearest method seems the best.  \nprompt: \"enhance it. add microdetails, keep it natural.\"",
          "score": 1,
          "created_utc": "2026-02-27 14:37:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7pptb4",
              "author": "sishgupta",
              "text": "> If you choose a very low res input image and the person is not known to you, it would impossible to evaluate which method/model/wf does better.\n\n1000000%",
              "score": 0,
              "created_utc": "2026-02-27 15:22:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ohob1",
          "author": "baddorox",
          "text": "Why not SEEDVR2?\n\nAm I missing something?",
          "score": 0,
          "created_utc": "2026-02-27 10:44:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7otm99",
          "author": "lazystingray",
          "text": "Are you de-blurring or up scaling ...?  The outputs are impressive but we need to remember that it's not the original content.  Not a dig, just a comment - these kind of images should never be passed as original.",
          "score": 0,
          "created_utc": "2026-02-27 12:19:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7pjsjk",
          "author": "nopalitzin",
          "text": "I think it turned jpeg artifacts into skin tone and texture, a lot of unusual colors in the face",
          "score": 0,
          "created_utc": "2026-02-27 14:52:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7nza24",
          "author": "tomuco",
          "text": "https://preview.redd.it/72tymomenzlg1.png?width=2048&format=png&auto=webp&s=ec0b89d532ab05274799d88928cdd424ef36d415\n\nJust cobbled this together in 10 minutes. Took the left image from the previous post (which might've even degraded it a bit more, I'm not too familiar with webp). Flux.1 Dev, absolute minimal workflow, no prompt, 32 steps, 1024x1024, otherwise default settings, Euler simple, seed:1. Added flux.1-dev-controlnet-upscaler. Set strength to 0.9, as default brought a bit too much grain, but it did come at the cost of losing a little bit of her facial likeness. Done. \n\nJust to be clear, if I tasked a professional with the job and this is what I'd receive, I'd want my money back. But that's not the point. This isn't just upscaling, it's also a fair bit of restauration. Even with AI, this requires much more work and multiple passes. Also, this was a VERY quick and dirty job, I didn't even try higher resolutions. However, I believe with some careful SDE noise scheduling, I could achieve even an better result in one pass. \n\nThe point however is, Klein can't do everything equally good, or even better than previous models (in this case F1 + a controlnet tailored to the task) and there's simply no perfect one-pass solution.",
          "score": -2,
          "created_utc": "2026-02-27 07:51:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nzton",
              "author": "YentaMagenta",
              "text": "I'm not sure I'm understanding you correctly. Are you suggesting that your result o the right is better than the one from Flux 2 Klein?",
              "score": 1,
              "created_utc": "2026-02-27 07:56:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7o10n0",
                  "author": "tomuco",
                  "text": "Yes. In terms of fidelity, defintely. But to reitereate, I'm not saying it's good as a final result, just as a first pass.",
                  "score": 0,
                  "created_utc": "2026-02-27 08:07:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7odmqp",
          "author": "HollowAbsence",
          "text": "why is everything greener after ?",
          "score": -1,
          "created_utc": "2026-02-27 10:07:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7pxq2r",
          "author": "KS-Wolf-1978",
          "text": "I am sorry, but the upscale you posted looks like she has 40 years of smoking and suntanning without any UV protection on.\n\nIt is not your fault, Klein just does that.\n\nFlux 1 Dev with controlnet: https://postimg.cc/WF8LFj1j\n\nThe only problem i see in my upscale is the hair strand on top right that looks bent at unnatural angles (inpaint easily fixes that).",
          "score": -1,
          "created_utc": "2026-02-27 16:00:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7pyf1m",
              "author": "YentaMagenta",
              "text": "People have skin details and imperfections and often want their upscalers to add them. But if you don't like them, it's very fixable:\n\nhttps://www.reddit.com/r/StableDiffusion/s/wR9yZqGkzi",
              "score": 1,
              "created_utc": "2026-02-27 16:03:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7pyu34",
                  "author": "YentaMagenta",
                  "text": "Also, using a control net is not apples to apples.\n\nI would be very excited to see Klein's performance with an analogous control net.",
                  "score": 1,
                  "created_utc": "2026-02-27 16:05:57",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o7q2l7b",
                  "author": "KS-Wolf-1978",
                  "text": "I see big blobs of same color on her skin like old people have or maybe some heavy jpg compression distortion.",
                  "score": 0,
                  "created_utc": "2026-02-27 16:23:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7nqfrg",
          "author": "devilish-lavanya",
          "text": "Don‚Äôt worry, We are not gonna leave you unless you fall for api trap.",
          "score": -2,
          "created_utc": "2026-02-27 06:34:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nxiog",
              "author": "YentaMagenta",
              "text": "Come again?",
              "score": 2,
              "created_utc": "2026-02-27 07:35:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ppl9v",
          "author": "sishgupta",
          "text": "The original was intentionally shot with a soft focus on the model, which is common in modeling shots. Unfortunately this is not just an upscale but a re-interpretation of the shot as it has completely robbed the original of it's artistic intent.",
          "score": -2,
          "created_utc": "2026-02-27 15:21:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7py1hb",
              "author": "YentaMagenta",
              "text": "The photo is from a 1950s copy of Playboy apparently, so separating artistic intent from the technical limitations of the medium is rather difficult. \n\nPeople generally want their upscalers to add detail and not adding detail is trivial.\n\nIf you look through the other comments you'll see that all I had to do was add soft focus and decrease the step count slightly to get a soft focus version.",
              "score": 1,
              "created_utc": "2026-02-27 16:02:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7q58aw",
                  "author": "sishgupta",
                  "text": "> The photo is from a 1950s copy of Playboy apparently, so separating artistic intent from the technical limitations of the medium is rather difficult. \n\nTell me you dont understand photography without telling me you dont understand photography.\n\n>People generally want their upscalers to add detail and not adding detail is trivial.\n\npeople generally dont want their upscalers to invent details that werent supposed to be there",
                  "score": -1,
                  "created_utc": "2026-02-27 16:36:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rckeon",
      "title": "Fine-tuning SDXL with childhood pictures ‚Üí audio-reactive geometries - [Experiment]",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/4s7zdq75i9lg1",
      "author": "Real-Philosopher-895",
      "created_utc": "2026-02-23 15:26:51",
      "score": 304,
      "num_comments": 21,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Animation - Video",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rckeon/finetuning_sdxl_with_childhood_pictures/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6ze7of",
          "author": "ThatOneDerpyDinosaur",
          "text": "Creative use of AI tools with zero bouncing anatomy. Have an upvote",
          "score": 15,
          "created_utc": "2026-02-23 17:16:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75m2oy",
              "author": "Real-Philosopher-895",
              "text": "‚ô•",
              "score": 3,
              "created_utc": "2026-02-24 15:58:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6z3gcw",
          "author": "repezdem",
          "text": "It's nice to see some actually good art made with AI tools. Great job",
          "score": 30,
          "created_utc": "2026-02-23 16:26:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zbxhl",
              "author": "zackmophobes",
              "text": "Agreed this is really cool and a fun use case. Thanks for sharing OP.",
              "score": 11,
              "created_utc": "2026-02-23 17:05:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o75lppv",
                  "author": "Real-Philosopher-895",
                  "text": "Thank you guys ‚ô•",
                  "score": 3,
                  "created_utc": "2026-02-24 15:57:17",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6zr77c",
          "author": "Tyler_Zoro",
          "text": "Hope you don't mind, but I've uploaded this video to the aiwars sub [here](/r/aiwars/comments/1rcp4rv/this_is_what_creative_people_do_with_new/). Sadly, that sub doesn't let me link to your post or mention you by name, but if you want to poke your head in and claim credit, please do!",
          "score": 5,
          "created_utc": "2026-02-23 18:16:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o722ng3",
          "author": "Itiiip",
          "text": "finally, introspective diffusion",
          "score": 4,
          "created_utc": "2026-02-24 01:18:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75m5nt",
              "author": "Real-Philosopher-895",
              "text": "I like that name. Thanks for the idea.",
              "score": 3,
              "created_utc": "2026-02-24 15:59:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o702pwa",
          "author": "bigman11",
          "text": "good experiment",
          "score": 3,
          "created_utc": "2026-02-23 19:09:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o707gde",
          "author": "Mid-Pri6170",
          "text": "needs to be in a gallery.",
          "score": 3,
          "created_utc": "2026-02-23 19:31:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75m7it",
              "author": "Real-Philosopher-895",
              "text": "I'd love that.",
              "score": 2,
              "created_utc": "2026-02-24 15:59:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6zkoav",
          "author": "raulsestao",
          "text": "Where can I find the first song from the video? It's very pretty, is it AI too?",
          "score": 2,
          "created_utc": "2026-02-23 17:46:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75m1zy",
              "author": "Real-Philosopher-895",
              "text": "Hey, thank you. No, no. It's composed by me. If I recall correctly I used my Osmose + Cosmos \\[SOMA\\] synths.",
              "score": 2,
              "created_utc": "2026-02-24 15:58:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6zwd76",
          "author": "mcpoiseur",
          "text": "I like the wobbly ness",
          "score": 2,
          "created_utc": "2026-02-23 18:40:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o750y81",
          "author": "Weak-Abbreviations15",
          "text": "Bro just made a Flashbacks before you die simulator. ",
          "score": 2,
          "created_utc": "2026-02-24 14:16:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70kg8m",
          "author": "jefharris",
          "text": "Very cool.",
          "score": 1,
          "created_utc": "2026-02-23 20:32:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o72coxd",
          "author": "diarrheahegao",
          "text": "Nice, what songs did you use for the video?",
          "score": 1,
          "created_utc": "2026-02-24 02:16:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75m9te",
              "author": "Real-Philosopher-895",
              "text": "None, it's a little something composed by me. ",
              "score": 2,
              "created_utc": "2026-02-24 15:59:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o73bxrx",
          "author": "Wormri",
          "text": "It's like something straight out of Control.",
          "score": 1,
          "created_utc": "2026-02-24 06:14:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76obc0",
          "author": "Professional-Alps479",
          "text": "Very nice.",
          "score": 1,
          "created_utc": "2026-02-24 18:50:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ys4hn",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -12,
          "created_utc": "2026-02-23 15:33:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rboeta",
      "title": "ZIB vs ZIT vs Flux 2 Klein",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1rboeta",
      "author": "Both-Rub5248",
      "created_utc": "2026-02-22 15:18:17",
      "score": 266,
      "num_comments": 176,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rboeta/zib_vs_zit_vs_flux_2_klein/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6seej0",
          "author": "Enshitification",
          "text": "It should be mentioned that neither ZiT nor ZiB have any edit capabilities. That is where Flux2.Klein dominates.",
          "score": 67,
          "created_utc": "2026-02-22 15:51:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sknu2",
              "author": "SlothFoc",
              "text": "For real, which is why I had to raise an eyebrow at this line from OP:\n\n>The huge Lora set for ZIT and ZIB also allows the model to be used in a wider range than the Flux 2 Klein.\n\nLike what? I can literally show Klein an image and say, \"make this\" and it will. The need for LoRas has been drastically reduced because of its edit capabilities.",
              "score": 35,
              "created_utc": "2026-02-22 16:18:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6url6l",
                  "author": "ThatRandomJew7",
                  "text": "Not to mention that Klein has LoRAs.\n\nIn fact a lot of the people that make them have said Klein trains much more easily than Z Image",
                  "score": 9,
                  "created_utc": "2026-02-22 22:39:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6sqovn",
                  "author": "Both-Rub5248",
                  "text": "I compared the models only in the T2I connector, I think this is obvious, which is why I did not touch on the Edit capabilities of this model.\n\nIt is clear that Flux 2 Klein will be better at general tasks, but it should not be forgotten that I was comparing exclusively in T2I tasks, not in I2I.\n\nFlux 2 Klein is not a universal model that can do absolutely everything. For T2I tasks, I would rather use ZIT, but for refinement (edit) or other tasks related to I2I, it is certainly better to use F2K.",
                  "score": 4,
                  "created_utc": "2026-02-22 16:45:12",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o6zyij3",
                  "author": "Imaginary_Belt4976",
                  "text": "Yeah, edit is almost a misnomer in some applications because its more like \"follow the example\". I have had amazing results bringing in specific clothing or objects using this technique, but you made me realize I havent actually tried using an image like this for t2i directly so now I need to try it!",
                  "score": 1,
                  "created_utc": "2026-02-23 18:49:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6sngu7",
                  "author": "Jetsprint_Racer",
                  "text": "Well, you still need LoRAs for it but more like guides. Even in dual-image mode it can inpaint some things wrong or modify the object's look from Image2 according to F.2K's dataset. Still, F.2K at least can work with LoRAs properly, compared to ZIT which often produces distorted outputs when LoRA is attached. Some people just recommend to lower the strength of course. Yeah, this tip works great when you use style LoRA. But not so great when you literally need 1.0 strength to make it work. Compared to good old Stable Diffusion (including 1.5), ZIT is terrible at LoRAs.",
                  "score": -1,
                  "created_utc": "2026-02-22 16:30:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6u2mib",
              "author": "RayHell666",
              "text": "I feel that people are missing out on Klein edit potential. Despite some body horror from pure T2I it's the most powerful local model I ever played with and it should not be seen as T2I vs I2I because that's one model that do everything unlike Qwen-image 2512 and Qwen-image edit 2511 that is 2 separate models to juggle with. I feel the same thing will happen to Z-Image Edit.",
              "score": 6,
              "created_utc": "2026-02-22 20:32:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6u5bpb",
                  "author": "Enshitification",
                  "text": "I'm using K9B right now to upscale and enhance a 640x quality dataset to 2MP. It is giving the results the best skin coloration and texture that I have seen in any model so far.",
                  "score": 5,
                  "created_utc": "2026-02-22 20:45:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6t2cav",
              "author": "Sarashana",
              "text": "IMHO it's fair game to look only at generations in such a comparison. While having editing and generation capability in the same model is neat, it's not THAT much work to switch to a different model when editing is required. I use ZIT for generation and Qwen Image Edit for editing, myself.",
              "score": 3,
              "created_utc": "2026-02-22 17:38:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6x88ke",
                  "author": "General_Session_4450",
                  "text": "Biggest advantage IMO is that you can train a single LoRA for it and use it both for generating full images and editing.",
                  "score": 1,
                  "created_utc": "2026-02-23 08:55:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6sjjrl",
              "author": "Jetsprint_Racer",
              "text": "I have only two F.2K workflows - both img2img, none of them is txt2img. One for general editing, one for lossless inpainting. It literally replaced Fooocus Inpaint for me which was my #1 editing tool for two years. Also works great as image enhancer which removes all these FP8/Turbo model artifacts, cuz SeedVR2 is merciless to ZIT outputs.",
              "score": 5,
              "created_utc": "2026-02-22 16:13:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6skbhw",
                  "author": "Enshitification",
                  "text": "Klein can be good for txt2img too if the prompts are good and one doesn't use an fp8 or quant of Qwen3-8B. I'm mostly using it right now to enhance and clean up a big low-quality dataset. It is unbelievably good at that task.",
                  "score": 4,
                  "created_utc": "2026-02-22 16:16:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6svh3d",
                  "author": "zekuden",
                  "text": "where do you use it? comfyUI?",
                  "score": 2,
                  "created_utc": "2026-02-22 17:06:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6srue4",
                  "author": "Both-Rub5248",
                  "text": "I don't know what problems you're talking about with Lora at ZIT, because I have cases where I used ZIT generation with 4-5 Loras and they did their job perfectly.\n\n1. Lora for adding details (1.1)\n\n2. Lora slider for Boobs (0.4)\n\n3. Lora slider for lighting brightness (1)\n\n4. Lora for amateur photos (0.45)\n\nAnd with all these LORA images, the results were perfect, and after running them through SeedVR2, the images came out first-class.\n\nI have never encountered such problems!",
                  "score": 2,
                  "created_utc": "2026-02-22 16:50:22",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6v1wed",
              "author": "Toby101125",
              "text": "Can you elaborate on edit? Like change the prompt wording without it totally changing?",
              "score": 2,
              "created_utc": "2026-02-22 23:37:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6v3jkq",
                  "author": "Enshitification",
                  "text": "Edit, as in \"remove the person on the left\" or \"change the subject to profile view\". The edit models are incredibly powerful like that.",
                  "score": 4,
                  "created_utc": "2026-02-22 23:46:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6spopt",
              "author": "Both-Rub5248",
              "text": "Well, that's super obvious, which is why I didn't write about it; only the T2I capabilities of the models were compared)  \nBut I would really like to wait for Z-Image Edit to come out and compare it with Flux 2 Dev, Flux 2 Klein, Qwen Edit, and FireRed Edit.\n\nWell, Flux 2 currently has no competitors in terms of editing capabilities, except for NanoBanana or to some extent FireRed Edit.",
              "score": 3,
              "created_utc": "2026-02-22 16:40:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6ss2ra",
                  "author": "Enshitification",
                  "text": "Qwen Image Edit also exists and is quite good.",
                  "score": 6,
                  "created_utc": "2026-02-22 16:51:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6smrp8",
              "author": "deadsoulinside",
              "text": "You can do image to image and even some inpainting with ZiT.",
              "score": 1,
              "created_utc": "2026-02-22 16:27:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6snxtl",
                  "author": "Enshitification",
                  "text": "Inpainting and img2img are not at all the same as edit.",
                  "score": 8,
                  "created_utc": "2026-02-22 16:32:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6upobl",
              "author": "YMIR_THE_FROSTY",
              "text": "Z image has edit version.",
              "score": -5,
              "created_utc": "2026-02-22 22:29:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6uqoiz",
                  "author": "Enshitification",
                  "text": "Really? Where can it be downloaded?",
                  "score": 4,
                  "created_utc": "2026-02-22 22:34:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6sj9mb",
          "author": "Finguili",
          "text": "What is it, a comparison that not only clearly labels which model was used to generate which image, but also provides full prompts? Am I on the right subreddit?\n\nThanks OP for posting, the prompt are quite varied. It‚Äôs funny how Z-Turbo ignored request for non-blurry background and how models in general struggle with age. These \"25 years old\" women by Z Image looks closer to 50 than 25.",
          "score": 22,
          "created_utc": "2026-02-22 16:11:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6txmze",
              "author": "Winter_unmuted",
              "text": "Hey now, not everyone here posts terrible comparisons. \n\nI always do full labeling and even made a post on how to label stuff properly. \n\nThere are dozens of us. DOZENS!",
              "score": 3,
              "created_utc": "2026-02-22 20:06:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6sv0dg",
              "author": "Both-Rub5248",
              "text": "***Flux 2 Klein 9B DISTILL FP8***  \n***Z-image Base FP8, FP8 scale, FP8 Mixed, FP4, Q5, BF16*** \\- I generated all these quantisations with the same seed, selected the best option from all the variants, and added it to the comparison.  \n***Z-image Turbo FP8***\n\nI tried all sorts of negative prompts for ZIB, wrote negative prompts in batches that I found on Reddit, sometimes wrote negative prompts individually for each image. Believe me, I spent enough time to squeeze the maximum possible out of ZIB, and what you see in comparison is better generations that came out on ZIB.",
              "score": 2,
              "created_utc": "2026-02-22 17:04:45",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6wwtm9",
              "author": "NorthernRealmJackal",
              "text": ">These \"25 years old\" women by Z Image looks closer to 50 than 25.\n\nMany models/encoders will respond better to \"mid-to-early twenties\" or \"late teens\" than to a specific number.\n\nI'm not sure what the purpose of the square brackets are, in those prompts (user input maybe). ZIT, for instance doesn't do weighted parameters and such, so maybe it gets thrown off by anything that isn't natural language.",
              "score": 2,
              "created_utc": "2026-02-23 07:06:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6ssg9h",
              "author": "Both-Rub5248",
              "text": "Can you name at least one basic model (not Checkpoint, not model assemblies such as SD 1.5 by Yoshi) that will not ignore the \"non-blurry background\" prompt without additional LORA?",
              "score": 1,
              "created_utc": "2026-02-22 16:53:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6t6kg0",
                  "author": "Finguili",
                  "text": "Eh, I was simply making fun if Z-Image Turbo which loves to ignore half of the prompt. But to answer your question, I tried Z-Image Base with \"blurry background\" in negative prompt and it makes everything sharp, though I cannot say that it makes results look better. This also works with SDXL anime models, as \"blurry background\" is danbooru tag.",
                  "score": 4,
                  "created_utc": "2026-02-22 17:58:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6ve1aa",
                  "author": "DrummerHead",
                  "text": "The problem with prompting \"non-blurry background\" is that the model can be free to interpret it as \"non?... Blurry background!\". It's always better to prompt positively, always say what you want. When you talk about what you don't want, you're inadvertently adding tokens that steer the intention towards what you don't want. If the model supports a negative prompt, then add \"blurry background\" to the negative and in the positive say \"sharp contrast, focused\" or similar terms.\n\nhttps://en.wikipedia.org/wiki/Ironic_process_theory applies to AI models",
                  "score": 3,
                  "created_utc": "2026-02-23 00:46:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6skowo",
          "author": "alerikaisattera",
          "text": "What klein?",
          "score": 6,
          "created_utc": "2026-02-22 16:18:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6st6f1",
              "author": "Both-Rub5248",
              "text": "Klein 9B Distill FP8, sorry, I forgot to mention that.",
              "score": 5,
              "created_utc": "2026-02-22 16:56:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6uxf60",
                  "author": "terrariyum",
                  "text": "In your opinion, how does the t2i of Klein 9B base vs K9B distill?  Zi in ZiT are very different (beside one being much faster).  Is the same true for K9B versions?",
                  "score": 1,
                  "created_utc": "2026-02-22 23:11:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6vbhoh",
                  "author": "Impressive-Scene-562",
                  "text": "Could you share your klein 9B workflow please?",
                  "score": 1,
                  "created_utc": "2026-02-23 00:32:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6taf8z",
          "author": "siegekeebsofficial",
          "text": "When z image base was released, it was already known the output quality was not as good as ZiT, think of ZiT as a realistic fine-tune of z image, z image base is more generalized and flexible and gives the opportunity for the community to develop their own fine tunes, but that will take time.",
          "score": 6,
          "created_utc": "2026-02-22 18:15:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6s82o1",
          "author": "wallofroy",
          "text": "I‚Äôm going with turbo",
          "score": 15,
          "created_utc": "2026-02-22 15:21:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6svjwf",
              "author": "berlinbaer",
              "text": "base still shines for me with better prompt adherence and diversity. i think overall you need a bit more robust prompting to make it really shine so when you just put in \"1girl big boobs\" it struggles a bit.\n\nklein is nearly unuseable for me for how often it generates extra limbs.\n\nalso saying ZIB is bad for realistic style scenarios is laughable. \n\nhttps://imgur.com/a/oLvD8GX\n\nhttps://imgur.com/a/21rb7BO\n\nall just z-image base with regular prompting.",
              "score": 7,
              "created_utc": "2026-02-22 17:07:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6sx02x",
                  "author": "wallofroy",
                  "text": "They all are good at specifics things sometimes I get great images with flux Klein 9B distill",
                  "score": 1,
                  "created_utc": "2026-02-22 17:13:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6sau5y",
              "author": "WartimeConsigliere_",
              "text": "Agree, to me it gets the spirit of the prompt most consistently",
              "score": 2,
              "created_utc": "2026-02-22 15:34:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6sqs4r",
                  "author": "General_Session_4450",
                  "text": "It seems like the opposite to me? ZIT tends to look better but is not following the instructions as well.\n\nThe zebra image style is clearly digital illustration rather than hand-drawn comic book style.\n\nThe vintage photo is prompted for a messy 90s retro room but instead made some weird Soviet style computer setup, wires also make no sense here.\n\nThe princess peach image looks better but it failed at \"the background is sharp and not blurred.\"\n\nThe Octane render of a 25 year old woman makes her look way too old and has the iconic ZIT noise texture all over her skin.\n\nThe CCTV footage put multiple people on the court when the prompt said \"A basketball player\", the style itself is okayish but not really what I would call CCTV style. It also again has the iconic ZIT noise texture all over the wood tiles.\n\nThe isekai style failed hard on \"amplified colors accents and epic composition\" and instead create an image with muted colors, simplistic background, and vectorized style.",
                  "score": 9,
                  "created_utc": "2026-02-22 16:45:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6sc937",
                  "author": "Both-Rub5248",
                  "text": "I am eagerly awaiting Z Image Edit so that I can compare it in Edit scenarios with Flux 2, Flux 2 Klein, and FireRed Edit.",
                  "score": 4,
                  "created_utc": "2026-02-22 15:41:28",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6sm6h8",
              "author": "deadsoulinside",
              "text": "LOL I was going to say the same",
              "score": 0,
              "created_utc": "2026-02-22 16:24:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ur2r5",
          "author": "YMIR_THE_FROSTY",
          "text": "Z-image base is very good and for obvious reasons it follows prompt very well. Rest cant so well, due those reasons. In my opinion, best.\n\nOnly exception is age, which is due training. Those models mostly respond to non-numerical age description, like \"mature/adult/old\" or some emphasis in \"very old\" and such. Maybe you could persuade it to do something like 25 years old, but it would need a bit more effort. Or just LoRA that can do age somewhat accurately.\n\nSame stuff is majority of SDXL (and similar) based models. While majority of users type in stuff (especially on civit) like 18-yrs-old, with models they use, apart few exceptions, its basically like if there would be nothing.",
          "score": 3,
          "created_utc": "2026-02-22 22:37:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6v4s4o",
              "author": "Both-Rub5248",
              "text": "Yes, I know about the age; it would be more correct to write \"young girl 25 years old\" here, or other more understandable descriptions of age, such as \"student\" etc.  \n25 years is just a rough guide, not the basis for the request.\n\nBut I deliberately wrote a poor-quality prompt to see how the models would cope with it.  \nTo be fair, it would have been necessary to conduct the test with a more accurate age prompt.",
              "score": 3,
              "created_utc": "2026-02-22 23:53:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6t3ttr",
          "author": "cobra838",
          "text": "1. Klein (I like Klein vibes more)\n2. ZIB (I like the chip design more in ZIB)\n3. ZIB (ZIT and Klein have a more Western European style)\n4. ZIT (It's hard to judge such a comic book style, but ZIT did it better)\n5. All are good (the ZIB Nike 1girl has less of an AI vibe, cause it is more dynamic)\n6. Klein (probably)\n7. ZIT (ZIB looks overcooked and Klein does not look like Peach at all)\n8. Klein (all of them look like women aged 40-50 rather than 25, though Klein probably looks a bit younger)\n9. Klein (Klein and ZIB are quite decent, ZIT is blurry)\n10. ZIB (probably)\n11. ZIB (choosing ZIB because it has fewer AI vibes)\n12. ZIB (ZIB because it has fewer AI vibes, Klein is second. ZIT is complete trash)\n13. All are good\n\nOverall:\n\n* ZIB: 5\n* ZIT: 2\n* Klein: 4",
          "score": 5,
          "created_utc": "2026-02-22 17:46:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6t9u13",
              "author": "Both-Rub5248",
              "text": "I like that you have compiled such a table and backed it up with explanations. Thanks for this.\nI was really interested in alternative opinions, especially with explanations of your opinion.",
              "score": 1,
              "created_utc": "2026-02-22 18:13:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6tanrm",
          "author": "LiveLaughLoveRevenge",
          "text": "Agree with all that you‚Äôve said here. But would like to add:\n\nFlux is great on accuracy, text, editing etc - but I‚Äôm constantly frustrated that it also can give the most ‚Äúobviously AI‚Äù images. Your Slavic fantasy image here is a perfect example of this. \n\nAs an alternative to LoRAs to improve variety in ZIT, you can also do a hybrid workflow of ZIB>ZIT, where ZIB crates the initial image, which is then denoised partially by ZIT.  It takes longer than ZIT but not as long as just using ZIB since you don‚Äôt have to fully generate the ZIB image, and can also upscale your latent between steps (so only ZIT does the full resolution). This has become my go-to when going entirely T2I with no reference images.",
          "score": 5,
          "created_utc": "2026-02-22 18:16:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6tgax1",
              "author": "Both-Rub5248",
              "text": "The connection between ZIT and ZIB looks interesting. Do you have a workflow or a screenshot of part of the workflow?\nI would like to test it.\n\nThank you in advance!",
              "score": 2,
              "created_utc": "2026-02-22 18:42:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6thrbi",
                  "author": "LiveLaughLoveRevenge",
                  "text": "Sure, here is the JSON for my hybrid workflow.\n\nhttps://files.catbox.moe/9s9hvw.json\n\nI'm still tinkering with it (ignore that 'dark mode' thing, it is unfinished).  It has some custom nodes but they are just for things like style selectors and easy setting the empty latent size.\n\nKey is the ZIB>ZIT part, and the latent upscale.  The rest of it can be swapped out with whatever you prefer.",
                  "score": 2,
                  "created_utc": "2026-02-22 18:49:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6vasfc",
          "author": "terrariyum",
          "text": "OP, I have some ideas that you can test that might change your opinions on ZiT vs Zi.  The more I use ZiT, the more I encounter the limitations of distillation.  I'm not shitting on ZiT here - overall quality and speed are great - I'm just pointing out its limitations.\n\n### Caveats for all my tests:\n* You have to use a detailed prompt because the more detail you add, the more ZiT looses diversity\n* Yes, it's possible to *sometimes* do any of these things with enough rerolls and careful prompt tweaking, but then all speed advantage of ZiT is lost\n* Yes a lora can fix any individual issue here, but every lora decreases diversity in things unrelated to the lora, even sliders.  Once you use multiple loras, diversity loss gets extreme\n* These are just the examples I can remember, but I've banged my head against many other knowledge limitations of distillation\n\n### Lighting\n* ZiT strongly leans towards boring simplistic lighting:\n  * Either frontal flash photography (like your computer room example)\n  * Or simple outdoor sunlight (like your bicyclist and princess peach examples)\n* Try testing:\n  * indoor setting without sunlight (e.g. in a bar)\n  * outdoor setting at night time\n  * prompting for specific lighting like rim-light, specific directionality, specific colors\n * in your octane render example, the ZiT lighting looks great (are you sure you didn't accidentally switch ZiT and Zi?).  But I bet if that if you add specific details about clothes, hair, and background objects, the ZiT lighting will get boring\n\n### Hairstyles\n* ZiT knows very few hairstyles, and certain hairstyles keywords are strongly associated with certain ages/ethnicities/makeup/etc.\n* Try testing:\n  * caucasian woman with pink hair\n  * pink hair but without dark roots\n  * short hair but without bangs\n  * sculpted cosplay/wig style (like your princess peach example) but with normal clothes\n  * classic 90s blowout hair or \"pageant\" hair (google to see example).  ZiT thinks \"blowout\" means curly\n\n### Facial expressions\n* ZiT can only do extreme expressions - e.g. tongue out is waaaay out, pouting is like they just bit into a lemon, surprised is like a soyjak meme\n\n### Blending anything\n* ZiT is very blending concepts creatively.  People often mention the issue with seed diversity (e.g. composition), but SVE node at least helps with that.  Nothing can fix the general lack of concept diversity and ability to blend them.\n* Try testing:\n  * Blend clothes styles of two characters ZiT knows (e.g. princess peach and lara croft)\n  * Blend cyberpunk or mecha with princess-style ornate dress\n  * harder examples like blending a motorcycle and a toy horse\n\n### Body poses\n* ZiT often makes boring body poses.  If you try to tell it where each limb goes, it's like a limp marionette.  \n* Non-photo style has better posing - like you got great results in your isekai example.\n* Try testing:\n  * standing but with legs crossed\n  * kneeling with only one knee touching the ground\n  * running hand through hair (not pulling hair away)\n  * any interesting standing pose (google \"standing pose ideas\") any try to imitate with prompting",
          "score": 4,
          "created_utc": "2026-02-23 00:28:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6vckdg",
              "author": "Both-Rub5248",
              "text": "Thank you very much. In my next posts, I will try to work more precisely with lighting, poses, and everything else you mentioned.\n\nThese images are my standard test images. I have been thinking for a long time that I need to diversify and refine them, so you have given me a very good idea for new tests.\n\nThank you very much for such a detailed comment, I appreciate it!",
              "score": 3,
              "created_utc": "2026-02-23 00:38:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6veb2n",
                  "author": "terrariyum",
                  "text": "I also appreciate your post!  Your standard test prompts already cover many styles and scenarios well",
                  "score": 5,
                  "created_utc": "2026-02-23 00:47:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6vcm9v",
              "author": "Both-Rub5248",
              "text": "No, I didn't mix up the generations in the Octane render example, everything is correct there",
              "score": 2,
              "created_utc": "2026-02-23 00:38:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6vefy1",
                  "author": "terrariyum",
                  "text": "Cool, good to know.  Sometimes ZiT gets it better for sure",
                  "score": 2,
                  "created_utc": "2026-02-23 00:48:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6x7pt3",
              "author": "Ken-g6",
              "text": "If you have an existing pose, that's what controlnet is for. Which would also be a good thing to test, ZiT with a controlnet. I don't think Klein has a separate controlnet, but it should work without it, saying \"pose from image 1\" or something, or with the controlnet image as a direct input.",
              "score": 2,
              "created_utc": "2026-02-23 08:50:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6xlwcz",
              "author": "OliverHansen313",
              "text": "You mention an SVE node. I can't find that anywhere. Could you elaborate on what this is?",
              "score": 1,
              "created_utc": "2026-02-23 11:07:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7177br",
                  "author": "terrariyum",
                  "text": "https://github.com/ChangeTheConstants/SeedVarianceEnhancer\n\nIt's essential for using ZiT because it makes the same prompt on different seeds produce different images.  \n\nBut it's not like with SDXL, where different seeds produce different images that are all constrained to the prompt.  SVE works by making each image *less* constrained to the prompt.  \n\nYou need to constantly fiddle with its many dials to find the sweet spot between it having no effect nothing and it deviating too far from the prompt, and that spot is different for every prompt.",
                  "score": 2,
                  "created_utc": "2026-02-23 22:24:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6sj0po",
          "author": "TheSlateGray",
          "text": "Did you use a negative prompt with ZIB?\n\nWith Klein, I'm assuming you used the distilled fast model, but 4b or 9b?",
          "score": 2,
          "created_utc": "2026-02-22 16:10:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6st61u",
              "author": "Both-Rub5248",
              "text": "Yes, I used different sets of negative prompts and selected the best results for ZIB. I will say more: for generation for ZIB, I used FP8, FP8 Scale, FP8Mix, FP4, Q5, BF16, and from all the generations of these models, I selected the best.  \nIt's just that ZIB has this specific quality of generation without Lora.\n\nKlein 9B Distill, sorry, I forgot to mention that.",
              "score": 2,
              "created_utc": "2026-02-22 16:56:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6sm0sl",
          "author": "Current-Rabbit-620",
          "text": "Turbo  for me",
          "score": 2,
          "created_utc": "2026-02-22 16:24:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6smll7",
          "author": "SanDiegoDude",
          "text": "All 3 have their strengths, and I find myself using each for those strengths in tandem. ZIT has turned into my favorite \"finisher\", Klein editing is incredible, and ZIB has great bones and is really good at world knowledge and natural scene building.",
          "score": 2,
          "created_utc": "2026-02-22 16:26:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6suth2",
          "author": "Both-Rub5248",
          "text": "**I forgot to mention that I used:**\n\n***Flux 2 Klein 9B Distill FP8***  \n***Z-image Base FP8, FP8 scale, FP8 Mixed, FP4, Q5, BF16*** \\- I generated all these quantisations with the same seed, selected the best option from all the variants, and added it to the comparison.  \n***Z-image Turbo FP8***\n\nI tried all sorts of negative prompts for ZIB, wrote negative prompts in batches that I found on Reddit, sometimes wrote negative prompts individually for each image. Believe me, I spent enough time to squeeze the maximum possible out of ZIB, and what you see in comparison is better generations that came out on ZIB.\n\n**In the coming days, I will post a comparison of all quantisations for ZIB (FP8, FP8 scale, FP8 Mixed, FP4, Q5, BF16)**",
          "score": 2,
          "created_utc": "2026-02-22 17:03:55",
          "is_submitter": true,
          "replies": [
            {
              "id": "o6t8mhl",
              "author": "rm_rf_all_files",
              "text": "Do you see noticeable differences in quality from ZiT fp4 vs ZiT bf16? I see it and that made me stop using it completely. Others said they don't see it. I generate only at 1MP and I can see it clearly. I wonder if fp8 would be better.",
              "score": 2,
              "created_utc": "2026-02-22 18:07:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6tf5mx",
                  "author": "Both-Rub5248",
                  "text": "I haven't compared quantisation on ZIT.\nBut the differences between BF16 and FP4 are very noticeable in absolutely all models, because the compression in FP4 is too high.\n\nI know that the difference in quality between BF16 and FP8 is about 10-20%, but the difference between BF16 and FP4 is already about 40-50%.\n\nI will soon publish a post about quantisation on ZIB.\nPerhaps you will find answers to your questions there.\nBut I will say in advance that in some scenarios, even FP4 outperforms BF16, at least in ZIB models.",
                  "score": 2,
                  "created_utc": "2026-02-22 18:37:23",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6tdov1",
          "author": "NunyaBuzor",
          "text": "1. Turbo\n\n2. tie between base and klein\n\n3. Base wins\n\n4. Turbo\n\n5. Turbo\n\n6. Tied between turbo and klein\n\n7. tied between turbo(character) and klein(background)\n\n8. klein\n\n9. klein\n\n10. klein\n\n11. klein\n\n12. turbo\n\n13. base or klein?\n\n14. klein",
          "score": 2,
          "created_utc": "2026-02-22 18:30:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6tghjy",
              "author": "Both-Rub5248",
              "text": "Thank you for your comment!",
              "score": 1,
              "created_utc": "2026-02-22 18:43:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6terja",
          "author": "dreamyrhodes",
          "text": "ZiT often creates third legs or arms in the first steps but then removes (corrects) them in later steps.",
          "score": 2,
          "created_utc": "2026-02-22 18:35:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6th1yu",
              "author": "Both-Rub5248",
              "text": "Yes, I noticed that too. The main thing is that the final image is produced without mutation, unlike Flux 2 Klein, which also makes mistakes in the early staps but then does not correct them and relies on the anatomy created in the early staps of generation.",
              "score": 1,
              "created_utc": "2026-02-22 18:45:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6vb09l",
                  "author": "Ill-Engine-5914",
                  "text": "Do the first or later steps in AI generation actually mean something? I thought steps just referred to how many times they train the model, is that wrong? ",
                  "score": 2,
                  "created_utc": "2026-02-23 00:29:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6tfaxu",
          "author": "elfninja",
          "text": "Side question, but how do you come up with these detailed prompts? Whenever I have a picture in my head I always struggle to get my descriptions right. Do you work with another LLM to detail out your prompt? Find presets from elsewhere? Something else?",
          "score": 2,
          "created_utc": "2026-02-22 18:38:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6tigwu",
              "author": "Both-Rub5248",
              "text": "The simpler prompts are the ones I came up with myself.\n\nThe biggest prompts are the ones I found on the internet.\n\nSome prompts are just my personal descriptions of pictures I found on Pinterest.\n\nSometimes I use prompt builders where you can take part of a prompt to create light, part to create hair, part for shot size, and so on.\n\nI rarely use LLM, except in cases where I need to structure and shorten what I have written from scratch.",
              "score": 2,
              "created_utc": "2026-02-22 18:52:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6tsxyj",
                  "author": "elfninja",
                  "text": "Darn, to be honest, I was really hoping for some magic LLM prompt that would make things easier. Thanks for sharing.",
                  "score": 2,
                  "created_utc": "2026-02-22 19:43:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6v1t1i",
          "author": "Toby101125",
          "text": "Flux knows which Peach we want. ‚ù§Ô∏èüçë",
          "score": 2,
          "created_utc": "2026-02-22 23:36:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6v6chd",
              "author": "Both-Rub5248",
              "text": "Only Flux doesn't know the colour of her dress.  \nTherefore, it is more Daisy than Pitch)",
              "score": 1,
              "created_utc": "2026-02-23 00:02:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vaxcj",
          "author": "overand",
          "text": "Which Flux.2 Klein version are you using, just to be sure?\n\n- [FLUX.2-klein-9B](https://huggingface.co/black-forest-labs/FLUX.2-klein-9B)\n- [FLUX.2-klein-base-9B](https://huggingface.co/black-forest-labs/FLUX.2-klein-base-9B)\n\nI assume the former - this is a \"the naming scheme isn't well thought-out\" issue, not a you issue, btw. Like, how does one specify the \"regular\" one specifically? If the other one wasn't called \"base\" in the name, I'd probably say \"Flux.2 Klein base model\" or such. Meh \n\n`</old person wagging a finger a passing kids>`",
          "score": 2,
          "created_utc": "2026-02-23 00:28:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6vcx8l",
              "author": "Both-Rub5248",
              "text": "I apologise, I forgot to mention that I used Flux 2 Klein 9B Distill FP8.",
              "score": 1,
              "created_utc": "2026-02-23 00:40:07",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6vd4sk",
              "author": "Both-Rub5248",
              "text": "In your comment, it is referred to as [FLUX.2-klein-9B](https://huggingface.co/black-forest-labs/FLUX.2-klein-9B)",
              "score": 1,
              "created_utc": "2026-02-23 00:41:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vnsi0",
          "author": "Toby101125",
          "text": "I wish there was a dark lighting test in here because holy hell I think Z-Image might be worse than SDXL at getting dark, realistic portraits.",
          "score": 2,
          "created_utc": "2026-02-23 01:45:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zob73",
              "author": "MasterFGH2",
              "text": "Workaround: Start with a black latent and then do a 80% denoise",
              "score": 2,
              "created_utc": "2026-02-23 18:03:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o707vkj",
                  "author": "Toby101125",
                  "text": "img2img with a black square?",
                  "score": 1,
                  "created_utc": "2026-02-23 19:33:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6x4mre",
          "author": "latentbroadcasting",
          "text": "Wow, this confirmed my thought that Z-Image Turbo is way better than \"base\" or at least it seems to perform better",
          "score": 2,
          "created_utc": "2026-02-23 08:20:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79h41z",
          "author": "Acrobatic-Gap5903",
          "text": "You inspire me.",
          "score": 2,
          "created_utc": "2026-02-25 03:23:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6scevv",
          "author": "fluce13",
          "text": "Awesome post thank you!",
          "score": 2,
          "created_utc": "2026-02-22 15:42:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sy297",
              "author": "Both-Rub5248",
              "text": "Thank you very much, I am very pleased that someone has appreciated my efforts!",
              "score": 0,
              "created_utc": "2026-02-22 17:18:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6tzy81",
          "author": "AI_Characters",
          "text": "I still dont understand why so many people complain about \"very poor anatomy\" with Klein. I get \"mutations\" about 1 in 4 images. Which is worse than the other models but not \"very poor\". \"Very poor\" is unuseable.\n\nI am starting to think that perhaps these issues only lie with the distilled or fp8 models because I dont encounter huge anatomy issues on Klein base 9B fp16.",
          "score": 4,
          "created_utc": "2026-02-22 20:18:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6uleog",
              "author": "djdante",
              "text": "I use fp8 in Klein all the time and I have the same feeling as you - extra limbs are occasional and \"so what\" just change the seer and wait another ten seconds....\n\nThe only area it can become annoying is actions.. getting someone rock climbing for example is a nightmare if bad limbs and bad proportions from hell..\n.playing soccer or another sport introduces a lot of extra limbs too.\n\nBut again. It's easy to work around and anminor annoyance at worst.",
              "score": 3,
              "created_utc": "2026-02-22 22:07:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6v0qdi",
              "author": "Both-Rub5248",
              "text": "I actually end up with 4 images with mutations and 1 without.  \nYes, perhaps the whole problem lies with Distill and FP8, but unfortunately my 6 GB of VRAM cannot handle full-fledged models.\n\nWhen using a device with 6 GB VRAM, Z-Image Turbo does not cause any mutations, so I have no complaints about this model.\n\nModels weighing more than 8 GB are not suitable for all purposes, because sometimes a huge number of generations are required, and the ratio of speed and quality is of great importance.\n\nAnd the maximum speed on Flux can only be achieved on Distill Fp8 version.\n\n",
              "score": 2,
              "created_utc": "2026-02-22 23:30:46",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6v9cgx",
              "author": "berlinbaer",
              "text": ">  I get \"mutations\" about 1 in 4 images.\n\nthats acceptable to you??",
              "score": 2,
              "created_utc": "2026-02-23 00:19:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6vdcfc",
                  "author": "AI_Characters",
                  "text": "Yes? why wouldnt it? what kind of ridiculous standards do you have lol? considering everything else this model offers this is ok. oh no so one 80s generation was wasted. the horror...",
                  "score": 2,
                  "created_utc": "2026-02-23 00:42:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6uc8mq",
              "author": "Fluffy-Maybe-5077",
              "text": "Are you generating or editing? This exists for a reason [https://civitai.com/models/2324991/klein-anatomy-quality-fixer](https://civitai.com/models/2324991/klein-anatomy-quality-fixer)",
              "score": 1,
              "created_utc": "2026-02-22 21:20:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6um0uc",
                  "author": "AI_Characters",
                  "text": "At least one person in the comments says he does not have major anatomy issues either so this really does not seem to be a universal issue but something with the settings or models.",
                  "score": 2,
                  "created_utc": "2026-02-22 22:10:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6v18v7",
                  "author": "Both-Rub5248",
                  "text": "I tested this Lora, it helps, but only 30%.  \nWith this Laura, I get 2-3 images with mutations and 1 without.  \nUnfortunately, this Laura is not a panacea.\n\nPerhaps the entire issue is indeed with Distill Fp8.",
                  "score": 1,
                  "created_utc": "2026-02-22 23:33:46",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6u276t",
              "author": "SlothFoc",
              "text": "A good thing to keep in mind about this subreddit is that a lot of people have no idea what they're doing. \n\nI'll get a 3 fingered hand here and there and that's about the extent of it.",
              "score": 1,
              "created_utc": "2026-02-22 20:29:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6sn4xx",
          "author": "superkickstart",
          "text": "Flux has the most obvious ai look.",
          "score": 3,
          "created_utc": "2026-02-22 16:29:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u3561",
          "author": "QuirksNFeatures",
          "text": "I'm very new to all this but that 8th image spoke to me.  A lot of the time I just cannot get these things to generate a person of the age I want.  In your example all three of the women look way older than 25.  The one in the middle looks 45 plus.\n\nAnd another thing that's not really related:  I cannot figure out a prompt to make a person face away from the \"camera\".  I've struggled mightily with this today.  Sometimes they turn their bodies a little.  Sometimes they turn their heads.  Most of the time it's just dead on facing the camera no matter what I write in the prompt.  Frustrating.",
          "score": 1,
          "created_utc": "2026-02-22 20:34:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6v3ss1",
              "author": "Both-Rub5248",
              "text": "In my example with age, one could have written **YOUNG GIRL**, 25 years old, instead of 25-year-old **WOMAN**.\n\nAge figures are just a small hint; the basis for the prompt is the words **\"young\"** and **\"girl\"** instead of **\"woman.\"**\n\nYou can also set LORA to determine age. (Age Slider)\n\nIn my example with three renderings of women, I deliberately made a mistake in the prompt to see which of the models would be able to correctly understand my poor-quality prompt. Apparently, none of them managed to do so :D",
              "score": 1,
              "created_utc": "2026-02-22 23:48:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6vbctt",
                  "author": "QuirksNFeatures",
                  "text": "Whenever I've tried \"young girl\" even with an age, there's a very good chance it will generate a literal child.  I may need to add some more hints.\n\nI don't know anything about LORAs yet.  How would that work if there is more than one person in the image?\n\nStill new, still learning.",
                  "score": 1,
                  "created_utc": "2026-02-23 00:31:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ua0yb",
          "author": "gone_to_plaid",
          "text": "Did you use a negative prompt on ZIB?  I've found including one very important to realism.",
          "score": 1,
          "created_utc": "2026-02-22 21:09:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6v3zgj",
              "author": "Both-Rub5248",
              "text": "Yes",
              "score": 2,
              "created_utc": "2026-02-22 23:49:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ucpfg",
          "author": "Suspicious-Click-688",
          "text": "F2K wins IMO",
          "score": 1,
          "created_utc": "2026-02-22 21:23:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ze63d",
          "author": "Odd-Mirror-2412",
          "text": "I like ZIB because it has the least AI look.",
          "score": 1,
          "created_utc": "2026-02-23 17:16:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70y45x",
          "author": "azination",
          "text": "This is great!",
          "score": 1,
          "created_utc": "2026-02-23 21:39:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o749uq7",
          "author": "New-Addition8535",
          "text": "Flux 2 klein is the best",
          "score": 1,
          "created_utc": "2026-02-24 11:23:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o786n5x",
          "author": "Reasonable-Pay-336",
          "text": "DID anyone figure out facial consistency with ZIT/ZIB",
          "score": 1,
          "created_utc": "2026-02-24 23:05:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6s9adl",
          "author": "Both-Rub5248",
          "text": "By the way, I forgot to mention and praise ZIB for its work with 2D graphics, such as graphic design. It did a very good job with the \"2 image\" with chips.\n\nIt can be used as an additional tool in design or in tasks where creativity is more important than quality.\n\nBut in realistic style scenarios, ZIB loses out to absolutely everything (",
          "score": 1,
          "created_utc": "2026-02-22 15:27:25",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o6tku2p",
          "author": "Bbmin7b5",
          "text": "ZIB is the clear winner but its slow generation time kills it for most.",
          "score": 1,
          "created_utc": "2026-02-22 19:03:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ugtzj",
          "author": "grahamulax",
          "text": "Holy crap this is the EXACT post I needed. THANK YA!!!",
          "score": 1,
          "created_utc": "2026-02-22 21:43:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6v47zi",
              "author": "Both-Rub5248",
              "text": "Thank you very much for your comment.",
              "score": 0,
              "created_utc": "2026-02-22 23:50:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6v85d1",
          "author": "Ok-Prize-7458",
          "text": "Klein is good but nerfed nsfw. I only use AI to goon, so i prefer Z-image for its anatomy consistency. I love ZIT and its primary my daily generator, but it lacks a lot of creativity.",
          "score": 1,
          "created_utc": "2026-02-23 00:13:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6vbolo",
              "author": "Both-Rub5248",
              "text": "Under this post, one person shared their workflow, in which ZIB generates the first steps and provides more creativity, while ZIT performs all subsequent and final steps, resulting in increased creativity in the generations)",
              "score": 2,
              "created_utc": "2026-02-23 00:33:06",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6zze24",
              "author": "Lost-Passion-491",
              "text": "You haven‚Äôt tried SNOFS?",
              "score": 2,
              "created_utc": "2026-02-23 18:53:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6xp76t",
          "author": "NesquikBoi",
          "text": "This is far from usable on a professional level",
          "score": 1,
          "created_utc": "2026-02-23 11:36:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6szuod",
          "author": "StableLlama",
          "text": "Why choose? Did you run out of storage?\n\nI use all of them, including the still great Qwen Image (especially Qwen Image 2512 is extremely great and the 4 and 8 step LoRA let it run). And I also still spin up Flux.1 dev, when I need a LoRA that's only available for it.  \nOnly SD1.5 and SDXL are the models I didn't run for many months.",
          "score": -2,
          "created_utc": "2026-02-22 17:27:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6t0mtt",
              "author": "Both-Rub5248",
              "text": "Well, yes, I don't have much space on my laptop's SSD right now :D\n\nMy main PC with 3TB of memory is currently in another city, so I was looking for the best and most versatile model for T2I.\n\nAnd in general, I'm very interested in comparing such models)\n\n  \nI also have Flux 1 Dev on my main PC, because I have a lot of personal workflows and a lot of unique Lora for different styles)",
              "score": 2,
              "created_utc": "2026-02-22 17:30:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6t6i8u",
                  "author": "StableLlama",
                  "text": "Comparing is important. But not to ditch a model, but to know where each model has its strengths and thus decide by the task which one to choose.",
                  "score": 1,
                  "created_utc": "2026-02-22 17:58:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6t10tt",
              "author": "Both-Rub5248",
              "text": "I will definitely keep Flux 2 Klein on my SSD, because it is very cool in the I2I segment. I was more interested in comparing ZIB and ZIT, and I made my choice. I hope it helped others too. ",
              "score": 1,
              "created_utc": "2026-02-22 17:32:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rf7d1d",
      "title": "üé¨ Big Update for Yedp Action Director: Multi-characters setup+camera animation to render Pose, Depth, Normal, and Canny batches from FBX/GLB/BHV animations files (Mixamo)",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/d0157859ntlg1",
      "author": "shamomylle",
      "created_utc": "2026-02-26 11:08:06",
      "score": 252,
      "num_comments": 27,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rf7d1d/big_update_for_yedp_action_director/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7hwg17",
          "author": "Candid-Station-1235",
          "text": "![gif](giphy|D3RDJy8gFPDnv8J6OQ)\n\n",
          "score": 11,
          "created_utc": "2026-02-26 11:26:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hx43q",
          "author": "Hearcharted",
          "text": "![gif](giphy|xT8qAY7e9If38xkrIY)\n\nAmazing!",
          "score": 6,
          "created_utc": "2026-02-26 11:31:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7idu09",
          "author": "devilish-lavanya",
          "text": "I can feel it in my bones, new era of AI VFX is coming‚Ä¶.I slowly passed away",
          "score": 4,
          "created_utc": "2026-02-26 13:26:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7iio2o",
              "author": "shamomylle",
              "text": "Don't worry, I didn't create anything new, I'm simply trying to bring the 3D pipeline everyone was already using in blender or any other 3D software, into ComfyUI in an intuitive way!\nYour bones are still fine :)",
              "score": 7,
              "created_utc": "2026-02-26 13:53:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7i4pey",
          "author": "nutrunner365",
          "text": "Any workflows?",
          "score": 3,
          "created_utc": "2026-02-26 12:28:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7i55e9",
              "author": "shamomylle",
              "text": "My bad, this is the one I used for my demo, it's very basic sorry, I'm still new to comfyUI :)\n\n[workflow](https://drive.google.com/file/d/1EBxUSrMS5WXK1iZYY0xLAcs-mpMc_V1a/view?usp=drive_link)",
              "score": 4,
              "created_utc": "2026-02-26 12:31:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7idy93",
                  "author": "devilish-lavanya",
                  "text": "I don‚Äôt believe you are new to comfyui",
                  "score": 1,
                  "created_utc": "2026-02-26 13:27:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7hxhe8",
          "author": "GarudoGAI",
          "text": "This looks amazing, gonna give this a try",
          "score": 1,
          "created_utc": "2026-02-26 11:35:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7iac6h",
          "author": "Brilliant-Station500",
          "text": "Holy shit! This is so fkin good !",
          "score": 1,
          "created_utc": "2026-02-26 13:05:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ioj0h",
              "author": "shamomylle",
              "text": "Thanks for the kind words :)",
              "score": 1,
              "created_utc": "2026-02-26 14:24:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7iij9u",
          "author": "devilish-lavanya",
          "text": "How to load mesh model? Can you support xnalara xps models?",
          "score": 1,
          "created_utc": "2026-02-26 13:52:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ilmjg",
              "author": "shamomylle",
              "text": "Hi! This node isn't a general 3D model importer. It actually uses a specifically engineered, built-in base rig (Yedp_Rig.glb) that contains a precise 56-color OpenPose skeleton and male/female Depth meshes required for ControlNet.\n\nThe dropdown menu in the UI is for loading MoCap animations (.fbx, .bvh, .glb) from Mixamo for instance, to animate the built-in actors, not for loading custom character meshes like XPS.\n\nIf you want to use custom meshes or props, you need to open the Yedp_Rig.glb file in Blender, attach your custom models to it, follow the same naming convention and overwrite the file, I hope it answers your questions :)",
              "score": 2,
              "created_utc": "2026-02-26 14:09:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7j3vne",
          "author": "LowYak7176",
          "text": "Noticed you were using Wan 2.1 Fun Control in your basic workflow, will this work with Wan 2.2 Fun Control?",
          "score": 1,
          "created_utc": "2026-02-26 15:40:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7j5xil",
              "author": "shamomylle",
              "text": "I use wan 2.1 because it is easy and fast for my low 8GB vram setup but if anything wan 2.2 would outperform 2.1 in both camera movement understanding and quality. It takes the same openPose/depth/canny inputs too (although I cheated my canny render with a rim light type of material so it might not be the best, better stick with openPose/depth).\n\nSo long story short, it should work fine :)",
              "score": 3,
              "created_utc": "2026-02-26 15:49:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7jubl5",
                  "author": "LowYak7176",
                  "text": "Thank you!\n\n",
                  "score": 1,
                  "created_utc": "2026-02-26 17:41:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7jypwc",
          "author": "serjuiced",
          "text": "https://preview.redd.it/025dxdz1pvlg1.png?width=182&format=png&auto=webp&s=5ae80f94398d16dcaba6474f76da87dd8776f278\n\n",
          "score": 1,
          "created_utc": "2026-02-26 18:01:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7myc3j",
              "author": "shamomylle",
              "text": "Thanks for your interest :)",
              "score": 1,
              "created_utc": "2026-02-27 03:16:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7l6bhp",
          "author": "Townsiti5689",
          "text": "Is there anything that takes in footage you shoot yourself, say via a smartphone or something, like a 30 second to one minute scene of a person or a group of people talking at a table or something, and allows you to upload it and modify it into whatever via AI video generation while keeping things consistent? Does that exist yet?",
          "score": 1,
          "created_utc": "2026-02-26 21:27:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7mih4b",
              "author": "shamomylle",
              "text": "Yes, what you are describing is called Video-to-Video (V2V) generation.\nIt uses a different workflow than my 3D node. Keeping things 100% consistent (without flickering) is still the biggest challenge in AI, but you could try 2 things right now:\n\n1. ComfyUI direct workflow:\nAnimateDiff + ControlNet: You feed your smartphone video into ComfyUI. ControlNet extracts the 2D poses and depth from your video frame-by-frame, and AnimateDiff forces Stable Diffusion to keep the generated frames consistent over time. It requires tweaking to stop flickering, but it can be done.\n\n2. The 3D route :\nUsing Andrea Pozzetti [ComfyUI-MotionCapture](https://github.com/PozzettiAndrea/ComfyUI-MotionCapture) to extract 3D motion as FBX + my node. I didn't test it but it should technically work. The advantage is being able to change the camera angle of your scene.\n\nHope it answers your question :)",
              "score": 3,
              "created_utc": "2026-02-27 01:44:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7mny8m",
                  "author": "Townsiti5689",
                  "text": "Yes, I was thinking a possible technique could be to record footage with a smartphone or camera, then extract depth and motion from it and feed that into an AI video generator of some kind. \n\nOr maybe, for much more control, extract the depth and motion into a 3D environment and create shots that way. I think these tools exist piecemeal but I haven't had a chance to try them or look into them with any depth.",
                  "score": 1,
                  "created_utc": "2026-02-27 02:16:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7n99rw",
          "author": "StacksGrinder",
          "text": "Wow this is amazing, I'm guessing this will really refine the fight sequences in a clip, a precise punch and a hit movement. :D Thanks for brining it to ComfyUI, You're amazing!  ",
          "score": 1,
          "created_utc": "2026-02-27 04:26:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7naad1",
              "author": "shamomylle",
              "text": "You're welcome! I can't wait to see what people can do with it or improve it :)",
              "score": 2,
              "created_utc": "2026-02-27 04:33:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7pkrlk",
          "author": "M4xs0n",
          "text": "Can it also generate an Animation from video to fbx?",
          "score": 1,
          "created_utc": "2026-02-27 14:57:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7q1oip",
              "author": "shamomylle",
              "text": "Hello! Thanks, that's a great question:\n\nSo there are a couple ways to do it, I haven't tested it yet but Andrea Pozzetti did release a great node for ComfyUI doing just that:\n[ComfyUI-MotionCapture](https://github.com/PozzettiAndrea/ComfyUI-MotionCapture)\n\nOther online solutions exist such as: [Rokoko](https://www.rokoko.com/products/video) and [Deepmotion](https://www.deepmotion.com/)\n\nFinally for another direction also directly inside ComfyUI, you can go the route of prompt-to-3D animation with [HY-MOTION](https://github.com/jtydhr88/ComfyUI-HY-Motion1) which also have an option to save FBX animations compatible with Mixamo.\n\nI hope these will help you :)\n\n\nAs a bonus, (if you want to go experimental!) I designed a suite of nodes for MoCap directly inside ComfyUI, which exports 3D data using mediapipe as a json file, you'd need to go through some process to get some conversion going and redirect that 3D data to a 3D rig.\nOr you can experiment with my MoCap nodes to directly use the output (openpose skeleton), here's the link in case : \n[ComfyUI-Yedp-Mocap](https://github.com/yedp123/ComfyUI-Yedp-Mocap)",
              "score": 1,
              "created_utc": "2026-02-27 16:19:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7syzvn",
          "author": "Optimal_Map_5236",
          "text": "is there a way to use controlnet vid with t2v workflow? like you make t2v vid using depth ref vid. all those animate vace scail are made for i2v",
          "score": 1,
          "created_utc": "2026-02-28 01:20:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7t267m",
              "author": "shamomylle",
              "text": "You should be able to do this! In fact, guiding a T2V (Text-to-Video) workflow can be done with my node.\n\nI think if you use AnimateDiff inside ComfyUI, as it is a native T2V model it will work.\n\nBasically using my node and passing it through an \"apply controlnet\" node then using AnimateDiff in theory ( you'd have to research it)\n\nAnimateDiff should generate the video completely from scratch (T2V) using your text, while being 100% physically guided by the 3D Depth/Pose sequence you created in the viewport.",
              "score": 1,
              "created_utc": "2026-02-28 01:40:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1re4vo2",
      "title": "Berserk Dark Fantasy Concept ‚Äì Why Art Direction Matters More Than Prompting [Workflow Included]",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/3p30stckoklg1",
      "author": "Feisty-Turnover9243",
      "created_utc": "2026-02-25 05:45:23",
      "score": 250,
      "num_comments": 57,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1re4vo2/berserk_dark_fantasy_concept_why_art_direction/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7a5mlq",
          "author": "TopTippityTop",
          "text": "Agree. AI has no sense of \"taste\", it simply tries to follow what the words say in a way which is consistent with its training data given the initial noise patter given. It doesn't understand shape language, identity, storytelling and design, etc.\n\nThat taste has to come from the human element. The ideas and taste the human imbues AI with, is what can turn the tool's craft into art.\n\nThe people who seek a one stop shop in prompting will find themselves amidst a wave of generic lookalikes. Those who use unique workflows, including manual work, won't save as much time, but can create a better sense of identity, stand out, and resonate more with a chosen audience.\n\nThere is a place for craft. We're surrounded by useful but forgettable things. However powerful AI as a crafting tool is, humans love novelty and surprise. It's often those who push boundaries which stand a greater chance at succeeding in those areas where this human desire shows up the most, such as in films, games, shows, marketing, etc. Whenever there's a need to get more eyeballs pointed someplace, higher engagement, talent will be requested.\n\nThen again, I could be wrong. Who knows, perhaps our future overlord Stable Diffusion XXL 20 will be superintelligent, have taste, be truly creative, and come up with beautiful ideas, unprompted, on its own.",
          "score": 35,
          "created_utc": "2026-02-25 06:12:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7a8ou5",
              "author": "Feisty-Turnover9243",
              "text": "100% spot on, man. I feel like treating AI as an all-in-one slot machine‚Äîjust pulling the prompt lever and praying for something usable‚Äîis a race to the absolute bottom rn. Everything just ends up looking like that same generic AI plastic.\n\nThe real moat is definitely¬†*curation and intent*. Knowing exactly what frame you need for the cut, and literally forcing the model to spit it out so it matches your composition. It takes way more manual work in After Effects to glue it all together (the grain, the crushed blacks), but at least it actually has an identity.\n\nAs for SD XXL 20 turning into some super-intelligent art director‚Ä¶ honestly, with how fast this tech moves, I wouldn't even be mad lmao. But until an algorithm can actually¬†*feel*¬†the tension of a 24fps cut-to-black, I think us manual editors are safe for a bit. Appreciate the insight!",
              "score": 8,
              "created_utc": "2026-02-25 06:38:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7a9maa",
          "author": "Nobodyss_Business",
          "text": "Hard  agree üëç \n\nAs a graphic designer myself I treat AI as a tool first and foremost,  which needs a lot of time and effort to master, just like any tool for any professional use. When I look at any AI image or video I first acknowledge the mistakes or any details that look or feel wrong to my professional \"eye\" and then the work as a whole and the idea or style behind it. \n\nSo the digital editor in me treats the \"piece of art\" (though being AI generated or assisted) as I would  pre-AI works. It should have some idea or concept behind, taste, story, style, it should feel \"crafted\" in the sense of both effort and skill put into it - so all the elements of real art should be present.",
          "score": 6,
          "created_utc": "2026-02-25 06:46:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7aau1i",
          "author": "Feisty-Turnover9243",
          "text": "A lot of people think the AIGC era made creating easy‚Äîjust type a prompt and boom, you have a film. But tbh, as someone actually in the trenches doing this, I gotta say:¬†**the technical barrier dropped to zero, but the aesthetic barrier just shot through the roof.**\n\nAI is an insanely powerful brush, but it‚Äôs not a brain. Without a solid foundation in visual storytelling, generated clips are just a random pile of footage with zero narrative breathing room. You literally have to think like a director:¬†*How does this shot transition? How does the lighting serve the emotional undertone? How are you controlling the pacing?*¬†You can‚Äôt outsource that to an algorithm. Without an overarching structure, your video just falls into disconnected logic and a fractured art style.\n\nNow that \"1-click generation\" is the norm, we're absolutely drowning in homogenous AI slop.¬†**Your only real moat right now is your unique taste and your understanding of human emotion.**¬†Don't let the tool box you in. In this human-AI collab, you¬†*must*¬†maintain your agency as the creator. You use your aesthetic judgment to ruthlessly curate and reconstruct what the AI spits out, making sure every single frame actually serves the theme.\n\n**TL;DR:**¬†Tech empowers the narrative, but it can never replace the soul. Be the director who controls the vision, not just a \"prompt jockey\" moving text from one box to another. In an era where everyone has access to the exact same tools, your taste and creativity are literally the only things they can't automate.",
          "score": 11,
          "created_utc": "2026-02-25 06:56:37",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o7ak89m",
          "author": "murderopolis",
          "text": "Agreed. Just weird that you also had an AI write your post",
          "score": 11,
          "created_utc": "2026-02-25 08:21:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7akqnc",
              "author": "Feisty-Turnover9243",
              "text": "Haha, nope, I just made that up myself.",
              "score": -11,
              "created_utc": "2026-02-25 08:26:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7akzhn",
                  "author": "murderopolis",
                  "text": "Wow. You must be the guy chapgpt is learning how to type and format from.",
                  "score": 10,
                  "created_utc": "2026-02-25 08:28:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7amvyg",
                  "author": "suspicious_Jackfruit",
                  "text": "Lol, no you didn't. Be honest, you aren't fooling a community who use AI regularly, it's obviously an AI generated post. You may have fed it your own thoughts but an AI made that text.\n\nThat aside, good video and much better than regular slop. But from a personal preference its not quite right for berserk, it's too fun and soft aesthetically for the brand imo",
                  "score": 11,
                  "created_utc": "2026-02-25 08:46:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7agpi1",
          "author": "ArtificialAnaleptic",
          "text": "Firstly, I wan't to say 100% that I agree. I try to do the same thing with my digital art. I've moved to a good 50-75% split of effort with that majority being AI but with tightly bound requirements in terms of target/end result. It works great and I'm very happy with my results.\n\nBut one thing I will say is that AI is also just very good at certain things and occasionally people (even those familiar with AI) ***don't*** recognize the difference between something that required deliberate thought/effort and something that was simply prompt/seed-luck. You do even see this with traditional artists occasionally getting mistakenly labelled as AI and it's a similar phenomenon.\n\nFor instance, I was initially unimpressed with this: https://v.redd.it/bi449b91u1zf1\n\nI assumed it was simply img2vid+prompt+some masking of the original video around the subject. In reality it's a much more complex and deliberate workflow.\n\nMore recently, I've tried to be a little less quick to jump to conclusion. If a piece is good, it's good. If a creator is ***consistent*** then they are good.",
          "score": 3,
          "created_utc": "2026-02-25 07:49:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ail6f",
              "author": "Feisty-Turnover9243",
              "text": "This is a brilliantly nuanced take. The 'prompt/seed-luck' phenomenon is incredibly real‚Äîsometimes the algorithm just hands you a miracle frame on a silver platter. And because of that, the line between an accidental good shot and deliberate art direction gets blurry to the general audience.\n\nYou nailed the ultimate truth at the end:¬†**Consistency**.\n\nAnyone can get lucky once and generate a cool generic 5-second clip. But dictating a specific, cohesive aesthetic across an entire sequence, or tailoring it to a strict brand brief‚Äîthat‚Äôs where the 'lucky prompters' fall off and the actual directors take over. That's the exact reason I'm building out a portfolio of these. Really appreciate the deep dive here.",
              "score": 0,
              "created_utc": "2026-02-25 08:06:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7b3n55",
          "author": "ukpanik",
          "text": "If you are going to lecture everyone about \"100% human-controlled rhythm\", at least choose music that vibes with Berserk.",
          "score": 6,
          "created_utc": "2026-02-25 11:19:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7cm0rb",
              "author": "SymphonyofForm",
              "text": "Have you even heard the 80's intro song? ",
              "score": 3,
              "created_utc": "2026-02-25 16:25:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7aa1po",
          "author": "story_of_the_beer",
          "text": "This goes hard, well done! Prime example of great composition, style consistency and cadence. I'd love to see more, also Glass Animals 10/10",
          "score": 2,
          "created_utc": "2026-02-25 06:49:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bcdad",
          "author": "addandsubtract",
          "text": ">AI generated the pixels, but the newsletter, the pacing, and the vibe are mine  \n  \nNewsletter?",
          "score": 2,
          "created_utc": "2026-02-25 12:26:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7aklk3",
          "author": "AnOnlineHandle",
          "text": "> AI should strictly be treated as a rendering engine\n\nIMO This is the key thing which is desperately needed for ML based image generation to be useful for creative purposes. It needs to behave more like a traditional 3D rendering engine, given locations, rotations, scalars, material properties, etc, in precise values rather than the vagueness of natural language descriptions. An ML tool could still be used to generate that from text, but the actual rendering stage should be precisely definable.",
          "score": 1,
          "created_utc": "2026-02-25 08:25:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ammvi",
              "author": "Feisty-Turnover9243",
              "text": "Totally agree. AI should absolutely be treated as a proper rendering engine.  \nNatural language prompts are way too vague and messy‚Äîit‚Äôs less directing a scene, more negotiating with a hyperactive kid.\n\nTools like ComfyUI and ControlNets are moving us closer to 3D-engine precision, letting us lock in exact depth, position, and orientation.  \nThe end goal is exactly what you said: a node-based workflow where we set precise values for lighting, rotation, and materials, with zero guesswork. That‚Äôs the only way this becomes truly useful for serious creative work.",
              "score": 2,
              "created_utc": "2026-02-25 08:44:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7al20p",
          "author": "joeyz550",
          "text": "Nice",
          "score": 1,
          "created_utc": "2026-02-25 08:29:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7aobld",
          "author": "lucassuave15",
          "text": "Looks really good, AI on the hands of someone who is already an artist can do wonders",
          "score": 1,
          "created_utc": "2026-02-25 09:00:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7aoo5i",
          "author": "JoelMahon",
          "text": "AI slop is made by the same humans that made \"organic\" slop before AI slop was an option.\n\nthose with taste vs those without taste will exist for a few more years at least.\n\nalthough I do think eventually AI will be far more proactive with shutting the tasteless down and being more proactively tasteful, but for now at least the difference is night and day between your quality work vs the crap some people shovel out using the same tools",
          "score": 1,
          "created_utc": "2026-02-25 09:03:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7cinw1",
              "author": "EducationalWeird5204",
              "text": "excellentÔºÅ",
              "score": 2,
              "created_utc": "2026-02-25 16:10:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7auk7w",
          "author": "Sleepy_Bandit",
          "text": "Agreed, but how do you ‚Äúhand apply‚Äù film grain? üòÖ",
          "score": 1,
          "created_utc": "2026-02-25 09:58:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7avnbm",
          "author": "NineThreeTilNow",
          "text": ">AI generated the pixels, but the newsletter, the pacing, and the vibe are mine. Curious to hear what other motion designers think about this approach to workflow!\n\nThank fuck. I have so many brain dead friends that think AI motion looks \"good\".\n\nSomehow they think swapping a ChatGPT generated image and prompt in to Wan 2.2 makes them an artist.\n\nCreative work is hard and they're lazy. I don't think some people understand that part.",
          "score": 1,
          "created_utc": "2026-02-25 10:08:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7b7b21",
          "author": "K0owa",
          "text": "The sentiment is great. However, the concept for Berserk doesn‚Äôt match the tone/mood of the manga or anime.",
          "score": 1,
          "created_utc": "2026-02-25 11:49:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7b81mv",
          "author": "Boogooooooo",
          "text": "It is prompt engineering. I am producing very similar vibe and pacing for my channel (arguebly even better sometimes). All scripting done automatically via automation flow.\n35mm film grain included :D",
          "score": 1,
          "created_utc": "2026-02-25 11:54:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bkjjb",
          "author": "Grand_Bobcat_Ohio",
          "text": "Art direction is prompting...",
          "score": 1,
          "created_utc": "2026-02-25 13:18:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bpecs",
          "author": "Sioluishere",
          "text": ">I‚Äôm a motion designer\n\nMakes sense",
          "score": 1,
          "created_utc": "2026-02-25 13:45:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bqiv6",
          "author": "switch2stock",
          "text": "Where is the workflow tough?",
          "score": 1,
          "created_utc": "2026-02-25 13:51:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bsvev",
          "author": "PwanaZana",
          "text": "True, though your post was written by an AI, so it is ironic. :P",
          "score": 1,
          "created_utc": "2026-02-25 14:04:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7byu28",
          "author": "RebelRoundeye",
          "text": "I have been wanting to experiment with gen ai video motion graphics. I planned on beginning with my own vector artwork then straight to Kling and LTX2 without attempting to t2i anything. I am curious how the video models would handle it. I haven‚Äôt seen anyone else attempt like you have. I suppose it should do well enough. Surely the video models have training on motion elements and not just motion photography. Ty for sharing!",
          "score": 1,
          "created_utc": "2026-02-25 14:35:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7coz4s",
              "author": "EducationalWeird5204",
              "text": "Bro, you‚Äôre deadass right!  \nUsing vector graphics paired with AI to polish the motion work?  \nThat‚Äôs the real secret sauce here‚Äîaside from OP‚Äôs insane aesthetic and the video‚Äôs tight audio-visual structure.",
              "score": 1,
              "created_utc": "2026-02-25 16:39:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7bzpa7",
          "author": "KleaningGuy",
          "text": "Nice ! I can't prompt better myself, but i want to point out that choice of music is questionable.",
          "score": 1,
          "created_utc": "2026-02-25 14:40:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7c56st",
          "author": "UnrelaxedToken",
          "text": "Can you share your premiere pro and after affect projects? lol",
          "score": 1,
          "created_utc": "2026-02-25 15:07:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7cf9yr",
          "author": "xdozex",
          "text": "Its really no different from what we're seeing happening with code, just a bit slower. Anyone can pop open Cursor or Claude Code and vibe code a quick semi-functional frontend that technically 'works'. But when the rubber meets the road, these apps won't scale, they won't be able to handle anything that wasn't specifically prompted for, and they tend to be security nightmares most of the time. Give the same tools to an experienced engineer, and they can use natural language to steer the models in the right direction. They understand the underlying architecture, they know where bugs or security issues could pose bigger problems later, and they know how to use the tools to work around them and produce a more legit end result. \n\nAll the lifeless slop you're seeing is posted by people who had a passion or desire to make mograph, but never really had the skills to pull it off using traditional software. These tools give them a way to achieve results that far exceed anything they could make themselves in After Effects, so for those people the lifeless slop feels like a big win. You, with your motion graphics background know what to look out for, know how to take what looks like a set of student b-roll graphics and coax more out of them. \n\nI also work in the industry and while you're results did look better than most AI motion graphics I've seen, it's still falling a bit short when you compare it to professional mograph. Another few model iterations and these artificial barriers will break down. ",
          "score": 1,
          "created_utc": "2026-02-25 15:55:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7cpjo4",
              "author": "EducationalWeird5204",
              "text": "As AI keeps advancing, it‚Äôll continue to lower the barrier and cost of manual content creation.  \nGoing forward, what truly matters in content creation won‚Äôt just be production speed or technical skill‚Äîit‚Äôll be your taste, original ideas, and a deep understanding of brand identity and film storytelling.  \nCreators like you and the OP, with real insight, are the ones who truly deserve all the respect.",
              "score": 1,
              "created_utc": "2026-02-25 16:41:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ck3b5",
          "author": "TogoMojoBoboRobo",
          "text": "Yah, it bugs me, working in games how company execs think it is about 'not knowing the right words' holding them back from being good at AI or thinking that a magic prompt will get them what they want.  No, the problem is the exec themselves being a dumbass who actually needs people, but their cheap ass egos won't allow them to see that.",
          "score": 1,
          "created_utc": "2026-02-25 16:16:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7cq04v",
              "author": "EducationalWeird5204",
              "text": "You‚Äôre totally right. A lot of game company executives fall into a common misconception. They assume AI isn‚Äôt delivering the results they want just because ‚Äúthe right prompts aren‚Äôt being used,‚Äù and even hope a single magic prompt will make everything work perfectly. This is a huge misunderstanding of AI-driven creation and content production.  \nThe core issue has never been the prompts themselves. What truly matters is the **creative vision, overall planning, narrative logic, and professional visual-audio expression** behind the work. AI is only a tool from start to finish‚Äîwhat defines the quality and soul of a project is human aesthetics, original ideas, deep understanding of content, and a complete creative framework.  \nWhat they actually need is professional creators to guide the direction, define the vision, and execute the expression. Unfortunately, many fail to recognize the true nature of AI tools and overlook the essential value of creation itself.",
              "score": 1,
              "created_utc": "2026-02-25 16:43:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ctktv",
          "author": "Silly-Dingo-7086",
          "text": "At I 100% believe that the future of AI generated movies will still be a production of a very small team of people. One who traditionally was a director and had an overall dream of pacing camera location angle etc. Someone that can prompt properly and generate what is needed and keep the consistency there. And like you said somebody who can mix it all together and make it work. Maybe and eventually will get to the point where you are people are needed but I think in the next five years these tools will be available for anybody with a creative mind to be able to start making their own beautiful creations of full-like TV shows or movies. Kind of like how the music industry is very easy to get into now because kids can mix music themselves and create whatever they want without needing a big studio. We will just see this for TV and movies. \n\nWhat's great about it is that we can see multiple takes on classics",
          "score": 1,
          "created_utc": "2026-02-25 16:59:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7cu95d",
              "author": "EducationalWeird5204",
              "text": "I fully believe the next five years will bring a ‚Äúrenaissance‚Äù in filmmaking, but it won‚Äôt be a victory for technology‚Äîit‚Äôll be a victory for people. Our job as creators is to use our expertise to define what ‚Äúgreat work‚Äù means, and turn AI into an amplifier for our ideas, not a machine for churning out mediocre content. I can‚Äôt wait to see more people use these tools to reimagine classic works in entirely new ways! ü§ç",
              "score": 1,
              "created_utc": "2026-02-25 17:03:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7cuplx",
                  "author": "Silly-Dingo-7086",
                  "text": "It's going to change everything and not for good or bad. A lot of people that put a lot of time and money and that person of things will lose out. I can only imagine all of the works of fiction and nonfiction that have been done over the last thousand years can now be done in a digital media where we can view it and enjoy it in a new life. But the authors who are writing these now won't be getting paid because that's just not how online streaming pirating and self-generated fanfic works. But how many shows and movies have they attempted to make into a series that sloppy because the director in the show runners suck. Now I can finally see wheel of Time done in the right way",
                  "score": 1,
                  "created_utc": "2026-02-25 17:05:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7abfan",
          "author": "FreezaSama",
          "text": "Great video and not to be rude but. I thought what you said was obvious to everyone? AI is a tool.",
          "score": 1,
          "created_utc": "2026-02-25 07:01:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ad08t",
              "author": "Feisty-Turnover9243",
              "text": "You‚Äôd assume it‚Äôs obvious. But when 90% of the AI videos flooding the internet still look like thoughtless, un-curated slop, it clearly isn't being practiced. Knowing a hammer is a tool is easy; actually building a house with it is what's missing right now. Just stating the reality of the space.",
              "score": 10,
              "created_utc": "2026-02-25 07:15:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7aoyg6",
                  "author": "ThePoetPyronius",
                  "text": "Everyone's got a hammer since Big Hammer opened up a franchise in every 2-bit town this side of the Rio Grande. We, the masons, are still with you bud. ü§ç",
                  "score": 1,
                  "created_utc": "2026-02-25 09:06:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7c0h0n",
                  "author": "ExplanationAway672",
                  "text": "To be fair 90% of everything on the internet is thoughtless, un-curated slop.  Is it really a problem though?  Same as with all the new tools we've had since computers have been easily accessible and that lower the barrier of entry to creating, a lot of people will just have a play, or use them to make memes, rag on mates etc.  A few will practice and learn the skills, and make the other 10%. - and that stuff surfaces very easily.",
                  "score": 1,
                  "created_utc": "2026-02-25 14:44:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7ahcg3",
                  "author": "FreezaSama",
                  "text": "It's definitely true! Most stuff is slop that, in the beginning could shine on its own but with the democratization of these tools they are easily forgettable and even here on reddit people are starting to call it off. That is undeniable. What I challenged was the conclusion you shared on \"AD matters more than promoting\" that's the part I would say is obvious. Either way not to pee on the parade. The work is great and I'm all for the argument. That's exactly what I do day to day",
                  "score": 1,
                  "created_utc": "2026-02-25 07:55:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7b6ls3",
          "author": "aastle",
          "text": "Downvoted for the music choice.",
          "score": 1,
          "created_utc": "2026-02-25 11:43:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7bamaf",
              "author": "lucak5s",
              "text": "put your grasses on",
              "score": 0,
              "created_utc": "2026-02-25 12:13:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ai9js",
          "author": "ScienceAlien",
          "text": "^^this",
          "score": 0,
          "created_utc": "2026-02-25 08:03:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7b83yd",
          "author": "Alisomarc",
          "text": "100% that's the only way to avoid the a.i slop era\n\n![gif](giphy|RrVzUOXldFe8M)\n\n",
          "score": 0,
          "created_utc": "2026-02-25 11:55:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7cq4h9",
              "author": "EducationalWeird5204",
              "text": "nbÔºÅ",
              "score": 1,
              "created_utc": "2026-02-25 16:44:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7b9cvs",
          "author": "Stunning_Macaron6133",
          "text": "Nuance? On Reddit? And with helpful tips on top of that!\n\nOh, how can this be?",
          "score": 0,
          "created_utc": "2026-02-25 12:04:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbyej5",
      "title": "3 Months later - Proof of concept for making comics with Krita AI and other AI tools",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1rbyej5",
      "author": "Portable_Solar_ZA",
      "created_utc": "2026-02-22 21:34:49",
      "score": 225,
      "num_comments": 97,
      "upvote_ratio": 0.82,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rbyej5/3_months_later_proof_of_concept_for_making_comics/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6us2un",
          "author": "SuikodenVIorBust",
          "text": "I feel like her level of thickness varies pretty substantially from page to page.",
          "score": 30,
          "created_utc": "2026-02-22 22:42:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o722itw",
              "author": "Icetato",
              "text": "Well, tbf, traditional mangakas often have trouble with consistent body proportions too.",
              "score": 4,
              "created_utc": "2026-02-24 01:17:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o72kbii",
                  "author": "SuikodenVIorBust",
                  "text": "Tbf if im having a machine do it one of the main appeals is near perfect consistency",
                  "score": 1,
                  "created_utc": "2026-02-24 03:00:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6zjb46",
              "author": "Portable_Solar_ZA",
              "text": "Yeah, this is one of the things I'm trying to clean up. Even when I sketch the figure proportionately the same, adding in the LORA throws things off.",
              "score": 3,
              "created_utc": "2026-02-23 17:40:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6uj2ay",
          "author": "ArmadstheDoom",
          "text": "So I think what I said then still applies now; the core hurdle is not the art itself or the tools. Comics and manga specifically need an understanding of page layouts and panel framing; you can tell when this is done well and when it's done poorly. \n\nBut the bottlenecks in this case are *not* the tools you're using. Krita itself isn't needed here; you could use comfy or forge and then generate images and then arrange them into pages via panels via gimp, for example. \n\nBut the core hurdle with both comics and anime is that most AI models, even today, do not understand things like *spacial dynamics* or *perspective* beyond the standard ones. Why? Because they're all trained on 'good' art which for training purposes is almost always splash pages or covers or figure drawing. I actually find it impressive that you've gotten some unique perspectives here. \n\nBut then, you said you used controlnets and and loras and you're the one who is storyboarding and sketching what you want, so honestly, the models aren't really doing a ton of heavy lifting. At this point you're basically still doing it all yourself! \n\nHowever, the answer I gave you before (I think) still applies here: the question is not whether you could do it, because you could train a model to do the art, it's whether or not you as the creator grasp how panels are placed and how things are cropped. \n\nSo basically, this is more a proof of concept for *you* as a storyboarder and panel setter.",
          "score": 36,
          "created_utc": "2026-02-22 21:55:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6voone",
              "author": "Beginning-Struggle49",
              "text": "> I actually find it impressive that you've gotten some unique perspectives here. \n\nSame!! I've been dabbling with trying to use comfyui to do as you said, and my biggest issues is definitely the dynamic angles and perspectives are next to impossible to prompt/figure out",
              "score": 6,
              "created_utc": "2026-02-23 01:50:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6wz6ok",
                  "author": "ArmadstheDoom",
                  "text": "it makes more sense if they're sketching things out beforehand. at that point, the model isn't really doing much more than building atop what's there.",
                  "score": 3,
                  "created_utc": "2026-02-23 07:27:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6zlf8n",
                  "author": "Portable_Solar_ZA",
                  "text": "If you're trying to really squeeze the most out of these models, I would 100% recommend learning some basic art skills and getting a basic PC drawing tablet with pressure sensitivity if you can. Being able to guide the model with image-to-image references allows you to do things that text-to-image just can't.",
                  "score": 1,
                  "created_utc": "2026-02-23 17:50:17",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6voy00",
              "author": "elrobolobo",
              "text": "At a certain point there will also need to be use cases that look less like hentai",
              "score": 6,
              "created_utc": "2026-02-23 01:52:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6we74y",
                  "author": "sukebe7",
                  "text": "I agree.  This would be great for creating new language teaching books.  However, the racy imagery, even though it's mild, isn't going to win customers.\n\nThis style would be OK for teens and up... at least where I'm at.",
                  "score": 5,
                  "created_utc": "2026-02-23 04:34:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6zmix0",
                  "author": "Portable_Solar_ZA",
                  "text": "So technically this is \"ecchi\" or \"fanservice\", and obviously it's entirely intentional. But yeah, it's also not something that bothers me at all and isn't out of place in this type of story which is being hinted at by the final page. \n\nUltimately, someone, maybe even me, will use these tools to tell a different kind of story, but for now this is what I'm enjoying making.",
                  "score": 1,
                  "created_utc": "2026-02-23 17:55:21",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6zl1iq",
              "author": "Portable_Solar_ZA",
              "text": "I agree with most of your main points, but I don't really agree with you on this. At least, not entirely.  \n  \n\\>Krita itself isn't needed here; you could use comfy or forge and then generate images and then arrange them into pages via panels via gimp, for example.\n\nThe integration of the KRITA AI plugin is what makes this a lot simpler than it would otherwise be. It wouldn't be impossible, but it would add a fair amount of time since you'd have to be constantly exporting or importing things between programs, adding time that would stack up into something fairly substantial by the end of a project. KRITA AI keeps everything in one interface, allowing you to make minor adjustments or quickly access tools without having to re-export things each time.\n\nThis video is the closest thing I have to my current process, so maybe this will help highlight the subtle but important differences:\n\n[https://www.youtube.com/watch?v=bKHo2Gh9O-c](https://www.youtube.com/watch?v=bKHo2Gh9O-c)\n\nBut yes, I agree that ultimately whether something succeeds or fails is ultimately if I can put together a series of images in sequence and have it resonate with the reader.\n\n",
              "score": 2,
              "created_utc": "2026-02-23 17:48:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vnuot",
          "author": "Ylsid",
          "text": "Booba",
          "score": 10,
          "created_utc": "2026-02-23 01:45:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xcx3k",
              "author": "MaitreSneed",
              "text": "Coomics",
              "score": 8,
              "created_utc": "2026-02-23 09:42:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6zn8mj",
                  "author": "Portable_Solar_ZA",
                  "text": "\\>Booba\n\nYes.\n\n\\>Coomics\n\nAnd yes.",
                  "score": 2,
                  "created_utc": "2026-02-23 17:58:38",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6un952",
          "author": "krautnelson",
          "text": "what I'd recommend is to read some well-regarded manga and really take note of how they they frame and block the characters, how they time actions and interactions, etc.\n\nfor example, on page three, the character is shown in three panels front, then back, then side. it would flow much better if you go front>side>back.\n\nand when the teacher accidently enters the wrong room and slams the door (which she shouldn't do. she should politely and quietly shut it), you immediatly go into a close-up headshot when it probably should be a 3/4 wide shot of her standing outside in the hallway still embarrassed from barging into the wrong room.\n\nsome of the timing generally feels off, like the teacher getting kicked at the end lacks anticipation. what I would do here is end the page with a shadowy figure showing up behind the teacher in the doorway, and then have the kick be on the next page as a page-turn surprise. it would have significantly more impact that way.\n\n(also, this is more of a me-thing, but as a regular manga reader, it annoys me that the panel order isn't right-to-left)\n\nif I am brutally honest, this feels like someone who has rough idea of what manga looks like but never paid attention to how it's actually written, drawn and structured.\n\ngo read Nisekoi Chapter 1. it's in my humble opinion one of the best made manga in terms of layout, flow, timing, etc. \n\ntake note of how the characters are positioned and framed, how the shots vary between panels, the order of the panels and how they flow into each other, and the set-up and pay-off between the pages.",
          "score": 21,
          "created_utc": "2026-02-22 22:16:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zrdms",
              "author": "Portable_Solar_ZA",
              "text": "\\>for example, on page three, the character is shown in three panels front, then back, then side. it would flow much better if you go front>side>back.\n\nI'll take a look at this later.\n\n\\>and when the teacher accidently enters the wrong room and slams the door (which she shouldn't do. she should politely and quietly shut it),\n\nI take it this is your character and your story? In case this is a \"oh in Japan they wouldn't do this\", this is a fictional short story loosely based on a Japanese setting. As demonstrated by the one adult getting kicked across the room by the other one, this clearly is a work of fiction and isn't a piece that's meant to be taken as some sort of direct cultural piece. \n\n\\>you immediatly go into a close-up headshot when it probably should be a 3/4 wide shot of her standing outside in the hallway still embarrassed from barging into the wrong room.\n\nI'll give this a bash and see. \n\n\\>(also, this is more of a me-thing, but as a regular manga reader, it annoys me that the panel order isn't right-to-left)\n\nI regularly switch between manga and traditional comics, so I don't really have any issues with this, but since I'm a Westerner I just started it from left-to-right. \n\n\\>if I am brutally honest, this feels like someone who has rough idea of what manga looks like **but never paid attention to how it's actually written, drawn and structured**.\n\nYour first points come across as constructive. You are pointing out areas for improvement. However, this comes across as being unnecessary simply because you don't actually know the time or effort I've put into this. Even if the work comes across as amateurish, that's exactly what I am: an amateur. This is not an easy art form to get to grips with. Some people spend decades producing manga and comics and only make their debuts later in life, so without actually know my process, this kind of \"feedback\" comes across more as rude than actually criticism. \n\nBut I also wonder if it's not just a purist thing considering how you pointed out the way the character would act.\n\n\\>go read Nisekoi Chapter 1. it's in my humble opinion one of the best made manga in terms of layout, flow, timing, etc.\n\nThanks. I'll take a look at this shortly.",
              "score": 2,
              "created_utc": "2026-02-23 18:17:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o70iye3",
                  "author": "krautnelson",
                  "text": ">I take it this is your character and your story?\n\nno, obviously not. if you want her to be the kind of person that slams doors shut for no reason - which I'm pretty sure is a rude thing to do regardless of where and when it's done- then that's your choice. I just felt it conflicted with what little of her character I saw in those few pages, especially when she did that super-deep bow and apology beforehand. \n\n>this clearly is a work of fiction and isn't a piece that's meant to be taken as some sort of direct cultural piece.\n\nbut it's clearly Japanese-coded, so that's something you also need to keep in mind as a writer. your setting will influence how the reader will interpret character's actions and interactions. if you don't want the reader to equate your setting to a Japanese High School, don't make it look like a Japanese High School.\n\n>this kind of \"feedback\" comes across more as rude\n\nlook, I just said it as I see it. if you think someone speaking their mind and giving their honest opinion is rude, then that's on you. maybe next time just say that you can't handle any negative criticism whatsoever and that people are only allowed to say nice things. I'm sure that will work just fine.",
                  "score": 0,
                  "created_utc": "2026-02-23 20:25:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6wfj0t",
              "author": "sukebe7",
              "text": "The ordering depends on which region the writer is targeting, IMO.  Essentially, Japan's mange is reverse, compared to U.S. comics.  They're also read from back to front; from a western perspective.\n\nI\"ve also seen action running clockwise on some panels.  However, the basic order is like a reverse z.  I've also seen where westerners try to adjust to this order; it's a bit like switching to southpaw for a year.  You always feel like you're working against what comes naturally.\n\nI don't think Japanese people are going to be the OP's primary target/customer.  There is nothing wrong with doing a manga styled comic in western layout.  But, ya gotta pick a side, bub.",
              "score": 1,
              "created_utc": "2026-02-23 04:43:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6x6yu0",
                  "author": "krautnelson",
                  "text": ">I don't think Japanese people are going to be the OP's primary target/customer.\n\nmanga are always right-to-left, doesn't matter if they are being released in Japan or overseas. they stopped flipping them a long time ago. if the target demographic is manga readers, then they are all gonna be used to that \"reverse\" order.\n\nbut again, this is a very minor and personal complain and far from the main issue.",
                  "score": 3,
                  "created_utc": "2026-02-23 08:43:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6v2v00",
              "author": "NorX_Aengelll",
              "text": "yeah as is a proof of concept...never he has said he will create the next banger...And fuck right to left...",
              "score": -12,
              "created_utc": "2026-02-22 23:42:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6vk49u",
                  "author": "InvalidFate404",
                  "text": "He literally asked for constructive criticism....",
                  "score": 12,
                  "created_utc": "2026-02-23 01:22:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6zrlx8",
                  "author": "Portable_Solar_ZA",
                  "text": "Thanks for your thoughts but I don't mind the parts that are actual crits. I've already replied where I felt the person wasn't providing actual feedback and just felt unnecessary.",
                  "score": 1,
                  "created_utc": "2026-02-23 18:18:40",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6uhdj7",
          "author": "FakeNameyFakeNamey",
          "text": "irt your question, the papers cover is much stronger -- more dynamic angle, and the hands in 2 look a bit off.\n\n  \nI feel like doing a matrix rotation on page 1 is a surprising choice, I think you should do more of a wider crop to a tighter crop to emphasize the feeling of running movement, right now it feels more like we're just swiveling a camera around someone walking in place.\n\n  \n2 is great\n\n  \nshot reverse shot in 3 is very solid\n\n  \n3 is probably fine although I do feel like if you had done a wider cropping for bottom left it would have worked better to create the feeling of 'zoom in' \n\n  \nthe crazy over the shoulder angle for 4 is awesome\n\nmid right on 5 needs something. it's a comic beat, but it's just confusing right now. maybe a 'scoot-scoot' sound effect with some motion lines, indicating she's moving away while bowed, otherwise it's actually not clear what is physically occurring in what is supposed to be the funniest panel of the scene\n\nbottom of 7 probably needs an impact emphasis point, I know the moment is supposed to be surprising but right now it's so surprising there's no way to understand why she is flying forward until you get to the next page\n\n\n\nI wish I had better answers to you for 2 and 3. If you find out let me know. I feel like gaining new subs for anything other than outright pornography using AI is extremely difficult right now, the sheer volume of AI-released material has made it so that there's just a nonstop deluge of low-effort slop in most 'AI-open' art spaces, making it very hard for carefully constructed AI-assisted comics to get exposure. This is pretty good, I feel like with an early access model you could probably get like 20 subs or something if you could ever find a way that the eyes of a human being would look at it",
          "score": 3,
          "created_utc": "2026-02-22 21:46:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ujo3v",
              "author": "Portable_Solar_ZA",
              "text": "Thanks for the feedback, it's late at night in my neck of the woods so I'll try to reply properly in the coming days, but I'll definitely keep your crits in mind for my revisions. Thanks!",
              "score": 2,
              "created_utc": "2026-02-22 21:58:14",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6zti3c",
              "author": "Portable_Solar_ZA",
              "text": "\\>I feel like doing a matrix rotation on page 1 is a surprising choice, I think you should do more of a wider crop to a tighter crop to emphasize the feeling of running movement, right now it feels more like we're just swiveling a camera around someone walking in place.\n\nYa, I've had a couple of people point this out to me. I'm going to see if I can have another shot at this while still keeping some of the fanservice elements without giving away the character immediately.\n\n\\> 3 is probably fine although I do feel like if you had done a wider cropping for bottom left it would have worked better to create the feeling of 'zoom in'\n\nWill take a look at this.\n\n\\> the crazy over the shoulder angle for 4 is awesome\n\nThanks. I had to do so much work to get the base sketch right before running it through the model. I was going for a fishbowl type effect and am glad I mostly nailed it coz the model had no idea how to handle it with so many characters when I was experimenting with just prompts.\n\n\\>mid right on 5 needs something. it's a comic beat, but it's just confusing right now. maybe a 'scoot-scoot' sound effect with some motion lines, indicating she's moving away while bowed, otherwise it's actually not clear what is physically occurring in what is supposed to be the funniest panel of the scene\n\nWill take a look at adding in something here.\n\n\\>bottom of 7 probably needs an impact emphasis point, I know the moment is supposed to be surprising but right now it's so surprising there's no way to understand why she is flying forward until you get to the next page\n\nYa, this was intentional, to try and keep the mystery of it, but maybe I'll add in something to at least hint at her being struck by a kick.\n\n\\>I wish I had better answers to you for 2 and 3. If you find out let me know. I feel like gaining new subs for anything other than outright pornography using AI is extremely difficult right now, the sheer volume of AI-released material has made it so that there's just a nonstop deluge of low-effort slop in most 'AI-open' art spaces, making it very hard for carefully constructed AI-assisted comics to get exposure.\n\nYeah, as someone who has messed around with these models for about 9 months, it's crazy how quickly you get over the novelty of the \"generic\" prompted images and how hollow they feel, but that doesn't stop people flooding the internet with it...\n\n\\> This is pretty good, I feel like with an early access model you could probably get like 20 subs or something if you could ever find a way that the eyes of a human being would look at it\n\nThanks. I'll keep on working at this. This is my first attempt and considering how much I've been able to learn in the last three months, am hoping things will look even better in another few months.",
              "score": 2,
              "created_utc": "2026-02-23 18:27:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6w4ix2",
          "author": "HighDefinist",
          "text": "Looks good! Definitely does not seem like there is a lot missing for it to look \"real\" - or rather, that which might be missing might not be primarily due to the limitations of AI...\n\nHowever, very soon (or even now?) models might be able to plan something like the layout of multiple panels at once - something like \"this panel should create this and that impression\", and then they can generate the appropriate prompt for i.e. the perspective or something, and also check if the produced image has the right properties...\n\nAt least, that's roughly the state that AI-programming is at, currently.\n\n",
          "score": 3,
          "created_utc": "2026-02-23 03:28:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ztyo2",
              "author": "Portable_Solar_ZA",
              "text": "\\>Looks good! Definitely does not seem like there is a lot missing for it to look \"real\" - or rather, that which might be missing might not be primarily due to the limitations of AI...\n\nYeah, I'm still learning.\n\n\\>However, very soon (or even now?) models might be able to plan something like the layout of multiple panels at once - something like \"this panel should create this and that impression\", and then they can generate the appropriate prompt for i.e. the perspective or something, and also check if the produced image has the right properties...\n\nMy only concern with this is that it'll always head towards the \"average\" of whatever it's been trained on, so while it may be able to potentially produce something okay, it probably won't produce something great, since greatness usually comes from experimenting and breaking the rules.",
              "score": 1,
              "created_utc": "2026-02-23 18:29:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o70j6k8",
                  "author": "HighDefinist",
                  "text": "\\> My only concern with this is that it'll always head towards the \"average\" of whatever it's been trained on\n\n\n\nTrue. \n\n\n\nThis will almost certainly remain a significant part of \"fighting against the AI\" (while using it) for quite a while... I am not aware of any developments that would enable something like \"deviate from the norm in an interesting way\" while not having to be very specific about what kinds of deviations you want exactly... \n\n\n\n\\> since greatness usually comes from experimenting and breaking the rules\n\n\n\nSort of.\n\n\n\nSo, just generalizing from a book about photography I read some time ago, one interesting aspect was \"you should either make your photo straight (then it looks like you know what you are doing), or with 10+¬∞ twist (then it looks like an intentional 'artistic' deviation), but don't do it only slightly off, because then it looks just accidental and therefore bad\". So, more generally, the idea is probably something like you should first learn the rules, and then break them deliberately and strongly, so you get a sense of the motivation behind them. It also means you should probably not break too many rules at once, particularly not at the beginning, because then it will also just look random and messy... but all of that is more of a \"general art thing\", than something specific to AI. However, AI probably enables you to more quickly iterate over and thereby learn all the various rules, so... that's definitely a good thing.\n\n\n\nSo, yeah, it's certainly interesting to see this result you made here, because (similar to programming), you still have to understand the fundamental principles relatively well (in some ways this is even getting more important), it's just that the execution-part itself becomes significantly less important.",
                  "score": 2,
                  "created_utc": "2026-02-23 20:26:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6w9879",
              "author": "soldierswitheggs",
              "text": "> However, very soon (or even now?) models might be able to plan something like the layout of multiple panels at once - something like \"this panel should create this and that impression\", and then they can generate the appropriate prompt for i.e. the perspective or something, and also check if the produced image has the right properties...\n\nI'm sure this is what a lot of people here want, but it sounds downright dystopian to me.\n\n\"Hey, Gemini. Can you write an ecchi fantasy adventure manga about a goblin for me? And then generate a hard science fiction novel about first contact with alien microorganisms on a colony ship, so I have something to read in bed.\"\n\nI can understand the appeal on some level, but we're already in an age of fairly disposable, commercialized media. The idea of less and less human intention and effort going into every sentence or panel... it just leaves me pretty cold.\n\nThis isn't wholly unique to gen AI. Lots of tools lower the skill or intent required to produce a work. Photography. Digital art tools. Buying paints rather than crafting them yourself, by hand. But I feel like there comes a point where the input from the creator becomes minimal enough that we risk *everything* becoming slop.",
              "score": 1,
              "created_utc": "2026-02-23 03:59:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6wau5m",
                  "author": "HighDefinist",
                  "text": "> I can understand the appeal on some level, but we're already in an age of fairly disposable, commercialized media.\n\nTo me, this sounds extremely arbitrary... kind of like \"cars are dystopian and inhumane because only living beings like horses should be responsible for the locomotion of people\".\n\nI mean... ok, sure, I can understand why people might have this emotion, and presumably this wasn't an unusual viewpoint 100 years ago. But... I don't feel this way at all, and I see no reason why I should.\n\nI also find it a bit narrowminded... as in, this idea that \"crafting by hand\" is somehow inherently superior to \"crafting by mind\" seems unnecessarily restrictive with regards to how to use human creativity.\n\nAnd, what is the real motivation by those opposed to AI? Perhaps it is some kind of gatekeeping? As in, \"only artists should be allowed to produce art, because if everyone can do it, then us artists can no longer feel special\"?\n\nIn any case, one of this particularly important I think - we live in a free world, and, for example, people who enjoy porn and those who hold Puritarian beliefs can coexist peacefully. The same is true for AI-generated art, so if you don't like it, that is ok, and there is also nothing wrong about you communicating about your dislike for AI with others - as long as you understand that people like me will not look at people like yourself as someone whose opinions, views, and thoughts are worth taking seriously.",
                  "score": 0,
                  "created_utc": "2026-02-23 04:10:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6wb8hf",
          "author": "sukebe7",
          "text": "LOL, I was just thinking about your initial post the other day.",
          "score": 3,
          "created_utc": "2026-02-23 04:13:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zu4br",
              "author": "Portable_Solar_ZA",
              "text": "Glad people didn't forget about it. I'm still slowly chipping away at things when I can!",
              "score": 2,
              "created_utc": "2026-02-23 18:30:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wbq3o",
          "author": "T_D_R_",
          "text": "Really cool and amazing ",
          "score": 2,
          "created_utc": "2026-02-23 04:16:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zu5qx",
              "author": "Portable_Solar_ZA",
              "text": "Appreciate the positive vibes!",
              "score": 2,
              "created_utc": "2026-02-23 18:30:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wzsnt",
          "author": "Alpha_wolf_80",
          "text": "Bro I didn't even notice this was AI. I am cooked",
          "score": 2,
          "created_utc": "2026-02-23 07:33:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zu9oy",
              "author": "Portable_Solar_ZA",
              "text": "Are you cooked because you're an artist?",
              "score": 1,
              "created_utc": "2026-02-23 18:30:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6x16b4",
          "author": "KallistiTMP",
          "text": "I'm also working on a comic project, would love to hear about your overall workflow",
          "score": 2,
          "created_utc": "2026-02-23 07:46:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zum7y",
              "author": "Portable_Solar_ZA",
              "text": "So I've been meaning to put together a workflow document to be a companion piece to my future comics, just so people can see this is not just \"put in prompt get out comic\". But it's going to be a while before I get to it.\n\nIf this helps, this is one of the videos that I learnt from that helps me guide the model and its output based on my sketches:\n\n[https://www.youtube.com/watch?v=bKHo2Gh9O-c](https://www.youtube.com/watch?v=bKHo2Gh9O-c)",
              "score": 1,
              "created_utc": "2026-02-23 18:32:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6y9q7h",
          "author": "Culturedcontentres",
          "text": "Only two things I want to know. How? And when can we get more ms. Ayako",
          "score": 2,
          "created_utc": "2026-02-23 13:56:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zuzjc",
              "author": "Portable_Solar_ZA",
              "text": "Krita AI and an SDXL model. I vaguely touch on my process in my other post, but here's a video to get you started. This is close-ish to what I do with my process for images at least.\n\n[https://www.youtube.com/watch?v=bKHo2Gh9O-c](https://www.youtube.com/watch?v=bKHo2Gh9O-c)\n\nIn regards to more? Working on the storyboards after I've finished the cover, but I can't commit to any completion deadlines. This is just a passion project that I do after work and outside of my social/family commitments.",
              "score": 1,
              "created_utc": "2026-02-23 18:34:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ygiz1",
          "author": "Drawsstuff",
          "text": "Wow that looks great! I've recently taken on a similar project so I know it requires a lot of work. Great job!",
          "score": 2,
          "created_utc": "2026-02-23 14:34:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zv0ya",
              "author": "Portable_Solar_ZA",
              "text": "Thanks for the positive vibes!",
              "score": 1,
              "created_utc": "2026-02-23 18:34:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vxlvv",
          "author": "K0owa",
          "text": "Inspiring certainly. I don‚Äôt read hentai type stuff tho. Not that this is showing porn but it‚Äôs teetering on the edge. Last real manga I read was Trigun. Last comic I read was Batman new 52 which was terrible and then I stopped reading comics after that.",
          "score": 3,
          "created_utc": "2026-02-23 02:44:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zv98a",
              "author": "Portable_Solar_ZA",
              "text": "Yeah, it's intentionally fanservice/ecchi. \n\nThere's still a lot of great manga/comics, but like with anything these days you have to dig through to find the gems. ",
              "score": 1,
              "created_utc": "2026-02-23 18:35:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6zxxxx",
                  "author": "K0owa",
                  "text": "Actually, I did just read some Berserk recently. I tend to not read something unless someone recommends it.",
                  "score": 1,
                  "created_utc": "2026-02-23 18:47:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6v0863",
          "author": "Plane-Marionberry380",
          "text": "This is really impressive progress for just 3 months. The panel compositions look way more intentional now compared to the first post. What resolution are you generating at before bringing it into Krita?",
          "score": 2,
          "created_utc": "2026-02-22 23:27:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zvrg8",
              "author": "Portable_Solar_ZA",
              "text": "Thanks. With me being more comfortable with the overall workflow, I've been intentionally trying to push image composition a bit further. \n\nSo I actually sketch straight into Krita. I start with a standard A4 300 DPI page for my storyboards. I think copy the sketch for each panel from the storyboard into a new KRITA page (I manually adjust the size depending on what aspect ratio I need for the panel). Some are standard 1024x1024, but others I go up to 1536x1536. Again, I play with these depending on whether I need portrait or landscape panels.",
              "score": 1,
              "created_utc": "2026-02-23 18:37:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wvd18",
          "author": "Hearcharted",
          "text": "LoRA: THICC PRO MAX ü§î",
          "score": 1,
          "created_utc": "2026-02-23 06:53:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zxwv7",
              "author": "Portable_Solar_ZA",
              "text": "She's definitely meant to be curvy.",
              "score": 2,
              "created_utc": "2026-02-23 18:47:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o72pwn0",
                  "author": "Hearcharted",
                  "text": "![gif](giphy|gictytW9IIIkNGIMcs)\n\n",
                  "score": 2,
                  "created_utc": "2026-02-24 03:34:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6wwn87",
          "author": "desktop4070",
          "text": "I highly recommend using a custom font for the text, or even drawing the text yourself. You'd be surprised how that alone makes the dialogue much more interesting to read than with a standard font.",
          "score": 1,
          "created_utc": "2026-02-23 07:04:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zy55b",
              "author": "Portable_Solar_ZA",
              "text": "Thanks, but I don't really have the time to clean up the text on top of the art. Maybe when I finish the art I'll see about giving the font/writing itself a bash.",
              "score": 1,
              "created_utc": "2026-02-23 18:48:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ztrcr",
          "author": "BlobbyMcBlobber",
          "text": "This is serviceable. It's not going to win awards for layout and framing but it's definitely readable. Question is can you make it interesting and varied beyond just the most simple layouts.\n\nI don't think this is ready for paid content. It feels like a hobby project. Maybe in the future if it really turns into something great.",
          "score": 1,
          "created_utc": "2026-02-23 18:28:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zz22b",
              "author": "Portable_Solar_ZA",
              "text": "Thanks for the feedback. In regards to the layouts, that's intentional at this point. Once I can complete a comic with fairly generic panelling, I'll try to get a bit more experimental.\n\nAnd thank for your thoughts on things otherwise. Just trying to get a realistic gauge of where this project is at.",
              "score": 1,
              "created_utc": "2026-02-23 18:52:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o70hp4z",
          "author": "PerformanceNo1730",
          "text": "Excellent work! Impressive.  \nSo you use a LoRa to keep your main caracter consistant ? You trained your LoRa yourself, or how did you get there ?  \nDo you post-process your generated image ? Typically to force greyscale / black and white ?",
          "score": 1,
          "created_utc": "2026-02-23 20:19:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o70iwhw",
              "author": "Portable_Solar_ZA",
              "text": "Yes, I trained a lora, but it was my first lora so it's not very consistent. It has about 60-70% accuracy, after which I go in and edit manually, and after edits, remove the lora and do a partial refinement using the ai model to smooth things out a bit. My second lora seems to be better, but will only properly find out once I start my next pages.\n\n\nI use a black and white manga model. I think it's beret manga mix and is on civitai.¬†",
              "score": 2,
              "created_utc": "2026-02-23 20:25:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o70k2a1",
                  "author": "PerformanceNo1730",
                  "text": "OK I did not know this model. I am having a look right now.  \nThank you for the feedback on the LoRA. Percistent caracter is a real pain.  \nI can imagine the amount of work good job !",
                  "score": 2,
                  "created_utc": "2026-02-23 20:30:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7arsoz",
          "author": "UnrelaxedToken",
          "text": "I would have liked to see (all the steps) like from a white paper to a comic?",
          "score": 1,
          "created_utc": "2026-02-25 09:33:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7az0q5",
              "author": "Portable_Solar_ZA",
              "text": "I'm planning to do a quick guide to go with the comic. But want to finish the comic first.¬†",
              "score": 1,
              "created_utc": "2026-02-25 10:39:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7b0bhn",
                  "author": "UnrelaxedToken",
                  "text": "Everyone answers that \\^\\^ (i will do xyz .. when.. i finish x)  \nAnd usually these type of projects take so much time you will forget to add the guide haha",
                  "score": 0,
                  "created_utc": "2026-02-25 10:51:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7kw233",
          "author": "SkyNetLive",
          "text": "I tried this with Qwen but failed spectacularly. Anyone can try it now at Altplayer.com but I will be getting rid of it. I made it worse by switching workflows.",
          "score": 1,
          "created_utc": "2026-02-26 20:38:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6v0ci7",
          "author": "Plane-Marionberry380",
          "text": "lol the lighting on that bread is oddly perfect thoughThis is really impressive progress for just 3 months.",
          "score": 1,
          "created_utc": "2026-02-22 23:28:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zx185",
              "author": "Portable_Solar_ZA",
              "text": "Ya, it's not a big deal so haven't bothered to add any texture to it.",
              "score": 1,
              "created_utc": "2026-02-23 18:43:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6uiqpe",
          "author": "Enshitification",
          "text": "I appreciate you sharing your work, but I hope you aren't outing yourself here if your readers weren't previously aware of your particular art technique.",
          "score": 1,
          "created_utc": "2026-02-22 21:53:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ujcla",
              "author": "Portable_Solar_ZA",
              "text": "No, I haven't released anything except for the pages I posted previously in my first post here. I also plan to be completely open with my use of generative AI tools and plan to release a mini-workflow with each book to show it's not just \"put in prompt get out comic page\". I've showed some of my work in progress stuff to close offline friends for feedback already, but I'm also very aware that some of my art friends will probably be very upset that I'm using AI to complete creative projects at all...",
              "score": 7,
              "created_utc": "2026-02-22 21:56:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6ukmdk",
                  "author": "Enshitification",
                  "text": "Very cool. I admire your forthrightness.",
                  "score": 1,
                  "created_utc": "2026-02-22 22:03:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6uy00j",
          "author": "maxtablets",
          "text": "this looks pretty good. It's not clear how much the ai workflow is doing though as you haven't shown what the level of the sketches are this time.\n\nI'm wanting to figure out a similar type of workflow though i'm more interested in using it to do half tone shading, speed lines, cross hatch shading, conversion of 3d bg into heavy stylized ink style backgrounds. I don't trust it with the figure drawing as I have more stylistic preferences. \n\n1) first image. the pose in the clock image is too flat, imo. You can stick the clock in the back of the first image.\n\n2) not really, yet. It looks good, but to really take advantage of A.I, I'd expect at least the visual quality of mitsuyoshi kanketsuhen. I like the high contrast look you got though. Just a little more immersion. There is not enough writing to know if its a story to be interested.\n\n",
          "score": 1,
          "created_utc": "2026-02-22 23:15:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zwftt",
              "author": "Portable_Solar_ZA",
              "text": "Thanks, sorry I haven't gotten into detail with my workflow. That on its own is a little mini project and I'm just trying to get the comic itself finished.\n\nSo I've dabbled with backgrounds and found that the SDXL models I've tried are generally pretty good at them. Effects are another story. At this point I tried using Flux2 Klein 9b and it's very hit and miss at adding effects. However, there has been some happy accidents with screen tones and shading that it made that have given me some ideas.",
              "score": 2,
              "created_utc": "2026-02-23 18:40:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6v1z6k",
          "author": "KaradocThuzad",
          "text": "I remember you posting before!\n\nThis is really great, I honestly look forward to reading the finished work, I can only imagine the time it takes to work on your workflows and to learn how to make a decent comic.\n\nGood luck, I'll keep an eye out for your work!",
          "score": 1,
          "created_utc": "2026-02-22 23:37:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zwhrf",
              "author": "Portable_Solar_ZA",
              "text": "Thank you. Appreciate the positivity!",
              "score": 1,
              "created_utc": "2026-02-23 18:40:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6v3h9o",
          "author": "Soraman36",
          "text": "Not going to repeat what others already said but so far so good. I give it a few more months and you'll get it down",
          "score": 1,
          "created_utc": "2026-02-22 23:46:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zwk6q",
              "author": "Portable_Solar_ZA",
              "text": "Really appreciate it. As I've said to the others, appreciate the good vibes.",
              "score": 2,
              "created_utc": "2026-02-23 18:41:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vsf1l",
          "author": "ModFrenzyAI",
          "text": "Man, Krita AI is the goat! I don't know if **Acly** is in this subreddit or not but huge thanks to him! I've started creating stuff with AI 2 months ago and I feel like Krita AI made things so much simpler and easier for me. ",
          "score": 1,
          "created_utc": "2026-02-23 02:12:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zwxp8",
              "author": "Portable_Solar_ZA",
              "text": "Dude, I love KRITA AI. I probably wouldn't be interested in AI creative projects if it wasn't for this tool.  \n  \nAlso, this video helped me out so much to try and squeeze as much as possible out of an AI model rather than just relying on prompts and roll of the dice with image-to-image generation:\n\n[https://www.youtube.com/watch?v=bKHo2Gh9O-c](https://www.youtube.com/watch?v=bKHo2Gh9O-c)",
              "score": 1,
              "created_utc": "2026-02-23 18:42:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vz3hd",
          "author": "STurbulenT",
          "text": "his is more a proof of concept for¬†you",
          "score": 1,
          "created_utc": "2026-02-23 02:53:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vo376",
          "author": "Beginning-Struggle49",
          "text": "Wow this is great ! I've also been experimenting making comics, but I'm always having trouble with the angles. Maybe I should try manga style loras instead, I've generally just been trying to use a generic anime style using qwen image edit\n\n\n1) I like the first cover more\n\n2) No sorry, I don't even pay for comics of people who really draw them, I wouldn't start with an AI artist :)\n\n3) check out storinex.com maybe",
          "score": 0,
          "created_utc": "2026-02-23 01:46:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zxoke",
              "author": "Portable_Solar_ZA",
              "text": "Thanks for the suggestion.",
              "score": 1,
              "created_utc": "2026-02-23 18:46:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o708vt7",
                  "author": "Beginning-Struggle49",
                  "text": "you're welcome!",
                  "score": 1,
                  "created_utc": "2026-02-23 19:37:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6w7nhs",
          "author": "wasabi991011",
          "text": "> Finally, if you have any other constructive thoughts/feedback, please feel free to add them here.\n\nI don't know how to say this nicely, but I have to say it anyway: it's way too pervy.\n\nLike as a layman, most of the framing stuff and angles and whatever is going over my head a bit. But what I notice is that the MC's bust and clothing (like the button almost exploding) feels like it's straight out of a hentai.  I'd understand if it was a NSFW comic like oglaf, but since it's not it makes me feel gross reading it.",
          "score": 0,
          "created_utc": "2026-02-23 03:48:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zxtoy",
              "author": "Portable_Solar_ZA",
              "text": "You're welcome to feel that way, but that's kind of the whole point of fanservice. Completely understand if it's not your thing though.",
              "score": 1,
              "created_utc": "2026-02-23 18:46:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wc7se",
          "author": "sukebe7",
          "text": "[https://mangadex.org/title/ff2d4da5-8b42-4fc9-8853-afda53874afb/ntr-kaeshi](https://mangadex.org/title/ff2d4da5-8b42-4fc9-8853-afda53874afb/ntr-kaeshi)",
          "score": 0,
          "created_utc": "2026-02-23 04:20:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ukqjq",
          "author": "InsolentCoolRadio",
          "text": "Great comic!\n\nI really loved the camera angle and use of negative space on the panel in image 7; I felt what Ayako was feeling.\n\n1. Cover #2 has a better vibe IMO; she looks more heroic and like someone to root for, whereas Cover #1 makes her seem more like a damsel or someone to look down on\n2. I‚Äôm not in the market to subscribe to anything, BUT if I were to buy something animated or illustrated I‚Äôd be super happy with this\n3. r/aicomics and r/aicomicmakers are pretty cool.",
          "score": -3,
          "created_utc": "2026-02-22 22:03:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ullkm",
              "author": "mobileJay77",
              "text": "Thanks for the links!",
              "score": 2,
              "created_utc": "2026-02-22 22:08:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6wl5ut",
                  "author": "InsolentCoolRadio",
                  "text": "Glad to help : )",
                  "score": 2,
                  "created_utc": "2026-02-23 05:26:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6zxf5f",
              "author": "Portable_Solar_ZA",
              "text": "Thanks. Appreciate the feedback regarding the covers. Like, I like the idea of #2 even though it looks a bit odd at the moment, but so many people have told me they like #1 more in relation to the comic... will have to see what I finally go with. \n\nAnd thanks for the suggestions.",
              "score": 2,
              "created_utc": "2026-02-23 18:45:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o71tk2i",
                  "author": "InsolentCoolRadio",
                  "text": "My pleasure! Thank you for sharing your comic with the community : )",
                  "score": 1,
                  "created_utc": "2026-02-24 00:26:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1revwgq",
      "title": "CLIP is back on Anima, because CLIP is eternal.",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1revwgq/clip_is_back_on_anima_because_clip_is_eternal/",
      "author": "Anzhc",
      "created_utc": "2026-02-26 00:58:35",
      "score": 225,
      "num_comments": 29,
      "upvote_ratio": 0.94,
      "text": "You thought you can get away from it? Never.\n\nhttps://preview.redd.it/ucku0gzegqlg1.png?width=743&format=png&auto=webp&s=2f349550205028c6e18e4b72aa9144304d2c1e75\n\nGuys at Yandex and Adobe implemented CLIP for bunch of models that don't use it - [https://github.com/quickjkee/modulation-guidance](https://github.com/quickjkee/modulation-guidance)\n\nI made it into ComfyUI node for Anima - [https://github.com/Anzhc/Anima-Mod-Guidance-ComfyUI-Node](https://github.com/Anzhc/Anima-Mod-Guidance-ComfyUI-Node)\n\nFor images above and below i used CLIP L from here - [https://huggingface.co/Anzhc/Noobai11-CLIP-L-and-BigG-Anime-Text-Encoders](https://huggingface.co/Anzhc/Noobai11-CLIP-L-and-BigG-Anime-Text-Encoders)\n\nBasic CLIP L also works, but your mileage may vary, every CLIP has different effect.\n\n\\---\n\nUnfortunately it won't let you use weighting as on SDXL, but from what i tested that also was a bit better at least.\n\nSo what are the benefits anyway?\n\nFrom what i tested(Left is base Anima, right with Modulation Guidance):\n\n\\- Can reduce color leaks\n\nhttps://preview.redd.it/ush1cgt9hqlg1.png?width=2501&format=png&auto=webp&s=968ea21bdbf5a89648c04502bb391965d9640151\n\n(necktie is not even prompted)\n\n\\- Improve composition and stability\n\nhttps://preview.redd.it/67a60iirhqlg1.png?width=2070&format=png&auto=webp&s=8268d0c1cbc3b4c95f44e091fc44e0a5864c7529\n\n(Yes, i picked the funniest example, sue me)  \nThat particular prompt i ran like 10 times, few of them it would show another issue:\n\n\\- Beach\n\nhttps://preview.redd.it/efvihns8iqlg1.png?width=2067&format=png&auto=webp&s=c61db50a509ab6772b74e60fb4834f0784dc7750\n\nFor no reason whatsoever, Anima LOVES to default to ocean or beach, that effect is reduced with CLIP.\n\n\\- Less unprompted horny (I know for most of you this is a negative though)\n\nhttps://preview.redd.it/b9byqkhkiqlg1.png?width=2286&format=png&auto=webp&s=800d55d03dcbe5a53d403b6b6a310e826bc5a25e\n\n(Afterimages prompted, i just wanted her to sweep floors...)\n\n\\- Little bit better (from what i tested) character separation, and adherence to character look\n\nhttps://preview.redd.it/hk1ye4pviqlg1.png?width=2507&format=png&auto=webp&s=6452c13d141cc1cf4c738c8c7d055cce3288c7e5\n\nBut it still largely relies on base model understanding in this aspect.\n\n\\- Can also improve quality in general (subjective)\n\nhttps://preview.redd.it/yhlkikw6jqlg1.png?width=1827&format=png&auto=webp&s=bd80337bb128773a19c9825cb426d7900272dd55\n\n\\- Less 1girl bias (prompt is just \\`masterpiece, best quality, scenery\\`)\n\nhttps://preview.redd.it/h681h5jnjqlg1.png?width=2588&format=png&auto=webp&s=df37a3c08f320d5a6877b28b13e2349f71a6a358\n\nhttps://preview.redd.it/elapkpktjqlg1.png?width=2112&format=png&auto=webp&s=f0d0aefda7ae627a3afba40a20695b296a8e0e9f\n\nhttps://preview.redd.it/9gdbycuyjqlg1.png?width=2114&format=png&auto=webp&s=0e749ae327f2390d762d165d6fe9c240374cdfd6\n\n  \nI primarily tested with tags only, while i did test with some NL, i generally don't have much luck with it on Anima, for me it's unstable and inconsistent, so i'll leave it to you to find if CLIP is helping there or not.\n\nP.S. All girls in images are clothed/in bikini, i just censored them to keep it safe. But i really can't emphasize how horny Anima is by default...\n\n  \nIt's easy to use, and i've included prepared workflow for you to compare both results for yourself:\n\nhttps://preview.redd.it/u6bue5hulqlg1.png?width=2742&format=png&auto=webp&s=2fbead9bb4da338312d1055b3e16de4a12bce2c4\n\nYou can find it in repo. To use it, you don't need to write a prompt for it every time, generally you just use it as secondary quality tags, and wire negative and base in from main prompts.\n\nBased on official repo, you can tune it to affect different things, but i haven't tried using it like that, so up to you to test it.\n\nThat's it. Have fun. Till next time.\n\n\n\nAlso\n\n  \nShe's just like me frfr\n\nhttps://preview.redd.it/7r0b9lx8kqlg1.png?width=555&format=png&auto=webp&s=f375ad6d8b5bf587f876416d5bd8193af0ba11fd\n\nIf you're here, here are links from the top of post so you don't have to scroll:\n\n  \nOriginal implementation - [https://github.com/quickjkee/modulation-guidance](https://github.com/quickjkee/modulation-guidance)\n\nComfyUI node for Anima - [https://github.com/Anzhc/Anima-Mod-Guidance-ComfyUI-Node](https://github.com/Anzhc/Anima-Mod-Guidance-ComfyUI-Node)\n\nWorkflows also can be found right in node repo.\n\nFor images above i used CLIP L from here - [https://huggingface.co/Anzhc/Noobai11-CLIP-L-and-BigG-Anime-Text-Encoders](https://huggingface.co/Anzhc/Noobai11-CLIP-L-and-BigG-Anime-Text-Encoders)",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1revwgq/clip_is_back_on_anima_because_clip_is_eternal/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "o7gdmes",
          "author": "comfyanonymous",
          "text": "Since anima is based on cosmos you can also use t5xxl 1.0 with it.\n\nJust use the native workflow with this file instead of qwen_0.6b: https://huggingface.co/comfyanonymous/cosmos_1.0_text_encoder_and_VAE_ComfyUI/tree/main/text_encoders",
          "score": 21,
          "created_utc": "2026-02-26 03:46:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7gogyq",
              "author": "ZootAllures9111",
              "text": "Is there any benefit to this?",
              "score": 8,
              "created_utc": "2026-02-26 04:58:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7h00eh",
                  "author": "comfyanonymous",
                  "text": "I don't think so but it's interesting.",
                  "score": 8,
                  "created_utc": "2026-02-26 06:27:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7jcyxo",
          "author": "Viktor_smg",
          "text": "Man it's so refreshing seeing actual anime on this sub again and not just the normie slop that normie models pump out. And featuring some pretty good shows at that.",
          "score": 11,
          "created_utc": "2026-02-26 16:21:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hea72",
          "author": "EirikurG",
          "text": "you're gonna need bigger grids with more images for your comparisons if we are to see a meaningful difference between the two  \n  \nshowing us just 1 seed of each and saying \"oh yeah, this looks better\" is not a very good comparison",
          "score": 18,
          "created_utc": "2026-02-26 08:36:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7j5dja",
              "author": "NanoSputnik",
              "text": "Amen.¬†",
              "score": 3,
              "created_utc": "2026-02-26 15:46:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7j6sz5",
              "author": "Choowkee",
              "text": "Yeah...Anima outputs can vary widely from seed to seen (for better or worse).\n\nStill I am gonna give OP the benefit of the doubt and assume it helps.",
              "score": 3,
              "created_utc": "2026-02-26 15:53:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7jz1if",
              "author": "Ok-Category-642",
              "text": "Yeah I tested this for a little bit and I have my doubts that it's actually better and not just different. The outputs ended up being very similar (even pure NL) including artist mixing too. Prompt weighting changes a little more, but it doesn't work too well either. It doesn't seem to be strictly better either; sometimes it's better and sometimes it's worse, sometimes they both make the same error, but overall it's not consistent. If you use a style Lora the difference becomes even smaller, it doesn't seem worth it overall as it just seems to make styles and NL slightly weaker with not much benefit.\n\nGranted I haven't done a lot of testing either but it doesn't seem to have the benefits I would've hoped for.",
              "score": 2,
              "created_utc": "2026-02-26 18:03:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7kqp4j",
              "author": "Anzhc",
              "text": "I obviously did gen many seeds per prompt, but it's not really good for reddit post. \n\nIn my experience, i preferred CLIP output in about 60 to 80% cases, depending on prompt. In post i just shown specific examples of what using it can result into.",
              "score": 1,
              "created_utc": "2026-02-26 20:12:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7fx8c7",
          "author": "Only4uArt",
          "text": "I was doubting the usability when reading the title but the results really point towards certain pain points one can have with anima preview and the clip results are great in the examples.\n\n\nI would say clip can elevate the floor of what the model can do in the average hands of a user.\n\nIt will be interesting to see what happens with the base model and fine-tunes on top of it. I can still see a lot of potential in using qwen . But no one would miss it currently in the status quo.",
          "score": 17,
          "created_utc": "2026-02-26 02:11:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7gocsy",
              "author": "ZootAllures9111",
              "text": "This node only works alongside Qwen, it doesn't work by itself.",
              "score": 5,
              "created_utc": "2026-02-26 04:58:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7g3fn8",
          "author": "Normal_Border_3398",
          "text": "I love your adetailers yolos with all my heart. <3",
          "score": 9,
          "created_utc": "2026-02-26 02:46:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7g15de",
          "author": "devilish-lavanya",
          "text": "Nooo, please Nooooo, i can‚Äôt take CLIP Anymore. Please",
          "score": 25,
          "created_utc": "2026-02-26 02:33:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7g2iyt",
              "author": "Anzhc",
              "text": "CLIP is eternal. Accept CLIP. Everyone needs CLIP in their life. Do not resist.",
              "score": 39,
              "created_utc": "2026-02-26 02:41:16",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o7hgkar",
              "author": "nicman24",
              "text": "clip might make cancer drugs think about that lol",
              "score": 2,
              "created_utc": "2026-02-26 08:58:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7fwh80",
          "author": "nsfwkorea",
          "text": "Nice work there mate. Thank you for making a post showing the comparisons.",
          "score": 9,
          "created_utc": "2026-02-26 02:07:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7h7j7z",
          "author": "NotSuluX",
          "text": "Super interesting thanks for this. The method implemented seems like a great way to get the upsides of clip (prompt adherence and styles), without the downsides (poor spatial awareness)",
          "score": 2,
          "created_utc": "2026-02-26 07:33:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ha9z6",
              "author": "Anzhc",
              "text": "Poor spatial awareness is an issue of datasets, not CLIP. It just so happens that old models that primarily use CLIP are also models that had poor datasets. There are some papers that train spatiality into sd1.5/sdxl just fine.",
              "score": 6,
              "created_utc": "2026-02-26 07:58:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7h8wmu",
          "author": "doomed151",
          "text": "All praise the CLIP",
          "score": 2,
          "created_utc": "2026-02-26 07:45:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hdxsv",
          "author": "Sugarcube-",
          "text": "I'm a CLIP enjoyer. This new gen of no negative prompts, ultra verbose and borderline philosophical positive prompts has been a pain in the ass",
          "score": 6,
          "created_utc": "2026-02-26 08:33:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7hke95",
              "author": "shapic",
              "text": "1. This is not true for anima and even z-image\n2. Title is a bit misleading, it is not clip as openai product that is being used here",
              "score": 8,
              "created_utc": "2026-02-26 09:36:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7kb6e0",
                  "author": "shapic",
                  "text": "I think I should clarify my comment after reading the paper. They did attach clip to non-clip model, and had to to additional finetuning, \"Specifically, we train a small MLP on top of the pooled text embedding and add it to the timestep embedding,\"",
                  "score": 1,
                  "created_utc": "2026-02-26 18:58:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7hm0r1",
          "author": "net_tribe24",
          "text": "Thank you for sharing this, I have been using Anima and would like to try your CLIP. I am fairly new to ComfyUI and the world of anime and am struggling to implement this. I have try to drag the base json in to comfyui, it hangs, then an image no embedded workflow. I can see you are an advance practitioner, but could you create a simple step guide for implementation for those like me that would like to try this, where this is not so obvious. Thanks in advance.",
          "score": 1,
          "created_utc": "2026-02-26 09:52:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7i8b4b",
              "author": "net_tribe24",
              "text": "Hi, it was user error on my part, I DL the WF in html not raw json, duh! Once I had the work flow, everything else installed okay. I have to agree with the OP, The final composition showing before and after, the latter is a better composition and has improved colours. A much more mature result. Thank you for sharing your WF, multiline input is new for me, and for not using subgraphs! lol ",
              "score": 2,
              "created_utc": "2026-02-26 12:52:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rfvx7c",
      "title": "WAN 2.2's 4X frame interpolation capability surpasses that of commercial closed-source software.",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/z4tiu9waiylg1",
      "author": "Some_Smile5927",
      "created_utc": "2026-02-27 03:42:03",
      "score": 223,
      "num_comments": 42,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rfvx7c/wan_22s_4x_frame_interpolation_capability/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7n3aji",
          "author": "Shifty_13",
          "text": "Workflow for WAN interpolation???",
          "score": 32,
          "created_utc": "2026-02-27 03:47:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nsilz",
              "author": "nsfwVariant",
              "text": "OP linked it in another comment: [https://huggingface.co/hyutsa/some\\_useful\\_workflows/resolve/main/wan22\\_4frames\\_interp.json](https://huggingface.co/hyutsa/some_useful_workflows/resolve/main/wan22_4frames_interp.json)",
              "score": 24,
              "created_utc": "2026-02-27 06:52:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7oeo8j",
                  "author": "FoxTrotte",
                  "text": "From what I can see this worflow doesn't allow for full video interpolation, only four frames",
                  "score": 3,
                  "created_utc": "2026-02-27 10:16:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7n3rkn",
          "author": "teekay_1994",
          "text": "You could have used a video with more movement...\n\nBut still, will have to try this. So far RIFE has been working pretty nicely for me.",
          "score": 22,
          "created_utc": "2026-02-27 03:50:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7n5y4p",
              "author": "AwesomeAkash47",
              "text": "And Rife is going to be fast as well, making it more practical",
              "score": 8,
              "created_utc": "2026-02-27 04:04:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7n6h56",
                  "author": "teekay_1994",
                  "text": "Yeah it's very fast actually. Nice to have a second alternative either way.",
                  "score": 5,
                  "created_utc": "2026-02-27 04:07:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7p9qc4",
                  "author": "Nevaditew",
                  "text": ">",
                  "score": 1,
                  "created_utc": "2026-02-27 13:59:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7n94e1",
              "author": "Some_Smile5927",
              "text": "RIFE is really good; I use it frequently. However, it does have frame repetition and artifacts above 3x.",
              "score": 4,
              "created_utc": "2026-02-27 04:25:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7noxxt",
                  "author": "teekay_1994",
                  "text": "I usually take 16fps videos from wan, convert them to 30fps and then I run them through a second RIFE pass for 60fps. So far I have had no issues.",
                  "score": 4,
                  "created_utc": "2026-02-27 06:22:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7nprl5",
                  "author": "Stepfunction",
                  "text": "Doing repeated 2x passes has always given me the best results.",
                  "score": 3,
                  "created_utc": "2026-02-27 06:29:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7r883j",
                  "author": "foxdit",
                  "text": "I've been a RIFE hater since early days. For me, it's Film VFI all day every day. No jerky/janky issues.",
                  "score": 1,
                  "created_utc": "2026-02-27 19:41:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7narjl",
          "author": "Stepfunction",
          "text": "I mean it may be marginally better than RIFE, but RIFE is blazingly fast, low in resource requirements, and also not closed-source or commercial.",
          "score": 18,
          "created_utc": "2026-02-27 04:36:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nbcca",
              "author": "Some_Smile5927",
              "text": "U are right ÔºÅ",
              "score": 1,
              "created_utc": "2026-02-27 04:40:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ni1zh",
          "author": "mobani",
          "text": "Seems WAN changed the eyes to focus on the viewer. They are looking beyond the camera on the other examples, because WAN is not interpolating, it's creating basically. (but that can be good if you want that).",
          "score": 5,
          "created_utc": "2026-02-27 05:28:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7p9nai",
              "author": "Cequejedisestvrai",
              "text": "not only that, it‚Äôs created 4 new white balls under her arm",
              "score": 2,
              "created_utc": "2026-02-27 13:58:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7pfij1",
                  "author": "necile",
                  "text": "those are pearls üòÇ you're totally right tho, didn't even notice",
                  "score": 2,
                  "created_utc": "2026-02-27 14:30:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7qru3b",
              "author": "_half_real_",
              "text": "Wan with VACE isn't supposed to do that, it _should_ keep the original frames unchanged if the masks are correct. I use VACE a lot so I'll need to look into this.",
              "score": 1,
              "created_utc": "2026-02-27 18:22:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7qwnf2",
                  "author": "mobani",
                  "text": "The problem is not the start and end frame, it's the generated frames between. Anything is up for change when you use diffusion to make the next frame. ",
                  "score": 1,
                  "created_utc": "2026-02-27 18:45:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7o38lt",
          "author": "krautnelson",
          "text": "the problem is that WAN doesn't just interpolate. it actually changes the video.\n\nlook at the eyes of the model.",
          "score": 5,
          "created_utc": "2026-02-27 08:27:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7o5my1",
              "author": "Some_Smile5927",
              "text": "This is likely related to the prompt. I should have emphasized slow motion, otherwise the blinking issue would occur. It's not the slow-motion model's inference that causes it to blink, but rather the duration of the time.",
              "score": 1,
              "created_utc": "2026-02-27 08:50:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7nelt1",
          "author": "Boysen_berry42",
          "text": "Nice comparison. I like that you showed the hair strands and the fan, that made it easier to see the differences. RIFE is still hard to beat for speed, but the artifacts above 3x are real. WAN 2.2 handling longer clips without the 8-frame limit is interesting though. Thanks for sharing",
          "score": 4,
          "created_utc": "2026-02-27 05:02:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nnt72",
              "author": "Life_Yesterday_5529",
              "text": "You could do 2000 frames with Wan if it only has to fill the blank frames between existing frames via Vace.",
              "score": 1,
              "created_utc": "2026-02-27 06:13:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7n33gq",
          "author": "Some_Smile5927",
          "text": "Wan Vace's frame interpolation effect is also good, but it's limited to 8 frames , and there will be color deviation.",
          "score": 3,
          "created_utc": "2026-02-27 03:46:13",
          "is_submitter": true,
          "replies": [
            {
              "id": "o7n4zjx",
              "author": "nsfwVariant",
              "text": "Is this not also using VACE?",
              "score": 1,
              "created_utc": "2026-02-27 03:58:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7n9bg1",
                  "author": "Some_Smile5927",
                  "text": "Not yet. This I use WAN 2.2 i2v + context, so it can deal any long time video.",
                  "score": 0,
                  "created_utc": "2026-02-27 04:26:41",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7p1kze",
          "author": "Ok_Cauliflower_6926",
          "text": "Some of the results are a waste of time, you can use FSR Frame Gen with Lossles Scaling.",
          "score": 2,
          "created_utc": "2026-02-27 13:12:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qh7f3",
              "author": "raysar",
              "text": "Visual quality is NOT AT ALL the same as RIFE. Do the test, FSR is crap. (it's usable but not at all the same quality.)",
              "score": 1,
              "created_utc": "2026-02-27 17:32:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7nj0uu",
          "author": "acamas",
          "text": "Would this be true for animation too or just realism?",
          "score": 1,
          "created_utc": "2026-02-27 05:35:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7opgsx",
          "author": "polawiaczperel",
          "text": "I was really curious how WAN would work with JAV decensoring and thought that it kinda obvious to use it in this case, but nobody was trying?",
          "score": 1,
          "created_utc": "2026-02-27 11:49:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7t5exi",
              "author": "Some_Smile5927",
              "text": "I've tried it in my previous post, and with the current technology, I'm confident it will be more realistic and stable, especially for JAV.",
              "score": 2,
              "created_utc": "2026-02-28 02:00:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7otz2o",
          "author": "Grindora",
          "text": "Wait what! Never heard of RIFE, how do i use it on windows?",
          "score": 1,
          "created_utc": "2026-02-27 12:22:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qtmbi",
              "author": "Conscious_Arrival635",
              "text": "\\+1 for linux",
              "score": 1,
              "created_utc": "2026-02-27 18:31:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7qtj3s",
          "author": "sandshrew69",
          "text": "Waiting until someone runs all of naruto through that. I remember there was a frame interpolator for anime but it kinda sucked.",
          "score": 1,
          "created_utc": "2026-02-27 18:30:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7qy3kz",
          "author": "Technical_Ad_440",
          "text": "i feel like wan has become really fractured with how you need to set it up. we really need some opensource video suite that has the image editing upscaling and such all in 1. i was working with opensource but google flow just kills it. like we really need accessible 96gb cards cause quantizing models making them understand less but be able to run at lower quality really isn't it. its useless being able to run models but quality nosedives and jumping through 20hoops to get full veo3 or seadance quality isnt it. opensource is for sure massively fractured",
          "score": 1,
          "created_utc": "2026-02-27 18:52:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7sux5a",
          "author": "jowala1",
          "text": "How about including the run time as well? Quality is less of a factor if it takes 10x longer to achieve it.",
          "score": 1,
          "created_utc": "2026-02-28 00:55:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7t6buc",
          "author": "Dead_Internet_Theory",
          "text": "whatever happened to FILM?  \n[https://film-net.github.io/](https://film-net.github.io/)  \nit's old but so is RIFE and back then I thought \"FILM is too slow and memory hungry\" but it's gotta be much less tough to run than Wan2.2.",
          "score": 1,
          "created_utc": "2026-02-28 02:06:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7nl6f5",
          "author": "hidden2u",
          "text": "I just came here to say I can‚Äôt believe how fast FL RIFE has gotten, 81 frames x3 in about 2 seconds",
          "score": 0,
          "created_utc": "2026-02-27 05:52:00",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rego9t",
      "title": "Latent Library v1.0.2 Released (formerly AI Toolbox)",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/vl5w7g5avnlg1.png",
      "author": "error_alex",
      "created_utc": "2026-02-25 15:43:04",
      "score": 215,
      "num_comments": 77,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rego9t/latent_library_v102_released_formerly_ai_toolbox/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7cha25",
          "author": "TopTippityTop",
          "text": "What is it?",
          "score": 13,
          "created_utc": "2026-02-25 16:04:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ci6l4",
              "author": "error_alex",
              "text": "It's a free, open-source desktop asset manager built specifically for organizing massive collections of AI-generated images (Stable Diffusion, Flux, etc.).\n\nThink of it like Adobe Bridge, but specialized for AI:\n\n* **Metadata Search:** It indexes your images so you can instantly search by prompt, seed, model, or LoRA (supports A1111, ComfyUI, Invoke, etc.).\n* **Local & Private:** It runs 100% offline on your machine‚Äîno cloud sync or telemetry.\n* **Workflow Tools:** Includes a duplicate finder, AI auto-tagging (running locally), and a \"speed sorter\" for cleaning up bad generations quickly.\n\nSee the [original post](https://www.reddit.com/r/StableDiffusion/comments/1r65bnh/i_built_a_free_localfirst_desktop_asset_manager/) or the [GitHub](https://github.com/erroralex/Latent-Library) for more info. Thank you!",
              "score": 21,
              "created_utc": "2026-02-25 16:08:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7cij1w",
                  "author": "TopTippityTop",
                  "text": "Got it, that's what it appeared to be from your image. I'd suggest making it front and center in GitHub and your marketing, whenever you post. Perhaps you did, but I glanced at it, saw release notes, but no clear explanation at the top. Good luck and thank you for sharing!",
                  "score": 16,
                  "created_utc": "2026-02-25 16:09:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7e9j9h",
                  "author": "victorc25",
                  "text": "So nothing related to latents?¬†",
                  "score": 7,
                  "created_utc": "2026-02-25 20:58:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7ha31u",
                  "author": "Head-Vast-4669",
                  "text": "Well organization is an excellent idea indeed. I already built a similar thing for myself in Notion.",
                  "score": 1,
                  "created_utc": "2026-02-26 07:56:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7csm9f",
          "author": "GroovynBiscuits",
          "text": "Ill check this out. Sounds exactly like something ive needed",
          "score": 5,
          "created_utc": "2026-02-25 16:55:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7g4772",
          "author": "sheepdog2142",
          "text": "Doesn't seem to be a way to set a networked folder to be a collection. I even tried running it exe off the networked folder and still no luck. \n\nWould be really nice to be able to pull from a nas or server storage inside my secure home network.",
          "score": 3,
          "created_utc": "2026-02-26 02:50:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7q87sp",
              "author": "error_alex",
              "text": "In the latest release, v1.1.0, you can manually browse and add a pinned folder (just press the + button above the Library folder tree). This should let you add network folders that is not recognized by the folder tree as directories.",
              "score": 1,
              "created_utc": "2026-02-27 16:50:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7qp1e3",
                  "author": "sheepdog2142",
                  "text": "Awesome thank you. Great work btw!",
                  "score": 2,
                  "created_utc": "2026-02-27 18:09:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7dep7w",
          "author": "grebenshyo",
          "text": "macos yay!\n\nheads up: to get it up you need to recursively clear quarantine on the entire bundle:  \nsudo xattr -cr \"/Applications/Latent Library.app\"\n\nIf the app is still in your Downloads or wherever you mounted it from, adjust the path accordingly. After running that, try opening it normally.",
          "score": 2,
          "created_utc": "2026-02-25 18:35:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7dq6lq",
              "author": "error_alex",
              "text": "Huge thanks for testing this! Since I don't own a Mac, I was flying completely blind on that build, so this confirmation is super helpful.\n\nYou hit the nail on the head‚Äîit's the standard Gatekeeper quarantine blocking it because I haven't paid the Apple Developer fee to get the app officially notarized yet.\n\nTo try and make this slightly smoother for the next patch, I‚Äôve just updated the build config to:\n\n**Ad-Hoc Signing:** I added `identity: null` to the build process, which ensures it at least has the pseudo-signature required to launch on Apple Silicon (M1/M2/M3) chips without crashing instantly.\n\nI‚Äôve added your `xattr` command to the main README troubleshooting section so others don't get stuck. Thanks again!",
              "score": 1,
              "created_utc": "2026-02-25 19:27:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7ds4xk",
                  "author": "grebenshyo",
                  "text": "my pleasure! i'm actively using this, so your work is much appreciated!  \nsince my install is in place now, i'll keep running that for the moment being. however, since we're at it, i can report another behavior i encountered, which i'm not quite sure if it's personal or general: having little snitch installed, i have the app being signaled on \"wants to connect to fd97:1a08:b277:db2b:1437:ef65:6726:22a0 in the local network\", from time to time, ‚Äî not sure if it's getting blocked \\*before\\* or \\*because\\* of this. approving solves, but it keeps reappearing, so this will need to get addressed. on this note: i was already planning to fork the project for this exact purpose of porting, but you beat me on time :D so i'd be glad to help in any way if i can! i'll add you here on reddit, so we keep posted! ‚úåüèæ",
                  "score": 2,
                  "created_utc": "2026-02-25 19:37:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7e7rhm",
          "author": "sixstringnerd",
          "text": "Thank you for creating this! I'm getting \"Back-end is Unreachable\" shortly after opening it. I remember now that I got the same message with the last version.\n\nI'm on Windows 11 Pro. Do you have any quick thoughts on this?",
          "score": 2,
          "created_utc": "2026-02-25 20:50:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ei8wl",
              "author": "grebenshyo",
              "text": "i assume this is an error that can appear because of a few different reasons. one of them seems to be the indexing overload: i noticed that if i use recursive indexing and go to huge folders, that error is more prone to appear, so it's just a matter of adjusting the pace with which one navigates the directories, at least in this specific case.",
              "score": 2,
              "created_utc": "2026-02-25 21:38:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7evhdh",
                  "author": "sixstringnerd",
                  "text": "Actually, through lots of trial and error, my issue was caused by 3 or 4 mapped, but disconnected, drives.",
                  "score": 2,
                  "created_utc": "2026-02-25 22:42:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7eargk",
          "author": "RebootBoys",
          "text": "I've been trying out something similar: https://github.com/LuqP2/Image-MetaHub\n\nHow does your tool differ from that?",
          "score": 2,
          "created_utc": "2026-02-25 21:03:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7eqaai",
          "author": "roculus",
          "text": "can you go into where and how the data is stored locally for windows? or providing a setting for choosing where to store the data?",
          "score": 2,
          "created_utc": "2026-02-25 22:16:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7hgt7m",
              "author": "error_alex",
              "text": "The data (thumbnails, database, logs etc) is all stored in a /data folder next to your executable. It's created on the first start of the application.\n\nIn settings there is a button to open data folder, as well as several data-related commands (clear database, clear thumbnails etc).",
              "score": 1,
              "created_utc": "2026-02-26 09:01:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7gzhoc",
          "author": "Passable_Funf",
          "text": "I like the new name! It sounds good.",
          "score": 2,
          "created_utc": "2026-02-26 06:23:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7jyvdp",
              "author": "error_alex",
              "text": "Thank you! :)",
              "score": 1,
              "created_utc": "2026-02-26 18:02:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7kdtei",
          "author": "Gerweldig",
          "text": "Will check it out! I hope It will have a hot folder.. So you can see the enlarged view of latest images during generation..  It's a rare feature and very handy during a generation run",
          "score": 2,
          "created_utc": "2026-02-26 19:11:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7l6bs4",
              "author": "error_alex",
              "text": "It does soon! I am implementing this as I write because it's an awesome idea that I did not think of!",
              "score": 2,
              "created_utc": "2026-02-26 21:27:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7m41up",
                  "author": "Gerweldig",
                  "text": "You are a hero, sir",
                  "score": 2,
                  "created_utc": "2026-02-27 00:22:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7n0pzd",
          "author": "story_of_the_beer",
          "text": "Does this do recursive folder searches? Or is it mainly for people who dump all their outputs in a single or few folders?",
          "score": 2,
          "created_utc": "2026-02-27 03:31:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nl3mi",
              "author": "error_alex",
              "text": "It can do, yes! There is a toggle to include subfolders.",
              "score": 1,
              "created_utc": "2026-02-27 05:51:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7g5xs2",
          "author": "Far_Let_5678",
          "text": "I like the rebrand. Now it has a unique identity. Less confusing. I actually clicked here out of confusion thinking that the LoRA training AI Toolkit had changed. LOL. Impressive what you've done. Way better than my attempts. Keep building!",
          "score": 2,
          "created_utc": "2026-02-26 03:00:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7jytmj",
              "author": "error_alex",
              "text": "Thank you, glad you like it!",
              "score": 1,
              "created_utc": "2026-02-26 18:02:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7cvbxw",
          "author": "SvenVargHimmel",
          "text": "This looks so much better than the vibecoded slop people have thrown over the fence lately. This code base actually has tests in it.\n\nHere's a tip, the UI looks vibe coded.  I strongly suspect that you leaned on AI for that part. Use the frontend skill from Anthropic, it helps with some of the lazy choices that Gemini,Oput , GPT 5.3 tend to make. \n\nAlso a \"getting started\" section  that gets the user from zero-to-hero will go a long way. ",
          "score": 2,
          "created_utc": "2026-02-25 17:08:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7deq7i",
              "author": "error_alex",
              "text": "Thanks! That really means a lot.\n\nI‚Äôm actually a system development student, so I built this on the side specifically to apply what I‚Äôve been learning in class (hence the tests and structure!).\n\nYou totally called it on the UI‚Äîthis is my first ever project with Vue, so I definitely leaned on AI to help get the frontend off the ground. I‚Äôll check out that Anthropic skill, thanks for the tip! A \"Zero-to-Hero\" guide is a great idea, I'll add that to the roadmap.",
              "score": 3,
              "created_utc": "2026-02-25 18:35:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7dgt6v",
          "author": "Erasmion",
          "text": "keeps getting better - metadata-ai-toolbox-latent-viewer!  best of the bunch.  thank you",
          "score": 2,
          "created_utc": "2026-02-25 18:44:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7dgz3b",
              "author": "error_alex",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2026-02-25 18:45:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7dmjvi",
          "author": "teadog24",
          "text": "Would you consider adding a feature to include custom \"metadata\" in the form of a comment or note? Nano banana doesn't include metadata with the prompt. It would be great to have everything in one place and not rely on Google Sheets.",
          "score": 2,
          "created_utc": "2026-02-25 19:10:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7dms1y",
              "author": "error_alex",
              "text": "That is a great idea! I will add it to the road map.",
              "score": 2,
              "created_utc": "2026-02-25 19:12:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7cyqmk",
          "author": "Justify_87",
          "text": "Does it do image to image compare? Even when zoomed in?",
          "score": 1,
          "created_utc": "2026-02-25 17:23:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7cyvsk",
              "author": "error_alex",
              "text": "Yes it does!",
              "score": 1,
              "created_utc": "2026-02-25 17:24:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7d08u8",
          "author": "the_bollo",
          "text": "Does this support things like filtering a library of images/videos to show just those that used a certain LoRA?",
          "score": 1,
          "created_utc": "2026-02-25 17:30:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7d0tmk",
              "author": "error_alex",
              "text": "Yes it does! You can quickly select a LoRA and filter by it. And you can also make custom Collections with certain filters that will auto-populate with images matching the filters and future images will be added as well. Images only at this moment.",
              "score": 2,
              "created_utc": "2026-02-25 17:33:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7d1y0p",
                  "author": "the_bollo",
                  "text": "I just went to install it on windows - why is it requesting a firewall exception on first run?",
                  "score": 1,
                  "created_utc": "2026-02-25 17:38:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7d18mh",
          "author": "ignorethecirclejerk",
          "text": "Thanks to the OP for creating this, certainly a lot of people could use this tool.\n\n\\-EDITED- I'm assuming this runs entirely locally?",
          "score": 1,
          "created_utc": "2026-02-25 17:35:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7d2g0u",
              "author": "error_alex",
              "text": "Thanks for the kind words!\n\nNo, I have never had \"telemetry\" or any issues like that. It has always been private and local. This is the 4th iteration of this application, and the second one that I've released.\n\nThe first released one is the one I mention in the original release post (link in this post above) which was named \"Metadata Viewer\".",
              "score": 2,
              "created_utc": "2026-02-25 17:40:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7e73ex",
          "author": "VirusCharacter",
          "text": "Downloading....",
          "score": 1,
          "created_utc": "2026-02-25 20:46:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ez2d2",
          "author": "sixstringnerd",
          "text": "Overall, I like it, but would it be possible to add directories or pin directories instead of just defaulting to \"This PC\" and everything under it? My output directories are in a couple of places and at least one is 7 levels down. I don't need/want every directory on my computer to be part of this.\n\nThanks!",
          "score": 1,
          "created_utc": "2026-02-25 23:00:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7hgjqi",
              "author": "error_alex",
              "text": "You can right-click a folder in the Folder tree to pin it!",
              "score": 2,
              "created_utc": "2026-02-26 08:58:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7jlss3",
                  "author": "sixstringnerd",
                  "text": "Thanks! I see that now. I could have sworn I tried, but obviously not.",
                  "score": 1,
                  "created_utc": "2026-02-26 17:02:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7g86eo",
          "author": "Space_Objective",
          "text": "https://preview.redd.it/t480q0klarlg1.png?width=1795&format=png&auto=webp&s=a4cdc615caa46f4d4d94dec6894257251efde030\n\n like this?",
          "score": 1,
          "created_utc": "2026-02-26 03:13:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7g8740",
          "author": "StuccoGecko",
          "text": "waxy skin, yummmm",
          "score": 1,
          "created_utc": "2026-02-26 03:13:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7i4jch",
          "author": "wam_bam_mam",
          "text": "Can this parse invoke and comfy ui meta data. The previous one can do comfy but not income which is a problem for me",
          "score": 1,
          "created_utc": "2026-02-26 12:27:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ifn2r",
              "author": "error_alex",
              "text": "It should! If it is failing to parse your Invoke metadata, I would deeply appreciate it if you could open an issue on the Github with one of the images attached and/or the raw metadata. Thank you!",
              "score": 1,
              "created_utc": "2026-02-26 13:36:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7igytz",
                  "author": "wam_bam_mam",
                  "text": "I will do so",
                  "score": 1,
                  "created_utc": "2026-02-26 13:43:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7rdbph",
          "author": "DawaForensics",
          "text": "The application is not Supported on Mac Intel machines, OS says DMG is not supported.  \nPlease add support for Intel mac !",
          "score": 1,
          "created_utc": "2026-02-27 20:07:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7rdk4e",
              "author": "error_alex",
              "text": "Have you tried the workaround for macOS mentioned in the Readme?",
              "score": 2,
              "created_utc": "2026-02-27 20:08:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7rf18n",
                  "author": "DawaForensics",
                  "text": "I did and it wont launch, but I download the Source Code and I am going to try and compile and run it here. Well done on making it, !!!  its very impressive !\n\n",
                  "score": 2,
                  "created_utc": "2026-02-27 20:15:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7sqe7k",
          "author": "tommyjohn81",
          "text": "How does it compare to Image Metahub which seems to do the same thing and also open-source?\n\nhttps://github.com/LuqP2/Image-MetaHub",
          "score": 1,
          "created_utc": "2026-02-28 00:28:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7fdwe6",
          "author": "VRAMFucker",
          "text": "Im using Stability Matrix is something like that? can I Generate inside the app?",
          "score": 0,
          "created_utc": "2026-02-26 00:22:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7jypvt",
              "author": "error_alex",
              "text": "This application is not for generating images, but instead for organizing your generated images into collections, compare and search for prompts or models you've used.\n\nIt should be compatible with Metadata from Stability Matrix.",
              "score": 2,
              "created_utc": "2026-02-26 18:01:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rdgeam",
      "title": "Wan 2.2 Video Reasoning Model (Apache 2.0)",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1rdgeam/wan_22_video_reasoning_model_apache_20/",
      "author": "LowYak7176",
      "created_utc": "2026-02-24 13:35:26",
      "score": 200,
      "num_comments": 74,
      "upvote_ratio": 0.99,
      "text": "[https://huggingface.co/Video-Reason/VBVR-Wan2.2](https://huggingface.co/Video-Reason/VBVR-Wan2.2)  \n[https://huggingface.co/Kijai/WanVideo\\_comfy/tree/main/LoRAs/VBVR](https://huggingface.co/Kijai/WanVideo_comfy/tree/main/LoRAs/VBVR)  \n[https://video-reason.com/](https://video-reason.com/)  \nBenji AI Playground explaining it:  \n[https://www.youtube.com/watch?v=kFgU0tgYUl8](https://www.youtube.com/watch?v=kFgU0tgYUl8)",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rdgeam/wan_22_video_reasoning_model_apache_20/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "o74tudo",
          "author": "martinerous",
          "text": "Interesting stuff. I wish there was also an LTX2 reasoning LoRA. It needs reasoning improvement so badly. Wan2.2 is better by default already.\n\nHowever, their demo website examples are too abstract - only diagrams and drawings. No good tests to see how it affects real-life awareness (walking through doors, putting on clothes etc.)",
          "score": 40,
          "created_utc": "2026-02-24 13:38:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o762i60",
              "author": "Eisegetical",
              "text": "![gif](giphy|e87a8PIiFU03nleRsz)\n\n\"pulling on clothes\" ",
              "score": 54,
              "created_utc": "2026-02-24 17:12:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o76pb1r",
                  "author": "No_Boysenberry4825",
                  "text": "https://www.theguardian.com/politics/shortcuts/2017/jun/27/whats-in-a-wink-lessons-from-clinton-corbyn-and-rihanna#img-3",
                  "score": -5,
                  "created_utc": "2026-02-24 18:54:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o760msx",
              "author": "Dzugavili",
              "text": "Yeah, LTX has fantastic motion and the quality is stellar; but you need to prompt the hell out of it and it will begin to blend actions together if you need a complex sequence. Reducing the prompt load with internal reasoning could be the key to solving a lot of LTX's misfires.\n\nThe WAN base model seems to have a greater understanding of scenario, where as LTX seems to have been trained on actions. But that also means it tends to tunnel to solutions more aggressively, which this lora hopes to fix.",
              "score": 2,
              "created_utc": "2026-02-24 17:04:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o77gg15",
                  "author": "deadsoulinside",
                  "text": "> Yeah, LTX has fantastic motion and the quality is stellar; but you need to prompt the hell out of it and it will begin to blend actions together if you need a complex sequence. \n\nI need to figure out that kungfu then. Seems I cannot have camera rotation or human rotation without it blending across things.",
                  "score": 3,
                  "created_utc": "2026-02-24 20:59:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7aep2g",
              "author": "Infninfn",
              "text": "It's specifically for screen display awareness in 2d. ",
              "score": 1,
              "created_utc": "2026-02-25 07:30:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o771cwg",
          "author": "Cultural-Team9235",
          "text": "Didn't test it thoroughly but it's definitely smarter, it seems to understand the consequences of the actions better, even with a small prompt.\n\nI had a picture of someone on the couch, with a cup of coffee in front of her on a news paper. My prompt was to pick it us as the coffee fell over. Without reasoning the spoon on the table was stuck to the paper, with reasoning it fell off the paper. \n\nSmall stuff but very cool to see these kind of improvements are possible. Just wow. I'm very curious where it leads from here. ",
          "score": 6,
          "created_utc": "2026-02-24 19:49:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77hues",
              "author": "Cultural-Team9235",
              "text": "A few tests later... Sometimes it's get better, sometimes it gets worse with reasoning. Will test more, fun stuff!",
              "score": 3,
              "created_utc": "2026-02-24 21:06:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o758agm",
          "author": "kkb294",
          "text": "Can someone ELI5.?",
          "score": 13,
          "created_utc": "2026-02-24 14:54:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75faae",
              "author": "YeahlDid",
              "text": "Smart people make video moving better maybe.",
              "score": 33,
              "created_utc": "2026-02-24 15:27:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o76yguh",
                  "author": "alb5357",
                  "text": "Nice so is wan better than ltx again?",
                  "score": 1,
                  "created_utc": "2026-02-24 19:36:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o764kzg",
              "author": "tankdoom",
              "text": "A first frame last frame video model that takes an input and expected result. The video output attempts to obey physics and follow logical rules to get to the desired output. \n\nIt seems potentially like it was trained on simple logic puzzles. But the model could help generate outputs that better obey the laws of physics. \n\nFor instance, you might say ‚Äúsolve the maze‚Äù with a first and last frame. One where the maze is unsolved and another where the maze is solved. And the video will show the correct path through the maze.",
              "score": 12,
              "created_utc": "2026-02-24 17:22:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o752rvw",
          "author": "tcdoey",
          "text": "That 'person' in the corner, and the not good AI voice.\n\nI don't get it, why do that? It just makes the whole video, which was interesting, instead really hard to watch. It kind of made me nauseous.",
          "score": 11,
          "created_utc": "2026-02-24 14:26:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o757jy9",
              "author": "ThatsALovelyShirt",
              "text": "Pretty sure they guy is 'real', but they don't speak english, so they used one of those (bad) AI translating/dubbing services or models to convert their speech into english.",
              "score": 3,
              "created_utc": "2026-02-24 14:50:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o75ar1g",
                  "author": "Famous-Sport7862",
                  "text": "Benji  is Chinese, he doesn't speak English, that's why the ai voice. But his videos are really good. And that person is not him, that's just an avatar, he uses different avatar in other videos",
                  "score": 15,
                  "created_utc": "2026-02-24 15:06:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o75vgr2",
                  "author": "Timboman2000",
                  "text": "I'd kind of just prefer text on the screen over the AI dubbed voice and fake avatar in the corner, it basically made me close the video after listening to it for 10 seconds.",
                  "score": 3,
                  "created_utc": "2026-02-24 16:41:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o75cbbi",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 1,
                  "created_utc": "2026-02-24 15:13:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o75zoqg",
                  "author": "Grand0rk",
                  "text": "Which is ironic. Using shit AI voice on video about AI Video.",
                  "score": 1,
                  "created_utc": "2026-02-24 16:59:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o77l2ql",
              "author": "terrariyum",
              "text": "agree, but youtube algo demand face.  creators gotta do what they gotta do",
              "score": 1,
              "created_utc": "2026-02-24 21:20:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o78rpcm",
                  "author": "tcdoey",
                  "text": "Thanks, didn't know that.",
                  "score": 2,
                  "created_utc": "2026-02-25 00:59:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o77thzd",
          "author": "cavaliersolitaire",
          "text": "Benji DO NOT use the ai avatar",
          "score": 3,
          "created_utc": "2026-02-24 21:59:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7846dd",
          "author": "MartinByde",
          "text": "Can I run it in a 4080? \nAnd can it make porn?",
          "score": 3,
          "created_utc": "2026-02-24 22:52:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74wmu1",
          "author": "Time-Teaching1926",
          "text": "Genuine question, could we get a LORA like this but for image models like Z image, Flux and Anima and Illustrious... And would it even work?\n\nLooks really interesting.",
          "score": 6,
          "created_utc": "2026-02-24 13:53:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76q2w3",
              "author": "Tyler_Zoro",
              "text": "> could we get a LORA like this\n\nYou can't implement reasoning capabilities as a LoRA.",
              "score": 2,
              "created_utc": "2026-02-24 18:57:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o773n6j",
                  "author": "JazzlikeLeave5530",
                  "text": "https://www.reddit.com/r/StableDiffusion/comments/1rdkr3n/kijais_lora_for_wan22_video_reasoning_model\n\nü§î",
                  "score": 4,
                  "created_utc": "2026-02-24 19:59:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o75zklt",
              "author": "COMPLOGICGADH",
              "text": "It's a ongoing research field and experimental,few latest examples of new local image models are omnigen2 and deepgen1 (high experimental 5B model),lora is most likely not possible to achieve this it is it's own diffrent architecture...",
              "score": 1,
              "created_utc": "2026-02-24 16:59:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o765019",
          "author": "broadwayallday",
          "text": "Wow at all these noobs complaining about Benji who has been a mainstay in learning this stuff for years now. Lame",
          "score": 7,
          "created_utc": "2026-02-24 17:23:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75v0tj",
          "author": "Justify_87",
          "text": "[https://huggingface.co/Kijai/WanVideo\\_comfy/tree/main/LoRAs/VBVR](https://huggingface.co/Kijai/WanVideo_comfy/tree/main/LoRAs/VBVR)",
          "score": 4,
          "created_utc": "2026-02-24 16:39:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7657ru",
              "author": "LowYak7176",
              "text": "Thanks, added it to the main body ",
              "score": 1,
              "created_utc": "2026-02-24 17:24:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o754crl",
          "author": "pmp22",
          "text": "Very cool! Visual reasoning and world models were both big advancements, this feels like a logical direction to go. At some point, surely, all modalities will converge.",
          "score": 3,
          "created_utc": "2026-02-24 14:34:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74ym80",
          "author": "Dzugavili",
          "text": "The AI guy in the bottom right is a hat-on-a-hat.",
          "score": 3,
          "created_utc": "2026-02-24 14:04:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o764v17",
          "author": "Grand0rk",
          "text": "So... Is this better than default Wan 2.2?",
          "score": 2,
          "created_utc": "2026-02-24 17:23:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7554l0",
          "author": "Violent_Walrus",
          "text": "TIL to never try to watch another video from Benji‚Äôs AI Playground.",
          "score": 2,
          "created_utc": "2026-02-24 14:38:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74zov2",
          "author": "Dirty_Dragons",
          "text": "What I really want is for the first frame last frame model to determine when a change isn't important and just gloss over it.\n\nRight now if a bedroom scene has a lamp on a nightstand on the last frame and it's not there on the first, the model will go as far as generating a random person to walk into the room and place a lamp down and then leave. Or if the wall color is different, it will have somebody throw paint. I've seen the weirdest reasons to justify a minor change I just don't care about.",
          "score": 2,
          "created_utc": "2026-02-24 14:10:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7541a7",
              "author": "altoiddealer",
              "text": "Could probably avoid these things by just prompting a bit better like, the camera pans right revealing lamp on dresser etc",
              "score": 2,
              "created_utc": "2026-02-24 14:32:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o754nf8",
                  "author": "Dirty_Dragons",
                  "text": "The thing is I don't care about the lamp. I wasn't even aware of it's existence until Wan made it dramatically appear.",
                  "score": 3,
                  "created_utc": "2026-02-24 14:36:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o77ud5r",
          "author": "EternalBidoof",
          "text": "So does this only work with FFLF? I never use last frame in my workflows, I like to start with a single frame and let the AI do what it will with the prompt. Will this lora have any effect without a last frame?",
          "score": 1,
          "created_utc": "2026-02-24 22:03:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7cglxt",
          "author": "MahaVakyas001",
          "text": "how do we use this in ComfyUI? Just download the LoRA? can it do I2V properly?",
          "score": 1,
          "created_utc": "2026-02-25 16:01:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7609w8",
          "author": "Valtared",
          "text": "So does it have practical use for us in comfyUI workflows ? If I add the high Lora to my wf it will get better results ? Only in FL2LF ?",
          "score": 1,
          "created_utc": "2026-02-24 17:02:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77aj0s",
              "author": "Front_Eagle739",
              "text": "Seems to give me better prompt adherence in wan t2i, t2v and i2v without a last frame. Just add the Kijai lora to the high noise side, maybe increase the high steps and see what happens",
              "score": 1,
              "created_utc": "2026-02-24 20:32:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o760lg6",
          "author": "Odd-Mirror-2412",
          "text": "It's interesting!",
          "score": 1,
          "created_utc": "2026-02-24 17:03:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o761734",
          "author": "z3rO_1",
          "text": "Is there a not huggingface link to this? I want to try it, but huggingface is the Cruelty Squad of AI, and it isn't on CivitAI, yet.",
          "score": 1,
          "created_utc": "2026-02-24 17:06:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o76xndl",
              "author": "Toclick",
              "text": ">huggingface is the Cruelty Squad of AI,\n\nWhy?",
              "score": 2,
              "created_utc": "2026-02-24 19:32:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o779rpj",
                  "author": "z3rO_1",
                  "text": "It is incomprehensible to anyone who isn't \"in the club\" already.",
                  "score": 0,
                  "created_utc": "2026-02-24 20:28:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o75jz1f",
          "author": "GifCo_2",
          "text": "a Lora can not add reasoning to a non reasoning model. This seems stupid",
          "score": -2,
          "created_utc": "2026-02-24 15:49:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77levt",
              "author": "terrariyum",
              "text": "Are you sure that you're smarter than all of these actual scientists?\n\nMaijunxian Wang, Ruisi Wang, Juyi Lin, Ran Ji, Thadd√§us Wiedemer, Qingying Gao, Dezhi Luo, Yaoyao Qian, Lianyu Huang, Zelong Hong, Jiahui Ge, Qianli Ma, Hang He, Yifan Zhou, Lingzi Guo, Lantao Mei, Jiachen Li, Hanwen Xing, Tianqi Zhao, Fengyuan Yu, Weihang Xiao, Yizheng Jiao, Jianheng Hou, Danyang Zhang, Pengcheng Xu, Boyang Zhong, Zehong Zhao, Gaoyun Fang, John Kitaoka, Yile Xu, Hua Xu, Kenton Blacutt, Tin Nguyen, Siyuan Song, Haoran Sun, Shaoyue Wen, Linyang He, Runming Wang, Yanzhi Wang, Mengyue Yang, Ziqiao Ma, Rapha√´l Milli√®re, Freda Shi, Nuno Vasconcelos, Daniel Khashabi, Alan Yuille, Yilun Du, Ziming Liu, Bo Li, Dahua Lin, Ziwei Liu, Vikash Kumar, Yijiang Li, Lei Yang, Zhongang Cai, Hokin Deng",
              "score": 17,
              "created_utc": "2026-02-24 21:22:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o780ilb",
                  "author": "GifCo_2",
                  "text": "Did you read the paper those names are attached to?",
                  "score": 1,
                  "created_utc": "2026-02-24 22:33:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7507w0",
          "author": "repezdem",
          "text": "Ugh we cant even get a video of a human being explaining this? I can't handle the fake dude in the corner with the horrible AI voice.",
          "score": -7,
          "created_utc": "2026-02-24 14:13:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75ib7s",
              "author": "Choowkee",
              "text": "There are two websites linked explaining the concept. Reading is really not that hard.",
              "score": 5,
              "created_utc": "2026-02-24 15:41:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o754gnr",
              "author": "klop2031",
              "text": "Yeah that voice made me turn it off. Also they should write more on their organization card",
              "score": 0,
              "created_utc": "2026-02-24 14:35:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7625bf",
              "author": "Naive-Kick-9765",
              "text": "Ask your mama.",
              "score": -1,
              "created_utc": "2026-02-24 17:10:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o75735o",
          "author": "tcdoey",
          "text": "Test comment, something's not working on my reddit.\n\nAlso couldn't stand watching that video, it was interesting stuff, but that AI person made me feel nauseous.",
          "score": -1,
          "created_utc": "2026-02-24 14:48:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o769uxr",
          "author": "hidden2u",
          "text": "interested to see how this turns out, but I Iike that their VBVR model is top ranked in their own VBVR benchmark lmao",
          "score": 0,
          "created_utc": "2026-02-24 17:46:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1re4rp8",
      "title": "Last week in Image & Video Generation",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1re4rp8/last_week_in_image_video_generation/",
      "author": "Vast_Yak_4147",
      "created_utc": "2026-02-25 05:39:40",
      "score": 196,
      "num_comments": 14,
      "upvote_ratio": 0.99,
      "text": "I curate a weekly multimodal AI roundup,¬†here are the open-source image & video highlights from last week(a day late but still good):\n\n**BiTDance - 14B Autoregressive Image Model**\n\n* A 14B parameter autoregressive image generation model.\n* [Hugging Face](https://huggingface.co/shallowdream204/BitDance-14B-16x/tree/main)\n\nhttps://preview.redd.it/8snkdmimtklg1.png?width=2500&format=png&auto=webp&s=53636075d9f8232ab06b54e085c6392b81c82e7e\n\nhttps://preview.redd.it/grmzd9hltklg1.png?width=5209&format=png&auto=webp&s=8a68e7aa408dfa2a9bfe752c0f2457ec2c364269\n\n**LTX-2 Inpaint - Custom Crop and Stitch Node**\n\n* New node from jordek that simplifies the inpainting workflow for LTX-2 video, making it easier to fix specific regions in a generated clip.\n* [Pos](https://www.reddit.com/r/StableDiffusion/comments/1r6s2f7/ltx2_inpaint_update_new_custom_crop_and_stitch/)t\n\nhttps://reddit.com/link/1re4rp8/video/5u115igwuklg1/player\n\n**LoRA Forensic Copycat Detector**\n\n* JackFry22 updated their LoRA analysis tool with forensic detection to identify model copies.\n* [Post](https://www.reddit.com/r/StableDiffusion/comments/1r8clyn/i_updated_my_lora_analysis_tool_with_a_forensic/)\n\nhttps://preview.redd.it/x17l4hrmuklg1.png?width=1080&format=png&auto=webp&s=aa99fe291d683d848eaff85943d2d9086cc7bbaf\n\n**ZIB vs ZIT vs Flux 2 Klein - Side-by-Side Comparison**\n\n* Both-Rub5248 ran a direct comparison of three current models. Worth reading before you decide what to run next.\n* [Post](https://www.reddit.com/r/StableDiffusion/comments/1rboeta/zib_vs_zit_vs_flux_2_klein/)\n\nhttps://preview.redd.it/iwqpwnbluklg1.png?width=1080&format=png&auto=webp&s=f362ed3d469cfe7d8ad0c5c1e8ff4a451dc17ec7\n\n**AudioX - Open Research: Anything-to-Audio**\n\n* Unified model that generates audio from any input modality: text, video, image, or existing audio.\n* Full paper and project demo available.\n* [Project Page](https://zeyuet.github.io/AudioX/)\n\nhttps://reddit.com/link/1re4rp8/video/53lw9bdjuklg1/player\n\n# Honorable mention:\n\n**DreamDojo - Open-Source Robot World Model (NVIDIA)**\n\n* NVIDIA released this open-source world model that takes motor controls and generates the corresponding visual output.\n* Robots practice tasks in a simulated visual environment before real-world deployment, no physical hardware needed for training.\n* [Project Page](https://dreamdojo-world.github.io)\n\nhttps://reddit.com/link/1re4rp8/video/35ibi7mhvklg1/player\n\n**Vec2Pix - Edit Photos via Vector Shapes(\"Code Coming Soon\")**\n\n* Edit images by manipulating vector shapes instead of working at the pixel level.\n* [Project Page](https://guolanqing.github.io/Vec2Pix/)\n\nhttps://preview.redd.it/iun918s1uklg1.jpg?width=2072&format=pjpg&auto=webp&s=7ddd6061a9c60512a068839df73fd94b53239952\n\nCheckout the¬†[full roundup](https://open.substack.com/pub/thelivingedge/p/last-week-in-multimodal-ai-46-thinking?utm_campaign=post-expanded-share&utm_medium=post%20viewer)¬†for more demos, papers, and resources.",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1re4rp8/last_week_in_image_video_generation/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "o7ak8o3",
          "author": "Gh0stbacks",
          "text": "Will you do this for every week?",
          "score": 12,
          "created_utc": "2026-02-25 08:21:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ba3bl",
              "author": "Vast_Yak_4147",
              "text": "Yep, I usually post these roundups every Monday but was delayed this week. ",
              "score": 26,
              "created_utc": "2026-02-25 12:10:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7eyqhl",
                  "author": "Erasmion",
                  "text": "great read - thank you",
                  "score": 3,
                  "created_utc": "2026-02-25 22:59:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7ajwci",
          "author": "LSI_CZE",
          "text": "Thank's for report",
          "score": 8,
          "created_utc": "2026-02-25 08:18:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7b8xmg",
          "author": "Alisomarc",
          "text": "![gif](giphy|OKvq25SbsTURpQOSWS)\n\nwe need things like that, thankyou",
          "score": 4,
          "created_utc": "2026-02-25 12:01:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7avrkq",
          "author": "Lazy_Lime419",
          "text": "Thank's for report",
          "score": 3,
          "created_utc": "2026-02-25 10:09:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bqpx5",
          "author": "Motor_Mix2389",
          "text": "Very nice work. Keep at it. Always good to have a short summary of the latest and greatest, its all moving so fast, its really hard to keep track of it all.",
          "score": 3,
          "created_utc": "2026-02-25 13:52:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7c58qd",
          "author": "KillerX629",
          "text": "how does BiTDance compare to flux2?",
          "score": 3,
          "created_utc": "2026-02-25 15:07:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ddwwj",
          "author": "ANR2ME",
          "text": "That AudioX looks interesting üòØ unfortunately, the license is for non-commercial only.",
          "score": 3,
          "created_utc": "2026-02-25 18:32:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7c3dad",
          "author": "fluce13",
          "text": "Thank you!",
          "score": 2,
          "created_utc": "2026-02-25 14:58:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7gmbvy",
          "author": "TopTippityTop",
          "text": "Doing God's work here ‚Äî thank you!",
          "score": 2,
          "created_utc": "2026-02-26 04:44:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7i96pw",
          "author": "Hearcharted",
          "text": "**Waiting for AudioX - Anything-to-Audio on ComfyUI / Google Colab...**",
          "score": 2,
          "created_utc": "2026-02-26 12:58:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7k5jgp",
          "author": "lynch1986",
          "text": "noice, thanks.",
          "score": 2,
          "created_utc": "2026-02-26 18:33:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7a6dup",
          "author": "YeahlDid",
          "text": "Interesting stuff!",
          "score": 2,
          "created_utc": "2026-02-25 06:18:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rfijze",
      "title": "Our next open source AI art competition will begin this Sunday; deadline March 31 - you have a month to push yourself + open models to their limits!",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/h3typhohwvlg1",
      "author": "PetersOdyssey",
      "created_utc": "2026-02-26 18:43:39",
      "score": 173,
      "num_comments": 10,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rfijze/our_next_open_source_ai_art_competition_will/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7kdvtv",
          "author": "KayBro",
          "text": "Who needs $50K when you have 10lbs of Tolblerone!? Looking forward to it!",
          "score": 11,
          "created_utc": "2026-02-26 19:11:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ke9vn",
              "author": "PetersOdyssey",
              "text": "This has always been my philosophy and it's served me well",
              "score": 3,
              "created_utc": "2026-02-26 19:13:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7lr1gg",
          "author": "yeahwhynot_",
          "text": "> Community members: Banodoco owners (long-time contributors to the open source AI art community) receive a 3√ó voting multiplier to reward those who've been building this ecosystem\n\nwhat?",
          "score": 3,
          "created_utc": "2026-02-26 23:10:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7lrsuh",
              "author": "PetersOdyssey",
              "text": "What do you mean?",
              "score": 1,
              "created_utc": "2026-02-26 23:15:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7m2jt4",
                  "author": "PetersOdyssey",
                  "text": "Oh, that's poorly phrased!\n\nIt actually means that Banodoco owners get a 3x voting multiplier when voting on entries - not on their entries.\n\nUpdating",
                  "score": 3,
                  "created_utc": "2026-02-27 00:14:26",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7kixy0",
          "author": "Motor_Mix2389",
          "text": "What do themes mean? As in, the movie has to follow a strict theme? Do we have to use ltx or any open model?",
          "score": 1,
          "created_utc": "2026-02-26 19:35:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7kjovr",
              "author": "PetersOdyssey",
              "text": "You can use any open model but there will be themes to direct at a high level what the video should be about",
              "score": 2,
              "created_utc": "2026-02-26 19:39:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7px9mk",
          "author": "halpmeowtbruv",
          "text": "Is there a sign up, or do we just submit on deadline date?",
          "score": 1,
          "created_utc": "2026-02-27 15:58:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rg7cpj",
      "title": "How to make multiple character on same image, but keep this level of accuracy and details?",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/u54ahlr7l1mg1.png",
      "author": "goku58s",
      "created_utc": "2026-02-27 13:56:06",
      "score": 161,
      "num_comments": 118,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Question - Help",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rg7cpj/how_to_make_multiple_character_on_same_image_but/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7pauy8",
          "author": "XpPillow",
          "text": "You are gonna need to do them one by one with inpaint. If you write them in the same prompt they‚Äôd mix up elements and lose details. So basically you need to generate a picture with one girl in it, and re-create the picture partially to get another one.",
          "score": 57,
          "created_utc": "2026-02-27 14:05:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7pxtmp",
              "author": "ayu-ya",
              "text": "You can generate two from the start and then correct the mixed up stuff with the inpaint, too - I found this easier when trying to make images where the characters interact with each other, so I have something with the right poses and composition as a base. I was told to use BREAK between the characters' prompts in the original gen and I have no idea how valid it is, but I didn't have to correct THAT much in the end",
              "score": 20,
              "created_utc": "2026-02-27 16:01:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7r2un1",
                  "author": "Caesar_Blanchard",
                  "text": "It's basically random. See, I've been using Illustrious for years and honestly, BREAK doesn't really help, at least not for the purpose of avoid characters to mingle each other.\n\nWhat I've recently noticed when trying to do 2 or 3 characters from the go, is to avoid over prompting, and if the model knows the characters without LoRa, don't prompt their traits. Name and or franchise is enough, i.e. ‚ÄúMakima (chainsaw man), Power (chainsaw man)‚Äù, no specify ‚Äúred horns‚Äù, because there's a high chance that Makima will also have the horns when that's incorrect.",
                  "score": 10,
                  "created_utc": "2026-02-27 19:15:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7rizjf",
                  "author": "-_Weltschmerz_-",
                  "text": "What's a good inpainting tool for Comfy?",
                  "score": 2,
                  "created_utc": "2026-02-27 20:35:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7rq47x",
                  "author": "soldierswitheggs",
                  "text": "BREAK isn't supported by default in Comfy. There's some nodes from [ComfyUI Prompt Control](https://github.com/asagi4/comfyui-prompt-control) that can enable it. It's definitely useful for keeping disparate elements of the prompt separate.",
                  "score": 1,
                  "created_utc": "2026-02-27 21:11:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7pbcsf",
              "author": "goku58s",
              "text": "I have been reading some about it, but didn't figure it out at all. Also it's not only about a girl, I mean I want to make a picture that can later be photshoped in manga or something like that. But that is less important. I had a workflow with 2 different prompts for 2 characters, but that is not giving me not even slightly close detail to the referenced pic above (example pic, I didn't have any other on hand)",
              "score": 3,
              "created_utc": "2026-02-27 14:08:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7pcc0y",
                  "author": "XpPillow",
                  "text": "well you can try the Qwen Edit workflow which is basically an AI photo editor like a low version of nano-banana. Feed it with 2 pictures of the 2 girls of yours, and then ask the model to \"put them together in one picture\" with whatever pose you want.",
                  "score": 4,
                  "created_utc": "2026-02-27 14:13:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7peeds",
          "author": "Comprehensive-Pea250",
          "text": "You could use the Anima model it does this pretty well",
          "score": 21,
          "created_utc": "2026-02-27 14:24:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7peki1",
              "author": "goku58s",
              "text": "I will sound stupid now... but what is that? I am not some genius for this things and I am honest about it",
              "score": 5,
              "created_utc": "2026-02-27 14:25:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7pi9ev",
                  "author": "Comprehensive-Pea250",
                  "text": "https://huggingface.co/circlestone-labs/Anima it‚Äôs a model sponsored by comfyui that is made for Anime it‚Äôs also on civitai",
                  "score": 19,
                  "created_utc": "2026-02-27 14:45:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7se4cb",
              "author": "Areinu",
              "text": "You're right, Anima does it pretty well, but not perfect.\n\nI love anima and I've been using it basically since it came out, but it still mingles characters up to certain extend. I follow all guidelines on the hugginsface, order of tags, way to describe characters, steps, cfg and so on, and usually results are good...\n\nThat said some traits are \"stronger\" than others and seem to \"leak\" into other characters more than others. For example \"overweight\" seems to make everyone chubbier, even if you used it to describe only one person.\n\nAnd once you go above 3 characters all hell might break loose. \n\nStill... 0-4 rerolls usually gets me results I want (with 2 characters), so it's not bad. \n\nIf you have some tricks or suggestions how to decrease leaking in Anima even more I'd like to hear them!",
              "score": 1,
              "created_utc": "2026-02-27 23:17:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7pl99n",
          "author": "Geritas",
          "text": "I did it with regional prompting on forge ui back in the day, it worked okay, but not 100% of time. Sometimes I had to roll 100s of images before getting exactly what i want in terms of two characters interacting with each other.",
          "score": 8,
          "created_utc": "2026-02-27 15:00:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7pm3sq",
              "author": "goku58s",
              "text": "Oh man... so I shouldn't use a forge, thanks for letting me know",
              "score": -3,
              "created_utc": "2026-02-27 15:04:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7pmg0p",
                  "author": "Geritas",
                  "text": "I didn't mean to say that forge is bad. It is arguably better if you don't need all the control that comfyui gives you, because it is way easier to just start doing shit in Forge, while in comfy simple things take way more time normally.",
                  "score": 8,
                  "created_utc": "2026-02-27 15:06:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7r7wh8",
          "author": "darktaylor93",
          "text": "I believe you're looking for this     \nhttps://github.com/yaoliliu/FreeFuse",
          "score": 5,
          "created_utc": "2026-02-27 19:40:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7r88i6",
              "author": "goku58s",
              "text": "Someone did send me this, but I am not good with making workflows, that is my issue. So I am also looking for a workflow, but thank you as well!",
              "score": 1,
              "created_utc": "2026-02-27 19:41:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7rraso",
                  "author": "Mahtlahtli",
                  "text": "Hey OP is this what you are talking about?\n\nhttps://civitai.com/posts/23735992\n\nI was able to generate different characters on the same single image by using this \"character pack\" lora that someone else made. Unfortunately, I don't really know how they trained this but if you search on CIVITAI \"characters pack\" maybe you will find an anime character that has already been done that you are trying to create yourslef. Also, you should message the creators of these \"character pacts\" and ask them how exactly they were able to train them.\n\nNow of course the downside is that you will only be able to put 2 anime characters into one image if they are from the same character pack (i.e from the same anime/manga/cartoon) so this only is a limited solution to the problem.\n\nhttps://civitai.com/models/1744203?modelVersionId=1974025",
                  "score": 1,
                  "created_utc": "2026-02-27 21:17:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7rptz9",
              "author": "Mahtlahtli",
              "text": "I tried this but it didn't work for me. If anyone else has successfully done so please let me know.",
              "score": 1,
              "created_utc": "2026-02-27 21:10:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7pj19t",
          "author": "Aplakka",
          "text": "I don't think there's any silver bullet, but I've had reasonably good luck with Illustrious based models, though it doesn't work nearly every time. Here is a quick example with Tifa and Aerith, I tried to make something with different expressions and poses per character. I was able to make a few different images with pretty similar style, but looks like I can't attach more than one image per comment.\n\nThe more popular characters the more likely it is that the model will know them well enough, but still it's likely you'll need to create multiple images to get one where most things look good enough. You may still need some inpainting, e.g. eye colors changing is a common issue and often you will get reversed poses or clothes. Forge has the \"variation seed\" option which can be useful if you get something that's pretty close but not quite what you want. ComfyUI most likely has something similar in some suitable node.\n\nI don't know how much effect the BREAK and () have in practice, but at least they make the prompt clearer to me. I use \"Stable Diffusion WebUI Forge - Classic\" so e.g. ComfyUI might not use similar syntax.\n\nmasterpiece, best quality, amazing quality, 4k, very aesthetic, high resolution, ultra-detailed, absurdres, newest, scenery, general,  \n2girls, tifa lockhart and aerith gainsborough, final fantasy, nightclub, looking at each other, side view,  \nBREAK (tifa lockhart, leaning back on wall, mischievous grin)  \nBREAK (aerith gainsborough, pointing at another, pout)  \nBREAK, depth of field, volumetric lighting  \nNegative prompt: modern, recent, old, oldest, cartoon, graphic, text, painting, crayon, graphite, abstract, glitch, deformed, mutated, ugly, disfigured, long body, lowres, bad anatomy, bad hands, missing fingers, extra digits, fewer digits, cropped, very displeasing, (worst quality, bad quality:1.2), bad anatomy, sketch, jpeg artifacts, signature, watermark, username, signature, simple background, conjoined,bad ai-generated  \nSteps: 30, Sampler: Euler a, Schedule type: Simple, CFG scale: 5, Seed: 3762178807, Size: 1024x1024, Model hash: 463eddd5b3, Model: novaAnimeXL\\_ilV160, Denoising strength: 0.2, Clip skip: 2, Hires Module 1: Use same choices, Hires CFG Scale: 4, Hires upscale: 2, Hires steps: 10, Hires upscaler: 4x-AnimeSharp, Version: neo\n\nhttps://preview.redd.it/36ro4sgru1mg1.png?width=2048&format=png&auto=webp&s=2b3405b6f35123b585ea7bb065b97e28209097e1\n\n  \n",
          "score": 10,
          "created_utc": "2026-02-27 14:49:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7pm9kr",
              "author": "Jaune_Anonyme",
              "text": "FYI BREAK does not have the effect you think it has unless you have a regional prompting extension (like https://github.com/Haoming02/sd-forge-couple) \n\nHere is what BREAK does exactly by default without the extension enable (and the default syntax is the same across most forks)\n https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/features#break-keyword\n\n\nIn other words, SD older models (SD 1.x, SDXL) have a limit of ~75 tokens.\nA workaround was implemented to get more tokens in your prompts.\nPass the first chunk (beyond the 75 tokens limits) a second chunk will be created and embedded back into the first one.\n\n\nProblem is, if ever you have a word half assed between the two chunks it could lead to undesired results (or content). So to avoid that happening, you can manually use the syntax BREAK to create manually the cutoff/2nd chunk.\n\n\nOne bad example of undesired content would be, you're prompting some NSFW spicy content, you soon reach the token limit almost creating a 2nd one. And the word falling perfectly between the two chunks is babydoll (a clothing/lingerie). Oops it got cut off as baby/doll. And you're in a bad jailbait surprise if ever your model is dumb enough.\n\nOf course, with more recent models that can handle hundreds of tokens out of the box, the BREAK syntax is totally useless (or detrimental to use).",
              "score": 11,
              "created_utc": "2026-02-27 15:05:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7rzf6m",
                  "author": "KadahCoba",
                  "text": "> FYI BREAK does not have the effect you think it has unless you have a regional prompting extension\n\nI know you are talking about A1111 forks and OP is using ComfyUI, so I'll give some translation.\n\nThe `BREAK` keyword does not work in ComfyUI core conditional processing. A close approximation of `BREAK` with only core nodes would be to use multiple conditional prompts, one for each `BREAK` block, and combine the conds with a cond concat node. The other option is to use a custom cond node that has `BREAK` support.\n\nWhat `BREAK` does is allow you to control where in the prompt the conditioning is wrapped to the next layer. This only applies to models that use CLIP, which has a limit of 77 input tokens (effectively 75 because of start/end tokens). Generally I think the idea was to have complete ideas per CLIP chunk that would become the conditioning.\n\nEmbeddings are/were also a good way to control prompt length, a whole series of tokens can become one set of vectors to save prompt space. There was also magic with embeddings since you can compute those vectors via other means than just combining tokens.\n\nControlling these chunks boundaries and prompt length was more important in SD1 and early SDXL models. By late stage Pony finetunes/merges and modem Illus merges, it has become mostly unnecessary to worry about the 75 token thing. And almosy every model since SDXL (that matters), CLIP stuff is either mostly or entirely a non-factor.",
                  "score": 3,
                  "created_utc": "2026-02-27 21:58:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7pocb2",
                  "author": "Aplakka",
                  "text": "Yeah I know about the 75 token per chunk limit, though I've never really understood what the effect is in practice. It makes sense that there would be issues when words are near the chunk boundary though. With some Pony based models I remember getting really weird results sometimes if the positive and negative prompts didn't have the same amount of chunks.\n\nThanks for the recommendation for the regional prompting, that sounds like a useful plugin. I tried something similar with A1111 ages ago but didn't realize there was something compatible with Forge Classic.",
                  "score": 1,
                  "created_utc": "2026-02-27 15:15:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7pohhk",
                  "author": "x11iyu",
                  "text": "even without regional prompting, tags between chunks wont have attention between them. this in my experience does help with concept bleed somewhat and can serve as a quick and dirty solution in emergencies, though obviously regional prompting of whatever flavor you like is more effective",
                  "score": 1,
                  "created_utc": "2026-02-27 15:16:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7pkstb",
              "author": "NorthernRealmJackal",
              "text": "Just wanted to say thanks for the comprehensive tip! What a great example image - amazing style, really sharp, and no artifacts or \"AI giveaways\".",
              "score": 6,
              "created_utc": "2026-02-27 14:58:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7pmy2c",
                  "author": "Aplakka",
                  "text": "Thanks! Hope it was helpful.",
                  "score": 1,
                  "created_utc": "2026-02-27 15:08:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7qu6ti",
                  "author": "Kazeshiki",
                  "text": "I think the model already have information about Tifa and Aerith already. You can use loras to force the subjects into who you want.",
                  "score": 1,
                  "created_utc": "2026-02-27 18:33:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7putfj",
              "author": "goku58s",
              "text": "Okay, I have read it this time. Unfortunately, BREAK seems to do nothing for me even though I have installed something that should make it work...",
              "score": 2,
              "created_utc": "2026-02-27 15:46:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7pywbs",
                  "author": "Aplakka",
                  "text": "I'm not sure how much effect BREAK has even if it's working, at least Jaune\\_Anomyne claimed it only has effect in very specific cases. Even with it in Forge it's pretty common to get the wrong character doing the thing the other one is supposed to be doing based on the prompt. I think it would require a different base model than Illustrious to get more consistent results.\n\nWith Illustrious your best bet is probably to make a reasonable prompt, generate e.g. 8 images, see if any match the prompt, then adjust the prompt if necessary.",
                  "score": 1,
                  "created_utc": "2026-02-27 16:06:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7pj6vo",
              "author": "goku58s",
              "text": "Ou huge text, reading it as soon as I can. Thanks in advance!",
              "score": 1,
              "created_utc": "2026-02-27 14:49:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7qkrxz",
          "author": "SweetGale",
          "text": "* **Known characters** ‚Äì If it's a character the model knows about or you have a LoRA for each one, Stable Diffusion XL is usually quite good at keeping them apart. If they're your own OCs, then you'll have to train a LoRA for each one.\n* **Inpainting** ‚Äì Create an image with two (or more) generic characters and then use inpainting to replace each one in turn.\n* **Cut and paste** ‚Äì Just generate each character against a simple background, try to make the style and lighting match and then cut them out and edit them together.\n* **Regional prompting** ‚Äì The *Comfy Couple* node for ComfyUI offers an easy way to split an image in two and provide a separate prompt for each half. Just remember that each side can see the whole image. Use \"duo\" in each prompt rather than \"solo\" and try to make the characters as different as possible. (I'm a heavy user of Illustrious-based models and regional prompting myself.)\n* **Newer models** ‚Äì SDXL models like Illustrious are good enough in a lot of situations. But handling multiple characters is one area they're quite bad at. Try the fp8 version of *Z-Image-Turbo*. It has similar system requirements and generation speed as SDXL but handles multiple characters without problems. I can name the characters in my prompt, provide a description for each and then position them relative to each other. Z-Image-Turbo is focused on photo realism though. There are some anime fine-tunes and LoRAs but I haven't spent that much time trying them out yet. *Anima* is a new anime model with relatively low system requirements. From my brief experiments it seems to handle multiple characters quite well. You can also try *Flux*, *Chroma*, *Qwen-Image* or *Flux.2 Klein*. Try quantised versions if your computer can't handle the full models.",
          "score": 5,
          "created_utc": "2026-02-27 17:49:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qnqpl",
              "author": "goku58s",
              "text": "Hi, I have 5070ti so I don't PC will be an issue. Can you maybe share the link towards workflow or something because I am quite big of a noob when it comes to making my own workflow. Anyway, thank you for reply",
              "score": 1,
              "created_utc": "2026-02-27 18:03:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7r4y42",
                  "author": "SweetGale",
                  "text": "I'm also fairly new to ComfyUI. I try to build the simplest workflows I can from scratch in order to learn how it works. Pre-made workflows tend to cover multiple use cases, be over-complicated and be hard to understand. *Comfy Couple* is a very simple node. It sits just before the *KSampler* node. Beyond that, you just need an extra *CLIP Text Encode (Prompt)* node for a total of three: positive\\_1, positive\\_2 and negative. For newer models, it's mostly a matter of figuring out which text encoder and VAE to use.\n\nYou can find the Comfy Couple node and an example workflow on this page: [https://github.com/Danand/ComfyUI-ComfyCouple](https://github.com/Danand/ComfyUI-ComfyCouple)",
                  "score": 1,
                  "created_utc": "2026-02-27 19:25:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7r7q2n",
          "author": "ToasterLoverDeluxe",
          "text": "you can make illustrious create 2 different characters in the same picture with just prompting, no need for any fancy workflows...\n\nhttps://preview.redd.it/z78rrjh2b3mg1.png?width=1200&format=png&auto=webp&s=0d0260841264544cb90c0cbba7ef022ca5522c86\n\n;(Hyuuga\\_Hinata is a woman+(chubby:0.6), Hyuuga\\_Hinata has large\\_breasts+wide\\_hips+black\\_hair+purple\\_eyes, Hyuuga\\_Hinata is wearing high\\_heels+white\\_high\\_heels+suit+mini skirt);\n\n;(Uzumaki\\_Boruto is a boy, Uzumaki\\_Boruto has blonde\\_hair+blue\\_eyes, Uzumaki\\_Boruto is wearing a suit);\n\n;Hyuuga\\_Hinata is at the side of Uzumaki\\_Boruto, office\n\nkeep in mind that some models understand better than others",
          "score": 3,
          "created_utc": "2026-02-27 19:39:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7r81ri",
              "author": "goku58s",
              "text": "Yeah, I believe that checkpoint that I am using is not good with this typenof prompt. Because I always had to use tags for it",
              "score": 1,
              "created_utc": "2026-02-27 19:40:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7rsnta",
                  "author": "ToasterLoverDeluxe",
                  "text": "The \"nova\" models have good adherence to prompts probably the best at that... also do not use lora's if the model already know the characters, also remember that most illustrious models can do several styles, you dont really need a whole model for a style",
                  "score": 1,
                  "created_utc": "2026-02-27 21:24:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7qcgg1",
          "author": "waynenors",
          "text": "Based Kohaku enjoyer",
          "score": 4,
          "created_utc": "2026-02-27 17:09:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qovlb",
              "author": "goku58s",
              "text": "Well I am glad someone likes the image :)",
              "score": 1,
              "created_utc": "2026-02-27 18:08:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7s65j2",
                  "author": "Brigapes",
                  "text": "no worries, you're not alone \n\nshe's top tier",
                  "score": 2,
                  "created_utc": "2026-02-27 22:33:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7q507p",
          "author": "Corgiboom2",
          "text": "I use Regional Prompter with hires.fix, then go into Img2Img for upscale and denoise, then inpaint where needed.",
          "score": 2,
          "created_utc": "2026-02-27 16:35:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qnzvq",
              "author": "goku58s",
              "text": "Yeah, that is the part where I have given up on like 2 workflows, because if I make over 500 images per day, then going through each is just not doable",
              "score": 1,
              "created_utc": "2026-02-27 18:04:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7qzriu",
                  "author": "Corgiboom2",
                  "text": "https://preview.redd.it/u7g66k3843mg1.png?width=1496&format=png&auto=webp&s=adb2b120519bda02a3221f107fccdeb35fb761fe\n\nYou gotta find the few pics you like the most and want to present, and then give those your attention. It is a method I've had quite a bit of success with.",
                  "score": 2,
                  "created_utc": "2026-02-27 19:00:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7qjm2m",
          "author": "featherless_fiend",
          "text": "Using a more intelligent/slower sampler like res_2s and the right amount of steps helps a little.\n\nBasically if two characters have the same face it's an intelligence problem, like having an extra arm or leg. So it does help to cook it a little more.",
          "score": 2,
          "created_utc": "2026-02-27 17:44:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7qpywt",
          "author": "Direct_Effort_4892",
          "text": "Can give [FreeFuse](https://github.com/yaoliliu/FreeFuse) a shot; you'll require each of your characters to have a LoRa though. Can't vouch for its success as haven't tried it myself, but worth a shot nonetheless.",
          "score": 2,
          "created_utc": "2026-02-27 18:14:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qqdwr",
              "author": "goku58s",
              "text": "I will have to see if there are any workflows with this. It looks good on git.\nMaybe if you know of any, I would be grateful. Thanks for this too¬†",
              "score": 2,
              "created_utc": "2026-02-27 18:16:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7qqxm8",
                  "author": "Direct_Effort_4892",
                  "text": "They do seem to have demo comfy workflows in their [repo](https://github.com/yaoliliu/FreeFuse/tree/master/freefuse_comfyui/workflows)\n\nEdit: This link links directly to their workflow directory BTW",
                  "score": 2,
                  "created_utc": "2026-02-27 18:18:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7pstud",
          "author": "truci",
          "text": "You can use the couples setup where you prompt left and right separately. \n\nYou can make them separately then throw them into like flux Kontext to merge them then upscale or resample the result with a medium denoise using your illustrious model. \n\nYou can use anima or z image to get the prompt adherence then feed that back into as latent or upscale with the illustrious again. \n\nMany ways but none are perfect and they all have pro and cons.",
          "score": 1,
          "created_utc": "2026-02-27 15:37:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7pud1x",
              "author": "goku58s",
              "text": "Oh man, as someone who is noob in all of this, I am so confused by all of thisü§Ø",
              "score": 1,
              "created_utc": "2026-02-27 15:44:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7qbht0",
                  "author": "truci",
                  "text": "There is just so much to learn. And being at the cutting edge of all this things change faster than you can keep up. I‚Äôve basically just decided to skip every other major model because it‚Äôs just too much. \n\nFind 1 thing you wana do and study that one thing.",
                  "score": 2,
                  "created_utc": "2026-02-27 17:05:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7pvtqs",
          "author": "woffle39",
          "text": "[https://www.youtube.com/watch?v=Ly6USRwTHe0](https://www.youtube.com/watch?v=Ly6USRwTHe0)",
          "score": 1,
          "created_utc": "2026-02-27 15:51:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7q60h9",
          "author": "seniorfrito",
          "text": "This is something I've thought about on and off since the beginning of Stable Diffusion. But, couldn't you just create LoRA that can handle both of the characters (or more)? Just be very specific about which side of the image each character is on. Essentially create your own dataset initially with inpaint, and have your characters in all sorts of different arrangements and then come out with a LoRA that can just do it without the inpainting?",
          "score": 1,
          "created_utc": "2026-02-27 16:39:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qolok",
              "author": "goku58s",
              "text": "I have tried multiple Loras for that, but none really worked beside one (that one was also relying a lot on luck) and also when you have to include over 100s of characters... making Lora for all of that is... well... you know already¬†",
              "score": 1,
              "created_utc": "2026-02-27 18:07:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7qc3gg",
          "author": "diogovk",
          "text": "In Krita + AI plugin, you can assign prompts that apply to different parts of the image (i.e. prompts associated with image layers).\n\nAnd after upscaling, you can do generations of only part of the image. \n\nIf you're generating part of the image that only includes one character, I still think it's best to *remove* the prompts related to other characters. My experience it's not so much that other regional prompts \"leak\", but that it still affects generation quality.\n\nWithout using those regional prompts, prompts \"leak\" like crazy, so I think it's definitely worth a try.",
          "score": 1,
          "created_utc": "2026-02-27 17:08:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qou3z",
              "author": "goku58s",
              "text": "For me the issue is that I have to make over 500 images per day, so having to upscale each manually is a big pain...",
              "score": 2,
              "created_utc": "2026-02-27 18:08:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7qtbgy",
                  "author": "osirixart",
                  "text": "Why do you have to make so many images and upscale each one? You should just upscale the ones that you know you're going to use/keep.",
                  "score": 2,
                  "created_utc": "2026-02-27 18:29:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7qx7ng",
                  "author": "diogovk",
                  "text": "You could still use Krita, save all images in a directory and then batch-upscale using ComfyUI or a script.\n\nBut the whole point of Krita is that you're trading time for quality/control.\n\nIt's gonna be difficult to make a workflow that generates 500 non-slop images.",
                  "score": 1,
                  "created_utc": "2026-02-27 18:48:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7qene4",
          "author": "Gemaye",
          "text": "You can cheat by creating each character you want with an even coloured (black) background, then create the background you prefer for your final image, then merge the three characters into one image using a graphics editor and then add the created background using qwen image edit or the same graphics editor.  \nFrom then use the edit model to change poses.\n\nEdit: You could use [paint.net](http://paint.net) for merging the images, that is what I use at least.",
          "score": 1,
          "created_utc": "2026-02-27 17:20:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qp276",
              "author": "goku58s",
              "text": "That is the issue for me because I have to make over 500 images per day, feom which like 380 are good, so it's massive pain to do...",
              "score": 1,
              "created_utc": "2026-02-27 18:09:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7qoixw",
          "author": "Maskwi2",
          "text": "Yeah, this has been the major pain for me. I don't know how models like Seedance do it so that they have 2 characters interact with each other like Brad Pitt and Tom Cruise fighting and not have one's face affect the other.¬†",
          "score": 1,
          "created_utc": "2026-02-27 18:07:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qp8t2",
              "author": "goku58s",
              "text": "If only I knew....¬†",
              "score": 1,
              "created_utc": "2026-02-27 18:10:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7r2z47",
          "author": "Caesar_Blanchard",
          "text": "I know it's unrelated but is she from some anime? or she's a character you created?",
          "score": 1,
          "created_utc": "2026-02-27 19:15:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7r3fdg",
              "author": "goku58s",
              "text": "Kohaku from dr stone anime",
              "score": 2,
              "created_utc": "2026-02-27 19:17:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7r4kzs",
          "author": "HashTagSendNudes",
          "text": "Use InvokeAi Regional guidance easy work",
          "score": 1,
          "created_utc": "2026-02-27 19:23:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7r4q5n",
              "author": "goku58s",
              "text": "If you can tell me, what is InvokeAI? I haven't tried it",
              "score": 1,
              "created_utc": "2026-02-27 19:24:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7rarc0",
          "author": "Madlyaza",
          "text": "I would personally just generate them separately completely and then just edit in a photo editing program and cut one into the others. Then use inpaint to work out some rough edges",
          "score": 1,
          "created_utc": "2026-02-27 19:54:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7rf1x5",
          "author": "TekeshiX",
          "text": "Just use the A1111 with the regional prompting extension, the best!",
          "score": 1,
          "created_utc": "2026-02-27 20:15:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7rfkw8",
              "author": "goku58s",
              "text": "I am actually thinking of returning to that one to try it",
              "score": 1,
              "created_utc": "2026-02-27 20:18:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7rftji",
                  "author": "TekeshiX",
                  "text": "Yea, do that. Also inpainting is better sometimes too.",
                  "score": 1,
                  "created_utc": "2026-02-27 20:19:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7rst9x",
          "author": "Goldkoron",
          "text": "You can reliably do 2 characters with no leakage, and sometimes 3 if you have a lot of multi-character images in your training dataset that are consistently captioned eg \"Kohaku and Senku in forest\"\n\nUntrained models are a bit harder to deal with though.",
          "score": 1,
          "created_utc": "2026-02-27 21:24:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7s0183",
              "author": "goku58s",
              "text": "Well, I Don't have all the multi character models for over 200 characters... and more... so yeah, I can't rely on those types of loras",
              "score": 1,
              "created_utc": "2026-02-27 22:01:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7rvbvl",
          "author": "KadahCoba",
          "text": "Use regional prompting.\n\nThere are multiple custom nodes for this, the ones I've run use masks and work in the magical realm of the fuckery that ComfyUI conditionals datatype. ComfyUI core has something similar that also support regional lora application and even more fuckery with conds, but it also increases the timestep (ie. slower gen, by 1.5-2x).\n\nBasics workflow with the ones I've used: Base prompt is for the overall image minus the specifics that will apply only within the regions, like background, overall scene, style, maybe details that apply to all regions within the context of being in the same composition (eg. pose). The masked regions will have additional prompts that essentially layer over the base prompt for that region.  As for where to put the masks, I would either gen most of the combined whole prompt to find a seed with composition I wanted to use, then used that as the input for making the masks, or do a more img2img inputs to the first stage, possibly with control nets.\n\nIt'll work for one-shot gens without having to go full effort inpainting from the start, but a good inpainting on the output of that is still likely going to provide a more preferable result.",
          "score": 1,
          "created_utc": "2026-02-27 21:37:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7s0aoe",
              "author": "goku58s",
              "text": "Do you maybe have the link or something that can show me what it looks like? I have tried regional prompting before, but nothing got this level of quality like on image above.",
              "score": 1,
              "created_utc": "2026-02-27 22:02:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7sj21k",
                  "author": "KadahCoba",
                  "text": "Which did you try?\n\nI'm not in a place right this moment where I can check my old workflows, but I think I was using [A8R8](https://github.com/ramyma/A8R8_ComfyUI_nodes) or some fork of it.\n\nCan you pastebin the workflow for the op image so I can test around with it if I have this weekend?",
                  "score": 1,
                  "created_utc": "2026-02-27 23:46:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7rwhyr",
          "author": "FluidEngine369",
          "text": "I believe if you use the PNG tab drag the image in there and then send all the info and most importantly the original seed into txt2img, you can easily swap out the characters in the prompt and generally keep the same pose and style. But if you change too many of the original parameters like overall image size, the sampler, CFG, then the end result will start to vary.",
          "score": 1,
          "created_utc": "2026-02-27 21:43:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7rxnj4",
          "author": "Sudden_List_2693",
          "text": "Generate image, send to inpaint, loop through all characters, crop them one by one possibly upscaled for the inpaint, automatically tag (if they need lora, it's best in my opinion to trigger the separate lora for each character), let the inpaint do its job on each character separately. ",
          "score": 1,
          "created_utc": "2026-02-27 21:49:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7s0hrx",
              "author": "goku58s",
              "text": "Well unless inpaint is automatic... this is quite much of a labour because I am making over 200-500 images per day....\nFrom which like 380 are what I am using....",
              "score": 1,
              "created_utc": "2026-02-27 22:03:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7sfsax",
                  "author": "Sudden_List_2693",
                  "text": "I meant totally automatic.  \nI can't even imagine inpainting manually unless I'm making something very specific - a very rare case.",
                  "score": 2,
                  "created_utc": "2026-02-27 23:26:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7s8wv4",
          "author": "Expicot",
          "text": "Just wondering... what about using a more 'modern' AI that has stronger prompt adherence. Klein4B for fast iterations by ex. Then finish the image with a img2img with your Illustrious model ? It will take more time for sure but there would be less waste (?).",
          "score": 1,
          "created_utc": "2026-02-27 22:48:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7s94kp",
              "author": "goku58s",
              "text": "Well simple answer is when you make a lot of images in one day, img2img for every and each one is pain... (over 200 images per day...]",
              "score": 1,
              "created_utc": "2026-02-27 22:49:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7sqcjf",
          "author": "Velvet-Vision",
          "text": "The easiest way that i know, u should build simple comfyui workflow with auto detector characters, and do auto inpaint with 0.6-0.9 denoise. And after one more Ksampler to remove artifacts.\nSo u generate just a 2+ persons, with masks inpaint it to characters that u need, and fix light artifacts, and u get good quality images with multichar",
          "score": 1,
          "created_utc": "2026-02-28 00:28:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7st79v",
          "author": "vamprobozombie",
          "text": "I prefer making each one then use QWEN edit to put them all on one image.  I run it with Wan2gp works even with 8GB vram if have enough ram.",
          "score": 1,
          "created_utc": "2026-02-28 00:45:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7t4mz2",
          "author": "tO_ott",
          "text": "Op, when you say illustrio do you mean illustrious?",
          "score": 1,
          "created_utc": "2026-02-28 01:55:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7taexa",
          "author": "coscib",
          "text": "regional prompt and inpainting",
          "score": 1,
          "created_utc": "2026-02-28 02:31:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7q9ygl",
          "author": "Zack_spiral",
          "text": "In my opinion the best and easiest way is to use a high end image editing model like nano banana or qwen image edit but don't forget the rtx to buy",
          "score": -4,
          "created_utc": "2026-02-27 16:58:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7qa6jw",
              "author": "goku58s",
              "text": "When you say rtx to buy, do you Gpu or something else? Because I have 5070ti, so I guess that's not the issue",
              "score": 1,
              "created_utc": "2026-02-27 16:59:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7qck81",
                  "author": "Zack_spiral",
                  "text": "If you say so the best model for you to download I recommend qwen image edit 2511 Q5 good enough for you with maximum image uploading of 3 character if you make it 4k it will be better there is also 2512 but it's larger and requires rtx 5090",
                  "score": 1,
                  "created_utc": "2026-02-27 17:10:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rc56rr",
      "title": "I built and trained a \"drawing to image\" model from scratch that runs fully locally (inference on the client CPU)",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/zrfq6ud7m5lg1",
      "author": "_aminima",
      "created_utc": "2026-02-23 02:24:20",
      "score": 159,
      "num_comments": 15,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rc56rr/i_built_and_trained_a_drawing_to_image_model_from/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6xhx4r",
          "author": "TonyDRFT",
          "text": "Congrats on achieving this! And thank you for sharing, that looks mighty impressive!",
          "score": 10,
          "created_utc": "2026-02-23 10:30:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xzdpu",
              "author": "_aminima",
              "text": "Thanks a lot!",
              "score": 5,
              "created_utc": "2026-02-23 12:53:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wsdbn",
          "author": "Myg0t_0",
          "text": "Didnt nvidia have something like this?",
          "score": 13,
          "created_utc": "2026-02-23 06:26:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x3zvl",
              "author": "_aminima",
              "text": "Yes! Found their research while working on the project (https://arxiv.org/pdf/1903.07291). The core idea is the same but there are some implementation differences (they use a GAN architecture while I use a DiT, we incorporate the segmentation map conditioning differently, etc.)",
              "score": 10,
              "created_utc": "2026-02-23 08:13:53",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6wyva7",
              "author": "Obvious_Set5239",
              "text": "There were a lot of similar models. I remember even was controlnet for sd1.5 or sdxl doing the same",
              "score": 2,
              "created_utc": "2026-02-23 07:25:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6x55qv",
                  "author": "_aminima",
                  "text": "Indeed and they're probably better in terms of image quality. I guess the difference here is that the model is tiny compared to sd models (easily runs on CPU) and was trained from scratch on a consumer GPU",
                  "score": 9,
                  "created_utc": "2026-02-23 08:25:23",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6z8sxc",
          "author": "[deleted]",
          "text": "Very nice project indeed.\n\nIt's a good idea to read AI papers, because thats how the tech evolves and new inventions are made.",
          "score": 3,
          "created_utc": "2026-02-23 16:51:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o79g5rd",
              "author": "_aminima",
              "text": "thank you :)",
              "score": 2,
              "created_utc": "2026-02-25 03:17:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o73eit6",
          "author": "Green-Ad-3964",
          "text": "Kudos to you for this great little project. Incredibile that it's developed by one man only on a consumer (not even top tier) hw.",
          "score": 3,
          "created_utc": "2026-02-24 06:36:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o79g0gf",
              "author": "_aminima",
              "text": "thanks for the kind words!",
              "score": 1,
              "created_utc": "2026-02-25 03:16:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o70pxt5",
          "author": "Certain-Cod-1404",
          "text": "really cool project man, good job!",
          "score": 2,
          "created_utc": "2026-02-23 20:58:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o79fvmv",
              "author": "_aminima",
              "text": "thanks!",
              "score": 1,
              "created_utc": "2026-02-25 03:16:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6y7wpj",
          "author": "LyriWinters",
          "text": "Very impressive.  \nNot sure how useful it is but very impressive. Great project to learn how to copy papers which is by far not the easiest thing to do.",
          "score": 1,
          "created_utc": "2026-02-23 13:46:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o719ecm",
              "author": "Historical-Doubt7584",
              "text": "This is super useful for prototyping UI from low fidelity to a possible product in real time. Figma would want to have a chat with OP",
              "score": 2,
              "created_utc": "2026-02-23 22:35:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o79jgqk",
              "author": "_aminima",
              "text": "Thanks! Yeah, I mainly did it out of curiosity (and to learn), and its current value is limited, but I think small on-device generative models are very promising (think real-time use cases like live prototyping or planning with a world model)",
              "score": 1,
              "created_utc": "2026-02-25 03:37:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rdkr3n",
      "title": "Kijai's LoRA for WAN2.2 Video Reasoning Model",
      "subreddit": "StableDiffusion",
      "url": "https://huggingface.co/Kijai/WanVideo_comfy/tree/main/LoRAs/VBVR",
      "author": "switch2stock",
      "created_utc": "2026-02-24 16:23:06",
      "score": 146,
      "num_comments": 28,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rdkr3n/kijais_lora_for_wan22_video_reasoning_model/",
      "domain": "huggingface.co",
      "is_self": false,
      "comments": [
        {
          "id": "o75ukvi",
          "author": "Cequejedisestvrai",
          "text": "Can someone explain what is does? ELI5?",
          "score": 25,
          "created_utc": "2026-02-24 16:37:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75vsr4",
              "author": "Dzugavili",
              "text": "https://www.reddit.com/r/StableDiffusion/comments/1rdgeam/wan_22_video_reasoning_model_apache_20/\n\nI believe the concept is that you can get far greater prompt compliance: you won't need to be as specific, it will begin to look inside the generation for solutions.\n\nEdit:\n\nDoing some same-seed testing, I'm getting very promising results. Very subtle changes in motion, but it seems to be following my prompts more.\n\nI'm going to try adding this to my SVI workflow, see how it does there.",
              "score": 16,
              "created_utc": "2026-02-24 16:42:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o768yuy",
                  "author": "bigman11",
                  "text": "What a fascinating concept that I don't understand at all.",
                  "score": 23,
                  "created_utc": "2026-02-24 17:42:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7af7y1",
                  "author": "xb1n0ry",
                  "text": "It was trained on IQ-Test-like data. How can it potentially affect human motion?",
                  "score": 1,
                  "created_utc": "2026-02-25 07:35:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7bkg2p",
                  "author": "switch2stock",
                  "text": "Cool. Keep us posted on the results.",
                  "score": 1,
                  "created_utc": "2026-02-25 13:17:28",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o763wzh",
          "author": "Derispan",
          "text": "Any one have comparision video?",
          "score": 5,
          "created_utc": "2026-02-24 17:19:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7b07nm",
              "author": "Tremolo28",
              "text": "Used the Lora together with Wan smoothmix model on this 20sec clip. First half of the clip has the Lora applied, 2nd half without the Lora. [https://civitai.com/images/122286483](https://civitai.com/images/122286483)",
              "score": 4,
              "created_utc": "2026-02-25 10:50:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7de8o0",
                  "author": "BigFuckingStonk",
                  "text": "Could you please share your workflow and gpu as well as rendering time? I'm getting weird results on my side ..",
                  "score": 0,
                  "created_utc": "2026-02-25 18:33:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o79s5w2",
          "author": "Ok-Prize-7458",
          "text": "Looks promising, I hope LTX2 gets its own lora, thats been my daily driver as ive left wan behind.",
          "score": 7,
          "created_utc": "2026-02-25 04:32:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76kxkd",
          "author": "Consistent-Mastodon",
          "text": "Is it high noise only?",
          "score": 2,
          "created_utc": "2026-02-24 18:35:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77gevl",
              "author": "Life_Yesterday_5529",
              "text": "Yes. Only the structure of the video needs reasoning.",
              "score": 2,
              "created_utc": "2026-02-24 20:59:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o76fjv5",
          "author": "BiceBolje_",
          "text": "Stupid question maybe, but does it work with lightx2v LORA? \n\nTo be more precise: Does it have any effect on the actual video when using lightx2v?",
          "score": 2,
          "created_utc": "2026-02-24 18:11:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77nolb",
              "author": "terrariyum",
              "text": "In this [vid](https://www.youtube.com/watch?v=kFgU0tgYUl8), they use lightx2v on the high pass.  And it makes sense that full reasoning would only be needed for the movement pass.  However, their results are pretty bad",
              "score": 1,
              "created_utc": "2026-02-24 21:32:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o76irpy",
              "author": "switch2stock",
              "text": "Im new as well, so take it with a grain of salt.\nLightx2v is for speeding up the process right, and this model is for reasoning. So I'm assuming that if the model does not have enough time to reason then the output might not be ideal.",
              "score": 0,
              "created_utc": "2026-02-24 18:25:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7bykaq",
                  "author": "diogodiogogod",
                  "text": "I don't think this is a \"traditional\" thinking. But to be honest, I'm still confused by this.",
                  "score": 0,
                  "created_utc": "2026-02-25 14:34:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7sfl5x",
          "author": "Nikoviking",
          "text": "Is this just a LoRA or do I need a special workflow?",
          "score": 1,
          "created_utc": "2026-02-27 23:25:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbb24f",
      "title": "A single diffusion pass is enough to fool SynthID",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1rbb24f/a_single_diffusion_pass_is_enough_to_fool_synthid/",
      "author": "abajurcu",
      "created_utc": "2026-02-22 03:24:34",
      "score": 141,
      "num_comments": 33,
      "upvote_ratio": 0.95,
      "text": "I've been digging into invisible watermarks, SynthID, StableSignature, TreeRing ‚Äî the stuff baked into pixels by Gemini, DALL-E, etc. Can't see them, can't Photoshop them out, they survive screenshots. Got curious how robust they actually are, so I threw together noai-watermark over a weekend. It runs a watermarked image through a diffusion model and the output looks the same but the watermark is gone. A single pass at low strength fools SynthID. There's also a CtrlRegen mode for higher quality. Strips all AI metadata too.\n\nMostly built this for research and education, wanted to understand how these systems work under the hood. Open source if anyone wants to poke around.\n\ngithub: [https://github.com/mertizci/noai-watermark](https://github.com/mertizci/noai-watermark)",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rbb24f/a_single_diffusion_pass_is_enough_to_fool_synthid/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "o6qvias",
          "author": "Mid-Pri6170",
          "text": "the guy who tricks old people on facebook a few weeks ago: 'darn it, people know im using AI!'\n\nthe same guy today: 'check out this statue of jesus made by frogs'",
          "score": 12,
          "created_utc": "2026-02-22 09:28:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pr7h3",
          "author": "akindofuser",
          "text": "I'm kind of OK with watermarks. Actually think its a smart idea. But as OP has shown easy to remove. Wish there was someway to enforce it. \n\nRight now the internet and world are all upset about AI pulling out the pitchforks with AI posts. That won't last. Diffusion models and AI is here to stay. Once it becomes more widely accepted we'll all wish there was a way to sign AI stuff so that it is known and obvious.",
          "score": 31,
          "created_utc": "2026-02-22 03:43:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6q9sll",
              "author": "Same-Pizza-6724",
              "text": "Another problem with watermarking is that it's probably trivial to add it to a real image.\n\nJust take a real image you want to discredit, add watermark \"look it's AI\".\n\nConspiracy nuts will have a field day adding watermarks to the new moon missions.",
              "score": 59,
              "created_utc": "2026-02-22 06:04:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6v23is",
                  "author": "xkulp8",
                  "text": "Society is going to have to accept that you're not going to be able to trust the authenticity of *any* digital image. We're very close to this point now, maybe we're already there.\n\nWhich means the only thing we're able to trust is film negatives. I don't think AI is close to reproducing those yet.",
                  "score": 4,
                  "created_utc": "2026-02-22 23:38:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6qj6ae",
                  "author": "akindofuser",
                  "text": "I wonder if that could be fixed with a seed and using key pairs similar to PKI. The model would have the seed and be able to sign the watermark. You'd need an authority like the model owner to verify it.\n\nSo if people tried to sign their own images they couldn't copy cat the watermark. ",
                  "score": 5,
                  "created_utc": "2026-02-22 07:30:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6qf32y",
              "author": "Chilidawg",
              "text": "Watermarks are effective so long as the end user is either honest or ignorant of the watermarks. Unfortunately, they are ineffective against well-informed bad actors.",
              "score": 8,
              "created_utc": "2026-02-22 06:52:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6px6o9",
              "author": "KangarooCuddler",
              "text": "Personally, I disagree and think that mandating watermarks is a poor idea. If watermarking AI images became mandatory, people might assume that they could trust an image just because it lacks an AI watermark. That would make them easier to fool in the long run.   \n  \nI think it's better that people learn to recognize the possibility that any image they see could be generated and use caution about what they choose to trust.",
              "score": 46,
              "created_utc": "2026-02-22 04:25:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6pylmv",
                  "author": "JazzlikeLeave5530",
                  "text": "That would be ideal but the problem is that's never going to happen because stupid people will always exist which is why protections are needed. If people just learned to recognize obvious scams then the whole scam industry wouldn't exist but it does because people are stupid.",
                  "score": 6,
                  "created_utc": "2026-02-22 04:35:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6pxsow",
                  "author": "akindofuser",
                  "text": "I don't think trusting an image based off watermark or not is a good argument. We're rapidly approaching a place where AI will be fully capable of truely realistic images. \n\nHaving some kind of tell would be nice. \n\n>I think it's better that people learn to recognize the possibility\n\nThis will end in failure. Tuning out tells and undesirable traits is easy and bigger models are better at hiding them anyways. ",
                  "score": 2,
                  "created_utc": "2026-02-22 04:29:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6ry3qu",
              "author": "Diabolicor",
              "text": "That's kind of how SynthID works. The model has some secret keys set up that mixes up with the seed for signing generated content like image, video, text. More info about it: [https://www.youtube.com/watch?v=\\_fMFb2Lv7rI](https://www.youtube.com/watch?v=_fMFb2Lv7rI)",
              "score": 2,
              "created_utc": "2026-02-22 14:29:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6sn154",
              "author": "2this4u",
              "text": "If you can watermark the information that it's AI, you can watermark other things like originating location, IP, etc.",
              "score": 2,
              "created_utc": "2026-02-22 16:28:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6qa7rs",
          "author": "AcePilot01",
          "text": "Curious, what's baked in?  aside from the meta data (which can be removed) what's visually in the pixel? and how can it not be taken out? that's interesting.",
          "score": 2,
          "created_utc": "2026-02-22 06:08:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6qsw9r",
              "author": "SpaceNinjaDino",
              "text": "Also be aware that printers add watermarks to all print outs. Even if you only print black ink, your colors (especially yellow) will eventually run out because it is sprinkling in a tracking id (MIC). Look up printer forensics for more info. Photoshop can add watermarks. I'm sure every cloud service adds their watermarks. \n\nBut yes, a diffusion pass with enough noise will destroy it. I wonder what minimal level of noise injection is required to defeat it.",
              "score": 7,
              "created_utc": "2026-02-22 09:02:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6qdhs1",
              "author": "eruanno321",
              "text": "A pseudorandom pattern that easily blends into the image but creates a detectable statistical signature when analyzed with the proper detector.",
              "score": 7,
              "created_utc": "2026-02-22 06:37:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6qg0zc",
                  "author": "AcePilot01",
                  "text": "But is it data, or just \"this was created by x\"",
                  "score": 2,
                  "created_utc": "2026-02-22 07:00:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6qibsa",
          "author": "jib_reddit",
          "text": "It is known.",
          "score": 3,
          "created_utc": "2026-02-22 07:22:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6tlo0h",
          "author": "InitialFly6460",
          "text": "That basically amounts to doing an upsampling / resampling pass with SDXL, right?",
          "score": 1,
          "created_utc": "2026-02-22 19:07:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6vi84x",
              "author": "Suoritin",
              "text": "Yes and no.\n\nCtrlRegen reconstructs the original image from pure noise using adapter that is somewhat similar to super strong ControlNet.",
              "score": 2,
              "created_utc": "2026-02-23 01:11:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6x056g",
                  "author": "InitialFly6460",
                  "text": " it seems SynthId is not very efficient [https://www.youtube.com/watch?v=63bcJ9w9uhA](https://www.youtube.com/watch?v=63bcJ9w9uhA)  Besides that, I tested a full subsampling followed by a full resampling with cfg 0.5, and the resampling does not reproduce the image 100% exactly; there are minute differences‚Ä¶",
                  "score": 2,
                  "created_utc": "2026-02-23 07:37:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6x64zy",
                  "author": "InitialFly6460",
                  "text": "I did some research, because my method required modifying the images, even if it only affected 0.05 percent, and there's a PyTorch implementation that just came out to remove watermarks: [https://github.com/andrekassis/ai-watermark?utm\\_source=tldrinfosec](https://github.com/andrekassis/ai-watermark?utm_source=tldrinfosec) And here's an article that proves that model destruction by diffusion is an excellent way to destroy the best watermarks currently available, and which advocates a semantic approach to combat SDXL: [https://browse-export.arxiv.org/pdf/2511.05598](https://browse-export.arxiv.org/pdf/2511.05598)",
                  "score": 2,
                  "created_utc": "2026-02-23 08:35:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6wxs1s",
                  "author": "InitialFly6460",
                  "text": "how is it superior than a upsampling / resampling pass with SDXL, ? if and if you add a full noise step  with SDXL ? to be more precise : imagine you unsampling a image from 50 to 10, then you resampling from 10 to 50 and you add one more set to 51 with SDXl... :  it should be efficient also isn't it ? I mean more than 75 per cent of the noise construction is from an another model.. 41 setp for only 10 original step... and based on a totaly different construction. ",
                  "score": 1,
                  "created_utc": "2026-02-23 07:14:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6u5l4c",
          "author": "Plane-Marionberry380",
          "text": "Not surprised at all. Any watermarking that operates in pixel space or latent space is going to be trivially removable by anyone who can run img2img. The real question is whether these watermarks are meant to catch bad actors (spoiler: they wont) or just give platforms plausible deniability for compliance purposes. I suspect its the latter.",
          "score": 1,
          "created_utc": "2026-02-22 20:47:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6t868o",
          "author": "jhnprst",
          "text": "they should turn it around: sign the images by the hardware taking them (i.e. camera etc.) any edit after will invalidate the signature.  so we assume all image are fake/edited, unless the signature verifies.  the trust moves up the chain to the hardware manufacturer, still not 100% but probably a lot better than all this",
          "score": 0,
          "created_utc": "2026-02-22 18:05:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rcc7r7",
      "title": "I know this ain't a lot, but I tried it.",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/cepz3w6ni7lg1",
      "author": "PRCbubu",
      "created_utc": "2026-02-23 08:43:00",
      "score": 138,
      "num_comments": 28,
      "upvote_ratio": 0.78,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Animation - Video",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rcc7r7/i_know_this_aint_a_lot_but_i_tried_it/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6xcahy",
          "author": "Formal-Exam-8767",
          "text": "What kind of black magic is she doing with her fingers? Casting a curse?",
          "score": 31,
          "created_utc": "2026-02-23 09:36:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xiz5r",
              "author": "Ordnael92",
              "text": "Massaging invisible nuts",
              "score": 36,
              "created_utc": "2026-02-23 10:40:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6yhmzd",
              "author": "razorree",
              "text": "you were meant to focus on something else...",
              "score": 11,
              "created_utc": "2026-02-23 14:40:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6xe2dn",
              "author": "PRCbubu",
              "text": "What I wanted to make was, she would grab the hand of the viewer and run with them (where she takes the lead)...\nI'm not that good at prompting.",
              "score": 4,
              "created_utc": "2026-02-23 09:53:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6xhns7",
                  "author": "Tbhmaximillian",
                  "text": "Add hand out of frame to your prompt or if you used image to video make a version where the hand is not visible, then this should work. Also which model workflow did you use?",
                  "score": 3,
                  "created_utc": "2026-02-23 10:27:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o715525",
              "author": "notislant",
              "text": "Only the right boob having physics is sending me lol",
              "score": 1,
              "created_utc": "2026-02-23 22:13:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6yid8b",
          "author": "luciferianism666",
          "text": "![gif](giphy|iKPQgXxAJtJSg)\n\n",
          "score": 13,
          "created_utc": "2026-02-23 14:44:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6x99i1",
          "author": "Mobile_Vegetable7632",
          "text": "wtf with her finger bro",
          "score": 11,
          "created_utc": "2026-02-23 09:05:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xj58b",
          "author": "fistular",
          "text": "https://preview.redd.it/i0jy938w38lg1.png?width=219&format=png&auto=webp&s=d55ef25ebf073da860778671769cae52501ec8ec\n\n",
          "score": 11,
          "created_utc": "2026-02-23 10:42:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6y9vby",
          "author": "berlinbaer",
          "text": "can you make her tits 20x bigger please ?",
          "score": 11,
          "created_utc": "2026-02-23 13:57:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xlwk6",
          "author": "umutgklp",
          "text": "With a proper workflow you can get better results, just focus on prompting. Do not leave prompting to any AI, the results will never be the same as you asked for, instead do edits on your main prompt. Overall your work is promising. and I'm sure you'll get better results soon. Keep up the good work!",
          "score": 7,
          "created_utc": "2026-02-23 11:07:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yu4lx",
          "author": "tomakorea",
          "text": "Can you give more info about your process to achieve that?",
          "score": 2,
          "created_utc": "2026-02-23 15:42:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o72ze2h",
          "author": "Darkmeme9",
          "text": "Guys imagining thier life with that random girl they see on a station never to see her again.",
          "score": 2,
          "created_utc": "2026-02-24 04:38:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xhrt8",
          "author": "flavioj",
          "text": "Workflow?",
          "score": 1,
          "created_utc": "2026-02-23 10:29:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xwgsh",
          "author": "lila_chasy",
          "text": "awww so sweety!",
          "score": 1,
          "created_utc": "2026-02-23 12:33:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yb4jm",
          "author": "devilish-lavanya",
          "text": "White hair? She is thousands year old fox?",
          "score": 1,
          "created_utc": "2026-02-23 14:04:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6z79zh",
          "author": "banedlol",
          "text": "Such manly hands you have",
          "score": 1,
          "created_utc": "2026-02-23 16:44:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6znwhw",
          "author": "turtleisinnocent",
          "text": "b‚àûbs",
          "score": 1,
          "created_utc": "2026-02-23 18:01:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70eedm",
          "author": "thanatica",
          "text": "She has 6 fingers for a few frames. Other than that, nice bounce.",
          "score": 1,
          "created_utc": "2026-02-23 20:03:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70pq9o",
          "author": "Tomarsnap",
          "text": "What did you use?",
          "score": 1,
          "created_utc": "2026-02-23 20:57:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o72m8j2",
          "author": "Zack_spiral",
          "text": "That image almost seems to be sd1.5 generated if you use an illustrios xl model and a screencap lora the quality will almost explode",
          "score": 1,
          "created_utc": "2026-02-24 03:12:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73pfl2",
          "author": "lolxdmainkaisemaanlu",
          "text": "now we got busty anime girls in a saree? I approve",
          "score": 1,
          "created_utc": "2026-02-24 08:14:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ygfpy",
          "author": "TechnoByte_",
          "text": "You need frame interpolation: https://github.com/Fannovel16/ComfyUI-Frame-Interpolation",
          "score": 1,
          "created_utc": "2026-02-23 14:33:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6yrlh2",
              "author": "TimeLine_DR_Dev",
              "text": "I assumed the frame rate was a choice",
              "score": 4,
              "created_utc": "2026-02-23 15:30:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6zqtca",
              "author": "nopalitzin",
              "text": "Amazing. A lot of models give you low fps on anything anime or 2d from grok to wan 2.2 to ltx2",
              "score": 1,
              "created_utc": "2026-02-23 18:15:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6yofza",
          "author": "jakiestfu",
          "text": "But why the fuck a big tit cat human OP ü§¢",
          "score": 0,
          "created_utc": "2026-02-23 15:15:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7dr71f",
              "author": "RegisNyx",
              "text": "Because its the best! Why the fuck would you not want that?",
              "score": 1,
              "created_utc": "2026-02-25 19:32:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o70al7s",
              "author": "AICatgirls",
              "text": "She's a Hindu goddess",
              "score": 1,
              "created_utc": "2026-02-23 19:45:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}