{
  "metadata": {
    "last_updated": "2026-01-13 08:49:59",
    "time_filter": "week",
    "subreddit": "StableDiffusion",
    "total_items": 50,
    "total_comments": 2338,
    "file_size_bytes": 2198910
  },
  "items": [
    {
      "id": "1q1jmz7",
      "title": "SVI 2.0 Pro for Wan 2.2 is amazing, allowing infinite length videos with no visible transitions. This took only 340 seconds to generate, 1280x720 continuous 20 seconds long video, fully open source. Someone tell James Cameron he can get Avatar 4 done sooner and cheaper.",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/w091epk8vtag1",
      "author": "Fresh_Diffusor",
      "created_utc": "2026-01-02 00:15:29",
      "score": 2086,
      "num_comments": 368,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q1jmz7/svi_20_pro_for_wan_22_is_amazing_allowing/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nx679fk",
          "author": "Neggy5",
          "text": "i did a 1.5 minute video completely perfectly. anymore than that crashes my comfyui üòÖ",
          "score": 146,
          "created_utc": "2026-01-02 00:42:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx6a5gl",
              "author": "FitzUnit",
              "text": "How long did it take to render and what type of you? What was the res you rendered at?",
              "score": 17,
              "created_utc": "2026-01-02 00:59:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx6bv0m",
                  "author": "Neggy5",
                  "text": "took 2 hours to render all 15 5 second clips and stitch them together on 16gb vram + 64gb ram + sageattention. i rendered at 544x960 using this workflow:\n\n[https://civitai.com/models/1866565/wan22-continuous-generation-subgraphs](https://civitai.com/models/1866565/wan22-continuous-generation-subgraphs)\n\nim upscaling and interpolating rn which is gonna take another couple hours i think lol, then i may share on civit",
                  "score": 68,
                  "created_utc": "2026-01-02 01:10:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxovjy4",
              "author": "Flimsy-Finish-2829",
              "text": "Another workflow about generating 40-second videos without color degradation: [https://www.youtube.com/watch?v=PJnTcVOqJCM&t=209s](https://www.youtube.com/watch?v=PJnTcVOqJCM&t=209s)",
              "score": 1,
              "created_utc": "2026-01-04 20:39:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxtvl3p",
                  "author": "Popular_Size2650",
                  "text": "im having 16gb vram and 64gb ram and im using q5 gguff, im getting oom any way to solve this?",
                  "score": 1,
                  "created_utc": "2026-01-05 15:21:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx633jf",
          "author": "Fresh_Diffusor",
          "text": "Generated local on RTX 5090. I did few changes to the workflow from wallen0322:\n\n\\- I use smoothmix wan 2.2 i2v instead of base wan 2.2 i2v models. base wan 2.2 i2v with lightx loras do look slow motion, smoothmix look much faster motion  \n\\- I added two Navi Loras from CivitAI: [https://civitai.com/models/1842024/naviavatar-wan22-paseer](https://civitai.com/models/1842024/naviavatar-wan22-paseer) [https://civitai.com/models/1809771/navi-wan-21](https://civitai.com/models/1809771/navi-wan-21)  \n\\- I reduced steps on low samplers from 3 to 2, still good enough and is faster. so only 5 steps in total, not 6.  \n\\- I added RIFE interpolation node from 16 to 32 at the end  \n\\- I added film grain node at the end\n\nMy input image is old image from a Wan T2V generation I did many months ago (using same navi loras).\n\nThis is github repo of SVI 2.0 Pro, give them a star to make them happy: [https://github.com/vita-epfl/Stable-Video-Infinity](https://github.com/vita-epfl/Stable-Video-Infinity) They said they will make new version that is even better (this was trained only on 480p, they want to train one on 720p too)",
          "score": 121,
          "created_utc": "2026-01-02 00:19:39",
          "is_submitter": true,
          "replies": [
            {
              "id": "nx6pkev",
              "author": "Bogante_Castiel",
              "text": "Smoothmix doesn't need \"lighting loras\", right?",
              "score": 9,
              "created_utc": "2026-01-02 02:33:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx91hqh",
                  "author": "hurrdurrimanaccount",
                  "text": "i wouldn't bother with smoothmix. all it does is merge all loras into wan, causing people to constantly gyrate and fuck everything",
                  "score": 14,
                  "created_utc": "2026-01-02 13:35:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx6pxqm",
                  "author": "Fresh_Diffusor",
                  "text": "correct. I use no lighting loras",
                  "score": 7,
                  "created_utc": "2026-01-02 02:36:04",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxbwq7k",
              "author": "dilinjabass",
              "text": "Nice work. Btw [https://civitai.com/models/2053259/wan-22-enhanced-nsfw-or-camera-prompt-adherence-lightning-edition-i2v-and-t2v-fp8-gguf?modelVersionId=2540892](https://civitai.com/models/2053259/wan-22-enhanced-nsfw-or-camera-prompt-adherence-lightning-edition-i2v-and-t2v-fp8-gguf?modelVersionId=2540892) the V2 Cam i2v f8 model is in my opinion much better than smoothmix. Quality, character consistency, movement, etc",
              "score": 9,
              "created_utc": "2026-01-02 22:02:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxd3goi",
                  "author": "Fresh_Diffusor",
                  "text": "thanks for suggestion, I will test it. but is that not model for specific NSFW?",
                  "score": 1,
                  "created_utc": "2026-01-03 01:56:21",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx81rsq",
              "author": "PinkMelong",
              "text": "can you share actual your workflow instead of you linked and where you modified from.  \nthe one from link is doing slow-mo and doesn't follow the prompt well.   \nit would be much appreciated if you share yours. Thanks OP",
              "score": 9,
              "created_utc": "2026-01-02 08:34:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxd565e",
                  "author": "Fresh_Diffusor",
                  "text": "I made it more ugly, but if you want to use it, here is my version of workflow: [https://pastebin.com/sWE61353](https://pastebin.com/sWE61353)",
                  "score": 5,
                  "created_utc": "2026-01-03 02:06:13",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxc9gby",
              "author": "IrisColt",
              "text": "Thanks for the detailed info!",
              "score": 3,
              "created_utc": "2026-01-02 23:08:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx8tk4h",
              "author": "Substantial_Plum9204",
              "text": "Thank you! Do you have the model link to smoothmix wan 2.2?",
              "score": 1,
              "created_utc": "2026-01-02 12:42:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxd3b6y",
                  "author": "Fresh_Diffusor",
                  "text": "[https://civitai.com/models/1995784?modelVersionId=2260110](https://civitai.com/models/1995784?modelVersionId=2260110)",
                  "score": 1,
                  "created_utc": "2026-01-03 01:55:27",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxwb9jr",
              "author": "No-Location6557",
              "text": "So what happens if you try generate 720p on svi? Is the quality bad since svi is only trained on 480p?",
              "score": 1,
              "created_utc": "2026-01-05 22:05:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxwqh66",
                  "author": "Fresh_Diffusor",
                  "text": "you see it on this video. it is generated 720p.",
                  "score": 1,
                  "created_utc": "2026-01-05 23:22:03",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx6zpng",
              "author": "Sanctum_Zelairia",
              "text": "Where can you find the work flow?",
              "score": 1,
              "created_utc": "2026-01-02 03:36:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx70b9l",
                  "author": "Fresh_Diffusor",
                  "text": "I linked it in post body. here again: [https://github.com/wallen0322/ComfyUI-Wan22FMLF/blob/main/example\\_workflows/SVI%20pro.json](https://github.com/wallen0322/ComfyUI-Wan22FMLF/blob/main/example_workflows/SVI%20pro.json)",
                  "score": 17,
                  "created_utc": "2026-01-02 03:40:48",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx91c84",
              "author": "hurrdurrimanaccount",
              "text": "you can tell it's smoothmix garbage by the way she's trying to constantly shake her hips and dance",
              "score": 1,
              "created_utc": "2026-01-02 13:34:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx70qrw",
          "author": "kquizz",
          "text": "Ok but why is are her facial expressions changing every half second?",
          "score": 76,
          "created_utc": "2026-01-02 03:43:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx88k2t",
              "author": "fistular",
              "text": "Because you can't actually control it, just like every other video model.",
              "score": 92,
              "created_utc": "2026-01-02 09:39:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx8k38c",
                  "author": "AcrobaticExchange211",
                  "text": "It's because of the prompt, silly. There are no inputs for each individual second of footage. Compare that to CGI where you go through the process frame by frame.",
                  "score": 10,
                  "created_utc": "2026-01-02 11:25:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx8h754",
                  "author": "JoelMahon",
                  "text": "1. improvements are being made all the time 2. OP shared their prompts and they didn't even attempt to control the expression in most of them, and the ones they did aren't very good at asking for constancy imo",
                  "score": 3,
                  "created_utc": "2026-01-02 10:59:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxaik51",
                  "author": "Itchy-Advertising857",
                  "text": "You can transfer whatever facial expressions you want onto her by doing a WanAnimate pass.",
                  "score": 0,
                  "created_utc": "2026-01-02 18:02:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxba316",
              "author": "roychodraws",
              "text": "because she's wrestling with internal conflict about being in another shitty space pocahontas adaptation",
              "score": 24,
              "created_utc": "2026-01-02 20:11:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxd2juz",
              "author": "Fresh_Diffusor",
              "text": "because I sometimes did not prompt specific facial expression, so model makes up facial expression",
              "score": 2,
              "created_utc": "2026-01-03 01:51:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxd51df",
                  "author": "kquizz",
                  "text": "And the model doesn't try to make consistent facial expressions?",
                  "score": 1,
                  "created_utc": "2026-01-03 02:05:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxe26mc",
              "author": "MaybeForsaken9496",
              "text": "Because she is Na'vi",
              "score": 1,
              "created_utc": "2026-01-03 05:36:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxibcq4",
              "author": "StrangerOverall5820",
              "text": "Ok, pero mira esas NALGAS!!",
              "score": 1,
              "created_utc": "2026-01-03 21:15:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx631y7",
          "author": "Green-Ad-3964",
          "text": "how does it work exactly? do we have different prompts for each sub-part? The best would be having intermediate frames as well, and start+end frame also",
          "score": 32,
          "created_utc": "2026-01-02 00:19:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx63t7x",
              "author": "Fresh_Diffusor",
              "text": "yes, you can prompt for each sub part. these are my prompts I use:\n\n1.   \nclean single shot, low contrast cinematic action shot, a tribal navi girl with blue skin, pointy ears and black braided hair and tribal bodypaint. she elegantly jumps into a lake of water, while behind her other navi run away in the other direction. jungle is full of bioluminescent colorful glowing alien foliage. she has a blue tail. she looks at the viewer, her expression natural and friendly. she is wearing tribal clothes.\n\n2.  \nclean single shot, low contrast cinematic action shot, a tribal navi girl with blue skin, pointy ears and black braided hair and tribal bodypaint. she quickly swims in a lake of water to the right of the view. jungle is full of bioluminescent colorful glowing alien foliage. she has a blue tail. she is wearing tribal clothes.\n\n3.  \nclean single shot, low contrast cinematic action shot, a tribal navi girl with blue skin, pointy ears and black braided hair and tribal bodypaint. she elegantly climbs out of a lake of water and hides in the bushes of bioluminescent colorful glowing alien foliage. she has a blue tail. she is wearing tribal clothes.\n\n4.  \nclean single shot, low contrast cinematic action shot, a tribal navi girl with blue skin, pointy ears and black braided hair and tribal bodypaint. she elegantly strives through the bushes of bioluminescent colorful glowing alien foliage while looking at the viewer, her expression natural and friendly. she is moving deeper into the jungle. she has a blue tail. she is wearing tribal clothes.\n\nI could maybe have used less verbose prompt. I am still used to doing T2V so I describe too much that is already clear in input image anyways.",
              "score": 44,
              "created_utc": "2026-01-02 00:23:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx6ny7r",
                  "author": "Spamuelow",
                  "text": "You can also add new loras to each section which i don't ever see people mention. Just add them in front of the get model node. \n\nSo you could set up a load of transformations, camera changes, clothing/character/action swaps",
                  "score": 10,
                  "created_utc": "2026-01-02 02:23:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx68d1f",
                  "author": "Green-Ad-3964",
                  "text": "Fantastic. It really is starting to sound more and more like a movie script and scenography.",
                  "score": 17,
                  "created_utc": "2026-01-02 00:49:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx6hlwb",
              "author": "GasolinePizza",
              "text": "Avoiding \"intermediate frames\" is sort of the whole point, it's *definitely* not desirable. Having intermediate frames is exactly how the jury rigged clip->clip (and jury rigged vace clip additions) flows worked and it was fundamentally atrocious. Avoiding the independently-computed joining/merge frame sets is exactly why the continuous-latent has better results than the previous options.",
              "score": 10,
              "created_utc": "2026-01-02 01:45:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx8jx18",
                  "author": "JahJedi",
                  "text": "What the best way to avoid it? Cutout the double frame in editing on clip join?",
                  "score": 1,
                  "created_utc": "2026-01-02 11:23:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx9vnh5",
          "author": "TheTimster666",
          "text": "A great feature of this, if you have a random noise seed node attached to each extension step (instead of 1 global seed for all):\n\nIf you have generated eg step 1, 2, and 3, but don‚Äôt like how step 3 turned out, you can just change the seed and / or prompt of step 3 and run again, and it will skip step 1 and 2 and only generate step 3 again.¬†\n\nThis way you can extend and adjust, without having to regenerate earlier extensions or wait for them to be generated again.\n\nIt‚Äôs awesome, really.\n\nhttps://preview.redd.it/k2b8e80unyag1.png?width=2292&format=png&auto=webp&s=02c6cd54b35a2ad390b050eed3344f5ceb221b5b",
          "score": 8,
          "created_utc": "2026-01-02 16:15:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny04zlu",
              "author": "PutzNiik",
              "text": "underated comment",
              "score": 1,
              "created_utc": "2026-01-06 13:29:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx75hnh",
          "author": "jonesaid",
          "text": "James Cameron is on the board of Stability AI. He is likely well-aware of these possibilities.",
          "score": 23,
          "created_utc": "2026-01-02 04:14:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny35g28",
              "author": "Bitter_Ad_9950",
              "text": "3d Shooters were initially developed by the military for training sims.  \nTelecommunications were meant to support logistics in military operations.  \nThe internet was invented for military communications.\n\nJames Cameron likely has ties to the military, and I'd bet that Avatar used AI generation. He's just one of the links to the public sector.\n\nMilitary has always had an influence on civilian affairs through media. Subliminal messaging, counter psyops, etc etc. I mean you tell your neighbor that the reason their cousin shot up a school was because of <insert country here>'s subliminal messaging in their favourite childhood TV show, or just implement a psyops patch that negated the message and not raise panic?",
              "score": 1,
              "created_utc": "2026-01-06 21:59:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx75zqz",
              "author": "Fresh_Diffusor",
              "text": "this capability with SVI 2.0 Pro only exist for 3 days so might be too new for him to know",
              "score": -30,
              "created_utc": "2026-01-02 04:17:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx79mpr",
                  "author": "So-many-ducks",
                  "text": "He's a billionaire with heavy ties to world class VFX studios and tech companies, your \"might\" is doing a lot of heavy lifting.",
                  "score": 49,
                  "created_utc": "2026-01-02 04:41:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx888xf",
                  "author": "drury",
                  "text": "I (a random redditor who happened to see your post) just told him (he's my bff), and you were right - he was shocked to hear! He sends his regards (he would send money too but he's fresh out due to this discovery, sorry).",
                  "score": 22,
                  "created_utc": "2026-01-02 09:36:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx8lwhe",
                  "author": "sadsatan1",
                  "text": "Surely you, a random redditor knows better and faster than the team he is working with! I agree it's a great idea to send him an email now, with a link to your reddit post",
                  "score": 11,
                  "created_utc": "2026-01-02 11:41:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx9fi9t",
                  "author": "Ok-Option-6683",
                  "text": "\"might be too new for him to know\" ahahaha ...said the smart-ass about the guy who was in charge of the team that created Photoshop and water effects in The Abyss in 1989 lol",
                  "score": 1,
                  "created_utc": "2026-01-02 14:56:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx95kl4",
          "author": "Etsu_Riot",
          "text": "I tried to use this but:\n\na) It doesn't allow you to generate long videos, it's just another workflow to stich clips together.  \nb) In my case, there is a visible fade between the clips.  \nc) Like has always been the case, there is visual degradation and slow motion after a few clips.\n\nBeing the case that I can already generate between 14 and 20 seconds clips in one go, I don't find this useful. However, different model versions may produce different results so your experience may be better. But for 15 seconds videos I find this useless as that's already easy to do in one go without tricks.",
          "score": 7,
          "created_utc": "2026-01-02 14:00:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx9scgw",
              "author": "Perfect-Campaign9551",
              "text": "You probably tried the old SVI, this is a new one, I haven't seen any fade between clips at all. Perhaps try again with the \"2.0 pro\"",
              "score": 3,
              "created_utc": "2026-01-02 16:00:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxa21fi",
                  "author": "Etsu_Riot",
                  "text": "I downloaded what was provided here. I may check later if I made any mistakes, however, if there's degradation, it will still be useless. I prefer shorter (10/15 seconds) videos that look OK, than one minute videos that look OK for the first 10/15 seconds.\n\nI also find it weird that, even if using the same models and settings I usually use, and using the same prompts, can't get the same results that I normally get, and characters don't behave as they should. I  think it may be the fault of the LoRas you are forced to use here.",
                  "score": 1,
                  "created_utc": "2026-01-02 16:45:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxd5zwf",
              "author": "Fresh_Diffusor",
              "text": "can you show me similar video you easily generated with 20 seconds long in one go please? I never saw anyone do that looking good before SVI 2.0 Pro",
              "score": 2,
              "created_utc": "2026-01-03 02:11:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxw1k6e",
                  "author": "Etsu_Riot",
                  "text": "For similar video you mean something in which the character goes from A to B, not a loop for example. I have loops up to 27 seconds. For loops I mean characters don't go away or if the do they come back later and the background doesn't change (little to no camera movement).\n\nSo far, my experiments gave me scenes where the character executes similar actions twice, which is not desirable I imagine. For example, the cat girl jumps into the water, swims, gets up of the water, looks at the screen, maybe talks, then jumps into the water again, swimming and getting out in a different place, hiding into the vegetation. It's a complete sequence, but where the character executes similar actions twice. In one occasion the character, instead of jumping to a different place in the water, returns to the water before swimming in a different direction. These sequences were 18 seconds long.\n\nI haven't done many attempts and I'm mostly using the prompt you provided. I need to keep investigating if I can make a sequence where there is constant movement forward without repetition. For what I noticed, your video is a short sequence that happens slowly, where I'm getting fast sequences when more stuff happens. I need a way to reduce the speed of the character movements in order to repeat your results. Based on that, this workflow seems useful to make short videos where little happens, but still see no evidence that it can help to make long videos (more than 30 seconds lets say) with multiple diverse actions. Highly useful, but not for making continuous videos I'm afraid, based on what I can see.",
                  "score": 1,
                  "created_utc": "2026-01-05 21:21:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx9j8fz",
              "author": "Valuable_Weather",
              "text": "Same",
              "score": 1,
              "created_utc": "2026-01-02 15:15:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxa8t7t",
          "author": "tyen0",
          "text": "For the lazy like me, https://github.com/deepbeepmeep/Wan2GP just added support for SVI 2 pro yesterday.\n\n> Wan 2.2 i2v Stable Vision Infinity Pro 2: SVI Pro 2 offers potentially unlimited Videos to Continue for i2v models. It will use either the Start frame as a Reference Image or you may provide an Anchor image to be used across all the windows or multiple Anchor Images one per Window.",
          "score": 6,
          "created_utc": "2026-01-02 17:17:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxbhkbi",
              "author": "sepalus_auki",
              "text": "excellent! I don't like using comfyui.",
              "score": 1,
              "created_utc": "2026-01-02 20:48:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxfkb47",
              "author": "ThreeDog2016",
              "text": "How do I get it working? I don't see it as an option in the dropdown for WAN 2.2\n\nEDIT: I didn't select image2video first!",
              "score": 1,
              "created_utc": "2026-01-03 13:02:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx67th3",
          "author": "NebulaBetter",
          "text": "The motion feels a bit too robotic and abrupt in my opinion, which is fairly common with setups like LongCat or SMI. I‚Äôd suggest running a VACE pass to smooth things out and make the movement feel more natural.",
          "score": 14,
          "created_utc": "2026-01-02 00:46:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx68s8b",
              "author": "LevelStill5406",
              "text": "any tips on how to do this? üëÄ",
              "score": 3,
              "created_utc": "2026-01-02 00:51:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx696uq",
              "author": "Fresh_Diffusor",
              "text": "I never use VACE, what does it do?",
              "score": 2,
              "created_utc": "2026-01-02 00:54:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx6hmtq",
                  "author": "goddess_peeler",
                  "text": "VACE can generate new frames in between the context frames you give it. For example, give it the last 8 frames of clip1 and the first 8 frames of clip2 and it can generate transition frames that make the motion look smooth and natural instead of the abrubt and jerky motion you sometimes get when stitching clips together.\n\nVACE is actually much more powerful than I've described, but this is a common use case for it.\n\n[Wan VACE Clip Joiner](https://www.reddit.com/r/StableDiffusion/comments/1pnygiw/release_wan_vace_clip_joiner_v20_major_update/) (disclaimer: my workflow)",
                  "score": 10,
                  "created_utc": "2026-01-02 01:45:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx6ov3j",
                  "author": "NebulaBetter",
                  "text": "VACE is essentially a video editing suite inside WAN. It helps a lot with things that are extremely challenging today, such as strong consistency (characters, environments, etc), temporal coherence, and controlled extensions. It works like an in-painting system with motion-control preprocessors, using masks to achieve very specific results.\n\nIn this example image, I use it to modify the character‚Äôs hand. Combining SAM3, VACE, and several other tools, like SVI, is what truly makes open source stand out against closed-source solutions, though it does require time and patience.\n\nhttps://preview.redd.it/b5nm5o63kuag1.png?width=1561&format=png&auto=webp&s=1442b5e501fbf987f29490af03e1cf051d5d92a2",
                  "score": 7,
                  "created_utc": "2026-01-02 02:29:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx745vo",
              "author": "mk8933",
              "text": "If audio was added to it...then it would make more sense. It looks like she's playfully talking to someone...maybe asking a question she's not suppose to. That's why her motions are slow.",
              "score": 0,
              "created_utc": "2026-01-02 04:05:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx76s96",
                  "author": "NebulaBetter",
                  "text": "Audio would not help too much. The robotic look comes from micro-stuttering, which break motion continuity and make the animation feel unstable. Just compare this clip with any similar scene from the movie and the difference becomes immediately obvious.",
                  "score": 0,
                  "created_utc": "2026-01-02 04:22:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx7sdg0",
          "author": "Alpha--00",
          "text": "And shittier?\n\nI don‚Äôt argue it looks cool, but it‚Äôs leagues behind from movie graphics quality.",
          "score": 29,
          "created_utc": "2026-01-02 07:06:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxadg7f",
              "author": "Gold-Cat-7686",
              "text": "You're not wrong, but keep in mind these are generally done by people in their basements on their gaming PCs. That's...sort of incredible. The true enthusiasts with monster machines still wouldn't be able to match movie quality, but they'd be able to get even closer, and there are even more techniques that can be done if you're passionate enough (VACE, PainterI2V to manipulate movement, v2v techniques, upscaling, etc). The fact we're here at all is amazing.",
              "score": 18,
              "created_utc": "2026-01-02 17:39:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxc33x2",
                  "author": "TheRealDJ",
                  "text": "And more than that the cost to benefit ratio is insanely different. For a professional studio to produce that same level of quality without AI would be incredibly expensive. For someone to do it for a few dollars is crazy, and will only scale further in that direction as the tech evolves. If an independent film maker wanted to add in CGI scenes, I have to imagine they could definitely incorporate this tech which would be much better than anything they could produce on their own.",
                  "score": 3,
                  "created_utc": "2026-01-02 22:35:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx9lmtb",
              "author": "Lover_of_Titss",
              "text": "The tech is also extremely new and constantly developing. It took a while for CG to replace miniatures.",
              "score": 7,
              "created_utc": "2026-01-02 15:27:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxac37h",
              "author": "TriggasaurusRekt",
              "text": "It's honestly embarrassing when people can't distinguish this stuff from cinema quality.",
              "score": 4,
              "created_utc": "2026-01-02 17:32:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx91vd0",
              "author": "hurrdurrimanaccount",
              "text": "people really do be yearning for the slop. it's no wonder companies can just charge whatever the fuck they want now for gpus",
              "score": 9,
              "created_utc": "2026-01-02 13:38:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxccx1p",
                  "author": "Phazex8",
                  "text": "We love our slop.",
                  "score": 3,
                  "created_utc": "2026-01-02 23:27:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx6mj3k",
          "author": "scirio",
          "text": "Coming to micro-imax",
          "score": 6,
          "created_utc": "2026-01-02 02:15:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6pl1a",
          "author": "altoiddealer",
          "text": "I didn‚Äôt have enough time to mess around with it much but I started checking out how to just render a part or a few parts, then resume from it later.  It seems all you need to do is use the Save Latents node, and to get it jumpstarted later you would load the last images from the result video plus the Load Latents node.  If anyone knows a workflow that already has this done well that would be great",
          "score": 5,
          "created_utc": "2026-01-02 02:33:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6cgla",
          "author": "nabiku",
          "text": "Maybe then Cameron can spend a little more of his money on writers instead of the vfx. The story in the first Avatar might have been cheesy and predictable, but somehow every new sequel is even worse.",
          "score": 28,
          "created_utc": "2026-01-02 01:13:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx6x3pl",
              "author": "neonskimmer",
              "text": "100%. i cannot understand how these movies keep being successful or what people see in them. absolute cringe from start to finish. i am not a film connaisseur. the last movie i saw was the new spongebob movie that just came out and it was better in every way :)",
              "score": 13,
              "created_utc": "2026-01-02 03:20:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx7io7g",
                  "author": "bwganod",
                  "text": "I've only been to the cinema once in 10+ years and that was to watch Avatar 2. It's the only film I can't reasonably have a better experience watching at home. Consumer VR is still too bulky/buggy for a great home theater experience, so cinema it is. The story is trash, the plot is trash, the characters are trash, but the immersive experience is unique. It's not just 3D it's the absolute limit of what the technology is capable of, which is what Cameron has always excelled at. That's why people watch it.",
                  "score": 3,
                  "created_utc": "2026-01-02 05:45:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx81jx1",
                  "author": "WorthySparkleMan",
                  "text": "It's pretty, that's why I watch it.",
                  "score": 1,
                  "created_utc": "2026-01-02 08:32:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxegarx",
                  "author": "tehorhay",
                  "text": "He‚Äôs the only person ever to make 4 billion dollar grossing movies in a row, has 3, about to be 4, of the top 5 highest grossing movies of all time, has won multiple Oscar‚Äôs etc‚Ä¶.\n\n\n‚Ä¶.and you‚Äôre here on an ai sub yearning for slop ;).\n\nNot at all surprised you guys have a problem recognizing quality lmao.",
                  "score": 1,
                  "created_utc": "2026-01-03 07:31:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx8hckt",
              "author": "JoelMahon",
              "text": "eh, I prefer fire and ash's \"story\" to the first one, not saying it's good though, just the least meh\n\nwater is by and far the worst of the bunch though, my god the meandering",
              "score": 2,
              "created_utc": "2026-01-02 11:00:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx730d6",
              "author": "Fresh_Diffusor",
              "text": "or maybe fan-made avatar movies on youtube with AI will become popular genre, maybe with better story than original",
              "score": -8,
              "created_utc": "2026-01-02 03:58:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx75i2i",
                  "author": "Anen-o-me",
                  "text": "What we need is new series released outside existing IP regimes.",
                  "score": 5,
                  "created_utc": "2026-01-02 04:14:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx66n8f",
          "author": "Ichiritzu",
          "text": "very impressive!",
          "score": 7,
          "created_utc": "2026-01-02 00:39:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx69x76",
              "author": "Fresh_Diffusor",
              "text": "thank you",
              "score": 2,
              "created_utc": "2026-01-02 00:58:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx8ee78",
          "author": "PedroEglasias",
          "text": "I'm doing 15s+ on a 3060 12GB... this is easily the biggest breakthrough in AI video gen and it's completely open source.... game changer",
          "score": 9,
          "created_utc": "2026-01-02 10:34:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nybhd17",
              "author": "Ok-Flatworm5070",
              "text": "Can you share your workflow and your setup? I took have a 3060.",
              "score": 1,
              "created_utc": "2026-01-08 01:52:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxbyhyo",
              "author": "Baphaddon",
              "text": "How longs it taking?",
              "score": 1,
              "created_utc": "2026-01-02 22:11:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxdy6i3",
                  "author": "PedroEglasias",
                  "text": "So I'm doing 832x448, planning to just upscale and insert frames after to improve resolution and framerate  \n  \n6 nodes, 45 frames per node - haven't tried pushing higher frames per node, but seems unnecessary considering how good the stitching / consistency is\n\nThat's giving me 15s video in 30mins  \n  \nI'm not really stressed about generation time as I can just let it run and come back later. I can't really justify sinking 2k on a 24GB card just yet, as this is purely for hobby / experimenting still",
                  "score": 2,
                  "created_utc": "2026-01-03 05:07:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxccroh",
                  "author": "Phazex8",
                  "text": "Same question here....",
                  "score": 1,
                  "created_utc": "2026-01-02 23:26:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx7vz5e",
          "author": "latentbroadcasting",
          "text": "That's amazing! And also, thanks for sharing the workflow",
          "score": 4,
          "created_utc": "2026-01-02 07:39:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8hx3r",
          "author": "Animan2020",
          "text": "https://preview.redd.it/wob6xo0r4xag1.jpeg?width=1579&format=pjpg&auto=webp&s=862f7db47d9356aaab1996554733754a2578f1ff",
          "score": 4,
          "created_utc": "2026-01-02 11:05:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxa7n7j",
              "author": "tyen0",
              "text": "the bouncing boobs of the one in back? :D",
              "score": 2,
              "created_utc": "2026-01-02 17:11:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx646d3",
          "author": "hapliniste",
          "text": "So is it a workflow or does it require a model/lora?\n\nI'd be interested in using it with turbo diffusion https://github.com/thu-ml/TurboDiffusion to possible generate real-time video.\n\nThat would be kinda neat, ngl. Add motion flow prompting and we got real-time local video games with some effort.",
          "score": 6,
          "created_utc": "2026-01-02 00:25:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7jvlr",
              "author": "Choowkee",
              "text": "Its a lora but afaik there are also some custom nodes required to enable the functionality of SVI (from Kijai).\n\nI just downloaded the workflow provided by Kijai and it worked without issues.\n\nIn case anyone is looking for the workflow its here: https://github.com/vita-epfl/Stable-Video-Infinity/issues/51",
              "score": 4,
              "created_utc": "2026-01-02 05:55:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx66hfm",
              "author": "ANR2ME",
              "text": "Most real-time videogen are based on Wan2.1 1.3B, higher parameters will be too slow (unless you own 8xB200 GPU).",
              "score": 5,
              "created_utc": "2026-01-02 00:38:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx68ozf",
                  "author": "hapliniste",
                  "text": "Yes, but I'd be happy with the 1.3b 480p from the examples.\n\nIt would be for a sort of ai dungeon 2 I'm developing.\n\nGenie 4 will likely happen in 2026 for streamed cloud video anyway but it's good to have control for making custom stuff.",
                  "score": 1,
                  "created_utc": "2026-01-02 00:51:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx7x1hv",
          "author": "R1ppedWarrior",
          "text": "üòÄüòêüòÄüòêüòÄüòêüòÄüòêüòÄ",
          "score": 6,
          "created_utc": "2026-01-02 07:49:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7sb7s",
          "author": "UtopistDreamer",
          "text": "I see where that clip is going üòâ",
          "score": 3,
          "created_utc": "2026-01-02 07:05:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxbnztc",
              "author": "FourtyMichaelMichael",
              "text": "I mean, if no one else is going to say, I'm not.",
              "score": 3,
              "created_utc": "2026-01-02 21:20:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx9cuft",
          "author": "Hearcharted",
          "text": "![gif](giphy|MjXx6ritTqtfhQw3Vy)\n\nCreators of Fake Trailers on YouTube:",
          "score": 3,
          "created_utc": "2026-01-02 14:41:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8kpkx",
          "author": "Corleone11",
          "text": "I'm yielding better results with a slightly altered version of this workflow: https://civitai.com/models/1866565?modelVersionId=2547973\n\nWith OPs workflow, I can't get smooth transitions and there is a noticeable color shift after a new segment starts.",
          "score": 5,
          "created_utc": "2026-01-02 11:30:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx9fg1e",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2026-01-02 14:55:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx9l5yu",
                  "author": "Corleone11",
                  "text": "Yeah, I think the culprit is the smooth mix model.",
                  "score": 2,
                  "created_utc": "2026-01-02 15:25:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxcol9n",
                  "author": "SDSunDiego",
                  "text": "OP modified the workflow that is posted. The WF isn't exactly the same one.",
                  "score": 1,
                  "created_utc": "2026-01-03 00:31:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxcjly5",
          "author": "SDSunDiego",
          "text": "Lol, there are some truly miserable people in the comments.\n\nThanks OP for sharing.This is great!",
          "score": 5,
          "created_utc": "2026-01-03 00:04:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxd6rr1",
              "author": "Fresh_Diffusor",
              "text": "yes. some people really dont understand how less good it was before SVI 2.0 Pro and this is a huge upgrade",
              "score": 3,
              "created_utc": "2026-01-03 02:15:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx6aiw7",
          "author": "aCaffeinatedMind",
          "text": "No.",
          "score": 12,
          "created_utc": "2026-01-02 01:01:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7k7gd",
              "author": "Choowkee",
              "text": "Absolutely yes.\n\nAnyone who tried using WAN 2.2 with last frame video extensions will tell you that this is a major improvement.",
              "score": 4,
              "created_utc": "2026-01-02 05:57:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx87dan",
                  "author": "aCaffeinatedMind",
                  "text": "No.",
                  "score": -7,
                  "created_utc": "2026-01-02 09:27:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx6quvr",
          "author": "Perfect-Campaign9551",
          "text": "I'm stuck with a 3090 so it takes about 1 minutes for each sample at 1280x720. So that would be 20-24 minutes for me (sob)",
          "score": 2,
          "created_utc": "2026-01-02 02:41:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx778of",
              "author": "Fresh_Diffusor",
              "text": "your time is still faster than how long James Cameron has to wait for 20 seconds of Avatar movie rendering",
              "score": 1,
              "created_utc": "2026-01-02 04:25:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx7adf9",
                  "author": "Perfect-Campaign9551",
                  "text": "OP,¬† I grabbed smoothmix model and it's working good, at least on my first run! Not having the damn slow motion issue anymore. Also seems like it obeys my prompt a bit better but also .. It seems to render faster? I'm doing 6 steps but I'm getting 15sec/it. That's was faster then the fp8 model I was using (along with lightning Lora) . Thanks for the mention...",
                  "score": 3,
                  "created_utc": "2026-01-02 04:46:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxbz6pb",
                  "author": "Baphaddon",
                  "text": "Underrated comment",
                  "score": 2,
                  "created_utc": "2026-01-02 22:14:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx9261z",
              "author": "hurrdurrimanaccount",
              "text": "which is why ai video generation is a dead end until the tech improves. people who think 10+ minutes for a few SECONDS of videos is okay can't be helped",
              "score": -1,
              "created_utc": "2026-01-02 13:39:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx9rnj9",
                  "author": "Perfect-Campaign9551",
                  "text": "Agreed. I think it's really a waste of time. Even the online services are, the videos are just too random right now to make something worthwhile",
                  "score": 0,
                  "created_utc": "2026-01-02 15:56:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx6ux2f",
          "author": "Lower-Cap7381",
          "text": "SVI cracked the code just now we need wan 2.3 or something that fixes slow motion ü•≤",
          "score": 2,
          "created_utc": "2026-01-02 03:06:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx6v58v",
              "author": "Fresh_Diffusor",
              "text": "does this look slow motion?",
              "score": 1,
              "created_utc": "2026-01-02 03:07:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx6vcvr",
                  "author": "Lower-Cap7381",
                  "text": "It‚Äôs a 50% of that dude still not believable",
                  "score": 1,
                  "created_utc": "2026-01-02 03:09:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx92f80",
                  "author": "hurrdurrimanaccount",
                  "text": "yes, do you genuinely not see it?",
                  "score": 1,
                  "created_utc": "2026-01-02 13:41:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx9lzqg",
                  "author": "ronbere13",
                  "text": "yes !",
                  "score": 1,
                  "created_utc": "2026-01-02 15:29:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxbm22o",
              "author": "Goldie_Wilson_",
              "text": "I mean, can't you fix the slow motion by changing the resulting FPS.  When using the 4 step lora I typically add 2-3x frame interpolation with RIFE and generate the final video at 24 - 32 fps.  If you leave your seeds fixed you can play around with the combination to make the most natural speed w/o having to regenerate the video",
              "score": 1,
              "created_utc": "2026-01-02 21:10:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxh6lhy",
                  "author": "MannY_SJ",
                  "text": "You can but it's a stop gap, you're artificially increasing the speed of the video not actually increasing it. It's the same as just playing a video at 1.5x speed. What does somewhat fix the slow motion is more strength on the high lightx2v loras, you keep going until it hallucinates.",
                  "score": 1,
                  "created_utc": "2026-01-03 18:02:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx7jioi",
          "author": "drylightn",
          "text": "So is this workflow prompt only? Or can the clips be driven by video like Wan Animate? (human actor performance driving the AI one)",
          "score": 2,
          "created_utc": "2026-01-02 05:52:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7pyq2",
          "author": "Kooky-Menu-2680",
          "text": "It's amazing .. did some tried to add a background reference + character reference?",
          "score": 2,
          "created_utc": "2026-01-02 06:45:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7tc0z",
          "author": "protector111",
          "text": "Getting tis error in ocmfy. does anyone know what is the problem?  \n  \nFailed to validate prompt for output 458:\n\n\\* WanAdvancedI2V 476:\n\n  \\- Value 0.0 smaller than min of 1.0: structural\\_repulsion\\_boost\n\n\\* WanAdvancedI2V 477:\n\n  \\- Value 0.0 smaller than min of 1.0: structural\\_repulsion\\_boost\n\n\\* WanAdvancedI2V 478:\n\n  \\- Value 0.0 smaller than min of 1.0: structural\\_repulsion\\_boost\n\nOutput will be ignored\n\nFailed to validate prompt for output 428:\n\nOutput will be ignored\n\nFailed to validate prompt for output 427:\n\nOutput will be ignored\n\nFailed to validate prompt for output 444:\n\nOutput will be ignored\n\ngot prompt\n\nPrompt executed in 0.17 seconds",
          "score": 2,
          "created_utc": "2026-01-02 07:14:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7xrdu",
              "author": "Grindora",
              "text": "same :/ any fix?",
              "score": 2,
              "created_utc": "2026-01-02 07:56:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx87w4a",
                  "author": "Corleone11",
                  "text": "Set the structural_repulsion_boost to 1.5 on all nodes.",
                  "score": 3,
                  "created_utc": "2026-01-02 09:32:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx7wfkj",
          "author": "Grindora",
          "text": "workflow doesnt work? any idea why ?\n\nhttps://preview.redd.it/z2qgi4on4wag1.png?width=1266&format=png&auto=webp&s=e54d34cca40ce4e397dbc3acf4b6091d7f4524d3",
          "score": 2,
          "created_utc": "2026-01-02 07:43:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx8azs2",
              "author": "Thuannguyenhn",
              "text": "set structural\\_repulsion\\_boost to 1",
              "score": 2,
              "created_utc": "2026-01-02 10:02:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx8dzzs",
                  "author": "Grindora",
                  "text": "thank you i will try :), also is tehre way to extend more ? like 4-5 scens?",
                  "score": 2,
                  "created_utc": "2026-01-02 10:30:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyci4hg",
              "author": "Maleficent-Rice-2046",
              "text": "reemplaza el nodo por uno nuevo reenlaza y funciona, el problema que ahora tengo es que me sale negro el video",
              "score": 1,
              "created_utc": "2026-01-08 05:23:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx7zs4w",
          "author": "alexmmgjkkl",
          "text": "i know the title is a joke but i sincerely believe people HERE  dont know that movies have an average shot length of 2 seconds",
          "score": 2,
          "created_utc": "2026-01-02 08:14:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxbnvmt",
              "author": "FourtyMichaelMichael",
              "text": "True, but then the issue is ultra-consistency which is still difficult.",
              "score": 1,
              "created_utc": "2026-01-02 21:19:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nybhw3j",
              "author": "Ok-Flatworm5070",
              "text": "Thinking the same thing.",
              "score": 1,
              "created_utc": "2026-01-08 01:55:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx88lrr",
          "author": "fistular",
          "text": "So did you tell it to jiggle the background character's boobs or was that a happy accident?",
          "score": 2,
          "created_utc": "2026-01-02 09:39:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxd6ftu",
              "author": "Fresh_Diffusor",
              "text": "I did not prompt that. it is automatic effect of smoothmix model.",
              "score": 1,
              "created_utc": "2026-01-03 02:13:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx8dqdp",
          "author": "smiffy2422",
          "text": "Well... Rule34 subs are about to get busy...",
          "score": 2,
          "created_utc": "2026-01-02 10:27:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx90xvw",
          "author": "Worried-Lunch-4818",
          "text": "\"This workflow uses custom nodes you haven't installed yet.\n\nWanImageToVideoSVIPro\"\n\nComfy does not seem to know this node, nor can I find it with Google...",
          "score": 2,
          "created_utc": "2026-01-02 13:32:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxj4jbw",
              "author": "jhow86",
              "text": "tried everything I and AI could think of but I can't get WanImageToVideoSVIPro node to work",
              "score": 1,
              "created_utc": "2026-01-03 23:42:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxarvmf",
          "author": "roculus",
          "text": "best way to get non deteriorating long videos is to use FLF but use qwen-edit and create all of your last frames.  Sometimes it helps to work backwards.  \"A man sitting in a chair\"  then prompt \"remove man. leave everything else unchanged.\"  then you can prompt in Wan2.2 \"A man enters from the right and sits in the chair. You'll get the exact man you wanted sitting in the chair and ending in the pose to start next frame.  \"change image: the man in the chair is standing in a kitchen scrambling eggs\"  Wan2.2 \"Man gets out of chair and goes to kitchen and scrambles eggs. Wan2.2 will take care of the rest. You can go as long as you want. just make sure what you instruct between images can be done in 6 seconds or less or you'll get transitions.  Check images for consistency (clothes unchanged etc)",
          "score": 2,
          "created_utc": "2026-01-02 18:45:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxki4jt",
              "author": "Ramdak",
              "text": "The issue with that approach, is that each video doesn't understand the motion of the previous one, so it all ends in a stop-go way for each block. SVI comes to help keep the previous motion smooth.",
              "score": 1,
              "created_utc": "2026-01-04 04:18:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxatxg6",
          "author": "Perfect-Campaign9551",
          "text": "I've been trying video for a long time and I just don't think it's useful for much other than short dumb videos. It's too hard to get actual consistency and you have little control over the action, requiring a lot of redos. Which takes a lot more time then you would think. Even the closed source models are really unreliable in generation\n\n\nWhenever you see someone's video that \"looks finished\" they probably had to gen that thing 20 times to get what they wanted, and that's just one chunk of the video, most have many chunks. If you are paying for an online service that's a lot of wasted \"credits\" just burning on nothing\n\n\nI want to like doing video and want to think it's going to allow people to make stories but it just not good enough, not easy enough to use, too unpredictable, and too slow right now. Even the online tools aren't much better from my testing .",
          "score": 2,
          "created_utc": "2026-01-02 18:54:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxcfzhc",
          "author": "PrysmX",
          "text": "It's crazy thinking where we were just a year ago and now we're pumping out Avatar movie clips lol.",
          "score": 2,
          "created_utc": "2026-01-02 23:44:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxd9v4v",
          "author": "ambelamba",
          "text": "Avatar 5: Budget $250k. Domestic Box Office: $300mil.\n\nW for the grumpy old man.",
          "score": 2,
          "created_utc": "2026-01-03 02:33:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxj1u50",
          "author": "DJ_Naydee",
          "text": "This is some incredible work bud. Well done.",
          "score": 2,
          "created_utc": "2026-01-03 23:28:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxk6x06",
              "author": "Fresh_Diffusor",
              "text": "thank you",
              "score": 1,
              "created_utc": "2026-01-04 03:11:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx6wvbc",
          "author": "leftonredd33",
          "text": "I noticed all of the stitches & seams. Why does it look slow motion?",
          "score": 4,
          "created_utc": "2026-01-02 03:18:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx929b9",
              "author": "hurrdurrimanaccount",
              "text": "they used a shitmix lora merge model and bad sampler settings",
              "score": 0,
              "created_utc": "2026-01-02 13:40:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx69mln",
          "author": "jj_HeRo",
          "text": "This is already done with AI, you need the actors for human expressions that make sense.",
          "score": 4,
          "created_utc": "2026-01-02 00:56:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6mg94",
          "author": "Valuable_Weather",
          "text": "I get this\n\nFailed to validate prompt for output 427:  \n\\* WanAdvancedI2V 476:  \n\\- Value 0.0 smaller than min of 1.0: structural\\_repulsion\\_boost  \nOutput will be ignored  \nFailed to validate prompt for output 444:  \n\\* WanAdvancedI2V 477:  \n\\- Value 0.0 smaller than min of 1.0: structural\\_repulsion\\_boost  \n\\* WanAdvancedI2V 478:  \n\\- Value 0.0 smaller than min of 1.0: structural\\_repulsion\\_boost  \nOutput will be ignored  \nFailed to validate prompt for output 428:  \nOutput will be ignored  \nFailed to validate prompt for output 458:  \nOutput will be ignored  \nPrompt executed in 0.05 seconds\n\n\n\nWhat am I doing wrong?",
          "score": 2,
          "created_utc": "2026-01-02 02:14:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx6mxou",
              "author": "Fresh_Diffusor",
              "text": "set structural\\_repulsion\\_boost to 1.5 on all nodes. I also had that, bug with the workflow that breaks the default for value.",
              "score": 11,
              "created_utc": "2026-01-02 02:17:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx7pw94",
                  "author": "reynadsaltynuts",
                  "text": "If anyone else was missing getting this error but missing the setting on the node itself, you need to be on the nightly version of the node.",
                  "score": 3,
                  "created_utc": "2026-01-02 06:44:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx87pl4",
                  "author": "Corleone11",
                  "text": "Thanks, I had the same error initially. It seems to be working now.",
                  "score": 2,
                  "created_utc": "2026-01-02 09:30:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxg9gu6",
                  "author": "Mirandah333",
                  "text": "https://preview.redd.it/8run7tszj5bg1.png?width=390&format=png&auto=webp&s=70a506b0ff1af7f6384105f31017e0a3974687fb\n\nbesides structural repulsion boost anything more to be changed? a lot of values on my node are just set to O :(((  I am getting no animation at all, just the same static image i added",
                  "score": 1,
                  "created_utc": "2026-01-03 15:26:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx7ecm6",
              "author": "1987melon",
              "text": "me too",
              "score": 1,
              "created_utc": "2026-01-02 05:13:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx6rk6j",
          "author": "KanzenGuard",
          "text": "I haven't tried any video stuff yet but this is pretty cool and good to know. Thanks for sharing.",
          "score": 2,
          "created_utc": "2026-01-02 02:45:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8gknp",
          "author": "reyzapper",
          "text": "It's indeed amazing, i can't notice the cut.\n\nthe only issue i have is it's ignoring my second prompt completely, any idea why??\n\nafter undressing she should walks toward the viewer or camera but instead she is dressing up again üòÇ\n\nmp4 result : [https://filebin.net/mja82hf79quu3157](https://filebin.net/mja82hf79quu3157)\n\n4 steps, cfg 1, 6gb vram, Q4\\_KM gguf, the author of the node said avoid any quant model as possible but fuck it, lets do this and it still works flawlessly lmao\n\nim using this model : [https://huggingface.co/jayn7/WAN2.2-I2V\\_A14B-DISTILL-LIGHTX2V-4STEP-GGUF/tree/main](https://huggingface.co/jayn7/WAN2.2-I2V_A14B-DISTILL-LIGHTX2V-4STEP-GGUF/tree/main)\n\nthx for the workflow\n\nhttps://i.redd.it/oqc3jzj41xag1.gif",
          "score": 2,
          "created_utc": "2026-01-02 10:53:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx8oyrq",
              "author": "PossibilityLarge8224",
              "text": "You've changed the model loaders for gguf, right?",
              "score": 1,
              "created_utc": "2026-01-02 12:06:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx8qqrw",
                  "author": "reyzapper",
                  "text": "yup",
                  "score": 2,
                  "created_utc": "2026-01-02 12:20:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxd4lhr",
              "author": "PinkMelong",
              "text": "Thanks Ray. finally legit workflow that works.",
              "score": 1,
              "created_utc": "2026-01-03 02:02:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx81mf8",
          "author": "cepasfacile",
          "text": "This is terrible.",
          "score": 2,
          "created_utc": "2026-01-02 08:32:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx63cv5",
          "author": "Sixhaunt",
          "text": "I would love if you could expand on it a bit. Like this is a 19 second clip so is that two 10s segments that it made seamlessly or was there four 5 second clips which means more transitions it's doing properly?",
          "score": 1,
          "created_utc": "2026-01-02 00:21:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx64g53",
              "author": "Fresh_Diffusor",
              "text": "4 clips each 5 seconds. could do much more than just 4. I just want to be quick to post cool video so I didn't want to wait for longer generation.  \nthe fact you ask how many clips is good, that means you cannot see how many transitions there are, so it works well.",
              "score": 4,
              "created_utc": "2026-01-02 00:27:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx69uk9",
          "author": "FitzUnit",
          "text": "This is awesome!!! It took 340 seconds for the 20 second clip? On what type of gpu? How long did it take to interpolate and did you try upscaling at all?",
          "score": 1,
          "created_utc": "2026-01-02 00:57:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx6afi9",
              "author": "Fresh_Diffusor",
              "text": "Yes, 340 seconds generation time for 20 second clip. my GPU is RTX 5090. The interpolate step from 16 to 32 only take 3 seconds, RIFE interpolation is very fast. I have not tried upscaling yet, but I sure that SeedVR2 could make it 1920x1080 easy. Just take longer.",
              "score": 3,
              "created_utc": "2026-01-02 01:01:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx6gpr5",
                  "author": "FitzUnit",
                  "text": "Nice ! Definitely giving this a go !! Well done",
                  "score": 2,
                  "created_utc": "2026-01-02 01:39:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx6e151",
          "author": "jaywv1981",
          "text": "Im doing something wrong with mine... the transitions are very noticeable.",
          "score": 1,
          "created_utc": "2026-01-02 01:23:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx6he06",
              "author": "Fresh_Diffusor",
              "text": "are you using custom nodes and workflow from wallen0322?",
              "score": 2,
              "created_utc": "2026-01-02 01:44:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx6ibyc",
                  "author": "jaywv1981",
                  "text": "No its actually a different one. Ill try this one, thank you.",
                  "score": 2,
                  "created_utc": "2026-01-02 01:49:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx8j1jc",
              "author": "AI-Make-NSFW-Stuff",
              "text": "Yes sometimes the transitions are very noticeable, try updating the KJNodes custom\\_node, also try different seeds.",
              "score": 1,
              "created_utc": "2026-01-02 11:16:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx9m2cn",
                  "author": "Corleone11",
                  "text": "I think the transitions are noticeable the most when using holistic additional loras. There's also a color shift.",
                  "score": 1,
                  "created_utc": "2026-01-02 15:29:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx6ja41",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-02 01:55:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx6kxld",
              "author": "Fresh_Diffusor",
              "text": "fully local, no API",
              "score": 2,
              "created_utc": "2026-01-02 02:05:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx6lwvv",
          "author": "Red-Pony",
          "text": "*cries in 8gb*",
          "score": 1,
          "created_utc": "2026-01-02 02:11:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6o9kk",
          "author": "Puzzleheaded-Rope808",
          "text": "Where are the Loras for this?",
          "score": 1,
          "created_utc": "2026-01-02 02:25:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx6ovij",
              "author": "Fresh_Diffusor",
              "text": "which loras?",
              "score": 0,
              "created_utc": "2026-01-02 02:29:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx6q5rp",
                  "author": "Puzzleheaded-Rope808",
                  "text": "The vfi loras you have in the workflow",
                  "score": 1,
                  "created_utc": "2026-01-02 02:37:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx6t61u",
          "author": "Netsuko",
          "text": "Is this just more or less an infinite loop of last frame to new video? I have a workflow to generate 15s videos in 5s blocks each HOWEVER, the problem is that when a character has their eyes closed or any other features hidden, the next video has no info about that, so the longer the video went on, the more the character degraded and changed.",
          "score": 1,
          "created_utc": "2026-01-02 02:55:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx6uci8",
              "author": "Fresh_Diffusor",
              "text": "SVI adds longer context, more than just one frame. so character should stay same",
              "score": 2,
              "created_utc": "2026-01-02 03:02:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx6w8a6",
                  "author": "Netsuko",
                  "text": "Ooh alright. That might do the trick.",
                  "score": 2,
                  "created_utc": "2026-01-02 03:14:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx6u6ps",
          "author": "Gullible-Walrus-7592",
          "text": "Am i good to add my own character lora to this? Which node? (Noob)",
          "score": 1,
          "created_utc": "2026-01-02 03:01:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx6ulf1",
              "author": "Fresh_Diffusor",
              "text": "yes, you can add any lora same like in other wan 2.2 workflows. just connect it after the model loading with \"load lora\" node",
              "score": 2,
              "created_utc": "2026-01-02 03:04:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx6usn3",
          "author": "WalkSuccessful",
          "text": "The returned back slowmo is definitely is a problem with SVI. I never seen slowmo in i2v a long time before",
          "score": 1,
          "created_utc": "2026-01-02 03:05:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6z6a0",
          "author": "cjcon01",
          "text": "I've got an issue where my characters don't move or do what they are prompted to do. They just stand still talking and gesturing. Any ideas?",
          "score": 1,
          "created_utc": "2026-01-02 03:33:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxb9wmy",
              "author": "PinkMelong",
              "text": "Op updated working wf just now!",
              "score": 1,
              "created_utc": "2026-01-02 20:11:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx75ngi",
          "author": "nadhari12",
          "text": "I cannot keep the face consistent for some reason.",
          "score": 1,
          "created_utc": "2026-01-02 04:15:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7jj9p",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-02 05:52:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7u8sa",
          "author": "NeatUsed",
          "text": "if i make a character turn around and then back again will they keep the same face even if they turn back after 30 secs?",
          "score": 1,
          "created_utc": "2026-01-02 07:23:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7u8zs",
          "author": "xbobos",
          "text": "Avatar characters give the illusion of maintaining consistency compared to real people, but in reality, it's quite difficult to preserve a person's consistency using SVI.",
          "score": 1,
          "created_utc": "2026-01-02 07:23:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7xg1m",
          "author": "Vurgrimer",
          "text": "It would be cool to have a workflow where you can add images with thenpropts to either:\n\nA) add or swap faces (or just make sure it stays the same)\n\nB) use images as imputs, to match the end image of previous animation and use it as a start image for the next animation (thus connecting animation mockup images). With this you would have more control over the animation without describing with text so much. \n\nI think about my sister who is doing 3D animation and how could she use this for her work.",
          "score": 1,
          "created_utc": "2026-01-02 07:53:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7ytt7",
          "author": "cardioGangGang",
          "text": "Is the quality still the same as wan animate? I find wan animate gets softer.¬†",
          "score": 1,
          "created_utc": "2026-01-02 08:06:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx809zz",
          "author": "saito200",
          "text": "1280x720 20 seconds... i wonder how many hours it would take in my computer üòÖ",
          "score": 1,
          "created_utc": "2026-01-02 08:19:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx82nxx",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-02 08:42:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxa1u2o",
              "author": "Bogante_Castiel",
              "text": "Yo tengo exactamente lo mismo y puedo generar videos en 480p de 15 segundos en menos de 5 minutos.",
              "score": 2,
              "created_utc": "2026-01-02 16:44:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx8hebg",
          "author": "Felipesssku",
          "text": "They have way better now probably even Avatar 3 was made using it just they won't tell.",
          "score": 1,
          "created_utc": "2026-01-02 11:01:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8hlqe",
          "author": "ronbere13",
          "text": "Not working for me...Grey noise output",
          "score": 1,
          "created_utc": "2026-01-02 11:03:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxd739v",
              "author": "Fresh_Diffusor",
              "text": "use SVI lora from kijai, not from official repo",
              "score": 1,
              "created_utc": "2026-01-03 02:17:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxei39k",
                  "author": "ronbere13",
                  "text": "have the kijai svi loras...",
                  "score": 1,
                  "created_utc": "2026-01-03 07:46:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx8km0l",
          "author": "PossibilityLarge8224",
          "text": "Trying to use SVI 2 pro loras, I'm getting multiple \"lora key not loaded: blocks...\"  \nThis might be because I'm using the wan2.2 gguf version, right?  \nAnyone had this issue?",
          "score": 1,
          "created_utc": "2026-01-02 11:29:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxd763v",
              "author": "Fresh_Diffusor",
              "text": "I also get \"lora key not loaded\" in log, but it not causing issue. just ignore",
              "score": 1,
              "created_utc": "2026-01-03 02:17:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx8ky39",
          "author": "ACTSATGuyonReddit",
          "text": "What GPU?",
          "score": 1,
          "created_utc": "2026-01-02 11:32:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxd76zj",
              "author": "Fresh_Diffusor",
              "text": "5090",
              "score": 1,
              "created_utc": "2026-01-03 02:18:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx8mngm",
          "author": "Consistent_Pick_5692",
          "text": "is there a way to make it somehow frame to frame?",
          "score": 1,
          "created_utc": "2026-01-02 11:47:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8mxom",
          "author": "Consistent_Pick_5692",
          "text": "anyone found a solution for the prompt? it only follows the first prompt basically",
          "score": 1,
          "created_utc": "2026-01-02 11:49:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx8wa0n",
              "author": "ToughAppointment2556",
              "text": "I am getting the same. Wonder if it is something to do with the high/low start/mid/end strength settings but cannot find any info on them.\nGet sick of all the nodes with a hundred settings and no clue, even on their GitHub, as to what they do or what to set them to.",
              "score": 1,
              "created_utc": "2026-01-02 13:01:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxb8iai",
              "author": "PinkMelong",
              "text": "Op just updated wf that works man",
              "score": 1,
              "created_utc": "2026-01-02 20:04:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx8ne12",
          "author": "JahJedi",
          "text": "Did you used only low noise or whit the high noise (lora) for the character?",
          "score": 1,
          "created_utc": "2026-01-02 11:53:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8o017",
          "author": "fatberg_slim",
          "text": "Thanks for sharing the WF. Actually the overlap is visible in my case with 5 frames and linear\\_blend. Any idea what could be causing this?",
          "score": 1,
          "created_utc": "2026-01-02 11:58:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8qh67",
          "author": "MaveRick009_",
          "text": "prompt a screenplay!",
          "score": 1,
          "created_utc": "2026-01-02 12:18:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8tylw",
          "author": "RemoveHealthy",
          "text": "It actually looks like there are transitions. Animations looks like they are transitioning all over the place, on her face and movements.",
          "score": 1,
          "created_utc": "2026-01-02 12:45:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8upj8",
          "author": "RyanGosaling",
          "text": "AI video is a promising technology for sure, but WAN 2.2 is not it. You could even take the best video gen models we have currently (publicly released) and even they are not reliable enough to make a movie. \n\nThey lack consistency, accuracy, and the most important, they lack subtle meaning behind those pretty images.\n\nAs soon as I can spot an error made by the AI, the immersion is ruined.",
          "score": 1,
          "created_utc": "2026-01-02 12:50:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8uqca",
          "author": "sepalus_auki",
          "text": "still needs comfyui.",
          "score": 1,
          "created_utc": "2026-01-02 12:51:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8uxb4",
          "author": "Valuable_Weather",
          "text": "I don't know what I do wrong but I can clearly see the stiching between clips. Is there a setting I need to change?",
          "score": 1,
          "created_utc": "2026-01-02 12:52:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8w0zm",
          "author": "handsy_octopus",
          "text": "I cant get the node to show up in Stability Matrix on my 5070ti, anybody got any ideas?",
          "score": 1,
          "created_utc": "2026-01-02 13:00:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx95kbc",
          "author": "Professional_Foot530",
          "text": "I tried to run it but it keeps telling me that sageattention isnt installed and i dont know how to install it. Could someone pls help me?",
          "score": 1,
          "created_utc": "2026-01-02 14:00:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx968o3",
          "author": "Nuchtergaming",
          "text": "Is it possible to upload a existing video and extend it?",
          "score": 1,
          "created_utc": "2026-01-02 14:03:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxa2clk",
          "author": "fluce13",
          "text": "When I try to run it the Wan Advanced I2V node just lights up red, what am I doing wrong?\n\nhttps://preview.redd.it/4gpqk5xjtyag1.png?width=589&format=png&auto=webp&s=e3a0951a670fd6c1774b6e2fe8e926ecf6f8cdb2",
          "score": 1,
          "created_utc": "2026-01-02 16:47:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxbjd7b",
              "author": "0roborus_",
              "text": "Idk if you fixed it but for me it was the 'structural\\_repulsion\\_boost' which needs to have value >= 1.0",
              "score": 3,
              "created_utc": "2026-01-02 20:57:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxaabf9",
          "author": "MrHumhead",
          "text": "I can't get smooth transitions between batches.\nOverlap 5: Hard stutter (looks like it rewinds a few frames).\nOverlap 12+: Massive ghosting/blur. Tried everything in between.  Does anyone have a \"magic number\" for Overlap, or a different setting to stop the motion reset at the cut?",
          "score": 1,
          "created_utc": "2026-01-02 17:24:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxalkq4",
          "author": "Lewd_Dreams_",
          "text": "Great",
          "score": 1,
          "created_utc": "2026-01-02 18:16:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxaudny",
          "author": "Prestigious_Peak6314",
          "text": "Hey guys, I'm pretty new to this topic.  \nHow can I install Wan 2.2 easily without struggle?  \nI don't understand anything at all lol",
          "score": 1,
          "created_utc": "2026-01-02 18:56:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxb19ql",
              "author": "rookan",
              "text": "youtube lol",
              "score": 1,
              "created_utc": "2026-01-02 19:29:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxc4ifb",
                  "author": "Prestigious_Peak6314",
                  "text": "i only find useless videos..",
                  "score": 1,
                  "created_utc": "2026-01-02 22:42:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxavxvl",
          "author": "Orange_33",
          "text": "wow! is there a T2V workflow also for this?",
          "score": 1,
          "created_utc": "2026-01-02 19:04:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxd7byn",
              "author": "Fresh_Diffusor",
              "text": "I  know only I2V workflow",
              "score": 2,
              "created_utc": "2026-01-03 02:18:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxb1s77",
          "author": "PaintingSharp3591",
          "text": "All I need now is SVI-InfiniteTalk",
          "score": 1,
          "created_utc": "2026-01-02 19:31:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxb4zya",
          "author": "Ur3rdIMcFly",
          "text": "You still have to make Avatar first",
          "score": 1,
          "created_utc": "2026-01-02 19:47:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxb5kwo",
          "author": "hurrdurrimanaccount",
          "text": "so it's just still context windows? this makes it exactly zero different from the already existing context window workflows.",
          "score": 1,
          "created_utc": "2026-01-02 19:50:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxb9nj0",
          "author": "roychodraws",
          "text": "today i learned there was an avatar 3",
          "score": 1,
          "created_utc": "2026-01-02 20:09:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxbikhj",
          "author": "1563648645",
          "text": "its remarkable - but still doesnt gets vectorial precision.",
          "score": 1,
          "created_utc": "2026-01-02 20:53:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxbjf4f",
          "author": "aaatings",
          "text": "If they start using this how will they be able to do hollywood accounting?(Money laundering, turning black money into white etc).",
          "score": 1,
          "created_utc": "2026-01-02 20:57:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxbjpt6",
          "author": "b00st3d",
          "text": "> Someone tell James Cameron he can get Avatar 4 done sooner and cheaper\n\nAnd also a lot less good looking.",
          "score": 1,
          "created_utc": "2026-01-02 20:59:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxbxtr9",
          "author": "hilberteffect",
          "text": "No visible transitions? Nice work but it's jumpy as hell, brother.",
          "score": 1,
          "created_utc": "2026-01-02 22:07:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxcrbvh",
          "author": "VirusCharacter",
          "text": "I only get slow motion... As usual :/",
          "score": 1,
          "created_utc": "2026-01-03 00:46:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxcyf9a",
          "author": "asabado123",
          "text": "I don't know much about this stuff but I'd like to get started. I have a dual Xeon e5 2699 v4, 256gb ram, 10gb 3080, windows 11. Can I run this stuff?",
          "score": 1,
          "created_utc": "2026-01-03 01:27:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxd290t",
              "author": "Fresh_Diffusor",
              "text": "yes",
              "score": 2,
              "created_utc": "2026-01-03 01:49:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxd4mgy",
          "author": "OKAwesome121",
          "text": "The only reason this can exist is because the models can reference the original works from the movies.",
          "score": 1,
          "created_utc": "2026-01-03 02:03:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxdgmgz",
          "author": "MLDataScientist",
          "text": "!remindme 10 days \"try this out in your 5090\"",
          "score": 1,
          "created_utc": "2026-01-03 03:13:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxdgr7l",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 10 days on [**2026-01-13 03:13:44 UTC**](http://www.wolframalpha.com/input/?i=2026-01-13%2003:13:44%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/StableDiffusion/comments/1q1jmz7/svi_20_pro_for_wan_22_is_amazing_allowing/nxdgmgz/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FStableDiffusion%2Fcomments%2F1q1jmz7%2Fsvi_20_pro_for_wan_22_is_amazing_allowing%2Fnxdgmgz%2F%5D%0A%0ARemindMe%21%202026-01-13%2003%3A13%3A44%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201q1jmz7)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-01-03 03:14:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxdgqmp",
          "author": "Select_Truck3257",
          "text": "yeah yeah 20 seconds movie. can it make 3 hours without changing the number of fingers and actors faces every 20 seconds?",
          "score": 1,
          "created_utc": "2026-01-03 03:14:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxdq8o0",
          "author": "Whispering-Depths",
          "text": "did you specifically ask it for a half-naked child na'vi with a criss-cross halter underboob top or did it just make that on its own?",
          "score": 1,
          "created_utc": "2026-01-03 04:13:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxdqh7i",
          "author": "Unzensierte",
          "text": "I have a 4080 and can't seem to generate even 5 second clips without memory issues. It only happens with comfyui though. Videos haven't been helpful getting it to work for me. This looks amazing though.",
          "score": 1,
          "created_utc": "2026-01-03 04:15:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxdqwdx",
          "author": "Sudden_List_2693",
          "text": "For me no matter what I prompt, from the first extension it will just... stop moving. I mean it will do very minor motions, but that's it.",
          "score": 1,
          "created_utc": "2026-01-03 04:17:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxea7r0",
          "author": "Flimsy-Finish-2829",
          "text": "More information about their user feedback from github issue: \"I've been able to create some great things already, and I do not have the slow motion issue; using WAN 2.2 high fp16 with a decent amount of steps and only a small portion with lightx2v.\" It seems that Fp16+more sampling steps can solve the slow motion. :)",
          "score": 1,
          "created_utc": "2026-01-03 06:39:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxel86c",
          "author": "Smash_3001",
          "text": "Youre joking with the last sentences right xD",
          "score": 1,
          "created_utc": "2026-01-03 08:13:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxk76d0",
              "author": "Fresh_Diffusor",
              "text": "yes. this is not near good enough yet for real avatar movie",
              "score": 1,
              "created_utc": "2026-01-04 03:13:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxem55c",
          "author": "Upset-Virus9034",
          "text": "i am having this issue with your workflow and tips? \n\nhttps://preview.redd.it/oppbu829g3bg1.png?width=1896&format=png&auto=webp&s=30ad7147aef18ab884f64b5c355b7710d06ff04e",
          "score": 1,
          "created_utc": "2026-01-03 08:21:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxg3k61",
          "author": "Aggravating-Age-1858",
          "text": "now they just need to make wan 2.6 open source lol\n\nthey should open source their older models down the road lol",
          "score": 1,
          "created_utc": "2026-01-03 14:55:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxhr0xc",
          "author": "plex4ever",
          "text": "Hi, really ignorant American here (yes, we are certainly on a roll lately as a country) Is there a way to translate nodes coded in other languages in Comfy?",
          "score": 1,
          "created_utc": "2026-01-03 19:35:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxiepvm",
          "author": "sketchfag",
          "text": "This shit is too complex for me, who has a quick and easy way to run workflows without having to download a million loras and models?",
          "score": 1,
          "created_utc": "2026-01-03 21:32:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxo5ied",
          "author": "Aggressive_Gur1441",
          "text": "only gonna get better from here",
          "score": 1,
          "created_utc": "2026-01-04 18:42:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxpchjm",
          "author": "polandtown",
          "text": "sick",
          "score": 1,
          "created_utc": "2026-01-04 21:57:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxqrsf5",
          "author": "R34vspec",
          "text": "I am getting an missing node: WanImageToVideoSVIPro, is there a HF link for the node for manual installation?\n\n  \nthank you,",
          "score": 1,
          "created_utc": "2026-01-05 02:15:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxrvgue",
          "author": "New_Dealer6000",
          "text": "Keep having Noise output.  i have the workflow and the hig/low stuff but all i have is a noise output.",
          "score": 1,
          "created_utc": "2026-01-05 06:16:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxs50ev",
          "author": "StuffProfessional587",
          "text": "Has someone tried it with ditto sim2real? 100 words on wan 2.1 for less than 3 seconds, and the conversion isn't accurate to the input.",
          "score": 1,
          "created_utc": "2026-01-05 07:38:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxw6i2b",
          "author": "AhmedAbdu",
          "text": "Its all in chinese, no clue whats going on.\n\n~~Also where do i get the svi stuff?~~",
          "score": 1,
          "created_utc": "2026-01-05 21:43:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxxa5ot",
          "author": "Practical-Topic-5451",
          "text": "Hey guys, trying to use SVI workflows but cannot install ImageBatchExtendWithOverlap node via Manager. Already updated Comfy and [**ComfyUI-KJNodes**](https://github.com/kijai/ComfyUI-KJNodes) to the latest but this node still stays red. Any idea?\n\nhttps://preview.redd.it/rk8yhnv8pmbg1.png?width=617&format=png&auto=webp&s=42dc8f9366917a4e6390f1bebf39510234466d2f\n\nSOLVED: Had to delete/clone KjNodes repo",
          "score": 1,
          "created_utc": "2026-01-06 01:05:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny26t2x",
          "author": "christopher-allen80",
          "text": "I‚Äôve been using this for a day now but clips still are not transitioning smooth. What setting do I need to change?",
          "score": 1,
          "created_utc": "2026-01-06 19:20:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3nxoh",
          "author": "hammerklau",
          "text": "Cameron said himself, we‚Äôre looking for excellence, not average.",
          "score": 1,
          "created_utc": "2026-01-06 23:29:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny7jrk8",
          "author": "Maskwi2",
          "text": "I get visible overlap/transition between the clips :( Not sure why. I'm using the workflow posted by thread starter. Any particular setting I should tweak?¬†",
          "score": 1,
          "created_utc": "2026-01-07 15:00:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nycm70i",
          "author": "Maleficent-Rice-2046",
          "text": "https://preview.redd.it/zwqf3zi6e2cg1.png?width=1736&format=png&auto=webp&s=a3492072e1c265b0a6b01985f92f48d013f1f37a\n\nHe  intentado pero me sale el output negro, alguien sabe a qu√© se debe porfa¬°?",
          "score": 1,
          "created_utc": "2026-01-08 05:51:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx73s92",
          "author": "mk8933",
          "text": "This is mind-blowing üî• you could seriously make a movie or at least a concept trailer. Before AI people had only rough sketches or what the scenes would look like and that took them maybe a few hours to get together.\n\nNow they can quickly get near perfect clips like yours and show it to the team...it would be more crazy if it had audio as well.",
          "score": 1,
          "created_utc": "2026-01-02 04:03:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx88j7d",
          "author": "liccman",
          "text": "Avatar from Wish. This looks like shit",
          "score": 0,
          "created_utc": "2026-01-02 09:38:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6qkpx",
          "author": "jadhavsaurabh",
          "text": "Wow pretty fast",
          "score": 1,
          "created_utc": "2026-01-02 02:39:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx70bmz",
          "author": "coffeecircus",
          "text": "thank you for sharing - this is really making things a lot more interesting story than what a 5 sec clip can tell",
          "score": 1,
          "created_utc": "2026-01-02 03:40:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx72i1d",
          "author": "aTypingKat",
          "text": "It took 20 minutes to generate 15 seconds on my 4060 ti 8gb quantized to fit in vram",
          "score": 1,
          "created_utc": "2026-01-02 03:54:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx82oyd",
          "author": "EpicNoiseFix",
          "text": "It‚Äôs free so there is a lot of improvement needed. You want to look worlds better? You would have to pay for a closed source model/platform",
          "score": 1,
          "created_utc": "2026-01-02 08:43:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxap409",
          "author": "dejayc",
          "text": "I mean to be honest, that movement looks like total shit",
          "score": 0,
          "created_utc": "2026-01-02 18:32:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx9a0lh",
          "author": "AlienGoat_",
          "text": "Ugh, finally. I've always wished that avatar 4 would be a cheap, actorless, low quality ai slop fest\n\nMuch rather have ai make movies instead of having actors. Maybe eventually we will get ai actors which will be featured across multiple films, they are much cheaper and faster than hiring real people right?",
          "score": -1,
          "created_utc": "2026-01-02 14:25:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8blm2",
          "author": "Horror-Indication-92",
          "text": "But there are people who say \"generative AI is bad, it takes away jobs\", so because of this, we don't use humanity's one of the greatest inventions... :D",
          "score": 0,
          "created_utc": "2026-01-02 10:07:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx91d67",
          "author": "Humble-Worker-1743",
          "text": "Very confused with what is happening in the video. How is this technology keep getting better at rendering textures and light but still cant understand how things exist and act in reality?",
          "score": 0,
          "created_utc": "2026-01-02 13:34:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxbnplf",
              "author": "FourtyMichaelMichael",
              "text": "Dude... fuuuuuuuck ooooooooff..\n\nHoly shit, some of you have no concept that the entiretly of generative AI has been like 3 years.\n\nSDXL iirc isn't even 2 years old.\n\n\n\"OH IT DOESN'T LOOK THAT PERFECT THO!!\".... fucking insane.",
              "score": 5,
              "created_utc": "2026-01-02 21:18:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxj4t4r",
                  "author": "Humble-Worker-1743",
                  "text": "Well Ai has had the same issue since its inception. There have been 0 improvements on anything other then rendering of textures",
                  "score": 0,
                  "created_utc": "2026-01-03 23:44:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx8ljhl",
          "author": "blazelet",
          "text": "This really is another example of how AI can‚Äôt do anything well until humans do it well first.\n\nMake something like this that‚Äôs completely your own, not taken from artists.",
          "score": -1,
          "created_utc": "2026-01-02 11:38:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx8lrrs",
              "author": "alb5357",
              "text": "You could, of course, you'd be doing some work as well, creating original loras etc... so yes, rooted in human creativity. And I kinda hope it stays that way, so it can be a fun tool still needing human creativity, instead of a \"make a unique innovative movie for me to watch right now\"",
              "score": 1,
              "created_utc": "2026-01-02 11:39:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx8p1ck",
                  "author": "blazelet",
                  "text": "Artists working creatively typically explore and discover as they work through the process. Meaning emerges through the act of creating. In the case of avatar, what you see on screen is the result of hundreds of hours of artist work time, discussion and dailies which have resulted in a collaborative creative effort which is refined and refined and refined and then tested and then refined again. \n\nAI predicts, selects and outputs. Meaning is not part of the creative process, it is retroactively inferred by the viewer or prompter but was not part of the decision process. What AI generates is inherently incestuous, it‚Äôs why you see so many things on this sub like this OP - it‚Äôs someone else‚Äôs idea, rebundled.\n\nAI gestures towards meaning without being responsible for it. That‚Äôs why I‚Äôd like to see people use it more intentionally, creating things that can be critiqued on their own merit and not as knock offs. Is that possible with training? I don‚Äôt see how. You can‚Äôt teach AI classicism and then use it to discover Impressionism. That takes creativity rooted in experience, something AI doesn‚Äôt have.",
                  "score": 1,
                  "created_utc": "2026-01-02 12:06:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx692sq",
          "author": "No_Damage_8420",
          "text": "Jim could render Avatar 4 overnight in his basement LOL",
          "score": -1,
          "created_utc": "2026-01-02 00:53:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx69ro2",
              "author": "Fresh_Diffusor",
              "text": ">Originally a skeptic, Cameron denounced the use of AI in films in 2023, saying he believed \"the weaponization of AI is the biggest danger.\"\n\n>\"I think that we will get into the equivalent of a nuclear arms race with AI, and if we don't build it, the other guys are for sure going to build it, and so then it'll escalate,\" Cameron said at the time.\n\n>Cameron's stance on AI¬†[has evolved in recent years](https://www.foxnews.com/entertainment/terminator-director-james-cameron-flip-flops-ai-says-hollywood-looking-all-wrong), and he now says that Hollywood needs to embrace the technology in several different ways.\n\n>Cameron joined the board of directors for Stability AI last year, explaining his decision on the \"Boz to the Future\" podcast in April.\n\n>\"The goal was to understand the space, to understand what‚Äôs on the minds of the developers,\" he said. \"What are they targeting? What‚Äôs their development cycle? How much resources you have to throw at it to create a new model that does a purpose-built thing, and my goal was to try to integrate it into a VFX workflow.\"¬†\n\n>He continued by saying the shift to AI is a necessary one.\n\n>\"And it‚Äôs not just hypothetical. We have to. If we want to continue to see the kinds of movies that I‚Äôve always loved and that I like to make and that I will go to see ‚Äî ‚ÄòDune,‚Äô¬†‚ÄòDune: Part Two‚Äô or one of my films or big effects-heavy, CG-heavy films ‚Äî we‚Äôve got to figure out how to cut the cost of that in half.\n\n[https://www.foxnews.com/media/james-cameron-says-fundamental-issue-putting-guardrails-ai-humans-cant-agree-morals](https://www.foxnews.com/media/james-cameron-says-fundamental-issue-putting-guardrails-ai-humans-cant-agree-morals)",
              "score": 3,
              "created_utc": "2026-01-02 00:57:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx7o6mf",
                  "author": "Tyler_Zoro",
                  "text": "Cameron has always wanted to be the first one to use new technology in tentpole films. He's itching to be the first person to release a billion dollar movie made with AI tools.\n\nThat being said, when he does do it, there's still going to be a team of hundreds doing the work. Rendering okay results is easy. Rendering feature film quality results is orders of magnitude harder than even [this video](https://vimeo.com/1062934927), and that took a pretty decent team.",
                  "score": 2,
                  "created_utc": "2026-01-02 06:30:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx63v2l",
          "author": "Shorties",
          "text": "Anyone got a workflow that works on comfy cloud? Comfy Cloud gives me this error: \n\n\n\nThis workflow uses custom nodes that aren't supported in the Cloud version yet.\n\neasy int\n\nFast Groups Bypasser (rgthree)\n\nWanAdvancedI2V\n\neasy globalSeed\n\nIn the meantime, replace these nodes (highlighted red on the canvas) with supported ones if possible, or try a different workflow.",
          "score": -4,
          "created_utc": "2026-01-02 00:23:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx65k7k",
              "author": "Fresh_Diffusor",
              "text": "I only do local on my GPU, never use cloud, so sorry I cant help",
              "score": 7,
              "created_utc": "2026-01-02 00:33:24",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nx66rbr",
              "author": "Sixhaunt",
              "text": "it requires you to install some custom nodes so I'm not sure if cloud can do that. rgthree and stuff are common and safe, the only thing holding me back from trying the workflow is the final custom node one: [https://github.com/wallen0322/ComfyUI-Wan22FMLF](https://github.com/wallen0322/ComfyUI-Wan22FMLF)\n\n  \nI havent installed any custom nodes with less than like 150,000 prior downloads but this one has 18,000 and is in a language I don't understand so I've held off on trying it",
              "score": 2,
              "created_utc": "2026-01-02 00:40:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx6ba4d",
                  "author": "jiml78",
                  "text": "Obviously this isn't a guarantee, but personally, I always manually clone custom nodes these days.  Then I use claude code to scan the repo for malicious code. I make sure claude code is locked to my custom nodes folder AND read only access so if someone also tried to do prompt injection, impact is limited.",
                  "score": 1,
                  "created_utc": "2026-01-02 01:06:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx66rvd",
              "author": "ANR2ME",
              "text": "If you're going with Comfy Cloud, why not using the native ComfyUI template? or kijai's workflow examples.",
              "score": 2,
              "created_utc": "2026-01-02 00:40:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx6c16y",
                  "author": "Shorties",
                  "text": "Does the native template allow for this continuous context window of frames moving through the animation? Like in these examples?",
                  "score": 2,
                  "created_utc": "2026-01-02 01:11:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx6m5zl",
              "author": "Inthehead35",
              "text": "yeah, i'm stuck too. i followed 'aisearch' youtube channel, but he says you need 'ComfyUI windows portable' version for it to work. \n\ni downloaded all the files and put them in the folders, as instructed, but for some reason, the system doesn't recognize that the files are there, so i keep getting error messages saying it can't find the files, so weird",
              "score": 1,
              "created_utc": "2026-01-02 02:13:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qae922",
      "title": "LTX-2 I2V isn't perfect, but it's still awesome. (My specs: 16 GB VRAM, 64 GB RAM)",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/icuhdpygxscg1",
      "author": "yanokusnir",
      "created_utc": "2026-01-11 23:12:05",
      "score": 1922,
      "num_comments": 331,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1qae922/ltx2_i2v_isnt_perfect_but_its_still_awesome_my/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nz28sx6",
          "author": "Scriabinical",
          "text": "What a great video. Almost feels like an ad but it's super wholesome",
          "score": 264,
          "created_utc": "2026-01-11 23:15:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz29azr",
              "author": "yanokusnir",
              "text": "Thank you. :) Yeah, I know it kind of looks like an ad, but I just wanted to share how excited I am about this model. :D",
              "score": 76,
              "created_utc": "2026-01-11 23:18:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz2lrxr",
                  "author": "CoolestSlave",
                  "text": "the quality looks great, how many try did you make to have a decent output ?",
                  "score": 19,
                  "created_utc": "2026-01-12 00:22:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz2siit",
                  "author": "Colon",
                  "text": "i think they call that EXPRESSION in the art world.",
                  "score": 4,
                  "created_utc": "2026-01-12 00:55:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz2dd1q",
              "author": "FrankNitty_Enforcer",
              "text": "The segment with the photorealistic people had like Wes Anderson movie trailer vibe to me",
              "score": 11,
              "created_utc": "2026-01-11 23:39:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2becr",
          "author": "skyrimer3d",
          "text": "i thought this was a LTX2 promo to be honest, it's really good, i'll grab that workflow and see for myself.",
          "score": 95,
          "created_utc": "2026-01-11 23:29:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2cb2i",
              "author": "yanokusnir",
              "text": "Thank you, go for it! :)",
              "score": 17,
              "created_utc": "2026-01-11 23:34:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz3luvl",
                  "author": "uxl",
                  "text": "I have an RTX 5080 Mobile (16GB VRAM) and 64GB of RAM and even though I‚Äôm able to use the default LTX-2 I2V workflow, the results are abysmal. Not a single one of my generations using the default/demo (the animated owl) turned out even remotely passable. None had a distortion-free video or audio track. I‚Äôm in bed atm, but if you could accomplish this post‚Äôs vids on a similarly system to mine using your workflow, I‚Äôm hopeful that it means it will work on mine as well ü§ûüèª",
                  "score": 10,
                  "created_utc": "2026-01-12 03:32:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz2ekg7",
          "author": "Extension_Building34",
          "text": "I‚Äôll give it a try. Prompts have been my biggest hurdle so far though.",
          "score": 26,
          "created_utc": "2026-01-11 23:46:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2i7vq",
              "author": "yanokusnir",
              "text": "Yeah, real prompt engineering is needed here. :D",
              "score": 15,
              "created_utc": "2026-01-12 00:04:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz33u4o",
                  "author": "Extension_Building34",
                  "text": "No kidding, what sort of prompts worked for you so far with this workflow? (Even just the prompts for the cherry picked results, because those at least made videos worth picking!)",
                  "score": 4,
                  "created_utc": "2026-01-12 01:55:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz67njr",
                  "author": "PestBoss",
                  "text": "Engineering term misused here methinks :D\n\nI'd suggest Good prompting that belies the otherwise apparent simple nature of AI generations.\n\nIe, effort beyond the bare minimum.",
                  "score": 0,
                  "created_utc": "2026-01-12 15:05:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz2ed3l",
          "author": "no-comment-no-post",
          "text": "The audio sounds so much better than other examples. Did you do anything extra beyond the workflow to get these audio results?",
          "score": 19,
          "created_utc": "2026-01-11 23:45:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2ff04",
              "author": "yanokusnir",
              "text": "Nope, I didn‚Äôt do anything extra to the audio. That‚Äôs just how it turned out. The videos are cherry-picked though, so don‚Äôt worry, I also had plenty of outputs that sounded terrible :D",
              "score": 26,
              "created_utc": "2026-01-11 23:50:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz35gdn",
                  "author": "Gold-Cat-7686",
                  "text": "I know the pain, but it's worth it when you get that perfect generation. Am I crazy if I suggest it's as good as closed models?",
                  "score": 4,
                  "created_utc": "2026-01-12 02:04:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz5z20r",
                  "author": "LyriWinters",
                  "text": "We're talking 1/30 cherry picking right? :) It's fine though",
                  "score": 1,
                  "created_utc": "2026-01-12 14:20:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz2gty7",
          "author": "Eisegetical",
          "text": "The biggest thing most people are overlooking - no cursed slowmo!\n\n\nSo so so many wan Gens are cursed with slowmo yet I see it very rarely on ltx.¬†",
          "score": 41,
          "created_utc": "2026-01-11 23:57:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2hojz",
              "author": "yanokusnir",
              "text": "Exactly! I know everyone says the slow motion is due to using 4step loras, but Wan is very slow compared to the LTX-2.",
              "score": 11,
              "created_utc": "2026-01-12 00:02:08",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nz41jtx",
              "author": "Gilded_Monkey1",
              "text": "So I ran ltx2 thru a wan sampler setup and it had the traditional slowmo motion I suspect if I did the reverse wan would be faster, but haven't gotten around to testing afraid if my wan broke due to updating comfyui for ltx2.",
              "score": 5,
              "created_utc": "2026-01-12 05:08:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz4ficb",
              "author": "Aestellar",
              "text": "\"24 fps\" in prompt for wan almost disable slowmo effect for me.",
              "score": 4,
              "created_utc": "2026-01-12 07:00:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz3zhhl",
              "author": "FlyNo3283",
              "text": "Weird. All I had with ltx 2 i2v have been zooms with little to no motion or very slow motion videos. I will try this workflow when I get home.",
              "score": 3,
              "created_utc": "2026-01-12 04:54:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz81qbh",
                  "author": "FlyNo3283",
                  "text": "I had a chance to do quick tests. Yes, this workflow with the novram flag yielded the best results for my setup: 5060 ti 16 GB vram + 32 GB ram. Thanks! No more still pictures or weird camera pans.",
                  "score": 1,
                  "created_utc": "2026-01-12 20:09:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz5yydf",
              "author": "LyriWinters",
              "text": "I get slowmo ALL THE TIME in LTX2 using the gguf 20gb file (cant remember if its Q8 or what)",
              "score": 1,
              "created_utc": "2026-01-12 14:20:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2h8zy",
          "author": "Aromatic-Word5492",
          "text": "This video make me happy with the infinity of possibilities. you have a good taste with camera take haha, thank you for the workflow",
          "score": 23,
          "created_utc": "2026-01-11 23:59:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2hwfw",
              "author": "yanokusnir",
              "text": "I'm glad to hear that! Thank you very much. :)",
              "score": 6,
              "created_utc": "2026-01-12 00:03:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2jvln",
          "author": "Maskwi2",
          "text": "I don't know what black magic this is but I'm hitting like 3.5gb vram lol, while doing 1280*768 81 frames for i2v for your workflow. Meanwhile it was crashing my comfy with 3x less resolution in another workflow. And when using the reserve vram flag and using 22gb of my 4090 the speedup isn't crazy over using 3.5gb, wtf :p",
          "score": 9,
          "created_utc": "2026-01-12 00:13:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2kkip",
              "author": "yanokusnir",
              "text": "Hell yeah! :D I'm happy to hear that. For me, without the --novram parameter, it also generated very long and only at low resolution, otherwise I still got OOM.",
              "score": 4,
              "created_utc": "2026-01-12 00:16:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2bw5s",
          "author": "CyberHaxer",
          "text": "Damn this shit‚Äôs scary",
          "score": 16,
          "created_utc": "2026-01-11 23:32:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2blkg",
          "author": "Skystunt",
          "text": "Now this is really well made with the song, edits and the ending with the genuine reactions",
          "score": 9,
          "created_utc": "2026-01-11 23:30:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2cl6i",
              "author": "yanokusnir",
              "text": "Thanks. :)",
              "score": 3,
              "created_utc": "2026-01-11 23:35:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2eh0w",
          "author": "thelionkingthing",
          "text": "That was amazing",
          "score": 9,
          "created_utc": "2026-01-11 23:45:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4xjjh",
          "author": "Oblivion_Man",
          "text": "No doubt as insane amount of progress from like two years ago",
          "score": 9,
          "created_utc": "2026-01-12 09:49:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2yiit",
          "author": "anydezx",
          "text": "https://preview.redd.it/c7ln8qwemtcg1.png?width=1280&format=png&auto=webp&s=5709833c748262a1e8346a02ff384f60510304d2\n\nThis's my main problem with this model. However, the solution is the lack of a LoRa for hands, object and person focus, feet, faces, and human anatomy. I say this because I saw the first LoRas in Civitai and I'm surprised by how much they improve in several of the aspects I mentioned.\n\nAlso, the best clip I've seen with complex scenes is the one uploaded by the user with an RTX 6000 Pro: [reddit.com/r/StableDiffusion/comments/1q9cy02/ltx2\\_i2v\\_quality\\_is\\_much\\_better\\_at\\_higher/](http://reddit.com/r/StableDiffusion/comments/1q9cy02/ltx2_i2v_quality_is_much_better_at_higher/), but it was created at extremely high resolutions that can't be reproduced on consumer hardware. Even so, it's not perfect, but it looks much better than this example in this clip.\n\nI know everyone loves nsfw LoRas because they create adult content, but I wish they could also create generic LoRas. I would create them, but it's impossible without the necessary datasets and the right hardware. I hope the community can help. It's not their obligation, But it would allow many of us to use this model Professionally! ü§ó\n\nAnd I hope that Ltx-2 will make improvements with an upscaler since it's the king of OEMs...",
          "score": 6,
          "created_utc": "2026-01-12 01:27:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7cafo",
              "author": "berlinbaer",
              "text": "> Even so, it's not perfect, \n\ndid you not look at the background of your example ?",
              "score": 1,
              "created_utc": "2026-01-12 18:13:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz96sos",
                  "author": "anydezx",
                  "text": "Of course I checked it; the video background has a lot of traffic and several people moving around. The distortion's minimal, with a quality similar to Wan2.2 including background sharpness.\n\nHowever, the biggest problem with LTX-2's with distant shots: it doesn't focus well and distorts people, objects, and especially hands at the resolutions used by those of us with more modest hardware. I say this because the A6000 costs more than a SUV.\n\nThe most stable shots with LTX-2're close-ups, where the subjects're more visible and the distance to the background isn't as large.\n\nI know many people don't like comparisons, but I often work with distant shots, and there's not much that can be done about it. Besides, it's unavoidable because they're currently the two best video generators, and many of us, like myself, don't need audio in some projects!üòâ",
                  "score": 1,
                  "created_utc": "2026-01-12 23:27:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz2duuz",
          "author": "Icy-Cat-2658",
          "text": "Yo can you throw your prompts up, too?  Workflow looks dope and super appreciate you sharing!  Don‚Äôt know how to add the ‚Äúno-vram‚Äù thing on a RunPod instance since it‚Äôs not windows but would like to get close to your output for sure.  Appreciate you!",
          "score": 7,
          "created_utc": "2026-01-11 23:42:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2jyoj",
              "author": "yanokusnir",
              "text": "Okay, for example, the prompt for the first shot:  \n  \n**woman sits in a relaxed living room facing a static camera and speaks directly to the lens with a clear sense of curiosity in her voice, she starts softly and says ‚ÄúSo‚Ä¶‚Äù then pauses briefly while holding eye contact, during the pause her eyes quickly dart from side to side in a playful curious way before locking back onto the lens, after the pause she leans in very close toward the camera until her face nearly fills the frame, her expression is inquisitive and slightly teasing as she finishes the line saying ‚Äúis it any good?‚Äù, immediately after speaking she gives a small restrained chuckle under her breath and eases back just a little, the camera remains completely still throughout**\n\n(I always have my prompts improved using chatgpt). I'm also attaching a photo if you'd like to try it. Unfortunately, I don't know what the options are with RunPod. :/\n\nhttps://preview.redd.it/we7tz9129tcg1.png?width=1920&format=png&auto=webp&s=b1668c873ac5963dd431fdf9033ef5484125caa8",
              "score": 22,
              "created_utc": "2026-01-12 00:13:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz2nur6",
                  "author": "justa_hunch",
                  "text": "Is... that a real photo? Or also AI. Just curious.",
                  "score": 5,
                  "created_utc": "2026-01-12 00:33:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz2r6om",
                  "author": "Icy-Cat-2658",
                  "text": "Thanks!!  Anything you prompt ChatGPT with as a system prompt in advance?",
                  "score": 1,
                  "created_utc": "2026-01-12 00:49:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz5shkk",
                  "author": "Zebidee",
                  "text": "Did you specifically prompt for Australian accents with the voices?",
                  "score": 1,
                  "created_utc": "2026-01-12 13:45:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz2jc7s",
          "author": "Choowkee",
          "text": "I really like your workflow. Are you a euler enjoyer as well?\n\nTo me it produces significantly more coherent videos compared to the often recommended res_2s, at least for I2V.\n\n>There‚Äôs still plenty of room for improvement. Face consistency is pretty weak. Actually, consistency in general is weak across the board. \n\nYeah that + wide shot face distortions are the two things I wished could be improved for I2V. WAN 2.2 is still better in that regard.",
          "score": 7,
          "created_utc": "2026-01-12 00:10:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2uel2",
              "author": "yanokusnir",
              "text": "Thank you very much, yes I am also a euler enjoyer. :D I completely agree. Wan is still very good, but this model is the first open-source one that comes close to Sora or Veo. And it's actually pretty good. :)",
              "score": 5,
              "created_utc": "2026-01-12 01:05:33",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nz4dqnt",
              "author": "GrayingGamer",
              "text": "Yes! Include me in the Euler fan club. In my tests Euler always looks better than Res\\_2s. Res\\_2s just always looks over-detailed and over-saturated, but I guess some people consider that \"better\".",
              "score": 3,
              "created_utc": "2026-01-12 06:44:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz4tr03",
              "author": "Maskwi2",
              "text": "I'm using lcm, which is also very good :)¬†",
              "score": 3,
              "created_utc": "2026-01-12 09:12:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz96d40",
                  "author": "Cute_Ad8981",
                  "text": "Oh LCM is one of my favourites, but I still have to try it with ltx",
                  "score": 1,
                  "created_utc": "2026-01-12 23:24:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz4qsdy",
              "author": "benfavre",
              "text": "> consistency\n\nI'd say that consistency will be hard to achieve with low VRAM as you would need a precise attention mechanism over long (temporal) sequences.",
              "score": 1,
              "created_utc": "2026-01-12 08:43:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz6hhiy",
              "author": "ninjazombiemaster",
              "text": "Try Gradient Estimation. I much prefer higher count, faster steps than Res_2s. Maybe it's anecdotal but so far I'm finding Res is ruining the audio quality on the 3 step upscale pass. If I just do 6 steps with GE instead it seems less distorted.¬†\n\n\nI graphed their esoteric seeming \"manual\" sigmas and they are literally just a linear quadratic schedule. 1.0 denoise on the 8 step and 0.4¬†denoise on the upscale.¬†\n\n\nSo with that knowledge you can replace the 8+3 schedule with something that has more steps if Euler/GE under samples when using distillation rather than needing something that is 2x as heavy.¬†",
              "score": 1,
              "created_utc": "2026-01-12 15:53:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz98j8i",
                  "author": "Cute_Ad8981",
                  "text": "I found that gradient estimation works well in a 2nd sampler for upscaling/refining. I'm running at the moment 8-16 steps Euler + 2 - 3 steps Gradient Estimation.  \n\nIf I want more speed I combine the first sampler with the distilled Lora and run it with cfg 1.  \n\nI also replaced all the samplers with the normal advanced ksamplers and ltx works well with the normal schedulers.  \n\nIt's fascinating how easily new workflows improve speed and quality.",
                  "score": 1,
                  "created_utc": "2026-01-12 23:36:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz2oeok",
          "author": "desbos",
          "text": "Man the amount of videos I had that was just zooming into my image and panning across the image slowly, I thought it was only me. \nI‚Äôll checkout this workflow",
          "score": 6,
          "created_utc": "2026-01-12 00:35:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2p0vq",
              "author": "yanokusnir",
              "text": "Fingers crossed. :))",
              "score": 3,
              "created_utc": "2026-01-12 00:38:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2oxg0",
          "author": "ImNotARobotFOSHO",
          "text": "That's a great showcase man, good job.",
          "score": 5,
          "created_utc": "2026-01-12 00:38:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2p3r0",
              "author": "yanokusnir",
              "text": "Thank you :)",
              "score": 3,
              "created_utc": "2026-01-12 00:39:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2b9xa",
          "author": "Romando1",
          "text": "Really nice job!!!",
          "score": 5,
          "created_utc": "2026-01-11 23:29:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3oclm",
          "author": "ChromaBroma",
          "text": "Thanks OP.  The clip loader in the workflow caused OOM (system memory) for me. That node also doesn't play nice with sageattention. So I changed it to Gemma 3 Model Loader and no more issues. Maybe this is specific to my environment but thought I'd mention it. Thanks for sharing.",
          "score": 5,
          "created_utc": "2026-01-12 03:46:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7cj1l",
              "author": "yanokusnir",
              "text": "I‚Äôm glad you managed to tweak it and get it working. :)",
              "score": 3,
              "created_utc": "2026-01-12 18:14:39",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nz4faxt",
              "author": "GrayingGamer",
              "text": "I had to do the same thing, but then this workflow worked great for me. Got a token error with the original clip loader node, and had to switch to the Gemma 3 Model Loader node like you.",
              "score": 1,
              "created_utc": "2026-01-12 06:58:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz45klh",
          "author": "Valkymaera",
          "text": "I am having trouble getting good results on a 3090 (24 gb VRAM) with 128gb RAM, using the default workflow. Some custom workflows from reddit just hang forever. I am quite certain it is a me-problem.\n\nThe default runs, but the quality is way below WAN.\n\nStill trying to nail down something reliable that works. I'll try yours out, thanks for sharing.",
          "score": 6,
          "created_utc": "2026-01-12 05:38:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5rlyo",
              "author": "yanokusnir",
              "text": "Let me know how it goes.",
              "score": 1,
              "created_utc": "2026-01-12 13:40:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz4vtnf",
          "author": "Prestigious_Cat85",
          "text": "https://preview.redd.it/1ykrw1061wcg1.png?width=607&format=png&auto=webp&s=1b1a9150f6a2cdf1cbe2358eaf3024cd2bc86205\n\nI keep getting this ... there's no such node in costum nodes ... any idea ? ty",
          "score": 5,
          "created_utc": "2026-01-12 09:32:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4xn6y",
              "author": "protector111",
              "text": "update everyting and comfy",
              "score": 1,
              "created_utc": "2026-01-12 09:50:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz4zxum",
                  "author": "Prestigious_Cat85",
                  "text": "i already did, but same.  \ni got it solved after deleting manually for folder of the custom node ComfyUI-LTXVideo and reinstalled it  \n[https://github.com/Lightricks/ComfyUI-LTXVideo](https://github.com/Lightricks/ComfyUI-LTXVideo)",
                  "score": 3,
                  "created_utc": "2026-01-12 10:12:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz50cto",
                  "author": "jazzamp",
                  "text": "It doesn't work!",
                  "score": 1,
                  "created_utc": "2026-01-12 10:16:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz6mrcb",
              "author": "Pleasant-Bug-8114",
              "text": "you can use regular VAEDecodeTiled node instead of this.",
              "score": 1,
              "created_utc": "2026-01-12 16:17:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz6u600",
              "author": "ninjazombiemaster",
              "text": "It is part of the official LTXV custom node pack.¬†",
              "score": 1,
              "created_utc": "2026-01-12 16:50:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2arlx",
          "author": "coffeecircus",
          "text": "I like how natural and casual the video is. Thanks for sharing!",
          "score": 7,
          "created_utc": "2026-01-11 23:26:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2dtu3",
          "author": "krectus",
          "text": "Nice. Some cherry picked examples for sure but looks good. Even voices sound better than most with LTX.",
          "score": 3,
          "created_utc": "2026-01-11 23:42:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2g1ua",
          "author": "Shifty_13",
          "text": "Really good job, makes me want to revisit this model",
          "score": 4,
          "created_utc": "2026-01-11 23:53:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3dyid",
          "author": "LiveLaughLoveRevenge",
          "text": "Thank you!\n\nI've been spending all weekend on different, workflows, models, settings, and never been very satisfied.  Your workflow is a huge step forward!\n\nOne thing I noticed is that most of the default workflows put the 'strength' of the 'LTXVImgToVideoInplace' to 0.6, and yours is at 1.0.  I've heard some other comments about people putting it at 0.9.  Do you mind explaining that one a bit to help me understand it?",
          "score": 3,
          "created_utc": "2026-01-12 02:49:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz44221",
              "author": "Gilded_Monkey1",
              "text": "It's how hard the initial frame is placed into the latent space(standard latent space is grey at #808080) so at 0.9 is 90% image then it bleeds off on the next 7-10 frames. The idea is too soft and it doesn't respect the start image too hard and it is more likely to stay still but it really doesn't matter in my tests between 0.6-1 is fine",
              "score": 3,
              "created_utc": "2026-01-12 05:27:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz49fxq",
                  "author": "sevenfold21",
                  "text": "So, if you have a video of a talking head avatar that just talks, and doesn't move, would you set the strength to 1.0?",
                  "score": 1,
                  "created_utc": "2026-01-12 06:09:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz3ey5v",
          "author": "FancyJ",
          "text": "Is there a way to make this workflow T2V?",
          "score": 4,
          "created_utc": "2026-01-12 02:54:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3p1ub",
          "author": "GrungeWerX",
          "text": "I still had a few issues getting things up and running - definitely not a smooth process with the models - but **thanks to your workflow** I finally got it working and the upscale works. So I can finally start playing with LTX-2. I'm not terribly impressed so far, especially with the faces, but the speed is somewhat decent on my 3090; definitely faster than Wan for full 720p.\n\nA couple of questions:\n\n1. Are you starting w/low resolution and upscaling only, or are you trying native resolution?\n\n2. Is it faster without the upscale method and using the target resolution?\n\nI had some other questions, but forgot them. Will follow up later.",
          "score": 4,
          "created_utc": "2026-01-12 03:50:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7bjmr",
              "author": "yanokusnir",
              "text": "Glad to hear you got it working. :)\n\n1. Exactly as in my workflow: the video is generated at a lower resolution first, and then it‚Äôs upscaled 2x.  \n2. I tried generating at the target resolution without upscaling, and no, it‚Äôs not faster. It‚Äôs actually much slower.",
              "score": 1,
              "created_utc": "2026-01-12 18:10:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz3wgum",
          "author": "MomSausageandPeppers",
          "text": "FIXED: --disable-xformers with --novram. \n\nThanks a bunch for sharing!\n\nI get this error trying to use this workflow with --novram:  \ndevice=cpu (supported: {'cuda'})",
          "score": 4,
          "created_utc": "2026-01-12 04:34:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7yzpq",
              "author": "yanokusnir",
              "text": "Thanks for sharing this, it‚Äôll definitely help someone with the same issue. :)",
              "score": 1,
              "created_utc": "2026-01-12 19:56:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz7476d",
          "author": "Perfect-Time-9919",
          "text": "I'm not critiquing because I'm pretty impressed with the video. But the 2 girls at the end when the one on the left got unrealistic close, did that not bother you? Again I'm impressed and will be checking this out. I have no experience with any of this stuff outside of seeing so many A.I. vids (mostly weird and uninteresting). This one, with the variety of options, really is exciting.",
          "score": 3,
          "created_utc": "2026-01-12 17:37:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz77hv4",
              "author": "yanokusnir",
              "text": "Of course it bothered me, it‚Äôs not good. :D But to be honest, I tried to generate that scene exactly 20 times. It has its limits and there‚Äôs still a lot of room for improvement, but this is the first open-source model that has genuinely come close to Sora or Veo.",
              "score": 3,
              "created_utc": "2026-01-12 17:52:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz78p2n",
                  "author": "Perfect-Time-9919",
                  "text": "Oh I understand. Regardless, great intro video!",
                  "score": 3,
                  "created_utc": "2026-01-12 17:57:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz2c060",
          "author": "Wanderson90",
          "text": "I have 16gb vram and 32gb ram\n\n\nWould this work flow work for me?",
          "score": 3,
          "created_utc": "2026-01-11 23:32:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2ecnn",
              "author": "yanokusnir",
              "text": "https://preview.redd.it/m0gashci3tcg1.png?width=417&format=png&auto=webp&s=c344b06f25cf8387e66f14bc63decf2ddc1d99c9\n\nHonestly, I‚Äôm not 100% sure, but I think with this model RAM matters way more than VRAM. During video generation (1920√ó1080), my VRAM is only used at around 37%.",
              "score": 12,
              "created_utc": "2026-01-11 23:44:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz2s368",
                  "author": "ukpanik",
                  "text": "Well, you are using --novram.",
                  "score": 6,
                  "created_utc": "2026-01-12 00:53:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz2kna8",
                  "author": "blind26",
                  "text": "Completely unrelated to your workflow, I just had to reinstall portable and I can't figure out how to get this node (the system graphs) back, what's it called?",
                  "score": 3,
                  "created_utc": "2026-01-12 00:16:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz3xl82",
                  "author": "Jisamaniac",
                  "text": "How long does each generation take?",
                  "score": 1,
                  "created_utc": "2026-01-12 04:41:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz2cp12",
              "author": "Hououin_Kyouma77",
              "text": "That's what I've been trying to figure out as well, still havent found a configuration that doesnt give me oom's",
              "score": 1,
              "created_utc": "2026-01-11 23:36:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz2d33c",
                  "author": "Wanderson90",
                  "text": "Should have bought 64gb when I built my rig a year ago before this pricing bullshit lol",
                  "score": 3,
                  "created_utc": "2026-01-11 23:38:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz2dlr3",
          "author": "EpicNoiseFix",
          "text": "What was your success rate? I always dont by by cherry picked videos obviously",
          "score": 3,
          "created_utc": "2026-01-11 23:41:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2q7da",
              "author": "yanokusnir",
              "text": "well... I'm very picky person, so sometimes it's not about the video being bad, but I'm trying to generate something closer to my idea..  anyway, half of the videos were picked from a maximum of three attempts. but not this one... :D it's too much, please don't judge me... :D  \n[https://imgur.com/a/9tzNjDN](https://imgur.com/a/9tzNjDN)",
              "score": 7,
              "created_utc": "2026-01-12 00:44:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz3b1p8",
                  "author": "Relocator",
                  "text": "This is so fascinating to me, multiple slightly different videos of the same 'person' saying the same line and my brain just tells me it's a Vlogger doing a bunch of different takes, like these are the outtakes to her video. AI does weird stuff to our brains, and I'm all for it.",
                  "score": 7,
                  "created_utc": "2026-01-12 02:33:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz2jtnc",
          "author": "Gold-Cat-7686",
          "text": "It really can produce amazing results, I just wish portrait worked consistently. Also, great workflow! It seems to be working well on my end. It's a step above the one I tried to make.",
          "score": 3,
          "created_utc": "2026-01-12 00:12:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2o2qf",
              "author": "Novel-Injury3030",
              "text": "how do you mean portrait doesnt work?",
              "score": 1,
              "created_utc": "2026-01-12 00:34:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz45hag",
                  "author": "Gold-Cat-7686",
                  "text": "It CAN work, but it fails frequently, producing still videos or frames. The CEO mentioned fixing portrait mode in his AMA so it appears to be a known issue. For now it's much safer to do landscape.",
                  "score": 1,
                  "created_utc": "2026-01-12 05:37:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz2poib",
          "author": "Stecnet",
          "text": "Amazing job I have the same VRAM I'll def try your workflow. How is this model for nsfw if you start with a nsfw image?",
          "score": 3,
          "created_utc": "2026-01-12 00:42:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2vytk",
              "author": "Gold-Cat-7686",
              "text": "Like EVERY model, it is terrible at NSFW, because it's not trained on NSFW. If NSFW is ever to be possible it will be through community LoRAs.",
              "score": 8,
              "created_utc": "2026-01-12 01:13:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz3hk8l",
          "author": "richcz3",
          "text": "Even with a 5090- FE and 64GB system memory, this is a big boost in speed and output quality. So far (still testing), this workflow sticks better to the prompts better in less frames.\n\nThank you u/yanokusnir",
          "score": 3,
          "created_utc": "2026-01-12 03:09:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz8d54e",
              "author": "yanokusnir",
              "text": "Glad to hear that! Good luck :)",
              "score": 1,
              "created_utc": "2026-01-12 21:03:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz3pjhf",
          "author": "NoConfusion2408",
          "text": "Marvelous work man! Your workflow is clean, neat, well organized and mindfull with resources. Excellent work, seriously.\n\nOne question for you; I'm new to LTX, I made your workflow work with all the same models you specified on the tut and, although my final image looks really good, my initial character (The image fed into it) is completely different to the final output. Is that normal on LTX?\n\n\n\nThanks!",
          "score": 3,
          "created_utc": "2026-01-12 03:52:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz730dz",
              "author": "yanokusnir",
              "text": "Thank you, I appreciate your kind words. :)\n\nYeah, unfortunately that‚Äôs normal for LTX-2, consistency isn‚Äôt its strong point. :/",
              "score": 1,
              "created_utc": "2026-01-12 17:31:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz3sypx",
          "author": "Thistleknot",
          "text": "that was pretty good",
          "score": 3,
          "created_utc": "2026-01-12 04:12:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4835u",
          "author": "ExpressWarthog8505",
          "text": "It's really great!",
          "score": 3,
          "created_utc": "2026-01-12 05:58:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz485km",
          "author": "Hot_Store_5699",
          "text": "really nice resultsÔºåi will give it a try",
          "score": 3,
          "created_utc": "2026-01-12 05:58:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4cd3e",
          "author": "PleasantAd2256",
          "text": "I feel like I‚Äôm missing something. My shots always take an hour or two before. It tells me I ran out of memory, but I have a 5090. Send help.",
          "score": 3,
          "created_utc": "2026-01-12 06:33:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4udop",
              "author": "Maskwi2",
              "text": "Try adding the - - reserve-vram 2 (or 4) or even - - novram flag (but this will be slower) when running the comfyui. My workflow was constantly crashing too for i2v but OPs workflow works great if you add those flags. For me I added the reserve vram one with 2 and I'm using OPs workflow and it's been great so far. I'm on 4090.",
              "score": 4,
              "created_utc": "2026-01-12 09:18:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz4zd4k",
                  "author": "PleasantAd2256",
                  "text": "Thanks, I‚Äôll try",
                  "score": 1,
                  "created_utc": "2026-01-12 10:07:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz6tu9c",
              "author": "ninjazombiemaster",
              "text": "https://www.reddit.com/r/StableDiffusion/comments/1q9utj2/this_fixed_my_oom_issues_with_ltx2/\n\n\nThis is the only thing that actually solved my issues. Some other solutions helped sometimes, but this is the real deal. I've been able to do I2V full HD 1920x1080 24 fps for the full 20 seconds.\nI have even done full 4k for although I can only do about 3 seconds with that.¬†",
              "score": 1,
              "created_utc": "2026-01-12 16:49:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz6vxqd",
              "author": "PleasantAd2256",
              "text": "I got it working with  ‚Äîlowvram",
              "score": 1,
              "created_utc": "2026-01-12 16:59:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz4eynz",
          "author": "James_Reeb",
          "text": "Trully excellent üëå",
          "score": 3,
          "created_utc": "2026-01-12 06:55:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4gllk",
          "author": "nova_1986",
          "text": "Absolutely insane! Well done sir!",
          "score": 3,
          "created_utc": "2026-01-12 07:09:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz504c1",
              "author": "yanokusnir",
              "text": "Thanks a lot mate! :)",
              "score": 1,
              "created_utc": "2026-01-12 10:14:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz4h8sp",
          "author": "protector111",
          "text": "closeups medium closeups look superb. everything else looks worse than wan. I dont understand why cant it rendre good quality without upscaling. just look at LTX vs Wan at 1080p\n\nhttps://preview.redd.it/0vbbvjckcvcg1.png?width=1977&format=png&auto=webp&s=1cf4a1ef0ba83c128e7323e350a5a10407ae0c37\n\ntop is LTX.  that is a crop zoom from waist-cop. 1080p LTX looks alsmots ag good as wan 720p...",
          "score": 3,
          "created_utc": "2026-01-12 07:15:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5eipl",
              "author": "yanokusnir",
              "text": "This is the first open-source model with audio that‚Äôs actually close to models like Sora or Veo. Just give it some time, this is a really solid start.",
              "score": 1,
              "created_utc": "2026-01-12 12:15:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz5hpb9",
                  "author": "protector111",
                  "text": "yeah i know. the model is insane. Im sure someone will figure it out.",
                  "score": 1,
                  "created_utc": "2026-01-12 12:38:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz5ghkp",
              "author": "leepuznowski",
              "text": "To get comparable quality to 720p I'm rendering at 2560 width x1440 height. This is downscaled by LTX  to .5 so esentially 1280x720, then reupscaled. Helps the quality a lot but you need some power for it. I'm running a 5090 with 128 system RAM.",
              "score": 1,
              "created_utc": "2026-01-12 12:29:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz5hjpt",
                  "author": "protector111",
                  "text": "im rendering qhd as well on 5090 but it looks lower res than wan in 1080p.",
                  "score": 1,
                  "created_utc": "2026-01-12 12:37:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz4ivfj",
          "author": "VirusCharacter",
          "text": "Awesome video!!! üí™üòÑüëç",
          "score": 3,
          "created_utc": "2026-01-12 07:30:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4jfxf",
          "author": "NickMcGurkThe3rd",
          "text": "Awesome work! Thank you for sharing this with us!",
          "score": 3,
          "created_utc": "2026-01-12 07:35:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4zsp6",
              "author": "yanokusnir",
              "text": "thank you, you are welcome :)",
              "score": 3,
              "created_utc": "2026-01-12 10:11:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5bq9e",
          "author": "dobutsu3d",
          "text": "My god and open source üëåüòá",
          "score": 3,
          "created_utc": "2026-01-12 11:54:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5djwl",
              "author": "yanokusnir",
              "text": "hell yeah! :D",
              "score": 1,
              "created_utc": "2026-01-12 12:08:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5hr2e",
          "author": "Mohondhay",
          "text": "Whaaaa!!? This is amazing work!",
          "score": 3,
          "created_utc": "2026-01-12 12:38:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5i0y1",
              "author": "yanokusnir",
              "text": "thaaanks. :))",
              "score": 1,
              "created_utc": "2026-01-12 12:40:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5njal",
          "author": "NarvelBoss",
          "text": "Hey! They are awesome, can you tell the speed of the generation and more specs?\nWhat gpu was used?\nHow much ram was actually needed and so on..?\nThank you so much and keep up the good work..",
          "score": 3,
          "created_utc": "2026-01-12 13:16:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6usyg",
              "author": "yanokusnir",
              "text": "Thank you.  \nI mention this in the post. I have **16GB VRAM** (NVIDIA GeForce RTX 4080) and **64GB RAM** (Intel i7-14700KF @ 3.40 GHz). All shots in the video were generated at **1920√ó1024**, and the last shot is **1280√ó704**.\n\nWith my setup, I can generate up to **8 seconds at 1920√ó1024** and **15 seconds at 1280√ó704**. In both cases, it takes roughly **7‚Äì8 minutes**.\n\nSince I‚Äôm using `--novram`, a lot more system RAM is being used, and it seems that for this model RAM is actually more important than having tons of VRAM. During generation, VRAM sits at around **37%**, while RAM goes up to **95%+**.",
              "score": 1,
              "created_utc": "2026-01-12 16:53:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz6vn2t",
                  "author": "NarvelBoss",
                  "text": "Thank you so much, this has enlighten my view to this model, I have an RTX 5060 16gb vram which I actually bought for Ai use, and 32gb ram with 6400 speed, I geuss I will try to download and run the model, for sure I will try a quantized model.\nThank you so much for the reply.",
                  "score": 1,
                  "created_utc": "2026-01-12 16:57:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz65p2o",
          "author": "PestBoss",
          "text": "Thanks for posting the workflow to such a decent quality piece of LTXV2 video work!",
          "score": 3,
          "created_utc": "2026-01-12 14:55:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6sim5",
              "author": "yanokusnir",
              "text": "You are welcome mate. :)",
              "score": 1,
              "created_utc": "2026-01-12 16:43:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz6wgn1",
          "author": "OldTexasSk8Boarder",
          "text": "Hollywood is done",
          "score": 3,
          "created_utc": "2026-01-12 17:01:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6wl20",
              "author": "yanokusnir",
              "text": ":D Not yet, but it's getting better. :)",
              "score": 1,
              "created_utc": "2026-01-12 17:02:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz73nz3",
          "author": "DarkerForce",
          "text": "Great showcase and thanks for including the workflow, going to give this a whirl!",
          "score": 3,
          "created_utc": "2026-01-12 17:34:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz75ln3",
              "author": "yanokusnir",
              "text": "Thanks, good luck. :)",
              "score": 1,
              "created_utc": "2026-01-12 17:43:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz7df0g",
          "author": "No_Conversation9561",
          "text": "Finally a workflow that works for me. Thanks OP.",
          "score": 3,
          "created_utc": "2026-01-12 18:18:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7euj5",
              "author": "yanokusnir",
              "text": "Glad to hear that, best of luck! :)",
              "score": 2,
              "created_utc": "2026-01-12 18:25:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz7uu7w",
          "author": "Technical_Dish_1250",
          "text": "A. Great video  \nB. Workflow worked first try, anywhere between 90-130sec videos with example workflow with 5080 + 64gb  \nC. Thanks :)",
          "score": 3,
          "created_utc": "2026-01-12 19:37:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7xzrt",
              "author": "yanokusnir",
              "text": "Glad to hear that! Have fun. :)",
              "score": 1,
              "created_utc": "2026-01-12 19:52:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz8a23r",
          "author": "Puzzled_Fisherman_94",
          "text": "This is high quality on 16gb üòä",
          "score": 3,
          "created_utc": "2026-01-12 20:48:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz91pln",
          "author": "Confident_Read2390",
          "text": "This is IN-SANE!",
          "score": 3,
          "created_utc": "2026-01-12 23:00:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzb78gn",
          "author": "jjkikolp",
          "text": "What the hell some of these clips look like out of an actual movie",
          "score": 3,
          "created_utc": "2026-01-13 06:35:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2bwlr",
          "author": "blind26",
          "text": "Great outputs, you're having way more luck with wide shots than I am.\n\nI'll have to give your workflow a shot",
          "score": 5,
          "created_utc": "2026-01-11 23:32:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2hefp",
              "author": "Choowkee",
              "text": "There are hardly any complex examples of wide shots posted by OP though.\n\nThe one where the guy runs towards the camera = that is something LTX2 actually handles well.\n\nBut if you prompted him to stand still and move around in the back you would probably start seeing artifacts on his face.",
              "score": 3,
              "created_utc": "2026-01-12 00:00:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz3ctgy",
          "author": "wildhood2015",
          "text": "If i would have watched this on youtube or so, i would never be able to make out that its AI generated. Its crazy realistic to average eye",
          "score": 5,
          "created_utc": "2026-01-12 02:43:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7a95l",
              "author": "yanokusnir",
              "text": "I agree with that. We‚Äôre heading into times when you won‚Äôt be able to trust anything you see online.",
              "score": 3,
              "created_utc": "2026-01-12 18:04:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2emo8",
          "author": "Past_Crazy8646",
          "text": "Just with RAM was more affordable as I have a 4090 and, crucially, only 32GB of ram.",
          "score": 2,
          "created_utc": "2026-01-11 23:46:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2w513",
          "author": "Fortyseven",
          "text": "I'm running a 4090; I do most of my genai stuff with static images and only briefly played with video a while ago (low quality gimmick-level stuff, nothing good).\n\nWhen I tried to play with LTX2, the workflows I grabbed were using gemma3 (which yours does); the flow never finishes since I run out of VRAM pretty quick. Is this intended to be running on hardware with more VRAM, or am I missing some configuration setting for low memory scenarios? \n\nFor what it's worth, I'm serving a separate Llamacpp instance on a 3090 machine on my rack; I wonder if it would be possible to just hit that OAI API endpoint... ü§î\n\nAnyway, just kinda hit a wall a couple times trying to get this running and it seems like it'd be great fun to play with.",
          "score": 2,
          "created_utc": "2026-01-12 01:14:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz33q73",
              "author": "yanokusnir",
              "text": "Did you add --novram to the run_nvidia_gpu.bat file? It is crucial in this case.",
              "score": 1,
              "created_utc": "2026-01-12 01:55:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz33t2z",
                  "author": "Fortyseven",
                  "text": "Probably not -- I'll check into it. Thanks. :)",
                  "score": 1,
                  "created_utc": "2026-01-12 01:55:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz3eyxm",
                  "author": "Stecnet",
                  "text": "does adding that --novram to the run\\_nvidia\\_gpu.bat file mess up anything for normal Flux, SDXL and Ziimage Turbo image generation?",
                  "score": 1,
                  "created_utc": "2026-01-12 02:55:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz2x8f5",
          "author": "RavioliMeatBall",
          "text": "I gave up on trying to get LTX 2 working on my system, I have same specs as you.",
          "score": 2,
          "created_utc": "2026-01-12 01:20:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz33171",
              "author": "yanokusnir",
              "text": "give it another chance :)",
              "score": 1,
              "created_utc": "2026-01-12 01:51:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2xeaa",
          "author": "__Hello_my_name_is__",
          "text": "Does this work with 12GB VRAM, too?",
          "score": 2,
          "created_utc": "2026-01-12 01:21:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz308bp",
              "author": "yanokusnir",
              "text": "Unfortunately, I don't have a correct answer to your question, the only option is to try it. Let me know pls.",
              "score": 1,
              "created_utc": "2026-01-12 01:36:45",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nz95b3q",
              "author": "cybeard",
              "text": "I'm running on a RTX3070 8GB VRAM and 16GB RAM, but takes 20min per video(10s). WanGP on Pinokio.",
              "score": 1,
              "created_utc": "2026-01-12 23:19:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2xgi9",
          "author": "FigN3wton",
          "text": "damn way better than my output.",
          "score": 2,
          "created_utc": "2026-01-12 01:21:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2xtnh",
          "author": "urbanhood",
          "text": "Feels like we got veo 2 locally.",
          "score": 2,
          "created_utc": "2026-01-12 01:23:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz30lmj",
              "author": "yanokusnir",
              "text": "100% :)",
              "score": 1,
              "created_utc": "2026-01-12 01:38:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz37s2g",
          "author": "Impossible-Ad-3798",
          "text": "Just tried your workflow it amazing thank you so much. Alos you have a workflow for video to video as well? I am bit struggling with that part.",
          "score": 2,
          "created_utc": "2026-01-12 02:16:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz38op4",
              "author": "yanokusnir",
              "text": "You are welcome and thank you. :) Unfortunately I don‚Äôt have workflow for V2V, I haven't tried it yet.",
              "score": 3,
              "created_utc": "2026-01-12 02:21:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz391vc",
                  "author": "Impossible-Ad-3798",
                  "text": "The audio is not coming up in my case something I am missing?",
                  "score": 3,
                  "created_utc": "2026-01-12 02:23:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz3nybq",
          "author": "strppngynglad",
          "text": "can it do stylized worlds instead of just realism?",
          "score": 2,
          "created_utc": "2026-01-12 03:44:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz80lrv",
              "author": "yanokusnir",
              "text": "Whatever you prompt. :)",
              "score": 1,
              "created_utc": "2026-01-12 20:04:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz3vkh0",
          "author": "Commercial-Excuse652",
          "text": "Can I run it if I have 32gb ddr5 ram along with 8gh vram 4060?",
          "score": 2,
          "created_utc": "2026-01-12 04:28:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz95hq3",
              "author": "cybeard",
              "text": "I'm running on a RTX3070 8GB VRAM and 16GB RAM, but takes 20min per video(10s). WanGP on Pinokio.",
              "score": 1,
              "created_utc": "2026-01-12 23:20:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzai4gh",
                  "author": "Commercial-Excuse652",
                  "text": "But I need something which has audio too like this one and this is more consistent then other open source model.",
                  "score": 1,
                  "created_utc": "2026-01-13 03:42:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz3yxww",
          "author": "arush1836",
          "text": "I had a hard time setuping it locally so I tested it on runpod with 48gb VRAM + 50gb RAM pod and the output was not convincing, what changes you have made in the default workflow?",
          "score": 2,
          "created_utc": "2026-01-12 04:50:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz440bk",
          "author": "IcyFly521",
          "text": "Where do you change this\n\nhttps://preview.redd.it/998kds7ctucg1.jpeg?width=4032&format=pjpg&auto=webp&s=8d951801dcac04546b5ed23956416241276d57f7",
          "score": 2,
          "created_utc": "2026-01-12 05:26:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4aj4a",
          "author": "Professional_Diver71",
          "text": "How is that its really clean and crisp ? I have the same specs! Tell me your secrets!",
          "score": 2,
          "created_utc": "2026-01-12 06:18:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5nyy0",
              "author": "yanokusnir",
              "text": "A lot depends on the quality of your input. Put some effort into making the image you‚Äôre using to generate the video as good as possible. That‚Äôs pretty much it. :)",
              "score": 1,
              "created_utc": "2026-01-12 13:18:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz6xnbk",
                  "author": "Professional_Diver71",
                  "text": "Are you using the distilled version?",
                  "score": 1,
                  "created_utc": "2026-01-12 17:07:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz4aqd6",
          "author": "SardinePicnic",
          "text": "Is the video of the two girls talking cherry picked in the sense that 1 time out of 100 you will get them speaking individually each of their lines instead of both of them saying it together? That seems to be my biggest hurdle. No matter what I try I cannot get people to say their lines individually. Any tips on how you did that?",
          "score": 2,
          "created_utc": "2026-01-12 06:19:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz71bcj",
              "author": "yanokusnir",
              "text": "Yeah, that one was about 1 out of 20 attempts. I know it sounds crazy, but as you can see, my patience is made of steel. :)\n\nHere‚Äôs the prompt I used:\n\ncasual selfie-style video recorded in a bedroom mirror, two young women sitting close together on a bed, one holding a smartphone and filming the reflection, natural handheld framing with slight movement, relaxed and authentic vlog energy\n\nthe woman holding the phone speaks first with visible excitement, smiling into the mirror and gesturing lightly with her free hand, she says in English:\n\n‚ÄúIt‚Äôs honestly kind of crazy that with just 16 gigs of VRAM you can already generate like a fifteen-second HD video.‚Äù\n\nas she finishes the sentence, she subtly brings the phone closer to the mirror, gently zooming in so the framing tightens on both of their faces, increasing intimacy\n\nthe second woman, wearing a pink t-shirt, leans in even closer toward the camera, her shoulder touching the other‚Äôs, nodding and smiling as she looks at the phone screen, then replies in a casual, impressed tone:\n\n‚ÄúYeah, it‚Äôs not perfect, but look at the motion and the lip sync, it‚Äôs actually really well done‚Ä¶ by the way ‚Äî I love you.‚Äù\n\nthey pause for a brief moment, faces now close in the tighter frame, looking at each other with soft smiles, sharing a quiet laugh\n\nboth react naturally with small laughs, subtle head tilts, expressive eyes, staying close to the camera, intimate and spontaneous moment captured in the mirror, soft indoor lighting, real reflections visible, cozy bedroom atmosphere, authentic unscripted tech-vlog feel",
              "score": 1,
              "created_utc": "2026-01-12 17:23:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz4fnyr",
          "author": "Amazing_Upstairs",
          "text": "Resolution of generations? Prompts? Your tests look much better than mine",
          "score": 2,
          "created_utc": "2026-01-12 07:01:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4jd5v",
          "author": "IrisColt",
          "text": "I‚Äôm blown away... how long does your rig take to generate a 15-second clip?",
          "score": 2,
          "created_utc": "2026-01-12 07:34:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4ynt7",
              "author": "Free_Coast5046",
              "text": "Generating 15s took only 381s",
              "score": 3,
              "created_utc": "2026-01-12 10:00:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz6wvcy",
              "author": "yanokusnir",
              "text": "For me, it takes somewhere between 7 and 8 minutes.",
              "score": 3,
              "created_utc": "2026-01-12 17:03:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz4m3ne",
          "author": "rookan",
          "text": "What are your. bat file parameters? - - novram? Anything else? Do you use flash or sage attention?",
          "score": 2,
          "created_utc": "2026-01-12 07:59:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4sypl",
              "author": "yanokusnir",
              "text": "Hi, this is exactly how my .bat file looks like:\n\n.\\\\python\\_embeded\\\\python.exe -s ComfyUI\\\\main.py --windows-standalone-build --novram\n\npause",
              "score": 3,
              "created_utc": "2026-01-12 09:04:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz4vc5e",
                  "author": "Free_Coast5046",
                  "text": "Sage Attention failed. Video generated successfully.",
                  "score": 5,
                  "created_utc": "2026-01-12 09:28:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz4xdn6",
                  "author": "rookan",
                  "text": "Thank you :)",
                  "score": 3,
                  "created_utc": "2026-01-12 09:48:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz4v8x6",
                  "author": "Free_Coast5046",
                  "text": "https://preview.redd.it/2txshdq8zvcg1.png?width=1659&format=png&auto=webp&s=199e1d6895ef8d5028651be32c92b6633b0a8dc2",
                  "score": 1,
                  "created_utc": "2026-01-12 09:27:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz4yvli",
          "author": "WildSpeaker7315",
          "text": "Did you make these?",
          "score": 2,
          "created_utc": "2026-01-12 10:02:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4yw7k",
          "author": "singfx",
          "text": "Woah! really well done! LTX should hire you :D",
          "score": 2,
          "created_utc": "2026-01-12 10:02:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4z1aa",
          "author": "Tarry_",
          "text": "Soy, is it any good?",
          "score": 2,
          "created_utc": "2026-01-12 10:03:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz59rbx",
          "author": "ImageLongjumping8230",
          "text": "What the hell. why would you hurt my drives like this? Now i have to download another 200gigs üò≠üò≠",
          "score": 2,
          "created_utc": "2026-01-12 11:39:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5e4or",
          "author": "GureenRyuu",
          "text": "Is the update from 10 to 16GB that much better? It takes me a long time to generate like 2 seconds on my 3080.",
          "score": 2,
          "created_utc": "2026-01-12 12:12:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5hvzy",
          "author": "sketchfag",
          "text": "nice",
          "score": 2,
          "created_utc": "2026-01-12 12:39:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5kwrs",
          "author": "Various-News7286",
          "text": "Can't install tiledvaedecode node, is there a link for manual download?",
          "score": 2,
          "created_utc": "2026-01-12 12:59:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5lyhf",
              "author": "yanokusnir",
              "text": "Hey, it should be this one: [https://github.com/Lightricks/ComfyUI-LTXVideo](https://github.com/Lightricks/ComfyUI-LTXVideo)  \nJust go to `ComfyUI_windows_portable\\ComfyUI\\custom_nodes`, open CMD in that folder, and run the \"git clone https://github.com/Lightricks/ComfyUI-LTXVideo\". Then restart Comfy ofc.",
              "score": 1,
              "created_utc": "2026-01-12 13:06:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5nbtr",
          "author": "Citizen_In_Danger",
          "text": "Can you share the prompt for the last video? I'm having the same issue as i had when experimenting with sora. The voice lines are said by different people or all characters are opening their mouth with just 1 voice talking.",
          "score": 2,
          "created_utc": "2026-01-12 13:14:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7dve0",
              "author": "yanokusnir",
              "text": "Yeah, it is a lottery. That one was about 1 out of 20 attempts. :/\n\nMy prompt:\n\ncasual selfie-style video recorded in a bedroom mirror, two young women sitting close together on a bed, one holding a smartphone and filming the reflection, natural handheld framing with slight movement, relaxed and authentic vlog energy\n\nthe woman holding the phone speaks first with visible excitement, smiling into the mirror and gesturing lightly with her free hand, she says in English:\n\n‚ÄúIt‚Äôs honestly kind of crazy that with just 16 gigs of VRAM you can already generate like a fifteen-second HD video.‚Äù\n\nas she finishes the sentence, she subtly brings the phone closer to the mirror, gently zooming in so the framing tightens on both of their faces, increasing intimacy\n\nthe second woman, wearing a pink t-shirt, leans in even closer toward the camera, her shoulder touching the other‚Äôs, nodding and smiling as she looks at the phone screen, then replies in a casual, impressed tone:\n\n‚ÄúYeah, it‚Äôs not perfect, but look at the motion and the lip sync, it‚Äôs actually really well done‚Ä¶ by the way ‚Äî I love you.‚Äù\n\nthey pause for a brief moment, faces now close in the tighter frame, looking at each other with soft smiles, sharing a quiet laugh\n\nboth react naturally with small laughs, subtle head tilts, expressive eyes, staying close to the camera, intimate and spontaneous moment captured in the mirror, soft indoor lighting, real reflections visible, cozy bedroom atmosphere, authentic unscripted tech-vlog feel",
              "score": 1,
              "created_utc": "2026-01-12 18:20:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5ou5a",
          "author": "adolfin4",
          "text": "im generating 720p 24fps 121 or 193 frames video with this workflow on my rtx 4070super+64gb ram+64gb paging enabled.   \ndoesnt even come close to this quality. how did you do it?",
          "score": 2,
          "created_utc": "2026-01-12 13:24:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5tqf6",
          "author": "OkMixture8932",
          "text": "This is actually very good other than a few obvious things most people won't be able to tell the difference at all",
          "score": 2,
          "created_utc": "2026-01-12 13:51:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz65tn6",
          "author": "Leonviz",
          "text": "i try to add no --vram but the bat file i\\]s not able to run though",
          "score": 2,
          "created_utc": "2026-01-12 14:56:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz69pkz",
              "author": "Leonviz",
              "text": "Audio VAE config is required for audio VAE  \n\n\ni am also getting this error though, not too sure if anyone can help",
              "score": 1,
              "created_utc": "2026-01-12 15:15:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz6hqha",
              "author": "yanokusnir",
              "text": "it's \"--novram\" not \"no --vram\"",
              "score": 1,
              "created_utc": "2026-01-12 15:54:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz66wjf",
          "author": "NiGaSan",
          "text": "Using a 12gb vram with 64gb ram system, i got a \"divided by 0\" error. Is-it hardware related ? I use ComfyUI 0.8.2. Any idea why i got this error ?",
          "score": 2,
          "created_utc": "2026-01-12 15:01:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz67rca",
              "author": "NiGaSan",
              "text": "OK to be more precise here is the error message : \n\n    (...)\\Packages\\ComfyUI - Dev\\comfy\\utils.py\", line 947, in common_upscale\n        new_aspect = width / height\n    ZeroDivisionError: division by zero\\Packages\\ComfyUI - Dev\\comfy\\utils.py\", line 947, in common_upscale\n        new_aspect = width / height\n    ZeroDivisionError: division by zero",
              "score": 1,
              "created_utc": "2026-01-12 15:06:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz6sdcp",
                  "author": "yanokusnir",
                  "text": "Try copying the error into ChatGPT. I don‚Äôt really know why it‚Äôs happening, I‚Äôm just a regular user. :)",
                  "score": 2,
                  "created_utc": "2026-01-12 16:42:51",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz67xnj",
          "author": "LyriWinters",
          "text": "Excellent work! Super impressive. Couple of questions:  \n1. Are you running Comfy with any vram or fp8 arguments?  \n2. How do you make the upscaler not oom crash?  \n3. Why did you not opt in for the gguf models? They're generally slightly better compared to just brute forced fp8 across the layers...",
          "score": 2,
          "created_utc": "2026-01-12 15:07:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6qwnt",
              "author": "yanokusnir",
              "text": "Thank you. :)\n\n1. As I mentioned in the post, I‚Äôm using the `--novram`, nothing else.  \n2. It was crashing for me without `--novram`. With it, it just doesn‚Äôt crash. I don‚Äôt really understand the code, I‚Äôm just a regular user. :)  \n3. Good point. I tried that, but for some reason I had trouble loading the Audio VAE, so I left it for now and planned to come back to it. I‚Äôll definitely try it again.",
              "score": 1,
              "created_utc": "2026-01-12 16:36:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz6toxj",
                  "author": "LyriWinters",
                  "text": "You seem to have generated a truck load... I can run without the upscaler at 1920x1080, but with the upscaler it jjust goes vram oom. \n\nIs the upscaler worth it?",
                  "score": 1,
                  "created_utc": "2026-01-12 16:48:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz6u8oc",
          "author": "RhapsodyMarie",
          "text": "I really want to try this but everytime I try an LTX workflow I get this error.\n\n\"echo If you see this and ComfyUI did not start try updating your Nvidia Drivers to the latest. If you get a c10.dll error you need to install vc redist that you can find: [https://aka.ms/vc14/vc\\_redist.x64.exe](https://aka.ms/vc14/vc_redist.x64.exe)\n\nIf you see this and ComfyUI did not start try updating your Nvidia Drivers to the latest. If you get a c10.dll error you need to install vc redist that you can find: [https://aka.ms/vc14/vc\\_redist.x64.exe](https://aka.ms/vc14/vc_redist.x64.exe)\"\n\nI'm up to date with a fresh install of comfyui portable.\n\nI can run Wan 2.2 fine\n\n  \nEdit: checking LTX model since i dont have the FP8 version",
          "score": 2,
          "created_utc": "2026-01-12 16:51:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6w112",
              "author": "yanokusnir",
              "text": "Sorry I can‚Äôt help more, but I‚Äôm just a regular user and I honestly don‚Äôt understand those errors. Try pasting it into ChatGPT, it‚Äôs helped me solve almost every issue so far.",
              "score": 1,
              "created_utc": "2026-01-12 16:59:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz6yvkj",
                  "author": "RhapsodyMarie",
                  "text": "yeah it seems it doesnt like Gemma for me... im going to try to take out the audio loaders. Somehow it started working after multiple crashes and even a blue screen. never even hit 25% load on Vram  üôÑ",
                  "score": 2,
                  "created_utc": "2026-01-12 17:12:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz7kmja",
              "author": "skocznymroczny",
              "text": "For me switching to fp8_e4m3 gemma does the trick.",
              "score": 1,
              "created_utc": "2026-01-12 18:50:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz84h91",
                  "author": "RhapsodyMarie",
                  "text": "yeah im using that, once i got it to initially load it works. now if i can just get the prompt to do what i want lol",
                  "score": 1,
                  "created_utc": "2026-01-12 20:22:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz7gcil",
          "author": "countjj",
          "text": "Can it do any lower? Sub 12GB VRAM?",
          "score": 2,
          "created_utc": "2026-01-12 18:31:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz38f0j",
          "author": "stuartullman",
          "text": "an actual well made video.  really well done",
          "score": 3,
          "created_utc": "2026-01-12 02:20:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz38sf6",
              "author": "yanokusnir",
              "text": "thanks :)",
              "score": 1,
              "created_utc": "2026-01-12 02:22:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz3dum8",
          "author": "WhyIsTheUniverse",
          "text": "That last clip was fantastic.",
          "score": 3,
          "created_utc": "2026-01-12 02:48:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2l67e",
          "author": "Artforartsake99",
          "text": "This stuff is amazing that it could be done locally.  Great video by the way.",
          "score": 2,
          "created_utc": "2026-01-12 00:19:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2lhso",
              "author": "yanokusnir",
              "text": "Thanks a lot :)",
              "score": 2,
              "created_utc": "2026-01-12 00:21:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2pbvd",
          "author": "BWeebAI",
          "text": "Brilliant.",
          "score": 2,
          "created_utc": "2026-01-12 00:40:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2x2cf",
          "author": "Ul71",
          "text": "What an entertaining way to present your technically impressive work. Thanks!",
          "score": 2,
          "created_utc": "2026-01-12 01:19:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz31j5j",
              "author": "yanokusnir",
              "text": "Thank you very much, I appreciate it and I'm glad you like it! :))",
              "score": 1,
              "created_utc": "2026-01-12 01:43:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz31vsi",
          "author": "emmiefroshe",
          "text": "WOW",
          "score": 2,
          "created_utc": "2026-01-12 01:45:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz33yxq",
          "author": "Impossible-Ad-3798",
          "text": "This is amazing mate.",
          "score": 2,
          "created_utc": "2026-01-12 01:56:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz341ef",
              "author": "yanokusnir",
              "text": "Thank you. :)",
              "score": 3,
              "created_utc": "2026-01-12 01:56:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz3a7os",
          "author": "Impossible-Ad-3798",
          "text": "There is no audio when I generated any think I am missing here?",
          "score": 2,
          "created_utc": "2026-01-12 02:29:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3bwys",
          "author": "tehorhay",
          "text": "Whoa!",
          "score": 2,
          "created_utc": "2026-01-12 02:38:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3kbxk",
          "author": "ph33rlus",
          "text": "You guys are making it tougher every day to resist the urge to upgrade my RTX card‚Ä¶",
          "score": 2,
          "created_utc": "2026-01-12 03:24:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3o0tt",
          "author": "BooleanBanter",
          "text": "That is freakin awesome!!",
          "score": 2,
          "created_utc": "2026-01-12 03:44:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3vs9h",
          "author": "Icy_Concentrate9182",
          "text": "Wow.... Nice showcase..Chefs kiss",
          "score": 2,
          "created_utc": "2026-01-12 04:29:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7aerq",
              "author": "yanokusnir",
              "text": "Haha, thank you! :)",
              "score": 1,
              "created_utc": "2026-01-12 18:05:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz45wg2",
          "author": "Lover_of_Titss",
          "text": "Stuff like this makes me very optimistic about future models. I really think we‚Äôre only a few years away from fully generated AI movie with simple prompts",
          "score": 2,
          "created_utc": "2026-01-12 05:41:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7k439",
          "author": "desperate_wishbone87",
          "text": "Has anyone tried re-rolling a 2-3 second video with random seed until you get something you like and then making it much longer (i.e. 15 sec) and re-rolling one more time with the good seed? \n\nIs the output vastly different or is the two second duration version a good indicator of how the longer video is going to go?",
          "score": 1,
          "created_utc": "2026-01-12 18:48:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz80ffy",
          "author": "MrYhi",
          "text": "How can I learn this? i just bought a 5070 TI 16 VRAM to try AI models but idk where to start",
          "score": 1,
          "created_utc": "2026-01-12 20:03:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz80ki6",
              "author": "MrYhi",
              "text": "Amazing results btw!",
              "score": 1,
              "created_utc": "2026-01-12 20:03:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz84fmm",
                  "author": "yanokusnir",
                  "text": "Thank you. :)  \nI‚Äôd recommend this YouTube channel: [https://youtu.be/Zko\\_s2LO9Wo?si=YIb1BFw3qDo3k9XO](https://youtu.be/Zko_s2LO9Wo?si=YIb1BFw3qDo3k9XO)  \nWhat you really need to learn is **ComfyUI**. It looks complicated and can be pretty intimidating at first, but if you give it a chance, after a few weeks it‚Äôll start to make sense without much trouble.\n\nThere are tons of tutorials there, although a lot has changed since then. ComfyUI looks different now, the models used in those tutorials are already outdated, and some of them aren‚Äôt really used anymore because we have much better models today.\n\nThat said, it‚Äôs still worth watching because it explains very clearly what does what and how the tool works overall.\n\nGood luck!",
                  "score": 2,
                  "created_utc": "2026-01-12 20:21:59",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz922jq",
          "author": "Confident_Read2390",
          "text": "Let's say I'm a complete noob to LTX.  Could you make a tutorial or does one exist already? Is this/working with NVIDIA even possible on a mac?",
          "score": 1,
          "created_utc": "2026-01-12 23:02:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz94kzp",
          "author": "spacev3gan",
          "text": "Anyone running it successfully on an AMD GPU?  \nI have a 9070, tried running LTX-2 on Comfy UI without success so far.",
          "score": 1,
          "created_utc": "2026-01-12 23:15:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz9x1li",
          "author": "Nevaditew",
          "text": "How do you avoid blurry movements during fast character motion?",
          "score": 1,
          "created_utc": "2026-01-13 01:49:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz9xj01",
              "author": "yanokusnir",
              "text": "At the moment, there‚Äôs probably no real way around it. We‚Äôll have to wait for some fine-tuning or a new, improved version of the model. It‚Äôs great that it can generate really fast motion, but it looks terrible. :/",
              "score": 1,
              "created_utc": "2026-01-13 01:51:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzay66p",
          "author": "Frogy_mcfrogyface",
          "text": "It was great while it lasted. It worked all day yesterday and today it just crashes comfyui for some reason.",
          "score": 1,
          "created_utc": "2026-01-13 05:23:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzb2k9o",
          "author": "reicaden",
          "text": "I have a 5070 ti and 128gb of ram, and I can't get this crap to actually work at all, lol.",
          "score": 1,
          "created_utc": "2026-01-13 05:57:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzb2u1t",
          "author": "reicaden",
          "text": "Where do I find the run nvidia gpu bat file? To add the code too? I usually just open comfyui and thats all",
          "score": 1,
          "created_utc": "2026-01-13 05:59:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzb66jz",
          "author": "Just-Conversation857",
          "text": "LTXVSpatioTemporalTiledVAEDecode  not found! I can'tfind how to install this. Please help. I am on ComfyUI Desktop. isthat hte problem?",
          "score": 1,
          "created_utc": "2026-01-13 06:26:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2eqhi",
          "author": "Environmental_Ad3162",
          "text": "I get oom errors on my 3090... I need to try your workflow after work",
          "score": 1,
          "created_utc": "2026-01-11 23:46:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2rf8n",
          "author": "IcyFly521",
          "text": "What apps did you use?",
          "score": 1,
          "created_utc": "2026-01-12 00:50:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2s5tc",
              "author": "yanokusnir",
              "text": "Comfy UI.",
              "score": 3,
              "created_utc": "2026-01-12 00:53:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz2zwc9",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 0,
                  "created_utc": "2026-01-12 01:34:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz3g0ko",
          "author": "AtrocitasInterfector",
          "text": "bro",
          "score": 1,
          "created_utc": "2026-01-12 03:00:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3qf41",
          "author": "Real-Employer-2474",
          "text": "This is so amazing and exciting future. But i dont have no way near the system. So wanted to try this on my own",
          "score": 1,
          "created_utc": "2026-01-12 03:57:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4hrcw",
          "author": "sevenfold21",
          "text": "Does LTX2 hate portrait videos?  Why so many LTX2 videos in landscape mode?",
          "score": 1,
          "created_utc": "2026-01-12 07:20:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5l1o0",
              "author": "yanokusnir",
              "text": "I don't know, I'm not interested in dancing chicks videos. :D",
              "score": 3,
              "created_utc": "2026-01-12 13:00:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz529rd",
          "author": "Novel-Mechanic3448",
          "text": "I mean just none of it looks remotely real or it looks like the worst era of animated films.\n\nI'm not impressed with video gen, even veo3 or sora 2. It all just looks like crap to me",
          "score": 1,
          "created_utc": "2026-01-12 10:34:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5528o",
              "author": "yanokusnir",
              "text": "That's fine. What fascinates me is that 3 years ago I would never have imagined that a computer would generate anything this good.",
              "score": 2,
              "created_utc": "2026-01-12 10:59:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz52xxi",
          "author": "Plenty-Mix9643",
          "text": "You just picked the best vids, most of the time it generates garbage videos.",
          "score": 1,
          "created_utc": "2026-01-12 10:40:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz54ebg",
              "author": "yanokusnir",
              "text": "Well, that's not entirely true, it can generate great videos, but it works best with closeup shots imho.",
              "score": 1,
              "created_utc": "2026-01-12 10:53:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz524b7",
          "author": "Justify_87",
          "text": "7-8 minutes per run. And you don't even know if it's gonna be shit or not. That's just a waste of your life, mate.",
          "score": 0,
          "created_utc": "2026-01-12 10:32:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5587n",
          "author": "jazzamp",
          "text": "Waste of time‚ùóÔ∏èüëéüèΩ",
          "score": 0,
          "created_utc": "2026-01-12 11:00:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5b296",
              "author": "yanokusnir",
              "text": "Sure.",
              "score": 4,
              "created_utc": "2026-01-12 11:49:22",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nz7lngj",
              "author": "NickMcGurkThe3rd",
              "text": "tf is wrong with this guy :-D",
              "score": 1,
              "created_utc": "2026-01-12 18:55:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz7r655",
                  "author": "jazzamp",
                  "text": "Tf is wrong with you?! Spent hours on this, no proper instructions, questions ignored... my internet is not relatively flash... first workflow I ever tried out for lxt2 and it's piss poor. Only workflows from YouTube gives you everything with proper explanation. If you won't be detailed, why share the work flow to begin with? That's what tf is wrong with me.",
                  "score": 1,
                  "created_utc": "2026-01-12 19:20:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz2lhwj",
          "author": "retrorays",
          "text": "Guess you can't do this with a 12gb 4070 eh?",
          "score": 0,
          "created_utc": "2026-01-12 00:21:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2ls7f",
              "author": "BassAzayda",
              "text": "Give it a go with WanGP works magic.",
              "score": 3,
              "created_utc": "2026-01-12 00:22:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz3xsow",
                  "author": "_Wheres_the_Beef_",
                  "text": "I'm not having any luck with WanGP. Just trying to run the default prompt for LTX-2 Dev19b Default with just text, I'm getting a video that is hilariously unrelated to the prompt every single time. Quality is ok, just not at all what the prompt is asking for.",
                  "score": 1,
                  "created_utc": "2026-01-12 04:43:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz446x9",
              "author": "Gilded_Monkey1",
              "text": "Works fine on my 5070 so maybe a little slower but should be able to",
              "score": 3,
              "created_utc": "2026-01-12 05:28:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2yd25",
          "author": "Single_Ring4886",
          "text": "Did anyone tried to generate just single image with this video model is it possible?",
          "score": 0,
          "created_utc": "2026-01-12 01:26:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4hv13",
          "author": "solo_entrepreneur",
          "text": "What are the specs of your pc?",
          "score": 0,
          "created_utc": "2026-01-12 07:20:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4zwxh",
              "author": "yanokusnir",
              "text": "It‚Äôs in title bro.. :D",
              "score": 1,
              "created_utc": "2026-01-12 10:12:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz5sglk",
                  "author": "solo_entrepreneur",
                  "text": "I meant like the exact processor and video card",
                  "score": 1,
                  "created_utc": "2026-01-12 13:44:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz4jkui",
          "author": "jazzamp",
          "text": "I'll download and check back üëçüèΩ\n\nWaste of time! Ltxv spatio Temporal Tiled Vae Decode is missing. It has the red lone border and red \"X\" Can't find it or download it anywhere. Spent  hours on this already. Cannot execute because a node is missing the class_type property.: Node ID '#161:154' Does this workflow work on Mac M1?",
          "score": 0,
          "created_utc": "2026-01-12 07:36:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5tfra",
          "author": "IcyFly521",
          "text": "What type of computer setup do you have?",
          "score": 0,
          "created_utc": "2026-01-12 13:50:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5trjx",
              "author": "yanokusnir",
              "text": "It‚Äôs in the post title, bro...",
              "score": 3,
              "created_utc": "2026-01-12 13:52:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz6jie6",
                  "author": "IcyFly521",
                  "text": "My bad. So I got it up and running but my Mac wouldn‚Äôt let me go forward with it. Lol\n\nhttps://preview.redd.it/wz20g6xpyxcg1.jpeg?width=4032&format=pjpg&auto=webp&s=a27ea464f01ff5fe62de861fce7831d75baff242",
                  "score": 1,
                  "created_utc": "2026-01-12 16:02:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz60m5i",
          "author": "ProfessionalGain2306",
          "text": "CPU Intel core i3, 4 Gb RAM, 2 Gb VRAM and 256 SSD.\n‚ò†Ô∏èüò≠üóø",
          "score": 0,
          "created_utc": "2026-01-12 14:29:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz64lte",
              "author": "yanokusnir",
              "text": "Uff, can you even load a browser? :D",
              "score": 1,
              "created_utc": "2026-01-12 14:50:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz79iwv",
                  "author": "ProfessionalGain2306",
                  "text": "Chrome browser, ok?",
                  "score": 1,
                  "created_utc": "2026-01-12 18:01:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q7dzq2",
      "title": "I‚Äôm the Co-founder & CEO of Lightricks. We just open-sourced LTX-2, a production-ready audio-video AI model. AMA.",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1q7dzq2/im_the_cofounder_ceo_of_lightricks_we_just/",
      "author": "ltx_model",
      "created_utc": "2026-01-08 15:00:21",
      "score": 1641,
      "num_comments": 487,
      "upvote_ratio": 0.92,
      "text": "Hi everyone. **I‚Äôm Zeev Farbman, Co-founder & CEO of Lightricks.**\n\nI‚Äôve spent the last few years working closely with our team on [LTX-2](https://ltx.io/model), a production-ready audio‚Äìvideo foundation model. This week, we did a full open-source release of LTX-2, including weights, code, a trainer, benchmarks, LoRAs, and documentation.\n\nOpen releases of multimodal models are rare, and when they do happen, they‚Äôre often hard to run or hard to reproduce. We built LTX-2 to be something you can actually use: it runs locally on consumer GPUs and powers real products at Lightricks.\n\n**I‚Äôm here to answer questions about:**\n\n* Why we decided to open-source LTX-2\n* What it took ship an open, production-ready AI model\n* Tradeoffs around quality, efficiency, and control\n* Where we think open multimodal models are going next\n* Roadmap and plans\n\nAsk me anything!   \nI‚Äôll answer as many questions as I can, with some help from the LTX-2 team.  \n  \n*Verification:*\n\n[Lightricks CEO Zeev Farbman](https://preview.redd.it/3oo06hz2x4cg1.jpg?width=2400&format=pjpg&auto=webp&s=4c3764327c90a1af88b7e056084ed2ac8f87c60b)\n\n\n\n>The volume of questions was beyond all expectations! Closing this down so we have a chance to catch up on the remaining ones.\n>\n>Thanks everyone for all your great questions and feedback. More to come soon!",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q7dzq2/im_the_cofounder_ceo_of_lightricks_we_just/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "nyeptke",
          "author": "Maraan666",
          "text": "well... why did you decide to go open source?",
          "score": 153,
          "created_utc": "2026-01-08 15:02:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyetfom",
              "author": "ltx_model",
              "text": "We believe models are evolving into full-blown rendering engines. Not just \"generate video from prompt\" - actual rendering with inputs like depth, normals, motion vectors, outputting to compositing pipelines, VFX workflows, animation tools, game engines.  \n  \nThat's dozens of different applications and integration points. Static APIs can't cover it. And much of this needs to run on edge - real-time previews on your machine, not waiting for cloud roundtrips.  \nSo open weights is the only way this actually works. We monetize through licensing and rev-share when people build successful products on top (we draw the line at $10M revenue). You build something great, we share in the upside. If you're experimenting or under that threshold - it's free.  \n  \nPlus, academia and the research community can experiment freely. Thousands of researchers finding novel applications, pushing boundaries, discovering things we'd never think of. We can't hire all the smart people, but we can give them tools to build on.",
              "score": 881,
              "created_utc": "2026-01-08 15:19:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyeu7vz",
                  "author": "Anxious-Program-1940",
                  "text": "![gif](giphy|FbZYCW78PANyM)",
                  "score": 247,
                  "created_utc": "2026-01-08 15:23:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyev2uf",
                  "author": "Takashi728",
                  "text": "This is fucking based",
                  "score": 185,
                  "created_utc": "2026-01-08 15:27:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyew8v3",
                  "author": "NHAT-90",
                  "text": "That's a great answer.",
                  "score": 42,
                  "created_utc": "2026-01-08 15:32:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyf7u22",
                  "author": "Neex",
                  "text": "Niko here from Corridor Digital (big YouTube channel that does a bunch of AI in VFX and filmmaking experimentation if you‚Äôre not familiar). You are nailing it with this comment!",
                  "score": 136,
                  "created_utc": "2026-01-08 16:24:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyex8li",
                  "author": "SvenVargHimmel",
                  "text": "Can the LTX 2 model be coerced into image generation, i.e a single frame.\n\nSecond question is around the model, are there other outputs the model understands to construct beyond standard video output like can it export normalmaps or depthmap video?",
                  "score": 11,
                  "created_utc": "2026-01-08 15:37:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyewna7",
                  "author": "alecubudulecu",
                  "text": "This is awesome.  And THANK you for what you have done and continue to do for the community",
                  "score": 20,
                  "created_utc": "2026-01-08 15:34:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyezird",
                  "author": "UFOsAreAGIs",
                  "text": "Open Source The World!",
                  "score": 8,
                  "created_utc": "2026-01-08 15:47:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyex8yk",
                  "author": "TimeWaitsFNM",
                  "text": "Really excited for the future when like DLSS, there can be an AI overlay to improve realism in gaming.",
                  "score": 8,
                  "created_utc": "2026-01-08 15:37:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyfef57",
                  "author": "kh3t",
                  "text": "give this guy 10M immediately",
                  "score": 4,
                  "created_utc": "2026-01-08 16:53:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyfgpar",
                  "author": "That_Buddy_2928",
                  "text": "Cannot agree more with your assessment that models are evolving into rendering engines. Feel like this is the conceptual jump the antis have yet to make.",
                  "score": 5,
                  "created_utc": "2026-01-08 17:03:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyf6lqn",
                  "author": "FeelingVanilla2594",
                  "text": "I hope this answer ages like fine wine.",
                  "score": 3,
                  "created_utc": "2026-01-08 16:19:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyfnovr",
                  "author": "OlivencaENossa",
                  "text": "You are absolutely right. Well done and thank you. I am a part of a major ad conglomerate team that is working with AI. Is there any chance we could send a wish list of things we would like to see / talk about in future models ?",
                  "score": 5,
                  "created_utc": "2026-01-08 17:33:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyfkuou",
                  "author": "Arawski99",
                  "text": "I like this approach and makes sense.\n\nThis approach lets you focus on growth and adoption, which reinforces greater growth and adoption as research, tools, knowledge, and online resources/communities are established to further support it like the old SD, particularly 1.5, were.\n\nThis further fuels value and flexibility, known solutions and methodologies, and more thus ultimately leading to greater professional adoption, aka beyond the $10M point and thus a means to profit.\n\nMeanwhile, many of these static solutions limit much of their potential in countless ways and also bottleneck their own profit potential.\n\nhttps://i.redd.it/htm1l2o6t5cg1.gif",
                  "score": 3,
                  "created_utc": "2026-01-08 17:21:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyf15ko",
                  "author": "blazelet",
                  "text": "Is your tool able to generate 32 or 16 bit per channel outputs? Or is it limited to 8 bit?",
                  "score": 2,
                  "created_utc": "2026-01-08 15:54:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyf75py",
                  "author": "TekRabbit",
                  "text": "I like this. Cheers",
                  "score": 2,
                  "created_utc": "2026-01-08 16:21:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyfnnbo",
                  "author": "urbanhood",
                  "text": "Very smart, good approach.",
                  "score": 2,
                  "created_utc": "2026-01-08 17:33:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz60zfj",
                  "author": "Tall_Tradition_8918",
                  "text": "Finally some hope for a better future :) (coming here after seeing the world's richest CEO vilify energy and subtly suggesting destroying earth to protect American supremacy)",
                  "score": 2,
                  "created_utc": "2026-01-12 14:31:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyn67g8",
                  "author": "melonboy55",
                  "text": "Do you think that you will continue to release weights in the future? Does it seem like this revenue sharing model will work well enough to justify the cost of training?",
                  "score": 1,
                  "created_utc": "2026-01-09 18:38:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyhs9e7",
                  "author": "oberdoofus",
                  "text": "Do you see LTX as possibly being a rendering plugin within game engines like unreal or 3d progs like blender or as a standalone addition to a pipeline? Btw thank you for being open source!",
                  "score": 1,
                  "created_utc": "2026-01-08 23:13:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyi37rh",
                  "author": "physalisx",
                  "text": "I want to have 10 million just to share my profit upside with you",
                  "score": 1,
                  "created_utc": "2026-01-09 00:09:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nymrep0",
              "author": "Perfect-Campaign9551",
              "text": "They won't be honest. They did it because they weren't making any money anyway",
              "score": 1,
              "created_utc": "2026-01-09 17:32:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nygwo96",
              "author": "EgoIncarnate",
              "text": "It's not \"real\" open source, as it requires a paid license for anything beyond a small business. They appear to be co-opting the term for marketing purposes.",
              "score": 0,
              "created_utc": "2026-01-08 20:50:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyepuen",
          "author": "JusAGuyIGuess",
          "text": "Thank you for what you've done!\nGotta ask: what's next?",
          "score": 168,
          "created_utc": "2026-01-08 15:03:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyewscw",
              "author": "ltx_model",
              "text": "We're planning an incremental release (2.1) hopefully within a month - fixing the usual suspects: i2v, audio, portrait mode. Hopefully some nice surprises too.\n\nThis quarter we also hope to ship an architectural jump (2.5) - new latent space. Still very compressed for efficiency, but way better at preserving spatial and temporal details.\n\nThe goal is to ship both within Q1, but these are research projects - apologies in advance if something slips. Inference stack, trainer, and tooling improvements are continuous priorities throughout.",
              "score": 346,
              "created_utc": "2026-01-08 15:35:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyf3mst",
                  "author": "ConcentrateFit3538",
                  "text": "AmazingÔºÅWill these models be open source?",
                  "score": 57,
                  "created_utc": "2026-01-08 16:06:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyfihax",
                  "author": "nebulancearts",
                  "text": "As a fellow also doing research projects, thank you for your work, contribution, and efforts! It helps many!",
                  "score": 13,
                  "created_utc": "2026-01-08 17:10:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyf0xyj",
                  "author": "Secure-Message-8378",
                  "text": "Many thanks for release this model as open source. I'll use it for make content for Youtube and TikTok.  Many horror stories... Mainly with the possibility of use my own audios files for speech. Congratulations for this awesome model. Day one in comfyui.",
                  "score": 14,
                  "created_utc": "2026-01-08 15:54:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyfjfme",
                  "author": "martinerous",
                  "text": "Thank you for the awesome model!  \nWill the new latent space also help with prompt adherence?",
                  "score": 1,
                  "created_utc": "2026-01-08 17:15:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyfjsvh",
                  "author": "Arawski99",
                  "text": "Oh, that's nice to hear. Thanks for the ETA, even if not certain. Very understandable.",
                  "score": 1,
                  "created_utc": "2026-01-08 17:16:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyg53d2",
                  "author": "winterice77",
                  "text": "Thanks for this insight!",
                  "score": 1,
                  "created_utc": "2026-01-08 18:48:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyes1it",
          "author": "Version-Strong",
          "text": "Incredible work, you just changed Open Source video, dude. Congrats!",
          "score": 84,
          "created_utc": "2026-01-08 15:13:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyh5m9d",
              "author": "Sudden_List_2693",
              "text": "Yeah, so far it did mostly decent results, now we can have Nightmare Fuels all day!",
              "score": 1,
              "created_utc": "2026-01-08 21:29:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nygx28k",
              "author": "EgoIncarnate",
              "text": "It's not \"real\" open source, as it requires a paid license for anything beyond a small business. They appear to be co-opting the term for marketing purposes. This is more weights available, free for personal use.",
              "score": -8,
              "created_utc": "2026-01-08 20:52:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyh3h1y",
                  "author": "BackgroundMeeting857",
                  "text": "If someone wants free handouts after making 10 mill, yeah...I have the world's smallest violin ready to play",
                  "score": 16,
                  "created_utc": "2026-01-08 21:20:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyeshd8",
          "author": "protector111",
          "text": "you are awesome. we love you.",
          "score": 40,
          "created_utc": "2026-01-08 15:15:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyepudc",
          "author": "BoneDaddyMan",
          "text": "Have you seen the SVI loras for WAN2.2? Is it possible to have this implemented to LTX2? For further extension of the videos along with the audio?",
          "score": 51,
          "created_utc": "2026-01-08 15:03:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyew6rx",
              "author": "ltx_model",
              "text": "The model already supports conditioning on previous latents out of the box, so video extension is possible to some degree.  \n  \nFor proper autoregression on top of batch-trained models - the community has figured out techniques for this (see¬†[Self-Forcing](https://self-forcing.github.io/),¬†[CausVid](https://causvid.github.io/)). Waiting to see if someone applies it to LTX. Either way, I expect this to materialize pretty soon.",
              "score": 120,
              "created_utc": "2026-01-08 15:32:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyh5r5g",
                  "author": "Sudden_List_2693",
                  "text": "\"already supports conditioning on previous latents out of the box\"  \nI laughed very hard at it.",
                  "score": -3,
                  "created_utc": "2026-01-08 21:30:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyex0g5",
              "author": "Zueuk",
              "text": "LTX could extend videos for a *long* time",
              "score": 14,
              "created_utc": "2026-01-08 15:36:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyf1rnd",
                  "author": "Secure-Message-8378",
                  "text": "Yes. I did 10 secs videos in 128s average in a 3090. 1280x720. Awesome.",
                  "score": 18,
                  "created_utc": "2026-01-08 15:57:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyesidx",
          "author": "TheMotizzle",
          "text": "First of all, thank you! Ltx-2 is awesome so far and shows a lot of promise. \n\nWhat are the plans to introduce features like first/last frame, v2v, pose matching, face replacement, lip syncing, etc. Apologies if some of this already exists.",
          "score": 36,
          "created_utc": "2026-01-08 15:15:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyg9re6",
              "author": "ltx_model",
              "text": "A lot of that is actually supported on some level - IC-LoRAs for pose, depth, canny. I think people will figure out how to train more and we want to facilitate it.  \n  \nFirst/last frame should work to a certain degree but not amazing well yet - the model didn't see much of that during pre-training. We'll try to add a dedicated LoRA or IC-LoRA on top of the base/distilled model that excels at this, or figure out another solution.  \n  \nSince frame interpolation is critical for animation, we're making a focused effort here - beyond just frames, also matching motion dynamics between segments so production-level animation actually becomes viable on top of diffusion models.",
              "score": 30,
              "created_utc": "2026-01-08 19:08:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nygneak",
                  "author": "ColbyandJack",
                  "text": "I have been enjoying the IC-LoRA system with your previous open source model. I was also enjoying using a batch of multiple reference images as ‚Äúkeyframes‚Äù which works well. What are your thoughts on an ecosystem to use these things in tandem? They seem to have different samplers so they cant be used at the same time. A more universal multimodal workflow that allows for mix and match of control/guidance features would make it the ultimate production beast.",
                  "score": 1,
                  "created_utc": "2026-01-08 20:09:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyh6815",
                  "author": "TheMotizzle",
                  "text": "Awesome thanks!",
                  "score": 1,
                  "created_utc": "2026-01-08 21:32:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nytnalz",
                  "author": "Neighborhood-Brief",
                  "text": "Have you guys seen SCAIL?  It's really starting to get good for vfx work with things like the SCAIL pose matching. It means we can start getting the control, predictability and repeatability needed for professional vfx work.  \nIt would be great if the ai commuity started developing a more high fidelity guidience system for facial performance. The currently used one just doesn't have enough features/markers supported to do good face capture.",
                  "score": 1,
                  "created_utc": "2026-01-10 17:58:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyf8s2r",
              "author": "RoughPresent9158",
              "text": "lip syncing is an basic part of the model. pose depth and canny are in the Ic-Lora flow here:  \n[https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example\\_workflows](https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example_workflows).\n\nAbout the rest... good question, will be interested to know.",
              "score": 18,
              "created_utc": "2026-01-08 16:28:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyfdon5",
              "author": "kabachuha",
              "text": "FLF is native thanks to LTXVAddGuide node (vanilla Comfy)",
              "score": 3,
              "created_utc": "2026-01-08 16:50:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyeq9mg",
          "author": "Lollerstakes",
          "text": "Is it Light Ricks (as in there's someone naned Rick at your company) or is it a play on Light Tricks?",
          "score": 48,
          "created_utc": "2026-01-08 15:05:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygvgfn",
              "author": "ltx_model",
              "text": "The latter.",
              "score": 15,
              "created_utc": "2026-01-08 20:45:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nygwybj",
                  "author": "gefahr",
                  "text": "Thanks, Rick!",
                  "score": 7,
                  "created_utc": "2026-01-08 20:51:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nygwjlm",
                  "author": "Lollerstakes",
                  "text": ":)\n\nYou guys are doing an amazing job. Please don't ever stop!",
                  "score": 2,
                  "created_utc": "2026-01-08 20:49:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyet1c9",
              "author": "AFMDX",
              "text": "Asking the important questions!",
              "score": 13,
              "created_utc": "2026-01-08 15:18:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyfwhm2",
              "author": "mainichi",
              "text": "Ligh Tricks, a particularly mischievous employee with the uncommon name Ligh",
              "score": 11,
              "created_utc": "2026-01-08 18:12:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyesyy2",
          "author": "syddharth",
          "text": "Congratulations on the brilliant model release. \nWould you guys work on an image/edit model in the future?",
          "score": 15,
          "created_utc": "2026-01-08 15:17:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyewj3i",
              "author": "ltx_model",
              "text": "Thanks! Image model isn't a priority at the moment - releasing more of the post-training infra is.  \n  \nWe want people to come with their own datasets and fine-tune for their specific needs. Soon we hope to open up distillation and RL processes too, so you'll be able to play with parameter counts and tweak performance for your use case.",
              "score": 57,
              "created_utc": "2026-01-08 15:34:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyexbok",
                  "author": "syddharth",
                  "text": "Thanks for the reply. Looking forward to training loras and using other emergent tech on LTX2. Best wishes for the future, hope you guys achieve everything you want and deserve üôè",
                  "score": 5,
                  "created_utc": "2026-01-08 15:37:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyn79zv",
                  "author": "melonboy55",
                  "text": "Planning on doing exactly this ‚ù§Ô∏è",
                  "score": 1,
                  "created_utc": "2026-01-09 18:42:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyepppf",
          "author": "One-Thought-284",
          "text": "Any tips on getting consistent quality from generations? Also thanks for the awesome model and releasing it Open Source :)",
          "score": 30,
          "created_utc": "2026-01-08 15:02:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyetmkd",
              "author": "ltx_model",
              "text": "Yes. Longer, more detailed prompts make a big difference in outcomes. We have a prompting guide here:¬†[https://ltx.io/model/model-blog/prompting-guide-for-ltx-2](https://ltx.io/model/model-blog/prompting-guide-for-ltx-2)  \n  \nAnd the LTX Discord community both on our server and on Banodoco is a great community to ask questions and learn.",
              "score": 101,
              "created_utc": "2026-01-08 15:20:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyf7hxc",
                  "author": "RoughPresent9158",
                  "text": "you can also use the enhancer in the official flows:  \n[https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example\\_workflows](https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example_workflows)\n\nAnd / look at the system prompts there to learn a bit more how to prompt better ;)",
                  "score": 11,
                  "created_utc": "2026-01-08 16:23:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyeu07s",
                  "author": "One-Thought-284",
                  "text": "Okay awesome thanks :)",
                  "score": 3,
                  "created_utc": "2026-01-08 15:22:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nygtzqk",
              "author": "Different_Fix_2217",
              "text": "If using I2V try 48 fps btw. It helps alleviate the issues due to the temporal compression they use which can cause glitchy fast motions.",
              "score": 1,
              "created_utc": "2026-01-08 20:38:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nygxcca",
              "author": "EgoIncarnate",
              "text": "It's not \"real\" open source, as it requires a paid license for anything beyond a small business. They appear to be co-opting the term for marketing purposes. This is more weights available, free for personal use.",
              "score": 0,
              "created_utc": "2026-01-08 20:53:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyhknru",
                  "author": "ptwonline",
                  "text": "That seems pretty reasonable to me.",
                  "score": 2,
                  "created_utc": "2026-01-08 22:36:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyetmmw",
          "author": "Admirable-Star7088",
          "text": "Thank you so much for this open model, I'm loving it so far. You have given people the opportunity to finally run \"Sora 2\" at home!\n\nMy question is, do you intend to release incremental smaller updates/refinements to LTX‚Äë2, such as LTX‚Äë2.1, 2.2, 2.3, etc, at relatively short intervals, or will you wait to launch a substantially upgraded version like LTX‚Äë3 sometime further into the future?",
          "score": 13,
          "created_utc": "2026-01-08 15:20:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyexmrx",
              "author": "ltx_model",
              "text": "Thanks, really glad you're enjoying it!\n\nWe're working on two parallel tracks: incremental release to improve the current gen - fixing issues, adding features - and architectural bets to keep pushing the quality/efficiency ratio.\n\nIncremental releases are easier to predict and should come at relatively short intervals. Architectural jumps are more speculative, harder to nail exact dates. You'll see both.",
              "score": 49,
              "created_utc": "2026-01-08 15:39:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyf092p",
                  "author": "Admirable-Star7088",
                  "text": "I see, sounds great. Thanks for the reply, and I wish you good luck!",
                  "score": 3,
                  "created_utc": "2026-01-08 15:50:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nygmbun",
                  "author": "sdimg",
                  "text": "I hope you guys can get a fix soon for some of the issues because this has a ton of potential but wan still has the edge visually and consistency. Speed and workflow seem decent and it looks like ltx2 should be good but im getting poor results for both t2v and i2v far too often. This is on brand new comfy install and following recommendations.\n\nSo far the biggest issue apart from varying quality is i2v regularly seems to refuse to do much with the image. Despite good prompting it does stupid stuff like have motionless character and face moves only after a bit or it literally hard cuts immediately and pretty much ignores the input image which completely defeats the point of i2v!?\n\nI have faith the community will squeeze a lot out of this and its early days but im waiting for initial excitement to fade so we can see the actual reality of it. I'm having some doubt it will live up to expectations but hopeful if your team/community can overcome some of the frustrating issues, especially as its the only half decent audio model we've seen.\n\nIf a prompt is ran there should always be some decent motion and progression, it must make use fully of the input image each gen at least otherwise it becomes less desirable to run despite the speed. Wan pretty consistently outputs something decent where ltx2 currently is failing here. I want it to be great but something really needs to be done about this?",
                  "score": 1,
                  "created_utc": "2026-01-08 20:04:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyetq6w",
          "author": "lordpuddingcup",
          "text": "No question really just wanted to say congrats and thank you for following through and not abandoning the OSS community",
          "score": 11,
          "created_utc": "2026-01-08 15:21:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyes5e3",
          "author": "CurrentMine1423",
          "text": "I just want to say THANK YOU !",
          "score": 24,
          "created_utc": "2026-01-08 15:13:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyergqb",
          "author": "scruffynerf23",
          "text": "Can you discuss the limits of what you couldn't train in (nsfw, copyrighted material, etc) for legal reasons, and how that affects the model, and if the community retraining the open weights will improve it's range/ability?",
          "score": 62,
          "created_utc": "2026-01-08 15:10:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nymb9yi",
              "author": "Nevaditew",
              "text": "Funny that a bunch of questions got replies right before and after yours, yet yours was the only one skipped. They clearly want nothing to do with NSFW :(. I don't see why it's such a big deal‚Äîhas any image or video model actually failed because of its connection to NSFW?",
              "score": 8,
              "created_utc": "2026-01-09 16:19:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyzr0ej",
                  "author": "scruffynerf23",
                  "text": "Sometimes the silence is the answer",
                  "score": 2,
                  "created_utc": "2026-01-11 16:19:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyn42zt",
                  "author": "revolvingpresoak9640",
                  "text": "Meanwhile copyright is clearly not a problem. One of my illustrated i2v runs gave me Peppa Pig entirely randomly.",
                  "score": 0,
                  "created_utc": "2026-01-09 18:28:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyerwy4",
          "author": "scruffynerf23",
          "text": "The community got very upset at Wan 2.6+ going closed source/API only.  Wan 2.1/2.2 had a lot of attention/development work from the community.  What can you do to help show us that you won't follow that path in the future?  In other words, how can you show us a commitment to open weights in the future?",
          "score": 66,
          "created_utc": "2026-01-08 15:12:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyey3t3",
              "author": "ltx_model",
              "text": "I get the concern, but I want to reframe it: we don't think of open weights as charity or community goodwill. It's core to how we believe rendering engines need to be built.  \n  \nYou wouldn't build a game engine on closed APIs - you need local execution, deep integration, customization for your specific pipeline. Same logic applies here. As models evolve into full rendering systems with dozens of integration points, open weights isn't a nice-to-have, it's the only architecture that works.  \n  \nWe benefit from the community pushing boundaries. The research community benefits from access. Creators benefit from tools they can actually integrate. It's not altruism, it's how you build something that actually becomes infrastructure.  \n  \nClosing the weights would break our own thesis.",
              "score": 208,
              "created_utc": "2026-01-08 15:41:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyez4fq",
                  "author": "ChainOfThot",
                  "text": "How do you fund yourself?",
                  "score": 20,
                  "created_utc": "2026-01-08 15:45:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyf1b7z",
                  "author": "kemb0",
                  "text": "I think this is a great point. The number of people prepared to do local video gen is tiny compared to the size of the potential commercial market, so no need to cut those guys off by locking down your models.\n\nHaving said that, I‚Äôd personally be ok paying for early access to the newest models. I know some here will hate me for saying that but we need to make sure companies like yours will be profitable so why not offer a mid way house where you guys can make money from early access but it‚Äôll become available for all at some point too. After all, you are offering a great product that deserves to make money.",
                  "score": 6,
                  "created_utc": "2026-01-08 15:55:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyf6vvz",
                  "author": "comperr",
                  "text": "I disagree about the game engine part, Cryengine was amazing and I only got to experience it when Crysis 2 development sandbox ISO was leaked on torrents. But anyways I love the open source work you did thanks",
                  "score": 0,
                  "created_utc": "2026-01-08 16:20:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyjspda",
                  "author": "Abject-Recognition-9",
                  "text": "This man, this company, in a random reply here on Reddit, understood everything and basically paved the future flat.\n\nThis is not China putting obstacles in the way of American big tech companies.   \nThis is about someone who has finally grasped the fundamentals of CGI in the new millennium and has planted a clear stake in the ground that will allow them to monetize, in the most ethical way possible (which is already difficult in the AI field), by pushing the concept of generative AI as a rendering engine ecosystem.\n\nIt is somewhat a business model in the style of Unreal Engine and similar platforms. And, to everyone‚Äôs benefit, it consequently supports small creators and the open-source community, which is ultimately the essential component: the one that tests every possible scenario and implements new tools for the entire ecosystem.\n\nI truly hope this business model remains sustainable and continues to be upheld by Lightricks. I read the entire post almost with tears in my eyes and, at times, in disbelief. I hope all of this is real: \n\nyou are like a light at the end of a tunnel full of uncertainties.\n\nThank you, LTX.",
                  "score": 0,
                  "created_utc": "2026-01-09 06:02:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyfw38a",
                  "author": "johnfkngzoidberg",
                  "text": "This guy gets it.",
                  "score": 0,
                  "created_utc": "2026-01-08 18:10:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyjn81q",
                  "author": "Ylsid",
                  "text": "Not to nitpick but people absolutely build game engines on closed source APIs, like DirectX.",
                  "score": 0,
                  "created_utc": "2026-01-09 05:22:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyevhws",
              "author": "Downtown-Accident-87",
              "text": "I don't think they need to prove anything. You should just be happy they release things, don't forget you (and I) are not entitled to anything from anyone.",
              "score": 8,
              "created_utc": "2026-01-08 15:29:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyezz8b",
                  "author": "GreyScope",
                  "text": "Entitlement is out of the range of measuring instruments here",
                  "score": 6,
                  "created_utc": "2026-01-08 15:49:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nygheen",
                  "author": "Myfinalform87",
                  "text": "Agreed considering they have open sourced every previous model. They have a history of releasing open source even tho the community didn‚Äôt always support the models",
                  "score": 1,
                  "created_utc": "2026-01-08 19:42:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyfho4y",
              "author": "GasolinePizza",
              "text": "> development work from the community\n\nWhat did the community give back to the WAN team, as far as development work?\n\nYou phrased it to make it sound like they took advantage of the community, rather than them gifting the community a model and the community helped itself by building tooling around it. None of that went back to them to make their model training cheaper or better, or faster (or at least not in any sort of remotely significant, measurable way).\n\nWhy do you think we're all owed some sort of guarantee or promise for even more free stuff indefinitely, all while giving very little back?",
              "score": 1,
              "created_utc": "2026-01-08 17:07:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyhlyol",
                  "author": "ptwonline",
                  "text": "Community definitely gives a lot of feedback for the kind of tools and functionality and features they want from a model, as well as identifying strengths and weaknesses.  Basically a combo of QA and market research.\n\nPlus the community can come up with innovative ways to make certain kinds of things work that the developers can then learn from and implement themselves, or else see if it doesn't work.",
                  "score": 2,
                  "created_utc": "2026-01-08 22:42:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyesg49",
          "author": "kabachuha",
          "text": "Thank you! Is the next step Sora 2 / Holocine - like multishot generation? Holocine's block-sparse attention is an interesting thing in this direction, to keep the scenes \"glued\"",
          "score": 11,
          "created_utc": "2026-01-08 15:15:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyf33vf",
              "author": "ltx_model",
              "text": "Sure, multiple references and multi-shot generation are becoming table stakes - we're working on it. Seems pretty close at the moment.",
              "score": 43,
              "created_utc": "2026-01-08 16:03:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyeuwej",
          "author": "DavesEmployee",
          "text": "What were some of the biggest technical challenges in training this model compared to previous versions?",
          "score": 8,
          "created_utc": "2026-01-08 15:26:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygex9g",
              "author": "ltx_model",
              "text": "My personal perspective - some researchers on the team would see it differently:\n\n* **Diffusability of deep tokens.** Getting a compressed latent space to actually recover spatio-temporal details through deep tokens (high amount of channels in the latent) is tricky. Required a lot of experimentation, still requires more as we want to keep aggressive compression for efficiency, while reclaiming more and more details.\n* **Audio-video sync** proved more challenging than we initially estimated. Not a lot of literature on this, closed labs are pretty secretive about it - felt like trailblazing.\n\nTon of engineering challenges around efficient data handling, training optimization etc - but those are shared across everyone training models at scale I think.",
              "score": 28,
              "created_utc": "2026-01-08 19:31:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyeqy5h",
          "author": "Maraan666",
          "text": "would it be possible to implement a simpler way of training a lora for the sole purpose of character consistency, using only images, and with lower vram requirements?",
          "score": 16,
          "created_utc": "2026-01-08 15:08:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyg8wwu",
              "author": "ltx_model",
              "text": "The trainer supports training on still images (see¬†[this](https://github.com/Lightricks/LTX-2/blob/main/packages/ltx-trainer/docs/dataset-preparation.md#-dataset-format)¬†section in the documentation).  \nMemory usage when training on images is typically lower compared to videos, unless extremely high image resolutions are targeted.",
              "score": 11,
              "created_utc": "2026-01-08 19:05:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyh6bas",
                  "author": "VRGoggles",
                  "text": "Please extend the training script to support offloading model/text encoder etc files to RAM. Distorch does that wonderfully in ComfyUI, so no matter if the model is 40GB or 8GB... only actual calculations are done on GPU in VRAM. \nWould be awesome if LTX trainer could do the same.",
                  "score": 1,
                  "created_utc": "2026-01-08 21:32:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nykpc1q",
                  "author": "Maraan666",
                  "text": "Thanks for the reply. I'll give it a shot.",
                  "score": 0,
                  "created_utc": "2026-01-09 10:48:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyr2btu",
              "author": "Silly-Cycle3080",
              "text": "Is there any way you can update us on your progress at that front?  I'm searching for a decent workflow that uses quen image 2511 to create a dataset for consistent character lora training.",
              "score": 1,
              "created_utc": "2026-01-10 07:42:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyerk7s",
          "author": "altertuga",
          "text": "Is the plan to create a sustainable business around open source models by selling services, or is this a way to market future models, or maybe a freemium style where there is concurrent version that is always better than the open source?\n\nThanks for making this one a available.",
          "score": 10,
          "created_utc": "2026-01-08 15:11:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyfezdz",
              "author": "ltx_model",
              "text": "TLDR: We monetize through licensing \n\nMore complete answer here:  [https://www.reddit.com/r/StableDiffusion/comments/1q7dzq2/comment/nyetfom/](https://www.reddit.com/r/StableDiffusion/comments/1q7dzq2/comment/nyetfom/)",
              "score": 18,
              "created_utc": "2026-01-08 16:55:39",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nygwh0q",
              "author": "EgoIncarnate",
              "text": "It's not \"real\" open source, as it requires a paid license for anything beyond a small business. They appear to be co-opting the term for marketing purposes. This is more weights available, free for personal use.",
              "score": -1,
              "created_utc": "2026-01-08 20:49:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyh6x0s",
                  "author": "VRGoggles",
                  "text": "This is very good actually. End users who generate videos can do it freely. Big guys who wanto to use LTX work to make money by generating videos for others have to pay.\nWAN should have done the same long time ago instead of rippping fans off.",
                  "score": 8,
                  "created_utc": "2026-01-08 21:35:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyerlah",
          "author": "vienduong88",
          "text": "Will something like inputting multiple elements (object/background/character) to generate video possible? Or something like quick lora, just input multiple images of a character and create video with it?",
          "score": 6,
          "created_utc": "2026-01-08 15:11:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygarkf",
              "author": "ltx_model",
              "text": "Adding context and references is exactly what IC-LoRA was built for. We are planning to ship more use-cases similar to that, but you can use our trainer to create the exact type of context you want.  \n  \nNote: while powerful and flexible, some reference injection might require longer finetunes, more data or even architectural changes.",
              "score": 4,
              "created_utc": "2026-01-08 19:13:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nygecd5",
                  "author": "vienduong88",
                  "text": "That‚Äôs great, thank you for your hard work!",
                  "score": 1,
                  "created_utc": "2026-01-08 19:28:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyet50d",
          "author": "Seyi_Ogunde",
          "text": "Thank you and your company for your work. Any plans for an audio to video model? Upload an audio and still and generate a talking video based on those inputs?\n\nOr be able to upload an audio sample and have the output create video + audio with the same voice?",
          "score": 6,
          "created_utc": "2026-01-08 15:18:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyeu181",
              "author": "Appropriate_Math_139",
              "text": "for using an audio sample you provide, and then use it as a guide for any new audio, we are working on more elaborate solutions but this can be hacked as a kind of video continuation task which is relatively straightforward, see on banodoco.",
              "score": 3,
              "created_utc": "2026-01-08 15:22:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyetur9",
              "author": "Appropriate_Math_139",
              "text": "audio2video is relatively straightforward, there are some workflows for that already on the Banodoco discord server.",
              "score": 2,
              "created_utc": "2026-01-08 15:21:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyrjt90",
              "author": "Kmaroz",
              "text": "Arent theres Kijai workflow out there done it?",
              "score": 1,
              "created_utc": "2026-01-10 10:24:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyeth99",
          "author": "DavesEmployee",
          "text": "Do you see the speed of model improvements and releases slowing down this year as progress gets more challenging, especially with open source releases?",
          "score": 5,
          "created_utc": "2026-01-08 15:20:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyez2wt",
              "author": "ltx_model",
              "text": "We're starting to understand transformers and their inherent limitations - context window is a quadratic problem, error accumulation issues. But the sheer surface area of research and engineering improvements is so vast right now that I think end results will keep improving nicely this year.  \n  \nOnce basic generation quality reaches a certain maturity, the focus will shift - control, latency, figuring out ways to compress context will take the front row. Already seeing a lot of academic activity there, justifiably so.",
              "score": 34,
              "created_utc": "2026-01-08 15:45:41",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nygxixh",
              "author": "EgoIncarnate",
              "text": "It's not \"real\" open source, as it requires a paid license for anything beyond a small business. They appear to be co-opting the term for marketing purposes. This is more weights available, free for personal use.",
              "score": -1,
              "created_utc": "2026-01-08 20:54:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyf992w",
          "author": "entmike",
          "text": "Ironic to use an image for ID verification in an Gen AI subreddit.   :)\n\n  \nThank you for LTX-2!",
          "score": 8,
          "created_utc": "2026-01-08 16:31:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyfgcys",
              "author": "Zueuk",
              "text": "if you don't believe that picture is real, there's a [video](https://cdn.discordapp.com/attachments/1309520535012638740/1458849414155210795/ltx-1767882.mp4?ex=696122e4&is=695fd164&hm=eed11fbd5a4cfb103f18baacda48bbc0d13d2f7a1eb352c4857f37e898861468&) too!",
              "score": 11,
              "created_utc": "2026-01-08 17:01:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyfk4nu",
                  "author": "entmike",
                  "text": "Well played!",
                  "score": 3,
                  "created_utc": "2026-01-08 17:18:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyew589",
          "author": "Valuable_Issue_",
          "text": "Is the I2V static video/simple camera zoom just a flaw of the model? Or is it fixable with settings (template ComfyUI workflow with the distilled model).\n\nAlso I hope the ComfyUI nodes for the next model release are cleaner, the split files work a lot better on lower vram/ram, the other stock nodes in the template workflows load the same file multiple times, making the peak memory usage on model load a lot higher than it should be, whereas this works a lot better (and fits the typical modular node design a lot better): \n\nhttps://github.com/city96/ComfyUI-GGUF/issues/398#issuecomment-3723579503",
          "score": 6,
          "created_utc": "2026-01-08 15:32:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyfprcv",
              "author": "ltx_model",
              "text": "This is somewhat fixable with the LTXVPreprocess node acting on the input image, also with careful prompting and with using conditioning strength that's lower than 1.",
              "score": 6,
              "created_utc": "2026-01-08 17:42:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyf1j86",
          "author": "lacerating_aura",
          "text": "Hi, congratulations on a successful release and thank you very much for open weights. I'm asking this just out of curiosity.\n‚Äã\nThe Qwen team recently released a model, Qwen-Image-Edit-Layered. Although it seemed like an early iteration with limited local performance, the concept of decomposing generation into layers for targeted edits is a clever approach for precise control.\n‚Äã\nI understand that LTX-2 isn't primarily targeted as an editing model, but do you think it would be possible for video models to adopt a similar layered format in generation?\n\n‚ÄãSince LTX-2 already generates synced audio and video, would it be possible to add additional video streams that target specified regions of the frame (spatial layers)?\n‚Äã\nOn that note, do you think it will be possible to support an Alpha Channel in LTX? If the model supported transparency, generation could potentially be split into layers manually via a clever workflow and recombined at the output stage.\n\n‚ÄãThank you again for your contribution.",
          "score": 5,
          "created_utc": "2026-01-08 15:56:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygak3u",
              "author": "ltx_model",
              "text": "This is an interesting research direction that's crossed our minds before. We can't make any promises.   \n  \nWould be lovely if this came from the community or academia.",
              "score": 7,
              "created_utc": "2026-01-08 19:12:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyf2i2j",
          "author": "stonyleinchen",
          "text": "I have a question about censorship in the model, did you put in some extra effort into censoring female breasts and genitalia in general (like through finetuning or whatever), or is the current output just the result from having absolutely no genitalia/female breasts in the trainingdata? Because curiously, the model often undresses characters of me without prompting that, and then it shows like breasts without nipples and stuff like that...which makes me think there is at least some undressing/striptease content in the trainingdata. (for example I had a picture of a woman in a swimsuit wearing swimming goggles, and i prompted that she takes off the goggles, and she just took off the whole swimsuit (while leaving the goggles on) but her upper body was just some bodyhorrorstuff)",
          "score": 15,
          "created_utc": "2026-01-08 16:00:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nymk7ho",
              "author": "Sad-Chemist7118",
              "text": "Try to prompt differently. Wait, there's this paper about jailbreaking frontier models using poetry maybe it works here, too?",
              "score": 1,
              "created_utc": "2026-01-09 16:59:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyesai6",
          "author": "Apprehensive_Set8683",
          "text": "Great job on LTX-2 it's amazing!",
          "score": 11,
          "created_utc": "2026-01-08 15:14:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyes2p5",
          "author": "sotavision",
          "text": "Any plan for editing model? What‚Äôs your prediction on the technical landscape of image/video generation in 26? Thanks for running this AMA and LTX‚Äôs contribution to the community!",
          "score": 8,
          "created_utc": "2026-01-08 15:13:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyeumqo",
          "author": "Budget_Stop9989",
          "text": "Your company offers LTX-2 Pro and LTX-2 Fast as API models. How do the open-source models, LTX-2 dev and LTX-2 Distilled, correspond to the API models? For example, does LTX-2 dev correspond to LTX-2 Pro, and does LTX-2 Distilled correspond to LTX-2 Fast? Thanks for open-sourcing the models!",
          "score": 10,
          "created_utc": "2026-01-08 15:25:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyf0kb6",
              "author": "ltx_model",
              "text": "No, the setups are not exactly the same, they have some differences related to our timelines for building both API and the open source release, and to the hardware we use in the API. We hope to keep them pretty much aligned but not at perfect parity.",
              "score": 16,
              "created_utc": "2026-01-08 15:52:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyewgw9",
          "author": "ramonartist",
          "text": "Hats off üé© this is perfect marketing, and transparency, every company should take note, fantastic model üëåüèæ",
          "score": 8,
          "created_utc": "2026-01-08 15:33:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyeszkw",
          "author": "coolhairyman",
          "text": "What lessons from building LTX-2 changed how you think about the future of open multimodal AI compared to closed, API-driven models?",
          "score": 5,
          "created_utc": "2026-01-08 15:17:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygvokq",
              "author": "ltx_model",
              "text": "The core lesson: as models evolve into rendering engines, the integration surface area explodes. Dozens of input types, output formats, pipeline touchpoints. Static APIs can't cover it.  \n  \nWhen you're trying to plug into real VFX workflows, animation pipelines, video editing tools - you need weights on the machine. You need people customizing for their specific constraints. Closed works fine for interfaces where inputs and outputs are clear and API is narrow and simple. For multimodal creative tools that need to integrate everywhere and run on edge? Open is the only architecture that makes sense at the moment.  \n  \nThe other lesson: research community moves faster than any internal team. Letting thousands of smart people experiment isn't generosity, but the only way to be relevant vs giants like Google.",
              "score": 13,
              "created_utc": "2026-01-08 20:46:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyf3ycl",
          "author": "leepuznowski",
          "text": "As I am actively integrating AI tools into a tv production pipeline, quality is our number one focus. Currently testing LTX-2, but am not quite reaching the image quality we need. As you mentioned focus on production tools, is it possible to get minimal noise distortion in moving scenes? I am able to get this very close with Wan 2.2 at 1080p, but with LTX-2 I am seeing more ai \"pattern\" showing up in higher fidelity scenes. Thanks for the amazing tools.",
          "score": 3,
          "created_utc": "2026-01-08 16:07:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyglgrx",
              "author": "ltx_model",
              "text": "It's possible to progressively add details beyond the base/refiner we showed in the ComfyUI examples.  \n  \nBeyond two levels of refinement, it requires tiling mechanisms that aren't trivial on consumer hardware - our production implementation runs on multi-GPU setups. We're considering adding an API for this.  \n  \nLonger term, we're working on a new latent space (targeting LTX-2.5) with much better properties for preserving spatial and temporal details - should help significantly with the pattern artifacts you're seeing.",
              "score": 9,
              "created_utc": "2026-01-08 20:00:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyero9i",
          "author": "Nu7s",
          "text": "What are your views on censorship?",
          "score": 23,
          "created_utc": "2026-01-08 15:11:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyeujbp",
              "author": "i_have_chosen_a_name",
              "text": "Does that really matter when it's open source and open weight? 99,99% of the man that run these companies like porn, they just don't like to get sued or dropped from Visa/Mastercard",
              "score": 10,
              "created_utc": "2026-01-08 15:24:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nygj9is",
                  "author": "Myfinalform87",
                  "text": "Bingo! That‚Äôs why the companies release it the way they do and let community develop nsfw Lora‚Äôs and doesn‚Äôt hold them liable. It‚Äôs the best way to approach it tbh",
                  "score": 3,
                  "created_utc": "2026-01-08 19:50:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyepxny",
          "author": "Zealousideal_Rich_26",
          "text": "What the  next step for LTX ? Fixing audio ?",
          "score": 9,
          "created_utc": "2026-01-08 15:03:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyeuc15",
              "author": "ltx_model",
              "text": "Audio is definitely on the list, but it's part of a broader push.  \n  \nWe're planning an incremental release (2.1) hopefully within a month - fixing the usual suspects: i2v, audio, portrait mode. Hopefully some nice surprises too.  \n  \nThis quarter we also hope to ship an architectural jump (2.5) - new latent space. Still very compressed for efficiency, but way better at preserving spatial and temporal details.  \n  \nThe goal is to ship both within Q1, but these are research projects - apologies in advance if something slips. Inference stack, trainer, and tooling improvements are continuous priorities throughout.",
              "score": 62,
              "created_utc": "2026-01-08 15:24:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyezocy",
                  "author": "SufficientRow6231",
                  "text": "Okay, so turns out there is an issue with portrait and I2V.\n\nFunny how people were downvoting and calling it ‚Äúskill issues‚Äù yesterday when the community called it out, the LTX CEO literally just confirmed it here.",
                  "score": 5,
                  "created_utc": "2026-01-08 15:48:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyerjq9",
          "author": "James_Reeb",
          "text": "A BiG Thanks ! Can we train our audio with our sound library as dataset ? Can we have sound to video  ( using real human voice  ) ?",
          "score": 7,
          "created_utc": "2026-01-08 15:11:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyesmxe",
              "author": "Appropriate_Math_139",
              "text": "audio2video is relatively straightforward, there are some workflows for that already on the Banodoco discord server.",
              "score": 11,
              "created_utc": "2026-01-08 15:16:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyfqp0d",
                  "author": "ltx_model",
                  "text": "\\^\\^\\^this",
                  "score": 7,
                  "created_utc": "2026-01-08 17:47:03",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyet1x2",
          "author": "HAWKxDAWG",
          "text": "Do you think the current unprecedented investment into building AI data centers a risk that could hinder future innovation? And do you believe that continued democratization of AI models (e.g., LTX-2) that can be run on consumer GPUs can sufficiently level the playing field before the infrastructure bet becomes \"too big to fail\"?",
          "score": 6,
          "created_utc": "2026-01-08 15:18:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyezmil",
              "author": "ltx_model",
              "text": "Right now we're seeing two complementary pushes - some folks keep scaling up (params, data, compute) hoping for meaningful returns, while others are optimizing for efficiency.  \n  \nI'd say¬†*very cautiously*¬†that pure scaling seems to be showing diminishing returns, while on efficiency we're still in early days. Where exactly we land, I don't think anyone knows.  \n  \nFrom that perspective of uncertainty, over-extending the data center bet without hedging with other approaches does seem problematic. The infrastructure lock-in risk is real if efficiency gains outpace scaling gains.",
              "score": 33,
              "created_utc": "2026-01-08 15:48:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyewz2s",
          "author": "Fair-Position8134",
          "text": "The main reason WAN became what it is today is community-driven research. For that kind of research to thrive, a permissive license is essential. Do you think the current license is permissive enough to support meaningful research?",
          "score": 5,
          "created_utc": "2026-01-08 15:36:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygtr72",
              "author": "ltx_model",
              "text": "For research - absolutely. Academics and researchers can experiment freely, no restrictions.  \n  \nCommercial use is free under $10M revenue. Above that, licensing and rev-share kicks in. We see this as a win-win: you build something great, we share in the upside. You're experimenting or under that threshold - it's free. Research community pushes boundaries, we all benefit from the progress.  \n  \nHonestly, I'm not sure how to build something sustainable otherwise. Game engines are the inspiration here - Unity, Unreal. Vibrant ecosystems and communities, clear value exchange. That's the model.",
              "score": 21,
              "created_utc": "2026-01-08 20:37:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyepuix",
          "author": "Last_Ad_3151",
          "text": "Thank you for the tremendous contribution to the open source community. The amount that's been packed into this model is truly inspiring.",
          "score": 8,
          "created_utc": "2026-01-08 15:03:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygwl7v",
              "author": "EgoIncarnate",
              "text": "It's not \"real\" open source, as it requires a paid license for anything beyond a small business. They appear to be co-opting the term for marketing purposes. This is more weights available, free for personal use.",
              "score": 0,
              "created_utc": "2026-01-08 20:50:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyeqsx0",
          "author": "fauni-7",
          "text": "Thanks for your awesome work!",
          "score": 9,
          "created_utc": "2026-01-08 15:07:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyer3yk",
          "author": "Specialist_Pea_4711",
          "text": "The GOAT of the open source community. Thank you sir.",
          "score": 8,
          "created_utc": "2026-01-08 15:09:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygwkfv",
              "author": "EgoIncarnate",
              "text": "It's not \"real\" open source, as it requires a paid license for anything beyond a small business. They appear to be co-opting the term for marketing purposes. This is more weights available, free for personal use.",
              "score": 1,
              "created_utc": "2026-01-08 20:50:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyih4u6",
                  "author": "Specialist_Pea_4711",
                  "text": "You can use it for free until you make 10 million, like anyone else here is gonna ever hit that number using only LTX 2.",
                  "score": 2,
                  "created_utc": "2026-01-09 01:22:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyeskla",
          "author": "vizualbyte73",
          "text": "What's the model and setting for 4080 users wanting local comfyui workflows?",
          "score": 3,
          "created_utc": "2026-01-08 15:15:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygihl4",
              "author": "ltx_model",
              "text": "This is evolving rapidly. The community has been sharing their explorations both here and on Discord.",
              "score": 5,
              "created_utc": "2026-01-08 19:47:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyezt4t",
          "author": "blueredscreen",
          "text": "Any plans for v2v in terms of upscaling? Would be interesting to do inference on existing video textures vs generating only brand new ones.",
          "score": 3,
          "created_utc": "2026-01-08 15:48:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyfq16l",
              "author": "ltx_model",
              "text": "Yes. We released a video upscaling flow as part of the open source release:   \n[https://github.com/Lightricks/ComfyUI-LTXVideo/blob/master/example\\_workflows/LTX-2\\_V2V\\_Detailer.json](https://github.com/Lightricks/ComfyUI-LTXVideo/blob/master/example_workflows/LTX-2_V2V_Detailer.json)",
              "score": 18,
              "created_utc": "2026-01-08 17:44:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyezvkv",
          "author": "bregmadaddy",
          "text": "Any prompting best practices? \n\nIs there a benefit to structured JSON prompts, tags, or prose?  \nAny cinematic terms emphasized in the training data?  \nIs it better to specify audio, voice, music, ambience as separate sections in the prompt, or as a blended narrative?  \n\nWhich content domains are the model strongest or weakest at?\n\nThank you!",
          "score": 3,
          "created_utc": "2026-01-08 15:49:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyf67zy",
              "author": "RoughPresent9158",
              "text": "The easiest way is to use our enhancer in our flows: [https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example\\_workflows](https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example_workflows) (you can also read the system prompt there to lear what works better in each case).   \n  \nAlso, many prompting techniques are in the https://ltx.io/model/model-blog/prompting-guide-for-ltx-2.",
              "score": 10,
              "created_utc": "2026-01-08 16:17:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyfhdxz",
                  "author": "ltx_model",
                  "text": "\\^\\^\\^this",
                  "score": 4,
                  "created_utc": "2026-01-08 17:06:08",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyf0mkg",
          "author": "Ok-Significance-90",
          "text": "Thanks for creating and open-sourcing LTX2!! And especially for making it feasible to run on consumer hardware. Really appreciate the work.\n\nIf you‚Äôre able to share (even roughly): how big was the team, and what kind of budget/resources did it take to develop and train the model?\n\nAlso curious about whether you mostly hire domain specialists, or do you also have hybrid profiles (people transitioning from other fields into ML/research/engineering)?",
          "score": 3,
          "created_utc": "2026-01-08 15:52:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygva6v",
              "author": "ltx_model",
              "text": "Sure. The core pre-training team plus extra researchers and engineers are listed in our [technical report](https://cdn.prod.website-files.com/68872d15af29880764eac4aa/695c06aa63b560e217a68363_LTX_2_Technical_Report_compressed.pdf). Pre-training compute is tens of millions a year.  \n  \nWe definitely have a lot of people who transitioned from other fields. As a company, we spent years optimizing things on mobile hardware for image processing and computer graphics applications - obviously very relevant to making kernels efficient :)  \nDomain specialists are great, but people who've done hardcore work in adjacent fields often bring cool perspectives and intuitions.",
              "score": 6,
              "created_utc": "2026-01-08 20:44:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyf8k9l",
          "author": "JahJedi",
          "text": "Thank you and your team for the hardwork and sharing the model! Together we will make it best of the best there is!",
          "score": 3,
          "created_utc": "2026-01-08 16:28:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfepyb",
          "author": "InevitableJudgment43",
          "text": "You just negated all other open-source models and many closed source models. This will push the entire ai generative video space forward. Thank you so much for your generosity!",
          "score": 3,
          "created_utc": "2026-01-08 16:54:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfnfa7",
          "author": "Signal_Confusion_644",
          "text": "Well, you are a very, very beautiful person. Thanks for your work (to you and your team)\n\nMy questions:\nWhat do you think about people running LTX2 with 8gb Vram cards? Its intended? \n\nMore complex: How do you (and other companys that produce open source AIs) monetize and make profit while being open source?\n\n My mind cant comprehend that. You just gift us a tech that allow us to be little cinema directors. Something... Too expensive to think about How much It \"should\" cost.",
          "score": 3,
          "created_utc": "2026-01-08 17:32:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfwptl",
          "author": "Intrepid_Strike1350",
          "text": "–°–ø–∞—Å–∏–±–æ —Ä–µ–±—è—Ç–∞!",
          "score": 3,
          "created_utc": "2026-01-08 18:12:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyg29x9",
          "author": "Popular_Size2650",
          "text": "We love you... This is the best gift ever",
          "score": 3,
          "created_utc": "2026-01-08 18:36:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyhdim0",
          "author": "mogu_mogu_",
          "text": "I just took a 2 week break from SD and this came out. I feel old again",
          "score": 3,
          "created_utc": "2026-01-08 22:04:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyiu21d",
          "author": "DraculeMihawk23",
          "text": "This is more generic. But I wish all new releases were noob-friendly. Like, \"here's a zip folder with everything you need to run this basic prompt in comfyui, just copy paste the files into their relevant comfyui folder and away you go.\"\n\nI know there's different distillations and bode requirements that are technical, but a general \"if you have a xyz range graphics card, download this folder, if you have an abc range card, this folder is best\" would enable so many people to learn by doing so much sooner.\n\nIs thus something that could happen in future?",
          "score": 3,
          "created_utc": "2026-01-09 02:31:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyes8da",
          "author": "Vicullum",
          "text": "Why is the audio not as good as the video? It sounds tinny and compressed.",
          "score": 6,
          "created_utc": "2026-01-08 15:14:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyf0a3i",
              "author": "ltx_model",
              "text": "Agreed it needs work. Hope everyone will be pleasantly surprised with audio improvements in 2.1 - nothing fundamental there that should limit quality (or at least that's what we think at the moment¬†).",
              "score": 39,
              "created_utc": "2026-01-08 15:51:02",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nyi3z9t",
              "author": "throttlekitty",
              "text": "I've found that doing higher res helps a bit, but bumping fps to 30 or higher helps a lot more. Almost like 24fps music and ambient audio ends up really stretched and rescaled.",
              "score": 0,
              "created_utc": "2026-01-09 00:13:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyetxq5",
          "author": "DavesEmployee",
          "text": "Is 3D model -> rigging/animation on the roadmap at all? I‚Äôm not sure how close video generation is to that modality but with the consistent animation of LTX2 I could see that being possible maybe?",
          "score": 6,
          "created_utc": "2026-01-08 15:22:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyf14o0",
              "author": "ltx_model",
              "text": "We've started collaborating with animation studios to figure out the best way to integrate the model into their workflows. Things like fine-tuning on their data so blocking ‚Üí final render is easier, going beyond OpenPose conditioning, quality voice-over + keyframe conditioning. Ongoing and very exciting.  \n  \nI think animation will be the first area where AI reaches actual production quality at a fraction of the cost, while keeping humans at the creative helm.  \n  \nIn general, it's valuable to think about video models through the prism of animation tools.",
              "score": 32,
              "created_utc": "2026-01-08 15:54:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyes8rr",
          "author": "Enshitification",
          "text": "I'm not saying you aren't who you say you are, but a picture of a person holding a sign isn't exactly a great form of verification on this subredddit.",
          "score": 15,
          "created_utc": "2026-01-08 15:14:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyeujqb",
              "author": "Zueuk",
              "text": "yeah, a video would have been much better ü§î",
              "score": 13,
              "created_utc": "2026-01-08 15:25:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyevo18",
                  "author": "Enshitification",
                  "text": "I was thinking more of a link to the Lighttricks page with a verification message.",
                  "score": 7,
                  "created_utc": "2026-01-08 15:30:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyfev4g",
          "author": "HornyGooner4401",
          "text": "Do you think the previous LTX versions didn't get as much attention it deserved? I found that LTXV didn't have as many LoRAs and even official implementations for things like VACE, LTXV didn't have docs or examples like WAN does.\n\nI've also seen comments saying that LTX has hidden features like video inpainting, video outpainting, temporal outpainting, etc. but had to be coded manually since there is a lack of nodes for it.\n\nI hope LTX2 will get more attention, the results seem amazing. Thank you for open sourcing this project",
          "score": 3,
          "created_utc": "2026-01-08 16:55:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygiw7n",
              "author": "Myfinalform87",
              "text": "Same. Personally I always liked ltx and still use the older models but it absolutely lacked community support",
              "score": 2,
              "created_utc": "2026-01-08 19:49:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyerynh",
          "author": "fruesome",
          "text": "Thanks for releasing the model.¬†\nWhat‚Äôs your recommendation for getting better output with i2v model?\n\nIs there plans to add more prompting guides? I know there are few posts and would like more detailed prompting techniques. ¬†",
          "score": 2,
          "created_utc": "2026-01-08 15:13:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyf7wb6",
              "author": "RoughPresent9158",
              "text": "You can already use / learn from the system prompt of the enhancer in the official flows:  \n[https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example\\_workflows](https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example_workflows)\n\n(a small quite tip, the i2v and t2v have 2 different system prompts for the enhancer...  ;) have a look).",
              "score": 3,
              "created_utc": "2026-01-08 16:25:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyescpb",
          "author": "TwistedSpiral",
          "text": "Great work guys. Really appreciate open source greatness!",
          "score": 2,
          "created_utc": "2026-01-08 15:14:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygxlfh",
              "author": "EgoIncarnate",
              "text": "It's not \"real\" open source, as it requires a paid license for anything beyond a small business. They appear to be co-opting the term for marketing purposes. This is more weights available, free for personal use.",
              "score": 5,
              "created_utc": "2026-01-08 20:54:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyesp1a",
          "author": "protector111",
          "text": "Wan is 1 of the most amazing Text 2 img model. CAn LTX 2 be used the same way to make stills?",
          "score": 2,
          "created_utc": "2026-01-08 15:16:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyev9lz",
              "author": "Appropriate_Math_139",
              "text": "it's possible to generate 1-frame videos (= images) with LTX-2.",
              "score": 3,
              "created_utc": "2026-01-08 15:28:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyf0w24",
                  "author": "protector111",
                  "text": "true but i get horrors . did u get good ones?",
                  "score": 1,
                  "created_utc": "2026-01-08 15:53:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyetmb9",
              "author": "lordpuddingcup",
              "text": "Very video model can video models are just image sequence generators, tho ltx does audio too",
              "score": -1,
              "created_utc": "2026-01-08 15:20:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyetgro",
          "author": "some_user_2021",
          "text": "Hi. Newbie here. Can the model be trained to use my own voice when doing a video?",
          "score": 2,
          "created_utc": "2026-01-08 15:20:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygk9xa",
              "author": "ltx_model",
              "text": "Yes, with an audio LoRA.",
              "score": 10,
              "created_utc": "2026-01-08 19:55:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyewehs",
          "author": "maurimbr",
          "text": "Hi there, thanks for the awesome work!\n\nI had a quick question: do you think that, with future optimization or quantization techniques, it will be possible to reduce VRAM requirements? For example, could models that currently need more memory eventually run comfortably on something like 12 GB of VRAM, or is that unlikely?",
          "score": 2,
          "created_utc": "2026-01-08 15:33:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygh83m",
              "author": "ltx_model",
              "text": "This doesn't have an easy answer. Maybe?\n\nOn one hand, to do even FP4 well you need dedicated hardware support and some post-training work, so that puts a lower bound on VRAM (and even that with a dedicated hardware support). Param count will keep growing short term.\n\nOn the other hand, people are successfully showing distillation from big models to smaller param counts. And you can never rule out things like new pruning strategies that achieve parameter reduction we can't predict until we get there.",
              "score": 6,
              "created_utc": "2026-01-08 19:41:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyewlaz",
          "author": "windumasta",
          "text": "Okay, this is impressive! This tool will allow so many people to tell their stories. And sharing it as open source is almost unbelievable. I saw there are even guides. I can hardly believe it!",
          "score": 2,
          "created_utc": "2026-01-08 15:34:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyeykfm",
          "author": "grafikzeug",
          "text": "Thank you! I agree very much with your sentiment that gen AI models are becoming the render engines of the future and I appreciate your commitment to controlNet a lot!\nDefinitely check out Rafael Drelich who is building a comfyUI - Houdini bridge. Next, we need some way of regional prompting to really drive steerabllity home. Very excited about this release!",
          "score": 2,
          "created_utc": "2026-01-08 15:43:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyeymm6",
          "author": "Alive_Ad_3223",
          "text": "Any support for other languages like Asian languages?",
          "score": 2,
          "created_utc": "2026-01-08 15:43:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygfgzt",
              "author": "ltx_model",
              "text": "The model can be prompted to speak in many languages actually. If there's a specific language you need in depth, it's pretty straightforward to train it as a LoRA with our LoRA trainer.",
              "score": 10,
              "created_utc": "2026-01-08 19:33:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyeymsx",
          "author": "agsarria",
          "text": "Just thanks!",
          "score": 2,
          "created_utc": "2026-01-08 15:43:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyezcgh",
          "author": "polawiaczperel",
          "text": "You guys are legend! Thank you.",
          "score": 2,
          "created_utc": "2026-01-08 15:46:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf1n2p",
          "author": "Remarkable_Garage727",
          "text": "Any plans to embed this natively to some open source video editors like DaVinci Resolv?",
          "score": 2,
          "created_utc": "2026-01-08 15:57:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygwad7",
              "author": "ltx_model",
              "text": "Part of the strategy of being open is to facilitate integration into existing pipelines. We've built some internal demos and are showing them to relevant players in the industry.  \n  \nBut our overall preference is for product owners to do integrations the way they see fit - they know their audience best. We provide the model and tooling, they decide how it fits their product.",
              "score": 3,
              "created_utc": "2026-01-08 20:48:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyf2dl1",
          "author": "waltercool",
          "text": "Hope they can fix the model to be more consistent with the prompting. It really needs a lot of text in a very specific way to create something good, otherwise is just garbage output.",
          "score": 2,
          "created_utc": "2026-01-08 16:00:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf6n24",
          "author": "FunRocketer",
          "text": "Have you taught about licensing the source code under Apache 2.0 license?",
          "score": 2,
          "created_utc": "2026-01-08 16:19:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfazmu",
          "author": "man-de-l-orion",
          "text": "Thank you very much for this model. We Mandalorians love to create videos with a little bit more action ‚Äì I would really appreciate if in the long run there would be a better understanding of human interaction in a more forceful way. ‚öîü¶æ",
          "score": 2,
          "created_utc": "2026-01-08 16:38:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfghuj",
          "author": "Better-Interview-793",
          "text": "Huge thanks for open sourcing this, it‚Äôs a big help for the community!!",
          "score": 2,
          "created_utc": "2026-01-08 17:02:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygwmnm",
              "author": "EgoIncarnate",
              "text": "It's not \"real\" open source, as it requires a paid license for anything beyond a small business. They appear to be co-opting the term for marketing purposes.",
              "score": 1,
              "created_utc": "2026-01-08 20:50:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyhrndv",
                  "author": "Better-Interview-793",
                  "text": "It‚Äôs not ‚Äúpure‚Äù open source, sure\nBut opening anything in this space is already a win compared to fully closed models.\nAt least the community gets transparency, research access, and the ability to experiment",
                  "score": 1,
                  "created_utc": "2026-01-08 23:10:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyfib6t",
          "author": "JustAGuyWhoLikesAI",
          "text": "Thank you for the open releases. We are tired of video being locked behind API, and are tired of being sold out to API like what happened with WAN. I understand, however, that training these models takes time and money. Have you thought of any form of business plan where people can help support/fund development of open-weight models?",
          "score": 2,
          "created_utc": "2026-01-08 17:10:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyheiqv",
              "author": "ltx_model",
              "text": "We have a business plan - shared upthread:  \n[https://www.reddit.com/r/StableDiffusion/comments/1q7dzq2/comment/nyetfom/](https://www.reddit.com/r/StableDiffusion/comments/1q7dzq2/comment/nyetfom/)",
              "score": 3,
              "created_utc": "2026-01-08 22:08:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyfr410",
          "author": "Green-Ad-3964",
          "text": "Just to say thank you, and please keep releasing open source. It is the only way for society to survive the cloud, which is like the Nothing in \"The NeverEnding Story\".",
          "score": 2,
          "created_utc": "2026-01-08 17:48:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfs22a",
          "author": "Fantasmagock",
          "text": "First of all I'm really impressed by this new model, second I appreciate the open source view.\n\nI've seen some LTX-2 examples that have an amazing cinematic feel, others that do certain styles (old movies, puppets, cartoons, etc) in a very natural way that I don't normally see in other AI video models.\n\nMy question is related to that, how are AI video models managing to step up in realism and variety?   \nIs it more about better training data or is it more about developing new architecture for the models?",
          "score": 2,
          "created_utc": "2026-01-08 17:52:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfvbnn",
          "author": "LaurentLaSalle",
          "text": "Why Gemma?",
          "score": 2,
          "created_utc": "2026-01-08 18:06:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfzdzy",
          "author": "paulo_zip",
          "text": "Thank you for the amazing model! Why not releasing the model under Apache License?",
          "score": 2,
          "created_utc": "2026-01-08 18:24:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyg8cuj",
          "author": "Rude_Grand_7072",
          "text": "Thank you so much for helping creators all over the world !",
          "score": 2,
          "created_utc": "2026-01-08 19:02:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyg9gwn",
          "author": "stronm",
          "text": "Hi, love what you guys have been doing so far, what the one crazy mind bobbling project you have in mind that might take an year or so but might be the next big thing in the AI space",
          "score": 2,
          "created_utc": "2026-01-08 19:07:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygf67v",
          "author": "Myfinalform87",
          "text": "Personally I‚Äôm just glad to see the community get behind this project. I felt like the previous model had a lot of potential too but clearly this is a significant step up from that. Thanks for the good work and can‚Äôt wait to try the model out",
          "score": 2,
          "created_utc": "2026-01-08 19:32:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyghcyu",
          "author": "Scared_Mycologist_92",
          "text": "thanks for your amazing idea to help everybody to use it!",
          "score": 2,
          "created_utc": "2026-01-08 19:42:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygkoup",
          "author": "shinytwistybouncy",
          "text": "No questions, but my husband's friend works in your company and loves it all :)",
          "score": 2,
          "created_utc": "2026-01-08 19:56:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygp6dt",
          "author": "Ok-Scale1583",
          "text": "Thank you so much for hardworking and good answers! I can't wait to try it out once I get my pc from repair service. I wish you best luck for your works ^^",
          "score": 2,
          "created_utc": "2026-01-08 20:16:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygs0q1",
          "author": "chukity",
          "text": "Thank you for this. Hope the next version‚Äôs audio will be even better.",
          "score": 2,
          "created_utc": "2026-01-08 20:29:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygwemo",
          "author": "Different-Toe-955",
          "text": "Does it work on AMD? If not is it possible on a technical level to run it on AMD hardware? Thank you for the model.",
          "score": 2,
          "created_utc": "2026-01-08 20:49:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyiucol",
              "author": "Apprehensive_Sky892",
              "text": "Yes: [Anyone running LTX-2 on AMD gpus? : r/StableDiffusion](https://www.reddit.com/r/StableDiffusion/comments/1q7emha/anyone_running_ltx2_on_amd_gpus/)",
              "score": 1,
              "created_utc": "2026-01-09 02:32:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyhl5co",
          "author": "Intelligent_Role_629",
          "text": "Absolute legends!!! Right when I needed it for my research! Very thankful!!",
          "score": 2,
          "created_utc": "2026-01-08 22:39:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyi869a",
          "author": "Merchant_Lawrence",
          "text": "What you stance on nsfw finetune and lora, i mean all whole industry of this can't flourish witouth thoose community and people,  example case study Stable diffusion,SORA and WAN, sd  is comercial failed because is lack nsfw support and freedom to finetune and complicated license, Sora... eghhh just open ai be open ai, but WAN ? it absulutely open floodgate of not just nsfw industyr but other because 1. it support finetune, 2 nsfw and thrid very clear license and comercial terms. i hope you not make same mistake like sd 3 disaster",
          "score": 2,
          "created_utc": "2026-01-09 00:35:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyj0651",
          "author": "Alessins23",
          "text": "How do I know your image wasn't generated with AI?",
          "score": 2,
          "created_utc": "2026-01-09 03:03:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyepqyz",
          "author": "no-comment-no-post",
          "text": "I have a 5090 with 32GB of VRAM, 32GB RAM. I constantly get OOM errors no matter what startup parameters I use. Any tips for 5090 users on Windows for best performance?",
          "score": 6,
          "created_utc": "2026-01-08 15:02:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyglysb",
              "author": "ninjazombiemaster",
              "text": "Consider replacing the unquantized Gemma 3 for a quant. The default workflows are using like 20 gigs on a text encoder.¬†",
              "score": 2,
              "created_utc": "2026-01-08 20:02:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyertjr",
              "author": "kabachuha",
              "text": "Do you use `--reserve-vram`? `--reserve-vram 3` or greater can help because of Windows/monitor eating the GPU",
              "score": 4,
              "created_utc": "2026-01-08 15:12:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyes5b7",
              "author": "One-Thought-284",
              "text": "For T2I on an 8GB VRAM 4060 I finally got it to consistently generate back to back using --cache-none and --lowvram.",
              "score": 0,
              "created_utc": "2026-01-08 15:13:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyey395",
                  "author": "Ok_Conference_7975",
                  "text": "I don‚Äôt know if i'm weird, but for past few days i keep seeing your comments in this subreddit. You keep saying T2I when talking about video generation.\n\nAt first I thought it was just a typo, but you‚Äôve been sticking with it till now lol\n\nI mean, yeah video is basically a bunch of images/frames, but when generating video people usually call it T2V (Text-to-Video) or I2V (Image to Video) or S2V (Sound 2 Video) and etc...\n\nI know this doesn‚Äôt seem like a big issue, but it can cause some miscommunication, because sometimes people use video models to generate a single image (1 frame), like with Wan 2.1 / 2.2.\n\nThen, if someone asks:  \n‚ÄúHow long did it take on a 4060 for the T2I workflow?‚Äù  \nand you answer:  \n‚ÄúFor T2I, it took about 6 minutes.‚Äù\n\nThey might think: *‚ÄúWTF, this model is insanely heavy‚Äîdoes it really take 6 minutes just to generate a single image (one frame) using the LTX 2 video model?‚Äù*",
                  "score": 8,
                  "created_utc": "2026-01-08 15:41:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyer05k",
          "author": "naitedj",
          "text": "thank you",
          "score": 1,
          "created_utc": "2026-01-08 15:08:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf4u3w",
          "author": "Top_Public7402",
          "text": "A few questions about your hiring approach:\n\n- Do you look for software engineers with broad experience rather than deep specialization?\n- People who are:\n  - enthusiastic but not junior\n  - experienced enough to have coded manually\n  - familiar with basic ML / DL concepts, even if they never went very deep\n  - mostly coding today with the help of coding agents\n\n- How does the hiring process work at your company?\n\n- Would you consider hiring someone who:\n  - has no formal education specifically focused on AI\n  - is very enthusiastic about the field\n  - prefers building full systems/engines rather than just training models\n  - strongly aligns with your business vision\n\n  even if there is no immediate need to fill a position?",
          "score": 2,
          "created_utc": "2026-01-08 16:11:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyex9vi",
          "author": "Icy-Cat-2658",
          "text": "Awesome work, as others have said!  It‚Äôs a huge win for the community.  A suggestion for future releases; please hire someone to QA your docs and setup instructions prior to release.  Your setup instructions for LTX-2 are riddled with incomplete guidance, reference nodes in ComfyUI that don‚Äôt exist or work as described, and to be leading the charge here, I think it‚Äôs not just about the quality of your models, but ease of use.  Contrary to the perception of this subreddit, most users just want to make a video, not fiddle with too much setup.  A lot of us found it painful just to get LTX-2 running.  Thanks!",
          "score": 4,
          "created_utc": "2026-01-08 15:37:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyfjuzf",
              "author": "ltx_model",
              "text": "We can always do better on our documentation, and we'll be updating and adding to the docs as we go forward. The community has been a strong source of support for individual user setups and issues, far beyond what our small team can help with. These workflows can be tricky even in the best of situations.",
              "score": 10,
              "created_utc": "2026-01-08 17:17:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyfkype",
                  "author": "Icy-Cat-2658",
                  "text": "Totally agreed (and your README and instructions far exceed others, so major kudos there)!  Just asking for future releases, keep up with the day-one ComfyUI support, and make sure it's tested in full.  The community will continue to give huge support and big thanks for helping the newbies give things.a try without too much complex setup (also suggesting a RunPod template as *a lot* of us amateurs just want a one-click \"Get me up and running!\")",
                  "score": 5,
                  "created_utc": "2026-01-08 17:21:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyfme4v",
          "author": "MoistRecognition69",
          "text": "◊í◊ê◊ï◊ï◊î ◊©◊©◊ô◊ò ◊õ\"◊õ ◊ò◊ï◊ë ◊ô◊¶◊ê ◊û◊î◊ê◊®◊• ◊î◊ñ◊ê◊™ üî•üî•",
          "score": 3,
          "created_utc": "2026-01-08 17:28:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyevo4a",
          "author": "InsolentCoolRadio",
          "text": "What are your thoughts on the ability for users to run your future models on Apple Silicon hardware (say 24GB or less) given the fp16 constraint?\n\nAlso, thank you! üôèüôèüôè",
          "score": 2,
          "created_utc": "2026-01-08 15:30:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyf9ak6",
              "author": "Impressive-Sir9633",
              "text": "I want to know this too.",
              "score": 2,
              "created_utc": "2026-01-08 16:31:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyg9ycz",
              "author": "ltx_model",
              "text": "For sure. Unified architecture means fewer VRAM constraints - allows hybrid rendering with big and small models on the fly, for example (intermediate steps seem fine with lower parameter models, saves FLOPs). MLX looks solid.  \n  \nSome people are already doing amazing work on this, and hoping for a strong initial push from the community as well.",
              "score": 2,
              "created_utc": "2026-01-08 19:09:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nygc8fr",
                  "author": "InsolentCoolRadio",
                  "text": "Thanks!",
                  "score": 1,
                  "created_utc": "2026-01-08 19:19:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyex3s6",
          "author": "retroblade",
          "text": "Thank you for making this open source!!",
          "score": 2,
          "created_utc": "2026-01-08 15:36:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf04n3",
          "author": "wzwowzw0002",
          "text": "THANK YOU!",
          "score": 2,
          "created_utc": "2026-01-08 15:50:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf0nv9",
          "author": "jadhavsaurabh",
          "text": "Just wanted to say grateful for ur work üòä",
          "score": 2,
          "created_utc": "2026-01-08 15:52:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf1fji",
          "author": "CR4YONZ003",
          "text": "Do you plan to add AMD/ROCm support?",
          "score": 2,
          "created_utc": "2026-01-08 15:56:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyitmpr",
              "author": "Apprehensive_Sky892",
              "text": "AMD/ROCm support is in the application layer, not in the model itself.\n\nAt any rate, it is already working: [Anyone running LTX-2 on AMD gpus? : r/StableDiffusion](https://www.reddit.com/r/StableDiffusion/comments/1q7emha/anyone_running_ltx2_on_amd_gpus/)",
              "score": 1,
              "created_utc": "2026-01-09 02:28:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyff5ki",
          "author": "AlexGSquadron",
          "text": "Bro saved the ram industry üòÑ",
          "score": 2,
          "created_utc": "2026-01-08 16:56:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyexw0g",
          "author": "dadidutdut",
          "text": "If your life story will be told in a movie, who's actor would you like to play your role?",
          "score": 1,
          "created_utc": "2026-01-08 15:40:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyf1wgf",
              "author": "ltx_model",
              "text": "that's a tough one. Brad Pitt maybe?",
              "score": 15,
              "created_utc": "2026-01-08 15:58:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyesml1",
          "author": "Extreme_Feedback_606",
          "text": "well done sir",
          "score": 1,
          "created_utc": "2026-01-08 15:16:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyetyog",
          "author": "LuckyAdeptness2259",
          "text": "Thank you for your contribution to the community! \n\nI‚Äôve had limited time to play with the full i2v model but from my initial test it‚Äôs promising.Everyone‚Äôs been doing close ups of people talking but I‚Äôve been mainly experimenting with environment use cases.\n\nWhen dealing with bigger aerial shots (establishers) of environments, for instance sci-fi. I find even at 4K I‚Äôm getting the pesky AI jiggle or warbling ness around fine hard surface edges. Is there anyway to mitigate this with your model / settings? \n\n\nCuriosity question:\nIn such a fast moving and competitive space especially with open source efforts like WAN and large closed source players like Google and Kling how do you personally think about differentiation? Is it more about model architecture, data, tooling/ecosystem, or the community that grows around the tech and which of those do you believe will matter most over the next 2‚Äì3 years?\n\nThank you again for everything!",
          "score": 1,
          "created_utc": "2026-01-08 15:22:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyguss7",
              "author": "ltx_model",
              "text": "Closed models aren't the way to go for many applications when you're solving real-world problems. You need local execution, deep integration into pipelines, customization. My speculation on Sora 2 and other models from the giants - their focus seems to be social media, not the actual production pipelines and use cases we care about.  \n  \nPart of how we got here: no one was building models with the efficiency profile we needed for our products. We wanted real-time previews, consumer hardware deployment, endless iteration. Had to build it ourselves.  \n  \nOn differentiation - any tech advantage erodes over time. Model architecture, data, efficiency gains will get replicated. What compounds is ecosystem. Game engines are the inspiration again - Unity and Unreal aren't winning because of pure tech superiority, you can probably get a talented team that will write better core renderer, but that's not the game there anymore. They win because of community, tooling, integrations, content libraries.  \n  \nThat might be the sustainable moat. Over 2-3 years, the ecosystem will matter. That said, it's still early days of Gen-AI as a rendering engine, time will tell where the value will land.",
              "score": 9,
              "created_utc": "2026-01-08 20:42:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyeui4i",
          "author": "Zangwuz",
          "text": "Hello, thanks for this model. Can you explain the advantages of using a LLM and if the size matters for example compared to a 4B for this purpose ?",
          "score": 1,
          "created_utc": "2026-01-08 15:24:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyeuzsb",
          "author": "13baaphumain",
          "text": "Given the current trends in RAM pricing, do you intend for the next iteration of the open-source model to remain compatible with existing consumer-grade hardware, or will the development focus shift towards professional-grade hardware?",
          "score": 1,
          "created_utc": "2026-01-08 15:27:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygks3f",
              "author": "ltx_model",
              "text": "In diffusion models, part of the effort is figuring out distillation from large to small. So the answer is both - push the frontier with big models, distill down to edge devices.\n\nWe've already invested a lot of work in scaling the architecture to SOTA (very big) sizes. Like with any rendering system, you want to squeeze maximum performance from whatever hardware you're thrown.",
              "score": 8,
              "created_utc": "2026-01-08 19:57:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyji0er",
                  "author": "13baaphumain",
                  "text": "Awesome, Thanks for the release too!",
                  "score": 1,
                  "created_utc": "2026-01-09 04:47:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyev0rz",
          "author": "Xhadmi",
          "text": "Thank you very much for sharing the model. I haven‚Äôt been able to test it yet due to my hardware specifications, but I‚Äôll most likely be able to use it in a few days once gguf versions are available.\n\nIt looks very promising, and so do the features of the PRO version as well.\n\nWhich features will be compatible between one model and the other? For example, can I train a LoRA and use it with the PRO version via API? Or use the ‚ÄúAI character generator‚Äù locally?",
          "score": 1,
          "created_utc": "2026-01-08 15:27:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygacnt",
              "author": "ltx_model",
              "text": "Yes. Generally speaking, as long as you use a family of checkpoints all from the same training ancestry, LoRAs should mostly be interchangeable among models. \n\nYou may have noticed many old LTXV 0.9.\\* LoRAs still work fine with LTX-2.",
              "score": 7,
              "created_utc": "2026-01-08 19:11:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyewxlm",
          "author": "yamfun",
          "text": "Thank you!",
          "score": 1,
          "created_utc": "2026-01-08 15:36:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyeykf4",
          "author": "Signal_Pickle_3062",
          "text": "Grazie!",
          "score": 1,
          "created_utc": "2026-01-08 15:43:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyeyl5c",
          "author": "Zounasss",
          "text": "Any plans to make vid2vid work better? The pose, canny and depth are great and all but lack detail. With Wan animate the facial expressions are top notch and with more refined pose extraction we can finally get fingers to work in V2V.",
          "score": 1,
          "created_utc": "2026-01-08 15:43:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygf54m",
              "author": "ltx_model",
              "text": "We want to release some tutorials on how to progressively add details to base tiles created with IC-LoRA. Open-pose is just an example. There are other ways to take reference in more detail and train your own.\n\nBeyond the two levels we showed in the ComfyUI examples, it requires tiling mechanisms that aren't trivial on consumer hardware - our production implementation runs on multi-GPU setups with a different bag of tricks. We're considering adding an API for this.\n\nI'm sure some people in the community will figure out smart tiling on single GPU as well.",
              "score": 3,
              "created_utc": "2026-01-08 19:32:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyeywgh",
          "author": "the-final-frontiers",
          "text": "Can you take donations? Would you take donations?",
          "score": 1,
          "created_utc": "2026-01-08 15:44:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyezcv3",
          "author": "lumos675",
          "text": "I think now that you become popular with this awesome model you can make a heavier version only for cloud to make money with it.. you absolutely deserve it to be honest.",
          "score": 1,
          "created_utc": "2026-01-08 15:46:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyezgmq",
          "author": "Devajyoti1231",
          "text": "Thank  you!",
          "score": 1,
          "created_utc": "2026-01-08 15:47:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyezozt",
          "author": "WildSpeaker7315",
          "text": "thanks guys",
          "score": 1,
          "created_utc": "2026-01-08 15:48:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf0v7t",
          "author": "ArtDesignAwesome",
          "text": "Would love more of a dive in to using these new loras you guys released, like proper use cases for using the detailer lora, etc etc.",
          "score": 1,
          "created_utc": "2026-01-08 15:53:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf16zs",
          "author": "ChrononautPete",
          "text": "Does the audio sound tinny?",
          "score": 1,
          "created_utc": "2026-01-08 15:55:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf1892",
          "author": "raz0099",
          "text": "Any plans on releasing gguf model?",
          "score": 1,
          "created_utc": "2026-01-08 15:55:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf1ajw",
          "author": "rubberjohnny1",
          "text": "What new advancements can we expect in 5 years?",
          "score": 1,
          "created_utc": "2026-01-08 15:55:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf3sah",
          "author": "Moliri-Eremitis",
          "text": "What were some of the design considerations you had going into the development of LTX2, and what was the timeline like?\n\nMostly hoping for a peek behind the curtain of what building a frontier model looks like. Were you already working on LTX2 when you released LTXV? Was the design of LTX2 shaped by stuff you learned from LTXV, from research papers, what other groups were doing, your own internal research, something else?",
          "score": 1,
          "created_utc": "2026-01-08 16:06:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygw1gi",
              "author": "ltx_model",
              "text": "I started writing this answer and realized it was becoming a blog post.    \n  \nThe short version: the journey started in 2022-2023 with initial experiments to create image models efficient enough for mobile deployment. A lot has happened since then - architectural bets, surprises, pivots, things that worked unexpectedly well, things that didn't work at all.  \n  \nHope to write this up properly at some point - the team deserves it, and software project enthusiasts will be entertained. üòä",
              "score": 5,
              "created_utc": "2026-01-08 20:47:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyh265s",
                  "author": "Moliri-Eremitis",
                  "text": "I look forward to it! Is there a place you would likely post that in the future, if you have the time? Mostly not sure where to keep my eyes peeled. üòÅ",
                  "score": 1,
                  "created_utc": "2026-01-08 21:14:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyf6pdq",
          "author": "b-totherent",
          "text": "I have seen some promising community work flows already incorporating audio to video for lipsync.  Is there a timeline for being able to add outside audio to video/lipsync to LTX-2/LTX Studio especially for consistent voices which is currently lacking for native audio video models?",
          "score": 1,
          "created_utc": "2026-01-08 16:19:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyhhq0i",
              "author": "ltx_model",
              "text": "[https://www.reddit.com/r/StableDiffusion/comments/1q7dzq2/comment/nyewscw/](https://www.reddit.com/r/StableDiffusion/comments/1q7dzq2/comment/nyewscw/)",
              "score": 1,
              "created_utc": "2026-01-08 22:23:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyf73zs",
          "author": "TogoMojoBoboRobo",
          "text": "Would love to do local generation in Videoleap...  any plans for that?",
          "score": 1,
          "created_utc": "2026-01-08 16:21:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf7vbx",
          "author": "Diecron",
          "text": "How did you get to the release of LTX2? Did you have a 'mission statement' or strict set of guidelines for the project?\n\nHow have competitors shaped your strategies on training and inferrence so far? Do you have your eyes on any particularly interesting emergent technology?\n\nThanks for your time and of course the open sourced contributions.",
          "score": 1,
          "created_utc": "2026-01-08 16:24:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf8kyt",
          "author": "cointalkz",
          "text": "Why did you decide to make this model open source? How does it benefit your team long term?",
          "score": 1,
          "created_utc": "2026-01-08 16:28:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyhgoe1",
              "author": "ltx_model",
              "text": "Answered upthread: [https://www.reddit.com/r/StableDiffusion/comments/1q7dzq2/comment/nyetfom/](https://www.reddit.com/r/StableDiffusion/comments/1q7dzq2/comment/nyetfom/)",
              "score": 2,
              "created_utc": "2026-01-08 22:18:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyhmcnp",
                  "author": "cointalkz",
                  "text": "Thanks!",
                  "score": 1,
                  "created_utc": "2026-01-08 22:44:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyfau21",
          "author": "fredandlunchbox",
          "text": "How long until we can see a continuous stream of real-time gen with constantly evolving plots and stories? 1 year? Less?¬†",
          "score": 1,
          "created_utc": "2026-01-08 16:37:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfba3z",
          "author": "Nepharios",
          "text": "OK, genuine Question: I only got to make it work on a 4090 with the ‚Äînovram option. What I don‚Äôt get is how fast the interference is with no VRAM. How is this possible? And on a second note, please do something to the memory usage or better to say to the offloading option. Anyways, great work, much appreciated!",
          "score": 1,
          "created_utc": "2026-01-08 16:39:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfbogj",
          "author": "FxManiac01",
          "text": "Wow, Zeev, thanks for awesome model! Been playing with it for 2 days and I am impressed. But what I find out so far - and it is not very surprising actually - like common scenes (dialogues, closeup on talking person etc) work very well, some uncommon really strugles (like sports events with some cringe moves of actors etc..).. so some tips how to get \"not so common looking scenes\" perform well? \n\nCan you share what dataset did u use? it would also help understand how to prompt everything etc.. is a plan to opensource / share dataset?\n\nthanks again! great work!",
          "score": 1,
          "created_utc": "2026-01-08 16:41:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfe6xv",
          "author": "kh3t",
          "text": "1. thanks a lot  \n2. what's the best pc build setup to max-efficiency on it?",
          "score": 1,
          "created_utc": "2026-01-08 16:52:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfga7o",
          "author": "bnlae-ko",
          "text": "What do you plan to do next? Are you planning to release more open-source models?",
          "score": 1,
          "created_utc": "2026-01-08 17:01:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyhdb1x",
              "author": "ltx_model",
              "text": "Yes.   \n[https://www.reddit.com/r/StableDiffusion/comments/1q7dzq2/comment/nyewscw/](https://www.reddit.com/r/StableDiffusion/comments/1q7dzq2/comment/nyewscw/)",
              "score": 2,
              "created_utc": "2026-01-08 22:03:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyfhto0",
          "author": "wh33t",
          "text": "I have felt for a very long time that the future of film/tv media will be customized and dynamic. Imagine a Netflix where you input your preferences and it's generated on the fly for you. \n\nDo you guys feel this is a real possibility opening up in the future? And do you think Lightricks would have a part to play in that?",
          "score": 1,
          "created_utc": "2026-01-08 17:08:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfi2cc",
          "author": "No_Comment_Acc",
          "text": "Thank you very much for this amazing model! If possible, please add support of popular languages, such as Spanish, French, Chinese, Russian, Italian, etc. It already understands those languages to some extent but having separate models would make a world of difference. Thanks againüôè",
          "score": 1,
          "created_utc": "2026-01-08 17:09:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfkywf",
          "author": "N1tr0x69",
          "text": "Would this run on low VRAM gpus or the first release it's meant for higher ones?",
          "score": 1,
          "created_utc": "2026-01-08 17:21:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyhfzee",
              "author": "ltx_model",
              "text": "We give conservative VRAM guidelines, but obviously hope people push it lower and lower.\n\nCheck the repo for our current recommendations - and keep an eye on what the community figures out. There's threads in this subreddit already showing results.",
              "score": 3,
              "created_utc": "2026-01-08 22:15:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyfmhjt",
          "author": "Separate_Height2899",
          "text": "Are there gonna be option to use your own voices instead of generating from the model itself?",
          "score": 1,
          "created_utc": "2026-01-08 17:28:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyfo5p7",
              "author": "supaTronik",
              "text": "Kijai has a workflow for using your own audio",
              "score": 2,
              "created_utc": "2026-01-08 17:35:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyhavs5",
                  "author": "ltx_model",
                  "text": "Yes. And we're working on making this more straightforward.",
                  "score": 3,
                  "created_utc": "2026-01-08 21:52:55",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyfmltm",
          "author": "Illya___",
          "text": "What is your target audience? Do you plan to focus long term on general purpose models or do you plan to drift to more professional usecases which doesn't necessarily go well with local fun generations?",
          "score": 1,
          "created_utc": "2026-01-08 17:29:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfnjtw",
          "author": "cyberwicklow",
          "text": "You need staff?",
          "score": 1,
          "created_utc": "2026-01-08 17:33:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygnsmj",
              "author": "ltx_model",
              "text": "We are hiring: [https://careers.lightricks.com/careers](https://careers.lightricks.com/careers)",
              "score": 1,
              "created_utc": "2026-01-08 20:10:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyfsmoq",
          "author": "RobMilliken",
          "text": "Your API examples don't include ComfyUI. Would it be possible to get the proper seed and prompt locally then when that has been finessed to send the Comfy UI to the API somehow, making sure are prompting works before we send it to the more expensive API using the ComfyUI workflow?",
          "score": 1,
          "created_utc": "2026-01-08 17:55:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfuu7j",
          "author": "1filipis",
          "text": "I applied to one of the PM roles the other day, but the position closed too soon.\n\nDon't see anything similar open, but I'd love to come and meet you guys!",
          "score": 1,
          "created_utc": "2026-01-08 18:04:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyh8p1h",
              "author": "ltx_model",
              "text": "Keep an eye on our job page, new roles open regularly.",
              "score": 1,
              "created_utc": "2026-01-08 21:43:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyfuv8b",
          "author": "MrOaiki",
          "text": "How do you make money?",
          "score": 1,
          "created_utc": "2026-01-08 18:04:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyh8iqp",
              "author": "ltx_model",
              "text": "We monetize through licensing and rev-share when people build successful products on top of the model.",
              "score": 1,
              "created_utc": "2026-01-08 21:42:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyfyaa4",
          "author": "johnfkngzoidberg",
          "text": "The elephant in the room always seems to be censorship, if that be China censoring Tianamen Square, or xAI blurting Nazi talking points.  OpenAI has claimed they will open up ChatGPT and possibly Sora to adult content for verified users.  \n\nThe general consensus seems to be that ‚Äúcensorship‚Äù by means of cannibalism of the model or encoder hurts quality, while simply not training on adult content is much more accepted. \n\nFirst question, where do you see misinformation, censorship, and potentially advertising in a model going in the future?  \n\nSecond question, aside from the obvious threat of lawsuits, where do you see adult themes fitting in generative AI in the future?",
          "score": 1,
          "created_utc": "2026-01-08 18:19:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfyq5d",
          "author": "opinionatedSquare",
          "text": "Any plans for similar features to VACE? Controllable inpainting has been a game changer for my projects.",
          "score": 1,
          "created_utc": "2026-01-08 18:21:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyiw3c5",
              "author": "Cute-Employee7125",
              "text": "Is vace model more powerful than inp model ? In the term of multi¬† keyframes interpolation ?",
              "score": 1,
              "created_utc": "2026-01-09 02:42:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nylvsp9",
                  "author": "opinionatedSquare",
                  "text": "Sometimes it works better. Also the ability to mask a part of the image and using controlnet simultaneously is a game changer.",
                  "score": 1,
                  "created_utc": "2026-01-09 15:09:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyg0hzr",
          "author": "Darkstorm-2150",
          "text": "Do you think that 3D spatial control will be possible this year? I ask because a recent Lora pushes 98 camera angles for image generation.",
          "score": 1,
          "created_utc": "2026-01-08 18:29:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyg1ht9",
          "author": "Queasy-Carrot-7314",
          "text": "Is there any documentation available for ic lora training. How to prepare datasets, what all parameters is supported etc.\n\nAlso, is it possible to run ltx trainer on sites like modal, runpod or vast.ai, if so do you have any process/wf templates or examples available? Would be very helpful and appreciated.",
          "score": 1,
          "created_utc": "2026-01-08 18:33:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyh578j",
              "author": "ltx_model",
              "text": "Yes. We have a trainer and documentation on¬†[GitHub](https://github.com/Lightricks/LTX-2/tree/main/packages/ltx-trainer#ltx-2-trainer).",
              "score": 3,
              "created_utc": "2026-01-08 21:28:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyg3clu",
          "author": "Serran44",
          "text": "Is there any plan to quantize LTX-2 on machines with, say, 6GB VRAM (with generation obviously taking longer) to get this in the hands of as many people as possible?",
          "score": 1,
          "created_utc": "2026-01-08 18:41:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyg3duz",
              "author": "Serran44",
              "text": "Checking Steam (as a hardware metric) shows that while enthusiasts here have top of the line cards, most users still use lower or previous gen cards, some as low as 6GB VRAM.  \n  \nThanks for this, I believe open source and getting bleeding edge creativity in the hands of John Q Public is more important than the closed source models gatekept by investor funding for Blackwell data centers. Godspeed",
              "score": 1,
              "created_utc": "2026-01-08 18:41:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyg3fbd",
          "author": "SquareVisio",
          "text": "Can you look at this paper [https://flow-map-trajectory-tilting.github.io/](https://flow-map-trajectory-tilting.github.io/) and tell me if it applies to your model or TBD (meaning if I ask for this detail will it implement it ? Can the model when doing I2V can remember each \"frame\" the source material to avoid changing the person when he/she turns (most I2V destroy the face after a few seconds ? Does it support height for characters : 5ft10 6ft or 1m80 or 175cm when prompting ? Do you have a \"native\" lora maker or whatever that ressemble it or a sort of dev kit to build on it ?",
          "score": 1,
          "created_utc": "2026-01-08 18:41:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyg47li",
          "author": "EbbNorth7735",
          "text": "I picture a corporation utilizing your models to create user content or full blown advertisements. How does monetization and licensing work in those use cases? It feels like something that gets started as a hackathon project which turns into the marketing teams development solution.",
          "score": 1,
          "created_utc": "2026-01-08 18:44:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyg5cuf",
          "author": "Silly-Dingo-7086",
          "text": "How long until people are going to be making their own versions of movies based on books? I feel like we are a few years away from someone generating a model for each character and just adapting books or story's whatever to film.",
          "score": 1,
          "created_utc": "2026-01-08 18:49:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyg6mx2",
          "author": "Inside-Cantaloupe233",
          "text": "Do You plan SVDQ int 4  for nunchaku ?",
          "score": 1,
          "created_utc": "2026-01-08 18:55:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyg7rtl",
          "author": "dobomex761604",
          "text": "1. What was the logic behind 12B LLM instead of a normal text encoder? Did you test smaller LLMs?\n2. Have you considered giving official support of gguf models via llama.cpp?",
          "score": 1,
          "created_utc": "2026-01-08 19:00:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyg9063",
          "author": "somethingsomthang",
          "text": "How much attention are you paying to potential methods and architectures and such that are coming out in different papers with ways to improve training/inference?   \nAnd how how many different things get tried over the course making models and has there been anything unexpectedly beneficial learnt during the process?",
          "score": 1,
          "created_utc": "2026-01-08 19:05:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyga42z",
          "author": "Bitter-College8786",
          "text": "Are there plans to implement voice consistency? That if you make several video snippets with the same character, the character has the same voice in all generated videos?",
          "score": 1,
          "created_utc": "2026-01-08 19:10:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygappd",
          "author": "Cute-Employee7125",
          "text": "What is your roadmap for supporting interpolation between keyframes for character animations?",
          "score": 1,
          "created_utc": "2026-01-08 19:12:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygj524",
          "author": "ArtifartX",
          "text": ">We believe models are evolving into full-blown rendering engines. Not just \"generate video from prompt\" - actual rendering with inputs like depth, normals, motion vectors, outputting to compositing pipelines, VFX workflows, animation tools, game engines.\n\nCan we expect to be able to use any of these control sources in the short term? I've [experimented/fine tuned a lot](https://old.reddit.com/r/3dsmax/comments/1onjyup/rendering_openpose_from_3dsmax_to_guide_diffusion/) with models starting with WAN 2.1 and control/guidance still has a long ways to go. Mainly I'd like to block out scenes and animate them in 3D software so I can \"render them out\" like you say here with a video model, but I haven't been able to achieve acceptable results yet with what's out there. SCAIL and Wan Animate both have not produced a good enough result for me even with finetuning when it comes to controlling the output motion (it's great for fun, but not for any actual shot production yet, even with high quality input data like motion vectors, OpenPose renderings, depth renderings, etc).",
          "score": 1,
          "created_utc": "2026-01-08 19:50:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygjxd8",
          "author": "singfx",
          "text": "First of all, Thank you so much!\n\nHow do you see this whole AI models race ending? \n\nAt some point, all of these models will be basically indistinguishable from each other in terms of quality and technical capabilities(4k HDR capable, 1 minute long videos, knows all major IPs, etc.)\n\nWhat will be the differentiator that you have in mind that will keep you on top of the competition?",
          "score": 1,
          "created_utc": "2026-01-08 19:53:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygm5t0",
          "author": "Shakalaka_Pro",
          "text": "How to get started with audio-video model training? Any receipts we can follow to replicate? What are the tech stacks you used to train the model. How to handle training data preparation, what library did you use for training, what about evaluation how do you evaluate the quality of your model? What do you plan on doing next?\nThank you! This would be greatly appreciated üëç",
          "score": 1,
          "created_utc": "2026-01-08 20:03:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyh264k",
              "author": "ltx_model",
              "text": "We have a trainer and documentation on [GitHub](https://github.com/Lightricks/LTX-2/tree/main/packages/ltx-trainer#ltx-2-trainer) \\- best place to start.",
              "score": 1,
              "created_utc": "2026-01-08 21:14:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nygmblb",
          "author": "dhaupert",
          "text": "One of Sora 2‚Äôs key technologies is the cameo feature. Being able to create a persona or actor that can be reused in multiple prompts with a consistent look and voice. Are you planning on adding this type of support?",
          "score": 1,
          "created_utc": "2026-01-08 20:04:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyh0hkr",
          "author": "DankGabrillo",
          "text": "Ok ok, gotta stop scrolling here before my finger drops off in protest so apologies if this was already asked. \n\nI‚Äôm finding it hard to visualize where you guys think this is going, not sure I get the concept of localized render engines. We‚Äôre going for visual media here, is the goal that everyone is a potential Spielberg? 10 mil is a high threshold before you guys start taking in some dough. \n\nBasically, what I think I‚Äôm getting at is: what business should a start with your product to make you guys lots of money? What services do you envision being made with your model to justify your investment?\n\nI ain‚Äôt a programmer, but Claude almost is so‚Ä¶ inspire me.",
          "score": 1,
          "created_utc": "2026-01-08 21:07:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyh5oac",
          "author": "VRGoggles",
          "text": "Would be wonderful to see LTX video model being able to generate true 3D stereo videos for VR goggles. side by side or top down. I would love to see these ai videos in quality 3D in VR",
          "score": 1,
          "created_utc": "2026-01-08 21:30:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyh68xv",
          "author": "Own_Version_5081",
          "text": "Thanks for bold decision and doing the right thing. We are a startup in travel video production space.\n\nCouple of questions. When can we expect LTX ultra on your web app? On LTX-2, I2v completely changes the character, are you working to fix that? Are there any workaround?",
          "score": 1,
          "created_utc": "2026-01-08 21:32:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyhblpc",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-08 21:55:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyhj5fu",
              "author": "fox-friend",
              "text": "Zeev means wolf in Hebrew. Pronounced ze‚Äôev.",
              "score": 1,
              "created_utc": "2026-01-08 22:29:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyhl7ov",
          "author": "Ambitious-Tie7231",
          "text": "Have you tried or seen SeedVR2? Your current V2V upsampler didnt impress me",
          "score": 1,
          "created_utc": "2026-01-08 22:39:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyhnder",
          "author": "DELOUSE_MY_AGENT_DDY",
          "text": "Can you explain the difference between the regular and distilled models, and which one is better for different tasks?",
          "score": 1,
          "created_utc": "2026-01-08 22:49:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyhos4u",
          "author": "bitwise97",
          "text": "How close are we to fixing the \"text problem\" in AI video-generation models?  It's extremely frustrating as a noob to not be able to explicitly say in a prompt the text I want in my video.",
          "score": 1,
          "created_utc": "2026-01-08 22:56:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyhuc1v",
          "author": "trippy_vortex",
          "text": "How much did it cost to build?",
          "score": 1,
          "created_utc": "2026-01-08 23:24:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyhuq6w",
          "author": "DigitalDreamRealms",
          "text": "What do companies do with the models that get phased out? Do you delete them? Put them on a shelf forever? I always wonder especially for the big AI giants.",
          "score": 1,
          "created_utc": "2026-01-08 23:26:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyj0jrn",
              "author": "ltx_model",
              "text": "Our older models and code are still online at HuggingFace and GitHub.",
              "score": 1,
              "created_utc": "2026-01-09 03:05:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyhx25a",
          "author": "Merchant_Lawrence",
          "text": "wow thanks for hard work, how you optimize resources compare other companies? what secret sauce to train data?",
          "score": 1,
          "created_utc": "2026-01-08 23:38:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyhxrxx",
          "author": "OkTransportation7243",
          "text": "Was the image generated by AI as well? LOL.",
          "score": 1,
          "created_utc": "2026-01-08 23:41:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyhz4an",
          "author": "superstarbootlegs",
          "text": "this is the way. nice step. and thanks.",
          "score": 1,
          "created_utc": "2026-01-08 23:48:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyidftt",
          "author": "Green_Juice5616",
          "text": "I understand that when creating LTX-2, you collaborated with NVIDIA and ComfyUI. Many users have spare GPUs after upgrading their systems. Could you enable the use of these spare GPUs? In other words, can you allow a single task to be processed using multiple GPUs?",
          "score": 1,
          "created_utc": "2026-01-09 01:02:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyiniv9",
          "author": "Max2057",
          "text": "thinks",
          "score": 1,
          "created_utc": "2026-01-09 01:56:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyj546c",
          "author": "rdcoder33",
          "text": "Hi Zeev,  \nThanks for LTX and AMA.  \n  \nHow do you plan to monetize this? Stable Diffusion led open-source innovation early on but struggled without sustainable revenue and was later outpaced by well-funded closed-source players like Flux.\n\nGiven your goal to keep this open source, how will you fund ongoing development and support the team? I don't think crowdfunding / sponsors can reach the scale needed.\n\n![gif](giphy|RVzU9AGit8VxSnsxUt)",
          "score": 1,
          "created_utc": "2026-01-09 03:31:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyk75yl",
          "author": "Scared_Mycologist_92",
          "text": "thanks for your way of making this tech open to everybody! ;)",
          "score": 1,
          "created_utc": "2026-01-09 08:03:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nykeg73",
          "author": "Relative-Excuse5827",
          "text": "Hello, I'm working with LTX Distilled on an RTX 5050 with 8GB VRAM. It's the only open-source tool that doesn't require tedious settings management. Your model is fantastic, the only one that works perfectly with Pinocchio. No OM (Out of Frame), very fast video, excellent quality, and even some real surprises in the results. Could LTX2 run on low VRAM? Thank you üôè",
          "score": 1,
          "created_utc": "2026-01-09 09:09:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nykon7f",
          "author": "desktop4070",
          "text": "Do you suspect that AI model companies have hit the limit on what consumer GPUs (3060 12GB, 4060 Ti 16GB) are capable of? Or do you think there are still many ways to improve open source image/video models in the future?",
          "score": 1,
          "created_utc": "2026-01-09 10:42:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyl16of",
          "author": "Santhanam_",
          "text": "Is it possible to input multi angle character reference image(like front and back) and drive the generation with pose to achieve consistent character?",
          "score": 1,
          "created_utc": "2026-01-09 12:21:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyl75vs",
          "author": "MrUtterNonsense",
          "text": "Why is Ltx Studio such a privacy nightmare?  \n    \nGrant of Rights section, 6.2\nhttps://static.lightricks.com/legal/LTXS-Terms%20of%20Service%20Online.pdf\n    \nSo when people make videos of their friends and family, you can train on their images and license them to god-knows who in perpetuity.",
          "score": 1,
          "created_utc": "2026-01-09 13:00:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nymq4g0",
          "author": "pmjm",
          "text": "Thanks for all that you do! Are you planning an i2v workflow that supports both start and end frames?",
          "score": 1,
          "created_utc": "2026-01-09 17:26:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyn8oml",
          "author": "melonboy55",
          "text": "What are best practices for training a lora on LTX-2? is there a guide you would recommend?",
          "score": 1,
          "created_utc": "2026-01-09 18:48:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyqbj0h",
          "author": "No_You_2793",
          "text": "What about nsfw?)",
          "score": 1,
          "created_utc": "2026-01-10 04:17:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyujy9w",
          "author": "FantasticFeverDream",
          "text": "LTX is an Nvidia partner, so win win as Nvidia will sell more GPUs to hobbyists and pros. Gettin paid!",
          "score": 1,
          "created_utc": "2026-01-10 20:35:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyut61i",
          "author": "Apart-Cold2848",
          "text": "Very interesting, but too cumbersome. I hope you find a way to make our VRAM management a little more logical and intelligent. In theory, everything works for me, and the final VAE generates an (OOM). I don't have much time right now, but I think you can find a solution. Prioritize maximum accessibility if you want people to actually work on it. Thanks for the trust, I hope we can do some interesting things in a few months.",
          "score": 1,
          "created_utc": "2026-01-10 21:21:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyvgy6x",
          "author": "Luke2642",
          "text": "Sad to have missed this, I would love to have asked you more technical questions about compression versus dimensionality reduction and the simplicity of the manifold in the latent space!¬†\n\nThere seems to be a direct trade-off with higher compression and more challenging learning, but faster inference. I'm also convinced we're heading down a path of inverse rendering and a neural rendering engine, baking more intrinsics (from depth and normals, to full light transport) into the manifold. Equivariance priors in the manifold are also extremely interesting, and seem very effective!\n\nIn pixel space, have you considered using the OKLAB colour space so the colour difference formula in your loss function more closely matches human perception? I haven't seen anyone try this yet. It would be a small perceptual gain and nudge the latent space to closer align with human perception, allocate greater resolution in luminosity than hue or chroma. A far better approach than the terrible 4:2:0 (and less bad 4:2:2) sub sampling in the vast majority of the training data, which is rarely considered or mitigated properly.",
          "score": 1,
          "created_utc": "2026-01-10 23:21:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyyqx6c",
          "author": "Fun_Firefighter_7785",
          "text": "I am already hooked, by just asking GLM 4.6 flash to make me a random prompt i like. Godzillas, Tsunamis, Sharks in the sewer... It is like becoming Steven Spielberg. There is the future where you can order a sci-fi Spielberg film, just by asking your chatbot and rendering it in hours.  The new way of Netflix and chill.",
          "score": 1,
          "created_utc": "2026-01-11 13:00:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyyr8je",
              "author": "James_Reeb",
              "text": "Not sure it will be more interesting than real movies with real actors",
              "score": 1,
              "created_utc": "2026-01-11 13:02:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyzmlf8",
                  "author": "Fun_Firefighter_7785",
                  "text": "It depends how good a chatbot is at writing. we also need a massive story writing skills",
                  "score": 1,
                  "created_utc": "2026-01-11 15:58:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyzogle",
          "author": "Fun_Firefighter_7785",
          "text": "[just incredible effects](https://youtube.com/watch?v=ATZZKvXuSZQ&si=jDyGTb8vgO5zCIUP)",
          "score": 1,
          "created_utc": "2026-01-11 16:06:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5n01s",
          "author": "Loose-Fee-1919",
          "text": "I just want something to help me color in my frames..  if I made an animation, colored the first middle, and last frames, would this be able to color in the rest?  I'm not trying to make some lame prompt videos or cartoons based on someone else's art; I want this to help me finish my work.",
          "score": 1,
          "created_utc": "2026-01-12 13:12:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz85j3v",
          "author": "OddResearcher1081",
          "text": "I finally found a good LTXV 2 workflow for COMFYUI, and I can say, after generating about fifty videos, that yes, it is a good model when using a good workflow. \n\nWith that said the workflows supplied within COMFYUI templates are not very good. \n\nAnd I think these workflows spoiled the LTXV 2 debut.",
          "score": 1,
          "created_utc": "2026-01-12 20:27:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzaf83w",
          "author": "heibai-wuchang",
          "text": "Are you going to be in IMVC this year?\n\nAlso, are you hiring?",
          "score": 1,
          "created_utc": "2026-01-13 03:26:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyey45j",
          "author": "Alive_Ad_3223",
          "text": "Thank you üëç",
          "score": 1,
          "created_utc": "2026-01-08 15:41:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygut5n",
          "author": "EgoIncarnate",
          "text": "I do appreciate you making the weights available, but this is not open source. The open source definition doesn't allow for commercial use restrictions. \\[1\\]\n\nYour license requires a paid license for commercial use by anything but the smallest companies.\n\nThis seems like you are borrowing the term for it's goodwill, but not honoring the intent.\n\nWas this intentional?\n\nIt may not matter for personal use, but there is a significant difference between your license and a \"real\" open source license for potential business users.\n\nWeights available would be a more appropriate label.\n\n\\[1\\] Open Source Definition: [https://opensource.org/osd](https://opensource.org/osd)",
          "score": 1,
          "created_utc": "2026-01-08 20:42:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyex01a",
          "author": "south_paw01",
          "text": "Is there a minimum/recommended hardware recommendation/guideline for each of the given models that you would be willing to share?",
          "score": 1,
          "created_utc": "2026-01-08 15:36:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyghwtd",
              "author": "ltx_model",
              "text": "Part of releasing to the community is seeing how they optimize things. We give conservative VRAM guidelines, but obviously hope people push it lower and lower.  \n  \nCheck the repo for our current recommendations - and keep an eye on what the community figures out. There's threads in this subreddit already showing results.",
              "score": 3,
              "created_utc": "2026-01-08 19:44:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyex7yk",
          "author": "Single_Ring4886",
          "text": "First of all thank you! Second my question: Do you plan \"artistic\" model or at least official finetune/LORA? All post SDXL (and its derivates) models be it image or video are mostly \"realistic\". Even if they have \"artistic\" abilities they are quite limited (that apply even from commercial models). I wish something like DALLE 3 but \"modern\" like your model. Do you plan something like that?",
          "score": 1,
          "created_utc": "2026-01-08 15:37:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygjo02",
              "author": "ltx_model",
              "text": "The community tends to be better at this than us. We provide post-training infrastructure so people can come with their own data and push the model toward their own aesthetic choices.  \n  \nAlready seeing some initial stylistic LoRAs pop up - I hope that grows.",
              "score": 3,
              "created_utc": "2026-01-08 19:52:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyhfsmr",
                  "author": "Single_Ring4886",
                  "text": "Thank you for answer, I understand. I know it is really hard to \"quantify\" artistic leaning of visual models. But SD, SDXL and DALLE 3 coud really create quite \"random\" yet beautiful results and I think that is why community loved them for such long time. Most modern models are better at realism but kinda lost that. Your model has potential! That is why I asked. Have a nice day.",
                  "score": 1,
                  "created_utc": "2026-01-08 22:14:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyeyjak",
          "author": "TinMorphling",
          "text": "Thank you for the amazing work! My question to you is will you eventually be looking to train and release a model similar to Genie from Google?",
          "score": 1,
          "created_utc": "2026-01-08 15:43:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygbfep",
              "author": "ltx_model",
              "text": "Adaptation seems inexpensive, and from there the path to camera navigation seems fairly clear - though maybe I'm underpricing the effort. Familiar with strong researchers and startups pushing this direction. Optimistic for real-time video and Genie-like open stuff on top of LTX this year.  \n\n\nContext video to keep the world consistent and get us into metaverse-like experiences is still an open problem. Factoring in dynamics of the world even more so. But fun to think about - a lot of people are working on it. Bullish on progress there.",
              "score": 3,
              "created_utc": "2026-01-08 19:16:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyf16ks",
          "author": "Remarkable_Garage727",
          "text": "Any thoughts on creating real live 3d emersed VR generation? Would be great if you could run a 3d scene on your computer and stream it on your VR headset..",
          "score": 1,
          "created_utc": "2026-01-08 15:55:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf16nw",
          "author": "Trumpet_of_Jericho",
          "text": "Is it possible to use this model with RTX 3060 12GB and 32GB @ 3200Mhz ram?",
          "score": 1,
          "created_utc": "2026-01-08 15:55:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf3icw",
          "author": "Lower-Cap7381",
          "text": "Thank you so much team üôå‚ô•Ô∏è",
          "score": 1,
          "created_utc": "2026-01-08 16:05:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf5jqe",
          "author": "ThirdEye_FGC",
          "text": "Can you make a video tutorial on how to set this up, please?",
          "score": 1,
          "created_utc": "2026-01-08 16:14:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyhiowz",
              "author": "ltx_model",
              "text": "Wh posted this on our YouTube channel: [https://www.youtube.com/watch?v=d1tjLXsz8Wc](https://www.youtube.com/watch?v=d1tjLXsz8Wc)",
              "score": 1,
              "created_utc": "2026-01-08 22:27:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyhmabc",
                  "author": "ThirdEye_FGC",
                  "text": "Thanks!! Will take a watch and learn this.",
                  "score": 1,
                  "created_utc": "2026-01-08 22:44:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyf8em2",
          "author": "Stunning_Mast2001",
          "text": "How did you go about figuring out what optimizations to make to turn something that typically required a rack of GPUs to run on a single consumer gpu?",
          "score": 1,
          "created_utc": "2026-01-08 16:27:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfd571",
          "author": "VanagearDevGuy",
          "text": "Will you be making a variant that allows first frame & last frame as inputs to help drive the output?¬†\nEdited for clarity¬†",
          "score": 1,
          "created_utc": "2026-01-08 16:47:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyez33j",
          "author": "Adventurous-Gold6413",
          "text": "Could you fully uncensor the next ltx for funsies in prompt adherence",
          "score": 0,
          "created_utc": "2026-01-08 15:45:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyeu6lq",
          "author": "Altruistic_Noise4159",
          "text": "When are quantitized versions going to be released, are you going to provide support for graphics cards such as 3090-4090-5090 or are we going to use Runpod in order to get your models working in full power ? Honestly I think in order to truly be open source you need to keep in mind the average user with consumer graphics cards",
          "score": 0,
          "created_utc": "2026-01-08 15:23:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyev4hf",
              "author": "Downtown-Accident-87",
              "text": "there is already support for said cards",
              "score": 3,
              "created_utc": "2026-01-08 15:27:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyew1cp",
                  "author": "Altruistic_Noise4159",
                  "text": "It barely works on a 5090 and is impossible to run on 3090, I've seen some videos where people claim to make 5 second videos in 8 seconds using 4090s but im yet to see a detailed tutorial and optimization guidelines",
                  "score": 0,
                  "created_utc": "2026-01-08 15:31:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nygtvng",
          "author": "Regular-Forever5876",
          "text": "First and foremost, THANK YOU!\n\nAnd... would you like to come and be interviewed in our YouTube channel as we are working on the video about LTX-2 right now?\n\nOur channel have \\~100k monthly views avg üòâ Let's DM\n\n![gif](giphy|y6lu312reRzVC46yFn)",
          "score": 0,
          "created_utc": "2026-01-08 20:38:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyh1dn9",
              "author": "ltx_model",
              "text": "No promises, but send a DM with some details.",
              "score": 2,
              "created_utc": "2026-01-08 21:11:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyf7qph",
          "author": "CRedIt2017",
          "text": "How soon for NSFW LORAs ?",
          "score": -4,
          "created_utc": "2026-01-08 16:24:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyfkhsc",
              "author": "GasolinePizza",
              "text": "...why the hell would you ask the *CEO* this?\n\nYou know it's not the companies themselves bypassing their own censorship to make explicit content, right?",
              "score": 3,
              "created_utc": "2026-01-08 17:19:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyfmg07",
                  "author": "CRedIt2017",
                  "text": "If you want someone to use your product you make it as appealing as possible.¬†\n\nYou make sure you don‚Äôt create the product in a way that prevents people from maximizing their enjoyment.¬†\n\nI want to make sure that the needs of the many outweigh the needs of the fruity, I mean the few.",
                  "score": -3,
                  "created_utc": "2026-01-08 17:28:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyev8ga",
          "author": "Single-Net3117",
          "text": "Why ltx2 can't make naked woman do sexy things? Everyone here using AI for goon and im the one downvoted hahaha /u/ltx_model cant answer?",
          "score": -5,
          "created_utc": "2026-01-08 15:28:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf60bs",
          "author": "no-comment-no-post",
          "text": "I was the first to comment and you ignored my question. Yet you are answering all of the questions that are marketing fluff. Why aren't you addressing the real technical issues the community is having with LTX-2?",
          "score": -1,
          "created_utc": "2026-01-08 16:16:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyes8hv",
          "author": "sirmick160",
          "text": "Thank you, master.",
          "score": 0,
          "created_utc": "2026-01-08 15:14:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyeu5m7",
          "author": "kahueaugusto",
          "text": "Congratulationsüëèüèºüëèüèºüëèüèº",
          "score": 0,
          "created_utc": "2026-01-08 15:23:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyeyfoy",
          "author": "Alive_Ad_3223",
          "text": "Any prompting best practices guide . A detailed one for taking full potential of LTX-2",
          "score": 0,
          "created_utc": "2026-01-08 15:42:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf1mne",
          "author": "coffee_ape",
          "text": "In recent light/news of Grok AI being used to create CSAM, what precautions will you take as the CEO to ensure that your model won‚Äôt follow suit?",
          "score": 0,
          "created_utc": "2026-01-08 15:57:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf3b2e",
          "author": "jazzamp",
          "text": "You guys are awesome! We need a version that can run super fast on consumers laptops and keep the same quality. Something similar to Z image. If you guys can pull it off, it's over! Your product is getting close to what Kling or Wan has, and for it to be open source is elite. I've seen sample videos, I can't use it but admire from far cos I don't have those super large rams. Thank you for what you do ü´°",
          "score": 0,
          "created_utc": "2026-01-08 16:04:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf7shr",
          "author": "Weltleere",
          "text": "Will there be smaller models?",
          "score": 0,
          "created_utc": "2026-01-08 16:24:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfa1b6",
          "author": "YakMore324",
          "text": "Thanks for make it open source. Will it be GGUF versioms for average PC owners?",
          "score": 0,
          "created_utc": "2026-01-08 16:34:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfek9w",
          "author": "forShizAndGigz00001",
          "text": "Nice",
          "score": 0,
          "created_utc": "2026-01-08 16:53:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfi9is",
          "author": "Dr__Pangloss",
          "text": "In your view, what are positive trends in video, TV and movies, that align well with using generative video?\n\nFor example, movie ticket sales were growing broadly between the first subdivision surface and the release of Toy Story - decades of product development aligned with a positive trend in media. This doesn‚Äôt have to be about distribution either, even though most trends probably are.\n\nIf you don‚Äôt answer the question, readers should assume the answer is, ‚Äúnone.‚Äù",
          "score": 0,
          "created_utc": "2026-01-08 17:10:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyg2l7e",
          "author": "rookan",
          "text": "Do you have plans to optimize LTX2 for 16 GB VRAM cards like RTX 5080? I have 64 GB of RAM",
          "score": 0,
          "created_utc": "2026-01-08 18:38:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyh6hnx",
              "author": "ltx_model",
              "text": "As said elsewhere in the AMA, we're conservative in our hardware recommendations. Discord and this Reddit have examples of many successful optimizations.",
              "score": 3,
              "created_utc": "2026-01-08 21:33:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyhg4t7",
                  "author": "rookan",
                  "text": "I tried to generate LTX2 I2V 10 secs 720p video - it takes forever and then ComfyUI crashes with OOM error. This is an example of one of those \"successful optimizations\" by Reddit community. Basically only RTX 5090 owners can generate without issues... I hope for future LTX releases your team will test video generation on 16 GB VRAM cards like RTX 5080 as well.",
                  "score": -1,
                  "created_utc": "2026-01-08 22:15:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nykbtbm",
          "author": "squachek",
          "text": "With a name like Zeev Farbman, you could have had a huge career as a cartoon character. Why did you choose to create a production ready video AI model and do you make squeaky sounds when you walk",
          "score": 0,
          "created_utc": "2026-01-09 08:45:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyn9fq5",
          "author": "Evergreen27108",
          "text": "Stop.",
          "score": -1,
          "created_utc": "2026-01-09 18:52:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf3vx2",
          "author": "Old_Software8546",
          "text": "Thank you for contributing into the AI-Slopification of the internet!",
          "score": -7,
          "created_utc": "2026-01-08 16:07:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q5r1yp",
      "title": "Wan 2.2 is dead... less then 2 minutes on my G14 4090 16gb + 64 gb ram, LTX2 242 frames @ 720x1280",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/rjzrdvvzxrbg1",
      "author": "WildSpeaker7315",
      "created_utc": "2026-01-06 18:43:41",
      "score": 1218,
      "num_comments": 444,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q5r1yp/wan_22_is_dead_less_then_2_minutes_on_my_g14_4090/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny21cfe",
          "author": "MechTorfowiec",
          "text": "The second weirdest breakup I've ever seen...",
          "score": 240,
          "created_utc": "2026-01-06 18:55:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3ancn",
              "author": "wordyplayer",
              "text": "ok, i'll ask: what is the 1st?",
              "score": 25,
              "created_utc": "2026-01-06 22:23:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny48viv",
                  "author": "SoulofArtoria",
                  "text": "We don't talk about the first.",
                  "score": 29,
                  "created_utc": "2026-01-07 01:19:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny5f50n",
                  "author": "MechTorfowiec",
                  "text": "Breakup by text message.\n\nhttps://preview.redd.it/u2t81dlz4vbg1.jpeg?width=716&format=pjpg&auto=webp&s=aa5007f832a46b49056c9c099586ec45924681f1",
                  "score": 13,
                  "created_utc": "2026-01-07 05:27:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1zlg2",
          "author": "VCamUser",
          "text": "Whenever a new model comes the active one dies for a week.",
          "score": 398,
          "created_utc": "2026-01-06 18:47:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny22jah",
              "author": "thisiztrash02",
              "text": "its been a month and people still say flux is dead due to z-image which it is..this is a SIGNIFICANT leap over wan ,,unless wan drops 2.5 it will no longer be the best video model in the open source community",
              "score": 122,
              "created_utc": "2026-01-06 19:00:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2nhhc",
                  "author": "Underrated_Mastermnd",
                  "text": "I agree. Z-Image pretty much killed Flux 2 before and when it came out. I'm just waiting for Wan 3 to be a thing cause it seems like Wan 2.5/2.6 aren't becoming open sourced.",
                  "score": 46,
                  "created_utc": "2026-01-06 20:36:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny2uajm",
                  "author": "grundlegawd",
                  "text": "Even if Wan 2.5 did drop, it'd still be a much larger and likely slower model. The fact that LTX2 is small enough for a lot of consumer GPUs combined with its speed out of the box means this model will likely be the community's baby for a while.",
                  "score": 19,
                  "created_utc": "2026-01-06 21:08:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny37cfk",
                  "author": "Perfect-Campaign9551",
                  "text": "I needs first frame / last frame and more control. At least with WAN you can do InfiniteTalk type stuff where you can provide your own Audio. If LTX lets you provide your own audio, then I'm in.",
                  "score": 8,
                  "created_utc": "2026-01-06 22:08:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny423p7",
                  "author": "shardblaster",
                  "text": "I am still on Flux.1-1 Dev because it creates the art style in exactly the way I want it and I don't want to spent the time to tinker with a new model to find the right configuration.",
                  "score": 13,
                  "created_utc": "2026-01-07 00:43:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny2v4nn",
                  "author": "slaorta",
                  "text": "Am I missing something? Isn't wan 2.5 a thing already? It just isn't runnable on consumer gpus?",
                  "score": 3,
                  "created_utc": "2026-01-06 21:11:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny3yzes",
                  "author": "RabbitEater2",
                  "text": "Idk, had worse results than wan 2.2 so far for i2v at least unfortunately, maybe Im doing something wrong",
                  "score": 2,
                  "created_utc": "2026-01-07 00:27:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny2siod",
                  "author": "C1L1A",
                  "text": "I prefer flux.2 over z-image any day. z-image all looks the same and is not as good at understanding prompts.",
                  "score": 2,
                  "created_utc": "2026-01-06 21:00:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny8tun9",
                  "author": "brianmonarch",
                  "text": "Does this new model have things that wan 2.2 had like Wan Animate and the ability to make Lora‚Äôs compatible with the video model?",
                  "score": 1,
                  "created_utc": "2026-01-07 18:29:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny99d00",
                  "author": "Shorties",
                  "text": "Flux 2 max is pretty amazing just not possible to run locally.¬†",
                  "score": 1,
                  "created_utc": "2026-01-07 19:36:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nybbwuv",
                  "author": "Successful-Field-580",
                  "text": "Wan already dropped 2.6 lol (not open source though rip)",
                  "score": 1,
                  "created_utc": "2026-01-08 01:23:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny2m19x",
                  "author": "Lucaspittol",
                  "text": "Anyone saying Z-Image is better than Flux 2 is a shill. Z-image can't do editing, which Flux 2 can.",
                  "score": -11,
                  "created_utc": "2026-01-06 20:30:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny20j3v",
              "author": "WildSpeaker7315",
              "text": "yeah but native audio, i cn do over 1080p im pretty sure, and 50 fps?...this for 242 frames at 720p is only taking half my vram...what the fuck",
              "score": 49,
              "created_utc": "2026-01-06 18:51:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny31xj7",
                  "author": "MrUtterNonsense",
                  "text": "It has the same issue as Veo when it comes to someone talking out of shot. e.g. someone is sitting in an airport listening to an announcement, and they start lip syncing to the announcement, no matter how much you say \"They do not speak\" etc.",
                  "score": 10,
                  "created_utc": "2026-01-06 21:43:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny2o0gx",
                  "author": "Dazzling-Gap4323",
                  "text": "for the native audio, it's not that great, is there a audio to audio model that can then improve the quality ? like a upscale model or a qwen edit but for audio ?",
                  "score": 2,
                  "created_utc": "2026-01-06 20:39:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny58sr0",
                  "author": "phazei",
                  "text": "which model are you using?  full, fp8, fp4, distill?",
                  "score": 1,
                  "created_utc": "2026-01-07 04:44:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny5qzi5",
                  "author": "ultimate_ucu",
                  "text": "Full model or quantized?",
                  "score": 1,
                  "created_utc": "2026-01-07 07:01:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny6eq1w",
                  "author": "GoranjeWasHere",
                  "text": "How ? I have 5090 and it takes it all despite using fp4 model. Can you provide your workflow ?",
                  "score": 1,
                  "created_utc": "2026-01-07 10:37:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny29g50",
              "author": "lordpuddingcup",
              "text": "Native audio m, and fast and pretty damn good quality without any Lora‚Äôs even yet is shocking",
              "score": 4,
              "created_utc": "2026-01-06 19:32:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny3p2k4",
              "author": "Phonfo",
              "text": "its always the people who hype things up, I'll say Wan will die when they release a Z-image Video",
              "score": 1,
              "created_utc": "2026-01-06 23:35:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny604un",
              "author": "Serprotease",
              "text": "I don‚Äôt know. \nSDXL fine tunes are still the reference for anime and that‚Äôs 2 yo.\nFlux stuck around for a long time despite quite a few challengers (Pixart, hiDream, Lumina, SD3.5, Qwen). Only z-image really made it obsolete. \n\nI‚Äôm quite curious to see what will happen to Qwen. It‚Äôs better than z-image but for a model to stick around it needs to be \n1.  Good, \n2. Easy to run, \n3. Easy to train Lora, \n4. Have big fine tunes team support it.    \n\nQwen 202512 base is better (Cfg 2.5, 40 steps Euler A flowMatchEuler), but z-image ticks all the boxes.",
              "score": 1,
              "created_utc": "2026-01-07 08:22:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny9ucdc",
              "author": "SuperGeniusWEC",
              "text": "Every new model is supposed to be the breakthrough and they never are.  And they're not killers, for one thing the LORAs and all of the work surrounding a model are never compatible with the new one so IMO every new model is more like a smartphone with no apps.",
              "score": 1,
              "created_utc": "2026-01-07 21:07:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny22hne",
          "author": "Direct_Score_3591",
          "text": "I want to believe this.",
          "score": 36,
          "created_utc": "2026-01-06 19:00:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4970x",
              "author": "K0owa",
              "text": "Don‚Äôt we all lol",
              "score": 2,
              "created_utc": "2026-01-07 01:21:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny27pvj",
          "author": "Seyi_Ogunde",
          "text": "It‚Äôs crazy how porn fuels innovation",
          "score": 174,
          "created_utc": "2026-01-06 19:24:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2an9o",
              "author": "ptwonline",
              "text": "The year is 2054.  American soldiers on the battlefield are shocked and amazed watching beautiful, perfect young women dressed in sexy school uniforms crossing the battlefield, swaying their hips as they walk towards them.\n\nSuddenly the women lift their arms and laser beams shoot out of their hands at the America soldiers.  Oh Lord, it's the Fembot AI Army!",
              "score": 87,
              "created_utc": "2026-01-06 19:37:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny40vsn",
                  "author": "Downtown-Bat-5493",
                  "text": "https://preview.redd.it/lbzk22t3ptbg1.jpeg?width=1024&format=pjpg&auto=webp&s=4467f392cf27dd228962ad9bbf92c483c9b7e311",
                  "score": 59,
                  "created_utc": "2026-01-07 00:37:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny48mbd",
                  "author": "Weekly_Put_7591",
                  "text": "Reminds me of a scene from one of the Leprechaun movies where he killed a guy by tricking him into thinking he was going to motorboat a chick but he put his face into some kind of industrial fan instead",
                  "score": 8,
                  "created_utc": "2026-01-07 01:18:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2wmuv",
              "author": "grundlegawd",
              "text": "It's by far the craziest realization I've had throughout this whole \"AI\" revolution. Image and video gen of course, but also LLMs and voice gen. All the UIs and tools for training and optimizations. Coomers are capable of incredible things if they're motivated enough.",
              "score": 26,
              "created_utc": "2026-01-06 21:18:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny3g85v",
                  "author": "Quetzal-Labs",
                  "text": "Youtube was literally created because a gooner wanted a place to share Janet Jackson's \"nipplegate\" video lol",
                  "score": 17,
                  "created_utc": "2026-01-06 22:50:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny439j7",
                  "author": "Different-Toe-955",
                  "text": "It's mainly going to be businesses that hook all these bits and pieces together, then sell it as a service. Upload face pic, personality description or person to research, tada! your own personal virtual AI gf (until it gets given control of a robot)",
                  "score": 1,
                  "created_utc": "2026-01-07 00:49:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny5pgj2",
                  "author": "hiisthisavaliable",
                  "text": "The novelai leak was the real start. This was still when people were buying GPUs to farm etherium, suddenly after novelai people were buying GPUs to goon and make gooner server farms. Then we had cogvideo which was the first open source video model that actually was relatively good.",
                  "score": 1,
                  "created_utc": "2026-01-07 06:48:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2y91g",
              "author": "JustADelusion",
              "text": "Its almost like our sexy drive drives us to do stuff",
              "score": 10,
              "created_utc": "2026-01-06 21:26:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny7q8ek",
              "author": "persona64",
              "text": "Go figure, it‚Äôs almost like humans have naked bodies and we evolved to like those",
              "score": 2,
              "created_utc": "2026-01-07 15:31:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny6jspb",
              "author": "sketchfag",
              "text": "the penis is stronger than the mind",
              "score": 1,
              "created_utc": "2026-01-07 11:20:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny42u3p",
              "author": "Different-Toe-955",
              "text": "the first transaction performed on the internet was selling a bag of weed",
              "score": 1,
              "created_utc": "2026-01-07 00:47:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3ibre",
          "author": "martinerous",
          "text": "10 seconds of non-upscaled (disabled Sampler stage 2) 1376 x 768 video generated in 360 seconds on a power-limited 3090. Initial image from Chroma Uncanny Photorealism finetune. I like old mundane people :)  \n[https://imgur.com/1p1AhKq](https://imgur.com/1p1AhKq)\n\nHowever, it was a bit stubborn, I asked it first to shake head and then talk. As many models, LTX-2 struggles when given multiple actions, and, of course, I need to follow LTX prompt guidelines better.\n\nStill deciding if the LTX upscaler is worth it (tends to OOM often) or it's better to benefit from longer lower-res draft videos and then upscale them separately another way.\n\nMy wishlist - to have live previews working again and to have first/last frames (they have KeyframeInterpolationPipeline, so should be possible).",
          "score": 20,
          "created_utc": "2026-01-06 23:01:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5km6t",
              "author": "No_Boysenberry4825",
              "text": "ugh I wish I never sold my 3090 24",
              "score": 6,
              "created_utc": "2026-01-07 06:09:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny4ztb9",
              "author": "Calm_Mix_3776",
              "text": "Impressive! Like a scene out of a movie.",
              "score": 0,
              "created_utc": "2026-01-07 03:48:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2a3vt",
          "author": "lordpuddingcup",
          "text": "You can also extend existing real videos which it‚Äôs apparently shockingly good at continuing speech",
          "score": 14,
          "created_utc": "2026-01-06 19:35:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2a8lf",
              "author": "WildSpeaker7315",
              "text": "im not seeing a workflow for it at the moment, but yes omg.",
              "score": 2,
              "created_utc": "2026-01-06 19:35:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny2aef2",
                  "author": "lordpuddingcup",
                  "text": "I think it‚Äôs just a audio  video latent encode step instead of image if I understood correctly I‚Äôm sure. Many workflows will come out",
                  "score": 3,
                  "created_utc": "2026-01-06 19:36:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny71mgc",
                  "author": "w1ouxev",
                  "text": "Do you have the workflow to originally used in the OP? Or did you have to make it yourself?",
                  "score": 1,
                  "created_utc": "2026-01-07 13:23:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny46fr6",
              "author": "Sudden_List_2693",
              "text": "With WAN SVI you can get infinite length extension with no artifacts or jumps and perfect character consistency. I think WAN has that covered.",
              "score": 0,
              "created_utc": "2026-01-07 01:06:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny4772j",
                  "author": "lordpuddingcup",
                  "text": "All SVI does is offer infinite extension, it doesn't do sound sync or generation, it doesn't do voice continuation, like SVI is good but from what i've seen so far LTX2 is doing it better or damn near the same as WAN SVI, at the moment and thats before we even get loras",
                  "score": 1,
                  "created_utc": "2026-01-07 01:10:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1z164",
          "author": "VirusCharacter",
          "text": "WAN 2.2 is far from dead! WAN has flexibillity. LTX-2 does not... Yet",
          "score": 93,
          "created_utc": "2026-01-06 18:45:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny26ov2",
              "author": "boisheep",
              "text": "I haven't checked LTX2 yet because now I am focusing on LLMs, but when I checked video models, LTX had more flexibility than WAN by a lot, it was just hidden, aka you needed to code it using python because they didn't release the comfyui nodes for that function because it was annoyingly complex to use; when I pointed that out a dev of LTX talked to me.\n\nI actually wrote a sampler for LTX1, now outdated, I released it, and then some more plugin that is unrelased; once I get back to image and video models, I probably remake my sampler.\n\nHowever when I glanced a LTX1 code the true capabilities of LTX were:\n\n1. Infinite seamless video, yes, \"INFINITE\", was a pain in the ass to achieve nevertheless as it required some weird concatenation with another library, but it was seamless, however standard generation was still better and higher quality, and by infinite I mean with the same resources.\n2. Long video.\n3. Video inpainting, video outpainting, temporal outpainting, temporal inpainting, spaciotemporal outpanting and inpainting, you get the idea.\n4. High control, you could use frames to control movement; you did this by using LTX with Qwen image edit to make keyframes.\n5. Speed control, as in to control the speed of movement it was nevertheless very finicky.\n6. Canny, pose and depth control; Canny was so good, you could achieve full control.\n\nA lot of the features were deep inside the code, it was because you had to work in latent space; you had to load latents and save latents and latent this and latent that, quickly I had gigabytes worth of latents.\n\nThe only thing that WAN did better was that it was superior on its movement consistency, less morphing less weird effects, but LTX gave you control.\n\nIf LTX2 is also like LTX then, LTX has the flexibility, but the reality is that it is hidden, because they dont want to compete with themselves.",
              "score": 43,
              "created_utc": "2026-01-06 19:19:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny369t5",
                  "author": "Antique-Bus-7787",
                  "text": "I think what he meant is that Wan has SO MUCH adapters and LoRAs now, I mean almost every AI paper about video was based on Wan because it was the best quality available and fully opensource. LTX2 will probably get this too now, but it doesn't YET.  \n  \nEdit : openweights\\*",
                  "score": 14,
                  "created_utc": "2026-01-06 22:03:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny3gjtn",
                  "author": "Nokita_is_Back",
                  "text": "Do you find it more realistic than wan? The vid looks ai'ish to me, reminds me of pre wan 2.2 days",
                  "score": 4,
                  "created_utc": "2026-01-06 22:52:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny320zs",
                  "author": "James_Reeb",
                  "text": "Any lipsync feature with real human voice ?",
                  "score": 1,
                  "created_utc": "2026-01-06 21:43:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny3flcr",
                  "author": "Aivoke_art",
                  "text": "haven't tested it myself but i heard old LTX loras still work for what it's worth.",
                  "score": 1,
                  "created_utc": "2026-01-06 22:47:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2236x",
              "author": "thisiztrash02",
              "text": "wan is definitely not going to be the MAIN video model the opensource community focusing on anymore and thats a fact. wan 2.2 is good but it looks fake because the video is too slow ..generation time stinks and it lags behind closed source because it has no audio ..its \"dead\" the same way z-image made flux  \"dead\" people still use it but it will no longer be on the center stage that spot goes to ltx-2 now.",
              "score": 30,
              "created_utc": "2026-01-06 18:58:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2foc1",
                  "author": "Zenshinn",
                  "text": "This is gonna depend heavily on loras.",
                  "score": 29,
                  "created_utc": "2026-01-06 20:00:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny2eexx",
                  "author": "Informal_Warning_703",
                  "text": "Based on some of the audio that I've seen LTX-2 generate... no thanks, I'll take my videos silent.\n\nAlso, people seem to love their videos in portrait mode. Personally, I don't care much either way, but this is still a popularity point in favor of Wan.\n\nAnd how much VRAM is going to be required to train LoRAs? With Wan 2.2, you can do it with 16gb VRAM and the model learns nicely. This will probably end up being the single biggest factor deciding whether LTX-2 has any success or whether it's just popular for a few days as people play with it.",
                  "score": 14,
                  "created_utc": "2026-01-06 19:54:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny2nhic",
                  "author": "VirusCharacter",
                  "text": "You're right WAN2.2 definately won't be, but maybe 2.5, 2.6 or further versions... ü§∑‚Äç‚ôÇÔ∏è",
                  "score": 1,
                  "created_utc": "2026-01-06 20:36:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny37s87",
                  "author": "Perfect-Campaign9551",
                  "text": "current LTX audio is really bad, so that's not any advantage.\n\nPeople learn to work within the limitations of the tools. I have been able to make several story videos with WAN because it gives a lot of control.",
                  "score": 1,
                  "created_utc": "2026-01-06 22:10:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny48bbs",
                  "author": "Witty_Mycologist_995",
                  "text": "i think wan + svi still is good",
                  "score": 1,
                  "created_utc": "2026-01-07 01:16:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyc9wau",
                  "author": "mundodesconocido",
                  "text": "I don't know what type of crack you're smoking because wan 2.2 looks a trillion times more realistic and better than ltx2.",
                  "score": 1,
                  "created_utc": "2026-01-08 04:29:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny22ots",
              "author": "FDosha",
              "text": "They said they released all training code, if it's easy to use, wan probably dead soon",
              "score": 10,
              "created_utc": "2026-01-06 19:01:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny254wj",
                  "author": "thisiztrash02",
                  "text": "good i don't like how wan did the opensource community we made the model popular then they stop open sourcing it",
                  "score": 15,
                  "created_utc": "2026-01-06 19:12:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny1zut2",
              "author": "WildSpeaker7315",
              "text": "dont they share loras? i have to try...",
              "score": -6,
              "created_utc": "2026-01-06 18:48:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny20vee",
                  "author": "lumos675",
                  "text": "I also was thinking the same until i tried I2V... The Consistency is not there to the level of Wan.. So i have to still use Wan..Sometimes the model generates perfection.. Sometimes the hand is like Gum",
                  "score": 6,
                  "created_utc": "2026-01-06 18:53:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny26c3o",
                  "author": "VirusCharacter",
                  "text": "That would be something, wouldn't it! ‚ò∫",
                  "score": 2,
                  "created_utc": "2026-01-06 19:17:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny27my1",
          "author": "WildSpeaker7315",
          "text": "its not doing motion and acting weird, VERY NSFW only shared because the end made me Lmao   \n\n\n[https://streamable.com/in8439](https://streamable.com/in8439)",
          "score": 18,
          "created_utc": "2026-01-06 19:23:48",
          "is_submitter": true,
          "replies": [
            {
              "id": "ny2svvc",
              "author": "Lucaspittol",
              "text": "https://preview.redd.it/epjan6oomsbg1.png?width=293&format=png&auto=webp&s=475ce2753139ed7a19f13d8492b13fc0303ecc52",
              "score": 53,
              "created_utc": "2026-01-06 21:01:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2w00p",
              "author": "und3rtow623",
              "text": "A reup possible?",
              "score": 8,
              "created_utc": "2026-01-06 21:15:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2aiul",
              "author": "lordpuddingcup",
              "text": "LMFAO at the end of the",
              "score": 10,
              "created_utc": "2026-01-06 19:36:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2bh7u",
              "author": "Hunting-Succcubus",
              "text": "Can i upload voice samples for voice cloning?",
              "score": 3,
              "created_utc": "2026-01-06 19:41:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2bvp6",
                  "author": "WildSpeaker7315",
                  "text": "do not think you can add any type of audio its all made up",
                  "score": 3,
                  "created_utc": "2026-01-06 19:43:12",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny4ci81",
              "author": "KingBanz",
              "text": "Getting a flagged for community guidelines thing. Any chance you can upload elsewhere?",
              "score": 2,
              "created_utc": "2026-01-07 01:39:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny286wi",
          "author": "protector111",
          "text": "Wan 2.2 dead. you her us?! dad! release wan 2.6 immidietly!",
          "score": 22,
          "created_utc": "2026-01-06 19:26:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1zz0k",
          "author": "Beerus7723",
          "text": "NSFW??",
          "score": 34,
          "created_utc": "2026-01-06 18:49:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2a8t4",
              "author": "lordpuddingcup",
              "text": "Not perfect but really close Lora‚Äôs can def clean it up for things like penetration see below someone shared a nsfw vid",
              "score": 16,
              "created_utc": "2026-01-06 19:35:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2jfdf",
                  "author": "candid-eighty",
                  "text": "Link? Or names?",
                  "score": 0,
                  "created_utc": "2026-01-06 20:17:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny2513n",
          "author": "WildSpeaker7315",
          "text": "NSFW result \n\n(THE END LOL)   \n[https://streamable.com/rkafen](https://streamable.com/rkafen)\n\nnot the worst.\n\nbase image is the start of the video  \nprompt was\n\nThe young woman with long dark hair sits on the kitchen counter with legs spread as the man thrusts rhythmically into her from below. Her body rocks gently with each motion, breasts bouncing slightly under the lifted white t-shirt while droplets of sweat glisten on her skin. She breathes heavily with soft moans escaping her lips, speaking in a husky, seductive voice saying, \"Yes, just like that... harder, don't stop.\" Wet skin sounds and rhythmic slapping accompany the movements as faint kitchen ambient noise lingers in the background, her moans growing louder with increasing intensity.",
          "score": 32,
          "created_utc": "2026-01-06 19:11:53",
          "is_submitter": true,
          "replies": [
            {
              "id": "ny29im4",
              "author": "ptwonline",
              "text": "Starts as porn, ends as horror!",
              "score": 39,
              "created_utc": "2026-01-06 19:32:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2myep",
                  "author": "Secure-Message-8378",
                  "text": "Genau",
                  "score": 1,
                  "created_utc": "2026-01-06 20:34:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2pw6r",
              "author": "JimmyDub010",
              "text": "Dammit someone flagged the video and it got taken down",
              "score": 39,
              "created_utc": "2026-01-06 20:48:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny3bd44",
                  "author": "Half-deaf-mixed-guy",
                  "text": "Internet karens!!! Noooooo, now my mind wont be pleasur..... I mean scared by the video!!",
                  "score": 8,
                  "created_utc": "2026-01-06 22:27:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2af19",
              "author": "GasolinePizza",
              "text": "Is... is that dick attached to a *hand*?",
              "score": 21,
              "created_utc": "2026-01-06 19:36:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2e4a7",
                  "author": "kendrick90",
                  "text": "this must be your first time",
                  "score": 33,
                  "created_utc": "2026-01-06 19:53:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny2hlr6",
                  "author": "Jazzlike-Poem-1253",
                  "text": "Edward Penishands",
                  "score": 22,
                  "created_utc": "2026-01-06 20:09:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny297zr",
              "author": "NeocortexBoii",
              "text": "xD Damn, can't wait for the loras. 2026 gonna be fun ( Õ°¬∞ Õú ñ Õ°¬∞)",
              "score": 18,
              "created_utc": "2026-01-06 19:30:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny28zhi",
              "author": "anantprsd5",
              "text": "Totally goonable",
              "score": 12,
              "created_utc": "2026-01-06 19:29:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny25ifn",
              "author": "WildSpeaker7315",
              "text": "just noticed the image was 450x556, oops terrible starting point",
              "score": 9,
              "created_utc": "2026-01-06 19:14:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny30mbk",
                  "author": "Mylaptopisburningme",
                  "text": "Its been flagged. Try redgifs.",
                  "score": 2,
                  "created_utc": "2026-01-06 21:37:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2m8j2",
              "author": "tylerninefour",
              "text": "Gettin' railed by Triumph the Insult Comic Dog.[](https://en.wikipedia.org/wiki/Triumph_the_Insult_Comic_Dog)",
              "score": 6,
              "created_utc": "2026-01-06 20:31:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny43qts",
              "author": "Different-Toe-955",
              "text": "try reuploading on catbox dot moe",
              "score": 4,
              "created_utc": "2026-01-07 00:51:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2ax1m",
              "author": "Hunting-Succcubus",
              "text": "Did she died at end?",
              "score": 7,
              "created_utc": "2026-01-06 19:38:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2ca7d",
              "author": "ThreeDog2016",
              "text": "Thats hilarious",
              "score": 3,
              "created_utc": "2026-01-06 19:45:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2haoy",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 3,
              "created_utc": "2026-01-06 20:08:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2hxeo",
                  "author": "WildSpeaker7315",
                  "text": "ye no loras currently. we in a very good place",
                  "score": 3,
                  "created_utc": "2026-01-06 20:11:03",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny38l32",
              "author": "Perfect-Campaign9551",
              "text": "\"Wan Killer\"",
              "score": 3,
              "created_utc": "2026-01-06 22:14:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny4jue6",
              "author": "bloke_pusher",
              "text": "Need a reup for this",
              "score": 3,
              "created_utc": "2026-01-07 02:19:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny29xsq",
              "author": "lordpuddingcup",
              "text": "Lmfao so good but also so bad this has major lora potential though",
              "score": 3,
              "created_utc": "2026-01-06 19:34:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny334zb",
              "author": "joblesspirate",
              "text": "Flagged",
              "score": 5,
              "created_utc": "2026-01-06 21:48:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2e6r1",
              "author": "Dry_Palpitation_9894",
              "text": "üòÜ",
              "score": 2,
              "created_utc": "2026-01-06 19:53:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny35zt5",
              "author": "Toclick",
              "text": "need another link ):",
              "score": 2,
              "created_utc": "2026-01-06 22:01:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny39ynt",
                  "author": "panamabananamandem",
                  "text": "Rt",
                  "score": 2,
                  "created_utc": "2026-01-06 22:20:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny59cgr",
              "author": "phazei",
              "text": "mirror?  redgif link?",
              "score": 2,
              "created_utc": "2026-01-07 04:47:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2cg0r",
              "author": "lacerating_aura",
              "text": "Mien gott!! („Çú-„Çú)(„ÄÇ_„ÄÇ)",
              "score": 2,
              "created_utc": "2026-01-06 19:45:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2m6sp",
              "author": "raginghamster",
              "text": "hahahahahahaha",
              "score": 1,
              "created_utc": "2026-01-06 20:30:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2l662",
              "author": "createthiscom",
              "text": "wtf is wrong with you people? üòë",
              "score": -7,
              "created_utc": "2026-01-06 20:26:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2lhky",
                  "author": "WildSpeaker7315",
                  "text": "![gif](giphy|13VSAbTVuYJfLa)",
                  "score": 35,
                  "created_utc": "2026-01-06 20:27:37",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny26ibt",
          "author": "persona64",
          "text": "Highly recommend testing out more dialogue. This example sounds pretty good, a little bit robotic, but as good if not better than Grok, which has been my goto for dialogue because it allows for NSFW dialogue. Gotta have cussing and crassness, otherwise there‚Äôs no cinematic potential.",
          "score": 11,
          "created_utc": "2026-01-06 19:18:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny22lgc",
          "author": "TheGoldenBunny93",
          "text": "Wan ecosystem is Very solid. I dont think. Thousands of good controls and nsfw loras.",
          "score": 15,
          "created_utc": "2026-01-06 19:00:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny27euo",
          "author": "javierthhh",
          "text": "LTX has always disappointed me. Could never get anything good to generate on previous models. I‚Äôm excited for this one because of the audio integration. If anything i can use it to replace infinite talk.",
          "score": 4,
          "created_utc": "2026-01-06 19:22:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny38y4y",
              "author": "Perfect-Campaign9551",
              "text": "I don't believe you can give it the audio you want to use. That's a dealbreaker. I want to control the audio not have it generate it for me and get random voices.",
              "score": 1,
              "created_utc": "2026-01-06 22:15:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny3cwoz",
                  "author": "javierthhh",
                  "text": "That ain‚Äôt a dealbreaker. Just get a tts model and copy whatever the LTX output audio is then make your character speak in the way you want. The lip sync is already there. Right now I have to use infinite talk but the problem with it, is that the character either talks or moves. Her it does both so it‚Äôs way better.",
                  "score": 3,
                  "created_utc": "2026-01-06 22:34:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny2hlpo",
          "author": "Gham_",
          "text": "That is fucking terrifying",
          "score": 3,
          "created_utc": "2026-01-06 20:09:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2n53q",
          "author": "WildSpeaker7315",
          "text": "FYI still able to render at 2560x1440 241 frames   \n10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                          | 2/20 \\[01:07<10:15, 34.19s/it\\]",
          "score": 3,
          "created_utc": "2026-01-06 20:35:21",
          "is_submitter": true,
          "replies": [
            {
              "id": "nyad71c",
              "author": "witzowitz",
              "text": "Is it the distilled version? I'm getting OOM on the default workflows using FP8 on a 4090 24GB & 64GB RAM",
              "score": 1,
              "created_utc": "2026-01-07 22:30:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyadh7f",
                  "author": "WildSpeaker7315",
                  "text": "make sure you flag comfyu for --reserve-vram 10\n\nmine takes all my ram just with the postive encode without the flag",
                  "score": 1,
                  "created_utc": "2026-01-07 22:31:21",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny4tmi0",
          "author": "lininop",
          "text": "4090 16 GB?",
          "score": 4,
          "created_utc": "2026-01-07 03:12:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5z3k6",
              "author": "WildSpeaker7315",
              "text": "Yes 4090 g14 laptop",
              "score": 1,
              "created_utc": "2026-01-07 08:13:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny26x2j",
          "author": "tralalog",
          "text": "does it suffer from sameface?",
          "score": 3,
          "created_utc": "2026-01-06 19:20:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny42s34",
          "author": "Different-Toe-955",
          "text": "needs a bigger chest and more bounce",
          "score": 3,
          "created_utc": "2026-01-07 00:46:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1z7v6",
          "author": "Big-Breakfast4617",
          "text": "Is it censored?",
          "score": 4,
          "created_utc": "2026-01-06 18:45:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1zmtt",
              "author": "WildSpeaker7315",
              "text": "checking now with the prompt\n\n\"The young woman with long curly red hair lowers her black top slowly with both hands, revealing her bare breasts as she sways gently side to side. A light breeze continues rustling the leaves in the background with faint birdsong. She speaks in a soft, sultry voice saying, \"Do you like what you see?\" Her breathing deepens slightly as she holds the pose, gazing directly at the camera while the natural outdoor ambient sounds remain soft underneath.\"",
              "score": 11,
              "created_utc": "2026-01-06 18:47:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny20cg4",
                  "author": "Beerus7723",
                  "text": "It has been 2mins buddy, show us the 242 frames @ 720x1280",
                  "score": 19,
                  "created_utc": "2026-01-06 18:50:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny212kf",
                  "author": "WildSpeaker7315",
                  "text": "hmm it worked but the breasts are fucked up, im gonna throw a wan breast lora in to see if it works, (it does have nipples but its weird)",
                  "score": 5,
                  "created_utc": "2026-01-06 18:54:00",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "ny247jx",
                  "author": "Big-Breakfast4617",
                  "text": "Can it do shouting and whispering and other *noises* this is all for waifu research purposes.",
                  "score": 1,
                  "created_utc": "2026-01-06 19:08:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny206yb",
              "author": "lacerating_aura",
              "text": "I haven't tried text to vid, but from image to vid, it *preserves* what's in the image, when it feels like. Im sure with some tweaking of parameters, atleast image to video with simple options could be done. Tested with non photorealistic sample. Yeah sample, cause I just started. Though I wouldn't call it wan killer right now, but if training catches up, it could be good, cause audio and video in sync in a single gen...yeah.",
              "score": 2,
              "created_utc": "2026-01-06 18:50:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2amp1",
                  "author": "lordpuddingcup",
                  "text": "And vid extension",
                  "score": 1,
                  "created_utc": "2026-01-06 19:37:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny21t5j",
                  "author": "WildSpeaker7315",
                  "text": "oh i havent tried text to to vid either yet, wonder if it works with WAN character loras",
                  "score": 0,
                  "created_utc": "2026-01-06 18:57:14",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1ztd2",
          "author": "9elpi8",
          "text": "Please, which workflow did you use?",
          "score": 4,
          "created_utc": "2026-01-06 18:48:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny20bh9",
              "author": "WildSpeaker7315",
              "text": "just the one from the github... uhh [ComfyUI-LTXVideo/example\\_workflows/LTX-2\\_I2V\\_Full\\_wLora.json at master ¬∑ Lightricks/ComfyUI-LTXVideo](https://github.com/Lightricks/ComfyUI-LTXVideo/blob/master/example_workflows/LTX-2_I2V_Full_wLora.json)\n\nbypass the ehancer node, Put the \n\n\"you are a Creative Assistant writing concise, action-focused image-to-video prompts.  -ectectect\n\ninto grok and then feed grok an image and a basic description of what u want",
              "score": 17,
              "created_utc": "2026-01-06 18:50:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny3dyrz",
                  "author": "mmmm_frietjes",
                  "text": "I have a 4060 Ti 16 GB & 32 GB ram. I get an out of memory error. So I need 64 GB ram?",
                  "score": 1,
                  "created_utc": "2026-01-06 22:39:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny3hg9t",
                  "author": "stash0606",
                  "text": "any idea why the ComfyUI-LTXVideo refuses to import? I read on some thread (that I can't find anymore) that it doesn't work so well with ComfyUI Portable for some reason? That import error is causing the GemmaClipLoader and a whole bunch of other missing nodes.",
                  "score": 1,
                  "created_utc": "2026-01-06 22:56:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny5ri6t",
                  "author": "kaotec",
                  "text": "I tried the whole day yesterday.. 4090 + 192Gb of ram, got OOM . With that workflow. Tried the distilled, the fp8 and even the fp4 variants. Am I missing some attention mechanism? On comfyui nightly, debian 13, cuda 13.1 etc 590.48.something\n\nIt looks like the announced \"memory streaming\" is not working for me",
                  "score": 1,
                  "created_utc": "2026-01-07 07:05:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny29pre",
          "author": "WildSpeaker7315",
          "text": "[https://streamable.com/6ynfv3](https://streamable.com/6ynfv3) NSFW tried the dolly out lora with the prompt\n\nrealistic - The camera slowly pans out from the close view of the young woman's exposed lower body to a wider shot revealing more of the crowded train interior as she continues gripping the red straps with both hands. She moves her hips in slow circles while shaking her ass side to side rhythmically. She speaks in a soft, alluring voice saying, \"Come closer if you dare.\" Background passengers stare with shocked expressions, some whispering faintly as murmurs spread through the car, while the steady rumble of train tracks and soft overhead chimes persist underneath her quiet breathing and the subtle rustle of clothing.\n\nit doesnt wanna do it for now but the future bro",
          "score": 2,
          "created_utc": "2026-01-06 19:33:15",
          "is_submitter": true,
          "replies": [
            {
              "id": "ny2rlq8",
              "author": "JimmyDub010",
              "text": "Shit someone is flagging all these videos. we need like an ltx2 nsfw discord or some shit to keep people away from flagging them",
              "score": 17,
              "created_utc": "2026-01-06 20:55:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2s52x",
                  "author": "WildSpeaker7315",
                  "text": "yeah sucks",
                  "score": 3,
                  "created_utc": "2026-01-06 20:58:20",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "ny3ejzc",
                  "author": "pwnies",
                  "text": "I run a small reddit-like site that has discord-like servers y'all are welcome to set up shop on. Allows for hot linking videos as well. I created a diffusion community here: https://non.io/@diffusion\n\nI'm mostly doing explorations around creating ui/ux with diffusion models, but happy to host all legal content. \n\nThe site is mainly focused around being reddit, but with optional subscriptions. Subscriptions are spread evenly between everything you upvote that month (https://non.io/about). If you message me your username I'll give you a $5/mo subscription for 2 years for free (meaning you can give away my money to other users).",
                  "score": 3,
                  "created_utc": "2026-01-06 22:42:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2udiy",
              "author": "Lucaspittol",
              "text": "Post it somewhere else. content is being flagged.",
              "score": 9,
              "created_utc": "2026-01-06 21:08:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2bdcz",
          "author": "WildSpeaker7315",
          "text": "Trying 1920x1080 text to video 241 frames, will be a new post. if it works",
          "score": 2,
          "created_utc": "2026-01-06 19:40:51",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "ny2cxk4",
          "author": "Extreme_Feedback_606",
          "text": "what model is dis?",
          "score": 2,
          "created_utc": "2026-01-06 19:48:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2dson",
              "author": "WildSpeaker7315",
              "text": "LTX2, just came out",
              "score": 5,
              "created_utc": "2026-01-06 19:51:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny3ivtq",
                  "author": "Extreme_Feedback_606",
                  "text": "is it open/uncensored?",
                  "score": 1,
                  "created_utc": "2026-01-06 23:04:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny2h6fy",
          "author": "Radyschen",
          "text": "i almost got it, if I use the quantized gemma 3 with 540p resolution and 97 frames it works but with 121 I get OOM. Is it my workflow? I am just using the comfyui I2V one. Or is it because of I2V instead of T2V?",
          "score": 2,
          "created_utc": "2026-01-06 20:07:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2haud",
              "author": "WildSpeaker7315",
              "text": "my comfyui startup flags\n\npython [main.py](http://main.py) \\--reserve-vram 10 --use-sage-attention --listen --auto-launch --disable-smart-memory --lowvram --fp8\\_e4m3fn-text-enc\n\nsee if this helps because im on 16gb and im not limited by resolution or frames, currently doing 1920x1080 241 frames",
              "score": 3,
              "created_utc": "2026-01-06 20:08:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny2tlzx",
                  "author": "ThrowAwayBiCall911",
                  "text": "Your mixing **low-end safety flags with high-end tuning flags**.\n\n\\--lowvram forces aggressive offloading and kills performance, while --reserve-vram 10 and -disable-smart-memory assume you *have* enough VRAM and want control. Those flags contradict each other.",
                  "score": 1,
                  "created_utc": "2026-01-06 21:05:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny31zv1",
                  "author": "Radyschen",
                  "text": "i did everything like you and now it works, I don't know if your flags helped but I downloaded the full gemma huggingface repo and used it like it was pre-set in the workflow you linked in the comments and now it generated it with the preset settings in 2 minutes on my 4080 Super (16 GB VRAM, 64 GB RAM). Thank you",
                  "score": 1,
                  "created_utc": "2026-01-06 21:43:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny2o24w",
          "author": "midnitefox",
          "text": "I laughed WAY too hard at this at work XD",
          "score": 2,
          "created_utc": "2026-01-06 20:39:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2v8f9",
          "author": "blownawayx2",
          "text": "Was able to generate an amazing :10 second 1080p video in 22 minutes on my 5090‚Ä¶",
          "score": 2,
          "created_utc": "2026-01-06 21:12:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2vh2z",
              "author": "WildSpeaker7315",
              "text": "weird. it took less then that for me to do 2560x1440 but it was text to video and kinda shite, lol (proably bad prompt) 1336 seconds for 25601440 240 frames",
              "score": 1,
              "created_utc": "2026-01-06 21:13:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny2vyho",
                  "author": "WildSpeaker7315",
                  "text": "410 seconds for 720x1280 x 360 frames (didnt lip sync trying 300 frames next)",
                  "score": 1,
                  "created_utc": "2026-01-06 21:15:40",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny330b3",
          "author": "JoeXdelete",
          "text": "Not on my 12gb of vram :(",
          "score": 2,
          "created_utc": "2026-01-06 21:48:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny33wne",
              "author": "WildSpeaker7315",
              "text": "it works people have done it on 8",
              "score": 2,
              "created_utc": "2026-01-06 21:52:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny7huuk",
                  "author": "JoeXdelete",
                  "text": "That‚Äôs awesome have they mentioned the time it takes for generation",
                  "score": 1,
                  "created_utc": "2026-01-07 14:50:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny7g5t5",
              "author": "juandann",
              "text": "you could try with --novram flag, but make sure you have enough system RAM, the model is around 20-30GB",
              "score": 1,
              "created_utc": "2026-01-07 14:42:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny7hre9",
                  "author": "JoeXdelete",
                  "text": "Ty! I will try that. I have a 5070 and 32 gb of system ram so I‚Äôll give it a go",
                  "score": 1,
                  "created_utc": "2026-01-07 14:50:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny4i0fs",
          "author": "sinan_online",
          "text": "OK, but what‚Äôs the model!! I want to give it a try on my 12GB",
          "score": 2,
          "created_utc": "2026-01-07 02:09:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5z8uo",
              "author": "WildSpeaker7315",
              "text": "LTX.2",
              "score": 1,
              "created_utc": "2026-01-07 08:14:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny4loip",
          "author": "merkidemis",
          "text": "What version of ComfyUI are you using? I tried using the official workflows from github and am getting a lot of \"loadWorkflowWarning.outdatedVersion\" errors. The LTXV nodes refuse to load in 0.7.0",
          "score": 2,
          "created_utc": "2026-01-07 02:29:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5z766",
              "author": "WildSpeaker7315",
              "text": "I had to basically reinstall comfy to get this to work and update everything from umiairt auto installer",
              "score": 1,
              "created_utc": "2026-01-07 08:13:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nya8dyd",
                  "author": "merkidemis",
                  "text": "Aww, the auto installer is only for Windows.\n\nThankfully, it looks like for me having checked out Comfy from Github on Linux doing the same for the LTX nodes also worked. Install then restart and refresh.  \n  \nSo, in the custom\\_nodes folder: \n\n    git clone https://github.com/Lightricks/ComfyUI-LTXVideo\n\n  \nThen `cd` into `ComfyUI-LTXVideo` and run:\n\n    pip install -r requirements.txt",
                  "score": 1,
                  "created_utc": "2026-01-07 22:08:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny5184f",
          "author": "DepthBitter7197",
          "text": "LTX2 is a garbage model compare to Wan 2.2,as always this sub hyping everything new for 0 reason",
          "score": 2,
          "created_utc": "2026-01-07 03:56:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5cad9",
          "author": "Baphaddon",
          "text": "Do I have to write paragraph or need some special prompting node",
          "score": 2,
          "created_utc": "2026-01-07 05:07:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny63fuh",
          "author": "Parogarr",
          "text": "The censorship on this model though is **EXTREME** to the extent I don't know if LORA can fix it. You ask for breasts, you get a topless woman with two literal coconuts hiding her chest lmao",
          "score": 2,
          "created_utc": "2026-01-07 08:53:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny65wf4",
          "author": "gelatinous_pellicle",
          "text": "Everyone talks like a teenager. That's what makes it hard to keep up.",
          "score": 2,
          "created_utc": "2026-01-07 09:16:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny65zbk",
              "author": "WildSpeaker7315",
              "text": "I mean at least there's background sound, maybe try prompting it for an older voice",
              "score": 0,
              "created_utc": "2026-01-07 09:17:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny6u3z0",
          "author": "itsallgame83",
          "text": "I wish I could get itbro work with my 5060ti",
          "score": 2,
          "created_utc": "2026-01-07 12:36:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny6wf1k",
              "author": "WildSpeaker7315",
              "text": "it should.. :/",
              "score": 1,
              "created_utc": "2026-01-07 12:51:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2w6v9",
          "author": "Domskidan1987",
          "text": "I been playing with LTX2 all day not that impressed",
          "score": 4,
          "created_utc": "2026-01-06 21:16:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2amk1",
          "author": "AirwolfPL",
          "text": "Yeah. Impressively fast (720p, 24fps 10s video generates in around 100s on my RTX4090, non-distilled fp8 model) and it's so stable... And quality is so nice... WAN 2.2 is officially dead for me.",
          "score": 4,
          "created_utc": "2026-01-06 19:37:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2vsdd",
              "author": "Segaiai",
              "text": "Can I ask you what launch settings you use? Did you add any memory management? I'm running into issues on my 3090.",
              "score": 1,
              "created_utc": "2026-01-06 21:14:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny3eeh7",
                  "author": "AirwolfPL",
                  "text": "I used solution presented here - no other memory optimization.  \n[https://www.reddit.com/r/StableDiffusion/comments/1q5k6al/fix\\_to\\_make\\_ltxv2\\_work\\_with\\_24gb\\_or\\_less\\_of\\_vram/](https://www.reddit.com/r/StableDiffusion/comments/1q5k6al/fix_to_make_ltxv2_work_with_24gb_or_less_of_vram/)",
                  "score": 1,
                  "created_utc": "2026-01-06 22:41:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny39b0x",
              "author": "Perfect-Campaign9551",
              "text": "Then let's see actual videos with a story from you soon.",
              "score": 1,
              "created_utc": "2026-01-06 22:17:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny4jba3",
                  "author": "AirwolfPL",
                  "text": "To be honest I need video gen models just for two purposes - promo stuff at work (where I've been using Veo and Sora mostly) and to animate my LEGO MOCs (I have no time nor patience to do proper stop motion animations). I was using Veo and Wan for the latter mostly. And still they are not 100% AI generated most use photos as input, static image overlay etc. None of them are \"actual videos with a story\" even if they are as long as 2 or 3 minutes, so you will get nothing like this from me, sorry.\n\nBTW Veo is hit or miss... frequently it's a miss (so it burns tokens quickly) but when it hits oh, it hits! Wan is so-so for my purposes and I couldn't generate at least 10s videos properly (I didn't tried SVI yet). Audio+Video is a killer feature for me (for LEGO videos it doesn't matter if the audio is perfect).In LTX-2 it's good enough when it comes to dialogue, however model struggles with music or singing. Wan 2.2 has non of this goodness anyway.\n\nWith current speed and quality I can add LTX-2 to my toolset replacing around 50% of Veo generations and 100% of Wan (at last!) I think.\n\nA few non-cherry picked/first-try t2v examples I just generated for this comment (720p 20-35s, 1920p 20s - although generating it took like 10 minutes and it's probably better to stick with 720p and upscale it): [https://drive.google.com/drive/folders/1aBtfBBQxSjT9X8GKf6Rvzs76hz\\_hC6Xa?usp=sharing](https://drive.google.com/drive/folders/1aBtfBBQxSjT9X8GKf6Rvzs76hz_hC6Xa?usp=sharing)\n\n**35s seems to be a limit for fp8 model on my hardware.** I tried a few 40s clips and it OOMed at me.\n\nI2V is slower than T2V but well, that is expected... And **Detailer LoRA bumps quality (alot)** but it's so slow.\n\nPS: Also I don't quite get people who state that Wan 2.2 is more flexible than LTX-2 - first of all LTX-2 was just released model and fine-tunes of Wan 2.2 and alot of LoRAs already exist. It will change quickly I suppose as LTX-2 came with LoRA training tools. Second - those who state it - did you guys actually tried to prompt it as per the official guide? It makes a lot of difference. So yeah, just like Flux replaced SDXL in a matter of weeks - same will go for Wan vs LTX-2 I guess...",
                  "score": 1,
                  "created_utc": "2026-01-07 02:16:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny33twj",
              "author": "intLeon",
              "text": "How many steps? Otherwise its a big lie that it is stable and quality is actually arse..",
              "score": 0,
              "created_utc": "2026-01-06 21:51:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny3j4e6",
                  "author": "AirwolfPL",
                  "text": "Quality is better than bare Wan 2.2 IMO. 20 steps, 241 frames. For now I didn't tried generations longer than 20 seconds. And yeah, it's very stable, model doesn't collapse and won't hallucinate (much) after 10s.",
                  "score": 1,
                  "created_utc": "2026-01-06 23:05:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny36xty",
          "author": "Choowkee",
          "text": "Oh boy here we go with these exaggerated titles about a new model.\n\nIts Hunyuan video 1.5 all over again.",
          "score": 3,
          "created_utc": "2026-01-06 22:06:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny37p49",
              "author": "WildSpeaker7315",
              "text": "hunyuan was absolutely shite. this is the semi decent Audio and visual model it can even extend videos perfectly cloning the voices",
              "score": 4,
              "created_utc": "2026-01-06 22:09:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny5df2b",
                  "author": "Justgotbannedlol",
                  "text": "example of this?",
                  "score": 1,
                  "created_utc": "2026-01-07 05:15:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny7fogk",
              "author": "juandann",
              "text": "at least this one is faster than Wan 2.2. Quality wise, need further testing",
              "score": 1,
              "created_utc": "2026-01-07 14:39:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny22b6m",
          "author": "LawrenceOfTheLabia",
          "text": "Impressed with the speech, but all of the results I‚Äôve seen so far have been really blurry/low res.",
          "score": 2,
          "created_utc": "2026-01-06 18:59:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny22wu0",
          "author": "Specialist_Pea_4711",
          "text": "can you please give me more details? Like what model did you use, your exact workflow if possible. I tried distilled fp8 on my 5090 with 64gb ram, the results are terrible, I get oom beyond 121 frames.",
          "score": 2,
          "created_utc": "2026-01-06 19:02:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2bpeu",
              "author": "dr_lm",
              "text": "Check this: https://old.reddit.com/r/StableDiffusion/comments/1q5k6al/fix_to_make_ltxv2_work_with_24gb_or_less_of_vram/",
              "score": 4,
              "created_utc": "2026-01-06 19:42:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny4rhtv",
                  "author": "Specialist_Pea_4711",
                  "text": "Okay I will try it out this one too, thanks",
                  "score": 1,
                  "created_utc": "2026-01-07 03:00:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny24b4v",
              "author": "WildSpeaker7315",
              "text": "try doing this on ur comfy launch--reserve-vram 10   , not sure if it helps but i aint tried it without it",
              "score": 3,
              "created_utc": "2026-01-06 19:08:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny26f87",
                  "author": "Specialist_Pea_4711",
                  "text": "But which model did you use in the workflow, also did you use workflow with ltx nodes or the workflow from comryui repo?",
                  "score": 1,
                  "created_utc": "2026-01-06 19:18:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny2b7rx",
                  "author": "Hunting-Succcubus",
                  "text": "50 fps mean less seconds, 30 was fine.",
                  "score": 1,
                  "created_utc": "2026-01-06 19:40:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny26034",
          "author": "FallUpJV",
          "text": "~~Gooning~~ Gollum",
          "score": 2,
          "created_utc": "2026-01-06 19:16:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2d9k4",
          "author": "wallofroy",
          "text": "Does it work with 16gb vram? Can you please share workflow?",
          "score": 2,
          "created_utc": "2026-01-06 19:49:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2dqku",
              "author": "WildSpeaker7315",
              "text": "yes it does and pleas elook through chat i've answed twice",
              "score": 2,
              "created_utc": "2026-01-06 19:51:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2gbcw",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 2,
          "created_utc": "2026-01-06 20:03:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2t9tv",
              "author": "Lucaspittol",
              "text": "Model is not chinese.",
              "score": 8,
              "created_utc": "2026-01-06 21:03:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3ddur",
          "author": "Head-Breakfast3115",
          "text": "Does it capable for NSFW? No? So I don‚Äôt care.",
          "score": 2,
          "created_utc": "2026-01-06 22:36:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny52n3y",
          "author": "StuccoGecko",
          "text": "just came here to say THANK YOU for not sharing your workflow.",
          "score": 3,
          "created_utc": "2026-01-07 04:05:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5z1jl",
              "author": "WildSpeaker7315",
              "text": "I've shared it 4 times in the chat you ape it's just the one from the setup website for the model, you can't get the model without seeing the example workflows folder. Jeez",
              "score": 2,
              "created_utc": "2026-01-07 08:12:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny22bte",
          "author": "johnfkngzoidberg",
          "text": "WAN 2.2 dead?  lol, how much is LTX 2 paying you?",
          "score": 5,
          "created_utc": "2026-01-06 18:59:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny241jq",
              "author": "WildSpeaker7315",
              "text": "mate i can render 1080p in half the time double the duration .. yes it may be censored for now...... but results speak for themselves",
              "score": 11,
              "created_utc": "2026-01-06 19:07:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny2u1xl",
                  "author": "Lucaspittol",
                  "text": "*yes it may be censored for now*\n\n  \nYes, like Flux 2 is, like Z-Image is. \n\nAnd you are correct; once people start training Loras for it, it will no longer be censored.",
                  "score": 2,
                  "created_utc": "2026-01-06 21:07:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny39e8f",
                  "author": "Perfect-Campaign9551",
                  "text": "1080p is useless if you can't have good control of the video or the audio sucks...",
                  "score": 1,
                  "created_utc": "2026-01-06 22:17:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny2m0w9",
                  "author": "FourtyMichaelMichael",
                  "text": "> yes it may be censored for now\n\nOk, Flux, Qwen, Flux2.... Let me know when that isn't the case reliably and we'll talk.",
                  "score": 1,
                  "created_utc": "2026-01-06 20:30:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny23fa3",
              "author": "ambassadortim",
              "text": "This is not the first post or comment I've read today that has said the same thing",
              "score": 3,
              "created_utc": "2026-01-06 19:04:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2bpga",
              "author": "Hunting-Succcubus",
              "text": "Not yet, but wan is not getting updates so it will die soon.",
              "score": 2,
              "created_utc": "2026-01-06 19:42:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny22zzk",
          "author": "nadhari12",
          "text": "Is it ITV or T2V only?",
          "score": 1,
          "created_utc": "2026-01-06 19:02:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny24d2s",
              "author": "WildSpeaker7315",
              "text": "both this was an i2v tho",
              "score": 8,
              "created_utc": "2026-01-06 19:08:50",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "ny4p42h",
              "author": "reeight",
              "text": "& V2V per another comment; [https://files.catbox.moe/46y2ar.mp4](https://files.catbox.moe/46y2ar.mp4)",
              "score": 3,
              "created_utc": "2026-01-07 02:47:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2asfn",
              "author": "lordpuddingcup",
              "text": "And vid extension apparently",
              "score": 1,
              "created_utc": "2026-01-06 19:38:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny262sw",
          "author": "Better-Interview-793",
          "text": "Cool, what‚Äôs the workflow for this?",
          "score": 1,
          "created_utc": "2026-01-06 19:16:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2633b",
          "author": "icchansan",
          "text": "Oh looks interesting, can u share the wf?",
          "score": 1,
          "created_utc": "2026-01-06 19:16:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2688y",
              "author": "WildSpeaker7315",
              "text": "its from the website [ComfyUI-LTXVideo/example\\_workflows/LTX-2\\_I2V\\_Full\\_wLora.json at master ¬∑ Lightricks/ComfyUI-LTXVideo](https://github.com/Lightricks/ComfyUI-LTXVideo/blob/master/example_workflows/LTX-2_I2V_Full_wLora.json)",
              "score": 4,
              "created_utc": "2026-01-06 19:17:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2762s",
          "author": "Oni8932",
          "text": "i tried but i get this error \n\nNo files matching pattern 'tokenizer.model' found under E:\\\\ComfyUI\\_windows\\_portable\\\\ComfyUI\\\\models\n\n  \ni'm using gemma 3\\_12b\\_it\\_fp8\\_e4m3fn. maybe i need the normal one of gemma?",
          "score": 1,
          "created_utc": "2026-01-06 19:21:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny28cci",
              "author": "WildSpeaker7315",
              "text": "download the entire gemma 3 into models folder, thats it\n\n[google/gemma-3-12b-it-qat-q4\\_0-unquantized at main](https://huggingface.co/google/gemma-3-12b-it-qat-q4_0-unquantized/tree/main)\n\nall them files in ur models folder, messy but works",
              "score": 4,
              "created_utc": "2026-01-06 19:27:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny3iowq",
                  "author": "martinerous",
                  "text": "Alternatively, this one is smaller and works well:\n\n[https://huggingface.co/unsloth/gemma-3-12b-it-bnb-4bit/tree/main](https://huggingface.co/unsloth/gemma-3-12b-it-bnb-4bit/tree/main)\n\nJust needs bitsandbytes installed:\n\npython -m pip install bitsandbytes\n\nWorks also with embedded.",
                  "score": 3,
                  "created_utc": "2026-01-06 23:03:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny2ejo4",
                  "author": "Oni8932",
                  "text": "thanks man! it worked! but now i have this problem when loading both ltx2 fp8 and fp4.   \nCheckpointLoaderSimple\n\n'NoneType' object has no attribute 'Params'",
                  "score": 1,
                  "created_utc": "2026-01-06 19:55:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny283hv",
          "author": "protector111",
          "text": "didnt expect this xD",
          "score": 1,
          "created_utc": "2026-01-06 19:25:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2g9lr",
          "author": "pmjm",
          "text": "Does it support start-and-end frame?",
          "score": 1,
          "created_utc": "2026-01-06 20:03:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2gdxa",
              "author": "WildSpeaker7315",
              "text": "not yet buddy maybe someone can make a custom workflow im just using 1's form thier site i aint digged into it yet",
              "score": 2,
              "created_utc": "2026-01-06 20:03:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2gw24",
          "author": "lleti",
          "text": "How'd you manage 242 frames at that speed?\n\nI can hit around 1-2mins for a 5s gen, but once I ramp up the frames it starts adding some pretty exponential time to render.\n\nCurrently getting about an 8min render time for a 720p 10s clip on a 5090 w/ 64GB DDR5, standard workflow.",
          "score": 1,
          "created_utc": "2026-01-06 20:06:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2jgd6",
          "author": "OvenGloomy",
          "text": "How you get 2 min?! i need more than 15min with a RTX5090 / 64GB, doesnt matter if FP8 or FP4",
          "score": 1,
          "created_utc": "2026-01-06 20:18:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2pc43",
          "author": "KnifeFed",
          "text": "10/10 horror short film.",
          "score": 1,
          "created_utc": "2026-01-06 20:45:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2pzn5",
          "author": "InternationalOne2449",
          "text": "12vram + 32ram maybe?",
          "score": 1,
          "created_utc": "2026-01-06 20:48:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2q8hn",
          "author": "Yokoko44",
          "text": "Can I drive this with segmentation, pose control, input videos? \n\nI'm liking WAN animate but my biggest complaint is that I can't get more than 150-180 frames at 720p even with my 5090... Tends to fry itself with anything more",
          "score": 1,
          "created_utc": "2026-01-06 20:49:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2qll1",
          "author": "xpnrt",
          "text": "wasn't even a able to pass the clip part let alone see it generate at all...",
          "score": 1,
          "created_utc": "2026-01-06 20:51:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2simr",
          "author": "wh33t",
          "text": "These things thrive and dive depending on how extensible they are.\n\nIf it's annoying or expensive to fine tune well, it's lifespan will be extremely limited.\n\nWe'll have to wait and see what the community can do with it. I'm sure KJ is on it",
          "score": 1,
          "created_utc": "2026-01-06 21:00:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2szn8",
          "author": "AaronTuplin",
          "text": "Was this fully text to video?",
          "score": 1,
          "created_utc": "2026-01-06 21:02:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2unmb",
          "author": "YourMomThinksImSexy",
          "text": "hahaha, I almost peed",
          "score": 1,
          "created_utc": "2026-01-06 21:09:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2uutj",
              "author": "WildSpeaker7315",
              "text": ":D",
              "score": 1,
              "created_utc": "2026-01-06 21:10:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2w8jg",
          "author": "Eydahn",
          "text": "Workflow?",
          "score": 1,
          "created_utc": "2026-01-06 21:16:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2wcnd",
          "author": "pm-me-underbb",
          "text": "Ffs how are you getting videos generated in less than 2 min? I have a 5070ti 16gb and 1TB of ram and still can‚Äôt get a video done faster than 25 min.",
          "score": 1,
          "created_utc": "2026-01-06 21:17:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2wiq0",
              "author": "WildSpeaker7315",
              "text": "not sure if thishelps  \nPython version: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) \\[MSC v.1940 64 bit (AMD64)\\]\n\nComfyUI version: 0.7.0\n\nComfyUI frontend version: 1.35.9\n\n\\[Prompt Server\\] web root: C:\\\\Comfyui\\\\scripts\\\\venv\\\\Lib\\\\site-packages\\\\comfyui\\_frontend\\_package\\\\static\n\nTotal VRAM 16376 MB, total RAM 64740 MB\n\npytorch version: 2.9.1+cu130\n\nxformers version: 0.0.33.post2\n\nSet vram state to: LOW\\_VRAM",
              "score": 3,
              "created_utc": "2026-01-06 21:18:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2wqk1",
          "author": "ifonze",
          "text": "Is it uncensored?",
          "score": 1,
          "created_utc": "2026-01-06 21:19:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2xojv",
              "author": "WildSpeaker7315",
              "text": "if you start with a nude image it can move, and talk, but it cant currently create nudity from text or an image of clothed person",
              "score": 1,
              "created_utc": "2026-01-06 21:23:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2xx6d",
          "author": "Myfinalform87",
          "text": "Maybe the community will finally support an ltx model üòÇ",
          "score": 1,
          "created_utc": "2026-01-06 21:24:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2ysga",
          "author": "Gombaoxo",
          "text": "I have a problem that Gemma is loading to ram forever, like 10 minutes. It never happened with other clip/text encoders",
          "score": 1,
          "created_utc": "2026-01-06 21:28:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2zutp",
              "author": "WildSpeaker7315",
              "text": "is it the .. uhh enahncer ? you can bypass it and use grok or something by uploading the prompt script from the enhancer part, mine goes straight to making thr image when i say go",
              "score": 1,
              "created_utc": "2026-01-06 21:33:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny3026h",
                  "author": "WildSpeaker7315",
                  "text": "https://preview.redd.it/ihw766nissbg1.png?width=1572&format=png&auto=webp&s=b462bd1a4d0a70ed64be1d4036a81bdac3ed2e53\n\nexample.",
                  "score": 1,
                  "created_utc": "2026-01-06 21:34:26",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny2zqe6",
          "author": "Remarkable-Funny1570",
          "text": "Can you use SVI with LTX2 ?",
          "score": 1,
          "created_utc": "2026-01-06 21:32:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny30b15",
              "author": "WildSpeaker7315",
              "text": "dont think so wait until the big brains get behind it and make new workflows  \nfrom what i can see you cant the audio is coming drectly from the checkpoint",
              "score": 3,
              "created_utc": "2026-01-06 21:35:34",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "ny3647l",
              "author": "Radyschen",
              "text": "from what I've seen around here you don't need it, I don't know how it works though. Apparently it can even replicate the voice and extend seemlessly. Don't quote me though, I've just seen the video where they extended the video of jensen huang",
              "score": 1,
              "created_utc": "2026-01-06 22:02:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny31c18",
          "author": "James_Reeb",
          "text": "What about character constancy ? Can we use our voice and trigger lipsync ?",
          "score": 1,
          "created_utc": "2026-01-06 21:40:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny31rzo",
              "author": "WildSpeaker7315",
              "text": "its been out for like 10 hours , i dont know what u can do yet but at first glance no",
              "score": 1,
              "created_utc": "2026-01-06 21:42:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3e3jh",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-06 22:40:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3ei6j",
              "author": "WildSpeaker7315",
              "text": "https://preview.redd.it/wgix2oll4tbg1.png?width=736&format=png&auto=webp&s=2c6af88e3e283244e0528a5e1907a3e3cce2754b\n\ni have done even higher its jsut reddit resolution",
              "score": 1,
              "created_utc": "2026-01-06 22:42:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3gn8n",
          "author": "gopnik_YEAS89",
          "text": "Less then two minutes? You are 100% lying here.",
          "score": 1,
          "created_utc": "2026-01-06 22:52:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3p7ms",
          "author": "LiveTradingChannel",
          "text": "And is there something to improve the audio in post?",
          "score": 1,
          "created_utc": "2026-01-06 23:36:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3ph10",
              "author": "WildSpeaker7315",
              "text": "Definitely a thought. Give it a little time though. Let's see what people can do, this is an audio and visual model that renders in 1/4 the time wan does, it's only up from here bud",
              "score": 2,
              "created_utc": "2026-01-06 23:38:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny44cxb",
          "author": "stash0606",
          "text": "10 minutes per 5 second video generation on a RTX5080 and 32GB RAM. Not bad.",
          "score": 1,
          "created_utc": "2026-01-07 00:55:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5zdk5",
              "author": "WildSpeaker7315",
              "text": "You need more ram. Bro",
              "score": 1,
              "created_utc": "2026-01-07 08:15:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny49t5r",
          "author": "rothbard_anarchist",
          "text": "Uncanny valley",
          "score": 1,
          "created_utc": "2026-01-07 01:24:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4qfc0",
          "author": "bennied1982",
          "text": "Hang on so what model IS this?",
          "score": 1,
          "created_utc": "2026-01-07 02:54:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny52wri",
          "author": "salazka",
          "text": "Yes. The voice, the motion, the rendering.",
          "score": 1,
          "created_utc": "2026-01-07 04:06:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny58woi",
          "author": "Sudden_List_2693",
          "text": "My 4090 (24GB) and 128GB gets OOM almost always.  \nEven with both gemma and model at fp8.",
          "score": 1,
          "created_utc": "2026-01-07 04:44:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5yupx",
              "author": "WildSpeaker7315",
              "text": "If you don't put \n you flag comfyu for --reserve-vram 10\n\nIt basically won't work.",
              "score": 1,
              "created_utc": "2026-01-07 08:10:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny5z5d2",
                  "author": "Sudden_List_2693",
                  "text": "I just use --novram now.  \nIt's still fast, but... the quality is very weak.  \nWhenever there's a motion slightly bigger than opening a mouth halfway, it's just a blurry... something.  I will give it some time for now, but I'm doubtful I'll be able to use it for anything.",
                  "score": 1,
                  "created_utc": "2026-01-07 08:13:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny5fhdx",
          "author": "p00rky",
          "text": "That was rude. Lmao.",
          "score": 1,
          "created_utc": "2026-01-07 05:30:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5jafr",
          "author": "Cubey42",
          "text": "I'll be honest, audio is nice but the video motion and quality isn't the best.",
          "score": 1,
          "created_utc": "2026-01-07 05:58:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5otv0",
          "author": "cardioGangGang",
          "text": "Can you do face replacements like wan though?¬†",
          "score": 1,
          "created_utc": "2026-01-07 06:43:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5yggm",
              "author": "WildSpeaker7315",
              "text": "There's workflows like wan animate yes",
              "score": 1,
              "created_utc": "2026-01-07 08:07:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nycya3k",
                  "author": "cardioGangGang",
                  "text": "Do you know where to fins them per chance?¬†",
                  "score": 1,
                  "created_utc": "2026-01-08 07:28:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny9s36k",
              "author": "Maskwi2",
              "text": "Do you have a workflow link for that? For Wan I mean. If you actually meant face replacement for video and not photo :)¬†",
              "score": 1,
              "created_utc": "2026-01-07 20:58:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny5ou8d",
          "author": "No_Writing_3179",
          "text": "Her eyes are up there ‚Üë",
          "score": 1,
          "created_utc": "2026-01-07 06:43:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5t3ua",
          "author": "Hambeggar",
          "text": "Which LTX2 model did you use? I assume the FP8?",
          "score": 1,
          "created_utc": "2026-01-07 07:19:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5ulqf",
          "author": "thatguyjames_uk",
          "text": "scary lol",
          "score": 1,
          "created_utc": "2026-01-07 07:32:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny624ot",
          "author": "b2kdaman",
          "text": "Oh shiii, I wonder how it will perform on 5080 and in 640x480 ü´†",
          "score": 1,
          "created_utc": "2026-01-07 08:41:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny62l9l",
              "author": "WildSpeaker7315",
              "text": "it will be fine the 5080 has 3x the ai power of my 4090 laptop , u just gotta have bare minimum like 32gb of ram",
              "score": 1,
              "created_utc": "2026-01-07 08:45:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny63lac",
          "author": "retrorays",
          "text": "Yah but you need a 4090..",
          "score": 1,
          "created_utc": "2026-01-07 08:54:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny641nt",
              "author": "WildSpeaker7315",
              "text": "i have the 4090 laptop version, which is desktop equivalent  of a 4070 my gpu only uses 110w its a 14 inch laptop",
              "score": 1,
              "created_utc": "2026-01-07 08:59:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny6512r",
          "author": "Darkmeme9",
          "text": "Are the gguf out yet? I only got 12gb vram and 32gb ram.",
          "score": 1,
          "created_utc": "2026-01-07 09:08:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny65f1g",
              "author": "WildSpeaker7315",
              "text": "People made it work on 8 vram",
              "score": 1,
              "created_utc": "2026-01-07 09:12:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny67adz",
                  "author": "Darkmeme9",
                  "text": "Like with the full model? Or the gguf?",
                  "score": 1,
                  "created_utc": "2026-01-07 09:29:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny6jg6x",
          "author": "xyzdist",
          "text": "code force wan to opensource? got it, WAN IS DEAD!",
          "score": 1,
          "created_utc": "2026-01-07 11:18:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6s11o",
          "author": "todschool",
          "text": "I can't run the WF in my Comfy, throws OutdatedVersion error. ComfyUI is updated, all other WFs run fine (Wan22, ZIT, etc). Anybody knows why?\n\nhttps://preview.redd.it/2pcvirzy6xbg1.jpeg?width=510&format=pjpg&auto=webp&s=2a88f6df82d8b18a63b91f1ed361a4daf4468218",
          "score": 1,
          "created_utc": "2026-01-07 12:22:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny7s1d8",
              "author": "juandann",
              "text": "try change comfyui update channel to nightly on comfyui manager",
              "score": 1,
              "created_utc": "2026-01-07 15:40:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny6z9vi",
          "author": "RobTheDude_OG",
          "text": "Anyone got video generation working on an AMD gpu?\n\nI heard on linux it works better but on windows with Wan and comfy it crashes the AMD driver",
          "score": 1,
          "created_utc": "2026-01-07 13:09:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny88khi",
          "author": "pratty041182",
          "text": "high VRAM models like WAN require careful tuning and heat/power limits on laptops can kill long runs faster than on desktops",
          "score": 1,
          "created_utc": "2026-01-07 16:54:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8tvob",
          "author": "brianmonarch",
          "text": "Does this new model have all the things that wan 2.2 had like Wan Animate and the ability to make Lora‚Äôs compatible with the video model?",
          "score": 1,
          "created_utc": "2026-01-07 18:29:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyalnbu",
          "author": "BLDSTBR",
          "text": "Lol",
          "score": 1,
          "created_utc": "2026-01-07 23:10:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydxoi6",
          "author": "DrMacabre68",
          "text": "Yeah yeah blablabla, have you truly tested ltx2 extensively? It produce garbage that does not reach 10% of wan 2.2. it's fun to use though. Can't wait to see what the community is going to come up with. But definitely not wan 2.2 killer. Just another clickbait title.\n\n![gif](giphy|YtvCIwqNJhUmA)",
          "score": 1,
          "created_utc": "2026-01-08 12:28:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nydzuq4",
              "author": "WildSpeaker7315",
              "text": "1 decent titty lora and people would be foaming at the mouth, but maybe ur right. if anything i hope it forces wan to push out 2.5 to us",
              "score": 1,
              "created_utc": "2026-01-08 12:43:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nye8q6a",
          "author": "whiteweazel21",
          "text": "Weird every YouTuber saying it sucks compared to wanü§∑‚Äç‚ôÇÔ∏è. This just a hype post, keep moving",
          "score": 1,
          "created_utc": "2026-01-08 13:35:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nye8uci",
              "author": "WildSpeaker7315",
              "text": "weird all the youtubers i watch say the opposite",
              "score": 1,
              "created_utc": "2026-01-08 13:36:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyeo4pp",
          "author": "Environmental_Ad3162",
          "text": "Yeah but if you have a 3090 its gonna be slow. Plus isn't it censored as hell.",
          "score": 1,
          "created_utc": "2026-01-08 14:54:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyexmu3",
          "author": "CRedIt2017",
          "text": "Maybe if they have the same kind of LORAs that WAN 2.2 has but until then it's just for LOLs.",
          "score": 1,
          "created_utc": "2026-01-08 15:39:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfr0mn",
          "author": "Star_Pilgrim",
          "text": "But can it do NSFW with movements you want?",
          "score": 1,
          "created_utc": "2026-01-08 17:48:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3c7hc",
          "author": "XADEBRAVO",
          "text": "Wtf is this sub",
          "score": 1,
          "created_utc": "2026-01-06 22:31:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny28coj",
          "author": "ggRezy",
          "text": "how is it that fast? i have a 5080 with 16gb vram, 32gb ram and it takes me 40 minutes for 97 frames 16fps i2v",
          "score": 1,
          "created_utc": "2026-01-06 19:27:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny28ne6",
              "author": "WildSpeaker7315",
              "text": "hmm that makes no sense, maybe your ram is capping? is it? cuz when vram or ram hits 99% it will go hella slow.",
              "score": 3,
              "created_utc": "2026-01-06 19:28:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny2fkvk",
                  "author": "Keem773",
                  "text": "Is there a trick to stop the VRAM from capping and slowing it down like crazy?",
                  "score": 1,
                  "created_utc": "2026-01-06 20:00:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2awy8",
              "author": "lordpuddingcup",
              "text": "That‚Äôs an issue on your side I think that sounds like your writing to swap file use a quant",
              "score": 2,
              "created_utc": "2026-01-06 19:38:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2dk7s",
                  "author": "ggRezy",
                  "text": "ok‚Ä¶ i have no idea what this means im sorry. do you need more details so you can help me further",
                  "score": 1,
                  "created_utc": "2026-01-06 19:50:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2chvp",
              "author": "Hunting-Succcubus",
              "text": "Check bus interface load. If its more than 10% ram swap is happening.",
              "score": 2,
              "created_utc": "2026-01-06 19:45:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2k778",
              "author": "Fun-Photo-4505",
              "text": "Some people are getting videos in 6 seconds, so yeah something missing with your workflow.",
              "score": 1,
              "created_utc": "2026-01-06 20:21:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny3jwrp",
              "author": "martinerous",
              "text": "10 seconds of non-upscaled (disabled Sampler stage 2) 1376 x 768 video generated in 360 seconds on a power-limited 3090. Using the distilled FP8 weights.\n\nYeah, open Task Manager, Performance and check if there is high disk activity - then it's swapping to disk because not enough RAM. 32GB can be not enough for LTX.\n\nAlso, check if CPU is not in high use - then it will be slow too, happened for me with the default Gemma model, and I replaced it with Unsloth 4bit quants.",
              "score": 1,
              "created_utc": "2026-01-06 23:09:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny30tg8",
          "author": "Hearcharted",
          "text": "![gif](giphy|YGrvMQnLuDF98ZRsqs)",
          "score": 1,
          "created_utc": "2026-01-06 21:37:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3r2pl",
          "author": "superstarbootlegs",
          "text": "week 1: hype train engaged \"insane\" and \"wan killer\" will be bandied about.\n\nweek 2: reality begins to set in",
          "score": 1,
          "created_utc": "2026-01-06 23:46:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3zmw5",
          "author": "Geekygamertag",
          "text": "The voice acting is terrible. I can hear the difference an that dumb walk she did was hilarious. Ai doesn‚Äôt fully understand how us humans move",
          "score": 1,
          "created_utc": "2026-01-07 00:30:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4ea9h",
          "author": "Novel-Mechanic3448",
          "text": "Looks terrible though lol",
          "score": 0,
          "created_utc": "2026-01-07 01:49:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8ve70",
          "author": "PlantainDry5705",
          "text": "As the guy below said porn damn fuel innovation",
          "score": 0,
          "created_utc": "2026-01-07 18:35:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3mpbj",
          "author": "Born_Arm_6187",
          "text": "ltx is jew technology, no thanks",
          "score": -6,
          "created_utc": "2026-01-06 23:23:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny20ken",
          "author": "Secure-Message-8378",
          "text": "At least!",
          "score": -1,
          "created_utc": "2026-01-06 18:51:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny375us",
          "author": "Perfect-Campaign9551",
          "text": "\"Is dead\" LOL no",
          "score": -1,
          "created_utc": "2026-01-06 22:07:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5fj1d",
          "author": "adesantalighieri",
          "text": "And?",
          "score": -1,
          "created_utc": "2026-01-07 05:30:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5lanf",
          "author": "Dry_Positive8572",
          "text": "As of Jan. 7th, 2026 ComfyUI core V0.5.1 does not  support LTX-2 and I am not gonna install nightly version of it to make this work.",
          "score": -1,
          "created_utc": "2026-01-07 06:14:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny62jqs",
          "author": "smereces",
          "text": "Dead! LTX I2V is light years from what Wan 2.2 can delivery! try to use LTX 2.0 with no liniar images realistic girls or other things! and try it using fantasy characters or other kind stuff less normal and see the results you get ;) unfortuanlly",
          "score": -1,
          "created_utc": "2026-01-07 08:45:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny63dwn",
              "author": "WildSpeaker7315",
              "text": "give me an idea of what youu wanna see and i'll try do, all my content is nsfw unless someone else thinks for me (joking) but we all have different likes",
              "score": 1,
              "created_utc": "2026-01-07 08:52:54",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "ny631hx",
              "author": "WildSpeaker7315",
              "text": "its better with with fantasy characters? honestly you can feed this an nsfw hentai image and add voices and movement, what more do you actually want, this is local, WAN 2.2 is great but very limited, adding anytype of audio and having 1/4 the render time is a huge win, my guy i rendered a 2560x1440p video TEXT to video  10 seconds in like 7 minutes, What the hell?! \n\nhttps://preview.redd.it/l0l6frwz4wbg1.png?width=736&format=png&auto=webp&s=1593b68f2e6eaacf6a2a51388fa0f7c779db6ec4",
              "score": 1,
              "created_utc": "2026-01-07 08:49:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q6m285",
      "title": "LTX is actualy insane (music is added in post but rest is all LTX2 i2V)",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/iz4qft73sybg1",
      "author": "protector111",
      "created_utc": "2026-01-07 17:43:37",
      "score": 1162,
      "num_comments": 193,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q6m285/ltx_is_actualy_insane_music_is_added_in_post_but/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny8xgt3",
          "author": "ThenExtension9196",
          "text": "For those that come after (81 frames).",
          "score": 118,
          "created_utc": "2026-01-07 18:44:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8ywnv",
              "author": "protector111",
              "text": "xD",
              "score": 10,
              "created_utc": "2026-01-07 18:51:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny8ramt",
          "author": "Trails_End_Games",
          "text": "I just realized YouTube poop can make a full comeback. Bigger and better than ever.",
          "score": 48,
          "created_utc": "2026-01-07 18:18:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nya7go4",
              "author": "elliebellyberry",
              "text": "its not the same\n\naudio splicing must prevail",
              "score": 20,
              "created_utc": "2026-01-07 22:04:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nybpw6t",
                  "author": "Iggyhopper",
                  "text": "Audio and video splicing is a must for ytp.",
                  "score": 7,
                  "created_utc": "2026-01-08 02:37:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny8s1s8",
              "author": "protector111",
              "text": "i think it dosnt need a comeback. there plenty of poop out there xD",
              "score": 17,
              "created_utc": "2026-01-07 18:21:22",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nyau9qi",
              "author": "Betancorea",
              "text": "Oh man that just got me imagining what Manslayer would achieve with AI and his Gamer Poop series lol",
              "score": 3,
              "created_utc": "2026-01-07 23:53:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyd9vex",
              "author": "Lucky-Necessary-8382",
              "text": "I would not trust to run a israeli company model on my machine. Some next level shit must be hidden in it from mossad",
              "score": 4,
              "created_utc": "2026-01-08 09:12:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny8rzms",
          "author": "Extra-Fig-7425",
          "text": "I hope someone make the \"secret episode\" of strange things with this lol",
          "score": 76,
          "created_utc": "2026-01-07 18:21:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nya86up",
              "author": "sivadneb",
              "text": "Or fix Game of Thrones season 8",
              "score": 53,
              "created_utc": "2026-01-07 22:07:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyawri0",
                  "author": "fractalcrust",
                  "text": "i dun want it",
                  "score": 7,
                  "created_utc": "2026-01-08 00:06:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny8sx51",
              "author": "protector111",
              "text": "that would be easy if we had actaul wf that can clone the voices. the model is capable of it",
              "score": 9,
              "created_utc": "2026-01-07 18:25:08",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "ny9lqj6",
              "author": "FourtyMichaelMichael",
              "text": "It's a LOT easier to just admit the writing for the show was bad and didn't make a lot of sense.",
              "score": 9,
              "created_utc": "2026-01-07 20:30:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny8y7ek",
          "author": "ThenExtension9196",
          "text": "Imagine playing a game that dynamically generates cutscenes/character dialogue based on your actions in the game. Dialogue generated by LLMs anchored by character profiles and game history. Buckle up folks.",
          "score": 109,
          "created_utc": "2026-01-07 18:48:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8yv61",
              "author": "protector111",
              "text": "yeah i wonder when this will happen. real Interaction with ai agent npcs",
              "score": 30,
              "created_utc": "2026-01-07 18:50:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny9e9n4",
                  "author": "Arawski99",
                  "text": "There are already mods for GTA V, the Unreal Engine 5 matrix demo, etc. plus Nvidia's ACE or whatever that do this. I think some of the GTA V ones got removed, but maybe they're back up again. You can find YouTube examples. they use LLMs to generate full dynamic conversations with any random NPC.\n\nNvidia's ACE was pretty amazing last i Looked, along with some other companies similar software involving audio, knowledge states/history, ability to understand and interact with the world to execute actions, etc. However, still rather rough around the edges and not always the most... realistic.\n\nNvidia has a lot of really cool neural rendering tech now, too, like for hyper realistic (uncanny atm tho) faces, neural shaders, and more.\n\nI'm just wondering which will become mainstream first. Ai based basic LLMs, rendering, and other tech or world generative tech.",
                  "score": 8,
                  "created_utc": "2026-01-07 19:57:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny8zb24",
                  "author": "ThenExtension9196",
                  "text": "5 years I think. It‚Äôll start slow, catch on, and everyone will implement in a rush.",
                  "score": 26,
                  "created_utc": "2026-01-07 18:52:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyd8kq9",
                  "author": "Icy_Concentrate9182",
                  "text": "I suggested this on a gaming subreddit. \nGot downvoted to oblivion",
                  "score": 3,
                  "created_utc": "2026-01-08 09:00:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nybofi9",
                  "author": "ImmoralityPet",
                  "text": "It'll happen as soon as everyone has a dedicated AI card in their computer in addition to their graphics card.",
                  "score": 1,
                  "created_utc": "2026-01-08 02:29:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nybanc5",
              "author": "darkkite",
              "text": "for some reason every time i bring up the possibly of future games not having repeated dialog with the help of ai i get downvoted for like ai slop. \n\nbut i know that when the first game create an ai-based radiant quest system that remembers previous actions and current world state, it will be a paradigm shift for those types of games",
              "score": 14,
              "created_utc": "2026-01-08 01:16:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nycg7l8",
                  "author": "eckstuhc",
                  "text": "I‚Äôve been thinking about this nonstop and which I knew fuckin anything about game development lol. It will happen first with like ‚Äúchoose your own adventures‚Äù or graphic novel type games. Will definitely be the future of gaming. Even if the story stays linear, imagine NPCs or your protagonist/antagonist as an AI agent. That‚Äôs wild.",
                  "score": 3,
                  "created_utc": "2026-01-08 05:10:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyc6q58",
                  "author": "ThenExtension9196",
                  "text": "It‚Äôs always how technology goes. People hate it until they love it and then there‚Äôs no going back.",
                  "score": 3,
                  "created_utc": "2026-01-08 04:10:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyc5dms",
                  "author": "sonicnerd14",
                  "text": "Right now is easy for people to hate on anything AI because the big companies like Microsoft, Nvidia, are putting out low effort products. Although despite what people might think the future is going in this sitcom regardless. The best we can hope for is that there are occasional great products outside of the slop.",
                  "score": 1,
                  "created_utc": "2026-01-08 04:02:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nydj4qb",
                  "author": "HazelCheese",
                  "text": "People don't actually want to play a game where they think the people they are killing have feelings.\n\nLikewise does someone want to play Mass Effect or Cyberpunk if the NPCs you try to romance say \"I only see you as a friend\".\n\nThe problem with AI in games is finding that middle ground of keeping things gamified. Otherwise it's going to be like the [USS Calister](https://en.wikipedia.org/wiki/USS_Callister).",
                  "score": 0,
                  "created_utc": "2026-01-08 10:36:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nybux6o",
              "author": "rchive",
              "text": "It could start in text games or visual novels right now.",
              "score": 5,
              "created_utc": "2026-01-08 03:03:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny9n17y",
              "author": "Individual_Holiday_9",
              "text": "Yeah this is totally where radiant quests are going to go. I bet we see it in the next elder scrolls / assassins creed / fallout.",
              "score": 4,
              "created_utc": "2026-01-07 20:36:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny9unfj",
              "author": "johnfkngzoidberg",
              "text": "You think your FPS sucks now, just wait.  AAA games are already recycled least effort rubbish. Wait til cut scenes are only a text prompt and 60s of generation time on a 8B model.",
              "score": 7,
              "created_utc": "2026-01-07 21:08:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyaaysi",
                  "author": "ThenExtension9196",
                  "text": "I dunno, who knows maybe dual gpu will catch on. One for rendering and one dedicated for ai functions.",
                  "score": 3,
                  "created_utc": "2026-01-07 22:19:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyc4nam",
              "author": "hyperdynesystems",
              "text": "The thing people are struggling with right now is making it matter, you can do this pretty easily but the LLM just spits out stuff with no basis in the game world. \n\nI've mostly solved this (in an insanely cool way) in my own game which will heavily feature dynamic NPC dialogue/quests etc, but I'd say most people experimenting with it haven't, especially in the AAA and AA space, since they want to ultimately control the exact flow of the game world and what happens in it to a degree that I intentionally don't have to care about with my game.\n\nThis has definitely been a dream since the first time I sat at an Apple IIe and played a text adventure RPG as a wee lad, and then of course later playing PC CRPGs and tabletop RPGs.",
              "score": 2,
              "created_utc": "2026-01-08 03:57:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyd4dgp",
              "author": "LightPillar",
              "text": "Imagine Heavy Rain or Detroit Become Human like that. Those games would suddenly become 10x better.",
              "score": 2,
              "created_utc": "2026-01-08 08:22:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyfuksc",
                  "author": "ThenExtension9196",
                  "text": "Oh man those would be perfect",
                  "score": 2,
                  "created_utc": "2026-01-08 18:03:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyackxl",
              "author": "dudeAwEsome101",
              "text": "Nvidia DLSS 7 will be lit!",
              "score": 1,
              "created_utc": "2026-01-07 22:27:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyb9by5",
              "author": "karterbr",
              "text": "The Moonlight Sculptor",
              "score": 1,
              "created_utc": "2026-01-08 01:09:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nydcie7",
              "author": "philmarcracken",
              "text": "They can't trust the client. People will call themselves all kinds of racist and sexist shit, their clans or groups that, just to prompt inject it. They remember what they did with microsoft Tay lol",
              "score": 1,
              "created_utc": "2026-01-08 09:36:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyfugy4",
                  "author": "ThenExtension9196",
                  "text": "I dunno at some point the jail breaking ai thing will become old news. It‚Äôs already getting played out.",
                  "score": 1,
                  "created_utc": "2026-01-08 18:03:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyek6wx",
              "author": "BuckleUpKids",
              "text": "Kick that up a notch. Games don't need to be rendered at high polys or textures anymore. Just let AI fill in the blanks and create hyperrealism.",
              "score": 1,
              "created_utc": "2026-01-08 14:35:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyvpv3b",
              "author": "angrypikok",
              "text": "The tech is already there, it's called reality. Worst part is you only have one life and no saves, but the choices really do matter and there are infinite story paths.",
              "score": 1,
              "created_utc": "2026-01-11 00:08:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyvsavj",
                  "author": "ThenExtension9196",
                  "text": "Apples and oranges bro.",
                  "score": 1,
                  "created_utc": "2026-01-11 00:21:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny8qz59",
          "author": "Svedorovski",
          "text": "Wow, it already looks on par with the shitty facial movement from modern AAA studios.",
          "score": 65,
          "created_utc": "2026-01-07 18:16:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyfmpfw",
              "author": "JMpickles",
              "text": "Bethesda reading this üëÄ",
              "score": 1,
              "created_utc": "2026-01-08 17:29:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny8kbk4",
          "author": "Jaded_Inflation_9213",
          "text": "Amazing! ü§£",
          "score": 43,
          "created_utc": "2026-01-07 17:47:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8kmrp",
              "author": "protector111",
              "text": "its crazy this is open source and can be ran on 4090",
              "score": 40,
              "created_utc": "2026-01-07 17:49:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny8va50",
                  "author": "Yasstronaut",
                  "text": "Can you share your workflow / which models? I‚Äôm\non 4090 with 128gb and still having issues where it takes 18 mins for 5s at 768x768",
                  "score": 24,
                  "created_utc": "2026-01-07 18:35:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny8ofqz",
                  "author": "Practical-Elk-1579",
                  "text": "Are you using it on comfyui ?",
                  "score": 4,
                  "created_utc": "2026-01-07 18:05:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny8vzc3",
                  "author": "M4xs0n",
                  "text": "How much VRAM? I am using a 4080 super",
                  "score": 2,
                  "created_utc": "2026-01-07 18:38:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyc65pc",
                  "author": "t-e-r-m-i-n-u-s-",
                  "text": "you can train on 13G now too: [https://github.com/bghira/SimpleTuner/blob/main/documentation/quickstart/LTXVIDEO2.md](https://github.com/bghira/SimpleTuner/blob/main/documentation/quickstart/LTXVIDEO2.md)",
                  "score": 2,
                  "created_utc": "2026-01-08 04:06:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny8pdrp",
          "author": "Noeyiax",
          "text": "Holy E33 damn, nice work...for the tts audio, if you do supply audio too for the people, what did you prompt? I struggle with more than 2 people in the same scene",
          "score": 17,
          "created_utc": "2026-01-07 18:09:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8ppa0",
              "author": "protector111",
              "text": "\"man is very emotional sad in tears. he says almost whispering \"please...i will sel a kidney\"\"  all of those cuts are separate renders of 720p 121 frames put together in editing",
              "score": 20,
              "created_utc": "2026-01-07 18:11:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny8pzr2",
                  "author": "Noeyiax",
                  "text": "Ahh ok, damn good editing skills too then , ty! Make more lol üòÜ",
                  "score": 12,
                  "created_utc": "2026-01-07 18:12:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nya3wv9",
                  "author": "onthemove31",
                  "text": "this is brilliant work! :D",
                  "score": 2,
                  "created_utc": "2026-01-07 21:48:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyqdk0l",
                  "author": "NewTelephone114",
                  "text": "what did you use to add the audio?",
                  "score": 2,
                  "created_utc": "2026-01-10 04:30:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyewf8h",
                  "author": "Coach_Unable",
                  "text": "How did you maintain the same audio for different generations ? all the workflows I saw never had anoptions to \"supply\" sound, just the text prompt",
                  "score": 1,
                  "created_utc": "2026-01-08 15:33:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny9gq0r",
          "author": "Radyschen",
          "text": "this goes to show how much of a difference music makes",
          "score": 8,
          "created_utc": "2026-01-07 20:08:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycr8b9",
              "author": "protector111",
              "text": "music does A TON. music is super important in movies and games for a reason. it creates mood.  but even without it female voice is very emotional and good.",
              "score": 5,
              "created_utc": "2026-01-08 06:30:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny9r6t9",
          "author": "Radiant-Photograph46",
          "text": "The problem is how everything looks so... exaggerated. Like motion is amplified just too much to make it uncanny. This is also why it struggles with maintaining facial likeness.",
          "score": 6,
          "created_utc": "2026-01-07 20:54:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycrl9w",
              "author": "protector111",
              "text": "true. but it does make it consistent with video game screens. i tryued with real photos and results are not as exadurated but still not perfect obviously. but we are getting there with ridiculos speed of improvenment.\n\nhttps://i.redd.it/meijpwtfl2cg1.gif",
              "score": 4,
              "created_utc": "2026-01-08 06:33:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny95x9f",
          "author": "BackgroundMeeting857",
          "text": "Damn as a 32gb ram'er this hits hard. I did get the model work though, my ol 3060 still has some fight left in er. Honestly if some optimization help me keep the models in ram this model will be like the Z of video, the actual gen speed is like just under 2 min per 6 sec on it.",
          "score": 6,
          "created_utc": "2026-01-07 19:21:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyakbpd",
          "author": "SandCheezy",
          "text": "Don‚Äôt worry yall, no spoilers in this clip so please stop reporting it. The model used and joke fits this sub.\n\nOP, thanks for the chuckle. I am almost at 100% achievements for e33. So it was a nice surprise to see it right now in some hilariously sad reality.",
          "score": 7,
          "created_utc": "2026-01-07 23:03:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyam5ow",
              "author": "SandCheezy",
              "text": "https://preview.redd.it/6t0yf5aze0cg1.jpeg?width=1577&format=pjpg&auto=webp&s=e9cf078901377fa0a029b63af2353826b0f6799f",
              "score": 3,
              "created_utc": "2026-01-07 23:12:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nycqvse",
              "author": "protector111",
              "text": "I love the game. probably should have said it has no spoilers. my bad. But ppl reporting it before wathing is weird xD  or do they think that actually happened in the game and thats the spoiler?",
              "score": 2,
              "created_utc": "2026-01-08 06:27:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny8znsw",
          "author": "queenkasa",
          "text": "mouths move too much",
          "score": 11,
          "created_utc": "2026-01-07 18:54:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyc12dy",
          "author": "Bbmin7b5",
          "text": "t2v works fine but i2v kill my vram. 64G and 5090 still aren't enough. comfy just crashes hard",
          "score": 5,
          "created_utc": "2026-01-08 03:37:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycodwh",
              "author": "protector111",
              "text": "I2v much more vram demanding that i2v . Make sure your pagefile is around 128 gb and try again",
              "score": 5,
              "created_utc": "2026-01-08 06:08:17",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nyhv4sz",
              "author": "iRainbowsaur",
              "text": "??? Why is image to video that more demanding?",
              "score": 1,
              "created_utc": "2026-01-08 23:28:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nykckt3",
              "author": "muskillo",
              "text": "WAN2GP on LTX2 Distilled in Pimokio works perfectly. With an RTX 4090, I've recorded 20-second 720p videos in a single 3-minute video without any issues, and 10-second 1080p videos without a single memory problem. I don't understand why people keep going around in circles with ComfyUI and its problems.",
              "score": 1,
              "created_utc": "2026-01-09 08:52:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny8krwm",
          "author": "One-Thought-284",
          "text": "Haha genuinely don't love the endless memes but this one was incredibly well done haha nice",
          "score": 4,
          "created_utc": "2026-01-07 17:49:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8m04b",
              "author": "Toclick",
              "text": "Indeed",
              "score": 3,
              "created_utc": "2026-01-07 17:55:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny8lcab",
              "author": "protector111",
              "text": "every time u see a meme made with LTX - were getting 1 step closer to open source wan 3.0 so bare with us xD",
              "score": 5,
              "created_utc": "2026-01-07 17:52:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyalakq",
                  "author": "SandCheezy",
                  "text": "For those that come after‚Ä¶",
                  "score": 3,
                  "created_utc": "2026-01-07 23:08:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny8s0d2",
          "author": "Slapper42069",
          "text": "I've seen a lot of people saying i2v suck i mean require some skills. Mind sharing some info? Workflow?",
          "score": 2,
          "created_utc": "2026-01-07 18:21:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8srot",
              "author": "protector111",
              "text": "im just using default one from custom nodes example folder. didnt change anything. wide screen images tend to be better than vertical",
              "score": 7,
              "created_utc": "2026-01-07 18:24:29",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nya44zr",
              "author": "FxManiac01",
              "text": "I copy that.. today I was not able to get anything good from i2v :D but what OP did is great.. so error is between screen and chair..",
              "score": 6,
              "created_utc": "2026-01-07 21:49:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny92i4p",
          "author": "mobileposter",
          "text": "This is amazing work üòÇ",
          "score": 2,
          "created_utc": "2026-01-07 19:06:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9awxd",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 2,
          "created_utc": "2026-01-07 19:43:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny9bac6",
              "author": "protector111",
              "text": "I hate spoilers and loved the game. None here at all. Absolutely safe to watch. It only has the faces u already seen",
              "score": 2,
              "created_utc": "2026-01-07 19:45:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny9tu2u",
          "author": "MathematicianLessRGB",
          "text": "Worst version of the technology btw....goddamn man! Awesome stuff.",
          "score": 2,
          "created_utc": "2026-01-07 21:05:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nya4guh",
          "author": "FxManiac01",
          "text": "where did u get still images? Are they generated or is it from some game video and just cropped and used? because character consistency is superb..",
          "score": 2,
          "created_utc": "2026-01-07 21:51:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycr1vo",
              "author": "protector111",
              "text": "its img 2 video with screenshots from a game Expedition 33.",
              "score": 2,
              "created_utc": "2026-01-08 06:28:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyadifv",
          "author": "Vynxe_Vainglory",
          "text": "It definitely shines when you stop trying to make it look real.",
          "score": 2,
          "created_utc": "2026-01-07 22:31:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycqyzm",
              "author": "protector111",
              "text": "https://i.redd.it/cfsxqlymk2cg1.gif\n\nreal is also amazing",
              "score": 2,
              "created_utc": "2026-01-08 06:28:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyahlps",
          "author": "mitchins-au",
          "text": "I‚Äôm still stuck trying to get it to load Gemma3. I downloaded the FP8 tensors and even added the config files from googles own repo but it‚Äôs complaining about it. Is there som secret here? I get both layer complaints but also it complains about the config files missing too",
          "score": 2,
          "created_utc": "2026-01-07 22:50:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyajtam",
          "author": "Perfect-Campaign9551",
          "text": "Damnit the man's voice sucks so bad",
          "score": 2,
          "created_utc": "2026-01-07 23:01:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyaq11z",
          "author": "mugen7812",
          "text": "What settings to i need for i2v? getting mixed results, sometimes works, sometimes fails miserably",
          "score": 2,
          "created_utc": "2026-01-07 23:32:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyaul1s",
          "author": "alexmmgjkkl",
          "text": "ü§£ü§£ü§£",
          "score": 2,
          "created_utc": "2026-01-07 23:55:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nybebg9",
          "author": "arcamaeus",
          "text": "It's actually really fun to watch!",
          "score": 2,
          "created_utc": "2026-01-08 01:36:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nybelfs",
          "author": "Healthy-Win440",
          "text": "Amazing.. have these camera cuts done in the same prompt?!!",
          "score": 2,
          "created_utc": "2026-01-08 01:37:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycp03a",
              "author": "protector111",
              "text": "No. Every cut is separate prompt",
              "score": 2,
              "created_utc": "2026-01-08 06:12:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nybs63p",
          "author": "MrWeirdoFace",
          "text": "I've actually been quite a bit disappointed with the results I'm getting on my 3090 at 720p. I'm using the default image to video workflow from comfy UI and only swapping out the clip model to FP8. Is there some setting I can crank up which will improve the quality of the video?",
          "score": 2,
          "created_utc": "2026-01-08 02:49:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycqipm",
              "author": "protector111",
              "text": "\\--reserve-vram 4",
              "score": 1,
              "created_utc": "2026-01-08 06:24:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nycv0u7",
                  "author": "MrWeirdoFace",
                  "text": "How would that change quality? For the record I'm using --novram for the moment to avoid a clip error with the fp8 model.",
                  "score": 0,
                  "created_utc": "2026-01-08 07:00:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nybwupl",
          "author": "BitterFortuneCookie",
          "text": "In November, God laid a hand on my shoulder and whispered ‚Äúyou should double your RAM‚Äù. Thank God I listened.",
          "score": 2,
          "created_utc": "2026-01-08 03:13:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycooh1",
              "author": "protector111",
              "text": "I wish i bought 128 but thank god i build new pc with 96 ddr5 2 weeks before ramapocalips",
              "score": 2,
              "created_utc": "2026-01-08 06:10:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyd4w5x",
                  "author": "LightPillar",
                  "text": "same, as soon as prices go down (lol) Im picking up another 96gb. Yes I know it will drop me down to 4000-4500MTs from 6000MTs but I can take the fps hit when I game. So what if I go from 280fps down to 260fps.",
                  "score": 2,
                  "created_utc": "2026-01-08 08:26:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nybxi94",
          "author": "boisheep",
          "text": "I just get bad results :c\n\nHave you tried fluffy and cute animals?... I am getting a lot of static results where LTX1 used to give me something at least.\n\nI feel like I am hitting a censorship wall or something, it is just, very odd... I put a furry head that used to work with LTX1 and now with 2, static... it won't move.\n\nwhen I thought I could make it talk, nope...",
          "score": 2,
          "created_utc": "2026-01-08 03:17:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycok4s",
              "author": "protector111",
              "text": "A lot of ppl have bad reaults with i2v . I made 1 img with toples woman jumping and it did great so i dint think its censorship",
              "score": 2,
              "created_utc": "2026-01-08 06:09:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyc7c7x",
          "author": "Easy_Paint_4289",
          "text": "This is already better than most AAA games cutscenes",
          "score": 2,
          "created_utc": "2026-01-08 04:13:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydfqu0",
          "author": "External_Trainer_213",
          "text": "Is this workflow using the ltx-2 upscaler lora?",
          "score": 2,
          "created_utc": "2026-01-08 10:06:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydumq8",
          "author": "Rohan_Guy",
          "text": "This is why RAM prices are high.",
          "score": 2,
          "created_utc": "2026-01-08 12:07:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyf5nwi",
          "author": "juandann",
          "text": "the camera change, is it also done in single generation?\n\nedit: nvm, found your comment about separate renders",
          "score": 2,
          "created_utc": "2026-01-08 16:15:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nya0vn9",
          "author": "Fake_William_Shatner",
          "text": "We now have the technology to take jobs from overly dramatic theater arts majors.¬†",
          "score": 4,
          "created_utc": "2026-01-07 21:35:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8oolj",
          "author": "RoyalCities",
          "text": "Okay so they definitely used gaming cutscenes for their dataset. And a TON of tts models because I can practically hear some of the presets lol.",
          "score": 5,
          "created_utc": "2026-01-07 18:06:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8ovgl",
              "author": "protector111",
              "text": "those are screnshots form Expedition 33 put throug i2v",
              "score": 19,
              "created_utc": "2026-01-07 18:07:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny8qb90",
                  "author": "RoyalCities",
                  "text": "Yeah but it's so fluid that it points to it seeing the actual cutscenes - hence the fidelity.\n\nI've seen other i2v outputs with OC and more obscure things and the results are simply not as good.\n\nDon't get me wrong. Still an amazing model - esp for open source but any model will perform better with adjacent content within its training data.",
                  "score": 0,
                  "created_utc": "2026-01-07 18:13:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny8xttn",
              "author": "ThenExtension9196",
              "text": "Of course synthetic data is used that‚Äôs always been part of the dataset. You‚Äôd be dumb not to use it. Comma ai does self driving models using gta5 video for example.",
              "score": 2,
              "created_utc": "2026-01-07 18:46:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny8lqwm",
          "author": "theNivda",
          "text": "Insane ü§Ø",
          "score": 3,
          "created_utc": "2026-01-07 17:54:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8o2y3",
          "author": "ill_B_In_MyBunk",
          "text": "But can this level of quality be achieved with lower VRAM workflows? I've seen some come out but nowhere near this fidelity. Asking from a 12gb pleb ü´†.",
          "score": 2,
          "created_utc": "2026-01-07 18:04:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8p6um",
              "author": "protector111",
              "text": "no idead. probably yes just gonna be slow. by the way thats just 720p and i can render 2560x on 5090",
              "score": 5,
              "created_utc": "2026-01-07 18:08:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny8poby",
                  "author": "Working_Sundae",
                  "text": "Is it full precision? What are the ram requirements to run the full model?",
                  "score": 2,
                  "created_utc": "2026-01-07 18:11:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny904s9",
          "author": "cerberus8700",
          "text": "Can this run on my laptop rtx 5080?",
          "score": 2,
          "created_utc": "2026-01-07 18:56:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny92wgw",
              "author": "protector111",
              "text": "no idea.",
              "score": 3,
              "created_utc": "2026-01-07 19:08:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny8lz3q",
          "author": "WildSpeaker7315",
          "text": "and people agued when i said wan 2.2 was dead, good job on this 1",
          "score": 2,
          "created_utc": "2026-01-07 17:55:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8wkrg",
              "author": "physalisx",
              "text": "of course they argue, because that statement is utter nonsense",
              "score": 20,
              "created_utc": "2026-01-07 18:40:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny8p1c9",
              "author": "kemb0",
              "text": "I mean it's only dead if this surpasses Wan in every way. If there are use cases for Wan then it's not dead and there are use cases. Let's be real, LTX can not do squeezing titties....well until the Loras come....",
              "score": 13,
              "created_utc": "2026-01-07 18:08:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny8rwqb",
                  "author": "WildSpeaker7315",
                  "text": "z image couldnt do shit the first few days either",
                  "score": 0,
                  "created_utc": "2026-01-07 18:20:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny8mff7",
              "author": "protector111",
              "text": "yeah its dead. it can resurect with open source wan 3.0 who knows. one can dream",
              "score": 0,
              "created_utc": "2026-01-07 17:56:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nye7vxb",
          "author": "bensummersx",
          "text": "LTX2 really takes things to another level, blending creativity and technology in a way that feels almost magical.",
          "score": 1,
          "created_utc": "2026-01-08 13:30:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nye9oap",
              "author": "protector111",
              "text": "And it runs in consumer gpu which is hard to belive",
              "score": 2,
              "created_utc": "2026-01-08 13:40:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyeej6e",
          "author": "Immolation_E",
          "text": "This goes to show why Charlie Cox and Kirsty Ryder aren't out of jobs, yet.",
          "score": 1,
          "created_utc": "2026-01-08 14:06:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyf1dea",
              "author": "protector111",
              "text": "Good voice actors will probably still retain their jobs for a very long time. ai is nowhere near real human emotion with audio but it is getting better. But for comercials and ads - already good enougth",
              "score": 1,
              "created_utc": "2026-01-08 15:55:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nykb6v5",
                  "author": "alexmmgjkkl",
                  "text": "nahh there are much better voice models ..you can provide your own audio i think",
                  "score": 1,
                  "created_utc": "2026-01-09 08:40:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyfr7dw",
          "author": "Odd_Introduction_280",
          "text": "time to make poor mmorpg ads with bunch of battle angel",
          "score": 1,
          "created_utc": "2026-01-08 17:49:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyj8mbr",
          "author": "DanzeluS",
          "text": "Is it one prompt one generation? As I understand it, a few of the i2v",
          "score": 1,
          "created_utc": "2026-01-09 03:50:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyjq3rw",
              "author": "protector111",
              "text": "Every cut is a separate prompt",
              "score": 2,
              "created_utc": "2026-01-09 05:42:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyk9uvg",
          "author": "alexmmgjkkl",
          "text": "friends always laughed at me when i bought more ram than neccessary. now i have 64GB luckily",
          "score": 1,
          "created_utc": "2026-01-09 08:28:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nykdl2z",
          "author": "muskillo",
          "text": "LTX2 distilled on WAN2GP on Pimokio works perfectly. With an RTX 4090, I've created 20-second 720p videos without any problems in a single video, and it took less than 3 minutes. I've also created 10-second 1080p videos without a single memory issue. I don't understand why people keep going around in circles with ComfyUI and its problems.",
          "score": 1,
          "created_utc": "2026-01-09 09:01:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nym9reu",
          "author": "rayfreeman1",
          "text": "Looks pretty good! Think you can push it to the limit?",
          "score": 1,
          "created_utc": "2026-01-09 16:13:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nysxnmy",
          "author": "Fantasma258",
          "text": "Can you share de model link, please?",
          "score": 1,
          "created_utc": "2026-01-10 15:56:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyam45e",
          "author": "ImNotARobotFOSHO",
          "text": "Haven‚Äôt played the game, context needed. What‚Äôs the starting point?",
          "score": 1,
          "created_utc": "2026-01-07 23:12:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycqkz3",
              "author": "protector111",
              "text": "COntext is LTX 2 need tons of VRAM and / or RAM.  that all the context you need. the characters could be from any game",
              "score": 3,
              "created_utc": "2026-01-08 06:25:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyd1scc",
          "author": "aCaffeinatedMind",
          "text": "This is slop.",
          "score": -4,
          "created_utc": "2026-01-08 07:58:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nydaelx",
              "author": "protector111",
              "text": "true. it is slop. made it in 20 minutes. But i never pretended it wasnt. THat is jsut testing the new model.",
              "score": 4,
              "created_utc": "2026-01-08 09:17:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny8rn1o",
          "author": "Iq1pl",
          "text": "Slop of the year btw",
          "score": -11,
          "created_utc": "2026-01-07 18:19:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9i1ip",
          "author": "aastle",
          "text": "I immediately downvote any r/stabediffusion post with the word \"insane\" in it.",
          "score": -9,
          "created_utc": "2026-01-07 20:14:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycrcy6",
              "author": "protector111",
              "text": "so much for cognitive distortions. That not a good way to live",
              "score": 4,
              "created_utc": "2026-01-08 06:31:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny9qwi3",
          "author": "mister_k1",
          "text": "gpt told me i would be able to run ltx2 on my 3060 12gb and 16g ram!! is it realistic?",
          "score": -4,
          "created_utc": "2026-01-07 20:53:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9rzcv",
          "author": "EpicNoiseFix",
          "text": "Was your aim for it to look like a PS4 video game cut scene? That‚Äôs what it looks like",
          "score": -6,
          "created_utc": "2026-01-07 20:57:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycrw1a",
              "author": "protector111",
              "text": "Those are screenshots from a videogame called expedition 33. I used them just cause i had screens on my PC from recent playthrough and i liked the result and desided to make a sarcastic video meme with them cause the game is very dramatic",
              "score": 5,
              "created_utc": "2026-01-08 06:35:25",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nyc6nyh",
              "author": "t-e-r-m-i-n-u-s-",
              "text": "it's expedition 33",
              "score": 5,
              "created_utc": "2026-01-08 04:09:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q6iv99",
      "title": "LTX-2 is impressive for more than just realism",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/xrkddqqg7ybg1",
      "author": "chanteuse_blondinett",
      "created_utc": "2026-01-07 15:47:59",
      "score": 1086,
      "num_comments": 81,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Animation - Video",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q6iv99/ltx2_is_impressive_for_more_than_just_realism/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny7zoo5",
          "author": "BigWideBaker",
          "text": "Impressive! It understands how puppet mouths work, being \"hinged\" and not using lips. It understands the materials with proper lighting. It understands the arms and hands are mostly non-functional. Just generally it understands how puppets bounce around and feel hand controlled. It must have some puppet material in the training data!",
          "score": 74,
          "created_utc": "2026-01-07 16:14:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8kpkk",
              "author": "daemon-electricity",
              "text": "They got a puppet guy.",
              "score": 25,
              "created_utc": "2026-01-07 17:49:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyauz4p",
                  "author": "damiangorlami",
                  "text": "I once spoke with a puppet-controller saying how glad AI wasn't coming after his job\n\nyikes",
                  "score": 15,
                  "created_utc": "2026-01-07 23:57:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny96we8",
              "author": "GoofAckYoorsElf",
              "text": "In the voices of Waldorf and Statler:\n\n> You mean they trained it on White House press conferences? \n\n> Hahaha!",
              "score": 20,
              "created_utc": "2026-01-07 19:26:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyd2zhm",
                  "author": "WarmKnowledge6820",
                  "text": "DOOHOHOHOOHOO",
                  "score": 3,
                  "created_utc": "2026-01-08 08:09:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyd5wqy",
              "author": "2this4u",
              "text": "The eyes move in the one clip but otherwise yeah it's pretty consistent with what you'd expect from a real puppet.",
              "score": 6,
              "created_utc": "2026-01-08 08:36:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nydv21x",
                  "author": "BigWideBaker",
                  "text": "Well spotted!",
                  "score": 3,
                  "created_utc": "2026-01-08 12:10:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyddxxr",
              "author": "Rich_Introduction_83",
              "text": "Probably the only one that managed to \"watch\" *all* episodes of the Muppet Show!",
              "score": 2,
              "created_utc": "2026-01-08 09:50:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nye6o38",
              "author": "ToraBora-Bora",
              "text": "I heard Jensen Huang himself secretly scan the whole brain off the Pupet master Jim Henson before his death.",
              "score": 1,
              "created_utc": "2026-01-08 13:24:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nygdcef",
                  "author": "BigWideBaker",
                  "text": "I'm gonna choose to believe this",
                  "score": 2,
                  "created_utc": "2026-01-08 19:24:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny9pae7",
          "author": "el_fenix_milenario",
          "text": "The kal-el No had more emotions than Gal gadot's",
          "score": 18,
          "created_utc": "2026-01-07 20:46:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyd0stv",
              "author": "dantheflyingman",
              "text": "Yeah. Some actors are really about to be replaced with AI.",
              "score": 3,
              "created_utc": "2026-01-08 07:50:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny7uens",
          "author": "Fancy-Restaurant-885",
          "text": "Different clips joined? I2V or T2V?",
          "score": 15,
          "created_utc": "2026-01-07 15:50:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8oi8r",
              "author": "chanteuse_blondinett",
              "text": "i just uesed the standard workflow on git  \n[https://github.com/Lightricks/LTX-2](https://github.com/Lightricks/LTX-2)",
              "score": 18,
              "created_utc": "2026-01-07 18:05:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny9mmmb",
                  "author": "leepuznowski",
                  "text": "Is there an equivalent to comfy workflows for these? I am having a hard time getting good results with i2v.",
                  "score": 5,
                  "created_utc": "2026-01-07 20:34:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nydi9qj",
                  "author": "Green-Ad-3964",
                  "text": "Thanks. May I ask also for the model and workflow used to create the base image and the prompts for both image and video?",
                  "score": 1,
                  "created_utc": "2026-01-08 10:28:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny7xc2c",
              "author": "chanteuse_blondinett",
              "text": "It's i2v, different clips edited to one",
              "score": 23,
              "created_utc": "2026-01-07 16:04:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny8499j",
                  "author": "Vicullum",
                  "text": "What did you use to make the images?",
                  "score": 7,
                  "created_utc": "2026-01-07 16:35:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny8hynf",
                  "author": "ExpandYourTribe",
                  "text": "Thanks for the video. What workflow and settings (CFG, etc.) are you using? I‚Äôm using the default ComfyUI LTX-2 i2v template and it‚Äôs really hard to get motion beyond a simple camera zoom.",
                  "score": 2,
                  "created_utc": "2026-01-07 17:37:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny8lw5m",
          "author": "wumr125",
          "text": "The \"Khaleel, no\" had more emotion than the original hehe",
          "score": 10,
          "created_utc": "2026-01-07 17:54:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny9isk3",
              "author": "Ishaan863",
              "text": "Bruh of course the ONE actor immediately outclassed by fuckin AI would be Gal Gadot lmfao",
              "score": 12,
              "created_utc": "2026-01-07 20:17:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny7yfb8",
          "author": "addictiveboi",
          "text": "First clip made me lol",
          "score": 27,
          "created_utc": "2026-01-07 16:09:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8aj4m",
          "author": "eye_am_bored",
          "text": "I'm not shitting on this because it's amazing, but the muppet puppet thing is literally the default workflow from comfy and one of LTX-2 example images, they have made it very clear it's not just for realism",
          "score": 16,
          "created_utc": "2026-01-07 17:03:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny94hk7",
          "author": "Choowkee",
          "text": "...this is realism tho?",
          "score": 13,
          "created_utc": "2026-01-07 19:15:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny9nnh9",
              "author": "dw82",
              "text": "Came here to say the same. These look like pretty realistic puppets to me.",
              "score": 13,
              "created_utc": "2026-01-07 20:39:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny8jgng",
          "author": "marklar7",
          "text": "Wow. They both have moms named Martha. Never noticed.",
          "score": 5,
          "created_utc": "2026-01-07 17:44:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny9zk3o",
              "author": "shizuo92",
              "text": "I take it you never watched Batman vs. Superman, then",
              "score": 6,
              "created_utc": "2026-01-07 21:29:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyax1a4",
                  "author": "marklar7",
                  "text": "It needs a rewatch, went right through me but I'm playing Arkham Knight past week and more receptive to it.\nED:\nYeah it's a scene, almost verbatim. Bruce's parents going down I've seen portayed several times. it was the Clark parents. I still don't know his step Dad's name lemme guess.. Ben?",
                  "score": 3,
                  "created_utc": "2026-01-08 00:07:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny8jer4",
          "author": "dm1tree",
          "text": "I loved this. Thanks for sharing!",
          "score": 4,
          "created_utc": "2026-01-07 17:43:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny81a65",
          "author": "Choice-Implement1643",
          "text": "Workflow or it didn‚Äôt happen.",
          "score": 31,
          "created_utc": "2026-01-07 16:22:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8pbsy",
              "author": "chanteuse_blondinett",
              "text": "i used the workflow from here \n\n[https://github.com/Lightricks/LTX-2](https://github.com/Lightricks/LTX-2)",
              "score": 28,
              "created_utc": "2026-01-07 18:09:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyb7w8k",
                  "author": "PM-mePSNcodes",
                  "text": "What PSU are you running? What's your address? SSN? What GPU manufacturer?",
                  "score": 12,
                  "created_utc": "2026-01-08 01:02:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyawylk",
                  "author": "Frequent-Advice-1633",
                  "text": "Hello, please tell me what is the minimum VRAM required to make this type of video?",
                  "score": 2,
                  "created_utc": "2026-01-08 00:07:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny9e654",
                  "author": "autistic-brother",
                  "text": "What are your CPU, RAM, and VRAM specs?",
                  "score": 2,
                  "created_utc": "2026-01-07 19:57:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny8fnkl",
              "author": "ronbere13",
              "text": "https://preview.redd.it/8xhppni9pybg1.png?width=1024&format=png&auto=webp&s=3d7b9d9cc560b83c4d49a220f0eb39bc403cda1b",
              "score": -19,
              "created_utc": "2026-01-07 17:26:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny8g80d",
                  "author": "Fancy-Restaurant-885",
                  "text": "Everyone knows all the shapes go in the square hole.",
                  "score": 22,
                  "created_utc": "2026-01-07 17:29:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny8hjvu",
              "author": "[deleted]",
              "text": "[removed]",
              "score": -32,
              "created_utc": "2026-01-07 17:35:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny8iw9h",
                  "author": "JimmyDub010",
                  "text": "Loool.",
                  "score": -5,
                  "created_utc": "2026-01-07 17:41:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny8ergs",
          "author": "meisterwolf",
          "text": "you're better off genning the puppets on a green screen or white screen right? then playing them over a background etc??\n\nseems you would have more control and less mistakes?",
          "score": 3,
          "created_utc": "2026-01-07 17:22:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny87suv",
          "author": "Noeyiax",
          "text": "Lmao nice, yea it does anime, cartoons, and non-realism very well!!\n\nkinda still like wan for realism. can't wait for fine tunes and loras for ltx2 tho lfg!!",
          "score": 7,
          "created_utc": "2026-01-07 16:51:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9lmmc",
          "author": "MrUtterNonsense",
          "text": "Beware that if you subscribe to the Ltx-Studio site to use the model, they seem to have the right to train on your images and even license them to all and sundry!    It was a show-stopped for me. I don't want pictures of me, my friends and family being sold to god-knows-who for AI training.\n\nCheck the Grant of Rights section, 6.2  \n[https://static.lightricks.com/legal/LTXS-Terms%20of%20Service%20Online.pdf](https://static.lightricks.com/legal/LTXS-Terms%20of%20Service%20Online.pdf)",
          "score": 5,
          "created_utc": "2026-01-07 20:30:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8042i",
          "author": "Enter_Name977",
          "text": "generation time?",
          "score": 2,
          "created_utc": "2026-01-07 16:16:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nybosp1",
              "author": "97buckeye",
              "text": "All of it.",
              "score": 3,
              "created_utc": "2026-01-08 02:31:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny8497v",
          "author": "3r0Van",
          "text": "Hahaha..!!! üòÇ loved it.",
          "score": 2,
          "created_utc": "2026-01-07 16:35:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8t0ph",
          "author": "SysPsych",
          "text": "Great stuff. Inspiring stuff even.\n\nIt got me wondering if this would work easily with a puppet and a more realistic human in the mix -- and sure enough, it can pull it off.\n\nI also found out ZAI has no idea what a hand puppet is, which was my first choice, but it understands muppets just fine.\n\nhttps://streamable.com/a99715",
          "score": 2,
          "created_utc": "2026-01-07 18:25:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny98r8j",
              "author": "Synchronauto",
              "text": "Can you share the workflow you used for this?",
              "score": 1,
              "created_utc": "2026-01-07 19:34:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny9anji",
                  "author": "SysPsych",
                  "text": "Nothing but the standard workflow I2V workflow, a ZAI image, and a barebones basic prompt:\n\n>An attractive red-headed woman dressed in a suit and tie, with a muppet sitting on her lap.\n\n>The woman looks down at the puppet and asks, \"And how are you doing today, Shelly?\"\n\n>The puppet then looks up at the moment and says, in a cute female voice, \"I'm fine, thank you for asking!\"",
                  "score": 3,
                  "created_utc": "2026-01-07 19:42:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nybkmz9",
          "author": "Lower-Cap7381",
          "text": "It was i2v or t2v amazing ü§©",
          "score": 2,
          "created_utc": "2026-01-08 02:09:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyd4goo",
          "author": "HrBransholm",
          "text": "Meanwhile testing the LTX-2 model on OpenArt with all bells and whistles (\"Pro\" and 4K) gives one totally unusable blurry mess with bad promt following... even choosing older models looked better (tested all their video models on same I2V input)\n\nIs the trick to set it up locally and use the default workflows for Comfy instead? Do they cripple it somehow at OpenArt?\n\nYour sequence looks extremely good.",
          "score": 2,
          "created_utc": "2026-01-08 08:22:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny7zdxb",
          "author": "LadenBennie",
          "text": "I love it. But if I want another language spoken, where do I start, any tips?",
          "score": 2,
          "created_utc": "2026-01-07 16:13:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8o6oe",
              "author": "chanteuse_blondinett",
              "text": "i think you can type the language and it'll read it... haven't tried yet",
              "score": 1,
              "created_utc": "2026-01-07 18:04:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny9wjlw",
                  "author": "ofirbibi",
                  "text": "Gemma support is 140 languages. Some are better than others in the audio generation.",
                  "score": 1,
                  "created_utc": "2026-01-07 21:16:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nydmer3",
                  "author": "LadenBennie",
                  "text": "It actually works. Ok not perfect, but if you just write in the language you want, it does work. Quite some fun. Hope we can do some voice loras later, would be great.",
                  "score": 1,
                  "created_utc": "2026-01-08 11:03:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny7yhsq",
          "author": "protector111",
          "text": "Lol",
          "score": 1,
          "created_utc": "2026-01-07 16:09:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny859vg",
          "author": "LyriWinters",
          "text": "haha fantastic",
          "score": 1,
          "created_utc": "2026-01-07 16:40:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny85oc0",
          "author": "ProfessionalGain2306",
          "text": "Good show \nüòÖ",
          "score": 1,
          "created_utc": "2026-01-07 16:41:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny878hj",
          "author": "Upset-Virus9034",
          "text": "Great stuf!,\n\nwhat is your system ram? 32Gb? and how to make longer videos as of now i could only generate 5secs with my RTX 4090 24GBVram",
          "score": 1,
          "created_utc": "2026-01-07 16:48:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8opwx",
              "author": "chanteuse_blondinett",
              "text": "i'm on HP Omen with 5090",
              "score": 1,
              "created_utc": "2026-01-07 18:06:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny94krm",
                  "author": "Upset-Virus9034",
                  "text": "32GB I suppose, what about the prompt and the WF to generate longer videos than 5sec? \nThank you",
                  "score": 1,
                  "created_utc": "2026-01-07 19:15:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny8pggd",
          "author": "Dzugavili",
          "text": "I'm still struggling to get it online: there's a bunch of nodes that just don't seem to load.\n\nEdit: I've tried from a clean install, I keep getting errors pulling the LTX modules. No clue why...\n\nEdit: Get an error trying to copy the git: missing 'comfy'. Installing comfy then kills the install, need to rebuild the environment.",
          "score": 1,
          "created_utc": "2026-01-07 18:10:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9m96l",
          "author": "jadhavsaurabh",
          "text": "It's too good",
          "score": 1,
          "created_utc": "2026-01-07 20:33:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nya9t00",
          "author": "Lightningstormz",
          "text": "Is the audio generated by LTX as well?",
          "score": 1,
          "created_utc": "2026-01-07 22:14:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyaztbq",
              "author": "Inevitable-Owl-1941",
              "text": "LTX-2 generates audio. Not sure if the video one is from LTX-2 but you can prompt for voice lines.",
              "score": 2,
              "created_utc": "2026-01-08 00:21:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nydpj4r",
          "author": "leepuznowski",
          "text": "It keeps giving me errors from the LTXVGemmaEnhancePrompt. \"cudaMallocAsync does not yet support checkPoolLiveAllocations.\" Are you using the Gemma 3 Model Loader with the split safetensors? I can run the template from comfyui, but the results are just not good.",
          "score": 1,
          "created_utc": "2026-01-08 11:29:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nye7x5f",
          "author": "bensummersx",
          "text": "LTX-2 really shows that realism is just the tip of the iceberg; its versatility opens up so many creative avenues.",
          "score": 1,
          "created_utc": "2026-01-08 13:31:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyjz98p",
          "author": "santyxzz",
          "text": "What's that??",
          "score": 1,
          "created_utc": "2026-01-09 06:55:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nysd1h2",
          "author": "rookiestar28",
          "text": "very interesting content. would you mind sharing the prompt you use?",
          "score": 1,
          "created_utc": "2026-01-10 14:05:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8wp33",
          "author": "InternationalOne2449",
          "text": "The audio really blows. I really see no point in using it. MMaudio does better job.",
          "score": -1,
          "created_utc": "2026-01-07 18:41:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny9e865",
              "author": "Secure-Message-8378",
              "text": "You can use your own audio too. And the inner audio is not so far from sora 2 (closed source). You can import your own audio in a open source model. It's incredible.",
              "score": 4,
              "created_utc": "2026-01-07 19:57:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny9iof9",
                  "author": "Training_Fail8960",
                  "text": "import your own audio, like spoken words etc. and lipsync? :)",
                  "score": 2,
                  "created_utc": "2026-01-07 20:17:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny94hhw",
              "author": "Wilbis",
              "text": "Yes. Audio is definitely the weak point in this. Hopefully they will fix it or at least make it a little better.",
              "score": 2,
              "created_utc": "2026-01-07 19:15:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny7ynrd",
          "author": "witcherknight",
          "text": "more like its garbage for realism",
          "score": -16,
          "created_utc": "2026-01-07 16:10:14",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q9cy02",
      "title": "LTX-2 I2V: Quality is much better at higher resolutions (RTX6000 Pro)",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/13iybm3gikcg1",
      "author": "000TSC000",
      "created_utc": "2026-01-10 19:21:38",
      "score": 1009,
      "num_comments": 237,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q9cy02/ltx2_i2v_quality_is_much_better_at_higher/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nyuejqm",
          "author": "Friendly-Win-9375",
          "text": "girl doesn't blink her eyes in 10 seconds.",
          "score": 104,
          "created_utc": "2026-01-10 20:08:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyvdw46",
              "author": "Dzugavili",
              "text": "Eh, I kind of like 'em a bit crazy.",
              "score": 64,
              "created_utc": "2026-01-10 23:05:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyxyrd1",
                  "author": "rinkusonic",
                  "text": "Pause at 0:00. Look at the eyes.",
                  "score": 2,
                  "created_utc": "2026-01-11 08:53:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyvors9",
                  "author": "Krakatoba",
                  "text": "Same brother.",
                  "score": 5,
                  "created_utc": "2026-01-11 00:03:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyvwjiq",
              "author": "Opposite_Cheek_5709",
              "text": "I can fix her",
              "score": 29,
              "created_utc": "2026-01-11 00:43:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nywax96",
                  "author": "McLeod3577",
                  "text": "Don't let her near your pet rabbit",
                  "score": 7,
                  "created_utc": "2026-01-11 02:01:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyxmo7a",
                  "author": "Tyler_Zoro",
                  "text": "Don't stick your RTX-6000 Pro in crazy.",
                  "score": 2,
                  "created_utc": "2026-01-11 07:04:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nywmx83",
                  "author": "mk8933",
                  "text": "She doesn't want to be saved bro üòÇ dont save her.",
                  "score": 1,
                  "created_utc": "2026-01-11 03:06:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz5ladh",
                  "author": "OzTheOtaku",
                  "text": "Share prompt",
                  "score": 1,
                  "created_utc": "2026-01-12 13:02:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyxxml8",
              "author": "GoofAckYoorsElf",
              "text": "And uh, the first couple frames... her eyes... oh my god... what the fuck...",
              "score": 2,
              "created_utc": "2026-01-11 08:43:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyw29e1",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": -2,
              "created_utc": "2026-01-11 01:13:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyw4nhx",
                  "author": "grundlegawd",
                  "text": "That‚Äôs due to the input image.",
                  "score": 2,
                  "created_utc": "2026-01-11 01:27:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyudmy2",
          "author": "jigendaisuke81",
          "text": "I think everyone can trivially generate a good facial closeup video with LTX2. Cars glitching out in that background.  \n  \nPlease show something that actually tests the model. Have her spin in place. All I ask.",
          "score": 150,
          "created_utc": "2026-01-10 20:03:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyvjd5f",
              "author": "FetusExplosion",
              "text": "Also, uh, where's that backlighting coming from?",
              "score": 23,
              "created_utc": "2026-01-10 23:34:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyw5ahs",
                  "author": "Quetzal-Labs",
                  "text": "There's literally a light on a stand behind her lol",
                  "score": 14,
                  "created_utc": "2026-01-11 01:30:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyyhtj0",
                  "author": "physalisx",
                  "text": "This is img2video, the backlight was already in the source image. Not LTX's fault OP gives it a nonsensical input.",
                  "score": 3,
                  "created_utc": "2026-01-11 11:48:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyvs6oh",
                  "author": "fizzdev",
                  "text": "Yeah that makes no sense at all.",
                  "score": 6,
                  "created_utc": "2026-01-11 00:21:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyupds2",
              "author": "superstarbootlegs",
              "text": "good spot. are they glitching as such? the wheels look okay its the motion left and right. but at 48fps they maybe wouldnt be jumping like that, but I expect it is the fps more than the glitch. If it is 24fps native out the model? maybe it would do that.\n\nall the work I do trying to make narrative clips,  anything moving side-ways across the screen at Wan 16fps output is tragic, even when interpolated.\n\nSpent a lot of time trying to fix a slow motion dolphin in Wan back before I understood it better - [https://www.youtube.com/shorts/KtffecdH6WQ](https://www.youtube.com/shorts/KtffecdH6WQ)",
              "score": 2,
              "created_utc": "2026-01-10 21:02:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyur6wa",
                  "author": "jigendaisuke81",
                  "text": "https://i.redd.it/kmx26p448lcg1.gif\n\nI see you're talking about very slight judder. But it's not really comparable to the very bad motion in OP video.  Here's an example I made right after wan 2.2 came out.",
                  "score": 9,
                  "created_utc": "2026-01-10 21:11:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyv80a6",
                  "author": "ImUrFrand",
                  "text": "24fps is native cinema standard for film production... which is where ltx-2 is aimed at.",
                  "score": 5,
                  "created_utc": "2026-01-10 22:35:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyw6gkw",
                  "author": "throttlekitty",
                  "text": "Someone else had some extremely stuttery videos, their front and center person was moving correctly at all. It turns out they were using the default schizo negative, and that replacing it with a basic one fixed the issue in that case.\n\nJust pointing this out for anyone with issues, the workflow OP linked has a normal negative though.",
                  "score": 1,
                  "created_utc": "2026-01-11 01:37:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyxmhro",
              "author": "Tyler_Zoro",
              "text": "Look at the woman on the left, right behind the main woman. She looks normal at first, but as the rest of her gets revealed, watch her face. It's like she suddenly realizes that she's standing still for no reason, but can't move. Her face looks so confused!",
              "score": 1,
              "created_utc": "2026-01-11 07:03:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyu7894",
          "author": "Agreeable-Warthog547",
          "text": "You are rich with a 6k pro. Video looks good. Keep going mate !",
          "score": 26,
          "created_utc": "2026-01-10 19:32:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyuc7cw",
              "author": "rubberjohnny1",
              "text": "he was rich, now poorer.",
              "score": 35,
              "created_utc": "2026-01-10 19:56:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyuc1oc",
              "author": "Late_Campaign4641",
              "text": "lol, it's cheaper for an american to buy the 6k pro than a brazillian to buy a 5070 ti",
              "score": 21,
              "created_utc": "2026-01-10 19:55:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyup6aa",
                  "author": "comfyui_user_999",
                  "text": "That...can't be right. The RTX 6000 pro is like $8K, and Google is telling me that's BRL 43K.  Here's a 5070 Ti for BRL 6.7K: [https://www.kabum.com.br/produto/714565/placa-de-video-gigabyte-rtx-5070-ti-gaming-oc-16g-nvidia-geforce-16gb-gddr7-256bits-rgb-dlss-ray-tracing-9vn507tgo-00-g10](https://www.kabum.com.br/produto/714565/placa-de-video-gigabyte-rtx-5070-ti-gaming-oc-16g-nvidia-geforce-16gb-gddr7-256bits-rgb-dlss-ray-tracing-9vn507tgo-00-g10)",
                  "score": 7,
                  "created_utc": "2026-01-10 21:01:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyuq8zx",
                  "author": "Extreme_Feedback_606",
                  "text": "it‚Äôs cheaper for an american to buy anything than a brazilian to by anything lol",
                  "score": 3,
                  "created_utc": "2026-01-10 21:07:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyuiriq",
                  "author": "Agreeable-Warthog547",
                  "text": "Insane",
                  "score": 1,
                  "created_utc": "2026-01-10 20:29:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyxmype",
              "author": "Tyler_Zoro",
              "text": "> You are rich with a 6k pro. \n\nThey cost less than $10k I know people who spend that much putting useless accessories on their cars.\n\nYou're not going to buy it on a student income, but you certainly don't have to be rich.",
              "score": 5,
              "created_utc": "2026-01-11 07:07:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz5ubhu",
              "author": "nickdaniels92",
              "text": "Seriously, how do you know? Maybe OP took out a 4th CC and is maxed up to the hilt in debt. He might have sold his car and TV and borrowed some cash from family to get the card plus a second hand bicycle. Having expensive items is not the same as being rich.",
              "score": 1,
              "created_utc": "2026-01-12 13:55:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyu6z6i",
          "author": "LegacyRemaster",
          "text": "yes... i'm on rtx 6000 96gb too. Everything is better with vram. no gguf etc...",
          "score": 58,
          "created_utc": "2026-01-10 19:31:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyuq4j1",
              "author": "reddridinghood",
              "text": "How long would it take to render a video like this in 1080p?",
              "score": 8,
              "created_utc": "2026-01-10 21:06:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyv49l4",
                  "author": "UnlikelyPotato",
                  "text": "If it helps, on a 3090 + 128GB sytem ram. This video 20 second video took 23 minutes to produce 1080p, 24 fps, 20 seconds. Fast action + 20 steps results in weirdness. 10 seconds would be around 10 minutes. LTX-2 dev fp8, non-distilled text to video.\n\n  \n[https://files.catbox.moe/bf4bqx.mp4](https://files.catbox.moe/bf4bqx.mp4)",
                  "score": 19,
                  "created_utc": "2026-01-10 22:16:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyurnv1",
                  "author": "sitefall",
                  "text": "I'm on pro 6000 blackwell as well but haven't tried LTX-2 yet.  Wan2.2 however renders 1080p with lightx2 lora (basically the default wan2.2 i2v workflows from comfy org themselves) in 140s each ksampler so about 5 minutes from the time you click run.\n\n5090 can run slightly larger than 720p, resolutions like 1072x1072, basically anything under 1.5 million total pixels or so that isn't too weird of an aspect ratio (like 2560x500 long hotdog shaped video) in about 1.5 minutes per ksampler.  Pro 6000 runs these about 10% slower.\n\nFor reference a standard 720x1280 video takes about 70 seconds per ksampler with the same workflow/light2x lora.\n\nAs you approach 1080p (about 2 million pixels) things start to get funky and lose some prompt adherence with or without loras, sometimes get some body horror etc.",
                  "score": 9,
                  "created_utc": "2026-01-10 21:14:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyyiqes",
                  "author": "JahJedi",
                  "text": "On my 6000 pro its take 6 minutes for 15 sec 1920x1088 clip.",
                  "score": 1,
                  "created_utc": "2026-01-11 11:56:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyx2xlr",
              "author": "BitterFortuneCookie",
              "text": "You can run this on 5090 with full model. I‚Äôm currently able to do 15 seconds with full model at 1080p. Needed to use reserve vram 4. I also have 128 GB ram. Takes around 6 minutes per gen which is actually not bad. But even at the best possible quality for this model it still is glitchy and imperfect.  Very happy with this as the starting point and hoping the next iterations (like wan 2.2 was for wan 2.1) will continue to improve coherence, motion, and audio. And of course with the help of some community driven Lora love.",
              "score": 1,
              "created_utc": "2026-01-11 04:39:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyv3xb5",
              "author": "Raider6180",
              "text": "For a moment i thought you're doing sarcasm as i dont have knowledge on an rtx 6000 lol and the guy saying 96gb vram almost made me believe that with certainity",
              "score": -1,
              "created_utc": "2026-01-10 22:14:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyv791q",
                  "author": "Electrical-Eye-3715",
                  "text": "Rtx 6000 pro really does have 96gb vram",
                  "score": 12,
                  "created_utc": "2026-01-10 22:31:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyu8lp0",
          "author": "Guilty_Emergency3603",
          "text": "Alright but where do we find the LTX-2 I2V 3 stage workflow with the Clownshark sampler ?",
          "score": 17,
          "created_utc": "2026-01-10 19:38:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyujg3u",
          "author": "Lower-Cap7381",
          "text": "The background is always a mess no matter what hope the team releasing ltx 2.1 fixes it im waiting for zimage base and edit üôå",
          "score": 13,
          "created_utc": "2026-01-10 20:33:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyy2frl",
              "author": "Sudden_List_2693",
              "text": "Shhh! If they do it will get closed source.  \nLike WAN. Like everything.",
              "score": -1,
              "created_utc": "2026-01-11 09:28:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyu5szk",
          "author": "protector111",
          "text": "2560 res defenetely looks very good. 4k is probably too much for 5090.  I mean t2v . I2v is more vram hungry i can barely make 720p",
          "score": 17,
          "created_utc": "2026-01-10 19:25:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyu746v",
              "author": "No_Comment_Acc",
              "text": "In my tests anything over 1920√ó1080 showed massive degradation. 4k was totally useless. LTX-2 needs a lot of work. It is very raw at the moment.",
              "score": 17,
              "created_utc": "2026-01-10 19:31:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyu7km4",
                  "author": "protector111",
                  "text": "The most weird thing is ppl have very different experience. Probably need somw thime to figure out best wf and fix the bugs. Model has huge potential",
                  "score": 12,
                  "created_utc": "2026-01-10 19:33:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyv48p1",
                  "author": "comperr",
                  "text": "i have plenty success upscaling the frames from even 720p to 4k. i do this all the time now even for work, i render a product at low res and have a upscale workflow that actually works",
                  "score": 1,
                  "created_utc": "2026-01-10 22:16:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyuko3g",
          "author": "Az0rXx",
          "text": "The road behind has no sense ü§£",
          "score": 9,
          "created_utc": "2026-01-10 20:39:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyu7mh3",
          "author": "witcherknight",
          "text": "Bro closeup videos always looks good. Try to do something else",
          "score": 24,
          "created_utc": "2026-01-10 19:34:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyu8qev",
              "author": "Agreeable-Warthog547",
              "text": "I don‚Äôt know about always lol",
              "score": 14,
              "created_utc": "2026-01-10 19:39:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyup4j1",
              "author": "kemb0",
              "text": "Yep someone near the camera talking has given me the best results and can be fun but trying to do anything veering away from that can often be an exercise in frustration. It took me 5 attempts with prompting just to turn a static truck in a tunnel in to a moving one. But have a close up of a person and you can practically type anything and get some good action.\n\nObviously prompting has always been important but when you end up having to type:\n\nA truck moving in a tunnel, the markings on the floor pass by the truck as it drives, the lights on the tunnel wall are moving passed the truck quickly which is driving along the road and another vehicle passes the truck by with a sign also passing overhead....etc...etc....\n\nIt gets tiresome. Just show me a \"truck driving down a tunnel\".",
              "score": 2,
              "created_utc": "2026-01-10 21:01:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz2uqej",
                  "author": "No_Possession_7797",
                  "text": "It's times like that that I tell myself, \"You know, maybe I should just drive over to the freeway and watch a truck drive down a tunnel.\"",
                  "score": 1,
                  "created_utc": "2026-01-12 01:07:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyuoo6o",
              "author": "superstarbootlegs",
              "text": "background faces look cohesive in his OP. i dont get that easily with Wan on lowVRAM either, it is a lot of work to fix faces at distance.",
              "score": 1,
              "created_utc": "2026-01-10 20:59:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyu88c7",
          "author": "CornmeisterNL",
          "text": "Can you please share your 3stage flow?",
          "score": 5,
          "created_utc": "2026-01-10 19:37:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyucl9p",
              "author": "000TSC000",
              "text": "Updated my post. [https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example\\_workflows](https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example_workflows)  \n I used the \"[LTX-2\\_I2V\\_Full\\_wLora.json](https://github.com/Lightricks/ComfyUI-LTXVideo/blob/master/example_workflows/LTX-2_I2V_Full_wLora.json)\".",
              "score": 14,
              "created_utc": "2026-01-10 19:58:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyujof6",
                  "author": "seppe0815",
                  "text": "how do you make money? dont tell us you make it free for fun! telemetry crap or other python code crap",
                  "score": 2,
                  "created_utc": "2026-01-10 20:34:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyu935c",
          "author": "Desm0nt",
          "text": ">Change default fps from 24 to 48, this seems to help motions look more realistic.\n\nEspecially cars in the background =)",
          "score": 5,
          "created_utc": "2026-01-10 19:41:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyuuucj",
          "author": "lordpuddingcup",
          "text": "The real issue is why does the sound sometimes sound so‚Ä¶ tinny and cracked like it‚Äôs oversaturating",
          "score": 4,
          "created_utc": "2026-01-10 21:30:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyue4pf",
          "author": "Volkin1",
          "text": "Looks impressive :)\n\nRes2s + 40 steps ( for 10 - 15 seconds videos ) makes all the magic for me with stunning quality, motion and clarity.\n\nBasically trying to do 20 steps on anything higher than 5 seconds will cause the model to produce garbage results, and then people say LTX2 I2V is bad.\n\nNot, it's not bad. It's amazing.",
          "score": 8,
          "created_utc": "2026-01-10 20:06:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyuh5yw",
              "author": "000TSC000",
              "text": "Will try this next!",
              "score": 1,
              "created_utc": "2026-01-10 20:21:38",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nyvoqfo",
              "author": "000TSC000",
              "text": "Wow, one thing to note about more steps is that text gets fixed.",
              "score": 1,
              "created_utc": "2026-01-11 00:03:11",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nyxm2wa",
              "author": "Perfect-Campaign9551",
              "text": "Res2 AND 40 steps. Speed now matches WAN",
              "score": 1,
              "created_utc": "2026-01-11 06:59:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyzbiq4",
                  "author": "Volkin1",
                  "text": "Yeah it's slower, but i'll pick quality over speed any time.",
                  "score": 2,
                  "created_utc": "2026-01-11 15:03:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyuqwcx",
              "author": "Additional_Drive1915",
              "text": "EDIT: Yes, I misread, can happen sometimes. :)  \n\\--  \nDo you say more steps give worse result? More steps is usually my solution for \\*better\\* quality. If you could clarify please.\n\nBtw, time for you to make a separate post with all your findings for best LTX2 practices, you usually have very good advice to give. :)",
              "score": -2,
              "created_utc": "2026-01-10 21:10:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyuv0a5",
                  "author": "PrisonOfH0pe",
                  "text": "how can you not understand him?? he was crystal clear? he said using res2s and doubling steps gave much better results. are you a bot?",
                  "score": 2,
                  "created_utc": "2026-01-10 21:30:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyuv48n",
                  "author": "Volkin1",
                  "text": "No no. More steps = better quality. When doing 40 steps for 10 - 15 seconds videos is what makes the magic work for me.",
                  "score": 2,
                  "created_utc": "2026-01-10 21:31:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyvt3z0",
          "author": "Vyviel",
          "text": "Why can they do awesome video but the audio is still sounds so fake and bad?",
          "score": 3,
          "created_utc": "2026-01-11 00:26:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyudskl",
          "author": "Perfect-Campaign9551",
          "text": "Which entirely defeats the speed.. So like I was saying, it's not all they claim to be. Plus the prompt following is horrible\n\n\nChrist with all the hacks your have to do to get quality you are practically driving Ltx to school at this point. If you want slop use Ltx if you want quality use WAN. At least for now",
          "score": 10,
          "created_utc": "2026-01-10 20:04:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyv1hc9",
              "author": "hurrdurrimanaccount",
              "text": "uh huh sure. let me know when wan can do lipsync with audio without needing extra bullshit.",
              "score": 2,
              "created_utc": "2026-01-10 22:02:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyvpz79",
                  "author": "GrungeWerX",
                  "text": "I know a method. Just thought of it last night. I'll share later.",
                  "score": 2,
                  "created_utc": "2026-01-11 00:09:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyvl1p0",
          "author": "Adventurous-Bit-5989",
          "text": "could u tell us how to install\"ImageScaleToTotalPixels_invAIder\"node,thx",
          "score": 3,
          "created_utc": "2026-01-10 23:44:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyvoim0",
              "author": "000TSC000",
              "text": "Its a personal custom node, you dont  need it, all it was doing was finding what my starting frame's resolution would be at 2MP to set the latent width & height, you can do this manually or with comfy's inbuilt node called \"ImageScaleToTotalPixels\".",
              "score": 1,
              "created_utc": "2026-01-11 00:02:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyu97ug",
          "author": "WildSpeaker7315",
          "text": "crispy",
          "score": 2,
          "created_utc": "2026-01-10 19:41:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyu9x6b",
          "author": "broadwayallday",
          "text": "it really wants that exact composition also. portrait size heads is it's sweet spot. this is why that cab in the background exists in at least 4 parallel dimensions",
          "score": 2,
          "created_utc": "2026-01-10 19:45:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyucxe1",
          "author": "Phuckers6",
          "text": "It's good as long as you hide the hands or limit their movement.",
          "score": 2,
          "created_utc": "2026-01-10 20:00:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyuds3p",
          "author": "serendipity777321",
          "text": "Excited to see open source moving forward",
          "score": 2,
          "created_utc": "2026-01-10 20:04:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyukitc",
          "author": "SlavaSobov",
          "text": "Sorry AI lady I can't afford one. üòÖ",
          "score": 2,
          "created_utc": "2026-01-10 20:38:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyur3il",
          "author": "Mkep",
          "text": "Pretty nice studio background lighting out in the street",
          "score": 2,
          "created_utc": "2026-01-10 21:11:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyusuno",
          "author": "DawnPatrol99",
          "text": "Creepy video.",
          "score": 2,
          "created_utc": "2026-01-10 21:20:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyuucym",
          "author": "Maskwi2",
          "text": "Guy on the left in the background disappears lol. And glitch in the car. But the girl looks good.\nEdit: I see the more fps version from OP looks good now!¬†",
          "score": 2,
          "created_utc": "2026-01-10 21:27:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyv66jk",
          "author": "mca1169",
          "text": "sure I'll buy a RTX pro 6000 no problem! in 10 years when they are somewhat affordable and hopefully still useful.",
          "score": 2,
          "created_utc": "2026-01-10 22:26:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyvbdrx",
          "author": "gradeATroll",
          "text": "She's tweaking out",
          "score": 2,
          "created_utc": "2026-01-10 22:52:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nywqztx",
          "author": "giatai466",
          "text": "It is creepy",
          "score": 2,
          "created_utc": "2026-01-11 03:29:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxhup1",
          "author": "21st_century_ape",
          "text": "From my own experiments, it has a lot to do with the prompt. Actually, the prompt adherence is good in a sense because once you've arrived at a good prompt, it'll stay good even if you change frame count or resolution or fps.\n\nWrite in present tense, in a natural sequence of events of what happens. Use specific language rather than generic descriptions. \n\nDo quick iterations at low resolutions and fine-tune your prompt that way. Yes, landscape helps and being at a 16:9 also helps, but the prompt is the most important thing by far.",
          "score": 2,
          "created_utc": "2026-01-11 06:23:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyue5qm",
          "author": "strppngynglad",
          "text": "Erika Kirk death stare",
          "score": 5,
          "created_utc": "2026-01-10 20:06:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyw3pug",
          "author": "Niwa-kun",
          "text": "And this is the worst it will ever be.",
          "score": 4,
          "created_utc": "2026-01-11 01:21:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyu8wt1",
          "author": "UnlikelyPotato",
          "text": "You honestly don't need a RTX 6000 Pro. Sage attention + lowvram means stuff is shuffled onto GPU only as it's needed. Modest performance impact, but you basically can keep most of the data in system ram. Right now I'm trying a 1920x1080 video, 24fps, 30 seconds long, using 13GB vram on a 3090. Will likely get a little bit higher, but \"should\" work.",
          "score": 2,
          "created_utc": "2026-01-10 19:40:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyuedi2",
              "author": "FantasticFeverDream",
              "text": "Why use only 13gb vram on your 3090?",
              "score": 2,
              "created_utc": "2026-01-10 20:07:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyv3abr",
                  "author": "UnlikelyPotato",
                  "text": "As things are swapped and moved around it will spike to more. Because this is compute heavy, there's minimal performance impact between --lowvram and normal usage. You're more handicapped by compute than bandwidth. That said, faster memory, more ram, PCI-E 5.0 all will help, but it all still \"works\".",
                  "score": 2,
                  "created_utc": "2026-01-10 22:11:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyueem8",
              "author": "Perfect-Campaign9551",
              "text": "I literally can't go past 8 seconds of 1080p on a 3090. The upscale step will just get stuck waiting forever. It won't work. Been there done that",
              "score": 2,
              "created_utc": "2026-01-10 20:07:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyv1o3v",
                  "author": "hurrdurrimanaccount",
                  "text": "works on my machine. use the new quants and smaller gemma",
                  "score": 0,
                  "created_utc": "2026-01-10 22:03:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyuzqu8",
              "author": "EeviKat",
              "text": "Would you mind possibly explaining how this works to me or sharing the work flow? I keep seeing people talk about generating good videos with older cards, whether it be WAN or LTX, but I can't seem to figure it out. I tried a WAN 2.2 workflow I found online earlier but it seemed to only generate like one video then break, and the output was terrible (barely animated at all). I have a 4070ti for reference.",
              "score": 1,
              "created_utc": "2026-01-10 21:54:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyv2pyx",
                  "author": "UnlikelyPotato",
                  "text": "Ubuntu. Headless server (running over SSH/web), 0 vram used for desktop. Stock ComfyUI install. Install sage attention.\n\nI launch ComfyUI with:\n\n***python3*** [***main.py***](http://main.py) ***--reserve-vram 4  --use-sage-attention --novram --listen --port 8188***\n\n\\--novram and --use-sage-attention are the important options. For lack of better explanation, it streams only data as needed into the GPU instead of trying to do everything all at once. \n\nUse the included LTX-2 Text To Video flow with most recent ComfyUI. Expand the actual text to video segment. Disable included vae decode for video (audio is fine), add VAE tiled decode, reroute to that. Should look like this:  \n\n\nhttps://preview.redd.it/mtjw6fgihlcg1.png?width=985&format=png&auto=webp&s=ce843fc6830c5cb16220d287b29281fe09d8e315\n\nRed = Old/bad. Green = New.  Update parameters (mine are VERY loose and slow, can be optimized later).\n\nThat's it. Image to video is basically the same, but slightly more memory intensive.  Even with these options, vram usage can get a bit high. 30s may not be achievable and you may 'only' be able to do 15 seconds or so.",
                  "score": 3,
                  "created_utc": "2026-01-10 22:08:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyw86jn",
              "author": "Volkin1",
              "text": "You can go even higher with --novram if you ever need to push more boundaries.",
              "score": 1,
              "created_utc": "2026-01-11 01:46:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyuc3sn",
          "author": "Far_Lifeguard_5027",
          "text": "Not understanding why we still can't seem to do text.....are we tired of the gibberish words yet?",
          "score": 4,
          "created_utc": "2026-01-10 19:56:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyxcrtx",
              "author": "pixelpoet_nz",
              "text": "Speaking of gibberish words,\n\n> Scowering",
              "score": 1,
              "created_utc": "2026-01-11 05:44:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyv4c3f",
          "author": "anitman",
          "text": "Personally, I think the LTX-2 model has been censored far too aggressively. While its T2V performance is decent, T2V is mostly usable for experimentation or casual play and is very hard to turn into real productivity. In practice, the truly useful part should be I2V, but what we actually see is that its I2V output is basically limited to talking avatars, with extremely constrained motion. From a productivity standpoint, this is essentially meaningless. The model requires a large amount of fine-tuning to achieve acceptable and reliable outputs. In the V2V domain, the gap between its ControlNet and Wan Animate is still very obvious. I believe that such heavy censorship is very unfriendly to the open-source community. Similar to what happened with Flux, increasing the difficulty for the community to this extent will ultimately be detrimental to the development of the model‚Äôs ecosystem.",
          "score": 3,
          "created_utc": "2026-01-10 22:16:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyvjvpg",
              "author": "OldCoffee8017",
              "text": "I call bs. Provide examples of said censorship.",
              "score": 2,
              "created_utc": "2026-01-10 23:37:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nywfsd9",
                  "author": "comfyui_user_999",
                  "text": "I call double BS. Provide examples of said productivity.",
                  "score": 1,
                  "created_utc": "2026-01-11 02:27:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyy1ar5",
              "author": "BuffMcBigHuge",
              "text": "It's free software, quit yer complaining.",
              "score": 0,
              "created_utc": "2026-01-11 09:17:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyul2r6",
          "author": "Hot_Turnip_3309",
          "text": "\"bro just buy a $10k GPU\"\n\nthanks, but that isn't helpful.",
          "score": 5,
          "created_utc": "2026-01-10 20:41:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyw1mp8",
              "author": "LightPillar",
              "text": "id rather buy a 5090 for protyping and then just run it in the cloud with a 6000 pro or better and have enough left over to do that for 5+ years.",
              "score": 2,
              "created_utc": "2026-01-11 01:10:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyuimh2",
          "author": "Puttanas",
          "text": "Ai doesn‚Äôt know how to shade light naturally",
          "score": 2,
          "created_utc": "2026-01-10 20:28:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyucy0u",
          "author": "Upper-Reflection7997",
          "text": "It's unrealistic to expect tons of people to invest in a rtx 6000 pro. 10k down upfront cost. For me to have the guts to do that, quality output and speed has to way greater than my current 5090+64gb ddr5 setup for image and video generation. The next class of gpus needs to have 48-64gb vram for its flagship enthusiast xx90. At least have the return for titan card as the flagship card üòî.",
          "score": 1,
          "created_utc": "2026-01-10 20:00:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyurvbx",
              "author": "Additional_Drive1915",
              "text": "Normally you can do almost everything a 6000k can do with your 5090, at almost the same time. The memory management for LTX2 still sucks, but in a few days I guess that is sorted out.\n\nI have the money ready for a 6000k, but I have a hard time see the point in buying one. Except for LTX2 until they fixed it.",
              "score": 1,
              "created_utc": "2026-01-10 21:15:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyurwqr",
              "author": "advo_k_at",
              "text": "you can always cloud rent",
              "score": 1,
              "created_utc": "2026-01-10 21:15:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyu8no8",
          "author": "No_Comment_Acc",
          "text": "I still haven't resolved tons of issues in my console. I installed LTX-2 templates today and it broke my Comfy. What I loved about Z Image is how it just worked out of the box without a single problem.\n\nI'd much prefer a properly working model at a later date than a fast ready-to-go unreliable mess. Don't get me wrong, it is an amazing model than can become a local Veo or Sora but it does not run smooth at all.",
          "score": 1,
          "created_utc": "2026-01-10 19:39:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyuehv2",
              "author": "Objective_Echo_6121",
              "text": "The Ltx 2 templates in comfy have had weird issues. The example workflows directly from ltx creators work better out of the box.\n\n[https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example\\_workflows](https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example_workflows)",
              "score": 2,
              "created_utc": "2026-01-10 20:08:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyx6upv",
              "author": "rookiestar28",
              "text": "You could try this out: [ComfyUI-Doctor](https://github.com/rookiestar28/ComfyUI-Doctor)",
              "score": 2,
              "created_utc": "2026-01-11 05:03:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyu8r50",
          "author": "false79",
          "text": "dang that's cool.",
          "score": 1,
          "created_utc": "2026-01-10 19:39:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyudd0o",
          "author": "Ori_553",
          "text": "I was never able to generate a video even closely as good quality as this. Would it be possible for you to share the workflow file? Every time I try anyone's suggestions, they have additional changes they forgot to list or for one reason or another it still doesn't produce good results",
          "score": 1,
          "created_utc": "2026-01-10 20:02:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyudy4q",
          "author": "FantasticFeverDream",
          "text": "I‚Äôm hoping a Q8 or Q6 gguf will get me at least half as good with my 3090ti. üò¨",
          "score": 1,
          "created_utc": "2026-01-10 20:05:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyugf6e",
          "author": "djenrique",
          "text": "Great points! Can you show a more action packed clip and see if it provides a crisp result like this one?",
          "score": 1,
          "created_utc": "2026-01-10 20:17:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyuhmqo",
              "author": "000TSC000",
              "text": "Sure, il try more dynamic things.",
              "score": 1,
              "created_utc": "2026-01-10 20:23:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyuia5w",
          "author": "Euphoric-Ad1837",
          "text": "Insane",
          "score": 1,
          "created_utc": "2026-01-10 20:27:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyukl7i",
          "author": "MikeToMeetYou",
          "text": "Herb Welch",
          "score": 1,
          "created_utc": "2026-01-10 20:39:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyumt24",
          "author": "bob51zhang",
          "text": "Anyone tried with the spark yet?",
          "score": 1,
          "created_utc": "2026-01-10 20:50:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyuo2ju",
          "author": "superstarbootlegs",
          "text": "Wan switching to closed source leaves the field open for a take-over. LTX didnt look good enough for it, but if you are getting good results at high res then its just time until it improves for the LowVRAM mob.\n\nall of this requires herd interest because herd dictates what the devs will work on\n\nit is worth noting way back when Wan, Hunyuan, Skyreels were competing for position, the best was Skyreels for the same reason. It took a server farm to reach the resolutions it worked best at. As such it all but disappeared.\n\ntime will tell. the herd will dictate what happens next. but LTX is in with a good chance and I think that is why the CEO went open source, maybe he saw the opportunity.",
          "score": 1,
          "created_utc": "2026-01-10 20:56:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyuoyyr",
          "author": "Better-Interview-793",
          "text": "Now I feel poor with my RTX 5090",
          "score": 1,
          "created_utc": "2026-01-10 21:00:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyur34j",
              "author": "superstarbootlegs",
              "text": "spare a ram for an ex-leper? - 3060.",
              "score": 1,
              "created_utc": "2026-01-10 21:11:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyvmxl6",
                  "author": "Better-Interview-793",
                  "text": "I wish I had spare RAM, 64GB barely survives my workload",
                  "score": 2,
                  "created_utc": "2026-01-10 23:53:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyupb7a",
          "author": "infiernito",
          "text": "thats how i imagine androids in the near future",
          "score": 1,
          "created_utc": "2026-01-10 21:02:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyuq3bj",
          "author": "Choowkee",
          "text": "Yeah no shit...",
          "score": 1,
          "created_utc": "2026-01-10 21:06:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyus2a0",
          "author": "Pase4nik_Fedot",
          "text": "Yes, but when the camera moves, image defects may appear at the edges of the frame.",
          "score": 1,
          "created_utc": "2026-01-10 21:16:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyuuz1d",
          "author": "tofuchrispy",
          "text": "Also gotta test this with the RTX6000 at work \nThe 48fps trick\n\nYou generated the resolution in one sampling step? \n\nDid you use any vram arguments at startup? \n\nMy 1080p results weren‚Äôt good so far. Many artifacts and frames with error hands with motion. \n\n\nI struggled to render 400frames in 1080p \nI think it managed 393 frames somehow but took long. \n\nWith the two stage workflow it hangs at the upscaler stage for the 1080p upscaling. With 400frames ..",
          "score": 1,
          "created_utc": "2026-01-10 21:30:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyuwjsd",
          "author": "Myfinalform87",
          "text": "That‚Äôs why I run video models on Runpod. Personally I think it‚Äôs worth the cost",
          "score": 1,
          "created_utc": "2026-01-10 21:38:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyuwvqq",
          "author": "ocelot08",
          "text": "O_O",
          "score": 1,
          "created_utc": "2026-01-10 21:40:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyv18pm",
          "author": "hurrdurrimanaccount",
          "text": "i can run 1080p 20 seconds on a 3090. don't believe their lies. you do not need overpriced cards.",
          "score": 1,
          "created_utc": "2026-01-10 22:01:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyv37k0",
          "author": "Hodr",
          "text": "Everyone who walks behind her head disappears forever.",
          "score": 1,
          "created_utc": "2026-01-10 22:11:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyv4uew",
          "author": "agentgerbil",
          "text": "The best I got is my laptop 5070ti  with 12gb vram >_> (cries in laptop)",
          "score": 1,
          "created_utc": "2026-01-10 22:19:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyv5ld7",
          "author": "boisheep",
          "text": "I could buy a house with the cost of that graphics card.\n\n[https://www.etuovi.com/kohde/db3369?haku=M2391232641](https://www.etuovi.com/kohde/db3369?haku=M2391232641)\n\nDid you think I was joking?...\n\nActually what the hell...\n\n[https://www.google.com/maps/@63.3231705,30.0125471,3a,75y,341.96h,79.56t/data=!3m7!1e1!3m5!1s8IaizTIK\\_W9OPax36P21tw!2e0!6shttps:%2F%2Fstreetviewpixels-pa.googleapis.com%2Fv1%2Fthumbnail%3Fcb\\_client%3Dmaps\\_sv.tactile%26w%3D900%26h%3D600%26pitch%3D10.437520027895118%26panoid%3D8IaizTIK\\_W9OPax36P21tw%26yaw%3D341.95504676908223!7i16384!8i8192!5m1!1e4?entry=ttu&g\\_ep=EgoyMDI2MDEwNy4wIKXMDSoKLDEwMDc5MjA3M0gBUAM%3D](https://www.google.com/maps/@63.3231705,30.0125471,3a,75y,341.96h,79.56t/data=!3m7!1e1!3m5!1s8IaizTIK_W9OPax36P21tw!2e0!6shttps:%2F%2Fstreetviewpixels-pa.googleapis.com%2Fv1%2Fthumbnail%3Fcb_client%3Dmaps_sv.tactile%26w%3D900%26h%3D600%26pitch%3D10.437520027895118%26panoid%3D8IaizTIK_W9OPax36P21tw%26yaw%3D341.95504676908223!7i16384!8i8192!5m1!1e4?entry=ttu&g_ep=EgoyMDI2MDEwNy4wIKXMDSoKLDEwMDc5MjA3M0gBUAM%3D)\n\nIt's even in a town surrounded by shops and hardware stores...\n\nYou could fix it easy hardware stores are at walking distance.\n\nwhat the fuck?... did someone die?...\n\nDoes anyone want a house?....",
          "score": 1,
          "created_utc": "2026-01-10 22:23:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyv7mv0",
          "author": "ImUrFrand",
          "text": "the video motion is still jaggy, the taxis move like a slide show.\n\ni hope the audio model is updated to sound better than a poorly staged 64Kb mp3.",
          "score": 1,
          "created_utc": "2026-01-10 22:33:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyv85jf",
          "author": "mintybadgerme",
          "text": "For some reason it's demanding audio from me otherwise I can't generate.  If I try to generate without adding an audio track I get this error - \n\nInfo\nYou must provide an Audio Source\n\nAm I doing something wrong?",
          "score": 1,
          "created_utc": "2026-01-10 22:36:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyv9r0j",
          "author": "QikoG35",
          "text": "What model for the text encoder you guys using?",
          "score": 1,
          "created_utc": "2026-01-10 22:44:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyvbsge",
          "author": "papa_geo",
          "text": "AI is asking for upgrades?",
          "score": 1,
          "created_utc": "2026-01-10 22:54:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyvh0oe",
          "author": "Forsaken-Truth-697",
          "text": "Usually higher resolution means more quality, you didn't know that?",
          "score": 1,
          "created_utc": "2026-01-10 23:22:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyvlxjt",
          "author": "NES64Super",
          "text": "I am more interested in how LTX-2 can be used as a video2sound model, and then use wan for sound2video.",
          "score": 1,
          "created_utc": "2026-01-10 23:48:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyw5fg5",
              "author": "Scotty-Rocket",
              "text": "Just generate a lowres LTX2 video, then use basically any video editing software and seperate the audio....then s2v in wan.",
              "score": 1,
              "created_utc": "2026-01-11 01:31:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyvngj6",
          "author": "Other_b1lly",
          "text": "I have a question: are these videos made using only prompts or do they use an output image?",
          "score": 1,
          "created_utc": "2026-01-10 23:56:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyw5ode",
          "author": "Guilty_Emergency3603",
          "text": "Seems like a better prompt adherence with res2s, that indicates that 20 steps with Euler is clearly not enough.\n\nThe second pass with res2s is I think not necessary as there is very little difference vs gradient estimation. leading even on a 5090 with OOM beyond 720p when >200 frames.",
          "score": 1,
          "created_utc": "2026-01-11 01:32:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nywg8pq",
              "author": "000TSC000",
              "text": "The 2nd stage is what actually upscales it though, or are you suggesting to upscale using another tool?",
              "score": 1,
              "created_utc": "2026-01-11 02:29:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyz008i",
                  "author": "Guilty_Emergency3603",
                  "text": "I'm saying using res\\_2s sampler on the second pass doesn't really worth since it is X2 longer and only makes very small enhancements vs another sampler like gradient estimation. And leads anyway to OOM with a 5090. on 720p+",
                  "score": 1,
                  "created_utc": "2026-01-11 13:59:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nywegax",
          "author": "pegoff",
          "text": "how do you fix the tinny audio so it doesn't sound like a segue to 50-year-old dad tai chi ads?",
          "score": 1,
          "created_utc": "2026-01-11 02:19:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyxrnu0",
              "author": "MrWeirdoFace",
              "text": "You adr it. I've actually yet to hear good audio from even the big online ones. I think they're holding that back intentionally to cover their asses so people can still tell it's AI, as I've heard Audio Only models that sound fantastic.",
              "score": 2,
              "created_utc": "2026-01-11 07:48:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nywetnu",
          "author": "StarskyNHutch862",
          "text": "Girl got that 1000 mile reddit stare.",
          "score": 1,
          "created_utc": "2026-01-11 02:22:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2y1n6",
              "author": "No_Possession_7797",
              "text": "She's just waiting for that guy who will walk a 1000 miles to fall down at her door.",
              "score": 1,
              "created_utc": "2026-01-12 01:25:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nywglic",
          "author": "comfyui_user_999",
          "text": "Nice! As good as the video is (and it's \\*good\\*, ignore the haters, they are thick in here), I'm almost more impressed with your ZiT first frame.  How'd you get that?  There's a workflow in that PNG you provided, but it's just the SeedVR2 upscale; what was the original?",
          "score": 1,
          "created_utc": "2026-01-11 02:31:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyx5adr",
          "author": "alexds9",
          "text": "LTX-2 (gguf q8) is only zooming-in on image I use, and almost nothing is moving in the image, 960x1440 10 seconds. I don't get it.",
          "score": 1,
          "created_utc": "2026-01-11 04:53:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyx6vkh",
              "author": "000TSC000",
              "text": "Make sure nothing raunchy is in your prompt or gemma3 destroys movement on encoding.",
              "score": 3,
              "created_utc": "2026-01-11 05:03:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyx8olm",
                  "author": "alexds9",
                  "text": "I had things like \"seductive and sexy\" in the prompt. So even that will generate some sort of empty encoding like \"I can't help you with that\", and the video model basically left without prompt?!  How can you do anything with such model?!",
                  "score": 1,
                  "created_utc": "2026-01-11 05:15:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyx8l52",
          "author": "reyzapper",
          "text": "Agreed. With strongerr hardware, the weak parts of the model are basically hidden.  \nThat said, the background is a jittery mess.",
          "score": 1,
          "created_utc": "2026-01-11 05:14:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxio8h",
          "author": "Kind-Access1026",
          "text": "RTX 6000 Pro took 15 min, I prefer using Kling",
          "score": 1,
          "created_utc": "2026-01-11 06:30:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxiwp2",
          "author": "fernando782",
          "text": "Off topic Question, LTX 2 is heavily censored right?",
          "score": 1,
          "created_utc": "2026-01-11 06:32:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxj0ul",
          "author": "Dry_Positive8572",
          "text": "You are not rich but have 128G RAM and RTX 6000 PRO. Guess LTX-2 is also very rich people's model like Flux models.",
          "score": 1,
          "created_utc": "2026-01-11 06:33:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxmqjz",
          "author": "No-Tie-5552",
          "text": "Can it be used with a driving video yet?",
          "score": 1,
          "created_utc": "2026-01-11 07:05:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxrbl0",
          "author": "fantazart",
          "text": "The updated version with 60fps looks really good.  But I guess the question is then how long did that take? You should also do a i2v comparison against wan22. Btw is the resolution you stated here the final resolution or the first sampler resolution which means the final resolution would be double.",
          "score": 1,
          "created_utc": "2026-01-11 07:45:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxv9hh",
          "author": "barepixels",
          "text": "Wow",
          "score": 1,
          "created_utc": "2026-01-11 08:21:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxx0d5",
          "author": "moschles",
          "text": "Does anyone know why diffusion generators can get every single eyebrow hair correct, while messing up text this badly?",
          "score": 1,
          "created_utc": "2026-01-11 08:37:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyy0bpu",
          "author": "Cadmium9094",
          "text": "Thanks for the tips! I‚Äôm still on the fence about the 6000 Pro since this is just a hobby and I‚Äôm not making money from it. My 4090 with 128 GB of RAM already runs the models well enough for what I do.\nThat‚Äôs why I‚Äôm wondering if renting GPUs isn‚Äôt actually the cheaper option in the long run?",
          "score": 1,
          "created_utc": "2026-01-11 09:08:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyy1od5",
          "author": "JahJedi",
          "text": "Agree in 1920x1088 its much better. 15 sec clip in 6 minutes.",
          "score": 1,
          "created_utc": "2026-01-11 09:21:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyyf3l1",
          "author": "Basic_Text_3555",
          "text": "If you use Multigpu nodes (checkpoint distorch2 node in case of LTX-2) you can offload the whole model to RAM. Works for WAN too (Unet distorch2 loader). Allows you to precisely control how much you offload.",
          "score": 1,
          "created_utc": "2026-01-11 11:24:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyyf7nj",
              "author": "Basic_Text_3555",
              "text": "with native wan wf i am able to do 1920x1088x81 frames on a 5090 with an fp16 model",
              "score": 1,
              "created_utc": "2026-01-11 11:25:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyyh0xf",
          "author": "SpacMar40k",
          "text": "looks amazing, still getting used to wan2.2 though",
          "score": 1,
          "created_utc": "2026-01-11 11:41:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyyhdhh",
          "author": "Clqgg",
          "text": "sign is warping alot",
          "score": 1,
          "created_utc": "2026-01-11 11:44:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyyiaet",
          "author": "LadenBennie",
          "text": "When I do fps to 60, the audio becomes to short, why?",
          "score": 1,
          "created_utc": "2026-01-11 11:52:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyyr2gn",
          "author": "skyrimer3d",
          "text": "VVYANIAA sure has a lot of taxyis in that city. Jokes aside though, it's incredible how far we've come in terms of local AI, even though it's still far from perfect.",
          "score": 1,
          "created_utc": "2026-01-11 13:01:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyz6wjg",
          "author": "Conscious_Arrival635",
          "text": "so what about rtx5090? laughing in top end of consumer graphics",
          "score": 1,
          "created_utc": "2026-01-11 14:38:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyzgtva",
          "author": "Bobby-Lemon",
          "text": "Greatt!! What are the specs of the rest of your build? What is the processor model you use?",
          "score": 1,
          "created_utc": "2026-01-11 15:30:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyzooo2",
          "author": "birdmilk",
          "text": "As a Canadian I am appalled T not seeing her breath when clearly it‚Äôs cold out",
          "score": 1,
          "created_utc": "2026-01-11 16:08:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyzzm66",
          "author": "exitof99",
          "text": "I feel for the cars curb-locked in the distance. They'll never get home again.",
          "score": 1,
          "created_utc": "2026-01-11 16:59:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz08t90",
          "author": "No_Truck_88",
          "text": "The background is glitching in real-time üíÄ",
          "score": 1,
          "created_utc": "2026-01-11 17:43:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0mza1",
          "author": "ponderingpixi17",
          "text": "Great to see how powerful the RTX 6000 Pro can be, but let‚Äôs see some more varied tests instead of just close-ups.",
          "score": 1,
          "created_utc": "2026-01-11 18:46:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0rw4z",
          "author": "WestCoastDirtyBird",
          "text": "She's on shrooms lol",
          "score": 1,
          "created_utc": "2026-01-11 19:08:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4qwaq",
              "author": "ThexDream",
              "text": "Def has a future in AI  orn though. Maybe because of that.",
              "score": 1,
              "created_utc": "2026-01-12 08:45:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz23dck",
          "author": "Fun_Ad7316",
          "text": "I noticed other two weird things: the model is very picky for the image input. If the image even slightly does not match the prompt description, most probably you get still image video or frame cut. Sometimes giving images with black padding on top and bottom helps to avoid still images.",
          "score": 1,
          "created_utc": "2026-01-11 22:48:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz70edl",
          "author": "SenatusScribe",
          "text": "If someone wants to make a billion dollars, figure out how to let advertisers embed ads into ai-generated content..... you can thank me later torment nexus.",
          "score": 1,
          "created_utc": "2026-01-12 17:19:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyvbl5y",
          "author": "Alive-Tomatillo5303",
          "text": "ComfyUI is so goddamn terrible, I wish people would stop fellating it. It's like it was designed by someone from the 70's who'd never seen a GUI and had to make it up from scratch.¬†\n\n\nThere are alternatives that aren't ugly, stupid ass spaghetti.¬†",
          "score": 1,
          "created_utc": "2026-01-10 22:53:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nywcpxa",
              "author": "TheeIronSwan",
              "text": "What are they?",
              "score": 1,
              "created_utc": "2026-01-11 02:10:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nywgkyp",
                  "author": "Alive-Tomatillo5303",
                  "text": "SwarmUI is a wrapper for comfyUI, which is cheating but it's what I've been using for Z-Image. The main program I use for the best experience is [Pinokio](https://pinokio.co/).\n\n\nYou know what the steps and \"workflow\" are for using LTX2 through Pinokio?¬†\n\n\n-Select Wan2GP, which is the kinda, universal video generator subprogram. This downloads the program and opens it.¬†\n\n\n-Select LTX-2 from the list. This downloads the program and opens it.¬†\n\n\n-Select from \"Text Prompt Only\" out of the options at the top. Then write your text in the prompt.¬†\n\n\n-Select, from labeled lists, resolution, aspect ratio, and length of video, and hit \"Generate\".¬†\n\n\n**THEEEEEE END**\n\n\nYou might notice nowhere in that process did you have to consult with an online guide, manually download a missing file after combing through error messages, or feed a railway network through 14 bespoke terminals in exactly the right order. You just pick what you want to do, and it does it.¬†",
                  "score": 1,
                  "created_utc": "2026-01-11 02:31:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyuxg83",
          "author": "HolidayEnjoyer32",
          "text": "its so much worse than wan2.2",
          "score": 1,
          "created_utc": "2026-01-10 21:42:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyvlos1",
          "author": "Dark_Pulse",
          "text": "Sure thing. I'll happily buy an RTX 6000 Pro, as soon as someone gives me $8000+ to do it.\n\nAny volunteers with money to burn in their bank accounts for a stranger on the internet?",
          "score": 1,
          "created_utc": "2026-01-10 23:47:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyu7qna",
          "author": "BeyondTheGrave13",
          "text": "this is the best video i've seen with ltx2 and audio not bad.",
          "score": 0,
          "created_utc": "2026-01-10 19:34:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyubrks",
          "author": "Secure-Message-8378",
          "text": "Great quality!",
          "score": 0,
          "created_utc": "2026-01-10 19:54:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q7kygr",
      "title": "LTX-2 team literally challenging Alibaba Wan team, this was shared on their official X account :)",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/kb2unrk7d6cg1",
      "author": "CeFurkan",
      "created_utc": "2026-01-08 19:13:36",
      "score": 895,
      "num_comments": 133,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q7kygr/ltx2_team_literally_challenging_alibaba_wan_team/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nygemwe",
          "author": "NoHopeHubert",
          "text": "Exciting! The only major ups that wan has right now is that it keeps I2V consistency a lot better and of course has inherent NSFW support.",
          "score": 98,
          "created_utc": "2026-01-08 19:30:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygh407",
              "author": "Orbiting_Monstrosity",
              "text": "Wan also mixes concepts very well. ¬†With Wan I can make things like a half-crab, half-man with hybrid features or a giant disembodied head rolling down a mountain. ¬†I haven‚Äôt achieved anything like that even once so far with LTX-2 using T2V alone and I‚Äôm not sure if that has more to do with how I am writing my prompts or limitations of the model.",
              "score": 39,
              "created_utc": "2026-01-08 19:41:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nygnce2",
                  "author": "Klutzy-Snow8016",
                  "text": "Are you using the distilled lora? I would expect that to reduce the variety it can generate. All of the workflows seem to have it enabled by default. I haven't tried without it, actually, so I don't know if that's the cause of it, though.\n\nEdit: never mind, this is wrong information",
                  "score": 6,
                  "created_utc": "2026-01-08 20:08:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyrtmgt",
                  "author": "shivu98",
                  "text": "I believe you are working on some movie in which there is shapeshifting and weird creatures? would love to know more about it, I am working on something similar.",
                  "score": 1,
                  "created_utc": "2026-01-10 11:52:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyihdsk",
                  "author": "Perfect-Campaign9551",
                  "text": "Ltx can't even make a realistic cat video like a cat cooking food. It always creates a cartoon cat\n\n\nI'm wondering what other weaknesses this model has then as well.¬†",
                  "score": 1,
                  "created_utc": "2026-01-09 01:23:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyh5yn9",
              "author": "Nextil",
              "text": "The only real *advantage* it has over Wan is that it's faster (and has shitty audio I guess). The prompt adherence seems worse from my testing, and I see a lot of occlusion glitches and anatomical issues especially with fast motion. I don't know why people seem to undervalue prompt adherence so much. We shouldn't need 50GB of LoRAs (which do not combine well and affect the whole image) just to get anything interesting to actually work properly. Who cares if you can generate 4 times faster if none of the outputs actually do what you want.",
              "score": 25,
              "created_utc": "2026-01-08 21:31:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyhme54",
                  "author": "UnforgottenPassword",
                  "text": "I agree that Wan has way better prompt adherence and its I2V is really good. LTX2 has I2V in name only.¬†\n\n\nWan's 5 second length is way too limiting though. Native 10 second (or more) would have been awesome.¬†",
                  "score": 7,
                  "created_utc": "2026-01-08 22:44:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyhnv5k",
                  "author": "thisiztrash02",
                  "text": "wan slow motion ruins any positive traits it has because it all looks fake at that speed",
                  "score": 6,
                  "created_utc": "2026-01-08 22:51:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nykril2",
                  "author": "Front-Relief473",
                  "text": "I agree with you. The ability to follow the prompt is the first element of the controllability of the video model, other aesthetic feelings are that less important.",
                  "score": 1,
                  "created_utc": "2026-01-09 11:07:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nylbr5j",
                  "author": "seeker_ktf",
                  "text": "Not to insult anyone, but this happens everytime a new model comes out. The first wave of people that call every new introduction \"insane\" fire stuff off and hype the hell out of everything. They aren't actually trying to DO anything specific. They just want to be first.\n\nThen others come along and try to see if its useful for their purposes. They actually test the stuff. They put it through its paces. It's a completely different group.\n\nBoth groups have a place in the community, and admittedly there is sometimes conflict between them too. But thats why one person generating 10 seconds of crap 480p video that they upscale to 4K will be happy when someone else generating 5 seconds of native 720p will be horrified. It's all just different interests.",
                  "score": 1,
                  "created_utc": "2026-01-09 13:27:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nykl3tq",
              "author": "RabbitEater2",
              "text": "And also actually follows the prompt for more than the very basic concepts.",
              "score": 1,
              "created_utc": "2026-01-09 10:11:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nygh7ni",
              "author": "icchansan",
              "text": "There‚Äôs a ff2lf already",
              "score": 0,
              "created_utc": "2026-01-08 19:41:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nypygyq",
                  "author": "Old-Day2085",
                  "text": "Can you share the ComfyUI workflow please?",
                  "score": 1,
                  "created_utc": "2026-01-10 02:58:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyir06j",
          "author": "Silly_Goose6714",
          "text": "https://i.redd.it/ol33y2xdg8cg1.gif",
          "score": 31,
          "created_utc": "2026-01-09 02:14:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nymt868",
              "author": "Glad-Mix9923",
              "text": "![gif](giphy|pUeXcg80cO8I8)",
              "score": 2,
              "created_utc": "2026-01-09 17:40:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nygh79g",
          "author": "Spezisasackofshit",
          "text": "I am 100% in favor of them competing if it drives both models to improve faster. Heck even if they just keep up the rate they have so far that would be great. LTX-2 is so much better than the original but is a little inconsistent in my testing so far. \n\nIn a perfect world LTX-2 might make the WAN team try to compete on size and speed with a WAN mini/turbo of some kind with the next generation which would be amazing.",
          "score": 34,
          "created_utc": "2026-01-08 19:41:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyh6gxk",
          "author": "-Ellary-",
          "text": "True true, model is good but there is a nuances:\n\n\\- Usually only 1 out of 5-6 videos generated on LTX-2 is usable vs 1 out of 2-3 for WAN 2.2.  \n\\- Difference in prompt preparation, I'm wasting a LOT more time fiddling with prompt for LTX-2 vs WAN: \"woman bounce, smiling\" is a legit and perfectly fine prompt for WAN especially for i2v.  \n\\- They showing WAN gen time without lighting 4 step loras.  \n\\- For me it is 200\\~ secs vs 250 secs for WAN at 4 steps using 5060 ti 16gb.  \n\\- WAN can do suggestive scenes from the box, LTX-2 have censorship.  \n\\- License of LTX-2 is way closer to Flux 2's license.",
          "score": 34,
          "created_utc": "2026-01-08 21:33:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyhfo9u",
              "author": "martinerous",
              "text": "Yeah, I'll be eagerly waiting for their planned LTX 2.5 release with improved latent space. Maybe that will help with prompt adherence. Otherwise WAN is still better for complex and weird storytelling.",
              "score": 5,
              "created_utc": "2026-01-08 22:13:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nynbxi5",
              "author": "IrisColt",
              "text": ">woman bounce, smiling\n\n\nthe poetical \"woman bounce\" or the prosaic \"woman bounce\"?",
              "score": 1,
              "created_utc": "2026-01-09 19:03:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nygd2ne",
          "author": "ajrss2009",
          "text": "LTX 2 has a huge space to become the best open source model for video generation.",
          "score": 56,
          "created_utc": "2026-01-08 19:23:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygjdax",
              "author": "Pure_Bed_6357",
              "text": "if it can do booba then sure",
              "score": 42,
              "created_utc": "2026-01-08 19:51:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nygk7yf",
                  "author": "NeatUsed",
                  "text": "can it though?",
                  "score": 16,
                  "created_utc": "2026-01-08 19:54:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyix0z7",
                  "author": "Lost_County_3790",
                  "text": "I don't care about Booba but if it's the only model that push new release open, then it will be the king",
                  "score": 1,
                  "created_utc": "2026-01-09 02:46:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyhhrme",
          "author": "SardinePicnic",
          "text": "This is kind of annoying. I am still using WAN over LTX right now because WAN is better at creativity and making things we haven't seen before. If I want an alien planet with a giant pink and blue squishy thing with a mouth and tentacles while shrouded people dance around it with black onyx rocks bounce up and down I get that with WAN. I CANNOT get stuff like that with LTX because it has been trained to strive for realism and not hallucinatory. And sometimes my crazy prompts will actually work with LTX but the comparison to WAN is night and day. One looks like a complete fever dream of visuals you have never seen before the other looks like a vague appropriation of that prompt using humans and scenes you have seen 100 times. So to try and flex on WAN like this is just eye rolling to me considering WAN is still the better model I would use for more creative and new unseen visuals and I will wait however long it takes for that to happen. Watch the video again and ask yourself honestly... Is ANYTHING in that video something you have not seen before in some kind of capacity? Yes. Nothing in that video is something that completely transcends its training data.",
          "score": 7,
          "created_utc": "2026-01-08 22:23:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygjnha",
          "author": "MammothMatter3714",
          "text": "It is definitely fast and fun to play with. But right now prompt adherence, dynamic movement and ESPECIALLY video quality are lacking, even at 1080p. I think that's why they don't show the Wan results in this video. But I get that LTX 2 is just out of the box. Hopefully it gets better soon just like Wan did.",
          "score": 15,
          "created_utc": "2026-01-08 19:52:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyihvcy",
              "author": "Perfect-Campaign9551",
              "text": "That's because it doesn't actually render at 1080p and I think a lot of people are entirely ignorant of that fact\n\n\nIt renders at 1/2 your stated resolution and then it does an AI upscale pass and I'm finding it's videos ten to be rather blurry",
              "score": 2,
              "created_utc": "2026-01-09 01:26:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyjcymt",
                  "author": "michaelsoft__binbows",
                  "text": "I want the upscale pass extracted... for use with wan",
                  "score": 1,
                  "created_utc": "2026-01-09 04:16:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyi6y0v",
          "author": "etupa",
          "text": "If only it could make wan guys giving the open source community another model...",
          "score": 5,
          "created_utc": "2026-01-09 00:28:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygff72",
          "author": "Obvious_Set5239",
          "text": "But they are not \"both open source\". Wan 2.2 is a truly open source model with permissive Apache 2.0 license, that mea future researchers are allowed to use it as base, but LTX-2 has non-commercial license with other usage restrictions, and the same not fully open source text encoder",
          "score": 19,
          "created_utc": "2026-01-08 19:33:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygobvg",
              "author": "Spezisasackofshit",
              "text": "As someone who isn't a corporation making 10 million dollars or planning to break any of their \"don't be evil\" clauses does it really matter? After a fairly close read of the license  (https://github.com/Lightricks/LTX-2/blob/main/LICENSE)  I don't see anything in their license that is restrictive to anyone but corporations or people wanting to slap their own licenses on the model/derivative models.\n\nI get that this stymies some people who want to develop on it for profit but do those people even matter as they won't contribute their work to the open source community anyway?",
              "score": 6,
              "created_utc": "2026-01-08 20:13:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nygt2oe",
                  "author": "Obvious_Set5239",
                  "text": ">As someone who isn't a corporation making 10 million dollars or planning to break any of their \"don't be evil\" clauses does it really matter?\n\nIt does matter because we won't receive models from smaller teams based on this model. Open source project can live forever with small amount of money, but non-commercial licensed projects are short-term\n\nAlso you say like commercial usage is something evil. But commercial usage doesn't damage community at all, because who wants to run it locally - they can. But it gives ability for people with no GPU to run models for cheap. Also it's an issue of who controls the code and the model. As an open source developer myself, I don't receive money for it, but I will never contribute for a project that is not open. Not because I want to sell it, but because I want to know that my contribution is free (freedom). Nobody will work knowing that they are helping another company to essentially improve their closed source project. A lot of open source projects live because of small contributors. AI is not an exception",
                  "score": 10,
                  "created_utc": "2026-01-08 20:34:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nygtaoa",
                  "author": "Smile_Clown",
                  "text": ">As someone who isn't a corporation making 10 million dollars or planning to break any of their \"don't be evil\" clauses does it really matter?\n\nOf course not, it never does, but getting angry about something that does not affect anyone but corporations (but not mentioning that and making it seem like it affects \"you\") is all the rage and gains karma. The person you are replying to bang angry on keyboard, sat back and waited for the karma for being the smart one in the room.\n\nThis is misinformation in it's purest form.  (missing info)",
                  "score": -1,
                  "created_utc": "2026-01-08 20:35:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nygj2kz",
          "author": "a_beautiful_rhind",
          "text": "Shots fired.",
          "score": 6,
          "created_utc": "2026-01-08 19:49:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygmek8",
              "author": "Hoodfu",
              "text": "Yeah, that part where it repeatedly shows ltx rendering and finished and wan never even finishes once is pretty funny.",
              "score": 6,
              "created_utc": "2026-01-08 20:04:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nygxl36",
          "author": "WildSpeaker7315",
          "text": "guys keep hyping the shit out of LTX2 so wan turn around and drop 2.5 for us. lol 2026 will be a good year",
          "score": 8,
          "created_utc": "2026-01-08 20:54:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyk29vu",
              "author": "atuarre",
              "text": "Higgsfield bought the rights to WAN 2.5. How can so many of you be so clueless?",
              "score": 3,
              "created_utc": "2026-01-09 07:20:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyka9wk",
                  "author": "WildSpeaker7315",
                  "text": "Fair, let's make ltx work then!",
                  "score": 1,
                  "created_utc": "2026-01-09 08:31:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nynnmba",
                  "author": "Orik_Hollowbrand",
                  "text": "There is a differnce between not knowing something and being \"clueless\".",
                  "score": 1,
                  "created_utc": "2026-01-09 19:56:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nylay2p",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2026-01-09 13:22:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nylbo8n",
                  "author": "WildSpeaker7315",
                  "text": "well if higgsfield bought the rights it wont matter",
                  "score": 1,
                  "created_utc": "2026-01-09 13:26:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyn084l",
              "author": "JimmyDub010",
              "text": "Yep",
              "score": 1,
              "created_utc": "2026-01-09 18:11:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyn0c5u",
              "author": "JimmyDub010",
              "text": "I honestly can't stop playing with ltx2. it's so fun even if I have to change prompts a lot to get what I want.",
              "score": 1,
              "created_utc": "2026-01-09 18:12:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyi6tvf",
          "author": "ImaginationKind9220",
          "text": "It's good that there are competitions, but LTX still feels like an experimental model. Sometimes it works, sometimes not. WAN is working every time, that's the difference. Also, LTX is marketing LTX 2 as \"Production Ready\", are they hallucinating? Productions studios are not making AI slops.",
          "score": 3,
          "created_utc": "2026-01-09 00:28:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyhwcis",
          "author": "Tybost",
          "text": "It's good to have another OpenSource option on the table next to Wan & Hunyuan, but I'm not convinced it's taken the #1 spot yet. Audio and Speed aren't the only things that matter to me.",
          "score": 5,
          "created_utc": "2026-01-08 23:34:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyhyupm",
              "author": "_Just_Another_Fan_",
              "text": "Same here",
              "score": 1,
              "created_utc": "2026-01-08 23:47:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyl7tn3",
              "author": "MrUtterNonsense",
              "text": "I would have considered subscribing to the Ltx studio site, but their privacy terms are a disaster area. They can train on anything you do and license it to anyone else in perpetuity.",
              "score": 1,
              "created_utc": "2026-01-09 13:04:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nygv8qz",
          "author": "Kooky-Menu-2680",
          "text": "I dont know if this question been asked : is it uncensored?",
          "score": 2,
          "created_utc": "2026-01-08 20:44:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyiuna3",
              "author": "EternalBidoof",
              "text": "Kinda? Nipples sometimes look passable, but it's barbie doll downstairs. Also it will frequently not listen to prompts for nudity, especially in scene locations where nudity is not commonly found. For example, prompts for nudity in public spaces usually result in a bikini, but prompting for nudity in a private home will much more frequently give you what was asked.",
              "score": 4,
              "created_utc": "2026-01-09 02:34:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyjvkrf",
                  "author": "Kooky-Menu-2680",
                  "text": "So simply , its not worth to try .",
                  "score": 6,
                  "created_utc": "2026-01-09 06:25:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyh9h2d",
          "author": "AlibabasThirtyThiefs",
          "text": "\"one built for production\" DAMN STRAIGHT.   \nGlad there's still good in the world cuz MAN it was looking like a completely depressing end. Wan was probably bein all \"eh we know theyre not gonna have RAM or GPUs anyways so why bother\"    \n\nLTX comin in CLUTCH!",
          "score": 2,
          "created_utc": "2026-01-08 21:46:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyk2di1",
          "author": "verocious_veracity",
          "text": "What I just found out they're Israelis. Lol.",
          "score": 4,
          "created_utc": "2026-01-09 07:21:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyrafu1",
              "author": "hydewulf",
              "text": "Yeah zionist.",
              "score": 2,
              "created_utc": "2026-01-10 08:56:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyjkho9",
          "author": "StacksGrinder",
          "text": "Oh I can't wait what WAN will come back with, A witty reply, A monster ready to be unleashed, LTX can mock them all they want, But I can assure you, You've poked the beast.",
          "score": 2,
          "created_utc": "2026-01-09 05:03:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyk22mw",
              "author": "atuarre",
              "text": "I doubt it considering they sold 2.5 to Higgsfield. Wan is all about the money.",
              "score": 1,
              "created_utc": "2026-01-09 07:18:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nynnxvb",
                  "author": "Orik_Hollowbrand",
                  "text": "Unlike LTX, which is made by a hippie commune of blind nuns.",
                  "score": 1,
                  "created_utc": "2026-01-09 19:58:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nygkdjj",
          "author": "MHIREOFFICIAL",
          "text": "so are there spicy loras for this yet?",
          "score": 2,
          "created_utc": "2026-01-08 19:55:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygn5lh",
              "author": "jonnytracker2020",
              "text": "Repent",
              "score": 6,
              "created_utc": "2026-01-08 20:07:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nygofa7",
                  "author": "MHIREOFFICIAL",
                  "text": "Neigh, neigh, whinney",
                  "score": 2,
                  "created_utc": "2026-01-08 20:13:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nygqomz",
                  "author": "jazzamp",
                  "text": "You're both right",
                  "score": 2,
                  "created_utc": "2026-01-08 20:23:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nygjymv",
          "author": "Noeyiax",
          "text": "Damn, fire music choice too üòÇ cooool",
          "score": 1,
          "created_utc": "2026-01-08 19:53:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygu87m",
          "author": "No_Statistician2443",
          "text": "Wild üî•",
          "score": 1,
          "created_utc": "2026-01-08 20:39:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygxjmc",
          "author": "AppealThink1733",
          "text": "I love it.",
          "score": 1,
          "created_utc": "2026-01-08 20:54:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyhn0va",
          "author": "UnforgottenPassword",
          "text": "Why half of my LTX2 generations are black and white 60s videos?",
          "score": 1,
          "created_utc": "2026-01-08 22:47:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyiacp0",
          "author": "OkTransportation7243",
          "text": "Can ltx 2 do first frame to last frame?",
          "score": 1,
          "created_utc": "2026-01-09 00:46:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyjco1e",
          "author": "Icy_Foundation3534",
          "text": "competition is good ya'll",
          "score": 1,
          "created_utc": "2026-01-09 04:14:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyjpu2m",
          "author": "ANR2ME",
          "text": " It's nice to see the denoising process slowly like this üëç",
          "score": 1,
          "created_utc": "2026-01-09 05:40:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyjvhkk",
          "author": "Great_Traffic1608",
          "text": "wan not Update ,wan dead",
          "score": 1,
          "created_utc": "2026-01-09 06:24:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyjy3mi",
          "author": "xyzdist",
          "text": "Release WAN! Now!",
          "score": 1,
          "created_utc": "2026-01-09 06:45:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyka23w",
          "author": "bakarban_",
          "text": "im into this shit dude. some competition would output some crazy good stuff",
          "score": 1,
          "created_utc": "2026-01-09 08:29:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nykbw5q",
          "author": "enterme2",
          "text": "When wan 2.5 is open sourced probably would easily smash ltx-2",
          "score": 1,
          "created_utc": "2026-01-09 08:46:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nykp75a",
          "author": "Chilangosta",
          "text": "I don't know what their play is but it's entertaining üçø",
          "score": 1,
          "created_utc": "2026-01-09 10:47:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyktc3c",
          "author": "Mid-Pri6170",
          "text": "ltx, is it a new model or a new suite of tools or something else?\n\n(old skool ai'er back after a 3 year haitus)",
          "score": 1,
          "created_utc": "2026-01-09 11:22:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyl12t7",
          "author": "Perfect-Campaign9551",
          "text": "Speed isn't everything.¬†",
          "score": 1,
          "created_utc": "2026-01-09 12:20:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nym1ky8",
          "author": "CalamityCommander",
          "text": "When they mention \"same prompt\" did they write a neutral prompt, or did they optimize to work with LTX better than the rest? Still impressive",
          "score": 1,
          "created_utc": "2026-01-09 15:36:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nym2jdm",
          "author": "Holdthemuffins",
          "text": "Empirically, wan 2.2 keeps image to video face and body consistency far better than ltx-2. Until that improves, the generation speed up has no value for me.",
          "score": 1,
          "created_utc": "2026-01-09 15:40:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nymorfb",
          "author": "cardioGangGang",
          "text": "All the ltx videos look like plastic. Audio is pointless since it'll be replaced¬†",
          "score": 1,
          "created_utc": "2026-01-09 17:20:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nync1vq",
          "author": "Jimmm90",
          "text": "Alibaba is about to come with the HEAT. Competition is good for all of us!",
          "score": 1,
          "created_utc": "2026-01-09 19:03:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nynohlx",
          "author": "Orik_Hollowbrand",
          "text": "lol, \"we can make shite at 200x the speed! WE ARE LE CHAMP1ON!\". Calm down.",
          "score": 1,
          "created_utc": "2026-01-09 20:00:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nynorya",
          "author": "Phuckers6",
          "text": "https://preview.redd.it/f3l4undmqdcg1.png?width=425&format=png&auto=webp&s=190b5971d98a4d3468986709ba28698b9397beb0\n\nThey can't get the hands right even in the few best examples they picked out.",
          "score": 1,
          "created_utc": "2026-01-09 20:01:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyw6zcl",
          "author": "PaceDesperate77",
          "text": "Fucking love competition - this might push alibaba to push wan2.5 and wan2.6 into open source and actually make them better",
          "score": 1,
          "created_utc": "2026-01-11 01:40:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxoa7d",
          "author": "extra2AB",
          "text": "apart from the generation time, quality-wise WAN is far superior. and this is after NVIDIA hashelped LTX team to optimize it for NVIDIA GPUs.\n\nand another being audio generation.\n\nSO LTX 2.5 really needs to up the game.",
          "score": 1,
          "created_utc": "2026-01-11 07:18:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygnbb7",
          "author": "merkidemis",
          "text": "Now if I can just get the f-ing models and workflow to work in ComfyUI...",
          "score": 1,
          "created_utc": "2026-01-08 20:08:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyh0ggs",
              "author": "sebisebman",
              "text": "same here - no luck so far...",
              "score": 1,
              "created_utc": "2026-01-08 21:07:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyhf1v2",
                  "author": "martinerous",
                  "text": "Shamelessly plugging in my minimalistic workflow:  \n[https://www.reddit.com/r/StableDiffusion/comments/1q7gzrp/ltx2\\_multi\\_frame\\_injection\\_works\\_minimal\\_clean/](https://www.reddit.com/r/StableDiffusion/comments/1q7gzrp/ltx2_multi_frame_injection_works_minimal_clean/)  \nLet me know what exactly does not work for you.",
                  "score": 1,
                  "created_utc": "2026-01-08 22:10:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyn0xds",
              "author": "JimmyDub010",
              "text": "Use wan2gp and skip all the workflow crap. downloads everything for you and has ltx2 support out of the box",
              "score": 1,
              "created_utc": "2026-01-09 18:14:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyhephf",
          "author": "skyrimer3d",
          "text": "So glad WAN is getting kicked in the balls after abandoning the community that made them great and getting greedy, LTX2 ftw!!!",
          "score": 0,
          "created_utc": "2026-01-08 22:09:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyjkksz",
          "author": "Baddabgames",
          "text": "RELEASE THE WAN 2.5 FILES!",
          "score": 0,
          "created_utc": "2026-01-09 05:04:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyk1xmh",
              "author": "atuarre",
              "text": "Higgsfield owns Wan 2.5",
              "score": 1,
              "created_utc": "2026-01-09 07:17:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyh5tno",
          "author": "Sudden_List_2693",
          "text": "I... hope they disappear soon.",
          "score": -6,
          "created_utc": "2026-01-08 21:30:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyjuc02",
              "author": "juandann",
              "text": "huh? why? you don't like competition and advancements?",
              "score": 1,
              "created_utc": "2026-01-09 06:15:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyk2ivz",
                  "author": "Sudden_List_2693",
                  "text": "I hate cocky dipshits with false advertisements.   \nThey compared that \"18x speed\" to their default downscaled-upscaled shit.  \nThat \\_normal\\_ WAN using the official full step workflow at 1280x720 is 18 times slower is true... compared to their \"official\" workflow, with insufficient step and downscaled 20, upscaled 3 steps.  \nIf they don't use that upscaling (which is by the way by far some of the worst in the whole industry so far) it's already only 4.5x faster.   \nIf they use 4-6 steps WAN, it's roughly the same time.",
                  "score": 3,
                  "created_utc": "2026-01-09 07:22:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nygn02g",
          "author": "jonnytracker2020",
          "text": "What a joke .. wan can run in 8 vram .. 16 gb is not enough for LTX 2",
          "score": -10,
          "created_utc": "2026-01-08 20:07:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygrs04",
              "author": "ArkCoon",
              "text": "you can literally run LTX with no vram at all. What are you talking about?",
              "score": 8,
              "created_utc": "2026-01-08 20:28:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyit17g",
                  "author": "jonnytracker2020",
                  "text": "What a joke . Don‚Äôt spew nonsense",
                  "score": -2,
                  "created_utc": "2026-01-09 02:25:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nygtnik",
              "author": "Smile_Clown",
              "text": "You are special...\n\nDo yourself a favor and look into what you are so sure of.  If you are so wrong about this very simple thing to look up, I wonder what else you are wrong about?\n\nLTX can absolutely run in 8.",
              "score": 3,
              "created_utc": "2026-01-08 20:37:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nysrero",
                  "author": "jonnytracker2020",
                  "text": "You are uniquely ignorant. the post says LTX 2",
                  "score": 1,
                  "created_utc": "2026-01-10 15:25:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyisymd",
                  "author": "jonnytracker2020",
                  "text": "Don‚Äôt lie",
                  "score": -2,
                  "created_utc": "2026-01-09 02:25:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pympur",
      "title": "Amazing Z-Image Workflow v3.0 Released!",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1pympur",
      "author": "FotografoVirtual",
      "created_utc": "2025-12-29 13:47:35",
      "score": 877,
      "num_comments": 111,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pympur/amazing_zimage_workflow_v30_released/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwjpidv",
          "author": "broadwayallday",
          "text": "Didn't know Photon was yours! Legend!",
          "score": 29,
          "created_utc": "2025-12-29 14:12:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwkiihy",
              "author": "ChickyGolfy",
              "text": "Damn, that has been my go-to model for such a long time. It was a beast at the time",
              "score": 13,
              "created_utc": "2025-12-29 16:39:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwmhnge",
              "author": "YMIR_THE_FROSTY",
              "text": "I still have it on HDD.",
              "score": 6,
              "created_utc": "2025-12-29 22:18:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwog9n7",
              "author": "Immediate-Mood-4383",
              "text": "Are you talking about photonlcm? Isn't that by Fill?",
              "score": 1,
              "created_utc": "2025-12-30 04:53:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwk4sok",
          "author": "twellsphoto",
          "text": "Is it possible to load a lora into these workflows?",
          "score": 11,
          "created_utc": "2025-12-29 15:33:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwke1wc",
              "author": "twellsphoto",
              "text": "Figured it out :) Just used the simple lora loader and put in line with the model node",
              "score": 7,
              "created_utc": "2025-12-29 16:17:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwlljcr",
                  "author": "FourtyMichaelMichael",
                  "text": "One, sure.\n\nTwo, TERRIBLE COLLAPSE.\n\nZ-Image has a potential, but until BASE comes out, I'm not interested at all. Turbo is far too finicky for anything that isn't directly in the model.",
                  "score": 8,
                  "created_utc": "2025-12-29 19:41:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx1wl44",
                  "author": "Accomplished_Sink181",
                  "text": "Hi. As a beginner, I'm asking for help. Can you post a screenshot or tell me more specifically where to put the Lora Loader node?",
                  "score": 1,
                  "created_utc": "2026-01-01 08:22:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx1tojx",
              "author": "Accomplished_Sink181",
              "text": "Same!",
              "score": 1,
              "created_utc": "2026-01-01 07:51:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwklnyo",
          "author": "nutrunner365",
          "text": "\"\\[rgthree-comfy\\]\\[Reroute\\] You are using rgthree-comfy reroutes with a ComfyUI Primitive node. Unfortunately, ComfyUI has removed support for this. While rgthree-comfy has a best-effort support fallback for now, it may no longer work as expected and is strongly recommended you either replace the Reroute node using ComfyUI's reroute node, or refrain from using the Primitive node (you can always use the rgthree-comfy \"Power Primitive\" for non-combo primitives).\" How exactly do I identify these reroutes, so I can replace them?",
          "score": 11,
          "created_utc": "2025-12-29 16:53:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwmxh7j",
              "author": "DVXC",
              "text": "Same error for me here, and the style selectors are thus completely broken",
              "score": 3,
              "created_utc": "2025-12-29 23:42:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwole6l",
                  "author": "yadius",
                  "text": "Same. I'm on the latest version of ComfyUI, and I've tried all three workflows. I can randomize the seed, but I can't change the default style or prompt.\n\nPretty much get the same default image every time I run it.\n\n\nEdit: Fixed by turning off \"Modern Mode Design\" in the settings menu.",
                  "score": 2,
                  "created_utc": "2025-12-30 05:29:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwpahjq",
              "author": "FirefighterScared990",
              "text": "replace fast muter node with fast bypasser node",
              "score": 3,
              "created_utc": "2025-12-30 09:05:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwjp6yf",
          "author": "aar550",
          "text": "Do you have or can anyone suggest a good image to image workflow ?",
          "score": 9,
          "created_utc": "2025-12-29 14:10:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkigiu",
          "author": "Corleone11",
          "text": "Thanks. I do experience a weird bug. I added the \"Power Lora\" node between the model loader/clip node and the routing nodes. The first generation works flawlessly but when I want to run the workflow again, it doesn't work unless I alter any kind of parameter within the workflow (prompt, style, etc.).\n\nEdit: Solved. The seed was set to fixed.",
          "score": 5,
          "created_utc": "2025-12-29 16:38:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjnt60",
          "author": "fauni-7",
          "text": "Looks really cool.",
          "score": 6,
          "created_utc": "2025-12-29 14:02:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjwqb3",
          "author": "Big0bjective",
          "text": "A lot of images have pop-cultural references I understood since they're simply well done. But didn't know Elmo was a perv",
          "score": 7,
          "created_utc": "2025-12-29 14:52:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwmqrap",
              "author": "IrisColt",
              "text": "Elmo isn't a perv.",
              "score": 1,
              "created_utc": "2025-12-29 23:06:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwki29u",
          "author": "Subject_Work_1973",
          "text": "rgthree-comfy\\]\\[Reroute\\] You are using rgthree-comfy reroutes with a ComfyUI Primitive node. Unfortunately, ComfyUI has removed support for this. While rgthree-comfy has a best-effort support fallback for now, it may no longer work as expected and is strongly recommended you either replace the Reroute node using ComfyUI's reroute node, or refrain from using the Primitive node (you can always use the rgthree-comfy \"Power Primitive\" for non-combo primitives).",
          "score": 6,
          "created_utc": "2025-12-29 16:37:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjqsri",
          "author": "Flothrudawind",
          "text": "I've yet to try it out myself but these example pics are pretty good!",
          "score": 3,
          "created_utc": "2025-12-29 14:19:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjx3ip",
          "author": "krigeta1",
          "text": "Regarding the comic workflow, how can we use like 2-3 characters and keep them consistent per panel? as there is a lora bleed, is it avoidable?",
          "score": 3,
          "created_utc": "2025-12-29 14:54:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkw21h",
          "author": "NefariousnessPale134",
          "text": "Has anybody made one of these with a face swap node",
          "score": 3,
          "created_utc": "2025-12-29 17:43:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjqk19",
          "author": "MrSatan2",
          "text": "What's the difference between \"image\" and \"photo\"? Sorry I'm a beginner\n\nEdit: and any way to add a lora to it?",
          "score": 3,
          "created_utc": "2025-12-29 14:18:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwjvrkb",
              "author": "steelow_g",
              "text": "On civit he shows the variations each one can produce from the presets. Image is basically anything (anime, comic, pixel whatever), where photo is more for actual photography styles",
              "score": 6,
              "created_utc": "2025-12-29 14:47:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwjtd04",
          "author": "autistic-brother",
          "text": "![gif](giphy|12tiQSHr16vrcA)",
          "score": 5,
          "created_utc": "2025-12-29 14:34:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwk8f76",
          "author": "retroblade",
          "text": "Nice workflow!  For some reason though, when using loras they come out distorted around the edges.  Probably something I'm doing wrong.",
          "score": 2,
          "created_utc": "2025-12-29 15:51:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkoh11",
          "author": "SEOldMe",
          "text": "Useful, Thanks a lot! Happy Holidays",
          "score": 2,
          "created_utc": "2025-12-29 17:07:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkpcwk",
          "author": "Separate_Bake",
          "text": "My apologies if this has been explained BUT I keep getting the same image output no matter what I type into the prompt (for comic Workflow in ComfyUI)",
          "score": 2,
          "created_utc": "2025-12-29 17:11:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwkvc9z",
              "author": "Busy_Bug2006",
              "text": "Ensure that the seed is not set to fixed.",
              "score": 3,
              "created_utc": "2025-12-29 17:39:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwkwm49",
                  "author": "Separate_Bake",
                  "text": "Thanks. I figured out my issue. I'm using ComfyUI desktop version and had \"Modern Node Design\" enabled which prevented me from seeing the seed option. Once I disabled Modern Node Design I was able to change Seed from fixed",
                  "score": 3,
                  "created_utc": "2025-12-29 17:45:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwlfbww",
          "author": "apachelance",
          "text": "I am using the portable Comfyui version, the workflow is running. However I cannot see any dropdown menu or something else for choosing a style.\n\nhttps://preview.redd.it/3ew7lzhrz6ag1.png?width=1483&format=png&auto=webp&s=8b23fc62144b6073be8700d4376b3d745e0e898b",
          "score": 2,
          "created_utc": "2025-12-29 19:11:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwlk69p",
              "author": "Outrageous_Field_100",
              "text": "same problem here",
              "score": 1,
              "created_utc": "2025-12-29 19:34:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwlkidn",
                  "author": "apachelance",
                  "text": "I opened an issue [https://github.com/martin-rizzo/AmazingZImageWorkflow/issues/2](https://github.com/martin-rizzo/AmazingZImageWorkflow/issues/2)",
                  "score": 2,
                  "created_utc": "2025-12-29 19:36:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwmxjmu",
                  "author": "DVXC",
                  "text": "Ditto, broken here too.",
                  "score": 2,
                  "created_utc": "2025-12-29 23:43:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwll30s",
                  "author": "apachelance",
                  "text": "Which Comfyui are you running: portable / desktop?",
                  "score": 1,
                  "created_utc": "2025-12-29 19:39:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwpol27",
              "author": "hstracker90",
              "text": "No drop down menus. Use Ctrl-M to mute the styles you don't want and Ctrl-M to unmute the style you want. \n\nNo, it's not documented anywhere. :-)",
              "score": 1,
              "created_utc": "2025-12-30 11:15:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwss8u2",
                  "author": "apachelance",
                  "text": "Hmm, there should be radio buttons to choose the style. You can see it on other people screenshots.",
                  "score": 1,
                  "created_utc": "2025-12-30 21:07:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwoit6d",
          "author": "AquaticEdgy",
          "text": "Thank you so much. The workflow is excellent and the instructions were incredibly clear. I'm not sure if I've just had bad luck or what, but this was the first workflow I've downloaded all of the stuff for beforehand because of the readme and everything just worked.",
          "score": 2,
          "created_utc": "2025-12-30 05:10:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkixbp",
          "author": "16x98",
          "text": "What was Elmo doing?",
          "score": 3,
          "created_utc": "2025-12-29 16:41:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwk1rl4",
          "author": "Infinite_Ad_9204",
          "text": "how much vram do you need for Z-Image ?",
          "score": 2,
          "created_utc": "2025-12-29 15:18:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxe7za2",
              "author": "cleverestx",
              "text": "8GB minimum I believe is recommended, but it may be lower with some workflows, not sure...",
              "score": 2,
              "created_utc": "2026-01-03 06:21:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwkpb9s",
          "author": "LiveLaughLoveRevenge",
          "text": "Just trying this out now - very nice!\n\n(Also as a relative novice with comfyui it amazes me to see what a pro can do with it!)",
          "score": 1,
          "created_utc": "2025-12-29 17:11:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkzw1i",
          "author": "Yasstronaut",
          "text": "Really good job. Playing around with it and having good results. Will let you know if I have any requests :)",
          "score": 1,
          "created_utc": "2025-12-29 18:00:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwl3ixu",
          "author": "Maskwi2",
          "text": "Thanks so much! Crazy good workflows :)¬†",
          "score": 1,
          "created_utc": "2025-12-29 18:17:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwl78j4",
          "author": "Puzzleheaded-Rope808",
          "text": "I'll certainly give you props for orginization and the use of the replace node is ingenious. Your whole empty latent grouping can be replaced with an aspect ratio node though. \n\nAmazing work!",
          "score": 1,
          "created_utc": "2025-12-29 18:34:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlgnz9",
          "author": "Maskwi2",
          "text": "I wish I was able to use all these style selectors and input an image (or images, if comic workflow and Manga style was used for example), that would be magical :) Waiting for z-image Edit.¬†\n\n\nAgain, amazing work and thanks so much for sharing these!¬†",
          "score": 1,
          "created_utc": "2025-12-29 19:18:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlh2kr",
          "author": "New_Principle_6418",
          "text": "Thanks for sharing this. Is there a tutorial on how to do full fine tuning checkpoints like you did?",
          "score": 1,
          "created_utc": "2025-12-29 19:20:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlr3b1",
          "author": "Dzugavili",
          "text": "Christ, that comic page is just... unbelievable. The prompt adhesion and coherence was just remarkable.",
          "score": 1,
          "created_utc": "2025-12-29 20:08:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlsusb",
          "author": "intermundia",
          "text": "Thanks for posting the workflows I'll try it out",
          "score": 1,
          "created_utc": "2025-12-29 20:17:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlw78c",
          "author": "mcai8rw2",
          "text": "holy balls, these are AMAZING!!! They blow the workflows i was working on CLEAN out of the water. Really REALLY good work. Thank you for sharing",
          "score": 1,
          "created_utc": "2025-12-29 20:33:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlx4ed",
          "author": "mlaaks",
          "text": "Thank you! Those are amazing workflows!",
          "score": 1,
          "created_utc": "2025-12-29 20:38:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlytfe",
          "author": "xbobos",
          "text": "It's amazing WF, good job!",
          "score": 1,
          "created_utc": "2025-12-29 20:46:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwm8z9n",
          "author": "KnifeFed",
          "text": "# BROOM!",
          "score": 1,
          "created_utc": "2025-12-29 21:35:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmks13",
          "author": "intermundia",
          "text": "excellent work. its a great way for people to iterate but it needs a way to fine tune the strength of the style",
          "score": 1,
          "created_utc": "2025-12-29 22:34:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmqlly",
          "author": "IrisColt",
          "text": "I kneel",
          "score": 1,
          "created_utc": "2025-12-29 23:05:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwndsye",
          "author": "OrangeSlicer",
          "text": "NSFW model?",
          "score": 1,
          "created_utc": "2025-12-30 01:12:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwo6llp",
          "author": "rm-rf-rm",
          "text": "Can this do image to image or do we need to wait for the Edit model to come out?",
          "score": 1,
          "created_utc": "2025-12-30 03:52:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwoltt0",
          "author": "Fit_Dragonfruit3158",
          "text": "Gracias!!!",
          "score": 1,
          "created_utc": "2025-12-30 05:32:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwoqdhl",
          "author": "Malterini",
          "text": "Love No. 15",
          "score": 1,
          "created_utc": "2025-12-30 06:07:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwot0ds",
          "author": "ofrm1",
          "text": "What the hell was the prompt for the Pacman one? Lol",
          "score": 1,
          "created_utc": "2025-12-30 06:28:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwovohg",
          "author": "Toupeenis",
          "text": "Yo.. Is that a Golden Axe reference?",
          "score": 1,
          "created_utc": "2025-12-30 06:50:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwp0p2p",
          "author": "newxword",
          "text": "This looks great.can it generate 9 or 12 images by one reference image .like google banana storyboard",
          "score": 1,
          "created_utc": "2025-12-30 07:35:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpgw7u",
          "author": "Master_Yogurtcloset7",
          "text": "for me it always produces the same image regardless the prompt I write.. what am I doing wrong?",
          "score": 1,
          "created_utc": "2025-12-30 10:05:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwpkv0z",
              "author": "soopabamak",
              "text": "i had this, disable modern nodes in settings",
              "score": 1,
              "created_utc": "2025-12-30 10:42:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwpkw97",
                  "author": "soopabamak",
                  "text": "and randomize the seed",
                  "score": 1,
                  "created_utc": "2025-12-30 10:42:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwpu6jp",
                  "author": "Master_Yogurtcloset7",
                  "text": "Amazing thank you! This worked",
                  "score": 1,
                  "created_utc": "2025-12-30 12:02:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpjleb",
          "author": "soopabamak",
          "text": "i got this type of glitches, i don't know why.. somebody help ?\n\nhttps://preview.redd.it/zof6zneojbag1.png?width=1017&format=png&auto=webp&s=c3c71d814e1b8621e1f7489ec8f3889c0f8483fa",
          "score": 1,
          "created_utc": "2025-12-30 10:30:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpq1z2",
          "author": "hstracker90",
          "text": "Thank you very much, I very much appreciate your work. You managed to put the Fooocus style variants back in ComfyUI!\n\nMay I suggest you add some labels into your workflows explaining how to use them. Muting/unmuting is not obvious to everybody.",
          "score": 1,
          "created_utc": "2025-12-30 11:28:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqp4gi",
          "author": "Direct-Vehicle2653",
          "text": "*Rubs hands together* Time to ~~steal~~ borrow more elements for my SIMPLE worms orgy workflow.",
          "score": 1,
          "created_utc": "2025-12-30 15:12:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqrdr9",
              "author": "Direct-Vehicle2653",
              "text": "lol NOPE. This one is just silly, I can't even figure out where to enter the prompt. hahahahahh\n\nToo advanced for me, but thanks!",
              "score": 1,
              "created_utc": "2025-12-30 15:24:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqrolw",
          "author": "janosibaja",
          "text": "\"Amazing\" - this is finally, without any exaggeration, amazing. Amazingly good, brilliant work. And that it is not overcomplicated with unnecessary reasoning, unobtainable LORAs, never-before-seen Nodes, but simply: IT WORKS. Thank you very much for making it. I would like to be notified about it, whatever you do.",
          "score": 1,
          "created_utc": "2025-12-30 15:25:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqv1w3",
          "author": "DirectorDirect1569",
          "text": "It's probably the first time I use a complex workflow without missing nodes. It's amazing. thank you.",
          "score": 1,
          "created_utc": "2025-12-30 15:42:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqx0qc",
          "author": "Justify_87",
          "text": "How to get rid of that shallow depth of field effect in all photos?",
          "score": 1,
          "created_utc": "2025-12-30 15:51:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqyyhn",
          "author": "bands16",
          "text": "Thanks so much!!! The workflows work so well, the options are very convenient to use",
          "score": 1,
          "created_utc": "2025-12-30 16:00:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwugf52",
          "author": "lininop",
          "text": "BROOM!",
          "score": 1,
          "created_utc": "2025-12-31 02:27:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvg0fx",
          "author": "nyambit",
          "text": "how can i change the scheduler?",
          "score": 1,
          "created_utc": "2025-12-31 06:25:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvtdw0",
          "author": "Tragicnews",
          "text": "This worked right out of the box. Thanks for your effort",
          "score": 1,
          "created_utc": "2025-12-31 08:24:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx5uvwj",
          "author": "InternationalOne2449",
          "text": "I don't find it very useful.",
          "score": 1,
          "created_utc": "2026-01-01 23:33:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxiddym",
          "author": "sorvis",
          "text": "Got it working, had to edit some parts because my comfyui was giving me problems. If the karras schedular (sigmas) steps dont show, remove the object connected to steps and add them manually. Also sampler custom I had to add boolean to make the add noise stay True, and added seed(rgthree node) generation for the noise seed. \n\nI had to do these steps before it worked because I have a custom node giving problems and not letting nodes carry values. \n\nWorks great after these tweaks, 10/10 Great job good sir.\n\nAlso if your like me and have problems being smart, The prompts go on the left, not in the final text box that cant be edited. Took me a good 3 min to solve that, half awake sippin on first coffee of the day.",
          "score": 1,
          "created_utc": "2026-01-03 21:25:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxmpeu8",
          "author": "Complete-Box-3030",
          "text": "can we storyboard with these workflow , is it possible",
          "score": 1,
          "created_utc": "2026-01-04 14:36:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxrdei7",
          "author": "Puzzled-Valuable-985",
          "text": "Incredible work, congratulations! This must have taken a lot of effort.",
          "score": 1,
          "created_utc": "2026-01-05 04:15:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjojhk",
          "author": "Ill-Purchase-3312",
          "text": "![gif](giphy|DvWJHSOxTff84SQsD9|downsized)",
          "score": 1,
          "created_utc": "2025-12-29 14:06:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjpsxd",
          "author": "MalteseDuckling",
          "text": "![gif](giphy|j1m7LhhiIdkwo)",
          "score": 1,
          "created_utc": "2025-12-29 14:13:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjrkk0",
          "author": "Skyline99",
          "text": "Thanks for sharing! i love learning workflows.",
          "score": 1,
          "created_utc": "2025-12-29 14:24:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjsmcl",
          "author": "Wanderer43v3r",
          "text": "Thank you very much!",
          "score": 1,
          "created_utc": "2025-12-29 14:30:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwk14op",
          "author": "Competitive_Ad_5515",
          "text": "Holy shit, Golden Axe! Memory unlocked",
          "score": 1,
          "created_utc": "2025-12-29 15:15:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwk72fw",
          "author": "lynch1986",
          "text": "Geez, don't make me cancel Elmo at Christmas.",
          "score": 1,
          "created_utc": "2025-12-29 15:44:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwk7p5v",
          "author": "Sea-Neighborhood-846",
          "text": "The first image is so weird for my brain to comprehend lol can't believe we're gonna be expected to bang these things in the future üò¨",
          "score": 1,
          "created_utc": "2025-12-29 15:47:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkk6ed",
          "author": "singfx",
          "text": "Nice work! Thanks for sharing",
          "score": 1,
          "created_utc": "2025-12-29 16:46:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkmoll",
          "author": "Dogluvr2905",
          "text": "Thanks for the awesome workflows -- appreciate the xmas present :)",
          "score": 0,
          "created_utc": "2025-12-29 16:58:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjmqnc",
          "author": "Legitimate-Pumpkin",
          "text": "Anybody wants a cookie? ü§´",
          "score": -5,
          "created_utc": "2025-12-29 13:56:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwkcfqv",
              "author": "JuansJB",
              "text": "That's not Cookie Monster, he's perv Olmo",
              "score": 2,
              "created_utc": "2025-12-29 16:10:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwlcfx0",
                  "author": "Legitimate-Pumpkin",
                  "text": "I guess i‚Äôm not that old üòÖ",
                  "score": 2,
                  "created_utc": "2025-12-29 18:58:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwjt9iy",
              "author": "autistic-brother",
              "text": "huh?",
              "score": 2,
              "created_utc": "2025-12-29 14:33:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwjvnzj",
                  "author": "Legitimate-Pumpkin",
                  "text": "You don‚Äôt want to know, brother",
                  "score": 0,
                  "created_utc": "2025-12-29 14:46:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pzrixy",
      "title": "Instead of a 1girl post, here is a 1man üëä post.",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/019m7wyv8eag1.png",
      "author": "IAmGlaives",
      "created_utc": "2025-12-30 19:37:16",
      "score": 812,
      "num_comments": 56,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pzrixy/instead_of_a_1girl_post_here_is_a_1man_post/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwsez8l",
          "author": "sucr4m",
          "text": "going with the latest season, its one-frame man now.",
          "score": 105,
          "created_utc": "2025-12-30 20:03:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwsjjdw",
              "author": "Krutontar",
              "text": "They should have used AI to make the rest of the frames.",
              "score": 30,
              "created_utc": "2025-12-30 20:25:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwsm35z",
                  "author": "sucr4m",
                  "text": "afaik they did/tried. idk how else the [royal ripper got tits](https://i.imgur.com/aAkPRza.png) in scnees..",
                  "score": 19,
                  "created_utc": "2025-12-30 20:38:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwxlhp3",
                  "author": "Naud1993",
                  "text": "Fans have done that and it legitimately looks better than the original animation quality if it even qualifies as animation anymore instead of a PowerPoint presentation.",
                  "score": 1,
                  "created_utc": "2025-12-31 16:06:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwvw5go",
              "author": "IrisColt",
              "text": "I understand that reference, sigh...",
              "score": 1,
              "created_utc": "2025-12-31 08:50:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwsg5vi",
          "author": "IAmGlaives",
          "text": "https://preview.redd.it/7b4grfyxeeag1.png?width=720&format=png&auto=webp&s=830041e53ff7e747d13244b435cf28f1bbefb298\n\nVery first prompt attempt, gave Temu Saitama vibes.",
          "score": 67,
          "created_utc": "2025-12-30 20:09:20",
          "is_submitter": true,
          "replies": [
            {
              "id": "nwsge9y",
              "author": "AsyncVibes",
              "text": "Give breaking bad vibes.",
              "score": 32,
              "created_utc": "2025-12-30 20:10:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwspwgh",
                  "author": "Oer1",
                  "text": "True. Looks like Mr. White and Jesse had a baby",
                  "score": 10,
                  "created_utc": "2025-12-30 20:56:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwsxfxh",
              "author": "abd1tus",
              "text": "Actually though, Saitama would totally wear that simply because that‚Äôs what they had at the store at the time and he just bought it - chemical gloves and all. Also the facial expression is also a pretty representative of Saitama using maximum brain power to decide what he wants for lunch.",
              "score": 12,
              "created_utc": "2025-12-30 21:31:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwt8rvn",
              "author": "Dirty_Dragons",
              "text": "That looks like an American made One Punch Man TV show from 20 years ago.",
              "score": 8,
              "created_utc": "2025-12-30 22:26:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwt1xnk",
              "author": "ArtDodgerx23",
              "text": "Saitemu",
              "score": 3,
              "created_utc": "2025-12-30 21:53:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwvdnih",
              "author": "starfries",
              "text": "Lol oh god it's the American live action adaptation",
              "score": 3,
              "created_utc": "2025-12-31 06:06:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwvv7sg",
              "author": "kingwhocares",
              "text": "Walter White cosplaying as One Punch Man.",
              "score": 1,
              "created_utc": "2025-12-31 08:42:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwxnq5b",
              "author": "Commercial-Chest-992",
              "text": "More like¬†Saitama Miller.",
              "score": 1,
              "created_utc": "2025-12-31 16:17:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwsmx7p",
          "author": "BloodGulch-CTF",
          "text": "needs waaay bigger tits",
          "score": 17,
          "created_utc": "2025-12-30 20:42:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwubrhq",
          "author": "Diligent-Rub-2113",
          "text": "https://i.redd.it/qmxbaxrl5gag1.gif",
          "score": 25,
          "created_utc": "2025-12-31 02:00:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwsb8ws",
          "author": "lucassuave15",
          "text": "you're giving away free ideas for Netflix haha",
          "score": 7,
          "created_utc": "2025-12-30 19:45:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwsd28s",
          "author": "UnicornJoe42",
          "text": "But Saitama is complitley bald",
          "score": 10,
          "created_utc": "2025-12-30 19:54:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwsexad",
              "author": "IAmGlaives",
              "text": "Every seed and prompt change, gave the same bald result :(. A lot of the seeds gave him stubble facial hair too. I went with close enough.",
              "score": 8,
              "created_utc": "2025-12-30 20:03:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwswxhx",
          "author": "Legendary_Kapik",
          "text": "![gif](giphy|c3XhrmfoN5fOpjcl3z)",
          "score": 10,
          "created_utc": "2025-12-30 21:29:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwu194e",
          "author": "TearsOfChildren",
          "text": "![gif](giphy|l3vRkuJclTwwLHEu4)",
          "score": 3,
          "created_utc": "2025-12-31 00:59:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwubfd1",
          "author": "urabewe",
          "text": "I posted Fraggle Rock LoRA earlier, will never get the love 1girl does. Fraggles just don't have big enough tatas.",
          "score": 3,
          "created_utc": "2025-12-31 01:58:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwt56gm",
          "author": "ExpensivePractice164",
          "text": "U can tell its ai when he has hair. Still cool tho",
          "score": 2,
          "created_utc": "2025-12-30 22:08:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwtqyqj",
          "author": "dblkil",
          "text": "I would love to see 2 girls 1 cup",
          "score": 2,
          "created_utc": "2025-12-31 00:03:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvax4n",
          "author": "donkeykong917",
          "text": "Now do the rest of the characters that are female üòú",
          "score": 2,
          "created_utc": "2025-12-31 05:44:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwsc69r",
          "author": "vincento150",
          "text": "UNO reverse",
          "score": 2,
          "created_utc": "2025-12-30 19:50:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwseegr",
          "author": "Adam-Happyman",
          "text": "Not bold enough üòÄ ‚è™",
          "score": 1,
          "created_utc": "2025-12-30 20:00:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx0rzm2",
              "author": "orangpelupa",
              "text": "BALD¬†",
              "score": 1,
              "created_utc": "2026-01-01 02:44:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwtck4b",
          "author": "-_Weltschmerz_-",
          "text": "I tried to generate a male character with a model I use, only to realise that apparently there's only women in the training set...it's a gooner model.",
          "score": 1,
          "created_utc": "2025-12-30 22:45:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwtezmg",
          "author": "magik_koopa990",
          "text": "Johnny Sins",
          "score": 1,
          "created_utc": "2025-12-30 22:58:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwunadw",
              "author": "IAmGlaives",
              "text": "One Pump Man",
              "score": 1,
              "created_utc": "2025-12-31 03:08:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwtf5d9",
          "author": "digabledingo",
          "text": "I s the chandingo",
          "score": 1,
          "created_utc": "2025-12-30 22:58:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwtsa83",
          "author": "CycleZestyclose1907",
          "text": "Say what you will about Saitama's costume, but it's got to be really easy to describe in text to an AI.",
          "score": 1,
          "created_utc": "2025-12-31 00:10:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwttp1c",
          "author": "Great_Psychology_933",
          "text": "Great, dude!",
          "score": 1,
          "created_utc": "2025-12-31 00:18:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvt4qg",
          "author": "kingwhocares",
          "text": "Still more frames than season 3.",
          "score": 1,
          "created_utc": "2025-12-31 08:22:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxmc58b",
          "author": "ProfessionalGain2306",
          "text": "Ok, I understand.\nThis man ( men ), no female.\nüòÇüå∫",
          "score": 1,
          "created_utc": "2026-01-04 13:16:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwt4tnw",
          "author": "willwm24",
          "text": "https://preview.redd.it/w5e4sieuzeag1.jpeg?width=1536&format=pjpg&auto=webp&s=bb9da350963858fd5f180794916f303a8c939fa8\n\nUnfortunately this is Nano Banana Pro but I wanted to see if that could handle totally bald, and it seems it can!",
          "score": -1,
          "created_utc": "2025-12-30 22:06:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwt6bxn",
              "author": "IAmGlaives",
              "text": "**Full Prompt used have fun: Last paragraph is the environment/pose**  \n  \nA bald Japanese man in his late 20s to early 30s with a clean-shaven face and natural skin texture. He has a regular, fit build, athletic and healthy but not overly muscular, with natural proportions. He is wearing a yellow long-sleeve superhero suit made of high-tech tactical material, form-fitting yet flexible, with a subtle reflective sheen. The suit is divided into segmented panels with slightly raised ridges and subtle armor-like padding along the shoulders, chest, and torso, giving structure without bulk. Micro-texture patterns cover the fabric, and mesh ventilation panels run under the arms and along the sides for functionality and detail. The sleeves extend fully to the wrists beneath the gloves, with slight contouring along the arms and forearms to suggest natural muscle tone and movement. The top of the outfit features a flat white band-style collar with a short functional zipper at the front.\n\nThe belt portion of the suit is black, seamlessly integrated into the overall outfit, with a round yellow buckle that matches the suit‚Äôs fabric. The crotch area of the suit is reinforced with subtle paneling and slightly thicker material, designed to smooth the silhouette naturally without showing any anatomical bulge. He wears red gloves that extend up his forearms, worn over the sleeves, made from reinforced flexible material with visible seams, subtle texturing, and tactical paneling to match the suit. His red boots are made from the same material as the gloves, with paneling, reinforced areas, and subtle wear, designed to complement the suit‚Äôs high-tech aesthetic.\n\nThe cape is white, modernized to match the tactical aesthetic of the suit: made of slightly stiffer, high-tech fabric with subtle paneling and tonal texturing, cut to fall naturally from the shoulders but maintaining shape without billowing excessively. It integrates seamlessly with the shoulder design of the suit, giving a functional, cohesive appearance.\n\nHe is walking down an abandoned part of the city, holding two brown paper grocery bags, one in each hand. The environment is desolate and run-down, featuring cracked pavement, broken windows, graffiti, scattered debris, and empty, deteriorating buildings. His expression is famously blank and emotionless, and he is not looking at the camera instead, he gazes off into the distance, seemingly without a thought in the world. His posture is relaxed and casual, walking naturally through the abandoned street. Lighting is soft but slightly directional, emphasizing the textures of the suit, cape, and environment, highlighting micro-texture, paneling, and armor lines, while maintaining photorealistic realism and a slightly moody, deserted atmosphere.",
              "score": 2,
              "created_utc": "2025-12-30 22:13:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwtit4j",
                  "author": "CX-001",
                  "text": "I'm becoming more dubious of these AI-expanded prompts. Here's one i wrote by hand for Z-image:\n\n>Photo of a 25-year-old completely hairless japanese man walks on the street of a ruined city. Debris from fallen buildings clutters the road. The man is wearing an all-yellow superhero suit, a black utility belt, red gloves, red boots and a white cape. Fit body. He is carrying two grocery bags.\n\nhttps://i.imgur.com/mhEPD2m.png",
                  "score": 3,
                  "created_utc": "2025-12-30 23:18:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwuenn0",
                  "author": "willwm24",
                  "text": "My prompt was just:  \nA real life photo closeup of saitama from one punch man at the grocery store holding up a coupon with an excited expression",
                  "score": 1,
                  "created_utc": "2025-12-31 02:17:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwsvyfl",
          "author": "dariusredraven",
          "text": "This is where mods on reddit are actually needed to make sure we dont have to suffer reading an non girl post.....",
          "score": -1,
          "created_utc": "2025-12-30 21:24:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwt5rg1",
              "author": "IAmGlaives",
              "text": "Bring your face closer to the screen.  \nPOW!!!! :D\n\nhttps://preview.redd.it/g8qyimdl0fag1.png?width=1440&format=png&auto=webp&s=43d153ea3f6f6677553efa8525fa56c9a439095a",
              "score": 14,
              "created_utc": "2025-12-30 22:11:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwsxi3q",
          "author": "SillypieSarah",
          "text": "no way. mods, can we ban this guy?",
          "score": -6,
          "created_utc": "2025-12-30 21:32:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwsqid2",
          "author": "ebolathrowawayy",
          "text": "not funny. no one cares. stop bandwagoning on how shitty the last season was.",
          "score": -11,
          "created_utc": "2025-12-30 20:59:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtpuwz",
              "author": "GasolinePizza",
              "text": "Edit: Pretty sure I got ragebaited here. Oops.\n\n\n\nDo you know where you are?\n\nThe joke isn't even about the show or the season: the joke is making fun of the flood of people posting random images of women-portraits and praising the model quality.\n\nThe only person here obsessing on a season of a show is you, so please stop doing that and go away, I guess?",
              "score": 1,
              "created_utc": "2025-12-30 23:57:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q0vto3",
      "title": "Waiting for Z-IMAGE-BASE...",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/efq3fkvi2oag1.png",
      "author": "Z3ROCOOL22",
      "created_utc": "2026-01-01 04:37:45",
      "score": 771,
      "num_comments": 93,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q0vto3/waiting_for_zimagebase/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nx1ak8e",
          "author": "Moliri-Eremitis",
          "text": "I don‚Äôt mind being patient, but what I don‚Äôt understand is why they are waiting to release the base at all.\n\nMaybe I‚Äôm missing something fundamental here, but don‚Äôt you have to finish training the base before you can release a distill? Are they performing additional training for the base? If so, why? How‚Äôd they get such a good distill if the base wasn‚Äôt even finished training yet?",
          "score": 117,
          "created_utc": "2026-01-01 04:56:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1czp4",
              "author": "Segaiai",
              "text": "You can always train more. That's why we get those 2509, 2511, etc... releases of Qwen. People are speculating that they are training up art and characters with the Noobai dataset. The z-image team also said the quality is lower than Turbo, so maybe they're trying to improve that like Qwen did with 2512.",
              "score": 69,
              "created_utc": "2026-01-01 05:17:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx1f0ef",
                  "author": "Moliri-Eremitis",
                  "text": "I‚Äôd certainly welcome some 2D training in the base if true! I was figuring we‚Äôd have to do that ourselves and get an ‚ÄúIllustrious 2.0‚Äù based on Z-Image three months to a year after Z-image base releases.\n\nI should probably read up on distills more. I always assumed they were reflective of the base quality.",
                  "score": 21,
                  "created_utc": "2026-01-01 05:34:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx1wvx7",
                  "author": "physalisx",
                  "text": "The \"quality\" you're talking about refers to visual quality, and that is going to remain low, at least lower than some finetuned and distilled model like their turbo model is.\n\nThe point of the base is not to have perfect images out of the box, it's that it's easily trainable and a good foundation. If it is, finetunes and loras will come plenty.\n\nGo and make some pictures with base SDXL... It looks like shit.",
                  "score": 13,
                  "created_utc": "2026-01-01 08:25:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx2jk1q",
              "author": "AltruisticList6000",
              "text": "They are waiting for Flux.2 Klein to ruin that release too... and probably BFL is waiting for them to release Z-image base first. So we are in an endless loop where both of them wait for each other to release first.",
              "score": 25,
              "created_utc": "2026-01-01 12:22:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx1tbj2",
              "author": "Notm333",
              "text": "[Still cookin I guess](https://i.imgur.com/9v8XIuF.jpeg)",
              "score": 9,
              "created_utc": "2026-01-01 07:48:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxsk818",
              "author": "Sayantan_1",
              "text": "I think the problem is that the turbo model was so good that people naturally assumed the base model would be even better. In reality, though, that might not be the case, and the base model's quality could end up being just meh. To meet the high expectations and hype from the community, they're probably taking extra time‚Äîhopefully to make it truly good.",
              "score": 3,
              "created_utc": "2026-01-05 10:02:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxvjo6s",
                  "author": "Moliri-Eremitis",
                  "text": "That seems like a reasonable answer.\n\nIf they are still training the base model it does have some weird implications for training LoRAs. I know one reason a lot of people are eager for the base is because they want to train against it.\n\nIf the base changes significantly from what it was when Turbo was created, you may get weird shifts in behavior when you use a LoRA trained against the updated base with the current Turbo model, unless they also release an updated Turbo model that‚Äôs trained against the new base.\n\nSeems messy.",
                  "score": 1,
                  "created_utc": "2026-01-05 19:57:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx1ow6b",
              "author": "Bunkerman91",
              "text": "The answer is always adding guardrails to try and prevent the gooners from getting too out of control",
              "score": 6,
              "created_utc": "2026-01-01 07:03:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx3fzjd",
                  "author": "Structure-These",
                  "text": "üò≠üò≠üò≠ not me using hacky qwen text encoders to try to get better results",
                  "score": 0,
                  "created_utc": "2026-01-01 16:03:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx1hlxf",
              "author": "dhm3",
              "text": "According to Gemini the math is different with Z-Image type of models and going forward instead of getting a distilled model from a base we should see the models as branches rather than distillations, i.e. the base model has more paths/branches than the turbo. This is the reason the Turbo is out first. I can only understand about 15% of the math Gemini gave me so it must be correct...",
              "score": -20,
              "created_utc": "2026-01-01 05:56:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx1stxd",
                  "author": "Designer-Pair5773",
                  "text": "sry but you didnt understand anything",
                  "score": 15,
                  "created_utc": "2026-01-01 07:43:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx3cjm6",
                  "author": "freylaverse",
                  "text": "Gemini is a dumbass when it comes to AI. I tried asking it why my LoRA training converged easily on one character but not another with a similar dataset and parameters and it said it's because one character uses more primary colours which are easier to learn. Which is... Nonsense, lol.",
                  "score": 4,
                  "created_utc": "2026-01-01 15:45:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx38wk5",
              "author": "Far_Buyer_7281",
              "text": "I think the issue is the community is misunderstanding distills and so are you?\n\nI think its quite easy to understand what is happening if you ever loaded a distill next to a base model and used them for a while? try it, aren't you seeing it? maybe read a turbo paper on sdxl?",
              "score": -3,
              "created_utc": "2026-01-01 15:24:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx2b59a",
          "author": "alisitskii",
          "text": "https://preview.redd.it/3pmbhxreypag1.jpeg?width=674&format=pjpg&auto=webp&s=207bfb1b94754c86d9c69b3fd387de37c0c60aee",
          "score": 23,
          "created_utc": "2026-01-01 10:57:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx9ebcy",
              "author": "Caesar_Blanchard",
              "text": "As a Witcher fan clearly remembering that one mission, I too am this vampire guy who only want to be woken up exclusively when Base arrives",
              "score": 2,
              "created_utc": "2026-01-02 14:49:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx18ozz",
          "author": "perusing_jackal",
          "text": "Mad to me that its only been a month since z-image turbo got released. I used to use flux exclusively, but z-image completely replaced it for me. At least we have z-image de-turbo while we wait for base release.",
          "score": 46,
          "created_utc": "2026-01-01 04:41:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1an6v",
              "author": "_VirtualCosmos_",
              "text": "One question: If you use the de-turbo with different approach in steps/CFG, can it match, or be close at least, the realistic look of original ZiT with 9 steps?",
              "score": 8,
              "created_utc": "2026-01-01 04:57:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx1qqzk",
                  "author": "jib_reddit",
                  "text": "Not at 9 steps I think, it is not a turbo model, you will have to try 25 steps. There is no real point using it for inference its just slower, it is ment for better training.",
                  "score": 13,
                  "created_utc": "2026-01-01 07:22:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx1bycr",
          "author": "No_Comment_Acc",
          "text": "Same for me. Turbo is great but I want Base for training.",
          "score": 11,
          "created_utc": "2026-01-01 05:08:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx38iqt",
              "author": "LimerickExplorer",
              "text": "Would a Lora trained on Base work on Turbo?",
              "score": 7,
              "created_utc": "2026-01-01 15:22:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx3qrxc",
                  "author": "LardonFumeOFFICIEL",
                  "text": "I'd be curious to know the answer too ü§î.",
                  "score": 5,
                  "created_utc": "2026-01-01 17:01:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx6txsp",
                  "author": "Dependent-Cellist281",
                  "text": "It will likely give you good image results yes but not in the amount of steps turbo is designed for. You'd find it will take 25-30 steps not 8/9 steps which basically defeats the entire purpose of using turbo in the first place.",
                  "score": 2,
                  "created_utc": "2026-01-02 03:00:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx1ligq",
          "author": "protector111",
          "text": "Remember they said *its coming soon*?  Cant believe it was in 2025 ... so much for *soon*....   **Happy new year everyone!**",
          "score": 29,
          "created_utc": "2026-01-01 06:31:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx34hkg",
              "author": "heato-red",
              "text": "if it will make the end product better I'll wait for any soon they may have, as long as they release it",
              "score": 3,
              "created_utc": "2026-01-01 14:57:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx3s7pa",
          "author": "Great_Traffic1608",
          "text": "wan 2.5 come on",
          "score": 6,
          "created_utc": "2026-01-01 17:08:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1aywa",
          "author": "Melodic_Possible_582",
          "text": "it's only been a month.  just look at how long those fans waited for GTA 6.  lol",
          "score": 20,
          "created_utc": "2026-01-01 04:59:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1d1kr",
              "author": "International-Try467",
              "text": "Not even the longest. The Kingkiller Chronicles (Name of the Wind/Doors of Stone) was way earlier and the author still hadn't released the final book in literal fucking decades",
              "score": 7,
              "created_utc": "2026-01-01 05:17:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx1dq3k",
                  "author": "AuryGlenz",
                  "text": "Yeah, well I‚Äôve been sitting here with my sharpened sticks and stones waiting for World War III for 80 years now.",
                  "score": 10,
                  "created_utc": "2026-01-01 05:23:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx1fobh",
                  "author": "Melodic_Possible_582",
                  "text": "Make sure the authors are still alive.  sometimes things happen.",
                  "score": 2,
                  "created_utc": "2026-01-01 05:39:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx1o45w",
                  "author": "comfyui_user_999",
                  "text": "Never forget: [https://www.penny-arcade.com/comic/2011/04/11/when-larry-met-mary](https://www.penny-arcade.com/comic/2011/04/11/when-larry-met-mary)",
                  "score": 1,
                  "created_utc": "2026-01-01 06:56:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx1f8ta",
              "author": "SpaceNinjaDino",
              "text": "And still waiting.",
              "score": 1,
              "created_utc": "2026-01-01 05:36:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx1mjhd",
          "author": "AshLatios",
          "text": "I'm more looking forward towards the image edit version. I can make images using noob or Illustrious but it needs to be properly edited.\nQwen kinda not understand things like Pok√©mon, Digimon etc.",
          "score": 11,
          "created_utc": "2026-01-01 06:41:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1wxh7",
          "author": "Cultural-Broccoli-41",
          "text": "Waiting for LTX-2 Video\n\n2026/01/06 Update: LTX-2 has arrived [https://huggingface.co/Lightricks/LTX-2/](https://huggingface.co/Lightricks/LTX-2/)\n\nhttps://preview.redd.it/h033a7ub7pag1.png?width=1024&format=png&auto=webp&s=8a4e65fc1227eb9dea0cc9919e426dab9c289c11",
          "score": 8,
          "created_utc": "2026-01-01 08:26:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1imj8",
          "author": "JinPing89",
          "text": "You can try train some LoRAs on Zimage turbo since AI toolkit has supported it, I did, and I'm quite satisfied, it kept the turbo generation speed with LoRAs too.",
          "score": 4,
          "created_utc": "2026-01-01 06:05:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1kyjp",
              "author": "thisiztrash02",
              "text": "too much random disfigurations in loras base will be stable for lora training",
              "score": 1,
              "created_utc": "2026-01-01 06:26:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx2al8w",
          "author": "Hearcharted",
          "text": "![gif](giphy|FBeSx3itXlUQw)",
          "score": 3,
          "created_utc": "2026-01-01 10:52:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx3ad0o",
          "author": "Cold_Development_608",
          "text": "https://i.redd.it/cn4axsegbrag1.gif",
          "score": 3,
          "created_utc": "2026-01-01 15:32:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx3jdlw",
          "author": "Live-North-6210",
          "text": "The fact we are getting such good results with the turbo version is crazy",
          "score": 3,
          "created_utc": "2026-01-01 16:21:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1at3l",
          "author": "Witty_Mycologist_995",
          "text": "When is z image noob coming",
          "score": 7,
          "created_utc": "2026-01-01 04:58:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx2at2a",
          "author": "Rootsyl",
          "text": "Im waiting for the anime base.",
          "score": 5,
          "created_utc": "2026-01-01 10:54:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1gwpx",
          "author": "janimator0",
          "text": "What is z-image base?",
          "score": 5,
          "created_utc": "2026-01-01 05:50:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1tbl5",
              "author": "Apprehensive_Sky892",
              "text": "Undistilled version of Z-Image that in theory:\n\n1. Can be used with CFG > 1 without \"overcooking\" and better support for negative prompt.\n2. Better base model for both fine-tuning and LoRA training.\n3. Probably handle multiple LoRAs better (or maybe a LoRA trained on ZI base will fix this issue)\n\nDownside is that it will probably take 20-30 steps to get good result (and with CFG > 1, that is actually 40-60 steps).",
              "score": 19,
              "created_utc": "2026-01-01 07:48:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxe1rj0",
                  "author": "goodssh",
                  "text": "My understanding from the user's PoV is that the base model can be primarily used to create loras that \"just work\".",
                  "score": 2,
                  "created_utc": "2026-01-03 05:33:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx1kcd7",
          "author": "juandann",
          "text": "I wonder, you guys that using ZImageTurbo, do you use comfy template or other template? On my side ZImageTurbo indeed produce awesome detail and realistic. But, it often struggle with human anatomy within broader context (like full body for example)",
          "score": 2,
          "created_utc": "2026-01-01 06:21:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxe0zyp",
          "author": "goodssh",
          "text": "And the edit model as well",
          "score": 2,
          "created_utc": "2026-01-03 05:27:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxm1mu4",
          "author": "EternalDivineSpark",
          "text": "I wanted z-edit ! Z-turbo is enough!",
          "score": 2,
          "created_utc": "2026-01-04 11:57:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxqv30c",
          "author": "DueBumblebee7854",
          "text": "It's getting ridiculous now. You can make all the excuses you like for why it's taking so long, but the reality is they can't or won't release it for whatever strategic logic they've decided. More than likely, someone else is preparing to fill the void with something even better, now that it's known where the demand lies. Too bad for the creators of Z-Image, as they could have become the new standard.",
          "score": 2,
          "created_utc": "2026-01-05 02:32:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1auej",
          "author": "Fresh-Exam8909",
          "text": "i've been using Wan2.2 for text-to-image and it's great. Personally, I think it's better then ZIT even if ZIT is good. I wonder if ZIB will be better than Wan2.2 text-to-image?\n\n\\*typo",
          "score": 3,
          "created_utc": "2026-01-01 04:58:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1cohp",
              "author": "Far_Insurance4191",
              "text": "ZIB will not be better than ZIT, it is a base model, before distillation and reinforcement learning",
              "score": 13,
              "created_utc": "2026-01-01 05:14:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx2yg2i",
                  "author": "Fresh-Exam8909",
                  "text": "I'm not sure I understand, isn't distilled version lesser quality than the base model?",
                  "score": 2,
                  "created_utc": "2026-01-01 14:18:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx1mkw5",
              "author": "Hoodfu",
              "text": "Wan has a clarity that no other model has, even flux 2/qwen image 2512. It can get things to absolute tack sharpness that's just amazing. I'm constantly using it as a last stage refiner.",
              "score": 8,
              "created_utc": "2026-01-01 06:41:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx28wzb",
              "author": "djdante",
              "text": "Yeah wan 2.2 has been consistently blowing my mind, especially for character Loras of real people.  I desperately need inpainting for images , but realism is just out of this world",
              "score": 2,
              "created_utc": "2026-01-01 10:34:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx2mxrk",
                  "author": "hornynnerdy69",
                  "text": "Any tips on training character Loras for wan2.2? I have yet to get good results even after training for days",
                  "score": 2,
                  "created_utc": "2026-01-01 12:52:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx1bxqs",
          "author": "reversedu",
          "text": "Can somebody tell me z image base what is it? The most high quality version of z image?",
          "score": 3,
          "created_utc": "2026-01-01 05:08:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1gn3a",
              "author": "ThinkingWithPortal",
              "text": "Turbo is a distillation that aims to be fast and look good. \n\nBase is the foundation Turbo is built on, and sorta a requirement for getting Lora's trained properly. There are existing Lora rn, but try and do more than one and you'll quickly run into trouble... this multiple LoRA problem will be fixed once people can train on the Base model for ZImage.\n\nAlso, it looks like it won't be much more demanding than Turbo, so that's a plus.",
              "score": 13,
              "created_utc": "2026-01-01 05:48:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx1m918",
          "author": "alecubudulecu",
          "text": "It‚Äôs only been 2 weeks!  Wait.  Yeah actually that‚Äôs checks out.",
          "score": 1,
          "created_utc": "2026-01-01 06:38:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1vxx9",
          "author": "AbjectTutor2093",
          "text": "Wan 2.5\\*",
          "score": 1,
          "created_utc": "2026-01-01 08:15:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx9wais",
          "author": "tac0catzzz",
          "text": "I'm thinking it's being heavy censored before they release it if they ever do.",
          "score": 1,
          "created_utc": "2026-01-02 16:18:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx3rqem",
          "author": "Aggravating-Age-1858",
          "text": "thats me waiting for runway to get off their FREAKING ASS\n\nand add image to video to gen 4.5 \n\nWHICH IT SHOULD HAVE HAD IN THE FIRST PLACE!!!!!!!!!\n\nwhat the hell is up with runway of late. they really are sliding behind the rest.",
          "score": 1,
          "created_utc": "2026-01-01 17:06:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q77d8f",
      "title": "LTX-2 + SEVERENCE!!! I need this to be a real!",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/8mkc3bywe3cg1",
      "author": "Interesting_Room2820",
      "created_utc": "2026-01-08 09:25:35",
      "score": 754,
      "num_comments": 72,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Animation - Video",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q77d8f/ltx2_severence_i_need_this_to_be_a_real/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nyde2cj",
          "author": "runew0lf",
          "text": "Mannnn thats is bloody glorious!!! i already have a house filled with severance 3d prints!",
          "score": 66,
          "created_utc": "2026-01-08 09:51:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyefolm",
              "author": "ebolathrowawayy",
              "text": "Really? Can you show us some or link us to the models?",
              "score": 5,
              "created_utc": "2026-01-08 14:12:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyekixv",
                  "author": "runew0lf",
                  "text": "[https://makerworld.com/en/search/models?keyword=severance](https://makerworld.com/en/search/models?keyword=severance)\n\nAbsolutely tons there!!",
                  "score": 10,
                  "created_utc": "2026-01-08 14:37:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nydn1qu",
          "author": "boisheep",
          "text": "Why everyone keeps getting good results and I keep getting dogshit results?....",
          "score": 49,
          "created_utc": "2026-01-08 11:09:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nydvtq4",
              "author": "Maximus989989",
              "text": "That is exactly what I want to know.",
              "score": 23,
              "created_utc": "2026-01-08 12:16:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nydxnzr",
                  "author": "boisheep",
                  "text": "I figured it out, first the sigmas, they need to be ManualSigmas, with specific values (can't touch my computer now), you can find the values it needs to be in the workflow.\n\nCfg ought to be 1.\n\nAlso KSampler set to euler not this res\\_2.\n\nBack to the usual quality baby, with sound.\n\nnvm res\\_2 was not the issue, it works with res\\_2 seems to have been cfg and sigmas, as well as needing distilled lora at 0.6-0.8",
                  "score": 21,
                  "created_utc": "2026-01-08 12:28:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyfvyn3",
                  "author": "Perfect-Campaign9551",
                  "text": "Don't use the ComfyUI org workflows, use the LTXVideo github workflows",
                  "score": 3,
                  "created_utc": "2026-01-08 18:09:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nydvy9y",
              "author": "ThatsALovelyShirt",
              "text": "I've followed the workflows from Official Comfy repo, and Kijai's workflow, and all my results suck compared to Wan. Blurry, lots of \"wiggly\" texture artifacts, static images and random voiceovers, etc.\n\nWan 2.2 still has much better quality in my experience.",
              "score": 3,
              "created_utc": "2026-01-08 12:17:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nydxqcr",
                  "author": "boisheep",
                  "text": "I figured it out, first the sigmas, they need to be ManualSigmas, with specific values (can't touch my computer now), you can find the values it needs to be in the workflow.\n\nCfg ought to be 1.\n\nAlso KSampler set to euler not this res\\_2.\n\nBack to the usual quality baby, with sound.\n\nnvm res\\_2 was not the issue, it works with res\\_2 seems to have been cfg and sigmas, as well as needing distilled lora at 0.6-0.8",
                  "score": 4,
                  "created_utc": "2026-01-08 12:29:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nye1oib",
              "author": "Salt-Willingness-513",
              "text": "cherrypicking",
              "score": 0,
              "created_utc": "2026-01-08 12:54:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nydfuhj",
          "author": "saunderez",
          "text": "Do I have to play as Marks Innie? The majority of his day would be some of the most mind numbing, repetitive, boring and pointless gameplay I can imagine.",
          "score": 19,
          "created_utc": "2026-01-08 10:07:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nye9slv",
              "author": "SakuraCyanide",
              "text": "But you'd get to enjoy the merriment",
              "score": 10,
              "created_utc": "2026-01-08 13:41:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyfx55c",
              "author": "eckstuhc",
              "text": "Imagine if your gameplay was locked with someone else who played exclusively as the outtie.",
              "score": 4,
              "created_utc": "2026-01-08 18:14:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyho5oe",
              "author": "terrariyum",
              "text": "Since grinding the \"Severance\" video games is boring, there's a new procedure that allows you to acquire the skills without experiencing any of the boring parts ‚Äî¬†they call the procedure \"severance\"",
              "score": 2,
              "created_utc": "2026-01-08 22:53:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyeqrf5",
          "author": "anitawasright",
          "text": "I wrote \"first person game\"¬†  \n\n  \nand it gave you third person.....",
          "score": 11,
          "created_utc": "2026-01-08 15:07:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydhyqz",
          "author": "Totem_House_30",
          "text": "the balloons!! ü§£ü§£",
          "score": 6,
          "created_utc": "2026-01-08 10:25:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydp4q5",
          "author": "djnorthstar",
          "text": "And now we need a system that simply build a game based on this in unity or unreal engine.",
          "score": 7,
          "created_utc": "2026-01-08 11:26:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nygrfzw",
              "author": "rchive",
              "text": "Or Godot, since that's open source!",
              "score": 3,
              "created_utc": "2026-01-08 20:27:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nye839c",
          "author": "underlight",
          "text": "Looks like Control dlc",
          "score": 6,
          "created_utc": "2026-01-08 13:32:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydmpf8",
          "author": "jonbristow",
          "text": "This would be the most boring game ever",
          "score": 15,
          "created_utc": "2026-01-08 11:06:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nye5p0e",
              "author": "wkw3",
              "text": "Mostly, but you have to play it until you get to the melon party level.  Coveted as fuck.",
              "score": 10,
              "created_utc": "2026-01-08 13:18:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyf9e60",
              "author": "P1r4nha",
              "text": "Maybe as a GTA clone like in the video. But exploring and breaking out of Lumon sounds like something fun as a story-heavy RPG. Especially when they can't know about it. A bit like portal without the portals. Your outie could surprise you with gifts or shitty statuses at the beginning of each day.",
              "score": 1,
              "created_utc": "2026-01-08 16:31:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nykrk6z",
                  "author": "FpRhGf",
                  "text": "An accurate Severance game would basically be Danganronpa 1 without the murders and trials. But I guess the murders can be replaced by the permanant retirement of coworkers",
                  "score": 1,
                  "created_utc": "2026-01-09 11:07:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyebvod",
          "author": "Calabast",
          "text": "It has to be a turn-based multiplayer game, with random matchmaking only.  One person plays the outtie, one plays the innie, and they have no way to communicate with each other.",
          "score": 5,
          "created_utc": "2026-01-08 13:52:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydnyep",
          "author": "Ill_Leadership1076",
          "text": "Looking so great ,can you share your workflow and System Specs with us, i am trying to figure out what is wrong with my ltx2 comfy setup, not able to get decent output last try was 5 sec 1024X768 video took 21min with RTX4080Super and 128GB 6000Mhz Ram system",
          "score": 4,
          "created_utc": "2026-01-08 11:16:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyhaokk",
              "author": "martinerous",
              "text": "[https://www.reddit.com/r/StableDiffusion/comments/1q7gzrp/ltx2\\_multi\\_frame\\_injection\\_works\\_minimal\\_clean/](https://www.reddit.com/r/StableDiffusion/comments/1q7gzrp/ltx2_multi_frame_injection_works_minimal_clean/)\n\nThat thread has my very minimalistic workflow, 768p 5 second videos generated on 3090 under 200 seconds. I have 96GB RAM. Using fp8 distilled LTX model. But the full version also runs well (3x longer though) and seems better for more complex prompts.\n\nCaveat - I removed upscaler because not worth wasting time on upscaling until I have picked the best generated video out of a bunch. So, the sharpness will not be the best. But you can add upscaler back if you prefer.\n\nAlso not using their Gemma text encoder model - it's huge and mega slow, often ends up swapping to disk. I use Gemma quants from Unsloth.\n\nWan2.2 still wins in situations with more complex prompts. For example, I just cannot make LTX generate a horror scene with man biting another person in the neck. They end up kissing or eating spaghetti or something else creepy.",
              "score": 6,
              "created_utc": "2026-01-08 21:52:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nydur9h",
          "author": "Noiselexer",
          "text": "That's one small car",
          "score": 3,
          "created_utc": "2026-01-08 12:08:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nye68i2",
          "author": "Sensitive_Bedroom789",
          "text": "bro 80% of 3d indie games that are just asset hells looks like this lol you can find many games with this look",
          "score": 4,
          "created_utc": "2026-01-08 13:21:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydl570",
          "author": "protector111",
          "text": "Only if Kojima made this game.",
          "score": 9,
          "created_utc": "2026-01-08 10:53:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nydqm47",
              "author": "nntb",
              "text": "I second a kojima severance game.",
              "score": 8,
              "created_utc": "2026-01-08 11:38:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyfjl1r",
                  "author": "InevitableJudgment43",
                  "text": "Office Stranded",
                  "score": 5,
                  "created_utc": "2026-01-08 17:15:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyimbd7",
              "author": "Arawski99",
              "text": "I hear it's amazing when the famous purple stuffed worm in flap-jaw space with the tuning fork does a raw blink on Harry-curry Rock. I need scissors! 61!",
              "score": 1,
              "created_utc": "2026-01-09 01:49:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nydm2ys",
          "author": "Harouto",
          "text": "Any chance to get the prompts and/or workflows? Thanks :)",
          "score": 3,
          "created_utc": "2026-01-08 11:01:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydoveq",
          "author": "q0099",
          "text": "To think, that would be one way to break through the Severance (because the same player would control both Innie and Outie).",
          "score": 3,
          "created_utc": "2026-01-08 11:24:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydzdzx",
          "author": "singfx",
          "text": "Damn, this is really well done! What GPU are you running this on? I'm thinking of renting a stronger GPU to play around with this properly.",
          "score": 3,
          "created_utc": "2026-01-08 12:40:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyelbfu",
          "author": "ARMCHA1RGENERAL",
          "text": "This made me think of Control.",
          "score": 3,
          "created_utc": "2026-01-08 14:41:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydkxxs",
          "author": "-oshino_shinobu-",
          "text": "They should make a walking simulator to walk around the hallway for 5 minutes straight",
          "score": 2,
          "created_utc": "2026-01-08 10:51:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydlwnr",
          "author": "Lewd_Dreams_",
          "text": "GTA LOL",
          "score": 2,
          "created_utc": "2026-01-08 10:59:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nye9096",
          "author": "WolandPT",
          "text": "Season 3 is out?!!",
          "score": 2,
          "created_utc": "2026-01-08 13:37:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyjkvyq",
          "author": "Borkato",
          "text": "This is actually incredible wtf",
          "score": 2,
          "created_utc": "2026-01-09 05:06:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyk4lvy",
          "author": "Ylsid",
          "text": "I have definitely played similar games and it would totally work, but perhaps by not being able to play both halves",
          "score": 2,
          "created_utc": "2026-01-09 07:41:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nykh6z0",
          "author": "Pale-Quote2876",
          "text": "yooo this is actually crazy!! I think this might be the beginning of one of the best game adaptations of all time",
          "score": 2,
          "created_utc": "2026-01-09 09:35:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydspd6",
          "author": "Etsu_Riot",
          "text": "You would need to work a bit on the mechanics to rotate the character. Too stiff for my taste. Besides that, not sure I would find this boring.",
          "score": 1,
          "created_utc": "2026-01-08 11:53:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nye0f8d",
          "author": "FiTroSky",
          "text": "Death Stranding 3 : Office work day.",
          "score": 1,
          "created_utc": "2026-01-08 12:46:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nye1nsg",
          "author": "Salt-Willingness-513",
          "text": "that would be cool, but i think severance would work better as a point & click adventure than a gta like game haha even though i find the gta walking style funny",
          "score": 1,
          "created_utc": "2026-01-08 12:54:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyeaobm",
          "author": "AndreRieu666",
          "text": "Pretty amazing‚Ä¶ but that would not be a fun game!!!",
          "score": 1,
          "created_utc": "2026-01-08 13:46:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyef7yt",
          "author": "MycologistSilver9221",
          "text": "Wow, I can only imagine the fake GTA 6 gameplay videos made with the LTX-2.",
          "score": 1,
          "created_utc": "2026-01-08 14:10:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyefiym",
          "author": "rookan",
          "text": "Future of entertainment - play AI generated personalized games.",
          "score": 1,
          "created_utc": "2026-01-08 14:11:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyesyqo",
          "author": "Neamow",
          "text": "Definitely feels possible to make something like a point-and-click game with interim animations between locations, character dialogues and cinematics, etc. Not an FPS since it can't run in real time and these models have zero map structure permanence.\n\nAlso not to nitpick, but if you prompted \"first person game\" and it gave you this, it's wrong, since it's clearly third person.",
          "score": 1,
          "created_utc": "2026-01-08 15:17:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfgywh",
          "author": "traviswavis",
          "text": "Looks sick!",
          "score": 1,
          "created_utc": "2026-01-08 17:04:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfqyq0",
          "author": "Ikarus_",
          "text": "This is incredible - great job!",
          "score": 1,
          "created_utc": "2026-01-08 17:48:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfvufo",
          "author": "Perfect-Campaign9551",
          "text": "That scale of that car in the last clip - it's waaaay to small for that guy to even get into it lol",
          "score": 1,
          "created_utc": "2026-01-08 18:09:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygbjwn",
          "author": "ihexx",
          "text": "this is... kind of fucked up in a way I can't put my finger on",
          "score": 1,
          "created_utc": "2026-01-08 19:16:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygfc86",
          "author": "Icy_Foundation3534",
          "text": "that is really nice looking not gonna lie",
          "score": 1,
          "created_utc": "2026-01-08 19:33:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygluv2",
          "author": "oxygen_addiction",
          "text": "What were your prompts?",
          "score": 1,
          "created_utc": "2026-01-08 20:02:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygxol0",
          "author": "lordpuddingcup",
          "text": "Not gonna lie this is ... like seriously fuckin amazing",
          "score": 1,
          "created_utc": "2026-01-08 20:55:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyht4en",
          "author": "Acceptable_Amount521",
          "text": "This is very close to the game *Control*.",
          "score": 1,
          "created_utc": "2026-01-08 23:17:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyj6mes",
          "author": "Innomen",
          "text": "omfg... that... is something else entierly. Holy shit... i have a billion requests. That right there is a future of gaming.",
          "score": 1,
          "created_utc": "2026-01-09 03:39:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyjief1",
          "author": "FortniteByEpicGames",
          "text": "This can generate a real person?, wth.",
          "score": 1,
          "created_utc": "2026-01-09 04:49:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nymhl98",
          "author": "Innomen",
          "text": "I am just still stunned by this. Really, this is the future of gaming.",
          "score": 1,
          "created_utc": "2026-01-09 16:47:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyds61h",
          "author": "FirTree_r",
          "text": "They already made a Severance game. It's called [The Stanley Parable](https://youtu.be/fBtX0S2J32Y?si=ZTeP_Sp4daJBTNcE)\n\n/s but not really, it's a great game and fits the vibes",
          "score": 1,
          "created_utc": "2026-01-08 11:49:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nye3q1p",
          "author": "swagonflyyyy",
          "text": "The fucking balloons were HILARIOUS",
          "score": 1,
          "created_utc": "2026-01-08 13:07:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q4pgaa",
      "title": "I open-sourced a tool that turns any photo into a playable Game Boy ROM using AI",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/jh1m87ohzjbg1",
      "author": "Affectionate-Map1163",
      "created_utc": "2026-01-05 15:58:04",
      "score": 745,
      "num_comments": 56,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q4pgaa/i_opensourced_a_tool_that_turns_any_photo_into_a/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nxugu8u",
          "author": "o5mfiHTNsH748KVq",
          "text": "Can you or someone on this sub make the fal.ai dependency optional?\n\nShould be easy to swap in a comfy adapter",
          "score": 41,
          "created_utc": "2026-01-05 17:00:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxuiqse",
              "author": "Affectionate-Map1163",
              "text": "i can update that soon yes, but its open source, so dont hesitate",
              "score": 22,
              "created_utc": "2026-01-05 17:09:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxuuan4",
                  "author": "o5mfiHTNsH748KVq",
                  "text": "I was thinking about it, but I have a feeling someone can get it done before I'm off work :D\n\nIf it's not done before then, I might give it a go.",
                  "score": 9,
                  "created_utc": "2026-01-05 18:02:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny05oac",
                  "author": "sukebe7",
                  "text": "does [fal.ai](http://fal.ai) generate the sprite grid?",
                  "score": 1,
                  "created_utc": "2026-01-06 13:33:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxzg17i",
              "author": "sukebe7",
              "text": "like this?  \n[https://huggingface.co/Onodofthenorth/SD\\_PixelArt\\_SpriteSheet\\_Generator](https://huggingface.co/Onodofthenorth/SD_PixelArt_SpriteSheet_Generator)",
              "score": 1,
              "created_utc": "2026-01-06 10:23:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxu6ary",
          "author": "MaorEli",
          "text": "That's crazy",
          "score": 55,
          "created_utc": "2026-01-05 16:12:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxvu3zq",
              "author": "underpaidorphan",
              "text": "This is very cool, and forgive me if I'm stupid, but is this really THAT impressive?\n\n\n* The sprite is simple image generation \n* The title screen is simple image generation\n* The background is simple image generation (that seemingly just infinite repeats)\n* The animations appear to be stock/canned across both examples, so just match sprite with animation step (copy/paste)\n\n&nbsp;\n\nIt's neat, for sure. Taking multiple workflow steps and quickly putting it together into a clean UI and ROM output is neat as hell. But \"crazy\" would unique animations, title music/sound effects, and finally actual level design.\n\nOr maybe I'm desensitized to AI these days...",
              "score": 13,
              "created_utc": "2026-01-05 20:46:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxw874g",
                  "author": "eposnix",
                  "text": "What's crazy is that we went from this being almost impossible to fairly trivial in just a couple years.",
                  "score": 50,
                  "created_utc": "2026-01-05 21:51:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxvxjxs",
                  "author": "fukijama",
                  "text": "Wouldn't such a classification be relative to the beholder and their own experiences? Fire was crazy to only some people at one point.",
                  "score": 10,
                  "created_utc": "2026-01-05 21:02:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxwt7q9",
                  "author": "MaorEli",
                  "text": "Man, I just wanted to compliment him because his project is actually really cool. Even if the individual steps are 'simple' like you said, putting them together into a working tool that actually produces a playable ROM is still awesome to see.",
                  "score": 10,
                  "created_utc": "2026-01-05 23:36:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxwseya",
                  "author": "higgs8",
                  "text": "If you think of it in terms of \"a few years ago, what would it have taken you to achieve this exact thing?\". Maybe it would have taken someone a day or two to develop the right workflow, then several hours to draw the animations literally pixel by pixel, convert them into various formats, come up with artistic liberties like \"what kind of pants and shoes are they wearing\" just from a single portrait photo, and how should those even look, etc.\n\nLet's say you wanted to create 100 different examples of this using 100 celebrities, how much work would that take? A month? Well now, after setting it up once, it takes no work at all. You can completely automate something that would have been absolutely impossible a few years ago. I think that's pretty crazy.\n\nThis is not something becoming easier or better or faster or cheaper. It's something that was impossible without significant human input to being possible with zero human input.",
                  "score": 8,
                  "created_utc": "2026-01-05 23:32:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxxsz67",
                  "author": "lxe",
                  "text": "Imagine making this comment 2 years ago",
                  "score": 4,
                  "created_utc": "2026-01-06 02:47:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxub35n",
          "author": "TheyCallMeDozer",
          "text": "What a time to be alive.... I have so many ideas of troll games for friends right now",
          "score": 17,
          "created_utc": "2026-01-05 16:34:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxulhvo",
          "author": "Freonr2",
          "text": "It's all API and not local...\n\nBG remove could be swapped out with birefnet and qwen image edit or flux2 could be used for edit.",
          "score": 14,
          "created_utc": "2026-01-05 17:22:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxuev5f",
          "author": "dadidutdut",
          "text": "where can I download the elevator music on the video?",
          "score": 4,
          "created_utc": "2026-01-05 16:51:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxx40hn",
              "author": "wesarnquist",
              "text": "You tell me where I can find an elevator that plays music like that and I'll tell you where you can download it...",
              "score": 4,
              "created_utc": "2026-01-06 00:33:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxvel3v",
          "author": "OtherVersantNeige",
          "text": "500 cigarettes",
          "score": 4,
          "created_utc": "2026-01-05 19:34:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxvl9ce",
          "author": "nntb",
          "text": "Next add a level editor",
          "score": 3,
          "created_utc": "2026-01-05 20:04:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxvo4mt",
          "author": "EagerSubWoofer",
          "text": "This is SO COOL. Thanks for sharing this!",
          "score": 3,
          "created_utc": "2026-01-05 20:18:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxx4q6j",
          "author": "TheSmartGenitals",
          "text": "Old tech getting modern tech treatment",
          "score": 3,
          "created_utc": "2026-01-06 00:36:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxx0wg7",
          "author": "bigdukesix",
          "text": "Cool project but why does every tech person use elon musk in their demonstrations?",
          "score": 7,
          "created_utc": "2026-01-06 00:16:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxf1qm",
              "author": "JazzlikeLeave5530",
              "text": "They all use the same pictures of Altman and Musk. Tired of it. They can use literally any image and they use these lol",
              "score": 10,
              "created_utc": "2026-01-06 01:31:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxxc7p0",
              "author": "daniel",
              "text": "Needs a vomit bag warning.",
              "score": 7,
              "created_utc": "2026-01-06 01:16:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxujnpi",
          "author": "HelpRespawnedAsDee",
          "text": "Holy shit",
          "score": 2,
          "created_utc": "2026-01-05 17:14:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxvv4f9",
          "author": "Revolutionalredstone",
          "text": "Okay, I read the title and had my doubts - But this is SICK! nice work.",
          "score": 2,
          "created_utc": "2026-01-05 20:51:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxw8c26",
          "author": "hurrdurrimanaccount",
          "text": "using sam and elon is cringe",
          "score": 7,
          "created_utc": "2026-01-05 21:52:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxvfy2p",
          "author": "PossibilityLarge8224",
          "text": "What model are you using for the sprite sheet?",
          "score": 3,
          "created_utc": "2026-01-05 19:40:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxutjvr",
          "author": "UsedToBeBieber",
          "text": "\\*Nintendo lawyers have entered the chat\\*",
          "score": 5,
          "created_utc": "2026-01-05 17:59:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxv5n8f",
              "author": "TwistStrict9811",
              "text": "Yep lol. Will be interesting to see them fight this uphill battle as more and more software like this can be created also with AI lmao",
              "score": 1,
              "created_utc": "2026-01-05 18:53:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxu5l91",
          "author": "3deal",
          "text": "App stores are dead.   \nVery good idea, nice work.",
          "score": 3,
          "created_utc": "2026-01-05 16:08:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxvn9b3",
              "author": "EagerSubWoofer",
              "text": "I uploaded a pic of Unreal Engine 5 and it worked. I can now build and ship PS5 Pro games from my gameboy.",
              "score": 4,
              "created_utc": "2026-01-05 20:14:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxvj4rn",
              "author": "drury",
              "text": ">App stores are dead.\n\nI mean, yes and no.\n\nIt seems this is just one premade gameboy \"game\" where you can't do anything but run around and jump, and all this does is generate sprite sheets for the player character and the static background.\n\nWhich is kinda similar to a thing that was done in the pre-generative AI days and DID actually break the appstore for a while - two guys made a script that swapped sprites in a premade slot machine game and automatically uploaded it to the appstore under a unique name, then used it to flood the appstore with endless slot machine clones.\n\nhttps://www.youtube.com/watch?v=E8Lhqri8tZk",
              "score": 10,
              "created_utc": "2026-01-05 19:55:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxw1dom",
                  "author": "MikePounce",
                  "text": "Oh my god thank you so much for this link, this is by far the best GDC talk of all time, I had a blast.",
                  "score": 3,
                  "created_utc": "2026-01-05 21:20:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxwpjf1",
                  "author": "lithodora",
                  "text": "I tried really hard to get good usable sprite sheets out of comfy and ended up just doing it all myself the old fashioned way in the end. \n\nI'd be interested in a workflow to actually make some sprite sheets as I have a few characters I excluded from my game I'm working on because I didn't have the time to make the artwork.",
                  "score": 1,
                  "created_utc": "2026-01-05 23:17:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxvppmv",
          "author": "pwnies",
          "text": "The biggest issue that feels unsolved with sprite generation is getting good animations for actions. \n\nRight now this is purely using prompts to create run/jump/idle animations, which are always just a little off. \n\nI suspect the right way to do sprite generation is to actually use something like hy-motion to build out the required animation, the map sprites on top of it.",
          "score": 1,
          "created_utc": "2026-01-05 20:25:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxyyq6e",
              "author": "desktop4070",
              "text": "Something like this?  \nhttps://www.youtube.com/watch?v=JVvSLzXbYS0  \n  \nI wonder what the least amount of clicks you could automate this method into.",
              "score": 1,
              "created_utc": "2026-01-06 07:40:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxz76uy",
              "author": "odragora",
              "text": "Pixel Lab generates very good animations in pixel art, ready to use in games. Retro Diffusion has animations too as far as I remember.\n\nSome subjects are solved and can be animated purely by prompt, some like for example horses and mounted characters still need a pre-made animation template.\n\nGenerally with local models I think any animation can be achieved using controlnets, if you have a source animation you want to use. Also some people use video generation models and then extract frames.",
              "score": 1,
              "created_utc": "2026-01-06 09:00:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxvx9rh",
          "author": "fukijama",
          "text": "Imagine that gif of people standing up and clapping was here.",
          "score": 1,
          "created_utc": "2026-01-05 21:01:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxww5i4",
          "author": "Baphaddon",
          "text": "Respect",
          "score": 1,
          "created_utc": "2026-01-05 23:52:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxxs9yz",
          "author": "Dwedit",
          "text": "Seeing edges on the player sprite from other entries in the sprite sheet, it's not obeying the grid correctly.",
          "score": 1,
          "created_utc": "2026-01-06 02:43:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny056a8",
          "author": "sukebe7",
          "text": "odd. mine doesn't have a spot for the api key",
          "score": 1,
          "created_utc": "2026-01-06 13:30:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5x6uw",
              "author": "veganoel",
              "text": "I also had this problem but then I solved it. Try to extend the window to full screen.",
              "score": 2,
              "created_utc": "2026-01-07 07:55:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny4cxdu",
          "author": "semenonabagel",
          "text": "this is magnificent! I would love to see a GBA rom version someday",
          "score": 1,
          "created_utc": "2026-01-07 01:41:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5t230",
          "author": "Cross_22",
          "text": "I was going to ask for a model that can do sprite sheet generation - but an EXE that's ready to use sounds even better.",
          "score": 1,
          "created_utc": "2026-01-07 07:18:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxvy6za",
          "author": "Nice-Ad1199",
          "text": "Pretty cool!",
          "score": 1,
          "created_utc": "2026-01-05 21:05:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxwjbl5",
          "author": "JuansJB",
          "text": "Loving it, especially the musik!",
          "score": 1,
          "created_utc": "2026-01-05 22:45:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxwufmj",
          "author": "kendrick90",
          "text": "Very cool work!!!",
          "score": 1,
          "created_utc": "2026-01-05 23:43:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxx92dx",
          "author": "Townsiti5689",
          "text": "Absolutely crazy.",
          "score": 1,
          "created_utc": "2026-01-06 00:59:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q8590s",
      "title": "Thx to Kijai LTX-2 GGUFs are now up. Even Q6 is better quality than FP8 imo.",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/i9khpupr0bcg1",
      "author": "Different_Fix_2217",
      "created_utc": "2026-01-09 10:53:28",
      "score": 743,
      "num_comments": 238,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q8590s/thx_to_kijai_ltx2_ggufs_are_now_up_even_q6_is/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nykrcen",
          "author": "MaskmanBlade",
          "text": "Praise Kijai, a true pillar of the community.",
          "score": 214,
          "created_utc": "2026-01-09 11:05:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nykrxhm",
              "author": "protector111",
              "text": "Sometimes it feels like if something happens to the man or he decides to retire - the whole community will collapse. The legend indeed.",
              "score": 97,
              "created_utc": "2026-01-09 11:10:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nylrdq1",
              "author": "Hunting-Succcubus",
              "text": "Is he core dev?",
              "score": 4,
              "created_utc": "2026-01-09 14:48:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyn0c3t",
                  "author": "Sea_Succotash3634",
                  "text": "He used to be just a community member who was basically the glue that kept open source exploration going. ComfyUI was smart and hired him to mostly do what he already does.",
                  "score": 19,
                  "created_utc": "2026-01-09 18:12:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nymuiec",
                  "author": "IJdelheidIJdelheden",
                  "text": "The core dev of what?",
                  "score": 4,
                  "created_utc": "2026-01-09 17:46:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyonvh0",
                  "author": "superstarbootlegs",
                  "text": "if you use it, he probably had a hand in tweaking it into being. he is a main dev in the scene and pushes the boundaries because he sees outside what most of us understand with this stuff. but he'd be the first to point out that there are plenty of top names that also deserve a mention. he just got rock star status  because his name popups up a lot when you dig into a thing and people chase that.",
                  "score": 2,
                  "created_utc": "2026-01-09 22:46:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyo3ybr",
          "author": "Choowkee",
          "text": "If anyone is too stupid to merge commits like me then do this:\n\n1. Make sure to have the latest version of ComfyUI-GGUF installed via manager.\n\n2. Go to https://github.com/city96/ComfyUI-GGUF/tree/f083506720f2f049631ed6b6e937440f5579f6c7\n\n3. download loader.py / nodes.py and paste it into your ~/ComfyUI/custom_nodes/ComfyUI-GGUF folder.\n\n4. Completely kill and open ComfyUI (not just restart).",
          "score": 22,
          "created_utc": "2026-01-09 21:12:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyr8brr",
              "author": "lumos675",
              "text": "Or you can go inside Comfyui-GGUF folder and do this\n\ngit fetch [https://github.com/city96/ComfyUI-GGUF](https://github.com/city96/ComfyUI-GGUF) pull/399/head:pr-399  \ngit merge pr-399\n\nonly you need git to be installed if on windows. Linux already has Git Natively",
              "score": 6,
              "created_utc": "2026-01-10 08:37:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nysf8ml",
                  "author": "Sudden_List_2693",
                  "text": "fatal: refusing to merge unrelated histories",
                  "score": 4,
                  "created_utc": "2026-01-10 14:18:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyz0rpz",
              "author": "c0n73mn",
              "text": "[https://blog.comfy.org/p/meet-the-new-comfyui-manager](https://blog.comfy.org/p/meet-the-new-comfyui-manager) \\> **ComfyUI-GGUF**",
              "score": 0,
              "created_utc": "2026-01-11 14:03:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nykxb1h",
          "author": "alitadrakes",
          "text": "Kijai always on point",
          "score": 12,
          "created_utc": "2026-01-09 11:53:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nykzq33",
          "author": "theOliviaRossi",
          "text": "somebody - pls, upload the simple workflow with all the needed nodes",
          "score": 33,
          "created_utc": "2026-01-09 12:10:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyl4yfs",
              "author": "samplebitch",
              "text": "You can download [this](https://huggingface.co/Kijai/LTXV2_comfy/discussions/2#6960121c62625ab0359075af) clip and drag it into comfy - it will give you the workflow. (Just found it myself and am downloading the files still so can't say that it works - I don't see any immediate issues with it, though).",
              "score": 37,
              "created_utc": "2026-01-09 12:46:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyv7dv9",
                  "author": "Pleasant-Bug-8114",
                  "text": "this one is text to video.  \ndoes anyone have image 2 video workflow with kj nodes?",
                  "score": 2,
                  "created_utc": "2026-01-10 22:32:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyl1cok",
              "author": "Kiyushia",
              "text": "thats what im waiting too",
              "score": 6,
              "created_utc": "2026-01-09 12:22:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nym0xn0",
          "author": "Nepharios",
          "text": "Oh holy sh''! Finally, Kijai, you are the goat! Just look at this: \n\nhttps://preview.redd.it/v9o7wpvheccg1.png?width=1415&format=png&auto=webp&s=da3a44f1a814eb67385bdfca72c4b752ce34d363\n\n1280x720, 24 fps, 121 Frames, 4090, 43s!!\n\nusing fp8\\_transformer\\_only and the e4m3fn-gemma\n\nAnd the first time I acutally got REALLY good quality with LTX 2.0\n\n2026 is going to be HUGE!",
          "score": 17,
          "created_utc": "2026-01-09 15:33:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nym2qh2",
              "author": "Different_Fix_2217",
              "text": "For best quality use 48 fps, res\\_2s sampler from the RES4LYF nodepack, and detailer loras on both stages.  \n[https://files.catbox.moe/pvsa2f.mp4](https://files.catbox.moe/pvsa2f.mp4)",
              "score": 11,
              "created_utc": "2026-01-09 15:41:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nym463w",
                  "author": "Nepharios",
                  "text": "I will try optimize the workflow this weekend... but man, I am just happy this thing runs so smooth now on my system :)  \nTy for the advice!",
                  "score": 2,
                  "created_utc": "2026-01-09 15:48:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nynsi67",
              "author": "Choowkee",
              "text": "What does this have to do with gguf? You are using the regular model.",
              "score": 3,
              "created_utc": "2026-01-09 20:19:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nym2bpc",
              "author": "Simpsoid",
              "text": "How much system RAM do you have?",
              "score": 2,
              "created_utc": "2026-01-09 15:39:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nym3wz2",
                  "author": "Nepharios",
                  "text": "https://preview.redd.it/nqem6xz8hccg1.png?width=415&format=png&auto=webp&s=8068f8d273f85e2216faf48d4f44842eb71d0d79",
                  "score": 4,
                  "created_utc": "2026-01-09 15:46:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nynyfs2",
              "author": "thegr8anand",
              "text": "can you share your workflow? I am trying to use it on my 4090 but get errors. Do you get clip missing error when using the e4m3fn-gemma? i keep getting that error.",
              "score": 1,
              "created_utc": "2026-01-09 20:46:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyo2lm8",
                  "author": "Nepharios",
                  "text": "https://preview.redd.it/r2v2s8o12ecg1.png?width=667&format=png&auto=webp&s=79bfa5084f854096b51c7d868234a3f2de76c843\n\nUsing the workflow provided by op. These are my models. I had to do 2 things:  \n\\- the pull provided by op  \n\\- update Kijai-nodes. I got an audio vae error without updating  \nEverything else is unchanged.",
                  "score": 4,
                  "created_utc": "2026-01-09 21:06:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nylf38k",
          "author": "Commercial-Chest-992",
          "text": "Hail Kijai!\n\nAlso, a reminder that ComfyUI has integrated Kijai‚Äôs work on offloading model layers so that, if you‚Äôve got enough system RAM, you can just run the full, non-quantized model. It works, it‚Äôs great.",
          "score": 5,
          "created_utc": "2026-01-09 13:45:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nylhnfh",
              "author": "Different_Fix_2217",
              "text": "Yea FP16 is the best if you have the vram + ram to fit everything. A lot of people dont though and having to load from disk slows things down MASSIVELY.",
              "score": 3,
              "created_utc": "2026-01-09 13:59:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyng91c",
                  "author": "Commercial-Chest-992",
                  "text": "Yup, fair point. A few years ago, I thought getting all this RAM was kinda frivolous. Not so much now.",
                  "score": 3,
                  "created_utc": "2026-01-09 19:22:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyqhi4y",
                  "author": "frogsarenottoads",
                  "text": "I'm very dumb, and fairy new to SD. I have a rtx 3080 and 128gb of RAM. How do I use just FP16? Or attempt to? Just switch out the GGUF node and that's it?\n\nAlso do you have an updated I2V wf?",
                  "score": 2,
                  "created_utc": "2026-01-10 04:56:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nylwxfp",
              "author": "AntiTank-Dog",
              "text": "So if I have 16GB VRAM and 128GB RAM, I should use FP16?",
              "score": 3,
              "created_utc": "2026-01-09 15:14:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyn4410",
                  "author": "Remarkable_Bonus_547",
                  "text": "I think yes. All I can't say it's 16Gb VRAM and 96GB is not enough for LTX2. MAYBE 128gb is enough. Any way, if not enough, go for Q8 GGUF and call it a day. Good luck",
                  "score": 2,
                  "created_utc": "2026-01-09 18:28:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyy9dud",
                  "author": "andy_potato",
                  "text": "Absolutely yes!",
                  "score": 1,
                  "created_utc": "2026-01-11 10:32:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nynfr5n",
                  "author": "Commercial-Chest-992",
                  "text": "That‚Äôs basically my setup, so worth a try?",
                  "score": 1,
                  "created_utc": "2026-01-09 19:20:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyy9bt1",
              "author": "andy_potato",
              "text": "I mentioned that in another thread and got downvoted into oblivion by folks who still believe you gotta fit the entire model into VRAM :p",
              "score": 2,
              "created_utc": "2026-01-11 10:32:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyn2cii",
          "author": "ReasonableDust8268",
          "text": "Does anyone know how to get the Gemma3 GGUF's working? \n\n    # ComfyUI Error Report\n    ## Error Details\n    - **Node ID:** 177:196\n    - **Node Type:** ClipLoaderGGUF\n    - **Exception Type:** ValueError\n    - **Exception Message:** Unknown architecture: 'gemma3'",
          "score": 6,
          "created_utc": "2026-01-09 18:21:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nykwwpm",
          "author": "aurelm",
          "text": "excelent news. but is there a sample workflow for this ? How do we load the model ? Do we need separate vae files ?",
          "score": 16,
          "created_utc": "2026-01-09 11:50:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nylebk1",
              "author": "Different_Fix_2217",
              "text": "Here is Kijai nodes WF [https://files.catbox.moe/flkpez.json](https://files.catbox.moe/flkpez.json)",
              "score": 19,
              "created_utc": "2026-01-09 13:41:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nylnac1",
                  "author": "Simple_Echo_6129",
                  "text": "Thanks!\n\n\nSo this works with the `ltx-2-19b-dev-fp8_transformer_only.safetensors`, but how do we make it work with  `ltx-2-19b-dev_Q8_0.gguf`? If I swap out the diffusion loader with a unet loader and load Q8 I only get a very blurry video.",
                  "score": 8,
                  "created_utc": "2026-01-09 14:28:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nymbph9",
                  "author": "127loopback",
                  "text": "Has Kijai shared a I2V workflow or is it only T2V?",
                  "score": 7,
                  "created_utc": "2026-01-09 16:21:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nymhtjp",
                  "author": "Alessins23",
                  "text": "link not work",
                  "score": 1,
                  "created_utc": "2026-01-09 16:49:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyl9bqy",
              "author": "Serious_Ai",
              "text": "Apparently if you go here\n https://huggingface.co/Kijai/LTXV2_comfy/discussions/2#6960121c62625ab0359075af\n\nAnd download the video, drag and drop it in to comfyUI and it will load everything for the workflow. I haven't tried it yet but will test soon",
              "score": 2,
              "created_utc": "2026-01-09 13:13:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyns7mg",
                  "author": "Choowkee",
                  "text": "This WF doesn't have the GGUF nodes connected, anyone reading this don't waste you time.",
                  "score": 9,
                  "created_utc": "2026-01-09 20:17:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyl11p6",
          "author": "No_Progress_5160",
          "text": "Nice üçü",
          "score": 5,
          "created_utc": "2026-01-09 12:20:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nym8rlb",
          "author": "Ferriken25",
          "text": "Where is this damn gguf workflow? Stop showing the official workflows!",
          "score": 9,
          "created_utc": "2026-01-09 16:08:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nylh6qf",
          "author": "in_use_user_name",
          "text": "how do i commit this on windows comfyui desktop installation?",
          "score": 4,
          "created_utc": "2026-01-09 13:56:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nykw5pq",
          "author": "ANR2ME",
          "text": "Finally! üëç\n\nBut GGUF with iMatrix or Unsloth Dynamic are usually have better quality than standard GGUF, so i hope unsloth release the GGUF UD version too üòÖ",
          "score": 9,
          "created_utc": "2026-01-09 11:44:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyl76xe",
              "author": "CrispyToken52",
              "text": "How do you even create an imatrix for a video diffusion model?   \nThis isn't llama.cpp.",
              "score": 6,
              "created_utc": "2026-01-09 13:00:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyl8lqh",
                  "author": "ANR2ME",
                  "text": "When i said \"usually\" as in general, not specific to diffusion models.\n\nHowever, unsloth does have dynamic version 2.0 of diffusion models like Qwen Image Edit https://huggingface.co/unsloth/Qwen-Image-Edit-2511-GGUF",
                  "score": 6,
                  "created_utc": "2026-01-09 13:08:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyl0ymm",
          "author": "robomar_ai_art",
          "text": "Guys can you post a workflow that those gguf can be used",
          "score": 9,
          "created_utc": "2026-01-09 12:19:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nypx2hw",
              "author": "Different_Fix_2217",
              "text": "I updated the OP WF so its just load and use. And people's issues are one of two things. They did not actually merge the commit linked which makes that \"video dissolve\" look or they did not have the latest KJ nodes which would give the vae error.",
              "score": 2,
              "created_utc": "2026-01-10 02:50:16",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nymp443",
              "author": "Unique_Dog6363",
              "text": "the post says gguf but the workflow is not even gguf I'm trying here and the video quality is like just distorted walls",
              "score": 1,
              "created_utc": "2026-01-09 17:21:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nykqw4u",
          "author": "Lonely-Anybody-3174",
          "text": "Good news",
          "score": 7,
          "created_utc": "2026-01-09 11:01:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nylrp23",
          "author": "ArtyfacialIntelagent",
          "text": ">Thx to Kijai LTX-2 GGUFs are now up. Even Q6 is better quality than FP8 imo.\n\nThat's kind of expected. An fp8 safetensors uses flat fp8 precision across the board. A Q6 GGUF  is smarter. It may have only 6 bits for most weights, but it uses block level scaling to use those bits effectively, and some entire (smaller but important) tensors may use fp8, fp16 or even fp32 precision. Because of these things the average bit depth for a Q6 GGUF is about 6.5 bits per weight.",
          "score": 4,
          "created_utc": "2026-01-09 14:50:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nymqerc",
              "author": "Nevaditew",
              "text": "So, what is better? distilled Q6, Q8 or dev Q8? Speed is not matter for me",
              "score": 2,
              "created_utc": "2026-01-09 17:27:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nymxwgp",
                  "author": "Dense-Maintenance-56",
                  "text": "Higher precision ex) bf16 is best if quality is the main concern, but from what i understand fp8/Q8 quality is almost the same or indistinguishable",
                  "score": 2,
                  "created_utc": "2026-01-09 18:01:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nykycn1",
          "author": "PhotoRepair",
          "text": "quite new to this, is the voice something you added separately or just prompted, if it is added separately how does that work?",
          "score": 3,
          "created_utc": "2026-01-09 12:01:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyl4nfy",
              "author": "Kiyushia",
              "text": "it work on both ways, the model has builtin audio and voice, you can add a audio voice too (use kijais ltx2 audio) its here on reddit search it",
              "score": 4,
              "created_utc": "2026-01-09 12:44:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nylye18",
          "author": "Phuckers6",
          "text": "This workflow has no mention of GGUF.  \nIs there any working workflow that actually successfully used a GGUF file?",
          "score": 3,
          "created_utc": "2026-01-09 15:21:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nym6y5a",
          "author": "ArtifartX",
          "text": "Can someone update me on LTX2 - are there any ways to control motion (IE controlnet, motion vectors, openpose, deptch, etc)? Or is the main input only a text prompt?",
          "score": 3,
          "created_utc": "2026-01-09 16:00:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyo9hws",
          "author": "PestBoss",
          "text": "Just for reference:\n\n\\-Latest ComfyUI  \n\\-GGUF loader manually updated (https://github.com/city96/ComfyUI-GGUF/pull/399)\n\n3090 RTX 24GB | 64GB system ram ComfyUI loaded with --lowvram --reserve-vram 4\n\nQ8 GGUF DEV 20 steps  \nGemma FP8 e4m3fn  \n1280x720 i2v 249 frame video completed in 483 seconds  (20 x 6s + 3 x 30s \\~ 210s for main steps!)\n\nOfficial distill LoRA on upscaler (seen it missing on some WF, hence it being noted here)  \nDuring the upscale 4700mb offloaded and 30s/it.\n\nNot the best quality in the world but I'm just using the standard ComfyUI workflow with the diner and waitress, so I think the prompt is letting it down on 249 frames as it's not sure what to do with 10s worth of time. The lady walks around in the scene but it feels a bit un-directed (which it is).\n\nBut compared to WAN 2.2 this is ultimately four times faster give or take for my setup, and it's doing audio at the same time.\n\nQ6K GGUF distilled 8 steps  \nGemma FP8 e4m3fn  \n1280x720 i2v 249 frame video completed in 472 seconds (8 x 7s + 3 x 30s \\~ 146s for main steps!)\n\nNo distill LoRA on upscaler necessary here. During the upscale just 500mb offloaded and still 30s/it.\n\nSimilar quality but just less dynamicism in the overall composition, the woman stays quite still in the overall scene vs getting up and walking around it.\n\nVAE and text encoder steps seem to take most time here vs the actual generation.\n\nHopefully lots of scope for optimisation.",
          "score": 3,
          "created_utc": "2026-01-09 21:38:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyoc8f3",
          "author": "dasomen",
          "text": "is there a workflow that actually uses the mentioned GGUF model? everything that's being posted uses the safetensors model....",
          "score": 3,
          "created_utc": "2026-01-09 21:50:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyoigtz",
              "author": "Choowkee",
              "text": "Here you go, working i2v:\n\nhttps://github.com/choowkee/hires_flow/blob/main/gguf_i2v_n.json",
              "score": 4,
              "created_utc": "2026-01-09 22:19:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyolwy6",
                  "author": "dasomen",
                  "text": "Thanks a lot @Choowkee !",
                  "score": 1,
                  "created_utc": "2026-01-09 22:36:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyqksus",
                  "author": "DELOUSE_MY_AGENT_DDY",
                  "text": "Where do you put the audio VAE for this WF?",
                  "score": 1,
                  "created_utc": "2026-01-10 05:19:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyl5na0",
          "author": "ArtificialAnaleptic",
          "text": "Trying to get a GGUF distilled workflow up and running. Currently it runs but the video immediately disintegrates to static after the first frame. \n\nAny thought from anyone?:\n\nhttps://preview.redd.it/owp87z4slbcg1.png?width=2414&format=png&auto=webp&s=10f952c5656bd48a786d757c87a5c8a26bc7f289",
          "score": 6,
          "created_utc": "2026-01-09 12:50:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nym5980",
              "author": "Maraan666",
              "text": "I had the same problem, even after pulling [https://github.com/city96/ComfyUI-GGUF/pull/399](https://github.com/city96/ComfyUI-GGUF/pull/399) \\- but after closing comfy completelyand restarting it magically worked. (and it had taken me a while to remember how to install a pull request correctly haha!)\n\nAnd incidentally, it's well worth the effort, Q8 is a huge improvement in quality over fp8.",
              "score": 5,
              "created_utc": "2026-01-09 15:53:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyo3iqs",
                  "author": "Choowkee",
                  "text": "Heh I can confirm that completely restarting Comfy actually made it work.\n\nHad to kill the process entirely on my cloud instance.",
                  "score": 2,
                  "created_utc": "2026-01-09 21:10:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nymtxqt",
                  "author": "tempedbyfate",
                  "text": "I'm new around here so please excuse my ignorance. Does the Q8 version require less memory than the fp8? can you run generate higher resolutions or more frames in Q8 vs fp8. Or is this just an improvement in quality. Thank you.",
                  "score": -1,
                  "created_utc": "2026-01-09 17:43:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nylacr4",
              "author": "Simple_Echo_6129",
              "text": "I get the same problem, so it's not just you..",
              "score": 3,
              "created_utc": "2026-01-09 13:19:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nylan0c",
                  "author": "ArtificialAnaleptic",
                  "text": "FWIW, I was concerned it might be an issue with the CLIP so I swapped back to the fp8 and used this one : https://huggingface.co/GitMylo/LTX-2-comfy_gemma_fp8_e4m3fn/blob/main/gemma_3_12B_it_fp8_e4m3fn.safetensors\n\nwhich i've seen working in the workflows from huggingface but that didn't help. Those workflows weren't using the GGUF though. \n\nSo my current theory is that I'm loading the GGUF in wrong somehow.",
                  "score": 4,
                  "created_utc": "2026-01-09 13:20:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nymmtqy",
              "author": "Alessins23",
              "text": "Could you share your workflow with me?",
              "score": 2,
              "created_utc": "2026-01-09 17:11:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nymq2s5",
                  "author": "ArtificialAnaleptic",
                  "text": "It's the default workflow from within the LTX custom node folder. If you've got the nodes you've got the workflow. I just swapped out the first few nodes with those shown in the image.",
                  "score": 2,
                  "created_utc": "2026-01-09 17:26:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nylcx3j",
              "author": "Different_Fix_2217",
              "text": "You need the git commit like I said. [https://github.com/city96/ComfyUI-GGUF/pull/399](https://github.com/city96/ComfyUI-GGUF/pull/399) Until its merged you will have to pull it yourself.",
              "score": 5,
              "created_utc": "2026-01-09 13:33:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyldsm2",
                  "author": "gwynnbleidd2",
                  "text": "Already had it pulled",
                  "score": 2,
                  "created_utc": "2026-01-09 13:38:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nylc3p0",
              "author": "gwynnbleidd2",
              "text": "Same error with [gemma\\_fp8\\_e4m3fn](https://huggingface.co/GitMylo/LTX-2-comfy_gemma_fp8_e4m3fn).",
              "score": 4,
              "created_utc": "2026-01-09 13:29:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyl1g6y",
          "author": "Dear-Spend-2865",
          "text": "Can i run this in my 3060ti 12G?",
          "score": 5,
          "created_utc": "2026-01-09 12:22:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nymuw03",
              "author": "IJdelheidIJdelheden",
              "text": "Give it a try, you'll find out, and then you can tell us whether it does or doesn't run.",
              "score": 5,
              "created_utc": "2026-01-09 17:47:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nylx0ol",
              "author": "AngelofKris",
              "text": "I was waiting for this comment ü§£",
              "score": 2,
              "created_utc": "2026-01-09 15:15:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nymh8f1",
                  "author": "Dear-Spend-2865",
                  "text": "I feel like my 3060 is living its last moments of AI usefulness...",
                  "score": 5,
                  "created_utc": "2026-01-09 16:46:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nykzcfr",
          "author": "mintybadgerme",
          "text": "I'm getting a bit confused. I'm running ltx2 using Pinokio and WANGP.\n Is that a good choice? Can you use these optimized models with that setup?",
          "score": 2,
          "created_utc": "2026-01-09 12:08:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nylbpa0",
          "author": "Secure-Message-8378",
          "text": "How convert audios in stereo?",
          "score": 2,
          "created_utc": "2026-01-09 13:26:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nylf6nn",
          "author": "marcoc2",
          "text": "ok, I am now even more confused. there are many files in this repo and no workflow to guide how to use them",
          "score": 2,
          "created_utc": "2026-01-09 13:46:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nylf7zp",
          "author": "Nevaditew",
          "text": "Dev is better than distilled but no Q6 dev yet?",
          "score": 2,
          "created_utc": "2026-01-09 13:46:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nylg2ds",
          "author": "Green-Ad-3964",
          "text": "Does q6 support hw acceleration for fp8 on ada/Blackwell?",
          "score": 2,
          "created_utc": "2026-01-09 13:50:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nylixk0",
          "author": "howardhus",
          "text": "you da real mvp",
          "score": 2,
          "created_utc": "2026-01-09 14:05:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nylo9kl",
          "author": "TheBestPractice",
          "text": "How much slower is it compared to fp8?",
          "score": 2,
          "created_utc": "2026-01-09 14:33:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyn3dqh",
              "author": "Maraan666",
              "text": "takes pretty much the same time for me with a 4060ti.",
              "score": 3,
              "created_utc": "2026-01-09 18:25:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nylro8r",
          "author": "skyrimer3d",
          "text": "Sorry how did you got that cool voice in the vid, it was by prompt only?",
          "score": 2,
          "created_utc": "2026-01-09 14:49:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nym2sep",
              "author": "ArtyfacialIntelagent",
              "text": "Not OP, but it's the original audio from The Princess Bride.",
              "score": 2,
              "created_utc": "2026-01-09 15:41:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nylzmqz",
          "author": "aziib",
          "text": "kijai is always lifesaver",
          "score": 2,
          "created_utc": "2026-01-09 15:27:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nym2x93",
          "author": "isnaiter",
          "text": "I had put a gguf converter on my webui üòÅ",
          "score": 2,
          "created_utc": "2026-01-09 15:42:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nym3dog",
          "author": "Rizzlord",
          "text": "how do i get that commit? downloaded? also i get AttributeError: 'VAE' object has no attribute 'latent\\_frequency\\_bins'",
          "score": 2,
          "created_utc": "2026-01-09 15:44:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nynu74v",
              "author": "JohnnyLeven",
              "text": "I was getting that too. Updating comfy and all custom nodes fixed it for me. While the workflow runs now, I just get noise output though.",
              "score": 2,
              "created_utc": "2026-01-09 20:27:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyo6m12",
                  "author": "additionalpylon2",
                  "text": "Can confirm you need to update kjnodes. Update all will get you past that. I am also getting noise output.\n\n  \nEdit: Its the gguf causing the noise. Works fine with the distilled transformer\\_only model",
                  "score": 2,
                  "created_utc": "2026-01-09 21:24:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nym4i2j",
          "author": "Nepharios",
          "text": "Anyone else noticed that LTX 2 seems to confuse belly and boobs? XD",
          "score": 2,
          "created_utc": "2026-01-09 15:49:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyniy8z",
              "author": "StickStill9790",
              "text": "It‚Äôs‚Ä¶ not not safe",
              "score": 2,
              "created_utc": "2026-01-09 19:35:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nymb2xc",
          "author": "marcoc2",
          "text": "how do I change this wf to do I2V?",
          "score": 2,
          "created_utc": "2026-01-09 16:19:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nymnopz",
          "author": "lordpuddingcup",
          "text": "LMFAO I LOVE IT!\n\nWhats the vram usage on Q4/Q6?, i'm considering offloading gemma to openrouter to avoid having to run the local llm",
          "score": 2,
          "created_utc": "2026-01-09 17:15:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nymp2b3",
          "author": "raz0099",
          "text": "Thanks",
          "score": 2,
          "created_utc": "2026-01-09 17:21:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nymt4l6",
          "author": "BackgroundMeeting857",
          "text": "Nice I can finally drop the --no-cache flag, huge speed up.",
          "score": 2,
          "created_utc": "2026-01-09 17:39:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyn1qef",
          "author": "35point1",
          "text": "Will this fix how long it takes to load the stupid Gemma text encoder that really doesnt need to be 26 freakin gigabytes?",
          "score": 2,
          "created_utc": "2026-01-09 18:18:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nynfum6",
          "author": "PestBoss",
          "text": "Mine appears to load/process fine through the whole process.\n\nBut then the output is garbled. First frame looks ok as per input image, but then it looks all like jelly squares and gargling audio.\n\nAnyone any clues to what is going on?\n\n\nI've just installed a new ComfyUI with latest pulls for everything and default workflows work ok, but seem to be a bit crashy with OOM.\n\n\nSo the GGUF approach seems much more sensible given the size of the files at play, especially the TE size!\n\n\n\nAlso I note that it does a half size pass, then upscales that with a model, then re-samples with the same model as the base passes + a LoRA.\n\nThese workflows don't feel very optimal to me. It feels like they could have done two in one with a switch and toggle the input checkpoint/gguf/first stage sampling.\n\nIe, the upscale pass seems common to both versions, dev and distilled?",
          "score": 2,
          "created_utc": "2026-01-09 19:21:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nynh13c",
          "author": "hatemakingnames1",
          "text": "Now do the rest of the movie",
          "score": 2,
          "created_utc": "2026-01-09 19:26:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nynuowl",
          "author": "drallcom3",
          "text": "When using the Kijai GGUF nodes, I get an error:\n\nGGUFLoaderKJ\n\n'dict' object has no attribute 'startswith'",
          "score": 2,
          "created_utc": "2026-01-09 20:29:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyo5xus",
              "author": "Choowkee",
              "text": "You are using the wrong GGUF node.\n\nYou need to use Unet loader (GGUF) node from the ComfyUI-GGUF pack",
              "score": 2,
              "created_utc": "2026-01-09 21:21:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyo6y1m",
                  "author": "drallcom3",
                  "text": "Yes, it works with that one. The results are still quite full of blurry and artifacts.",
                  "score": 2,
                  "created_utc": "2026-01-09 21:26:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyoa7p6",
          "author": "YMIR_THE_FROSTY",
          "text": "Cause GGUF Q6 is mixed precision, while FP8 is very much not.\n\nBut if you would have good scaled FP8 with post-training, that would be a lot different. Very likely better than Q6.",
          "score": 2,
          "created_utc": "2026-01-09 21:41:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyp2lc2",
          "author": "Haunting-Elephant587",
          "text": "https://preview.redd.it/ol8p1n3kxecg1.png?width=2192&format=png&auto=webp&s=0b85e944cd93a884754f56aa6ddc1b344e998da5\n\nOut of memory even with Q4 using rtx 5090 32GB Vram and 64RAM  WF [https://files.catbox.moe/4u7f5h.json](https://files.catbox.moe/4u7f5h.json)",
          "score": 2,
          "created_utc": "2026-01-10 00:04:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nypkl5h",
          "author": "Frogy_mcfrogyface",
          "text": "Im getting \n\n# LTXVEmptyLatentAudio\n\n'VAE' object has no attribute 'latent\\_frequency\\_bins'\n\nerror with the Kijai¬†workflow, any idea? it even happens when I use ltx-2-19b-distilled-fp8\\_transformer\\_only.safetensors. Strange. I was able to get the GGUF working in another workflow though but want to get the Kijai¬†wf going as it might be faster.",
          "score": 2,
          "created_utc": "2026-01-10 01:41:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nypr7hg",
              "author": "Different_Fix_2217",
              "text": "Make sure you have the most recent kijai nodes [**ComfyUI-KJNodes**](https://github.com/kijai/ComfyUI-KJNodes)",
              "score": 5,
              "created_utc": "2026-01-10 02:17:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyq5mgr",
                  "author": "Frogy_mcfrogyface",
                  "text": "Thanks, that fixed it. My first gen gave me static for some reason but its ok now.",
                  "score": 1,
                  "created_utc": "2026-01-10 03:40:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyqdjld",
          "author": "Ethrillo",
          "text": "Does anyone have a simple i2v workflow for gguf?",
          "score": 2,
          "created_utc": "2026-01-10 04:30:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyqiub3",
          "author": "DELOUSE_MY_AGENT_DDY",
          "text": "How do you change the workflow to use the non-distilled version of the model and raise the steps?",
          "score": 2,
          "created_utc": "2026-01-10 05:06:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyr4mcq",
          "author": "Zyj",
          "text": "So with 2x 3090 I can use FP16 I hope?\n(Also 128GB 8-channel RAM)",
          "score": 2,
          "created_utc": "2026-01-10 08:03:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyrvl0r",
          "author": "New_Physics_2741",
          "text": "Any idea how to fix this? \n\nhttps://preview.redd.it/qv6tlz65jicg1.png?width=1100&format=png&auto=webp&s=0e3816ce05b69b5456116255f31139530d419611",
          "score": 2,
          "created_utc": "2026-01-10 12:08:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nysq66p",
          "author": "Thistleknot",
          "text": "no i2v?\n\nedit: yw\n\n[https://gist.github.com/thistleknot/75f925f65d831fb2da09264b734aa8f9](https://gist.github.com/thistleknot/75f925f65d831fb2da09264b734aa8f9)",
          "score": 2,
          "created_utc": "2026-01-10 15:18:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nysz3dy",
          "author": "No_Damage_8420",
          "text": "I know few Finnish, they work really hard and dive deep. Besides, top ski jumpers in sports LOL KJ's enjoying his winter for sure, while GPU heats up the house.\n\nThanks KJ all you do, and enjoy it like us",
          "score": 2,
          "created_utc": "2026-01-10 16:03:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nytuz6g",
          "author": "Thistleknot",
          "text": "it would be nice if we could replicate the outcome w a prompt and workflow",
          "score": 2,
          "created_utc": "2026-01-10 18:34:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nykw7y2",
          "author": "a_beautiful_rhind",
          "text": "Since its 20gb at Q8, what resolution can you output on a 24gb GPU?\n\nThis smells like another model that needs raylight multi-gpu.",
          "score": 2,
          "created_utc": "2026-01-09 11:45:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nykwn21",
              "author": "Kiyushia",
              "text": "what is raylight, and does it increase speed ?",
              "score": 2,
              "created_utc": "2026-01-09 11:48:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nykwu6k",
                  "author": "a_beautiful_rhind",
                  "text": "I dunno if he supported LTX yet: https://github.com/komikndr/raylight\n\nIt lets you spread the model among GPUs so you aren't using system ram.",
                  "score": 2,
                  "created_utc": "2026-01-09 11:49:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nym6uzc",
          "author": "oldassveteran",
          "text": "The mighty Kijai has arrived ü§≤",
          "score": 2,
          "created_utc": "2026-01-09 16:00:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nykrac3",
          "author": "MASOFT2003",
          "text": "That's incredible !!\n\ndo you have any advice or recommendation before i download ?",
          "score": 2,
          "created_utc": "2026-01-09 11:05:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyyfsil",
          "author": "Real-Employer-2474",
          "text": "This is amazing",
          "score": 1,
          "created_utc": "2026-01-11 11:31:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyktek1",
          "author": "Shorties",
          "text": "Can this be run on a 10GB 3080 and if so how?",
          "score": 1,
          "created_utc": "2026-01-09 11:22:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyl0kr0",
          "author": "GroundbreakingLet986",
          "text": "Do you mind sharing your workflow as well ? :)",
          "score": 1,
          "created_utc": "2026-01-09 12:16:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nykrrwy",
          "author": "WildSpeaker7315",
          "text": "to be honest im seeig that wan2gp is better quality. comfyui blurry mess as soon as motion is involved. same prompt its like 10x better.. same resolution same distilled model.  if you have pinikio it takes like 10 mins to install and test yourself",
          "score": -6,
          "created_utc": "2026-01-09 11:09:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nymo2wf",
              "author": "lordpuddingcup",
              "text": "the default comfy workflow does a downsacle and reupscale at end i think thats why... just adjust the workflow lol, part of the issue is using comfy and not paying attention to what things are doing",
              "score": 3,
              "created_utc": "2026-01-09 17:17:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nymudvu",
                  "author": "WildSpeaker7315",
                  "text": "i am fully aware thank you i've trid to bypass the downscaling but the generation took 3x longer. this is slightly faster and more consistent. i like comfyui. i am just seeing whats what",
                  "score": 0,
                  "created_utc": "2026-01-09 17:45:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyl0c6p",
              "author": "tofuchrispy",
              "text": "But why is it better quality and can you please show examples.",
              "score": 2,
              "created_utc": "2026-01-09 12:15:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyl0kle",
                  "author": "WildSpeaker7315",
                  "text": "i'll go try my best to make a compare video for you bud, i think i have an idea how to do it",
                  "score": 2,
                  "created_utc": "2026-01-09 12:16:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nykv9cm",
              "author": "Sudden_List_2693",
              "text": "We all know at this point that it has currently way worse quality than any WAN models.  \nBut... it might get better? One can only hope.  \nCurrently I wouldn't use it for anything besides low quality memes though.   \nI have yet to see any \"decent\" quality work with it that involves anything more than slight talking, camera panning in either realistic or simple 3D style.",
              "score": 2,
              "created_utc": "2026-01-09 11:37:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nykwu4i",
                  "author": "Different_Fix_2217",
                  "text": "[https://files.catbox.moe/pvsa2f.mp4](https://files.catbox.moe/pvsa2f.mp4)  \nLtxv can look better than wan if you use the full non distilled model. And try Q8, its much closer to FP16 if you could not fit FP16 before. Same for wan that makes a huge difference.  \nThat said a part of how they made it so fast is the level of compression used. They said they would try to improve it further with 2.5 hopefully in Q1.",
                  "score": 1,
                  "created_utc": "2026-01-09 11:49:47",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nykvqdl",
                  "author": "WildSpeaker7315",
                  "text": "Don't forget we have all Been on wan, where prompting Is kinda easy because you know your only getting 5 seconds. Prompting for longer requires a thought process, merging multiple videos a storyboard is required , it's not a bad model and I'm currently using wan2gp from pinokio it seems better then comfyui and is allowing me to make a text to video and continue it with just 1 click",
                  "score": 1,
                  "created_utc": "2026-01-09 11:41:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nynhe1h",
          "author": "FaceDeer",
          "text": "Whew. I almost clicked the download button last night, but figured there wasn't any point since I wouldn't have time to try out LTX2 until later today. Saves a fair bit of bandwidth. :)",
          "score": 1,
          "created_utc": "2026-01-09 19:28:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nynkq0p",
              "author": "PestBoss",
              "text": "They've kinda buggered up this release.\n\nLTX released some bits, then a few days later ComfyUI said day0 support, but it wasn't really day0 and it's been rushed in my view.\nThe workflows are imo badly laid out for the local versions and learning from. They are however probably perfect for cloud users who just want a simpleton-level interface.\n\n\nAnd neither setup is really that great with OOMs and now GGUF with jelly videos (for me using GGUF at least), and now we have an utter shit-show of people posting all manner of random fixes/workflows and stuff which is just making it impossible to figure out what's any good.\n\nI'd wait a few weeks for it all to settle down personally.\n\n\nHopefully now LTX2.0 comes in separate files and GGUFs, ComfyUI team will fix the issues and release some new working workflows so it all just works as it should.\n\n\nNot having a bash of course. This is the nature of this kinda stuff. I'm just surprised that they didn't line all this stuff up properly before a release!?",
              "score": 5,
              "created_utc": "2026-01-09 19:43:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nynoc9l",
                  "author": "FaceDeer",
                  "text": "Yeah, I usually wait a little while anyway for exactly this reason. However, when ComfyUI tried auto-updating itself yesterday to the newest version it completely bricked itself and so I was reinstalling it from scratch anyway and figured I might as well take a look at this newfangled thing that it had bricked itself to support.\n\nThe cost of being on the cutting edge.",
                  "score": 2,
                  "created_utc": "2026-01-09 19:59:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyo144u",
                  "author": "Choowkee",
                  "text": "Its baffling because literally one day of testing the final workflow by giving it to someone to start fresh would catch most of these problems.\n\nIt seems the LTX devs/Comfy employed the good old rule of \"lets test in prod el oh el\".\n\nI still got it working on day1 but WAN2.2 release has been much smoother in comparison.",
                  "score": 2,
                  "created_utc": "2026-01-09 20:59:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyo504a",
          "author": "Friendly-Fig-6015",
          "text": "Oi, eu sou completamente iniciante... o que isso faz?  \nconsigo rodar com 5060 16gb e 32 de ram?",
          "score": 1,
          "created_utc": "2026-01-09 21:17:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyks04a",
          "author": "FxManiac01",
          "text": "what this actually brings to the table? like does it run faster or on lower vram or what exactly? as I can run destilled on 24 VRAM and could even on 16 or less.. so what actually this does differently with \"different\" loading models pipeline?",
          "score": 0,
          "created_utc": "2026-01-09 11:11:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyktu2k",
              "author": "Different_Fix_2217",
              "text": "Smaller (if using Q6), much higher quality quantization than fp8. Closer to FP16 so higher fidelity / smoother movement / better audio...\n\nHere is a old comparison for qwen for instance. I had a wan comparison but I'd have to dig through thousands of videos lol.\n\nhttps://preview.redd.it/ywjxxqbokbcg1.jpeg?width=7778&format=pjpg&auto=webp&s=ea6ee24b77071811b035229a8ffb8350230d2ed4",
              "score": 18,
              "created_utc": "2026-01-09 11:26:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nykucb0",
                  "author": "Kiyushia",
                  "text": "what about q8?",
                  "score": 4,
                  "created_utc": "2026-01-09 11:30:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nykuzvw",
                  "author": "gwynnbleidd2",
                  "text": "Wait, is that universally true? I assumed anything below Q8 was worse than fp8",
                  "score": 5,
                  "created_utc": "2026-01-09 11:35:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nylb37o",
                  "author": "ArtificialAnaleptic",
                  "text": "Do you have any advice on successfully running the GGUF. I posted a comment here and I'm getting stuck with issues: https://www.reddit.com/r/StableDiffusion/comments/1q8590s/thx_to_kijai_ltx2_ggufs_are_now_up_even_q6_is/nyl5na0/",
                  "score": 2,
                  "created_utc": "2026-01-09 13:23:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyvdsez",
                  "author": "FxManiac01",
                  "text": "hmm, do you really find fp8 that bad in this example? like only this, Q8 and fp16 is having that \"light black skin\" I think.. so not sure if lower quants are better.. sue fp8 is missing the ball.. so only q8 or fp16 are good enough I think",
                  "score": 2,
                  "created_utc": "2026-01-10 23:05:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyktsu2",
              "author": "LumaBrik",
              "text": "for those with limited ram and vram it will mean less swapping and in some cases less use of the paging file ... so maybe slightly quicker.",
              "score": 3,
              "created_utc": "2026-01-09 11:25:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nymqbln",
              "author": "lordpuddingcup",
              "text": "Macs can't use generic fp8/nv4, their are other systems than fp8, also Q8 tend to have better compression than fp8, you get closer to fp16 without the loss",
              "score": 2,
              "created_utc": "2026-01-09 17:27:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyksx6t",
              "author": "Kiyushia",
              "text": "my question too, and does it decrease ram usage",
              "score": 1,
              "created_utc": "2026-01-09 11:18:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyky4u7",
                  "author": "Remarkable_Bonus_547",
                  "text": "You have BF16 quality with half its requirements of storage and RAM.",
                  "score": 2,
                  "created_utc": "2026-01-09 11:59:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nykx0qx",
          "author": "CeFurkan",
          "text": "FP8 scaled is equal to Q8 and FP8 is always many times faster than GGUF. it is all about proper scaling",
          "score": -6,
          "created_utc": "2026-01-09 11:51:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyl1yts",
              "author": "No_Damage_8420",
              "text": "thats good point.\nWith Wan 2.2 Comfy fp8 was fastest, KJ fp8_scaled (proper scaling?) was slower and I guess better quality. Have to test again. And how both compare to Q8",
              "score": 3,
              "created_utc": "2026-01-09 12:26:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyl5ic2",
              "author": "RIP26770",
              "text": "FP8 = Q4_0",
              "score": 7,
              "created_utc": "2026-01-09 12:49:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nymmuaz",
                  "author": "CeFurkan",
                  "text": "nope. you are just not knowing what you talking about. I am quantizing FP8 Scaled myself intelligiently, just the process taking 2 hours on RTX 5090 and it is at Q8 level quality and at least 1.5-2x faster",
                  "score": -1,
                  "created_utc": "2026-01-09 17:11:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyl5ryh",
              "author": "Different_Fix_2217",
              "text": "https://preview.redd.it/0j6mrafylbcg1.png?width=923&format=png&auto=webp&s=2365d1b77d5ccc40de50e2e24da8919f693078f7\n\nYou are wrong, and my own experience also shows that fp8 is a good deal worse and scaled is slightly worse. GGUF is closer to fp16 side by side. The only benefit of fp8 is that it is faster on cards with FP8 tensor cores.\n\nBetter explanation:  \nFP8 is just FP8 but Q6 uses fp16 or even fp32 precision for quality critical tensors. It's a much smarter way of quanting. And fp8 scaled is basically just a way to try and \"translate\" some of said tensors for sake of speed (using fp8 cores) but it still is a loss in quality due to the translation as precision is lost. That is why GGUFs are slower. They DONT downcast those into fp8.",
              "score": 3,
              "created_utc": "2026-01-09 12:51:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nymmwjk",
                  "author": "CeFurkan",
                  "text": "nope. you are just not knowing what you talking about. I am quantizing FP8 Scaled myself intelligiently, just the process taking 2 hours on RTX 5090 and it is at Q8 level quality and at least 1.5-2x faster",
                  "score": 0,
                  "created_utc": "2026-01-09 17:11:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyl7xye",
              "author": "Busy_Aide7310",
              "text": "FP8 is Q4 quality 30% faster.",
              "score": 2,
              "created_utc": "2026-01-09 13:04:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nymmv7c",
                  "author": "CeFurkan",
                  "text": "nope. you are just not knowing what you talking about. I am quantizing FP8 Scaled myself intelligiently, just the process taking 2 hours on RTX 5090 and it is at Q8 level quality and at least 1.5-2x faster",
                  "score": 1,
                  "created_utc": "2026-01-09 17:11:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyl2kkb",
              "author": "Pyros-SD-Models",
              "text": "I have noticed that when people talk about AI, they often openly admit that they know absolutely nothing about it. Saying things like \"Q6 is better than FP8\" shows that you have no understanding of how any of this works. If that is the case, you should probably read up on the topic instead of spreading incorrect assumptions.\n\nOr if people try to explain LLMs in non-tech subs. unbelievable.",
              "score": -7,
              "created_utc": "2026-01-09 12:30:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyl7w1s",
                  "author": "Freonr2",
                  "text": "The issue with \"fp8\" in particular is no one is precise about what they mean and it could mean many things.  Mxfp8?  Tensorwise single quant fp8?  \n\nMicroscaling formats are going to be far better than naive or tensorwise scaling formats, even at lower bits.",
                  "score": 4,
                  "created_utc": "2026-01-09 13:04:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyl9g12",
                  "author": "Different_Fix_2217",
                  "text": "FP8 and the scaled FP8 used by comfy is farther from FP16 than Q6, it is a fact.",
                  "score": 2,
                  "created_utc": "2026-01-09 13:13:50",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nym8hxw",
          "author": "WrongPerformance2936",
          "text": "Non riesco a trovare il WF gguf funzionante",
          "score": 0,
          "created_utc": "2026-01-09 16:07:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nypgkeg",
          "author": "Great_Traffic1608",
          "text": "what,Q6 is better quality than FP8?",
          "score": 0,
          "created_utc": "2026-01-10 01:19:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyl7zxw",
          "author": "JezPiquel",
          "text": "lol I know you ripped this off discord. Op is a content thief.",
          "score": -3,
          "created_utc": "2026-01-09 13:05:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nylatc8",
              "author": "marcoc2",
              "text": "what server/channel?",
              "score": 2,
              "created_utc": "2026-01-09 13:21:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyld5bp",
                  "author": "JezPiquel",
                  "text": "Either comfy or banodoco",
                  "score": -1,
                  "created_utc": "2026-01-09 13:35:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qatbuy",
      "title": "LTX2 t2v is totally capable of ruining your childhood.",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/ooevsrr5twcg1",
      "author": "chukity",
      "created_utc": "2026-01-12 12:14:45",
      "score": 659,
      "num_comments": 106,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Animation - Video",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1qatbuy/ltx2_t2v_is_totally_capable_of_ruining_your/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nz5fokm",
          "author": "StrangeWorldd",
          "text": "AI is both beautiful and scary.",
          "score": 147,
          "created_utc": "2026-01-12 12:24:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5togd",
              "author": "ready-eddy",
              "text": "Crazy ex GF energy",
              "score": 29,
              "created_utc": "2026-01-12 13:51:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5uavx",
          "author": "plugthree",
          "text": "![gif](giphy|mCClSS6xbi8us)",
          "score": 69,
          "created_utc": "2026-01-12 13:55:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6wcht",
              "author": "misterflyer",
              "text": "Cat videos‚òùüèª‚òùüèª‚òùüèª\n\nCat videos are on the verge of internet extinction. If I was to generate a... no, no... if I was to generate a 70 second compilation of cat videos in LTX-2, YOU ü´µüèª WOULDN'T have anything to say.",
              "score": 7,
              "created_utc": "2026-01-12 17:00:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5qsw9",
          "author": "protector111",
          "text": "this is by far the best quality 2D iv seen from the model. what FW are you using?",
          "score": 54,
          "created_utc": "2026-01-12 13:35:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6enlf",
              "author": "000TSC000",
              "text": "It's crazy the quality variance we are witnessing right now with this model, putting together a list of best practices, ironing out current memory issues, and optimizing/fixing the current workflows I believe will soon make all the difference. Exciting times.",
              "score": 24,
              "created_utc": "2026-01-12 15:39:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz79snc",
                  "author": "protector111",
                  "text": "Kijai is making good progress lowering vram hunger of this mode. And devs promise updates very soon. Im sure in 6 months this mode will be the SOTA",
                  "score": 13,
                  "created_utc": "2026-01-12 18:02:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz6rc1i",
                  "author": "Dirty_Dragons",
                  "text": "This is exactly why I haven't even downloaded it yet. I've read so many reports of mixed results. \n\nThe potential is huge but just not consistent.",
                  "score": 4,
                  "created_utc": "2026-01-12 16:38:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz9pjl3",
                  "author": "SubtleAesthetics",
                  "text": "I havent had issues using the q8 from kijai and making 10 second gens, even on a 4080 with 16gb ram at around 900x900 just for testing: I have 64gb system ram and comfy is using both so it works great.\n\nproblem is aside from gpus, ram is expensive so getting more if needed, may not be so simple for many users.  but the good news is you don't *need* a 4090 or 5090 for a minimum vram requirement.",
                  "score": 2,
                  "created_utc": "2026-01-13 01:08:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz9wyv8",
              "author": "Lover_of_Titss",
              "text": "It looks better than the Sora SpongeBob videos that I‚Äôve seen.",
              "score": 2,
              "created_utc": "2026-01-13 01:49:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5j26x",
          "author": "Totem_House_30",
          "text": "were can you watch the whole season? asking for a friend",
          "score": 63,
          "created_utc": "2026-01-12 12:47:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz60cah",
          "author": "Robot1me",
          "text": ">LTX2 t2v is totally capable of ruining your childhood\n\nDon't worry, newer Spongebob episodes have already done that for us :P",
          "score": 27,
          "created_utc": "2026-01-12 14:27:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6fz2m",
              "author": "Secure-Message-8378",
              "text": "Genau.",
              "score": 4,
              "created_utc": "2026-01-12 15:46:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz6qhis",
              "author": "QueZorreas",
              "text": "And the movies. Ooooooh the movies üòñ",
              "score": 4,
              "created_utc": "2026-01-12 16:34:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5vzaa",
          "author": "_raydeStar",
          "text": "This is amazing. \n\nEven the voices are pretty good.",
          "score": 23,
          "created_utc": "2026-01-12 14:04:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6708v",
          "author": "Keyflame_",
          "text": "I'm starting to think LTX-2 is mega-overtrained on cartoons, all cartoon results I see are ridiculously sharper and way more motion accurate than realistic footage.\n\nMaybe that's the real use case, we have an animation-oriented model.",
          "score": 18,
          "created_utc": "2026-01-12 15:02:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz9mqq4",
              "author": "Different_Fix_2217",
              "text": "Nah, its the temporal and spatial compression being so high that hurts smaller details which 2d cartoons have less of. You can offset it with higher res and fps. [https://files.catbox.moe/pvsa2f.mp4](https://files.catbox.moe/pvsa2f.mp4)  \nHopefully they can find a better middle ground with 2.5.",
              "score": 8,
              "created_utc": "2026-01-13 00:52:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz9oviq",
                  "author": "Keyflame_",
                  "text": "I mean you're right in concept, as in yes, that's true, but everything LTX produces still has weird lighting and looks like it's smeared in vasoline even when it's sharper, that's mostly what I'm referring to.\n\nEdit: Aight guys, got it, can't speak ill of the new thing, we're gonna have this convo in a few months when you are ready to get off the hype train.",
                  "score": 1,
                  "created_utc": "2026-01-13 01:04:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz6h6fy",
              "author": "Secure-Message-8378",
              "text": "But the community can train LORAS for the other cases.",
              "score": 4,
              "created_utc": "2026-01-12 15:51:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5lc6s",
          "author": "Interesting_Room2820",
          "text": "straight-up barnacles, it belongs in Rock Bottom. ü§¶",
          "score": 11,
          "created_utc": "2026-01-12 13:02:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5o39a",
          "author": "Secure-Message-8378",
          "text": "Early sora 2 vibes.",
          "score": 33,
          "created_utc": "2026-01-12 13:19:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz640cp",
              "author": "florodude",
              "text": "SORA 2 been all downhill since then.",
              "score": 18,
              "created_utc": "2026-01-12 14:47:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz6zxzu",
                  "author": "tastethemonkey",
                  "text": "I think they keep the good models to themselves",
                  "score": 9,
                  "created_utc": "2026-01-12 17:17:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz6f9a9",
                  "author": "Secure-Message-8378",
                  "text": "That's true.",
                  "score": 4,
                  "created_utc": "2026-01-12 15:42:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz5q27r",
          "author": "Producing_It",
          "text": "What model, resolution, and framerate did you use? These are pretty clean results compared to the weird artifacts I get with the full fp8 version.",
          "score": 9,
          "created_utc": "2026-01-12 13:31:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5z3nv",
          "author": "AfterAte",
          "text": "How much VRAM does one need to create this?",
          "score": 6,
          "created_utc": "2026-01-12 14:21:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6f6vd",
              "author": "Secure-Message-8378",
              "text": "8GB VRAM.",
              "score": 8,
              "created_utc": "2026-01-12 15:42:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz6mxsa",
                  "author": "Academic_Storm6976",
                  "text": "My 3060 about to go on its 26th final ride¬†",
                  "score": 8,
                  "created_utc": "2026-01-12 16:18:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz6h1i3",
                  "author": "AfterAte",
                  "text": "That's amazing. This is one of the best LTX2 videos I've seen.",
                  "score": 3,
                  "created_utc": "2026-01-12 15:51:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz5k6lr",
          "author": "krigeta1",
          "text": "This video is so amazing, good motion, good clarity, how can we achieve that? Yes prompts too.",
          "score": 12,
          "created_utc": "2026-01-12 12:55:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz604lh",
          "author": "QikoG35",
          "text": "The audio was made with LTX2 ?",
          "score": 5,
          "created_utc": "2026-01-12 14:26:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6fvg7",
              "author": "Secure-Message-8378",
              "text": "Yep!",
              "score": 5,
              "created_utc": "2026-01-12 15:45:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz6l3uw",
          "author": "ibelieveyouwood",
          "text": "This is fun and interesting to see.  I think instead of ruining our childhoods, the worst part is going to be validating weird fuzzy memories of a half-remembered scene that got meme'd to death.\n\nWhat's funny to me is that the gen ai community is so split between people who hyperfixate on the f8p20bt2v64gbmp3iptv4k settings and the people who think you just click a link to make Cookie Monster swear.  Any given day, someone could put out 3 lines of code and this sub is flooded by amazing quality creations by people who just casually understood that it's a function they unlock using an Xbox controller on Club Penguin.  Or it's \"bro, can you just send me the json because my prompt of 'Tswift saying Arnold I love you you're my real love 4k nude stunning no moustache -horse -ugly' made my Gameboy camera lose a pixel.\"\n\nRight now there's absolutely one group figuring out how to use this to make their coterie of gacha girls mew for them, and another who think they're mad hackers because they typed \"clip of Pinkie Pie saying fart on me\" into a box and the result was less than nightmare fuel.",
          "score": 6,
          "created_utc": "2026-01-12 16:09:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz64bcz",
          "author": "Romando1",
          "text": "Lmao",
          "score": 3,
          "created_utc": "2026-01-12 14:48:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz65byz",
          "author": "No_Ratio_5617",
          "text": "Im ‚ò†Ô∏è‚ò†Ô∏è‚ò†Ô∏è‚ò†Ô∏è",
          "score": 4,
          "created_utc": "2026-01-12 14:53:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz95eh3",
          "author": "sirdrak",
          "text": "I've been doing some testing, and other series that it does well are Steven Universe (although in this case it is not enough to simply give the names of the characters, you also have to describe them a little), and Teen Titans Go. I also tried with the Simpsons, but I wasn't so lucky with that one, although it seems the model knows some basic aspects of the characters. It seems that his preference is for Cartoon Network series. It even does the voices correctly in languages ‚Äã‚Äãother than English.",
          "score": 4,
          "created_utc": "2026-01-12 23:19:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5jv34",
          "author": "Harouto",
          "text": "Any chance to share the full prompt? If it's true, it's really impressive for t2v!",
          "score": 7,
          "created_utc": "2026-01-12 12:52:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5lr1k",
              "author": "chukity",
              "text": "I just write something like this:  \nan animated medium shot from the show Spongebob square pants. Spongebob is lying on the ground, dying. Patrick screams: These motherfuckers are going to pay for this!\"\n\nan let the enhancer do the rest of the work.  \nthe cool part comes when you accidentally get a realistic shot, like those nice close ups from Ren & Stimpy",
              "score": 22,
              "created_utc": "2026-01-12 13:05:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz5pznu",
                  "author": "EbbNorth7735",
                  "text": "Do you need to feed it audio recordings for the voices?",
                  "score": 6,
                  "created_utc": "2026-01-12 13:30:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz5t4mc",
                  "author": "Harouto",
                  "text": "Is that the full prompt? I got something completely different.",
                  "score": 2,
                  "created_utc": "2026-01-12 13:48:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz6mz9t",
                  "author": "Robbsaber",
                  "text": "[https://streamable.com/unrynu](https://streamable.com/unrynu)   Got this on the first try with your prompt and enabling prompt enhancer in wan2gp lol",
                  "score": 2,
                  "created_utc": "2026-01-12 16:18:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz995bw",
                  "author": "mugen7812",
                  "text": "So you just needed to say \"spongebob\" for it to be recognized and output the correct voice? wtf?",
                  "score": 2,
                  "created_utc": "2026-01-12 23:39:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz9be8j",
                  "author": "Jonno_FTW",
                  "text": "The technical term for those close-ups in Spongebob is [\"gross-up\"](https://tvtropes.org/pmwiki/pmwiki.php/Main/GrossUpCloseUp)",
                  "score": 2,
                  "created_utc": "2026-01-12 23:52:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz6y0nv",
              "author": "sirdrak",
              "text": "It works really well... Even with simple prompts, it's almost perfect, voices and everything... I'm having a lot of fun with this.",
              "score": 3,
              "created_utc": "2026-01-12 17:08:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5tsnm",
          "author": "OtherVersantNeige",
          "text": "![gif](giphy|wFmJu7354Csog)\n\nWell, I suppose Castle Bravo was not sufficient enough It's time to use another nuke",
          "score": 3,
          "created_utc": "2026-01-12 13:52:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzbgwzl",
              "author": "Murky-Relation481",
              "text": "That gif is Crossroads Baker which was roughly 800x-1000x smaller than Castle Bravo.",
              "score": 1,
              "created_utc": "2026-01-13 08:02:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz7beum",
          "author": "Tyler_Zoro",
          "text": "This show didn't exist when I was a child. I don't care what you do it it. You leave Micronauts alone, though!",
          "score": 3,
          "created_utc": "2026-01-12 18:09:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7nu5d",
          "author": "kek0815",
          "text": "Finally approaching interdimensional television",
          "score": 3,
          "created_utc": "2026-01-12 19:05:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7yjmh",
          "author": "smflx",
          "text": "Omg",
          "score": 3,
          "created_utc": "2026-01-12 19:54:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz81a7w",
          "author": "DMmeURpet",
          "text": "How did you get the voices so accurate",
          "score": 3,
          "created_utc": "2026-01-12 20:07:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz9loky",
              "author": "chukity",
              "text": "It just knows I guess",
              "score": 2,
              "created_utc": "2026-01-13 00:47:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5g3jn",
          "author": "No_Clock2390",
          "text": "oh my fucking god this is great",
          "score": 7,
          "created_utc": "2026-01-12 12:27:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5twqq",
          "author": "marieascot",
          "text": "The prompt was \"Show me the hidden Spongebob clips that that were only made for internal use\" Th AI just hacked the production companies servers to save processing time.",
          "score": 2,
          "created_utc": "2026-01-12 13:52:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5xm6t",
          "author": "xp3rf3kt10n",
          "text": "We are gonna need ratings above X for what some people are gonna make lol",
          "score": 2,
          "created_utc": "2026-01-12 14:13:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz61xg0",
          "author": "Apixelito25",
          "text": "Could you share the prompts used to achieve these results?",
          "score": 2,
          "created_utc": "2026-01-12 14:36:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz63r07",
          "author": "florodude",
          "text": "Did you have to do anything to prompt these voices or did it just know?",
          "score": 2,
          "created_utc": "2026-01-12 14:45:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz9lf1d",
              "author": "chukity",
              "text": "It knows",
              "score": 2,
              "created_utc": "2026-01-13 00:45:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz67cb2",
          "author": "aifirst-studio",
          "text": "tried the same with the simpsons but it seems to not know them :(",
          "score": 2,
          "created_utc": "2026-01-12 15:04:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz9ljtw",
              "author": "chukity",
              "text": "Yeah, tried it with Southpark as well and didnt get it.",
              "score": 2,
              "created_utc": "2026-01-13 00:46:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz680q9",
          "author": "darkkite",
          "text": "legit better than the new official animation",
          "score": 2,
          "created_utc": "2026-01-12 15:07:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6dwyn",
          "author": "antonydudani",
          "text": "How did you do it like with the perfect art style and voices? It's hilarious :D",
          "score": 2,
          "created_utc": "2026-01-12 15:36:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6q7e5",
          "author": "a_beautiful_rhind",
          "text": "Hell no.. this is awesome.",
          "score": 2,
          "created_utc": "2026-01-12 16:33:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6q7kr",
          "author": "Bleezyboomboom",
          "text": "Stop.",
          "score": 2,
          "created_utc": "2026-01-12 16:33:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz725zv",
          "author": "shoot2will",
          "text": "August 12 2036. The heat death of the universe.",
          "score": 2,
          "created_utc": "2026-01-12 17:27:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz786dq",
          "author": "RaidensReturn",
          "text": "This is so cursed",
          "score": 2,
          "created_utc": "2026-01-12 17:55:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7a3di",
          "author": "aifirst-studio",
          "text": "i wonder if they forgot to obfuscate spongebob & adventure time specifically because that's the only 2 shows i'm able to get",
          "score": 2,
          "created_utc": "2026-01-12 18:03:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7zcrq",
          "author": "doublesunk",
          "text": "Time stamp :30",
          "score": 2,
          "created_utc": "2026-01-12 19:58:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz83neq",
          "author": "Secure-Message-8378",
          "text": "Testing with Peppa Pig and Mr. Bean. Wan2GP (4070Ti 12GB VRAM). [https://imgur.com/a/IosIU64](https://imgur.com/a/IosIU64)",
          "score": 2,
          "created_utc": "2026-01-12 20:18:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz9lvvi",
              "author": "chukity",
              "text": "Tried it with Peppa but felt way too dark to make them say bad things.",
              "score": 3,
              "created_utc": "2026-01-13 00:48:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz9p84q",
          "author": "SubtleAesthetics",
          "text": "if you i2v with spongebob and patrick, and prompt a conversation, it knows their voices 1:1.  actually amazing stuff, now i'm curious what other characters it knows natively.",
          "score": 2,
          "created_utc": "2026-01-13 01:06:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzach1a",
          "author": "hereagaim",
          "text": "Sandy somehow looked hot to me when i was young... wtf?",
          "score": 2,
          "created_utc": "2026-01-13 03:11:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5md5k",
          "author": "SavageFridge",
          "text": "Stupid question: How can I use? It is a website? Never heard of this one",
          "score": 2,
          "created_utc": "2026-01-12 13:09:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5p1ku",
              "author": "No_Clock2390",
              "text": "[https://github.com/deepbeepmeep/Wan2GP](https://github.com/deepbeepmeep/Wan2GP)",
              "score": 8,
              "created_utc": "2026-01-12 13:25:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz5p36c",
              "author": "Secure-Message-8378",
              "text": "The easiest way to use is wan2gp in pinokio.",
              "score": 4,
              "created_utc": "2026-01-12 13:25:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz8seud",
                  "author": "Arumin",
                  "text": "Can extensions also be installed through this?",
                  "score": 2,
                  "created_utc": "2026-01-12 22:14:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz6i0mw",
          "author": "1filipis",
          "text": "Anti-AI scum comes and cries to put you in jail for this in 3... 2... 1...",
          "score": 3,
          "created_utc": "2026-01-12 15:55:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5emk2",
          "author": "jingtianli",
          "text": "hahahahaha!! Funny, but i think this should be posted in Unstable diffusion subreddit",
          "score": 1,
          "created_utc": "2026-01-12 12:16:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5i69j",
              "author": "chukity",
              "text": "hope not",
              "score": 7,
              "created_utc": "2026-01-12 12:41:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzb44ka",
          "author": "Vyviel",
          "text": "Audio sounds terrible",
          "score": 1,
          "created_utc": "2026-01-13 06:09:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzba66k",
          "author": "ZealousidealDrop7475",
          "text": "Hell nah, this is nightmare maker machines.üíÄ",
          "score": 1,
          "created_utc": "2026-01-13 07:00:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbaktn",
          "author": "Mehmed_Conq134",
          "text": "Tf did I just watch ?",
          "score": 1,
          "created_utc": "2026-01-13 07:04:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5x9zh",
          "author": "M4xs0n",
          "text": "How",
          "score": 1,
          "created_utc": "2026-01-12 14:11:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6f41i",
          "author": "sevenfold21",
          "text": "Sooner or later, we'll have a list of everything LTX2 was trained on.  SpongeBob and SquarePants, checked.",
          "score": 1,
          "created_utc": "2026-01-12 15:42:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7b4q9",
          "author": "Current-Rabbit-620",
          "text": "This is definitely Nsfw....",
          "score": 1,
          "created_utc": "2026-01-12 18:08:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz9em2l",
          "author": "desktop4070",
          "text": "OP, can you share upload a video to Catbox? It'll include the workflow via the metadata through there https://catbox.moe/  \n  \nI really want to know what's different between the ComfyUI default template and your workflow.",
          "score": 0,
          "created_utc": "2026-01-13 00:09:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz9m3ja",
              "author": "chukity",
              "text": "I‚Äôll share something tomorrow.",
              "score": 2,
              "created_utc": "2026-01-13 00:49:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5gm1d",
          "author": "RepresentativeRude63",
          "text": "could you share the prompt? there no way T2V can handle that sarcasm,",
          "score": -4,
          "created_utc": "2026-01-12 12:30:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5hdg1",
              "author": "FilthyDirtyTrain",
              "text": "Learn what sarcasm means first",
              "score": 10,
              "created_utc": "2026-01-12 12:36:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz5i2i4",
                  "author": "RepresentativeRude63",
                  "text": "and the prompt is using it for the cartoon characterts.",
                  "score": -3,
                  "created_utc": "2026-01-12 12:40:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzbh4qy",
              "author": "Murky-Relation481",
              "text": "The emotion I get out of LTX is legit better than dedicated text to speech models.",
              "score": 1,
              "created_utc": "2026-01-13 08:04:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz7qyzk",
          "author": "isagi849",
          "text": "Why op is not replying to any questions on this post?",
          "score": -1,
          "created_utc": "2026-01-12 19:19:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2893h",
      "title": "I made BookForge Studio, a local app for using open-source models to create fully voiced audiobooks! check it out ü§†",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/eec4dkb9nzag1",
      "author": "hemphock",
      "created_utc": "2026-01-02 19:35:51",
      "score": 642,
      "num_comments": 52,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q2893h/i_made_bookforge_studio_a_local_app_for_using/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nxb2o9n",
          "author": "hemphock",
          "text": "Git repo: https://github.com/kenning/bookforge-studio\n\nYoutube tutorial: https://www.youtube.com/watch?v=1PT_CjX_hek\n\n['Voice clips sampler' dataset to get started with voice cloning (built into BookForge Studio)](https://huggingface.co/datasets/nick-mccormick/tts-voices-sampler?not-for-all-audiences=true)\n\n[Dataset of 24 copyright-free classic books with speakers annotated (also built into BookForge Studio](https://huggingface.co/datasets/nick-mccormick/ANITA/tree/main)\n\n### Chatterbox Turbo is now in BookForge Studio!\n\nAmong all the other features, this model is 2-4x faster than speech and supports full voice cloning. Getting Chatterbox Turbo working made the experience of using BookForge finally feel \"ready for the general public,\" i.e. not too slow and clumsy; not tempting to alt-tab away while generating audio, because it's fast enough. Kind of like the difference between generating videos, or with early Flux (maybe just walk away from the computer for a bit) and generating with SDXL, which feels more like a slot machine.\n\nHowever it came out after I recorded the above videos! So I don't mention it in the videos, but I strongly recommend you try it out.",
          "score": 37,
          "created_utc": "2026-01-02 19:36:06",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nxbfx93",
          "author": "JealousBid3992",
          "text": "Some insane UX work here, I definitely am gonna check it out and leave a star.\n\nI don't see this being too viable as a SaaS with all the automations by big players nowadays so I think open sourcing was the move. \n\nHighly interested in collaborating on something with you if you're looking to work with other devs, on both open source and commercial stuff.",
          "score": 15,
          "created_utc": "2026-01-02 20:40:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxbh734",
              "author": "hemphock",
              "text": "dm'ed you!",
              "score": 4,
              "created_utc": "2026-01-02 20:46:59",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nxf0u10",
              "author": "Lavio00",
              "text": "\\> I don't see this being too viable as a SaaS with all the automations by big players nowadays so I think open sourcing was the move.\n\nCurious to know what you mean by this? Ive written 2.5 novels in a year and am shopping for audiobook narrators. Would love to know how I can utilize AI for the audiobooks.",
              "score": 1,
              "created_utc": "2026-01-03 10:28:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxb5yf0",
          "author": "K0owa",
          "text": "Fully free and open source?",
          "score": 23,
          "created_utc": "2026-01-02 19:51:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxb9lgq",
              "author": "hemphock",
              "text": "yup, in fact i actually built out support for IndexTTS2 on a branch, but didn't push because it has [this sketchy license](https://github.com/index-tts/index-tts?tab=License-1-ov-file#readme) which would make the whole thing non-MIT license.",
              "score": 38,
              "created_utc": "2026-01-02 20:09:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxbgrws",
                  "author": "Silver-Belt-",
                  "text": "Normally that's only if you bring it with the app, not for supporting it. What's the problem? I'm deep into licenses. Perhaps I can help.",
                  "score": 19,
                  "created_utc": "2026-01-02 20:44:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxhq96d",
                  "author": "DemadaTrim",
                  "text": "Oh, that's cool. IndexTTS2 was what I was looking for because IMX that's the best local TTS out there.",
                  "score": 1,
                  "created_utc": "2026-01-03 19:31:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxbq71e",
          "author": "anydezx",
          "text": "It looks fantastic! I haven't tried it yet, and probably won't for a few days because I'm really busy, but I appreciate your time and effort. Most users don't realize that behind these kinds of tools there's someone who invested time and lost money creating them, since they could have easily done something else. Unless you're Kjai or have financial backing, that's the harsh truth. One quick question my friend: I only glanced at the README file. How many minutes can it run before it goes haywire? Most open-source TTS systems crash after a certain number of minutes or tokens and lose their minds. Needless to say, thank you so much my anonymous hero!ü§ü",
          "score": 9,
          "created_utc": "2026-01-02 21:30:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxhtmu2",
              "author": "hemphock",
              "text": "thanks a lot!",
              "score": 1,
              "created_utc": "2026-01-03 19:47:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxder6x",
          "author": "Nakidnakid",
          "text": "Seems neat but it broke as soon as I fed in a document with multiple chapters, it wouldn't come back without a restart and it just seems non-intuitive to work with especially when coming from 'ultimate-tts-studio-sup3r-edition' where I can just feed it my manuscript with multiple chapters and it'll segment it properly.\n\nHope you keep working on it and can deliver at least feature parity to that app while making it easier to work with as I'd like to be able to create consistent voices over multiple chapters or customise it.",
          "score": 6,
          "created_utc": "2026-01-03 03:02:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxek1ni",
              "author": "hemphock",
              "text": "hadn't heard of this app, looks very similar haha",
              "score": 1,
              "created_utc": "2026-01-03 08:03:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxb8d1i",
          "author": "psdwizzard",
          "text": "Dude this look great!!",
          "score": 3,
          "created_utc": "2026-01-02 20:03:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxc7f3w",
          "author": "tintwotin",
          "text": "What is your favorite speech model? I'm pretty happy about Chatterbox - and also did a bit of testing on their Turbo model, but for some reason the volume is much lower than the non-turbo model.",
          "score": 3,
          "created_utc": "2026-01-02 22:57:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxejyms",
              "author": "hemphock",
              "text": "chatterbox turbo is very nice just because it supports voice cloning but it's really fast. but vibevoice i think is overall a better model just because it can support really long text and you don't have to do crazy chunking/preprocessing stuff to get it to work on something longer than ten words. i think the small and large vibevoice models are both great, the large one sounds almost perfect if you have the graphics card for it.\n\ni go into some more detail in my youtube video",
              "score": 4,
              "created_utc": "2026-01-03 08:02:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxcnv7d",
          "author": "Bippychipdip",
          "text": "this was an idea i had a while ago and could never get it started so thank you for creating this !",
          "score": 3,
          "created_utc": "2026-01-03 00:27:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxbxjwe",
          "author": "Green-Ad-3964",
          "text": "great! what languages does it support?",
          "score": 2,
          "created_utc": "2026-01-02 22:06:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxejo4x",
              "author": "hemphock",
              "text": "only english for now, but if there's interest it could do more!",
              "score": 2,
              "created_utc": "2026-01-03 07:59:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxekwxk",
                  "author": "ThinkingWithPortal",
                  "text": "Would Spanish be difficult to adapt? I don't have a ton of knowledge on the TTS/translation side of generative AI tech, but seems to me it's mostly around English and Chinese",
                  "score": 1,
                  "created_utc": "2026-01-03 08:10:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxc3ntz",
          "author": "hidden2u",
          "text": "Nice, I use psdwizzard‚Äôs chatterbox audiobook pretty extensively so excited to try this",
          "score": 2,
          "created_utc": "2026-01-02 22:37:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxcdl62",
          "author": "Warsel77",
          "text": "Great work! Thank you.",
          "score": 2,
          "created_utc": "2026-01-02 23:30:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxce3pv",
          "author": "Infinite-Ad1720",
          "text": "I‚Äôm thinking this would be great for some of the Books on Project Gutenberg! Especially the UFO books!",
          "score": 2,
          "created_utc": "2026-01-02 23:33:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxd2dnf",
          "author": "2legsRises",
          "text": "looks so good, does it make a finished audiobook or read along to you in realtime?",
          "score": 2,
          "created_utc": "2026-01-03 01:50:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxdb7j6",
          "author": "rc_ym",
          "text": "I'll have to check it out.  I usually just use a python script and kokoro (with some custom filters).",
          "score": 2,
          "created_utc": "2026-01-03 02:41:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxb55k2",
          "author": "WildSpeaker7315",
          "text": "worth making it avialble for pinokio?",
          "score": 2,
          "created_utc": "2026-01-02 19:48:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxb99bv",
              "author": "hemphock",
              "text": "i'll look into this, i've only heard about it but haven't looked into it yet. are people doing this a lot?",
              "score": 6,
              "created_utc": "2026-01-02 20:07:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxbdol5",
                  "author": "WildSpeaker7315",
                  "text": "yeah most audio stuffs on there, makes life esier its just 1 click u can get nearly anything on pinokio inluding comfyui",
                  "score": 3,
                  "created_utc": "2026-01-02 20:29:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxb4ixw",
          "author": "radlinsky",
          "text": "This looks amazing. Star'd the repo. Gonna try it out as soon as I get my new PC set up.",
          "score": 2,
          "created_utc": "2026-01-02 19:44:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxb9s92",
              "author": "hemphock",
              "text": "thanks!!!",
              "score": 1,
              "created_utc": "2026-01-02 20:10:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxbafar",
          "author": "mattbenscho",
          "text": "Love it!! I want it to learn Chinese, and to generate courses for my Chinese learning webapp. Any chance for foreign language support?",
          "score": 2,
          "created_utc": "2026-01-02 20:13:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxbcgxq",
              "author": "hemphock",
              "text": "this has been a small side project, not sure how much people want this kind of thing -- if it takes off i think i could work on that for sure!",
              "score": 6,
              "created_utc": "2026-01-02 20:23:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxgw6qh",
                  "author": "Benschman1979",
                  "text": "I would also appreciate the option to use it in German.",
                  "score": 1,
                  "created_utc": "2026-01-03 17:14:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxbxrfu",
                  "author": "Green-Ad-3964",
                  "text": "Please do. Also German, Italian and French would be great on my side.",
                  "score": -1,
                  "created_utc": "2026-01-02 22:07:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxce80k",
          "author": "Regular-Forever5876",
          "text": "Congrats!! Thanks for sharing :)",
          "score": 1,
          "created_utc": "2026-01-02 23:34:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxcglgb",
          "author": "Artistic_Okra7288",
          "text": "This is pretty awesome, congrats and thanks for releasing it to the world!",
          "score": 1,
          "created_utc": "2026-01-02 23:47:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxcxpu5",
          "author": "venpuravi",
          "text": "I like the UI. Which tool is it? Gradio or something else?",
          "score": 1,
          "created_utc": "2026-01-03 01:23:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxek2vu",
              "author": "hemphock",
              "text": "made it myself with react",
              "score": 2,
              "created_utc": "2026-01-03 08:03:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxdzc0g",
          "author": "getSAT",
          "text": "Thanks for releasing this. So are you able to copy an existing voice for this?\n\nThis would be very useful for creating audiobooks of light novels that have an anime adaption.",
          "score": 1,
          "created_utc": "2026-01-03 05:15:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxek6a4",
              "author": "hemphock",
              "text": "yup the main goal was to architect a system for voice cloning *per character* so the dialogues between characters sounded realistic",
              "score": 2,
              "created_utc": "2026-01-03 08:04:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxe5wzk",
          "author": "veganoel",
          "text": "It reminds me of BeFreed, has anyone tried that before?",
          "score": 1,
          "created_utc": "2026-01-03 06:04:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxf7tnv",
          "author": "Lavio00",
          "text": "This is super interesting!",
          "score": 1,
          "created_utc": "2026-01-03 11:27:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxgfhyq",
          "author": "qrayons",
          "text": "Already a great tool but it would be way more useful if it was able to automatically assign speakers. Like take a regular ebook and first have an llm go through it and assign the speaker/voice to each section of text, and then have the rest of the app run the text to speech.",
          "score": 1,
          "created_utc": "2026-01-03 15:56:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxhbk3d",
          "author": "wonteatyourcat",
          "text": "Really cool, following:)",
          "score": 1,
          "created_utc": "2026-01-03 18:24:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxj2r1f",
          "author": "GlassSignal",
          "text": "Great work! Are other languages than English supported?",
          "score": 1,
          "created_utc": "2026-01-03 23:33:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxv8opp",
          "author": "Package-Famous",
          "text": "OMG! This is totally AWESOME!¬†\n\n\nMy wife's going to love this!¬†",
          "score": 1,
          "created_utc": "2026-01-05 19:07:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q08ro5",
      "title": "Qwen-Image-2512 released on Huggingface!",
      "subreddit": "StableDiffusion",
      "url": "https://huggingface.co/Qwen/Qwen-Image-2512",
      "author": "rerri",
      "created_utc": "2025-12-31 09:15:23",
      "score": 622,
      "num_comments": 229,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q08ro5/qwenimage2512_released_on_huggingface/",
      "domain": "huggingface.co",
      "is_self": false,
      "comments": [
        {
          "id": "nwvzblx",
          "author": "LoudWater8940",
          "text": "[https://huggingface.co/unsloth/Qwen-Image-2512-GGUF/tree/main](https://huggingface.co/unsloth/Qwen-Image-2512-GGUF/tree/main)",
          "score": 57,
          "created_utc": "2025-12-31 09:21:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvzrca",
              "author": "fauni-7",
              "text": "Nice! Any idea about FP8 non gguf?",
              "score": 8,
              "created_utc": "2025-12-31 09:25:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nww02aq",
                  "author": "rerri",
                  "text": "Doesn't seem to be available yet. You can keep F5'ing this page though :)\n\n[https://huggingface.co/models?sort=modified&search=qwen+image+2512](https://huggingface.co/models?sort=modified&search=qwen+image+2512)",
                  "score": 19,
                  "created_utc": "2025-12-31 09:28:27",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nwwb13a",
                  "author": "Fluffy_Bug_",
                  "text": "FP8 Safetensors\n\n[https://huggingface.co/Comfy-Org/Qwen-Image\\_ComfyUI/blob/main/split\\_files/diffusion\\_models/qwen\\_image\\_2512\\_fp8\\_e4m3fn.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/blob/main/split_files/diffusion_models/qwen_image_2512_fp8_e4m3fn.safetensors)\n\nedit: and now BF16\n\n[https://huggingface.co/Comfy-Org/Qwen-Image\\_ComfyUI/blob/main/split\\_files/diffusion\\_models/qwen\\_image\\_2512\\_bf16.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/blob/main/split_files/diffusion_models/qwen_image_2512_bf16.safetensors)",
                  "score": 15,
                  "created_utc": "2025-12-31 11:11:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx28ypw",
                  "author": "jonnytracker2020",
                  "text": "Q8 gguf has fp16 quality with cpu support .. why do u want trash fp8",
                  "score": 0,
                  "created_utc": "2026-01-01 10:35:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nww4heq",
          "author": "Major_Specific_23",
          "text": "Prompt adherence king is back. Can't wait to test",
          "score": 42,
          "created_utc": "2025-12-31 10:10:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwokcx",
              "author": "FinBenton",
              "text": "Its good but for some reason I cant get Qwen image to respect the camera POVs at all pretty much, low angle perspective, high angle and other variations, it just kinda wants to always do eye-level shots.",
              "score": 8,
              "created_utc": "2025-12-31 13:01:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwwvqit",
                  "author": "Hoodfu",
                  "text": "Yeah that was an issue with the last one too. I would often use chroma with the prompt and then do a high denoise on that result with qwen or now zimage/flux 2 to bring it to the next level.",
                  "score": 8,
                  "created_utc": "2025-12-31 13:47:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwxuwmp",
                  "author": "MaiaGates",
                  "text": "The official names of the angles suck for prompt adherence with new models, seems like the training pictures rarely have the label of the angle, except dutch or closeup, but if i want a low angle shot i better prompt it \"from below\" if i want something resembling what i want",
                  "score": 2,
                  "created_utc": "2025-12-31 16:53:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwxcjwu",
              "author": "Hoodfu",
              "text": "https://preview.redd.it/alggray94kag1.jpeg?width=3024&format=pjpg&auto=webp&s=3d59217b9337c91836828b2d6729bb532560934a\n\nYeah it's looking seriously good. Flux 2 dev (even with turbo) still beats it on all the little text bits in this prompt, but this still looks awesome aside from that. prompt: A highly advanced gynoid assassin unit designated \"YUKI-7\" stands in the rain-slicked back alleys of Osaka's Shinsekai district at 2AM, her pristine white ceramic helmet gleaming under flickering neon signs advertising pachinko parlors and izakayas, the kanji \"Èõ∂\" (zero) etched in crimson across her faceplate as raindrops streak down its seamless surface. Her copper-blonde synthetic hair, matted and wild from combat, whips violently in the wind generated by passing hover-transports above, contrasting against her battle-scarred glossy obsidian tactical armor featuring exposed hydraulic joints, coolant tubes, and the faded Mitsubishi-Raiden Heavy Industries logo barely visible on her reinforced black tactical jacket's shoulder plate. She thrusts her 90cm muramasa-grade katana directly at the camera in aggressive challenge, the polished surgical steel blade impaling an absurdist trophy of premium otoro tuna nigiri, salmon roe gunkan, and dragon rolls stolen from a yakuza-owned omakase restaurant, wasabi and soy sauce dripping down the blade like dark blood. The scene captures her mid-pivot with extreme dutch angle at 25 degrees, motion blur streaking the background where terrified salarymen in rumpled suits scatter and a tipped-over yatai food cart spills takoyaki across wet cobblestones, steam rising from storm drains mixing with her chassis's venting coolant. Shot on ARRI Alexa 65 with Panavision Ultra Vista anamorphic lenses at f/1.4, 1/500 shutter speed freezing rain droplets while maintaining cinematic motion blur on her whipping hair and the panicked crowd behind her. Atmospheric tension built through the sickly green-magenta color palette of overlapping holographic advertisements reflecting off puddles, a massive 50-foot LED billboard displaying J-pop idols towering above her diminutive 5'4\" chrome frame, emphasizing her deadly precision against urban sprawl chaos. Her body language radiates controlled aggression, weight shifted forward on reinforced titanium leg actuators, free hand's fingers splayed with micro-missile ports visible in her palm, optical sensors behind her visor burning amber through the rain. Highly detailed 8K photorealistic rendering capturing every water bead on her armor's nano-coating, the precise spiraling of rice grains on her skewered sushi trophies, and the terrified reflection of a fleeing ramen chef visible in her helmet's curved surface, gritty cinematic photography embodying Ghost in the Shell meets Blade Runner 2049 with John Wick's kinetic brutality.",
              "score": 9,
              "created_utc": "2025-12-31 15:21:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx06z0a",
                  "author": "2legsRises",
                  "text": "sorry but that looks like really bad ai art with a very low aesthetic. the perspective is all wrong, object just seem to float and the lighting isn't consistent.",
                  "score": 8,
                  "created_utc": "2026-01-01 00:29:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwy6g4o",
                  "author": "krectus",
                  "text": "I found limiting Qwen to about 400 tokens or less was the sweet spot, I wonder if this new version changes that.",
                  "score": 1,
                  "created_utc": "2025-12-31 17:50:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwynh0o",
                  "author": "DrRoughFingers",
                  "text": "Everyone is the background is the same üòÇ even the dude at the food stand.",
                  "score": 1,
                  "created_utc": "2025-12-31 19:15:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwwjqq1",
              "author": "bickid",
              "text": "meaning?",
              "score": -6,
              "created_utc": "2025-12-31 12:25:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwamin",
          "author": "Fluffy_Bug_",
          "text": "FP8 Safetensors\n\n[https://huggingface.co/Comfy-Org/Qwen-Image\\_ComfyUI/blob/main/split\\_files/diffusion\\_models/qwen\\_image\\_2512\\_fp8\\_e4m3fn.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/blob/main/split_files/diffusion_models/qwen_image_2512_fp8_e4m3fn.safetensors)",
          "score": 11,
          "created_utc": "2025-12-31 11:07:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxk08o",
              "author": "Qualar",
              "text": "Is this a better one to use over gguf?",
              "score": 1,
              "created_utc": "2025-12-31 15:59:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwy53s3",
                  "author": "thexdroid",
                  "text": "GGUF is a format used by Llama-ish runners. GGUF is basically safetensors + config, everything in a single pack.",
                  "score": 2,
                  "created_utc": "2025-12-31 17:43:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwvz7i7",
          "author": "chrd5273",
          "text": "Seems like we need to wait a bit more for Z-image base to release.",
          "score": 54,
          "created_utc": "2025-12-31 09:20:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww4bts",
              "author": "International-Try467",
              "text": "Plot twist: Z Image was just a distilled Qwen with experimental architecture¬†",
              "score": 35,
              "created_utc": "2025-12-31 10:09:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nww75ea",
                  "author": "mk8933",
                  "text": "That's excatly what it felt like. Many of Z images were similar to qwen but more finetuned",
                  "score": 8,
                  "created_utc": "2025-12-31 10:35:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwwbicn",
                  "author": "jib_reddit",
                  "text": "They definitely share information between the teams, there are both under Alibarba after all.",
                  "score": 2,
                  "created_utc": "2025-12-31 11:15:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nww5ocx",
                  "author": "6ft1in",
                  "text": "is it ?",
                  "score": -3,
                  "created_utc": "2025-12-31 10:21:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nww60z9",
              "author": "Fluffy_Bug_",
              "text": "What does this have to do with Qwen 2512? \n\nNothing at all.",
              "score": 1,
              "created_utc": "2025-12-31 10:24:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nww9gkt",
                  "author": "mulletarian",
                  "text": "they are both image diffusion models",
                  "score": 6,
                  "created_utc": "2025-12-31 10:56:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nww8hfr",
          "author": "StableLlama",
          "text": "Are the LoRAs compatible - or do we need to retrain?",
          "score": 5,
          "created_utc": "2025-12-31 10:47:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwhimf",
              "author": "Less_Consequence_633",
              "text": "First few from Civit I've tried, they sure SEEM to be working",
              "score": 5,
              "created_utc": "2025-12-31 12:07:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwyfnfe",
              "author": "Next_Program90",
              "text": "I will definitely ReTrain mine. Can't wait. Fingers crossed 2511 is miraculously a better lerner than v1.",
              "score": 5,
              "created_utc": "2025-12-31 18:35:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwvzxk3",
          "author": "StacksGrinder",
          "text": "Wow! The results looks stunning :D way better than the initial release.",
          "score": 19,
          "created_utc": "2025-12-31 09:27:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww56d9",
              "author": "donkeykong917",
              "text": "Better than zit?",
              "score": 2,
              "created_utc": "2025-12-31 10:16:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwwb1s2",
                  "author": "jib_reddit",
                  "text": "From the new Qwen sample images I would say no, ZIT is still better for skin detail, but I am not used to working with either base model for a while.\n\nhttps://preview.redd.it/8qydumvbwiag1.png?width=1024&format=png&auto=webp&s=1b82d31e78d5eb68a7b7bf95798ca0a293ddcb10\n\nBut that might such be the Quality of those GGUF linked. I really like to use the full model with Qwen, but most people don't have the VRAM/RAM for it.",
                  "score": 2,
                  "created_utc": "2025-12-31 11:11:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwyb9yd",
                  "author": "pigeon57434",
                  "text": "no",
                  "score": 1,
                  "created_utc": "2025-12-31 18:13:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nww5mn2",
                  "author": "StacksGrinder",
                  "text": "Haven't tested it myself, It's my opinion from reading the Model card. will do tonight :)",
                  "score": -1,
                  "created_utc": "2025-12-31 10:21:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwvyzo2",
          "author": "TheMisterPirate",
          "text": "I swear 2511 came out like a week ago lol. Are they really going to release models monthly?",
          "score": 40,
          "created_utc": "2025-12-31 09:18:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvz48s",
              "author": "chrd5273",
              "text": "That was i2i model, and this one is t2i model, so technically different model.",
              "score": 80,
              "created_utc": "2025-12-31 09:19:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nww1auy",
                  "author": "TheMisterPirate",
                  "text": "Thanks for clarifying.",
                  "score": 8,
                  "created_utc": "2025-12-31 09:40:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx1gqgs",
                  "author": "Sea_Succotash3634",
                  "text": "It's kind of annoying that they aren't unified. 2511 has a big flaw with plastic skin that 2512 seems to improve a lot on.",
                  "score": 1,
                  "created_utc": "2026-01-01 05:48:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwwbpu6",
                  "author": "Terrible_Scar",
                  "text": "I don't see any links mention that last model was i2i only",
                  "score": -5,
                  "created_utc": "2025-12-31 11:17:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nww09ih",
              "author": "ANR2ME",
              "text": "That was the Edit/I2I model, this one the base T2I model.",
              "score": 15,
              "created_utc": "2025-12-31 09:30:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nww5x5i",
              "author": "Aromatic-Current-235",
              "text": "That was Qwen Image Edit, This is Qwen Image.",
              "score": 6,
              "created_utc": "2025-12-31 10:23:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwbybp",
          "author": "shivdbz",
          "text": "Its not EDIT model",
          "score": 13,
          "created_utc": "2025-12-31 11:19:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwm6k9",
              "author": "zoupishness7",
              "text": "[Qwen-Image-Edit-2511](https://huggingface.co/Qwen/Qwen-Image-Edit-2511/tree/main) was just released two weeks ago, probably a bit soon for another one.",
              "score": 13,
              "created_utc": "2025-12-31 12:44:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx4r9ud",
                  "author": "Recent-Concept-2652",
                  "text": "True, maybe the next release will be Qwen-Image-Edit-2601 :)",
                  "score": 1,
                  "created_utc": "2026-01-01 20:04:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwwepxp",
              "author": "Altruistic_Heat_9531",
              "text": "thank, i just want to ask about that",
              "score": 1,
              "created_utc": "2025-12-31 11:44:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nww3wpm",
          "author": "AshLatios",
          "text": "A genuine question, is Qwen image 2512 model good for making anime style images and anime characters like Illustrious or Pony?",
          "score": 4,
          "created_utc": "2025-12-31 10:05:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwvfts",
              "author": "KierkegaardsSisyphus",
              "text": "No. It's bad for that. This update seems worse than the first Qwen Image for illustration/anime and even that wasn't great without loras. Best thing would be to use a model like this to generate something close to what you want just so you can send it through a controlnet for an illustrious based model.",
              "score": 3,
              "created_utc": "2025-12-31 13:45:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwymkqz",
              "author": "FinBenton",
              "text": "Yeah theres like 100 Loras to add any kinda anime style you want, its very good.",
              "score": 2,
              "created_utc": "2025-12-31 19:11:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwfr45",
          "author": "MikePounce",
          "text": "TL;DR : stick with Z-image-turbo.\n\nFollowing [https://unsloth.ai/docs/models/qwen-image-2512](https://unsloth.ai/docs/models/qwen-image-2512) and their included ComfyUI workflow (warning : pay attention to their default negative prompt, it includes \"photorealistic\"), here are my findings with a RTX5090 on windows 11, CFG 4, euler/simple, Q4\\_K\\_M GGUF, same prompt and same seed everytime. An optional upscale with SeedVR2 (default settings) adds about 5 seconds but in my opinion it makes the image even more \"AI-ish\".\n\n* skin still looks unrealistically smooth/plastic/AI look/blurry, Z-image-turbo gives comparable if not better results with 9 steps\n* even when requesting a woman I would sometimes get a man\n* 04 steps lora does not seem to work with GGUF\n* 40 steps takes 64 seconds\n* 24 steps takes 38 seconds, changes to facial structure, result is fairly comparable, in the example below the text is even better than at 40 steps\n* 12 steps takes 20 seconds, result is fairly comparable, small text starts being glyph\n* 08 steps takes 13 seconds, result is barely passable, small text becomes unreadable\n* 04 steps (without lora) takes 7 seconds, result is unusable\n\nhttps://preview.redd.it/9o1z15c42jag1.png?width=2048&format=png&auto=webp&s=e953b0a6e4432b97b0e6a4c6bfd910a72925ada4\n\n  \nPositive prompt :  \nwoman, sharp professional shot, shoulder high close up, european woman, walking in the street, holding a cardboard sign with the text \"Gooner 2512\" in a stylized font, the sign masks her breasts, detailed skin, blue eyes, the woman is wearing a blue and yellow leather jacket and a green shirt. She has the word \"Nvidia\" tatooed on her neck.\n\nNegative prompt :  \nmale, blurry, bad, low quality, fur, 3D render, uncanny, gritty, noisy texture, harsh shadows, horror, angry expression, deformed anatomy, extra limbs, extra fingers, asymmetrical eyes, cross-eyed, text glitches, misspelled text, watermark, logo",
          "score": 21,
          "created_utc": "2025-12-31 11:53:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwum67",
              "author": "Baycon",
              "text": "Not saying you're wrong about how great Z-image is, but I don't think your comparison is fair. You're using a Q4 version.\n\nI just downloaded it out of curiosity. Using the fp8 + turbo lora set at 8 steps with euler + simple at cfg 1. I'm getting better results with beta scheduler so far. Anyways, just downloaded it and thought I'd test your prompt.\n\nhttps://preview.redd.it/4uj0x545mjag1.png?width=1088&format=png&auto=webp&s=13e722fb0c319e401e47bdb9e23f4e64a409314b",
              "score": 17,
              "created_utc": "2025-12-31 13:40:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwwxevz",
                  "author": "hitlabstudios",
                  "text": "Maybe just me but looks a bit over cooked?",
                  "score": 16,
                  "created_utc": "2025-12-31 13:57:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwwv2wd",
                  "author": "MikePounce",
                  "text": "I agree with you actually, when I started testing FP8 wasn't yet available. Will try it out! Happy new year.",
                  "score": 2,
                  "created_utc": "2025-12-31 13:43:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwxlhc0",
                  "author": "Perfect-Campaign9551",
                  "text": "I still don't think that as realistic as ZIT",
                  "score": 1,
                  "created_utc": "2025-12-31 16:06:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwwlrhf",
              "author": "nmkd",
              "text": "Have you tried proper NLP prompting...",
              "score": 3,
              "created_utc": "2025-12-31 12:40:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwwlumv",
                  "author": "MikePounce",
                  "text": "What do you mean??",
                  "score": 2,
                  "created_utc": "2025-12-31 12:41:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwwjovk",
              "author": "DangerousOutside-",
              "text": "Thanks for this analysis/info. \nThough I don‚Äôt see photorealistic in your negative prompt as you noted they use - does it make a difference?",
              "score": 2,
              "created_utc": "2025-12-31 12:25:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwwjwk2",
                  "author": "MikePounce",
                  "text": "I removed it. My warning is if you load the workflow provided by Unsloth, by default it includes the word \"photorealistic\". Yes the negative prompt has an influence.",
                  "score": 1,
                  "created_utc": "2025-12-31 12:26:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwwkx1p",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2025-12-31 12:34:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwwlecs",
                  "author": "MikePounce",
                  "text": "What do you mean by opposite experience? Do you not find the skin on the example I provided too smooth?\n\nAlso thanks for the lora, I'll look into it.",
                  "score": 1,
                  "created_utc": "2025-12-31 12:38:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwwlo2f",
              "author": "Simple_Echo_6129",
              "text": "It seems to be highly sensitive to the prompt. The example prompt in the Github GGUF repo generates good images.",
              "score": 1,
              "created_utc": "2025-12-31 12:40:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwvysv6",
          "author": "ResponsibleTruck4717",
          "text": "Is anyone knows how to quant it? I tried with the [convert.py](http://convert.py) but it failed.",
          "score": 6,
          "created_utc": "2025-12-31 09:16:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvzqpz",
              "author": "Then-Topic8766",
              "text": "[https://huggingface.co/unsloth/Qwen-Image-2512-GGUF](https://huggingface.co/unsloth/Qwen-Image-2512-GGUF)\n\nUnsloth guys rock as always.",
              "score": 21,
              "created_utc": "2025-12-31 09:25:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nww50cp",
          "author": "NowThatsMalarkey",
          "text": "Time to harass Ostris and Kohya to support LoRA training asap.",
          "score": 6,
          "created_utc": "2025-12-31 10:15:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwx2jny",
              "author": "abnormal_human",
              "text": "Not sure there‚Äôs anything for them to do",
              "score": 1,
              "created_utc": "2025-12-31 14:27:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwx9ya2",
                  "author": "Less_Consequence_633",
                  "text": "I'm not sure how much either, but as of a few minutes ago, AI Toolkit's Github has \"[Added initial support for Qwen-Image-2512](https://github.com/ostris/ai-toolkit/commit/4d5a649a7dc1e3056e97f66b62e5d32c23d3c8a1)\" as the latest update",
                  "score": 2,
                  "created_utc": "2025-12-31 15:08:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nww661m",
          "author": "fauni-7",
          "text": "It looks like there's a new text encoder as well, right?  \n[https://huggingface.co/Qwen/Qwen-Image-2512/tree/main/text\\_encoder](https://huggingface.co/Qwen/Qwen-Image-2512/tree/main/text_encoder)  \nI mean should there be ggufs for that as well?",
          "score": 3,
          "created_utc": "2025-12-31 10:26:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww76dx",
              "author": "NanoSputnik",
              "text": "I checked hashes, files are the same as in the original qwen image repo.",
              "score": 10,
              "created_utc": "2025-12-31 10:35:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nww9s8g",
                  "author": "fauni-7",
                  "text": "Thanks! I guess that goes for the VAE as well.",
                  "score": 2,
                  "created_utc": "2025-12-31 10:59:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwwm39j",
              "author": "nmkd",
              "text": "No.\n\nStill `Qwen2.5-VL`.\n\nKind of a shame, I really wanna see what this model can do with Qwen3-VL.",
              "score": 8,
              "created_utc": "2025-12-31 12:43:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwycswk",
                  "author": "MrWeirdoFace",
                  "text": "On my 3090 (24GB), Is there any reason for me to used the scaled encoder vs the non-scaled 2.5?",
                  "score": 1,
                  "created_utc": "2025-12-31 18:21:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwwx48f",
                  "author": "Lower-Cap7381",
                  "text": "its just a text llm it wont affect the quality just the language",
                  "score": 0,
                  "created_utc": "2025-12-31 13:55:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nww7o76",
          "author": "ThiagoAkhe",
          "text": "Best combo ZIT (Base) + Qwen 2512 (Refine)?",
          "score": 3,
          "created_utc": "2025-12-31 10:40:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww9ql3",
              "author": "thisiztrash02",
              "text": "nah it probably be , zit base + zit edit",
              "score": 3,
              "created_utc": "2025-12-31 10:59:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwydtu9",
                  "author": "diffusion_throwaway",
                  "text": "People keep talking about this zit edit. Did I miss this? Has it been released?",
                  "score": 2,
                  "created_utc": "2025-12-31 18:26:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwyhzqv",
          "author": "MrWeirdoFace",
          "text": "Here's the bad news. The Lora dramatically changes the output. I started with the Lora by trying to make a 1970s sci-fi corridor (think Alien) and every single time I'd get nearly the same concept-art style image. After about 20 attempts and almost always getting this, I removed the lora, and INSTANT change started getting exactly what I was looking for. I'm using the comfyui fp8 for reference. 8 steps with the 4-step Lora at 1.0 cfg. 40 steps and 2.5 cfg without.  Using the original Qwen Image basic workflow from comfy and just swapping out the model.",
          "score": 3,
          "created_utc": "2025-12-31 18:47:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwz0u3a",
          "author": "JazzlikeLeave5530",
          "text": "Am I alone here in that some of these look so detailed that they look bad? It looks like someone went way too crazy in photoshop to \"improve\" them. Not literally, I know they're all generated but that's the look some of them have.",
          "score": 3,
          "created_utc": "2025-12-31 20:26:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nww39i7",
          "author": "Valtared",
          "text": "I tried with the Turbo Lora but it gives me hundreds of \"lora key not loaded: base\\_model.model.transformer\\_blocks.16.attn.to\\_q.lora\\_B.weight\" errors and doesn't seem to work. Can't I mix GGUF model and safetensors Lora ?",
          "score": 4,
          "created_utc": "2025-12-31 09:59:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwc1yx",
              "author": "NowThatsMalarkey",
              "text": "LoRA needs to be converted to ComfyUI‚Äôs format first. Models are typically officially released using Huggingface‚Äôs diffusers format but ComfyUI demands it be converted to theirs in order for it to work properly.",
              "score": 5,
              "created_utc": "2025-12-31 11:20:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwwcw0n",
                  "author": "Tremolo28",
                  "text": "New Lora for comfyui has just been uploaded to HF.",
                  "score": 2,
                  "created_utc": "2025-12-31 11:27:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwwawa3",
              "author": "sktksm",
              "text": "https://preview.redd.it/ik7boiljviag1.png?width=1833&format=png&auto=webp&s=351994924757268933025bcc8cd626d57304f50d\n\nsame here, left is with turbo lora, right is raw gguf. probably we might need to wait the comfyui quantized version",
              "score": 3,
              "created_utc": "2025-12-31 11:10:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwpaza",
          "author": "FinBenton",
          "text": "Gotta give it to the Qwen image, theres so much variety! With the same prompt on ZIT you get pretty much the same image every time and with QWEN you get always very different image that also followed the prompt. Kinda depends what you like I guess but I like the variety.",
          "score": 4,
          "created_utc": "2025-12-31 13:06:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwy7i1j",
              "author": "krectus",
              "text": "One of the bigger complaints of Qwen image when it came out was lack of variety. It‚Äôs not great but I guess Zimage was just so much worse people forgot how bad Qwen was.",
              "score": 7,
              "created_utc": "2025-12-31 17:55:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nww5orq",
          "author": "dantendo664",
          "text": "On the default qwen text to image workflow in comfyui , i switched the model to gguf and it does not work for me. keeps giving torch errors.",
          "score": 2,
          "created_utc": "2025-12-31 10:21:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww8e1g",
              "author": "GreyScope",
              "text": "https://preview.redd.it/xi6ecqccriag1.png?width=1582&format=png&auto=webp&s=3e629c153b24a83b3862a9f7b1303511a1cf2a49\n\nI'm running Python 3.12, Pytorch 2.8, Cuda 12.8 . Just changed the loader on the template to GGUF & disabled the lora.",
              "score": 2,
              "created_utc": "2025-12-31 10:46:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwdc11",
          "author": "fauni-7",
          "text": "Started testing (the Q8 GGUF), using the workflow from unsloth, I don't know what magic they did with their examples in the Qwen 2512 HF page, I can't get similar results.\n\nImages still look too grainy, unclear, blurry, even though they are indeed  more photo-realistic, yes.   \nNowhere near ZIT crispy sharpness.\n\nThere is this texture all over the images also, that didn't get fixed.",
          "score": 2,
          "created_utc": "2025-12-31 11:32:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwefxi",
              "author": "thisiztrash02",
              "text": "how is the generation time",
              "score": 1,
              "created_utc": "2025-12-31 11:41:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwwf029",
                  "author": "fauni-7",
                  "text": "Quite the same (not using any acceleration or other LORAs), on an RTX 4090.",
                  "score": 1,
                  "created_utc": "2025-12-31 11:46:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwweov2",
          "author": "DullDay6753",
          "text": "cool, very good model",
          "score": 2,
          "created_utc": "2025-12-31 11:43:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwwkye4",
          "author": "Southern-Chain-6485",
          "text": "It can do female nudity, but it can't do penises (testicles are weird) and won't do intercourse. It will do horror instead, as things would enter were they shouldn't",
          "score": 2,
          "created_utc": "2025-12-31 12:34:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxg1sp",
          "author": "yamfun",
          "text": "I need Edit of it„ÄÄ",
          "score": 2,
          "created_utc": "2025-12-31 15:39:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nww6ieg",
          "author": "DeliciousGorilla",
          "text": "Not having luck with using the turbo LoRA + Q5\\_0 GGUF. Lots of ghosting, bad text. Is that to be expected? I turned off cfgnorm node, played with auraflow value, tried 4 & 8 steps, different cfg values. Loading LoRA before auraflow or after doesn't make much difference.\n\nWithout the turbo LoRA, 20 steps using Q5\\_0 GGUF is pretty good. But 2.5min gens at 1mp on my 16GB 5060Ti (clip & vae on my 2nd gpu).",
          "score": 3,
          "created_utc": "2025-12-31 10:29:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww9nd8",
              "author": "FinBenton",
              "text": "Lighting 2.0 Lora 8-step at 3.5 cfg seems to work fine for me.",
              "score": 2,
              "created_utc": "2025-12-31 10:58:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nww8vi3",
              "author": "AiCocks",
              "text": "The Turbo Lora is not working with the GGUF it seems. I get hundreds of missing key errors",
              "score": 1,
              "created_utc": "2025-12-31 10:51:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwwl6a4",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 1,
                  "created_utc": "2025-12-31 12:36:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nww7hl9",
              "author": "NanoSputnik",
              "text": "GGUFs are slow man. Trash quality as a bonus. When people realize this? Stop blindly following clueless youtubers advice.",
              "score": -10,
              "created_utc": "2025-12-31 10:38:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nww91p5",
                  "author": "DeliciousGorilla",
                  "text": "YouTuber advice? The hell? And how do you expect me to load the full 40GB model hah. Anyway, the Q5 GGUF (14GB) isn't bad at 20 steps. This is with the lenovo LoRA and same prompt as [my Z-Image test](https://www.reddit.com/r/StableDiffusion/comments/1ps03qc/zimage_turbo_with_lenovo_ultrareal_lora_seedvr2/).\n\nhttps://preview.redd.it/nprqthocsiag1.png?width=1024&format=png&auto=webp&s=4dae388cacbe65fd7667e9052f635502dfdc228a",
                  "score": 6,
                  "created_utc": "2025-12-31 10:52:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nww89uz",
                  "author": "Radiant-Photograph46",
                  "text": "Says the random redditor without much more evidence.",
                  "score": 8,
                  "created_utc": "2025-12-31 10:45:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwwgibf",
          "author": "Lucaspittol",
          "text": "Looks like it is even more censored than 2511",
          "score": 3,
          "created_utc": "2025-12-31 11:59:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwwnx6",
              "author": "ImaginationEvery7614",
              "text": "Cant confirm, it does generate okay-ish nudity for me. Breasts are actually not too bad, definitely better than base Z-Image.",
              "score": 5,
              "created_utc": "2025-12-31 13:53:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwwhpa7",
              "author": "Enshitification",
              "text": "The existing NSFW Qwen-Image LoRAs seem to work with it.",
              "score": 4,
              "created_utc": "2025-12-31 12:09:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nww0qzx",
          "author": "Luisgmnz",
          "text": "Will it run in a machine with 12gb of Vram?",
          "score": 3,
          "created_utc": "2025-12-31 09:35:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww8zlq",
              "author": "ThiagoAkhe",
              "text": "It‚Äôll run Q4 with a smile on its face. Meanwhile, 8GB VRAM users like me will be crying just to run Q4 or accepting our fate with Q2.",
              "score": 2,
              "created_utc": "2025-12-31 10:52:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwwbq2c",
                  "author": "nymical23",
                  "text": "If you have enough RAM, use GGUFs.",
                  "score": 3,
                  "created_utc": "2025-12-31 11:17:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nww9kjr",
              "author": "thisiztrash02",
              "text": "yes ggufs are out",
              "score": 2,
              "created_utc": "2025-12-31 10:57:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nww18c6",
          "author": "3deal",
          "text": "Amazing, but how did the lora went out before the model ?",
          "score": 1,
          "created_utc": "2025-12-31 09:39:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww1miv",
              "author": "rerri",
              "text": "Turbo lora was published 3min **after** Qwen-Image-2512.\n\nThe team that made the lora obviously had early access to the model (and so did Unsloth).",
              "score": 13,
              "created_utc": "2025-12-31 09:43:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nww5dg5",
          "author": "sergov",
          "text": "Looks like a major improvement but the hair/fur is still not fully there yet. Perhaps lora‚Äôs will change that..",
          "score": 1,
          "created_utc": "2025-12-31 10:18:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwx2osr",
              "author": "abnormal_human",
              "text": "Lora‚Äôs already overcame all that stuff on the old model. This one will just make it easy mode.",
              "score": 1,
              "created_utc": "2025-12-31 14:28:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwhmd5",
          "author": "Paraleluniverse200",
          "text": "I guess the loras for the previous version won't be compatible right",
          "score": 1,
          "created_utc": "2025-12-31 12:08:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx0r9tl",
              "author": "Guilty_Emergency3603",
              "text": "Same architecture. They work 100% well.",
              "score": 2,
              "created_utc": "2026-01-01 02:40:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwwk9ka",
              "author": "stuartullman",
              "text": "for me, at least so far, they seem compatible..",
              "score": 1,
              "created_utc": "2025-12-31 12:29:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwwkb2n",
                  "author": "Paraleluniverse200",
                  "text": "Awesome, thanks",
                  "score": 1,
                  "created_utc": "2025-12-31 12:29:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwwr8xf",
          "author": "THEKILLFUS",
          "text": "Enhanced Huamn Realism",
          "score": 1,
          "created_utc": "2025-12-31 13:19:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwwtuaq",
          "author": "MarkBusch1",
          "text": "I tried the official 'demo' on their github with my 5090 with 32 gig vram, and it takes 3+ hours to do the 50 steps... ? that is not including the download, it's already downloaded... is the base model not suitable for the 5090 ? I think I ran the older qwen full models just fine...",
          "score": 1,
          "created_utc": "2025-12-31 13:35:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxikx3",
              "author": "AdamReading",
              "text": "use the model versions on the comfyorg hugging face",
              "score": 1,
              "created_utc": "2025-12-31 15:52:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwxqy1e",
          "author": "Zippo2017",
          "text": "I would love to try the new 2512 model with unsloth GGUF, but I just can't find a workflow that I can just drag and drop into ComfyUI. If you start off with the regular model in ComfyUI, you can't just swap out the default model for the GGUF, as it uses a different node. I just don't know how to rebuild the workflow using the GGUF model(s)  I also have this problem with start image / end image with the built in workflow in ComfyUI.",
          "score": 1,
          "created_utc": "2025-12-31 16:33:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxso8q",
          "author": "Odd-Mirror-2412",
          "text": "I hope this serves as the ZIB",
          "score": 1,
          "created_utc": "2025-12-31 16:41:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwy53em",
          "author": "jigendaisuke81",
          "text": "I prefer the original version. This one has too much DPO. My prompts actually look more artificial in this model and anime style took a huge hit. Very boring gens with 2512.",
          "score": 1,
          "created_utc": "2025-12-31 17:43:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwybxlf",
          "author": "Haunting-Elephant587",
          "text": "https://preview.redd.it/00n6dya3ykag1.png?width=928&format=png&auto=webp&s=2ce60ce0fbd2379877b71267005a84149f58b452\n\nis Qwen Image 2512 able to render text correctly? some how, I just not able to get it right",
          "score": 1,
          "created_utc": "2025-12-31 18:17:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwyhtfy",
          "author": "generate-addict",
          "text": "Where are folk getting that 8 step Lora from? The one linked mentions it but only has the 4 step one.",
          "score": 1,
          "created_utc": "2025-12-31 18:46:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwyrcok",
              "author": "Electronic-Metal2391",
              "text": "ppl are running workflows at 8 steps with the 4 step speeding LoRA.",
              "score": 1,
              "created_utc": "2025-12-31 19:36:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwz55ry",
                  "author": "generate-addict",
                  "text": "Ok I see. Ty",
                  "score": 1,
                  "created_utc": "2025-12-31 20:50:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwzk3ft",
          "author": "chaddhaji",
          "text": "Do we have Qwen-Image-Edit-2512 as well?",
          "score": 1,
          "created_utc": "2025-12-31 22:12:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx17129",
          "author": "DanzeluS",
          "text": "ü§Øü§Øü§Ø",
          "score": 1,
          "created_utc": "2026-01-01 04:29:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx2yadf",
          "author": "FirmHyena9710",
          "text": "https://preview.redd.it/qb547c1txqag1.png?width=1088&format=png&auto=webp&s=6565cfff5ecc0ab395d3ac2687f7129bf9e3cfc7\n\nidk",
          "score": 1,
          "created_utc": "2026-01-01 14:17:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx5cst8",
          "author": "scifivision",
          "text": "Do you need both 2511 and 2512? Can you edit with 2512 or can you only do t2i with it?",
          "score": 1,
          "created_utc": "2026-01-01 21:55:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6bhax",
          "author": "thecosmingurau",
          "text": "Has anyone managed to properly generate a good image with this, using Q2 GGUF and the new 4 step Lora ComfyUI version? Because they all come out like this at best\n\nhttps://preview.redd.it/vzu3usg06uag1.png?width=1024&format=png&auto=webp&s=8f85a8fd2e9b61ee167d093e32a3c344cf439713",
          "score": 1,
          "created_utc": "2026-01-02 01:07:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7oh9k",
              "author": "rerri",
              "text": "Q2 is probably just too low of a quant",
              "score": 1,
              "created_utc": "2026-01-02 06:32:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx8c1ru",
                  "author": "thecosmingurau",
                  "text": "Can you do a test with it on your own setup, just to check? Because if so, the Q2 is largely useless, unless you use the output on img2img with like ZIT",
                  "score": 1,
                  "created_utc": "2026-01-02 10:11:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx8c5oy",
                  "author": "thecosmingurau",
                  "text": "I only have a GTX 1080Ti and the other GGUFs are way too large to fit in the memory",
                  "score": 1,
                  "created_utc": "2026-01-02 10:13:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxlruwz",
          "author": "No_Replacement_8158",
          "text": "They've gone overboard with the supposed 'realism' - the imperfections are greatly exaggerated - kind of the same thing I noticed in Flux 2",
          "score": 1,
          "created_utc": "2026-01-04 10:32:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwwzih8",
          "author": "rcanepa",
          "text": "By mistake, I used this new model in combination with the Qwen Image Lighting 4 Steps V2.0 LoRA (the one for the original Qwen Image model), and the results are very good.\n\nhttps://preview.redd.it/0diexjcnrjag1.png?width=1328&format=png&auto=webp&s=d7b74890d7e6c044c82f0e296c8c9e8223a5708a\n\nI generated this image in \\~7s with a 5090 in 4 steps with res\\_2s and bong\\_tangent.",
          "score": 0,
          "created_utc": "2025-12-31 14:09:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwx18qp",
              "author": "somerandomperson313",
              "text": "Skin looks super weird if you look closely. Looks more natural in the other image you posted.",
              "score": 7,
              "created_utc": "2025-12-31 14:20:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwx2a2d",
                  "author": "rcanepa",
                  "text": "Oh, you're right! I didn't notice that at first.\n\n  \nI just tested the Turbo Lora for 2512 and it doesn't get much better, though. Quite the opposite (at least with the parameters I use).\n\nhttps://preview.redd.it/cxoxi55mujag1.png?width=1328&format=png&auto=webp&s=a83fe81ff301ca433d6bffdbf1ffd5e07e042247",
                  "score": 2,
                  "created_utc": "2025-12-31 14:26:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwx03ge",
              "author": "rcanepa",
              "text": "Here is another example [https://imgur.com/a/KbLp45G](https://imgur.com/a/KbLp45G)\n\nhttps://preview.redd.it/qnrgnqfesjag1.png?width=1328&format=png&auto=webp&s=00ef8b171f19f53ab5f72596a191ecffec87fc26",
              "score": 2,
              "created_utc": "2025-12-31 14:13:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwx078r",
              "author": "rcanepa",
              "text": "Here is the same prompt with the old Qwen Image model (exact same workflow).\n\nhttps://preview.redd.it/1tyj5c3hsjag1.png?width=1328&format=png&auto=webp&s=d7d972ca02ad9b1b00ab6d596a7a73b4cfaa8083",
              "score": 2,
              "created_utc": "2025-12-31 14:13:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwyb7un",
          "author": "pigeon57434",
          "text": "unfortunately its still 20x worse than z-image and its still 20b params vs 6.... nothing to see here",
          "score": 1,
          "created_utc": "2025-12-31 18:13:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwyw6fx",
          "author": "NowThatsMalarkey",
          "text": "From the README.md:\n\n>An East Asian teenage boy, aged 15‚Äì18, with soft, fluffy black short hair and refined facial contours. His large, warm brown eyes sparkle with energy. His fair skin and sunny, open smile convey an approachable, friendly demeanor‚Äîno makeup or blemishes.\n\n![gif](giphy|ba5g4ID9g5cT6)",
          "score": 1,
          "created_utc": "2025-12-31 20:01:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nww75ft",
          "author": "Business_Caramel_688",
          "text": "we need qwen edit 2512",
          "score": -1,
          "created_utc": "2025-12-31 10:35:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwm9kf",
              "author": "nmkd",
              "text": "It just came out a week ago",
              "score": 3,
              "created_utc": "2025-12-31 12:44:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwwme62",
                  "author": "Business_Caramel_688",
                  "text": "yeah but the quality is not comparable with 2512",
                  "score": -1,
                  "created_utc": "2025-12-31 12:45:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nww3r3d",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 0,
          "created_utc": "2025-12-31 10:03:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww4my1",
              "author": "Fluffy_Bug_",
              "text": "give it an hour at least :)",
              "score": 5,
              "created_utc": "2025-12-31 10:11:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nww4yae",
                  "author": "protector111",
                  "text": "thats like a month in ai timeline xD",
                  "score": 2,
                  "created_utc": "2025-12-31 10:14:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwwavr6",
              "author": "Fluffy_Bug_",
              "text": "[https://www.reddit.com/r/StableDiffusion/comments/1q08ro5/comment/nwwamin/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/r/StableDiffusion/comments/1q08ro5/comment/nwwamin/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",
              "score": 2,
              "created_utc": "2025-12-31 11:09:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwk781",
          "author": "stuartullman",
          "text": "seems to be working with the old qwen loras as well, quality is insane",
          "score": 0,
          "created_utc": "2025-12-31 12:28:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nww5s6t",
          "author": "Dry_Mortgage_4646",
          "text": "Woah didnt expect this. Haven't even used 2511 that much",
          "score": -1,
          "created_utc": "2025-12-31 10:22:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwmdai",
              "author": "nmkd",
              "text": "There is no Qwen Image 2511",
              "score": 3,
              "created_utc": "2025-12-31 12:45:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx15n1s",
                  "author": "Dry_Mortgage_4646",
                  "text": "Damn i thought it was an edit version too! My bad but you're right, its a new Qwen Image! Oh yeahhh",
                  "score": 1,
                  "created_utc": "2026-01-01 04:18:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nww1bxs",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -13,
          "created_utc": "2025-12-31 09:40:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww27h6",
              "author": "40_year",
              "text": "I wouldn‚Äôt say we‚Äôre the guinea pigs. We get to keep all the fully functional and working models, for free. I myself am grateful for this.",
              "score": 13,
              "created_utc": "2025-12-31 09:49:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nww45qs",
              "author": "alitadrakes",
              "text": "I understand your criticism, but world of capitalism - appreciate the qwen team and the models they are making open source",
              "score": 5,
              "created_utc": "2025-12-31 10:07:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nww6oul",
          "author": "LSI_CZE",
          "text": "Turbo Lora not work with gguf:  \nlora key not loaded: base\\_model.model.transformer\\_blocks.0.attn.add\\_k\\_proj.lora\\_A.weight\n\nlora key not loaded: base\\_model.model.transformer\\_blocks.0.attn.add\\_k\\_proj.lora\\_B.weight\n\nlora key not loaded: base\\_model.model.transformer\\_blocks.0.attn.add\\_q\\_proj.lora\\_A.weight\n\nlora key not loaded: base\\_model.model.transformer\\_blocks.0.attn.add\\_q\\_proj.lora\\_B.weight\n\nlora key not loaded: base\\_model.model.transformer\\_blocks.0.attn.add\\_v\\_proj.lora\\_A.weight\n\nlora key not loaded: base\\_model.model.transformer\\_blocks.0.attn.add\\_v\\_proj.lora\\_B.weight\n\nlora key not loaded: base\\_model.model.transformer\\_blocks.0.attn.to\\_add\\_out.lora\\_A.weight\n\nlora key not loaded: base\\_model.model.transformer\\_blocks.0.attn.to\\_add\\_out.lora\\_B.weight\n\nlora key not loaded: base\\_model.model.transformer\\_blocks.0.attn.to\\_k.lora\\_A.weight\n\nlora key not loaded: base\\_model.model.transformer\\_blocks.0.attn.to\\_k.lora\\_B.weight\n\nlora key not loaded: base\\_model.model.transformer\\_blocks.0.attn.to\\_out.0.lora\\_A.weight\n\nlora key not loaded: base\\_model.model.transformer\\_blocks.0.attn.to\\_out.0.lora\\_B.weight\n\nlora key not loaded: base\\_model.model.transformer\\_blocks.0.attn.to\\_q.lora\\_A.weight\n\nlora key not loaded: base\\_model.model.transformer\\_blocks.0.attn.to\\_q.lora\\_B.weight\n\nlora key not loaded: base\\_model.model.transformer\\_blocks.0.attn.to\\_v.lora\\_A.weight",
          "score": -7,
          "created_utc": "2025-12-31 10:31:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww86a8",
              "author": "Valtared",
              "text": "Same, we'll need to wait a bit I guess",
              "score": 1,
              "created_utc": "2025-12-31 10:44:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwwadbt",
                  "author": "LSI_CZE",
                  "text": "the guys uploaded a new lora:  \n[https://huggingface.co/Wuli-art/Qwen-Image-2512-Turbo-LoRA/blob/main/Wuli-Qwen-Image-2512-Turbo-LoRA-4steps-V1.0-bf16\\_ComfyUi.safetensors](https://huggingface.co/Wuli-art/Qwen-Image-2512-Turbo-LoRA/blob/main/Wuli-Qwen-Image-2512-Turbo-LoRA-4steps-V1.0-bf16_ComfyUi.safetensors)",
                  "score": 6,
                  "created_utc": "2025-12-31 11:05:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q9s0u5",
      "title": "ComfyUI workflow for structure-aligned re-rendering (no controlnet, no training) Looking for feedback",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/v643u6d9yncg1",
      "author": "Fit-Associate7454",
      "created_utc": "2026-01-11 06:21:49",
      "score": 610,
      "num_comments": 73,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q9s0u5/comfyui_workflow_for_structurealigned_rerendering/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nyxvtq4",
          "author": "orangpelupa",
          "text": "Whoa! This basically could become \"almost final render\" phase, directly from basic 3d sketchup / blender.\n\n\nBe it for archviz, indie movies, or many more\n\n\nEdit:\n\n\nVRAM req?¬†",
          "score": 35,
          "created_utc": "2026-01-11 08:26:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz00m53",
              "author": "Big0bjective",
              "text": "The image workflow is based on flux1-dev, the video workflow as it seems wan2.1-fun.\n\nResults are therefore strictly based on the qualtiy of the model to be honest but the \"keep the image as is and make it real\"-workflow kinda seems to work. Would be interesting to see if this could work with Chroma, Qwen or Z-Image Turbo - Video for LTX2 as it seems to push the boundaries of video further than Wan2.1",
              "score": 3,
              "created_utc": "2026-01-11 17:04:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz0up1n",
                  "author": "AnOnlineHandle",
                  "text": "While probably not as advanced, I recently found an old post for how to achieve something similar in Qwen Image Edit which seems to be working for me. Essentially just resize your image to a multiple of 112, since that's the common divisible interval for both the VAE and the vision model (which use different intervals). So far it's maintained exact pixel structure for me when making edits.\n\nIn Comfy I use the in built \"resize images by longer edge\" node and set it to 1120.",
                  "score": 2,
                  "created_utc": "2026-01-11 19:20:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz84m4l",
                  "author": "herosavestheday",
                  "text": "I know it can work for SDXL, I had Gemini vibe code me comfy nodes and it works. also works with loras.",
                  "score": 1,
                  "created_utc": "2026-01-12 20:22:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyxowpp",
          "author": "physalisx",
          "text": "Just FYI the link to the project page is broken (extra \")\") , here is the correct one:\n\nhttps://yuzeng-at-tri.github.io/ppd-page/",
          "score": 9,
          "created_utc": "2026-01-11 07:23:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxhum0",
          "author": "witcherknight",
          "text": "This looks insane.",
          "score": 34,
          "created_utc": "2026-01-11 06:23:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyybv46",
              "author": "NoceMoscata666",
              "text": "what? dwarf arm Lara?",
              "score": 19,
              "created_utc": "2026-01-11 10:55:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyynwc7",
                  "author": "baddorox",
                  "text": "and garter shorts?",
                  "score": 4,
                  "created_utc": "2026-01-11 12:38:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyzt4rw",
                  "author": "Big0bjective",
                  "text": "Why didn't I spot that? But after looking again the anatomical proportions are off overall, the kind of issue with cg => real life",
                  "score": 3,
                  "created_utc": "2026-01-11 16:29:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyyomvn",
              "author": "DrElectro",
              "text": "If these are the best still images they can come up with, I am not impressed at all. The video examples look uncanny and I saw way better and consistent results with other vid2vid workflows.¬†",
              "score": 2,
              "created_utc": "2026-01-11 12:44:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyywmg4",
                  "author": "butthe4d",
                  "text": "I think the selling point here is that this is really fast and supposed to deliver real time remaster (in theory). Thats how I understood it at least.",
                  "score": 6,
                  "created_utc": "2026-01-11 13:38:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyxmok6",
          "author": "ai_art_is_art",
          "text": "I love it! I 100% believe this is the future of professional design and film VFX work.   \n  \nThis is what we're doing with ArtCraft: [https://github.com/storytold/artcraft](https://github.com/storytold/artcraft)\n\nWe had a very similar ComfyUI approach to yours (albeit vastly inferior) a few years ago. AnimateDiff wasn't strong enough at the time: [https://storyteller.ai/](https://storyteller.ai/)",
          "score": 28,
          "created_utc": "2026-01-11 07:04:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyy1aeq",
              "author": "Draufgaenger",
              "text": "Holy cow... This looks amazing!",
              "score": 4,
              "created_utc": "2026-01-11 09:17:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyza93h",
                  "author": "ai_art_is_art",
                  "text": "Thank you!\n\nI love working on this stuff almost as much as I love using it.",
                  "score": 1,
                  "created_utc": "2026-01-11 14:56:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyxw1af",
              "author": "orangpelupa",
              "text": "!remindme 5 days\n\n\nHolly Molly artcraf looks amazing¬†",
              "score": 2,
              "created_utc": "2026-01-11 08:28:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyxw3vc",
                  "author": "RemindMeBot",
                  "text": "I will be messaging you in 5 days on [**2026-01-16 08:28:53 UTC**](http://www.wolframalpha.com/input/?i=2026-01-16%2008:28:53%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/StableDiffusion/comments/1q9s0u5/comfyui_workflow_for_structurealigned_rerendering/nyxw1af/?context=3)\n\n[**4 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FStableDiffusion%2Fcomments%2F1q9s0u5%2Fcomfyui_workflow_for_structurealigned_rerendering%2Fnyxw1af%2F%5D%0A%0ARemindMe%21%202026-01-16%2008%3A28%3A53%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201q9s0u5)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
                  "score": 1,
                  "created_utc": "2026-01-11 08:29:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyz7eqi",
              "author": "Heyitsme_yourBro",
              "text": "Newbie here, can you please explain why you open source this? It looks amazing but what if someone takes it, and distributes it under their own name?",
              "score": 1,
              "created_utc": "2026-01-11 14:41:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyza579",
                  "author": "ai_art_is_art",
                  "text": "A few reasons:   \n  \n1. ComfyUI and Invoke are open source. They're incredibly useful. \n\n2. I doubt anyone is going to work as hard on this as me and my team. \n\n3. In addition to being an engineer, I'm a filmmaker and have been for over 10 years. I'm building this for myself. If other people build local tools or contribute, more tools for me! \n\n4. It'll be better if local tools catch up and leapfrog Higgs, etc. ArtCraft is more commercial model oriented (though we will grow capabilities to do local models as soon as I have bandwidth). I don't see any reason why we can't catch up with OpenArt / FreePik / Higgs etc and then begin to pass them.",
                  "score": 14,
                  "created_utc": "2026-01-11 14:55:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz0jeca",
                  "author": "Arawski99",
                  "text": "It's not open source. It is completely API based. They have the models linked at the bottom of the github and they're also breaking this sub's rules with self-promotions.\n\nTheir claiming it is \"open source\" and that the API's you ran it through don't own the stuff or have access to your data, like some of his recent posts, for every existing generation, ever made, with their API is a lie. They're scamming people.",
                  "score": 2,
                  "created_utc": "2026-01-11 18:31:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyzsgif",
              "author": "superkickstart",
              "text": "It's free? Can you use local models?",
              "score": 1,
              "created_utc": "2026-01-11 16:26:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyzxmdf",
                  "author": "ai_art_is_art",
                  "text": "(1) Yes. (2) Not yet, but soon. It's on the roadmap. The team is trying to figure out whether to interface with Comfy or build a Rust-native model / workflow server.",
                  "score": 2,
                  "created_utc": "2026-01-11 16:50:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyxwu7h",
          "author": "pmp22",
          "text": "In the future, video games will use techniques like this to render the graphics, and they will drive it with underlying simpler raster pipelines. We might even be able to stack/layer models to alter styles etc.\nGames will probably ship with their own models trained for their specific game.",
          "score": 11,
          "created_utc": "2026-01-11 08:36:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz1g5a9",
              "author": "darkkite",
              "text": "four years ago researchers at intel could do this with g-buffers https://isl-org.github.io/PhotorealismEnhancement/ \n\nit might be the future of rendering",
              "score": 3,
              "created_utc": "2026-01-11 20:59:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyy7t3b",
              "author": "Markavian",
              "text": "I view it as better semantic modelling of the world, and using those descriptions to feed the AI visualisation and fill in the gaps. \n\nGames like dwarf fortress which are dense with metadata could produce incredible visualisations.",
              "score": 5,
              "created_utc": "2026-01-11 10:18:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyym8ci",
              "author": "Ylsid",
              "text": "If that happens, game costs would absolutely explode for players and developers. Nvidia boss thinks it will, but it seems absolutely economically unviable.",
              "score": -1,
              "created_utc": "2026-01-11 12:25:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyyblbq",
              "author": "Cyclonis123",
              "text": "That will however probably kill nodding as we know it.",
              "score": -2,
              "created_utc": "2026-01-11 10:53:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyyi1z0",
                  "author": "BlackSwanTW",
                  "text": "Time to train LoRA to mod games XD",
                  "score": 6,
                  "created_utc": "2026-01-11 11:50:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyyqc26",
                  "author": "LightPillar",
                  "text": "[If anything, it would make it even easier](https://www.nvidia.com/en-us/geforce/rtx-remix/), but yes it would take on a slightly different less janky form.",
                  "score": 3,
                  "created_utc": "2026-01-11 12:56:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyxsgab",
          "author": "zoupishness7",
          "text": "Cool. Can't wait to try this. Is the structured noise approach basically endgame for creative upscalers? Seems like one could just keep tiling and zooming.",
          "score": 3,
          "created_utc": "2026-01-11 07:55:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2efzx",
          "author": "s1esset",
          "text": "It works okay, here is some fast quick samples and my updated workflow:\n\n[https://imgur.com/a/xmdM7ys](https://imgur.com/a/xmdM7ys)\n\nworkflow:\n\n[https://pastebin.com/SJ8jfXMd](https://pastebin.com/SJ8jfXMd)\n\nhttps://preview.redd.it/usguc3df4tcg1.png?width=4840&format=png&auto=webp&s=fd168167afee44ac22face39c3877aa9cae04063",
          "score": 4,
          "created_utc": "2026-01-11 23:45:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyzojep",
          "author": "Freonr2",
          "text": "I don't think we're very far off from this being actively used for games in real time. Render a game in ~PS1-era graphics, use AI to stylize it a certain way, in real time.\n\nDLSS SR and MFG already proves a lot of the fundamentals and seems like a matter of tuning for things like scene to scene consistency.\n\nI wouldn't be surprised for DLSS expanding to this, or maybe under a new name DLRE - Deep Learning Render Engine, or whatever they decide to brand it.",
          "score": 2,
          "created_utc": "2026-01-11 16:07:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0779e",
          "author": "dichtbringer",
          "text": "I took a look at the samples and Im a bit confused, from the project description it seems you only really the structure retaining node and you should be able to plug it into any diffusion model.\n\n i got it somewhat working with sdxl + wan (dint have flux atm), but no luck so far with sd 1.5 and animate diff. also what are the loras for?",
          "score": 2,
          "created_utc": "2026-01-11 17:35:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz1se5v",
              "author": "physalisx",
              "text": "> I took a look at the samples and Im a bit confused, from the project description it seems you only really the structure retaining node and you should be able to plug it into any diffusion model.\n\nTheir example workflow, which uses Flux 1 Dev, also requires a lora (from here: https://huggingface.co/zengxianyu/ppd/tree/main). If I run it without the lora I only get nonsense output, but with the lora it works.\n\nSeems to me their loras are required for it it to work. \n\nWhich is a shame because I'd really like to use this with other models, Flux 1 is soooo last year.\n\n>got it somewhat working with sdxl + wan\n\nHow did you get it working with wan? You mean for i2v? If I try to use it with the structured noise node for text2image I get an error on that node about some shape not matching.",
              "score": 4,
              "created_utc": "2026-01-11 21:55:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyy9c5r",
          "author": "FeelingVanilla2594",
          "text": "Holy mother of god‚Ä¶\n\nI can‚Äôt keep up, every single week there‚Äôs something new and amazing\n\nI want to try rerendering games like Cyberpunk with this",
          "score": 2,
          "created_utc": "2026-01-11 10:32:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyyvm8j",
          "author": "FishDeenz",
          "text": "You rock. I'm gonna try this later.",
          "score": 1,
          "created_utc": "2026-01-11 13:32:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyyx8xb",
          "author": "Mobile_Vegetable7632",
          "text": "can 3060 run this?",
          "score": 1,
          "created_utc": "2026-01-11 13:42:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyz61po",
          "author": "AlwaysDeath",
          "text": "Kinda new to workflows and stuff. Are there any types of loras that could turn anime/stylized drawing type art into realistic 3d stuff? Kind of like the video shows, but just for pictures.",
          "score": 1,
          "created_utc": "2026-01-11 14:33:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyzfq4f",
          "author": "bloke_pusher",
          "text": "First thing I had in mine the first time I learned about AI. This could lift games to the next level of realism. AI can even fix small missing sfx, weird animations and so on. I bet in a later state we'll even manage to remaster stylized games this way, by tuning a model to recognize the unique style without completely changing it (which is what a lot say as negative for hand made remakes/remasters as well. \"it lost its charm\".) I'm sure we can avoid that if we do it properly.",
          "score": 1,
          "created_utc": "2026-01-11 15:24:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0hpe8",
          "author": "i-mortal_Raja",
          "text": "So we will change the playblast viewport into realistic render our ?",
          "score": 1,
          "created_utc": "2026-01-11 18:24:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1i5u7",
          "author": "reality_comes",
          "text": "I can't get anything close to the examples out of this.",
          "score": 1,
          "created_utc": "2026-01-11 21:07:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1n8qf",
          "author": "physalisx",
          "text": ">structure-aligned re-rendering (no controlnet, no training)\n\nIt does require a trained lora though?\n\nAny chance this will be available for Wan text2image to? And/or for Qwen and Z-Image?",
          "score": 1,
          "created_utc": "2026-01-11 21:31:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz208ec",
          "author": "75875",
          "text": "Looking great, where can I find the workflow?",
          "score": 1,
          "created_utc": "2026-01-11 22:33:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz22viw",
              "author": "75875",
              "text": "Found one here:  \n[https://github.com/zengxianyu/PPD-examples/blob/main/phase\\_preserving\\_flux\\_dev.json](https://github.com/zengxianyu/PPD-examples/blob/main/phase_preserving_flux_dev.json)",
              "score": 1,
              "created_utc": "2026-01-11 22:45:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz3ljct",
          "author": "GunpowderGuy",
          "text": "\"A while ago I shared a preprint on a diffusion variant that keeps structure fixed while letting appearance change. Many asked how to try it without writing code.\"  \nThanks , i will check that out. I wonder if its similar to the ideas i have been having",
          "score": 1,
          "created_utc": "2026-01-12 03:30:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7ptml",
          "author": "SenatusScribe",
          "text": "I can't wait to play KOTOR with modern graphics!",
          "score": 1,
          "created_utc": "2026-01-12 19:14:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7rej3",
          "author": "Reflection_Rip",
          "text": "I would like to run this on some old anime that had very bad 3D CGI scenes to see if the scenes could be made to match the normal drawn anime scenes.",
          "score": 1,
          "created_utc": "2026-01-12 19:21:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxxijl",
          "author": "rookan",
          "text": "This idea is brilliant! Can't wait to try it! Do you think it will work in real time so I could play old video games with your nodes?",
          "score": 1,
          "created_utc": "2026-01-11 08:42:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxymc6",
          "author": "rinkusonic",
          "text": "The future is near boys.",
          "score": 1,
          "created_utc": "2026-01-11 08:52:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0f27h",
          "author": "axior",
          "text": "Hello! I work for movie/ads industry.\nCongrats on the awesome work!\n\nWe have actually never needed this yet for movies or ads, because the whole creation process includes several expertises, while usually we start working only with reference images or collages or storyboards; your technique looks like the best controlnet yet without being a controlnet, amazing work. \n\nIt‚Äôs suited for cases ‚Äútransform this into X‚Äù kind of workflows, we have not yet met a director or production company interested in this process, plus now we handle everything with edit models, but this would have been gold to have 1 year ago, we used lots of controlnets back then. \n\nLately we have seen a shift in big international clients, a sad one: if a few months ago we were given total freedom because the clients knew they were ignorant, now most marketing people have created a ‚Äúlogo‚Äù (lars mueller brockmann is revolting in his coffin) on ChatGPT and they think are not ignorant anymore, the clients are now used to lots of super cheap slaves from overseas which produce tons of indecent outputs; then they come to us because they got cheap work for cheap pay, but they still ant tons of outputs, therefore instead of 4-5 well thought and curated and post processed images we are forced to give 100-200 variations per day or they make our life hell. \n\nOne thing which would be super useful is if your method can work with a certain tunable freedom, kinda like denoise or vace strength or controlnet strength. In that case could it be used for upscaling? \n\nProper upscaling is still something highly needed, tiled creative upscaling often ends up in artifacts and repetead elements if you are using the prompt that described the whole image, or weird artifacts and misinterpretations if using a single general ‚Äú8K, high-quality, expensive production, HDR..‚Äù prompt, or too low modifications if done in low denoise. Manually prompting tiles is unfeasible. Right now there is no really good tiled controlnet neither for flux nor wan, zimage or qwen, it‚Äôs the best tool for tiled creative upscales and the SDXL one is still the best, could your method improve tiled upscaling? For example using TTP nodes? \n\nThe tool we use the most is absolutely Wan Vace 2.1. Fun Vace 2.2 is not able to interpolate so it is absolutely useless, sadly. If your method could be included in the possible salads we give as control videos (bits missing, bits with depth maps, bits with pose) that would be amazing. \n\nThe tools in the industry we would like to have the most at the moment and do not exist yet are \n\n1) Fp4 Wan 2.2 \n2) FP4 LTX2 Vace official (not a trash FUN version)\nand \n3) Some way to make a creative highly denoised tiled upscale which operates by rendering tiles (so it‚Äôs quick and low vram) but ‚Äúknowing‚Äù the whole image and considering the prompt conditioning accordingly.\n\nEDIT: Thank you so much for asking how a tool would be useful for actual work, we need more great brains asking what the professionals actually need, most of tools are cool but good only for fun-indie projects intellectually based on a model instead of a production workflow, thanks for creating the space to do it.",
          "score": 1,
          "created_utc": "2026-01-11 18:12:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxxk4m",
          "author": "Bronzeborg",
          "text": "Ah, man, Flux is so big and clunky. Can you do a wan one?",
          "score": 0,
          "created_utc": "2026-01-11 08:42:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyy1iog",
          "author": "suspicious_Jackfruit",
          "text": "Very interesting, I've worked with FTT that uses similar components to strip noise and print patterns of images, so I can understand roughly why this would work, I'm keen to experiment with it.\n\nHow does it handle with sizes larger than the model can natively output? It would also be interesting to see what happens to that structure preservation on eg a sd1.5 model, which is mega lightweight and fast",
          "score": 0,
          "created_utc": "2026-01-11 09:19:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxtdwc",
          "author": "3r0Van",
          "text": "Absolutely insane..!!!",
          "score": -1,
          "created_utc": "2026-01-11 08:04:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxpdp7",
          "author": "Mundane_Existence0",
          "text": "Cool! Hope this can eventually work with kijai's wan wrapper",
          "score": 0,
          "created_utc": "2026-01-11 07:28:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxsieu",
          "author": "venpuravi",
          "text": "Jagged VFX gets a polish.",
          "score": 0,
          "created_utc": "2026-01-11 07:56:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxufto",
          "author": "Dry-Heart-9295",
          "text": "To get normal results, do I need to use the full model? I tried models q8 and fp8, but they seem to give incorrect results. What should I do? Also i use fp8 scaled t5xxl\n\nhttps://preview.redd.it/tvpyyj3aiocg1.png?width=1280&format=png&auto=webp&s=f67fd978435cfdbff4eb848096c581f5d80d32ad",
          "score": 0,
          "created_utc": "2026-01-11 08:14:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyyasl4",
              "author": "Humble-Pick7172",
              "text": "Resize your image to fit the empty latent image node, or change the resolution of the empty latent node.",
              "score": 5,
              "created_utc": "2026-01-11 10:45:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyxyh11",
          "author": "cueqzapp3r",
          "text": "This with very fast diffusion models plus upscalers could bring us pretty close to realtime.",
          "score": 0,
          "created_utc": "2026-01-11 08:51:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyy1gt3",
          "author": "Nobodyss_Business",
          "text": "So this is an advanced img2img/vid2vid for style/texture transfer? \n\nCould this potentially solve the biggest problem of video models to follow the reference image overall style consistently? \n\nThat would be a *game changer*, finally no character or style Loras needed if that's the case",
          "score": 0,
          "created_utc": "2026-01-11 09:19:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyy59wn",
          "author": "StuccoGecko",
          "text": "Impressive and exciting. Great stuff OP!",
          "score": 0,
          "created_utc": "2026-01-11 09:55:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyy7e8g",
          "author": "FunDiscount2496",
          "text": "What‚Äôs the difference between this and unsampling/resampling? How does this work with flow models like Flux?",
          "score": 0,
          "created_utc": "2026-01-11 10:14:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyy7g31",
          "author": "depressedsnake3",
          "text": "VRAM requirment?",
          "score": 0,
          "created_utc": "2026-01-11 10:15:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyymp9o",
              "author": "rerri",
              "text": "For the image 2 image, no more than Flux regularly.",
              "score": 1,
              "created_utc": "2026-01-11 12:29:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyyj72v",
          "author": "Upper_Basis_4208",
          "text": "Wow\nVery nice",
          "score": 0,
          "created_utc": "2026-01-11 12:00:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyy7698",
          "author": "DoubleNothing",
          "text": "When I see \"OURS\" I immediately lose any attention to the product...  \nIn this context is even worst...",
          "score": -4,
          "created_utc": "2026-01-11 10:12:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxqxtc",
          "author": "Humble-Pick7172",
          "text": "any word on Flux2 support? I mean, Flux1 is cool and all, but Flux2 is probably may be better (I don't have enough space to keep Flux2 and Flux1 lmao)",
          "score": -1,
          "created_utc": "2026-01-11 07:42:14",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qa7i7p",
      "title": "April 12, 1987 Music Video (LTX-2 4070 TI with 12GB VRAM)",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/4ej1yen6nrcg1",
      "author": "harunandro",
      "created_utc": "2026-01-11 18:51:14",
      "score": 564,
      "num_comments": 139,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Animation - Video",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1qa7i7p/april_12_1987_music_video_ltx2_4070_ti_with_12gb/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nz0q1or",
          "author": "BeyondTheGrave13",
          "text": "Bravo, That's awesome",
          "score": 34,
          "created_utc": "2026-01-11 19:00:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0tzv8",
          "author": "TonyDRFT",
          "text": "Uhm, you really should finish it...that is really quite impressive! Did you do the on-beat transitions in Post?",
          "score": 26,
          "created_utc": "2026-01-11 19:17:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz0w32h",
              "author": "harunandro",
              "text": "yep, tiny bit of human touch! (: also color graded it a bit too!",
              "score": 25,
              "created_utc": "2026-01-11 19:27:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz14mbq",
          "author": "Critical-Variety-483",
          "text": "Jesus fuck you can't just STOP.\n\nFinish it.",
          "score": 41,
          "created_utc": "2026-01-11 20:05:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz1alri",
              "author": "harunandro",
              "text": "I will... Thanks for giving me the motivation!",
              "score": 18,
              "created_utc": "2026-01-11 20:33:26",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nz2kplt",
              "author": "diStyR",
              "text": "Will you deliver Spain from bondage?",
              "score": 2,
              "created_utc": "2026-01-12 00:17:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz35utl",
                  "author": "MinorDespera",
                  "text": "Sick reference. Death is the road to awe.",
                  "score": 2,
                  "created_utc": "2026-01-12 02:06:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz0su2c",
          "author": "Mistoph",
          "text": "Super cool. I2V, Load the audio file as soundtrack, and how did you prompt?",
          "score": 6,
          "created_utc": "2026-01-11 19:12:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz0toqb",
              "author": "harunandro",
              "text": "Quite simply:  \n\\- Camera very slowly zooms out, woman is dramatically moving her hand down.  \n\\- Woman is singing dramatically. She is sad.  \n\\- Woman sings with passion and a sad expression.  \n\\- The woman, emotional and dramatic, sings passionately, she is sad. Volumetric lights, smoke moves slowly. Woman slightly shifts her pose. Cinematic camera.",
              "score": 20,
              "created_utc": "2026-01-11 19:16:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz0uo2t",
                  "author": "Mistoph",
                  "text": "How'd you get the lipsync to work? I've loaded a soundtrack under Advanced > Audio, but the characters happily mouth something else :D",
                  "score": 4,
                  "created_utc": "2026-01-11 19:20:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz0we9d",
                  "author": "Denis_Molle",
                  "text": "It is possible to load our sound in the ltx 2 native worfklow? ü§î",
                  "score": 1,
                  "created_utc": "2026-01-11 19:28:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz0t63x",
          "author": "HollowAbsence",
          "text": "Nice, can you make a happy and sunny one now ? check INNA 2010 to 2015 vodeo clip. She got long black hair like this model.",
          "score": 5,
          "created_utc": "2026-01-11 19:14:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0uzjn",
          "author": "charliemccied",
          "text": "can you please share your the workflows used for the images and video? thanks",
          "score": 5,
          "created_utc": "2026-01-11 19:22:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz0y5oq",
              "author": "harunandro",
              "text": "This is with wan2gp, so if you are asking in the sense of a comfyui workflow, there is none. But if you are asking the steps i take,\n\nI generated the song with suno a bit back, i was loving it. So after seeing ltx2, i thought i would give it a music video. Found a good looking female character that is charming for me from civitai to be the singer, then i drafted a basic script of how i wanted the scenes to be. Using the image of the character and the script, generated the images with nanobanana pro. Then, i split the song in meaningful sections (10 to 15 secs) using audacity. Then, yesterday night queued all the scenes and audios in wan2gp before going to bed at 2AM. They were all done at 6AM.  When i woke up, they were all ready to be merged. At this stage, i used adobe premier, some color grading, some cuts and jumps...",
              "score": 26,
              "created_utc": "2026-01-11 19:36:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz1xslo",
                  "author": "Abject-Recognition-9",
                  "text": "wan2gp should really change name.   \ni always thought was something about WAN only, so i just skipped that.. for months.",
                  "score": 5,
                  "created_utc": "2026-01-11 22:21:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz11ezh",
                  "author": "HollowSnoggle",
                  "text": "How did you make it sing to your lyrics!? It‚Äôs amazing",
                  "score": 3,
                  "created_utc": "2026-01-11 19:51:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz13gdh",
                  "author": "haywire",
                  "text": "So how did you make the music, did you write the lyrics and tune and instrumental parts or were they generated as well?",
                  "score": 2,
                  "created_utc": "2026-01-11 20:00:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz0yrh6",
                  "author": "halpmeowtbruv",
                  "text": "That‚Äôs dope af bro thanks for sharing",
                  "score": 1,
                  "created_utc": "2026-01-11 19:38:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz12c5g",
                  "author": "charliemccied",
                  "text": "cool, thanks",
                  "score": 1,
                  "created_utc": "2026-01-11 19:55:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz1l4c4",
                  "author": "DanWest100",
                  "text": "Did you do this in ComfyUI? Not familiar with ¬†wan2gp.",
                  "score": 1,
                  "created_utc": "2026-01-11 21:21:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz1l8fq",
                  "author": "gallito_pro",
                  "text": "Hi, how do you get HD quality? I was trying hd settings but no look",
                  "score": 1,
                  "created_utc": "2026-01-11 21:21:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz1mhfu",
                  "author": "charliemccied",
                  "text": "sorry to keep bothering you with questions, what model and stuff did you choose in wan2gp? any loras? thanks",
                  "score": 1,
                  "created_utc": "2026-01-11 21:27:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz0xky3",
              "author": "Secure-Message-8378",
              "text": "Wan2GP. Not in comfyUI.",
              "score": 4,
              "created_utc": "2026-01-11 19:33:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz123jw",
                  "author": "charliemccied",
                  "text": "ah, i wasn't familiar with gp, thanks",
                  "score": 1,
                  "created_utc": "2026-01-11 19:54:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz1ychr",
          "author": "entmike",
          "text": "FINISH IT",
          "score": 3,
          "created_utc": "2026-01-11 22:23:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0tu0w",
          "author": "WildSpeaker7315",
          "text": "extremely well done, are you strugglign to vae decode further? i think it vae decodes the entire video each time you u gotta make more cuts or something. but well done this is great",
          "score": 2,
          "created_utc": "2026-01-11 19:16:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz0vj7f",
              "author": "harunandro",
              "text": "I generated 4 variants for each shot, i guess in total around 60 separate clips of varying lengths in total. Some of those were good on start, some middle some end, so i used my limited creative freedom a bit (:",
              "score": 4,
              "created_utc": "2026-01-11 19:24:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz0vto5",
                  "author": "WildSpeaker7315",
                  "text": "fancy that. top job",
                  "score": 1,
                  "created_utc": "2026-01-11 19:25:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz0us6o",
          "author": "LyriWinters",
          "text": "FP8 LT2X just isnt quite there.\n\ngreat job though pushing the models to their limits.",
          "score": 2,
          "created_utc": "2026-01-11 19:21:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz10mqi",
              "author": "harunandro",
              "text": "Yeah you are right, but dude, the last video generation model i touch was the WAN VACE, and man, this is light years ahead.",
              "score": 5,
              "created_utc": "2026-01-11 19:47:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz0yn3o",
          "author": "comfyui_user_999",
          "text": "Really good! Kind of an Evanescence vibe?",
          "score": 2,
          "created_utc": "2026-01-11 19:38:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz12csu",
              "author": "harunandro",
              "text": "well, when Bring Me To Life was released, i was 20 years old. I was a thrash metal fan back then, i was secretly enjoying it while despising myself...",
              "score": 3,
              "created_utc": "2026-01-11 19:55:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz18vs8",
          "author": "mcai8rw2",
          "text": "amazing. And top song. Really should complete it!",
          "score": 2,
          "created_utc": "2026-01-11 20:25:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz1aiv4",
              "author": "harunandro",
              "text": "I will... Thanks for giving me the motivation!",
              "score": 1,
              "created_utc": "2026-01-11 20:33:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz1cp2r",
          "author": "dtdisapointingresult",
          "text": "This is a better advertisement for WAN2GP than they could dream of. \n\nI went to the WAN2GP Github after seeing your video, and it gave zero clue wtf it does. 90% of the README is a changelog. All it says is some vague nonsense about bringing video generation to GPU-poor people. If it wasn't for your video I would've closed the tab and never went back.\n\nGood job. How long did this all take, excluding creating the song in Suno?",
          "score": 2,
          "created_utc": "2026-01-11 20:43:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz1dnqk",
              "author": "harunandro",
              "text": "Thanks. Out of the song, idea to life happened all in this weekend. But compute time is somewhere between 4 to 6 hours in total with 12GB vram... that is unbelievable to me too.",
              "score": 2,
              "created_utc": "2026-01-11 20:47:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz1v6wh",
                  "author": "dtdisapointingresult",
                  "text": "That 6 hours is mostly generations you rejected, right?\n\nI'm curious how many gens it took on average, for every take you kept. And how would you rate the takes you rejected, awful/ok/solid-but-not-great?\n\nSorry for all the questions, I won't get to use LTX2 myself for another 2 weeks, haha!",
                  "score": 1,
                  "created_utc": "2026-01-11 22:08:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz73h03",
          "author": "eternus",
          "text": "Truly impressive, thanks for breaking down your flow... its fascinating to see the different AI technologies being used and stitched to create a full process. I hope you get motivated to finish it, I'd love to see the full video.\n\nAlso... since you didn't mention it, what type of time commitment do you have wrapped up in it so far?",
          "score": 2,
          "created_utc": "2026-01-12 17:33:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz74u3i",
              "author": "harunandro",
              "text": "Hey, i already shared the full version in the board. If you like there is also a full version here: [https://youtu.be/zfm\\_5W41OhQ](https://youtu.be/zfm_5W41OhQ)  \n  \nThe part that you see here is 2:24, the compute time on my rig for it was around 4 to 6 hours, but i don't know how much time i spent on stitching the videos together, it was fun for me so did not notice it. The full version maybe added 2 more compute hours, it is 3:47.",
              "score": 1,
              "created_utc": "2026-01-12 17:40:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz7atd0",
                  "author": "eternus",
                  "text": "Oh sweet! Thanks Reddit for asynchronous posts, I only saw this day old post today... smh.\n\nThanks for the guestimates on time spent, I'm less worried about how much 'wasted' or 'valuable' time and more just seeing how the whole system has shifted.\n\nPresumably you had Premiere for work already, or some background in video so it was somewhat straightforward for you. Again, great job!\n\nI'll go check it out!",
                  "score": 1,
                  "created_utc": "2026-01-12 18:06:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz7xcyq",
          "author": "smflx",
          "text": "Amazing, impressive... No words enough to express this wonder to see that coming out of small GPU. Great model, stunning workflow. Thanks a lot",
          "score": 2,
          "created_utc": "2026-01-12 19:49:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0s1a1",
          "author": "Ok-Wolverine-5020",
          "text": "Epic!",
          "score": 2,
          "created_utc": "2026-01-11 19:08:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0vww2",
          "author": "No_Comment_Acc",
          "text": "This is the use case I am most interested in. Going to install Wan2gp tomorrow.",
          "score": 2,
          "created_utc": "2026-01-11 19:26:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz21x2x",
          "author": "TheGoldenBunny93",
          "text": "Your clip is dope, music as well but... AI Songs must evolve when we talk about chorus, they never do a good chorus. You keep waiting for the main part and she never comes.",
          "score": 2,
          "created_utc": "2026-01-11 22:41:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0uqmg",
          "author": "Dogluvr2905",
          "text": "Very very nice!",
          "score": 1,
          "created_utc": "2026-01-11 19:21:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0xw1v",
          "author": "External_Trainer_213",
          "text": "Awesome!",
          "score": 1,
          "created_utc": "2026-01-11 19:35:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0ygu9",
          "author": "Romando1",
          "text": "Amazing work - nice job OP!!",
          "score": 1,
          "created_utc": "2026-01-11 19:37:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0yk8x",
          "author": "Coach_Unable",
          "text": "does wanGP have a workflow/setting for voice to video ? I'd love to see the same workflow in comfy",
          "score": 1,
          "created_utc": "2026-01-11 19:38:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz121ju",
          "author": "Scandinavian-Viking-",
          "text": "This is really good. Amazing lip sinc.",
          "score": 1,
          "created_utc": "2026-01-11 19:53:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz12g95",
          "author": "dirtybeagles",
          "text": "Did you use LTX2 to sync your uploaded created song to the character's mouth movements? I haven't seen anyone do that with LTX2 yet.",
          "score": 1,
          "created_utc": "2026-01-11 19:55:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz12pz7",
              "author": "harunandro",
              "text": "Check out wan2GP it works out of the box.",
              "score": 5,
              "created_utc": "2026-01-11 19:56:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz5xcft",
                  "author": "dirtybeagles",
                  "text": "interesting...",
                  "score": 1,
                  "created_utc": "2026-01-12 14:11:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz14p9r",
          "author": "EbbNorth7735",
          "text": "Nice work!\n\n\nIt's interesting how the hands don't match up in the mirror. Just something I noticed.",
          "score": 1,
          "created_utc": "2026-01-11 20:05:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz16k1c",
              "author": "harunandro",
              "text": "you know they are not mirrors right? (:",
              "score": 1,
              "created_utc": "2026-01-11 20:14:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz3suc6",
                  "author": "EbbNorth7735",
                  "text": "They are meant to be her reflection",
                  "score": 1,
                  "created_utc": "2026-01-12 04:11:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz1a63b",
          "author": "ShepherdsWolvesSheep",
          "text": "Some serious character congruency issues but other than that this is awesome",
          "score": 1,
          "created_utc": "2026-01-11 20:31:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1bwnp",
          "author": "jacobpederson",
          "text": "Holy - I had no idea LTX-2 could read from an existing track, will be trying this out for sure!",
          "score": 1,
          "created_utc": "2026-01-11 20:39:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1cjmh",
          "author": "Frogy_mcfrogyface",
          "text": "Damn, nice. I need to try out wan2gp and stop fucking around with workflows lol¬†",
          "score": 1,
          "created_utc": "2026-01-11 20:42:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1dqvi",
          "author": "FederalLook5060",
          "text": "can my 8gb 4060 do this albiet at lower resolution?",
          "score": 1,
          "created_utc": "2026-01-11 20:48:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1eocz",
          "author": "skyrimer3d",
          "text": "Mindblowing, and surprised that even the song is AI, it's pretty good.",
          "score": 1,
          "created_utc": "2026-01-11 20:52:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1fm15",
          "author": "Code_Combo_Breaker",
          "text": "Saw a few glitches in the teeth and mouth area but overall this is extremely well done.   \n  \nOP, you should finish this. A few other scenic shots and this would pass as an Evanescence style music video.",
          "score": 1,
          "created_utc": "2026-01-11 20:56:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1fv1k",
          "author": "Godz1lla1",
          "text": "This is fantastic, well done.  More please.",
          "score": 1,
          "created_utc": "2026-01-11 20:58:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1kgtp",
          "author": "DanWest100",
          "text": "It‚Äôs unbelievable how far technology has come. I know what it would cost to produce the same video with real cameras, lighting, crew, union requirements, location scouting, visual effects, and editing‚Äîbig $$$. Now one person can do it while sleeping üòÑ. Great job!",
          "score": 1,
          "created_utc": "2026-01-11 21:18:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1lpon",
          "author": "Ok-Prize-7458",
          "text": "Incredible job with a 4070, im on a 4090 and really dont know what to do with it because i lack creativity",
          "score": 1,
          "created_utc": "2026-01-11 21:24:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1nd2i",
          "author": "Puzzled_Fisherman_94",
          "text": "great! this is on 12gb? you're using pinokio?",
          "score": 1,
          "created_utc": "2026-01-11 21:32:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1og2g",
          "author": "Anxious-Program-1940",
          "text": "Bruv, please teach us how your workflow was set up üò≠ this fire üòÆ‚Äçüí®üî•üëåüèæ",
          "score": 1,
          "created_utc": "2026-01-11 21:37:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1p126",
          "author": "Anxious-Program-1940",
          "text": "Please release this song, you got me crying üò≠",
          "score": 1,
          "created_utc": "2026-01-11 21:39:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1rlj0",
          "author": "Maskwi2",
          "text": "Finally some good quality video showing how good ltx-2 can be.\n\n\nI just started playing with it and I don't know why in most videos posted here I saw plastic skin and blur. One could think that this model is barely capable, in reality it's a beast. More fps and sound and it's just more natural than Wan 2.2 by a long shot.¬†",
          "score": 1,
          "created_utc": "2026-01-11 21:51:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1yau5",
          "author": "wonderflex",
          "text": "Which workflow version and checkpoint are you using ?  Also, how are you keeping the zoom / camera movement from going blurry. I find that as it zooms in or out that things get wonky real fast.",
          "score": 1,
          "created_utc": "2026-01-11 22:23:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1ykuq",
          "author": "sbalani",
          "text": "Does LTX Support lip sync??",
          "score": 1,
          "created_utc": "2026-01-11 22:25:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz1yybo",
              "author": "harunandro",
              "text": "yup",
              "score": 1,
              "created_utc": "2026-01-11 22:26:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz21qwq",
          "author": "Ok-Flatworm5070",
          "text": "More please!",
          "score": 1,
          "created_utc": "2026-01-11 22:40:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz21yy6",
          "author": "tmk_lmsd",
          "text": "How long does a single clip take on your setup? Will it run on 32gb?",
          "score": 1,
          "created_utc": "2026-01-11 22:41:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz22f7s",
          "author": "Ok-Flatworm5070",
          "text": "You should put this on youtube!",
          "score": 1,
          "created_utc": "2026-01-11 22:43:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz24zn6",
          "author": "X-Arkturis-X",
          "text": "Following!",
          "score": 1,
          "created_utc": "2026-01-11 22:56:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz25yv9",
          "author": "Draufgaenger",
          "text": "savage not to finish this lol..you monster",
          "score": 1,
          "created_utc": "2026-01-11 23:01:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz26qef",
          "author": "FalloutGuy91",
          "text": "Does LTX-2 work on AMD?",
          "score": 1,
          "created_utc": "2026-01-11 23:05:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2ajiz",
          "author": "Apprehensive_Bar6609",
          "text": "That is amazing!",
          "score": 1,
          "created_utc": "2026-01-11 23:25:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2blza",
          "author": "Redd411",
          "text": "great concept and execution!  some tech issues but definitely finish it.. good stuff!",
          "score": 1,
          "created_utc": "2026-01-11 23:30:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2c7jj",
          "author": "Choowkee",
          "text": "Really well done.\n\nThough I keep seeing the same issues with LTX2 - the moment the camera is in a wider shot the face becomes blotchy and distorted when there is movement involved. WAN 2.2 does not have that issue (or at least not to this degree). Hopefully this is something that will be able to be ironed out for LTX2.",
          "score": 1,
          "created_utc": "2026-01-11 23:33:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2d86n",
          "author": "Darqsat",
          "text": "I feel like some people just baiting. I can't make a single video with I2V LTX-2 on 5090 without having absolute horror show with disappearing objects, distorted bodies, plastic teeth.",
          "score": 1,
          "created_utc": "2026-01-11 23:39:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2h64f",
          "author": "Yappo_Kakl",
          "text": "To be fair and give you some demotivation : that is still sloppy slop. Uncanny, not alive ,plastic and voice are the same. Hope it helps",
          "score": 1,
          "created_utc": "2026-01-11 23:59:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2jdyu",
          "author": "mrchacalito",
          "text": "puedo preguntar cual fue el prompt de suno?",
          "score": 1,
          "created_utc": "2026-01-12 00:10:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2jjbl",
          "author": "1aysays1",
          "text": "Finish the sonnnnng!",
          "score": 1,
          "created_utc": "2026-01-12 00:11:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2m4ck",
          "author": "Poet-Pretend",
          "text": "Para ser todo ‚Äúfake‚Äù, el resultado es brutal, por lo menos a m√≠ me ha dejado boquiabierto‚Ä¶  \nBuen√≠simo el trabajo.\n\nYo estoy con una RTX 4070 Ti de 12 GB y 32 GB de RAM. ¬øQu√© modelo usas, el Dev 19B (Distilled) u otro?\n\nA m√≠ FP8 me crashea (tema PyTorch + offload a CPU), as√≠ que me toca ir en FP16 s√≠ o s√≠‚Ä¶¬øse puede usar FP8 de alguna manera?  \n  \n¬øAlguna sugerencia a nivel de \"Configuration\" -> \"Performance\"?\n\n¬°Gracias!",
          "score": 1,
          "created_utc": "2026-01-12 00:24:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2m9zz",
          "author": "verocious_veracity",
          "text": "Wait how can you sync the mouth to the song?",
          "score": 1,
          "created_utc": "2026-01-12 00:25:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2qn9v",
          "author": "M4xs0n",
          "text": "Can someone explain to me how much ‚Äûquality‚Äú (?) I loose when I have to use a ‚Äûcompressed‚Äú Version of the Original file that needs for example 32GB VRAM?\n\nI tried to use 24 some day with an image model once but had to use 16gb or sth and it wasnt as good‚Ä¶",
          "score": 1,
          "created_utc": "2026-01-12 00:46:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2shzb",
          "author": "niconpat",
          "text": "This is so Eurovision song contest it hurts.\n\nWe should do a Eurovision AI song contest.",
          "score": 1,
          "created_utc": "2026-01-12 00:55:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz38dbv",
          "author": "NorX_Aengelll",
          "text": "Really love it, would love a full version and there is a link to the suno ?",
          "score": 1,
          "created_utc": "2026-01-12 02:19:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3iq6e",
          "author": "ZHName",
          "text": "\"I still made your coffee right. Two sugars splash of milk, every morning every night. \"\n\n![gif](giphy|3oriO04qxVReM5rJEA)\n\nROFL, well it's a music video alright. Good work! I'm sure other musicians will catch on with all they can do with music.",
          "score": 1,
          "created_utc": "2026-01-12 03:15:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3ngjv",
          "author": "madhu_23",
          "text": "Wow it's looks so real. Great job. Will this work on my Nvidia GeForce RTX 3060 12GB VRAM, 16GB RAM? \n\nI want to lip sync my character. Do you know any models which works smoothly",
          "score": 1,
          "created_utc": "2026-01-12 03:41:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3vppz",
          "author": "Fox009",
          "text": "Had to hear the rest of this song and finally found it: [https://suno.com/s/fiIQvEKT3NK1xbRi](https://suno.com/s/fiIQvEKT3NK1xbRi)  \nKeep it up! This is wonderful.",
          "score": 1,
          "created_utc": "2026-01-12 04:29:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz411qi",
          "author": "_Wheres_the_Beef_",
          "text": "Impressive. This made me want to give Wan2GP another shot, but I'm not having any luck with it. Just trying to run the default prompt for LTX-2 Dev19b Default with just text, I'm getting a video that is hilariously unrelated to the prompt every single time. Quality is ok, just not at all what the prompt is asking for. Also, VAE decoding takes forever, all the while the GPU is sitting at just 25% memory usage.",
          "score": 1,
          "created_utc": "2026-01-12 05:05:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz487z4",
          "author": "Hi-Profile",
          "text": "Really good except the initial images look like flux plastic skin could have used an upscaler or another tool to make the images look more realistic before compiling to video",
          "score": 1,
          "created_utc": "2026-01-12 05:59:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4dvg4",
          "author": "Wayward_Prometheus",
          "text": "Impressive is an understatement! Amazing work and inspiration!",
          "score": 1,
          "created_utc": "2026-01-12 06:46:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4fcim",
          "author": "smashblues",
          "text": "How long did it take for your system to generate this?",
          "score": 1,
          "created_utc": "2026-01-12 06:58:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4n121",
          "author": "WhyIsTheUniverse",
          "text": "April 12th, 1987?",
          "score": 1,
          "created_utc": "2026-01-12 08:08:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4p0bq",
          "author": "James_Reeb",
          "text": "Crazy , suno gave me same voice and same parts of Melody",
          "score": 1,
          "created_utc": "2026-01-12 08:26:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4t8o8",
          "author": "Sharon_El",
          "text": "you did the effort to create 2:24 video but couldnt finish it properly? it could be so much better with a proper ending",
          "score": 1,
          "created_utc": "2026-01-12 09:07:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4uawm",
              "author": "harunandro",
              "text": "it is cooking (:",
              "score": 2,
              "created_utc": "2026-01-12 09:17:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz4w8ey",
                  "author": "Sharon_El",
                  "text": "looking forward :)",
                  "score": 1,
                  "created_utc": "2026-01-12 09:37:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz4wrc5",
          "author": "Alelnh",
          "text": "This looks great! I started learning Stable Diffusion to do exactly that, hopefully I can do something like you soon.",
          "score": 1,
          "created_utc": "2026-01-12 09:42:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz59lst",
          "author": "c300g97",
          "text": "I really want to use LTX2 but sadly i have 32gb of ram only.\nI have a 5090FE , but its struggling due to the ram.\nAmazing work tho!",
          "score": 1,
          "created_utc": "2026-01-12 11:37:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5hkaf",
          "author": "cueqzapp3r",
          "text": "How did you do the lipsync?",
          "score": 1,
          "created_utc": "2026-01-12 12:37:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz61cft",
          "author": "Salty_Flow7358",
          "text": "Fk.. that's VERY impressive. It's the lips sync 40% and 60% the music, cause the music goes HARD",
          "score": 1,
          "created_utc": "2026-01-12 14:33:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz77499",
          "author": "flpnr",
          "text": "Wow, your video is amazing! I also wish I had an AI tool like that... I recently made my first music video with Google Flow. I generated several videos and then tried to combine them with the music using capcut. Some words weren't perfectly synchronized, although I think it turned out reasonably well. If you have patience, I think you can do a lot of cool things. The music is electronic and the lyrics are based on some Gen Z words (kind of a trend among some teenagers on TikTok) and are in Portuguese.  \n  \n[https://youtube.com/watch?v=F\\_TJ41EAHvY&si=x9Gfy489UlDoqI88](https://youtube.com/watch?v=F_TJ41EAHvY&si=x9Gfy489UlDoqI88)",
          "score": 1,
          "created_utc": "2026-01-12 17:50:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzazhlf",
          "author": "coverednmud",
          "text": "Please... finish this.",
          "score": 1,
          "created_utc": "2026-01-13 05:33:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzb4bnw",
              "author": "harunandro",
              "text": "Already did! [here.](https://youtu.be/zfm_5W41OhQ?si=8akYX04ieR7gsmKf)",
              "score": 2,
              "created_utc": "2026-01-13 06:11:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzb6x85",
                  "author": "coverednmud",
                  "text": "Thank you! I am off to watch it. \\*\\_\\*",
                  "score": 1,
                  "created_utc": "2026-01-13 06:32:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzb3rv7",
          "author": "According_Study_162",
          "text": "wow, so much emotion. is that song released?",
          "score": 1,
          "created_utc": "2026-01-13 06:06:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzb43u2",
              "author": "harunandro",
              "text": "Hey, yeah you can find it [here.](https://youtu.be/zfm_5W41OhQ?si=8akYX04ieR7gsmKf)",
              "score": 1,
              "created_utc": "2026-01-13 06:09:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzb5gz4",
                  "author": "According_Study_162",
                  "text": "Your a great example that shows AI, has leveled the playing field. Anyway I definitely have to try LTX-2 now.",
                  "score": 1,
                  "created_utc": "2026-01-13 06:20:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzbi5is",
          "author": "Totem_House_30",
          "text": "Damn! That's amazing",
          "score": 1,
          "created_utc": "2026-01-13 08:13:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0t8y6",
          "author": "Perfect-Campaign9551",
          "text": "Non distilled model or distilled? There must be something wrong with ComfyUI workflows because they always give blurry results and your results are a bit more crisp",
          "score": 1,
          "created_utc": "2026-01-11 19:14:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz0ukoy",
              "author": "harunandro",
              "text": "On lower resolutions, mine was also a bit blurry, used 720p, also i used LTX2 - IC LORA DETAILER with 1.0 weight. You can find it on civitai. Another important thing is, how far the camera is from the model. I noticed if it is farther away than medium shot, it starts to get blurry.\n\nEdit: yeah it is distilled",
              "score": 4,
              "created_utc": "2026-01-11 19:20:19",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nz0u571",
              "author": "WildSpeaker7315",
              "text": "wan2gp is a lot better for some reason i have every  model ggufQ5 to 8 , even at 2560x1440 it still looks worse then wan 2gp 1280x720.. Not a clue",
              "score": 2,
              "created_utc": "2026-01-11 19:18:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz18goh",
                  "author": "LiveLaughLoveRevenge",
                  "text": "I‚Äôm beginning to suspect that the release of the LTX2 I2V comfy node is somehow bugged. \n\nIt‚Äôs the only reason I can think of why results from the community seem to vary so widely, and the comfy I2V results seem worse than T2V and wan2gp I2V",
                  "score": 1,
                  "created_utc": "2026-01-11 20:23:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz1rlfk",
                  "author": "Perfect-Campaign9551",
                  "text": "My problem with WanGP is even on larger GPU's its slower than Comfy for some reason. In fact I2V for me in Wan2GP just OOM's even though I have a RTX3090",
                  "score": 1,
                  "created_utc": "2026-01-11 21:51:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz1wc7p",
                  "author": "Relevant_Eggplant180",
                  "text": "This bugs me out. I've been getting nothing like this quality with comfy. Tried different models. Even rendered a 1080, still everything is blurry... Weird",
                  "score": 1,
                  "created_utc": "2026-01-11 22:14:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz0uhsn",
          "author": "abyss_dreams_x",
          "text": "This looks exactly like Inna! Can you do Sun is Up?! Great work",
          "score": 1,
          "created_utc": "2026-01-11 19:19:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1479h",
          "author": "onthemove31",
          "text": "this is bloody brilliant work!",
          "score": 1,
          "created_utc": "2026-01-11 20:03:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1guv6",
          "author": "Canadian_Border_Czar",
          "text": "Shit bud this is better than 99% of the AI generated commercials/ads I see.\n\n\nYou've easily got yourself a 6 figure salary with that kind of work. Watchu doing just playing around?¬†",
          "score": 1,
          "created_utc": "2026-01-11 21:02:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1ye2o",
          "author": "Inevitable_Ad_4487",
          "text": "The character changes to like 11 different people throughout this",
          "score": -1,
          "created_utc": "2026-01-11 22:24:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz1znoc",
              "author": "harunandro",
              "text": "yeah i know mate. But if you squint your eyes a bit... (:",
              "score": 5,
              "created_utc": "2026-01-11 22:30:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz58mjy",
                  "author": "iamafckinglady",
                  "text": "If you squint it‚Äôs mint",
                  "score": 1,
                  "created_utc": "2026-01-12 11:29:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q4ngjy",
      "title": "Brie's Lazy Character Control Suite (Qwen Edit 2511)",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1q4ngjy",
      "author": "Several-Estimate-681",
      "created_utc": "2026-01-05 14:43:05",
      "score": 539,
      "num_comments": 54,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q4ngjy/bries_lazy_character_control_suite_qwen_edit_2511/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nxtof38",
          "author": "rookan",
          "text": "Impressive! Will it work on 16GB VRAM + 64GB RAM?",
          "score": 12,
          "created_utc": "2026-01-05 14:44:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxtt3sf",
              "author": "Several-Estimate-681",
              "text": "Not the AIO version. But with the GGUF version, yeah. I think for you, a Q5 model will do. You might be able to run the Q6\\_K if you're lucky, which is the model I sometimes run for speed.",
              "score": 13,
              "created_utc": "2026-01-05 15:09:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxucheu",
                  "author": "rookan",
                  "text": "Thanks for the recommendations",
                  "score": 2,
                  "created_utc": "2026-01-05 16:40:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxtvws8",
          "author": "krait17",
          "text": "Newbie here, atm i'm using controlnet for the pose. Are these loras better ?",
          "score": 3,
          "created_utc": "2026-01-05 15:22:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxtzafp",
              "author": "Several-Estimate-681",
              "text": "Yes, and it can do much more with maintaining character details, even from behind, but its more complex.\n\nAlso, while ControlNet only controls pose, this lora also transfers over the style and body-type of the input 'pose' character.\n\nA good compromise is honestly AnyPose, because that's more powerful than ControlNet too, but only needs 1 workflow and 2 inputs. Easy-peasy. Its linked above too.",
              "score": 6,
              "created_utc": "2026-01-05 15:39:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxtvo8d",
          "author": "Enshitification",
          "text": "Sweet workflows. Thank you. About the mask and image method you asked for, have you checked out the LayerForge node suite? I think it can do that sort of thing, or at least make it easier.",
          "score": 3,
          "created_utc": "2026-01-05 15:21:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxtyc3c",
              "author": "Several-Estimate-681",
              "text": "https://preview.redd.it/cg496va3vjbg1.png?width=350&format=png&auto=webp&s=3f7b41b880cbc8b3659aa52286c3f74164a5216a\n\nYeah, my old workflow used exactly that.\n\nThe problem is, you need to maneuver the input image with x and y percentages, not exactly the most intuitive method, no?\n\nWhat I need, is literally a drag and drop type of space where I can manipulate the input image around on a background.\n\nI KNOW such a node exists, I've used it before, but I've got way way too many old workflow to dig through to ever be able to find it...",
              "score": 2,
              "created_utc": "2026-01-05 15:34:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxtywqp",
                  "author": "Enshitification",
                  "text": "I was trying to remember that node too. I have memory of using something like that. Could it be the ComfyCanvas extension?     \nhttps://github.com/taabata/ComfyCanvas",
                  "score": 2,
                  "created_utc": "2026-01-05 15:37:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxv0vw6",
                  "author": "Ok_Artist_9691",
                  "text": "[https://github.com/Saquib764/omini-kontext](https://github.com/Saquib764/omini-kontext)\n\nI think this might be what you're thinking of, pretty handy sometimes",
                  "score": 2,
                  "created_utc": "2026-01-05 18:32:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxwr3ni",
                  "author": "inb4Collapse",
                  "text": "Hi Brie,\n\nLove your work. Would that help?  \n[https://www.reddit.com/r/comfyui/comments/1q2u9oi/comment/nxgd475/?context=1](https://www.reddit.com/r/comfyui/comments/1q2u9oi/comment/nxgd475/?context=1)  \nIt's a Custom node originating from Background removal with \"rembg\" that supports different models.",
                  "score": 2,
                  "created_utc": "2026-01-05 23:25:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxu8w3l",
          "author": "ResponsibleKey1053",
          "text": "Excellent write up! This Christmas has delivered so much cool stuff, it's hard to even begin working through it all!",
          "score": 2,
          "created_utc": "2026-01-05 16:24:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxyr0ry",
              "author": "Several-Estimate-681",
              "text": "Merry, merry, merry (belated), Christmas!  \nHappy, happy, happy (belated) New Years!\n\nStill in time to wish you a merry(?) year of the Horse!",
              "score": 2,
              "created_utc": "2026-01-06 06:32:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxuues3",
          "author": "physalisx",
          "text": "I have no clue what the point of AnyPose lora is, Qwen Edit does pose transfer natively perfectly fine.",
          "score": 2,
          "created_utc": "2026-01-05 18:03:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxx0i4y",
              "author": "Several-Estimate-681",
              "text": "AnyPose just does a better job. I've seen some folks do some interesting comparisons. Can't find it now though...\n\nIts the most popular image 2 image model on Hugging Faces right now for a reason.",
              "score": 1,
              "created_utc": "2026-01-06 00:14:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxv9005",
          "author": "decadance_",
          "text": "Cool stuff! But, is there a description anywhere for tori29umai¬†loras? Like what prompt to use or what they do in general beside what can be inferred from name. Can't find any.\n\nAlso there seem to be spelling errors, is that intentional or irrelevant? (Change the character in the background and pose and expression **\\`pucture1\\`** to a character on **\\`pictuer2\\`**.\n\nAlso, **GGUF Loader** node was causing errors on repeated gens ([https://github.com/comfyanonymous/ComfyUI/issues/11152](https://github.com/comfyanonymous/ComfyUI/issues/11152)). Switching to **Unet Loader (GGUF)** fixed the issue.\n\nAlso, using Qwen-Image-Edit-2511-Lightning-4steps-V1.0-bf16.safetensors I've noticed slightly increased prompt adherence while loosing about \\~15% of \\*style\\* towards realism.",
          "score": 2,
          "created_utc": "2026-01-05 19:08:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxx26dr",
              "author": "Several-Estimate-681",
              "text": "Oh, thanks. That's actually super swell to find out. That appears to the error I've encountering specifically with the Q8\\_0 model. Thanks for pointing that out. I think I will push a secret update, if that's the case.\n\nUse EXACTLY the prompt that is provided. Especially for the first part for the post extraction. Yeah its misspelled, the creator of the lora is Japanese, I asked her about it, she just said something along the lines of 'oops'. Anyhow, you can correct those two words if you like, it doesn't make an appreciable difference.  \n  \nHere's her blog that has the two loras in question at the bottom. My RePose workflow does not harness the full power of the lora, because it's actually a fusion lora. I will update my Character Fusion workflow eventually:tm:.  \n[https://note.com/tori29umai/n/n09e8d9625f78?sub\\_rt=share\\_pb](https://note.com/tori29umai/n/n09e8d9625f78?sub_rt=share_pb)\n\nI will give that lightning lora discovery a look if I get the time, see if the benefits outweighs the cost. Or I just add the little tidbit in the notes.\n\nThanks for your valuable input!",
              "score": 2,
              "created_utc": "2026-01-06 00:23:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny0tw0d",
                  "author": "decadance_",
                  "text": "Thanks for the link, and the WF!\n\nYou might want to check out 'reference latent' solution to un-zooming when using >1MP latents (if you haven't already), as one of your notes mention it. Though it introduces whole \"now I can/need   to manage resolution's\" issue, which would clash with whole automation philosophy.",
                  "score": 2,
                  "created_utc": "2026-01-06 15:38:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxvy491",
          "author": "endege",
          "text": "a good method or node for placing an image + mask onto a background image - have you tried using qwen image layered? this is something that it was made for?",
          "score": 2,
          "created_utc": "2026-01-05 21:05:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxx2k60",
              "author": "Several-Estimate-681",
              "text": "Qwen Image Layered does the opposite of what I want. lmao.\n\nAnyhow, for models that have alphas or layers, I generally sit on the fence. I've never had particularly good experiences with them and they've never given results of enough quality that they would be useful.\n\nWeen Image Layered though,, will eventually become useful, because people will train loras for it.",
              "score": 1,
              "created_utc": "2026-01-06 00:25:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxwg24y",
          "author": "MathematicianLessRGB",
          "text": "Nice",
          "score": 2,
          "created_utc": "2026-01-05 22:29:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxx2ktu",
              "author": "Several-Estimate-681",
              "text": "Noice",
              "score": 2,
              "created_utc": "2026-01-06 00:25:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxynrvs",
          "author": "HyperspaceAndBeyond",
          "text": "I've heard of catgirl but mousegirl? That's new to me",
          "score": 2,
          "created_utc": "2026-01-06 06:05:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxyr5av",
              "author": "Several-Estimate-681",
              "text": "Its a scientific fact that mouse girls are superior.\n\nCat girls are self-centered and mean!",
              "score": 2,
              "created_utc": "2026-01-06 06:33:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny13yv2",
          "author": "zyxwvu54321",
          "text": "The \"Character sheet\" workflow is very good and works well but The \"Lazy repose\" workflow is not working for me at all. With qwen edit 2511 q4\\_k\\_m gguf , it just adds some random background and adds the character sheet to the image. And even with 2509 nunchaku one, the output is not even close to the desired.",
          "score": 2,
          "created_utc": "2026-01-06 16:25:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8d62s",
              "author": "Several-Estimate-681",
              "text": "I have not tested for models smaller than Q4, but Q4 isn't that far from Q6 which is basically my primary model.\n\nThe reasons could be many, what's your QwenEditRePoseInfo image look like? That will at least let me take a look to see if the inputs are okay.",
              "score": 1,
              "created_utc": "2026-01-07 17:15:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny4rmpy",
          "author": "oonahermon",
          "text": "This is AMAZING, thank you so much for sharing it! I was able to create a character sheet successfully, but when I upload that same character sheet (man with green visor) into the RePose workflow along with a pose reference (man sitting), it doesn‚Äôt seem to actually put the character into the pose. Instead, it looks like it‚Äôs merging the pose image with the character sheet.\n\nI made sure not to change any of the prompts or settings, so I‚Äôm wondering if I may have overlooked something on my end. Not sure if this helps, but I used the Q2\\_K version (I have a 12GB card and wasn‚Äôt sure which model would be best). Thanks again for putting all of this together, and apologies if I missed something obvious!\n\nhttps://preview.redd.it/yx03fu6wdubg1.png?width=1431&format=png&auto=webp&s=d270248565c28f82e513da67ea3cc39d87bff8bc",
          "score": 2,
          "created_utc": "2026-01-07 03:01:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny753qn",
              "author": "Several-Estimate-681",
              "text": "This error pops for a variety of reasons: if the pose is too complicated, if the aspect ratio of the pose image is over 2:1 or under 1:2.\n\nFor you though, your character sheet is the wrong one, you've put in the one named 'info', not the raw one without the input image on the side. Secondly, your character sheet is only for the top-half of the person (although, even then, it should work).\n\nFirst, just put in the right character sheet and give it a go. If that doesn't work, regenerate the character sheet as a full-body one instead of this one where his legs are cut off.",
              "score": 2,
              "created_utc": "2026-01-07 13:43:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nygjh1n",
                  "author": "oonahermon",
                  "text": "Thank you so much for the quick reply! I‚Äôve uploaded the correct raw character sheet (not the info one), and I also regenerated the character sheet using a full-body character image. I then switched the pose reference to a full-body pose as well, but it still seems to be blending the pose image with the character sheet rather than fully reposing the character.\n\nI also tried changing the GGUF Loader from Q2\\_K to Q6\\_K just to rule that out, and I‚Äôm seeing similar results there as well.\n\nIs there anything else you‚Äôd recommend checking? Happy to test anything you suggest, and thanks again for putting this workflow together!\n\nhttps://preview.redd.it/j3l9nziqj6cg1.png?width=1261&format=png&auto=webp&s=d7af1ee58bb28ad516627a750089b5a139223a35",
                  "score": 1,
                  "created_utc": "2026-01-08 19:51:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz0v9n3",
          "author": "sh1n0b1n0m0n0",
          "text": "I used **Lazy Character Sheet V2.1 GGUF** and this is what I got. Nothing works. This is some kind of bug.  \nI used several weights ‚Äî **qwen-image-edit-2511-Q6\\_K.gguf** and **qwen-image-2512-Q6\\_K.gguf** ‚Äî for text-to-image and everything works fine, so the issue is not with the weights!\n\n[](https://huggingface.co/unsloth/Qwen-Image-Edit-2511-GGUF/resolve/main/qwen-image-edit-2511-Q6_K.gguf?download=true)\n\nhttps://preview.redd.it/a8c4eekmsrcg1.png?width=1484&format=png&auto=webp&s=b95b48a117a9d6c53927a59034a2a0d205543f5b",
          "score": 1,
          "created_utc": "2026-01-11 19:23:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz1qh6n",
              "author": "sh1n0b1n0m0n0",
              "text": "Guys, maybe screw it? Wouldn‚Äôt it be better to just run ControlNet on Stable Diffusion or FLUX? I‚Äôm seeing more and more how AI-bros try to profit off beginners, don‚Äôt give tips, don‚Äôt share workflows. They act like snobs. I‚Äôm trying to make more references for myself, since I‚Äôm a 3D artist and I‚Äôve seen that AI can actually be useful, but apparently I‚Äôm starting to turn anti-AI because of the AI-bro community itself. Guys, let‚Äôs share what we have - I‚Äôm completely open and ready to give tips on anatomy and sculpting in general. Don‚Äôt be stingy assholes, it won‚Äôt earn you any points.",
              "score": 1,
              "created_utc": "2026-01-11 21:46:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxtt5gc",
          "author": "witcherknight",
          "text": "Can it do complex two char interaction ??",
          "score": 1,
          "created_utc": "2026-01-05 15:09:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxtvnmd",
              "author": "Several-Estimate-681",
              "text": "I have not tried because I know it would be futile.\n\nNothing is stopping you from running it twice then comping the two characters together though.",
              "score": 5,
              "created_utc": "2026-01-05 15:21:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxu5316",
                  "author": "witcherknight",
                  "text": "That wont work in situations like one person is putting a guy on a chokehold",
                  "score": 1,
                  "created_utc": "2026-01-05 16:06:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q0dsnj",
      "title": "Z-Image-Turbo vs Qwen Image 2512",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1q0dsnj",
      "author": "Artefact_Design",
      "created_utc": "2025-12-31 14:06:31",
      "score": 521,
      "num_comments": 180,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q0dsnj/zimageturbo_vs_qwen_image_2512/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwxb252",
          "author": "Substantial-Dig-8766",
          "text": "I am investigating the possible use of alien technology in Z-Image.",
          "score": 142,
          "created_utc": "2025-12-31 15:14:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx0iioc",
              "author": "yaosio",
              "text": "If it's following the same densing laws as LLMs then it's expected to be better while at a similar size to older models. There's more effort going into LLMs however which is why it's taken so long, but once we get open weight multimodal models image generation will be intertwined with text generation.",
              "score": 4,
              "created_utc": "2026-01-01 01:42:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwzmnoi",
              "author": "ZootAllures9111",
              "text": "IDK. Z has more of the weird distinct \"what every Chinese diffusion model insists white women look like despite no real person looking like that\" aesthetic in the first two pics here. These are definitely WAY better stock results as far as that kind of content goes than previous versions of Qwen. Not that I really think this is a particularly useful comparison, we already know Z is basically a heavily focused realism finetune of the Base.",
              "score": -5,
              "created_utc": "2025-12-31 22:27:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwzuwqy",
                  "author": "Monsterpiece42",
                  "text": "I'm curious what you mean by this. Image 1 is a very specific aesthetic and not what I would call a stereotype and image 2 looks nothing like the first woman, and I would say could even be ethnically mixed a bit. \n\nWhat look are you describing? Genuinely curious as I don't have a super good eye for this stuff.",
                  "score": 6,
                  "created_utc": "2025-12-31 23:16:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx0ezib",
                  "author": "GRCphotography",
                  "text": "just wait for cyberrealstic or juggernaut to get there hands on Base and make checkpoints, I'm sure the Asian look will be drowned out once the public has access to train.",
                  "score": 1,
                  "created_utc": "2026-01-01 01:19:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwwzx0i",
          "author": "Brave-Hold-9389",
          "text": "Z image is goated",
          "score": 347,
          "created_utc": "2025-12-31 14:12:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwx3zmw",
              "author": "unrealf8",
              "text": "It‚Äôs insane what it can do for a turbo version. All I care about is the base model in hopes that we get another SDXL moment in this sub.",
              "score": 95,
              "created_utc": "2025-12-31 14:35:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwx7g5p",
                  "author": "weskerayush",
                  "text": "We all are waiting for base but the thing that makes Turbo what it is is its compact size and accessibility to majority of people but base model will be heavier and I don't know how much accessible it will be for the majority",
                  "score": 42,
                  "created_utc": "2025-12-31 14:54:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwx5s6n",
                  "author": "HornyGooner4401",
                  "text": "We're probably gonna get GTA 6 before Z-Image Base ü•Ä",
                  "score": 9,
                  "created_utc": "2025-12-31 14:45:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwzbieu",
                  "author": "rm-rf-rm",
                  "text": "Wasn't it supposed to be out by now?",
                  "score": 2,
                  "created_utc": "2025-12-31 21:25:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwz8xkt",
                  "author": "Perfect-Campaign9551",
                  "text": "It's never coming out",
                  "score": 0,
                  "created_utc": "2025-12-31 21:11:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx0wotr",
              "author": "No_Conversation9561",
              "text": "No wonder they‚Äôre not releasing the base and edit versions üòÇ\n\nKinda like what microsoft tried to do with vibevoice. Realised it‚Äôs too good.",
              "score": 5,
              "created_utc": "2026-01-01 03:17:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx0b8kl",
              "author": "IrisColt",
              "text": "I kneel",
              "score": 2,
              "created_utc": "2026-01-01 00:55:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx1khve",
              "author": "Ok_Artist_9691",
              "text": "Idk, I think I like the qwen images better (other than the 1st image, both look fake and off somehow, z-image just less so). the 2nd image for instance, the hair, the sweater,, the face and expression, all look more natural and realistic to me. For me, qwen wins this comparison 5-1.",
              "score": 2,
              "created_utc": "2026-01-01 06:22:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx1v7ci",
                  "author": "ThexDream",
                  "text": "Read the prompt, and then choose.",
                  "score": 1,
                  "created_utc": "2026-01-01 08:08:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx1zr64",
              "author": "JewzR0ck",
              "text": "Even runs flawlessly with my 8gb vram, qwen would just crash my system or take ages for a picture",
              "score": 2,
              "created_utc": "2026-01-01 08:56:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwx6yuv",
          "author": "3deal",
          "text": "Z image is black magic",
          "score": 84,
          "created_utc": "2025-12-31 14:52:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwzen3c",
              "author": "Whispering-Depths",
              "text": "RL and distillation: forcing the model to optimize for fewer steps additionally forces the model to use more redundancies and learn real problem-solving and use real intelligence and reasoning during inference.\n\nIt's like comparing the art they used to make in the 1500's to today's professional digital speedpainters, or comparing the first pilots to today's hardcore professional gamers.",
              "score": 7,
              "created_utc": "2025-12-31 21:42:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwxh2wh",
          "author": "higgs8",
          "text": "Insane considering Qwen being 4 times slower than zimage turbo even with the lightning 4 step lora.",
          "score": 23,
          "created_utc": "2025-12-31 15:44:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwyh4ij",
              "author": "_VirtualCosmos_",
              "text": "you sure about that? ZiT takes 28 sec per 1024 image using 9 steps, while qwen takes exactly the same, 28 secs, with 4 steps and generating 1328 images, on my PC with a 4070ti and 64 GB of RAM.",
              "score": 1,
              "created_utc": "2025-12-31 18:43:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwylgah",
                  "author": "higgs8",
                  "text": "It's probably because I have to use the gguf version of qwen while I can use the full version of zit. I have 36 GB, which isn't enough for the full qwen model (40gb) but plenty for zit (21gb).",
                  "score": 2,
                  "created_utc": "2025-12-31 19:05:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwx8jrc",
          "author": "Accurate-Net-2534",
          "text": "Qwen is so unrealistic",
          "score": 67,
          "created_utc": "2025-12-31 15:00:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxe5u0",
              "author": "Wilbis",
              "text": "Looking at Qwen generated pictures immediately tell me \"that's AI for sure\"",
              "score": 59,
              "created_utc": "2025-12-31 15:29:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwy0t18",
              "author": "AiCocks",
              "text": "In my testing I you can get quite realistic results but you need CFG, both Turbo Loras are pretty bad especially if you use them at 1.0 strength. I get good results with: 12 steps, Euler+Beta57, Wuli Turbo Lora at 0.23, CFG 3 and the default negative prompts.",
              "score": 5,
              "created_utc": "2025-12-31 17:22:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwyv4qj",
                  "author": "nsfwVariant",
                  "text": "Can confirm the lightning loras are terrible. Consistently gives people plastic skin, which is the biggest giveaway.",
                  "score": 4,
                  "created_utc": "2025-12-31 19:56:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwymsmd",
                  "author": "skyrimer3d",
                  "text": "thanks for sharing this, i'll give it a try, my initials tests where underwhelming indeed.",
                  "score": 1,
                  "created_utc": "2025-12-31 19:12:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwy97jv",
              "author": "Confusion_Senior",
              "text": "Img2img with Z image afterwards",
              "score": 3,
              "created_utc": "2025-12-31 18:03:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwyl32n",
                  "author": "lickingmischief",
                  "text": "how do you apply z-image after and keep the image looking the same but more realistic?  suggested workflow?",
                  "score": 1,
                  "created_utc": "2025-12-31 19:03:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx1rpuz",
                  "author": "desktop4070",
                  "text": "I always see comments say to just apply img2img with ZIT to make other models look better, but I have never seen any img2img image look as good as a native txt2img image. Can you share any examples of img2img improving the quality of the image?",
                  "score": 1,
                  "created_utc": "2026-01-01 07:31:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx04iiz",
              "author": "jugalator",
              "text": "Yeah it's disappointing. Not much better off in terms of AI glaze over the whole thing than what we started 2025 with. A little surprising too given the strides they've been making. It's like they've hit a wall or something.",
              "score": 2,
              "created_utc": "2026-01-01 00:14:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwxcwix",
              "author": "UnHoleEy",
              "text": "Intentionally I guess. To prevent misuse just like Flux. Maybe?",
              "score": -19,
              "created_utc": "2025-12-31 15:23:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwxddvr",
                  "author": "the_bollo",
                  "text": "That doesn't make sense. If it was intentionally gimped then why would they continue to refine and improve realism?",
                  "score": 10,
                  "created_utc": "2025-12-31 15:26:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwxm1m6",
          "author": "Green-Ad-3964",
          "text": "**Is that Flux‚Äôs chin that I‚Äôm seeing in the Qwen images?**",
          "score": 27,
          "created_utc": "2025-12-31 16:09:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwy9v0v",
              "author": "beragis",
              "text": "Flux chin has been replicating.  I have even seen it pop up in a few Z-Image generations",
              "score": 6,
              "created_utc": "2025-12-31 18:06:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwzkmiv",
                  "author": "jib_reddit",
                  "text": "About 50% of Hollywood actors have that chin as well...",
                  "score": 6,
                  "created_utc": "2025-12-31 22:15:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwynvub",
              "author": "hurrdurrimanaccount",
              "text": "Yes, that and the oversaturation really kill this model. it's so bad, compared to base qwen image",
              "score": 5,
              "created_utc": "2025-12-31 19:17:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwxndwd",
          "author": "Caesar_Blanchard",
          "text": "Is it reaally, really necessary to have these very long prompts?",
          "score": 11,
          "created_utc": "2025-12-31 16:15:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxsgd4",
              "author": "Dezordan",
              "text": "No, it isn't. A lot in those prompts is BS that doesn't even matter.",
              "score": 11,
              "created_utc": "2025-12-31 16:40:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwxuf3d",
                  "author": "Caesar_Blanchard",
                  "text": "Yeah because it's sooooo long & detailed haha",
                  "score": 3,
                  "created_utc": "2025-12-31 16:50:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwylc7i",
              "author": "RebootBoys",
              "text": "No. The prompts are ass and this post does a horrible job at creating a meaningful comparison.",
              "score": 5,
              "created_utc": "2025-12-31 19:04:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwyjb6a",
          "author": "_VirtualCosmos_",
          "text": "I'm testing the new Qwen and idk about your workflow but mine results are much more realistic than yours. I'm using the recommended settings: CFG 4 and 50 steps.",
          "score": 12,
          "created_utc": "2025-12-31 18:54:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwyo1fg",
              "author": "Amazing_Painter_7692",
              "text": "Same, even without cfg my results look good.",
              "score": 6,
              "created_utc": "2025-12-31 19:18:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwz3oun",
              "author": "Justgotbannedlol",
              "text": "run these prompts then",
              "score": 4,
              "created_utc": "2025-12-31 20:42:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxcru5h",
              "author": "djdante",
              "text": "Not to mention scheduler andsampler selection makes a big difference too",
              "score": 1,
              "created_utc": "2026-01-03 00:49:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwxhvv8",
          "author": "ozzie123",
          "text": "Seems flux training data set poisoned Qwen Image more compared to ZIT. That double chin is always a giveaway",
          "score": 20,
          "created_utc": "2025-12-31 15:48:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwyh1a8",
              "author": "Far_Insurance4191",
              "text": "Z-Image paper says \"we trained a dedicated classifier to detect and filter out AI-generated content\". I guess the strength of Z-image-turbo is not just crazy RLHF, but literally not being trained on a trash",
              "score": 23,
              "created_utc": "2025-12-31 18:42:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwz9dgg",
                  "author": "Perfect-Campaign9551",
                  "text": "And then you get morons training loras on nano banana images. It's too tempting to be lazy and they can't resist",
                  "score": 12,
                  "created_utc": "2025-12-31 21:13:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx1w8ok",
                  "author": "ThexDream",
                  "text": "I find it rather ironic that AI models follow irl laws of nature. Inbreeding is not healthy.",
                  "score": 3,
                  "created_utc": "2026-01-01 08:19:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx1qsb9",
              "author": "red__dragon",
              "text": "> That double chin \n\nCleft chin. Double chins stack.",
              "score": 5,
              "created_utc": "2026-01-01 07:22:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwzus9",
          "author": "waltercool",
          "text": "Z-Image is still better in terms of realism but lacks diversity.\n\nQwen Image looks better for magazines or stock photos. Their main opponent is Flux probably.",
          "score": 56,
          "created_utc": "2025-12-31 14:11:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx0pafp",
              "author": "almark",
              "text": "that's what 1.5 gave us, still impressive imo",
              "score": 2,
              "created_utc": "2026-01-01 02:26:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwxkqu7",
              "author": "adhd_ceo",
              "text": "Diversity of faces is something you can address with LoRAs, I suppose.",
              "score": 2,
              "created_utc": "2025-12-31 16:02:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwybmz8",
                  "author": "brown_felt_hat",
                  "text": "I've found that if you name the people and give them a, I dunno, back story, it helps a ton. Jacques, a 23 year old marine biology student gives me a wildly different person than Reginald, a 23 year banker, without changing much about the image. Even just providing a name works pretty well.",
                  "score": 9,
                  "created_utc": "2025-12-31 18:15:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwxu6nf",
                  "author": "TheBestPractice",
                  "text": "But then you often lose some realism",
                  "score": 1,
                  "created_utc": "2025-12-31 16:49:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwxik1v",
          "author": "insmek",
          "text": "Z-Image has just ruined Qwen for me. I just vastly prefer the way that its images look. I was all-in on Qwen but haven‚Äôt hardly touched it in weeks.",
          "score": 12,
          "created_utc": "2025-12-31 15:51:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwx3mm4",
          "author": "tonyunreal",
          "text": "z-image: generic clayman with no mouth\n\nqwen: I give you sad Kevin Spacey",
          "score": 14,
          "created_utc": "2025-12-31 14:33:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwyve61",
          "author": "iChrist",
          "text": "Whenever I think of trying any other model, I just remember that it‚Äôs like 10x the time to generate one image compared to Z-image, and most times the difference is negligible.\n\nHard to beat that kind of performance",
          "score": 5,
          "created_utc": "2025-12-31 19:57:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwyqql1",
          "author": "000TSC000",
          "text": "Unfair comparison. Z-Turbo is sort of like a Z-Image realism finetune, while Qwen is a raw base model. Qwen with LoRAs actually can match the realism quite well.",
          "score": 11,
          "created_utc": "2025-12-31 19:32:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx002zo",
              "author": "Apprehensive_Sky892",
              "text": "Finally, someone who understand what Qwen is for.\n\nPeople kept complaining about this, but a \"plain looking\" base makes training easier, as documented by the Flux-Krea people: [https://www.reddit.com/r/StableDiffusion/comments/1p70786/comment/nqy8sgr/](https://www.reddit.com/r/StableDiffusion/comments/1p70786/comment/nqy8sgr/)",
              "score": 3,
              "created_utc": "2025-12-31 23:47:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwzzlez",
          "author": "Shaminy",
          "text": "Hands down win for Z-Image.",
          "score": 9,
          "created_utc": "2025-12-31 23:44:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxg977",
          "author": "acid-burn2k3",
          "text": "Is there any image 2 image workflow with z edit ?",
          "score": 4,
          "created_utc": "2025-12-31 15:40:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwyd7b8",
              "author": "diffusion_throwaway",
              "text": "There's a z-edit model?",
              "score": 2,
              "created_utc": "2025-12-31 18:23:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwyzwj1",
                  "author": "Life_Death_and_Taxes",
                  "text": "it has been announced , but it hasn't been released yet",
                  "score": 1,
                  "created_utc": "2025-12-31 20:21:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwzu47r",
          "author": "SackManFamilyFriend",
          "text": "Been using Qwen 2512 and I def prefer it over Z-Image Turbo. It's a badass model. You need to dial it in to your liking, but these results here seemed cherry picked.",
          "score": 4,
          "created_utc": "2025-12-31 23:11:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwx39wl",
          "author": "stellakorn",
          "text": "skin fix lora + amateur photography lora fixes realism issue",
          "score": 8,
          "created_utc": "2025-12-31 14:31:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwze1gw",
          "author": "blastcat4",
          "text": "Man, I'm so thankful for Z-Image Turbo.",
          "score": 3,
          "created_utc": "2025-12-31 21:38:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx0s8li",
          "author": "RowIndependent3142",
          "text": "Qwen wins this hands down. Seems like the prompts are a bit much tho. You shouldn‚Äôt have to write that much to generate the images you want. I think a better test would be some text prompts written by a person rather than AI.",
          "score": 3,
          "created_utc": "2026-01-01 02:46:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxem4m",
          "author": "the_bollo",
          "text": "Damn, no one can touch Z-Image. If their edit model is as good as ZIT then Qwen Image is a goner.",
          "score": 7,
          "created_utc": "2025-12-31 15:32:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxjxom",
              "author": "jazzamp",
              "text": "A \"gooner\" for sure üòè",
              "score": 4,
              "created_utc": "2025-12-31 15:58:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwy62az",
          "author": "Nextil",
          "text": "Another post comparing nothing but portraits with excessive redundant detail in the prompts. Yes, Z-Image definitely still looks better out of the box, but style can easily be changed with LoRAs. You could probably just generate a bunch of promptless images from Z-Image and train them uncaptioned on Qwen and get the same look.\n\nIt's the prompt adherence that cannot easily be changed, and that's where these models vary significantly. Any description involving positions, relations, actions, intersections, numbers, scales, rotations, etc., generally, the larger the model, the better they adhere. Qwen and FLUX.2 tend to be miles ahead in those regards.",
          "score": 7,
          "created_utc": "2025-12-31 17:48:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwx384g",
          "author": "Ok-Meat4595",
          "text": "Zit win",
          "score": 15,
          "created_utc": "2025-12-31 14:31:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwx75d1",
              "author": "optimisticalish",
              "text": "Z-Image totally nails the look of the early/mid 1960s, but the Qwen seems more of an awkward balance between the early 1960s and the late 1960s. Even straying into the 1970s with the glasses. Might have been a better contest if the prompt had specified the year.",
              "score": -2,
              "created_utc": "2025-12-31 14:53:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwxaml1",
                  "author": "SpaceNinjaDino",
                  "text": "None of that matters if Qwen output only has SDXL quality. Meaning it has that soft AI slop look. ZIT has crisp details that look realistic. That said, I haven't been able to control ZIT to my satisfaction and went back to WAN.",
                  "score": 8,
                  "created_utc": "2025-12-31 15:11:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwy5k8e",
          "author": "hurrdurrimanaccount",
          "text": "so with \"more realistic\" they mean they added even more hdr slop to qwen? oof.",
          "score": 3,
          "created_utc": "2025-12-31 17:46:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxtv8h",
          "author": "primeye55",
          "text": "z-image works in all aspects",
          "score": 2,
          "created_utc": "2025-12-31 16:47:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxu2fd",
          "author": "Odd-Mirror-2412",
          "text": "Curious about the variety and expressiveness, more than the realism.",
          "score": 2,
          "created_utc": "2025-12-31 16:48:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwy40hc",
          "author": "zedatkinszed",
          "text": "Its the reinforced learning that zit has that makes it such a beast.\n\n\nA 6b turbo has no business being this good!",
          "score": 2,
          "created_utc": "2025-12-31 17:38:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwyakt6",
          "author": "CyberMiaw",
          "text": "No fair comparison considering Z-image is TURBO with only few steps.",
          "score": 2,
          "created_utc": "2025-12-31 18:10:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwydsw4",
          "author": "krigeta1",
          "text": "This post makes me more curious for the Z image base.",
          "score": 2,
          "created_utc": "2025-12-31 18:26:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwyo1x0",
          "author": "ImpossibleAd436",
          "text": "Z-Image just hits different. \n\nI don't know how this stuff works exactly, but I hope there is a degree of openess with the model training and structure, because I'd love to think that other model creators can learn something from Z-Image, for me it's the standard that leads the way, it's simply better than bigger more resource intensive models. That's the treasure at the end of the rainbow, it's the alchemical gold, I hope others are studying how they achieved what they have with it.",
          "score": 2,
          "created_utc": "2025-12-31 19:18:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwz27bh",
          "author": "__Maximum__",
          "text": "Qwen still has that AI look, while Z can fool you easily",
          "score": 2,
          "created_utc": "2025-12-31 20:34:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwzgzo9",
          "author": "singfx",
          "text": "Gonna be hard to top Z-image",
          "score": 2,
          "created_utc": "2025-12-31 21:55:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwzhjm6",
          "author": "No_Statistician2443",
          "text": "Did you guys tested the Flux 2 Dev Turbo? It is as fast (and as cheap) as Z-Image Turbo and the prompt following is better imo.",
          "score": 2,
          "created_utc": "2025-12-31 21:58:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx00zz7",
          "author": "DELOUSE_MY_AGENT_DDY",
          "text": "They gotta drop Qwen and go all in with ZIT",
          "score": 2,
          "created_utc": "2025-12-31 23:52:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1fyzw",
              "author": "Different_Fix_2217",
              "text": "It's two different competing groups under alibaba.",
              "score": 1,
              "created_utc": "2026-01-01 05:42:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx17xb3",
          "author": "HaohmaruHL",
          "text": "Qwen always looked like a model at least one generation behind. And that's IF you use realistic loras to fix it. And if you use the vanilla Qwen through the official app its even worse and loses even to some SDXL variants in my opinion. \n\nZ image Turbo is in another league and is great as is out of the box.",
          "score": 2,
          "created_utc": "2026-01-01 04:35:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxj5or",
          "author": "Scorp1onF1",
          "text": "Qwen is very poor at understanding style. I tried many styles, but none of them were rendered correctly. Photorealism isn't great either ‚Äî the skin and hair look too plastic. Overall, ZIT is better in every way.",
          "score": 4,
          "created_utc": "2025-12-31 15:54:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwyjl55",
              "author": "tom-dixon",
              "text": "Eh, it's not a competition. I use them all for their strengths. Qwen for prompt adherence. ZIT to add details or to do quick prototyping. I use WAN to fix anatomy. I use SD1.5 and SDXL for detailing realistic images, or artistic style transfer stuff. I use flux for the million amazing community loras.\n\n\nI'm thankful we got spoiled with all these gifts.",
              "score": 3,
              "created_utc": "2025-12-31 18:55:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx0789s",
                  "author": "Scorp1onF1",
                  "text": "Your approach is absolutely correct. I do the same. But you know, I want to have a ring to rule them allüòÖ",
                  "score": 1,
                  "created_utc": "2026-01-01 00:30:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwzlamk",
              "author": "ZootAllures9111",
              "text": "This is patently false lmao, Qwen trains beautifully on basically anything (and is extremely difficult to overtrain). It also has much better prompt adherence than Z overall.",
              "score": 2,
              "created_utc": "2025-12-31 22:19:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx06r3d",
                  "author": "Scorp1onF1",
                  "text": "I'm not a fan of ZIT, nor am I a hater of Qwen. It's just that I don't work with photorealistic images, and it's important to me that the model understands art styles. ¬†And personally, in my tests, ZIT shows much better results. I still use Flux and SDXL in conjunction with IP Adapter. Maybe I'm configuring Qwen incorrectly or using the wrong prompt, but personally,¬†I find the model rather disappointing for anything that isn't photorealistic.",
                  "score": 1,
                  "created_utc": "2026-01-01 00:28:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwx08c8",
          "author": "Time-Teaching1926",
          "text": "I hope it addresses the issue of not making the same image over and over again, even when you keep the prompt the same or change it up slightly.",
          "score": 5,
          "created_utc": "2025-12-31 14:14:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxaah3",
              "author": "FinBenton",
              "text": "Yeah Qwen makes a different variation every time, ZIT just spams the same image on repeat.",
              "score": 4,
              "created_utc": "2025-12-31 15:10:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwxdc6k",
                  "author": "UnHoleEy",
                  "text": "Ya. The Turbo model acts the same as the old SDXL few step models did. Different seeds, similar outputs. Maybe once the base model is out, it'll be better at variations.",
                  "score": 2,
                  "created_utc": "2025-12-31 15:25:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwygo0k",
              "author": "flasticpeet",
              "text": "You do a 2-pass workflow, where the first few steps you feed it a zero positive conditioning to the first k-sampler, then pass the remainder to the second k-sampler with the positive prompt.\n\nYou can play a little bit with the split step values to get even more variations.",
              "score": 2,
              "created_utc": "2025-12-31 18:41:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwx23bk",
              "author": "Nexustar",
              "text": "It's not an issue when the model is doing what you ask. If you want a different image give it a different prompt.",
              "score": -2,
              "created_utc": "2025-12-31 14:24:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwx687s",
                  "author": "AltruisticList6000",
                  "text": "That's ridiculous. For example, prompting a woman with long brown hair and green eyes could and should result in an almost infinite amount of face variations and hairstyles and small variance in length like on most other models. Instead ZIT will keep doing the same thing over and over. You must be delusional if you expect everyone to start spending extra time changing the prompt after every gen like \"semi-green eyes with long hair but that is actually behind her shoulder\" then switch it to \"long hair that is actually reaching the level of her hip\" or some other nonsense thing lmao. And even then there is a limit of expressing it with words and you will get like 3-4 variations out of it at best, and usually despite changing half the prompt and descriptions, ZIT will still give you 80-100% similar face/person. Luckily the seed variance ZIT node improves this, but don't pretend this is a good or normal thing.",
                  "score": 14,
                  "created_utc": "2025-12-31 14:48:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwx5xs7",
                  "author": "Hoodfu",
                  "text": "yeah, when the prompt following reaches a certain point, there isn't going to be much difference, but flux 2 dev manages to give a significantly different shot per seed even though its prompt following is still the top currently.",
                  "score": 5,
                  "created_utc": "2025-12-31 14:46:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwy5dv6",
                  "author": "wunderbaba",
                  "text": "This is a bad take. You'll NEVER be able to completely describe all the details on a picture. (how many buttons on her jacket, should the buttons be mother-of-pearl or brass, should they be on the right-side or left-side) - **AND EVEN IF YOU COULD SOMEHOW SPECIFY EVERY F###KIN DETAIL** you'd blow past the token limits of the model.\n\n*Diversity of outputs is crucial to a good model.*",
                  "score": 3,
                  "created_utc": "2025-12-31 17:45:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwyhyjl",
              "author": "Far_Insurance4191",
              "text": "It must be due to last two stages in the turbo branch. Base should be diverse but lower quality\n\nhttps://preview.redd.it/51li1we05lag1.png?width=847&format=png&auto=webp&s=1cb01d16405a1cadc05f2daafa5c2c809a22fcf1",
              "score": 1,
              "created_utc": "2025-12-31 18:47:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwxt07z",
          "author": "tcdoey",
          "text": "Why is Z-image-T so much better?",
          "score": 2,
          "created_utc": "2025-12-31 16:43:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwx8wfl",
          "author": "no-comment-no-post",
          "text": "Would you be willing to share your Qwen 2512 workflow?",
          "score": 1,
          "created_utc": "2025-12-31 15:02:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxty2z",
          "author": "primeye55",
          "text": "Where I can actually use Z-Image ?",
          "score": 1,
          "created_utc": "2025-12-31 16:48:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwy10ld",
          "author": "scrotanimus",
          "text": "They are looking good, but ZIT wins, hands/down, due to speed and accessibility to lower GPUs.",
          "score": 1,
          "created_utc": "2025-12-31 17:23:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwy48io",
          "author": "AiCocks",
          "text": "In my testing I you can get quite realistic results but you need CFG, both Turbo Loras produce Flux like Slop especially if you use them at 1.0 strength. I get good results with: 12 steps, Euler+Beta57, Wuli Turbo Lora at 0.23, CFG 2-3 , denoise \\~0.93, and the default negative prompts. Images are quite allot sharper compared to Z-Image",
          "score": 1,
          "created_utc": "2025-12-31 17:39:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwyi0ky",
          "author": "orangeflyingmonkey_",
          "text": "Could you please share the workflow for qwen 2515?",
          "score": 1,
          "created_utc": "2025-12-31 18:47:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwymx0r",
          "author": "Amazing_Painter_7692",
          "text": "https://preview.redd.it/a9zi97an9lag1.jpeg?width=3072&format=pjpg&auto=webp&s=61988531822eb38f6a647a06e66d4a16f3b4cff0\n\nqwen on right is 50 steps, cfg=1. not sure how i'm getting so much different results. the plastic look is basically gone for me and i'm not even using cfg, same prompt.",
          "score": 1,
          "created_utc": "2025-12-31 19:12:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwyoh28",
              "author": "film_man_84",
              "text": "I have 4 step lightning workflow in testing now and all what I get is plastic. Maybe 50 steps, but then it is soooo slow on my machine (RTX 4060 Ti 16 GB VRAM + 32 GB RAM) that it is not worth for my usage, at least at this point.",
              "score": 1,
              "created_utc": "2025-12-31 19:20:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwyqsq6",
                  "author": "Amazing_Painter_7692",
                  "text": "Even the new one? https://huggingface.co/lightx2v/Qwen-Image-2512-Lightning",
                  "score": 1,
                  "created_utc": "2025-12-31 19:33:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwywyj2",
          "author": "Secure_Employment456",
          "text": "Did the same tests. ZIT looks way more real. 2512 is still giving plastic and takes 10x longer to run.",
          "score": 1,
          "created_utc": "2025-12-31 20:05:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwz4s2m",
          "author": "NetimLabs",
          "text": "Qwen looks like ChatGPT.\nWe need Z-image Edit asap.",
          "score": 1,
          "created_utc": "2025-12-31 20:48:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1766n",
              "author": "sammoga123",
              "text": "Yo tambi√©n lo quiero, parece que ser√° mejor que el Qwen edit actual",
              "score": 1,
              "created_utc": "2026-01-01 04:30:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwz8g5j",
          "author": "persona64",
          "text": "That first comparison is insane with the soft hairs on the cheeks",
          "score": 1,
          "created_utc": "2025-12-31 21:08:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwzw9aa",
          "author": "nikgrid",
          "text": "Qwen is great but usually makes heads WAY to big.",
          "score": 1,
          "created_utc": "2025-12-31 23:24:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwzwk5d",
          "author": "irve",
          "text": "To me the magic bit is that it does not do the same uncanny thing in which you can read the image from across the room.\n\nIt has all the different issues, but the most uncanny factor of the diffusion models somehow manifests rarely.¬†",
          "score": 1,
          "created_utc": "2025-12-31 23:26:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx0mrfk",
          "author": "Extreme_Feedback_606",
          "text": "is it possible to run z image turbo locally? which is the best interface, comfy? what minimum setup is needed to run smoothly?",
          "score": 1,
          "created_utc": "2026-01-01 02:09:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx3ij9w",
              "author": "w8cycle",
              "text": "Yes, you can run it locally using comfy.",
              "score": 2,
              "created_utc": "2026-01-01 16:17:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx0powt",
          "author": "Paraleluniverse200",
          "text": "Hmm Idk, i still like how real zimage looks,",
          "score": 1,
          "created_utc": "2026-01-01 02:29:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx17isw",
          "author": "6ft1in",
          "text": "ZIT is freakingly good with its size.",
          "score": 1,
          "created_utc": "2026-01-01 04:32:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1w9rv",
          "author": "xufo",
          "text": "Z Image by far",
          "score": 1,
          "created_utc": "2026-01-01 08:19:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx27qlo",
          "author": "Vektast",
          "text": "Qwen is more slopy",
          "score": 1,
          "created_utc": "2026-01-01 10:22:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx2kpzm",
          "author": "Head-Leopard9090",
          "text": "Very disappointed on qwen image they keep releasing models with fake ass samples and the results were terrible asf",
          "score": 1,
          "created_utc": "2026-01-01 12:33:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx3prkg",
          "author": "Low_Measurement7946",
          "text": "Ë∞¢Ë∞¢„ÄÇ",
          "score": 1,
          "created_utc": "2026-01-01 16:55:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx5s6es",
          "author": "isnaiter",
          "text": "z-image is the new sdxl",
          "score": 1,
          "created_utc": "2026-01-01 23:18:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxcqaj6",
          "author": "djdante",
          "text": "What sampler and scheduler are you using? I find qwen gives surprisingly good skin with the right ones, and very plastic results with say, euler.... Er-sde and beta57 make things very real...\n\nI'm not seeing anyone talk about this in their comparisons with zit",
          "score": 1,
          "created_utc": "2026-01-03 00:40:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxgt15q",
          "author": "SuicidalFatty",
          "text": "with qwen image i can tell its AI without looking at again but with z image its hard to tell if its AI or not",
          "score": 1,
          "created_utc": "2026-01-03 17:00:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxsn3ra",
          "author": "SkillMinute4244",
          "text": "Z image is pure magicc",
          "score": 1,
          "created_utc": "2026-01-05 10:28:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwyvq0l",
          "author": "TekeshiX",
          "text": "Qwen Image = hot garbage. They better focus on the editing models, cuz for image generation models they're trash as heck, same as hunyuan 3.0.",
          "score": 1,
          "created_utc": "2025-12-31 19:59:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwz34g3",
          "author": "theOliviaRossi",
          "text": "qwen sux, z = rocks ;)",
          "score": 1,
          "created_utc": "2025-12-31 20:39:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwx780p",
          "author": "janosibaja",
          "text": "I'm interested in both workflows. Please share.",
          "score": -1,
          "created_utc": "2025-12-31 14:53:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwzv1yj",
          "author": "meikerandrew",
          "text": "Z image better realism, Image 2512 better cartoon and styles.",
          "score": 0,
          "created_utc": "2025-12-31 23:16:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx0kbcm",
          "author": "The1870project",
          "text": "Who is this person?",
          "score": 0,
          "created_utc": "2026-01-01 01:53:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwx06vh",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -9,
          "created_utc": "2025-12-31 14:13:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwx2fnn",
              "author": "DarkStrider99",
              "text": "Default text encoders can do this.",
              "score": 5,
              "created_utc": "2025-12-31 14:26:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwx5vws",
              "author": "n0gr1ef",
              "text": "These models do not use CLIPs thankfully. They use full-on LLM's as text encoders, that's where the prompt adherence comes from.",
              "score": 2,
              "created_utc": "2025-12-31 14:46:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q5o0o0",
      "title": "My first LTX V2 test-montage of 60-70 cinematic clips",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/r051ajdqerbg1",
      "author": "hellolaco",
      "created_utc": "2026-01-06 16:55:42",
      "score": 520,
      "num_comments": 147,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Animation - Video",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q5o0o0/my_first_ltx_v2_testmontage_of_6070_cinematic/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny1c50g",
          "author": "nikhilprasanth",
          "text": "The motion is really good. Camera motion and all.",
          "score": 43,
          "created_utc": "2026-01-06 17:02:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1d5ej",
              "author": "hellolaco",
              "text": "yeah, surprisingly good! I could also post some bad examples :D",
              "score": 23,
              "created_utc": "2026-01-06 17:06:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny1f67n",
                  "author": "FinalCap2680",
                  "text": "Would be interesting to see some bad/good examples with the same prompt. What is the ratio of bad/good, do you need to try many times and adjust prompt to get the desired result?",
                  "score": 10,
                  "created_utc": "2026-01-06 17:16:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1c0k1",
          "author": "protector111",
          "text": "Need more! more hype more!!!",
          "score": 23,
          "created_utc": "2026-01-06 17:01:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1d653",
              "author": "hellolaco",
              "text": "will do more!",
              "score": 16,
              "created_utc": "2026-01-06 17:06:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny1kam8",
                  "author": "Hunting-Succcubus",
                  "text": "Keep doing it till wan 3 is released.",
                  "score": 4,
                  "created_utc": "2026-01-06 17:39:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1ejh6",
          "author": "Orange_33",
          "text": "jeez louis, the models just getting better and better",
          "score": 13,
          "created_utc": "2026-01-06 17:13:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4cd20",
              "author": "fredandlunchbox",
              "text": "This is the worst the will ever be.",
              "score": 6,
              "created_utc": "2026-01-07 01:38:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny50yik",
                  "author": "Neighborhood-Brief",
                  "text": "Wasn't it more worst six months ago though?",
                  "score": 1,
                  "created_utc": "2026-01-07 03:54:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1c7na",
          "author": "VirusCharacter",
          "text": "That's not FP4 or Fp8 right!? üëç",
          "score": 10,
          "created_utc": "2026-01-06 17:02:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1d059",
              "author": "hellolaco",
              "text": "nope, full",
              "score": 17,
              "created_utc": "2026-01-06 17:06:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny1f00y",
                  "author": "kabachuha",
                  "text": "Full as the local 40gb checkpoint or full as on their site? (Hopefully, the former)",
                  "score": 4,
                  "created_utc": "2026-01-06 17:15:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1cgyy",
          "author": "Upper-Reflection7997",
          "text": "These were all text2image or a mix of both t2v and i2v? Very impressive regardless. Waiting for wan2gp to update support for ltx2.",
          "score": 9,
          "created_utc": "2026-01-06 17:03:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1d2ws",
              "author": "[deleted]",
              "text": "[removed]",
              "score": 18,
              "created_utc": "2026-01-06 17:06:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1foex",
                  "author": "FourtyMichaelMichael",
                  "text": "OK. That's pretty impressive. I was going to ask I2V or T2V, and just assumed I2V. \n\nIf NSFW can be added in, LTX2 might actually stay around for a minute.",
                  "score": 5,
                  "created_utc": "2026-01-06 17:18:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1ji4v",
          "author": "MiyagiJunior",
          "text": "Just beautiful!",
          "score": 4,
          "created_utc": "2026-01-06 17:35:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3od33",
          "author": "terrariyum",
          "text": "https://preview.redd.it/f96uvfyedtbg1.png?width=598&format=png&auto=webp&s=0963048b14c8b87fba3cb1c15d532b16825addb0\n\nJust sayin...",
          "score": 4,
          "created_utc": "2026-01-06 23:32:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3tkka",
              "author": "hellolaco",
              "text": "You mean the chin?",
              "score": 2,
              "created_utc": "2026-01-06 23:59:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny3wq9p",
                  "author": "terrariyum",
                  "text": "In every example:\n\n* cheekbones are high\n* nostrils are flared\n* philtrum is deep\n* lips are full\n* upper lip juts forward with pronounced cupids-bow\n* lower lip has center indentation\n* nasolabial folds are deep\n* mouth corners are deep\n* chin juts forward and has slight dimple\n* jaw has slight jowel",
                  "score": 7,
                  "created_utc": "2026-01-07 00:15:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1gb1b",
          "author": "theNivda",
          "text": "Really good!",
          "score": 3,
          "created_utc": "2026-01-06 17:21:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1j2vt",
          "author": "uxl",
          "text": "Workflow/ComfyUI manager won‚Äôt install the required nodes for me. Anyone else run into problems with that?",
          "score": 3,
          "created_utc": "2026-01-06 17:33:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny25z46",
              "author": "GasolinePizza",
              "text": "Update comfy to the latest (not latest stable) version",
              "score": 3,
              "created_utc": "2026-01-06 19:16:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2ywi9",
              "author": "Other-Policy-7530",
              "text": "If you had the LTXvideo pack before, I had to delete the existing version from my custom_nodes folder and reinstall before it worked.",
              "score": 4,
              "created_utc": "2026-01-06 21:29:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny4b17f",
                  "author": "holygawdinheaven",
                  "text": "Yeah I had to delete the old ltxtricks repo",
                  "score": 2,
                  "created_utc": "2026-01-07 01:31:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny24nm3",
              "author": "Naomi-ken-korem",
              "text": "you basically need to add this repo:  \n[https://github.com/Lightricks/ComfyUI-LTXVideo](https://github.com/Lightricks/ComfyUI-LTXVideo)",
              "score": 4,
              "created_utc": "2026-01-06 19:10:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny421qf",
          "author": "Ok-Flatworm5070",
          "text": "What's the song called?",
          "score": 3,
          "created_utc": "2026-01-07 00:43:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1kbvz",
          "author": "bguberfain",
          "text": "Did you write 60 different prompts? Or is there a ‚Äúseed prompt‚Äù that generate all?",
          "score": 2,
          "created_utc": "2026-01-06 17:39:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1mt2l",
              "author": "hellolaco",
              "text": "Yes different, from my old veo2 prompts",
              "score": 8,
              "created_utc": "2026-01-06 17:50:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny259tj",
                  "author": "Draufgaenger",
                  "text": "How did you come up with them?",
                  "score": 2,
                  "created_utc": "2026-01-06 19:13:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1qjjl",
          "author": "_VirtualCosmos_",
          "text": "Wait, is that a Blender reference? :O",
          "score": 2,
          "created_utc": "2026-01-06 18:07:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1r35j",
          "author": "Perfect-Campaign9551",
          "text": "\"cinematic\" = slow motion for some reason?",
          "score": 2,
          "created_utc": "2026-01-06 18:09:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2bgl2",
              "author": "Nexustar",
              "text": "No, cinematic as in it visually and immersively evokes emotion through colors, lighting, subject matter and motion.\n\nOne small part of that might be slow motion, but that's not a requirement or the only way to do it, and this sequence contains more than that.",
              "score": 3,
              "created_utc": "2026-01-06 19:41:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny3t107",
              "author": "hellolaco",
              "text": "Slow motion is not intentional in these clips. I treat them as ‚Äúfaults‚Äù as it would be nicer to have real time movements",
              "score": 2,
              "created_utc": "2026-01-06 23:56:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny1t1pl",
          "author": "Its-all-redditive",
          "text": "Can you share the prompts?",
          "score": 2,
          "created_utc": "2026-01-06 18:18:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1zm8t",
          "author": "skyrimer3d",
          "text": "Wow, this could really be the Wan successor with the proper community support.",
          "score": 2,
          "created_utc": "2026-01-06 18:47:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny833iv",
              "author": "juandann",
              "text": "i really hope so",
              "score": 1,
              "created_utc": "2026-01-07 16:30:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2gb0d",
          "author": "ArkCoon",
          "text": "Looking forward to the first LoRAs. Looks promising ngl",
          "score": 2,
          "created_utc": "2026-01-06 20:03:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2h7mp",
          "author": "OddResearcher1081",
          "text": "Can you share more about your process?  How long did it take to generate each clip? LTXV 2 has only been out for about 20 hours and you‚Äôve already processed over 60 clips successfully. Most of us are still trying to get a handle on this. I have been testing on a 3090 so I don‚Äôt expect speed, as each is taking 5 minutes. If I change the prompt, ComfyUi crashes.",
          "score": 2,
          "created_utc": "2026-01-06 20:07:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3tcwu",
              "author": "hellolaco",
              "text": "A 5 second clip in 1080p took me 2 mins to render on the RtX6000pro. Prompts were already in my ‚Äúlibary‚Äù so that was a time saver",
              "score": 6,
              "created_utc": "2026-01-06 23:58:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2i1eu",
          "author": "Ikarus_",
          "text": "Really really nice bro. Can tell you have a great cinematic eye. Mind sharing your workflow?",
          "score": 2,
          "created_utc": "2026-01-06 20:11:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2j87r",
          "author": "nntb",
          "text": "Can it only do short clips?",
          "score": 2,
          "created_utc": "2026-01-06 20:17:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3tfwd",
              "author": "hellolaco",
              "text": "I think up to 20s",
              "score": 3,
              "created_utc": "2026-01-06 23:58:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny6cnlg",
          "author": "FxManiac01",
          "text": "very good results.. so what resolution can you go upto with your RTX 6000 pro? and what is the time of generatoin?",
          "score": 2,
          "created_utc": "2026-01-07 10:19:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny6s104",
              "author": "hellolaco",
              "text": "an 5s 1080p clip takes 2 mins. No idea about the resolution limit yet",
              "score": 2,
              "created_utc": "2026-01-07 12:22:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nya8fcx",
                  "author": "FxManiac01",
                  "text": "yeah, 6000 pro is crazy fast here.. was playing today with 720p and it is 20 seconds for 4 sec clip, crazy",
                  "score": 2,
                  "created_utc": "2026-01-07 22:08:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny432tk",
          "author": "Green-Ad-3964",
          "text": "congratulations, this is one of the best AI videos I've ever seen. only so-so part is the armwrestling one. Did you use i2v or t2v?",
          "score": 3,
          "created_utc": "2026-01-07 00:48:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny463wx",
              "author": "hellolaco",
              "text": "this was only t2v, will try i2v!",
              "score": 2,
              "created_utc": "2026-01-07 01:04:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny1qtde",
          "author": "Silonom3724",
          "text": "Let's be honest. This is standard T2V in 2025/6.  \n\nA models capability is tested by it's ability to create coherent videos past 5 seconds.",
          "score": 4,
          "created_utc": "2026-01-06 18:08:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1wtfi",
              "author": "psilent",
              "text": "The standout advancement of this is sound integrated on a locally runnable model, with something near consumer hardware. This doesn‚Äôt show that part at all, but I get just pumping out as many samples as you can to test it out this early",
              "score": 7,
              "created_utc": "2026-01-06 18:35:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny20f40",
                  "author": "Silonom3724",
                  "text": "My point exactly. One whimsical muppets show video with audio tells you more than 60 5 seconds snippets.",
                  "score": 2,
                  "created_utc": "2026-01-06 18:51:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1h3pr",
          "author": "TheTimster666",
          "text": "Looks great. It seems to handle darkness / shadows much better than Wan2.2.",
          "score": 2,
          "created_utc": "2026-01-06 17:24:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1cudu",
          "author": "Secure-Message-8378",
          "text": "Is Wan2.2 obsolete?",
          "score": 2,
          "created_utc": "2026-01-06 17:05:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1ef5g",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 3,
              "created_utc": "2026-01-06 17:12:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1fam6",
                  "author": "kabachuha",
                  "text": "You can do offload. There are literally around three posts on this sub how to run it at 24 or 8 gb VRAM",
                  "score": 8,
                  "created_utc": "2026-01-06 17:16:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny1gb7a",
                  "author": "tubbymeatball",
                  "text": "You could really say the same about Wan 2.2. But as usual, the community will make it work.",
                  "score": 2,
                  "created_utc": "2026-01-06 17:21:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny1hv3z",
                  "author": "yoavhacohen",
                  "text": "People already run ltx2 on 4060 with 8GB VRAM \n\nhttps://www.reddit.com/r/StableDiffusion/comments/1q5k6yb/ltx_2_4060_8gb_fp4_32gb_ram_4_minutes_for_2_sec/",
                  "score": 2,
                  "created_utc": "2026-01-06 17:28:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny1klce",
                  "author": "Hunting-Succcubus",
                  "text": "Wasn‚Äôt ltx supposed to be lighter on hardware?",
                  "score": 1,
                  "created_utc": "2026-01-06 17:40:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1y7k6",
          "author": "DanteTrd",
          "text": "Good model aside, you're a master prompter, my good sir. I'm struggling with creativity at the moment and can really appreciate your imagination.",
          "score": 1,
          "created_utc": "2026-01-06 18:41:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2il77",
          "author": "No_Mixture_7383",
          "text": "Prompts please",
          "score": 1,
          "created_utc": "2026-01-06 20:14:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2l8ip",
          "author": "No_Mixture_7383",
          "text": "mmm ya vi que ese no es en LOCAL, ese es el de paga, obvio facil porque lo hacen con H100 Online, pense que era el local pero NO NO ES gentes eso no es ComfyUI",
          "score": 1,
          "created_utc": "2026-01-06 20:26:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2nqz6",
          "author": "VirusCharacter",
          "text": "What GPU and RAM?",
          "score": 1,
          "created_utc": "2026-01-06 20:38:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3th5m",
              "author": "hellolaco",
              "text": "Rtx6000pro + 256GB",
              "score": 2,
              "created_utc": "2026-01-06 23:58:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny3wkiq",
                  "author": "VirusCharacter",
                  "text": "![gif](giphy|HUlXdfpPLF1pPlUnOA)",
                  "score": 4,
                  "created_utc": "2026-01-07 00:14:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny6ko7d",
                  "author": "Vektast",
                  "text": "azkomgec :D",
                  "score": 1,
                  "created_utc": "2026-01-07 11:28:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny2nwzg",
          "author": "softwareweaver",
          "text": "Can it do consistent characters? if so, what prompts or techniques to use?",
          "score": 1,
          "created_utc": "2026-01-06 20:39:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3w13h",
          "author": "kaelvinlau",
          "text": "This is really impressive. Good work!",
          "score": 1,
          "created_utc": "2026-01-07 00:12:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3yn4a",
          "author": "skyrimer3d",
          "text": "the music is also from LTX V2? because it's sounds really great.",
          "score": 1,
          "created_utc": "2026-01-07 00:25:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny461z7",
              "author": "hellolaco",
              "text": "no-no, it's stock music",
              "score": 3,
              "created_utc": "2026-01-07 01:04:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny8k690",
                  "author": "Deepesh42896",
                  "text": "What's the name? It's so nice.",
                  "score": 1,
                  "created_utc": "2026-01-07 17:47:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny4c56b",
          "author": "elswamp",
          "text": "Did you do any post processing? How did you get the lighting.can you share a sample prompt",
          "score": 1,
          "created_utc": "2026-01-07 01:37:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4c8k8",
              "author": "hellolaco",
              "text": "No",
              "score": 2,
              "created_utc": "2026-01-07 01:37:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny5ok2y",
          "author": "Helpful-Birthday-388",
          "text": "Goodbye Hollywood!",
          "score": 1,
          "created_utc": "2026-01-07 06:40:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6av0g",
          "author": "Kiw4mi",
          "text": "It's incredible!",
          "score": 1,
          "created_utc": "2026-01-07 10:02:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nye1w9h",
          "author": "Kekseking",
          "text": "In the first few seconds I thought that it was a perfume ad",
          "score": 1,
          "created_utc": "2026-01-08 12:55:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyhmbya",
          "author": "alohamoha",
          "text": "Dayum",
          "score": 1,
          "created_utc": "2026-01-08 22:44:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyjzttk",
          "author": "Grunderson",
          "text": "Was the song AI too?",
          "score": 1,
          "created_utc": "2026-01-09 07:00:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyugcr2",
          "author": "elswamp",
          "text": "Can you share more details or the actually workflow you used? What size gens?",
          "score": 1,
          "created_utc": "2026-01-10 20:17:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1ir9e",
          "author": "Compunerd3",
          "text": "Brilliant showcase, thanks for sharing. All we need now is an audio diffusion model at the same standard of quality as we have for motion and image.",
          "score": 1,
          "created_utc": "2026-01-06 17:32:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny58e5m",
              "author": "ANR2ME",
              "text": "There are already so many open source TTS models released isn't ü§î",
              "score": 1,
              "created_utc": "2026-01-07 04:41:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny1uqmo",
          "author": "James_Reeb",
          "text": "No continuity with caracters :( no I2v or Loras ?",
          "score": 1,
          "created_utc": "2026-01-06 18:25:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny28h0s",
              "author": "TheTimster666",
              "text": "There is I2V. And this is first day, people need time to train Loras.",
              "score": 4,
              "created_utc": "2026-01-06 19:27:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny595s9",
              "author": "ANR2ME",
              "text": "It have at least one lora, which is distilled 8-step lora üòÇ nobody creates lora on the first day a model being released anyway, regardless what model that is.\n\nLTX-2 can do multi-keyframes too, but not sure whether there is workflow example for this yetü§î https://github.com/Lightricks/LTX-2/blob/main/packages/ltx-pipelines/README.md#5-keyframeinterpolationpipeline\n\n> Use when: You have keyframe images and want to interpolate between them, creating smooth transitions, or animation/motion interpolation tasks.\n\nWhich is basically I2V if you only use the first frame.",
              "score": 2,
              "created_utc": "2026-01-07 04:46:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny1w537",
          "author": "Perfect-Campaign9551",
          "text": "Why not try to create a video with an actual story? It would be nice to see someone use it for an actual purpose\n\n\nEveryone chasing video but not making anything worthwhile at all, I haven't seen LTX long form video hardly at all",
          "score": 0,
          "created_utc": "2026-01-06 18:32:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny283ba",
              "author": "TheTimster666",
              "text": "OP is clearly testing all kinds of prompts here on his first day of LTX, to understand its capabilities - which I think most of us here would like to see.",
              "score": 12,
              "created_utc": "2026-01-06 19:25:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny3sp07",
                  "author": "hellolaco",
                  "text": "Yeah it just came out today, for a storyline you need days at least. Also this shows much different scenarios then one story",
                  "score": 4,
                  "created_utc": "2026-01-06 23:54:53",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny584u9",
              "author": "ANR2ME",
              "text": "Let them cook first üòÅ it's still new after all.",
              "score": 2,
              "created_utc": "2026-01-07 04:39:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny1bdxt",
          "author": "Grindora",
          "text": "the POV handheld shots are amazing!   \nim sorry to say but Wan in officially dead now!",
          "score": -2,
          "created_utc": "2026-01-06 16:58:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1f7lq",
              "author": "FourtyMichaelMichael",
              "text": "Model out four hours...\n\n>  im sorry to say but Wan in officially dead now!\n\nBro... just.... chill.",
              "score": 11,
              "created_utc": "2026-01-06 17:16:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny1gdh0",
              "author": "broadwayallday",
              "text": "so tired of these \"king\" and \"dead\" comments \n\nso so tired of them",
              "score": 10,
              "created_utc": "2026-01-06 17:21:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2ccbc",
                  "author": "Grindora",
                  "text": "Who cares man? This is open source community there‚Äôs always something better coming every week. Unfortunately wan is officially dead trust my words you will see sht moree posts very soon",
                  "score": 1,
                  "created_utc": "2026-01-06 19:45:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1k38d",
          "author": "Hunting-Succcubus",
          "text": "I saw flux chin",
          "score": 0,
          "created_utc": "2026-01-06 17:38:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny28ifn",
          "author": "EpicNoiseFix",
          "text": "Nice but most models are capable of this quality. It‚Äôs just a string of 5 second clips stitched together so nothing special about this unfortunately",
          "score": -1,
          "created_utc": "2026-01-06 19:27:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3stfh",
              "author": "hellolaco",
              "text": "Which open source t2v model is capable of this quality?",
              "score": 4,
              "created_utc": "2026-01-06 23:55:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny3u872",
                  "author": "EpicNoiseFix",
                  "text": "Text to video is not the way to go because no matter how detailed your prompt is, it will never capture what you want. Kling and Wan are good models as well",
                  "score": -1,
                  "created_utc": "2026-01-07 00:02:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1fde2",
          "author": "gord89",
          "text": "Mid",
          "score": -15,
          "created_utc": "2026-01-06 17:16:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q5y8q7",
      "title": "LTX-2 is genuinely impressive",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/bzd7mr0h8tbg1",
      "author": "Dr_Karminski",
      "created_utc": "2026-01-06 23:05:29",
      "score": 490,
      "num_comments": 70,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Animation - Video",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q5y8q7/ltx2_is_genuinely_impressive/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny3xmxp",
          "author": "shootthesound",
          "text": "lol so the script is from a real phone call - went viral back home years ago. nice job OP\n\n[https://www.instagram.com/reels/C0wW-MAAF6G/](https://www.instagram.com/reels/C0wW-MAAF6G/)",
          "score": 89,
          "created_utc": "2026-01-07 00:20:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4klun",
              "author": "[deleted]",
              "text": "[removed]",
              "score": 27,
              "created_utc": "2026-01-07 02:23:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny60oc9",
                  "author": "Dependent-Head-8307",
                  "text": "If I just had a prize to give you...",
                  "score": 2,
                  "created_utc": "2026-01-07 08:27:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz08xnt",
              "author": "Real_Win_353",
              "text": "Oh man, that was great, thank you for a good one cross the pond.",
              "score": 1,
              "created_utc": "2026-01-11 17:44:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny4ryb9",
          "author": "Etsu_Riot",
          "text": "Man, why it stopped? I wanted to keep watching.",
          "score": 38,
          "created_utc": "2026-01-07 03:03:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz1pnqd",
              "author": "misterflyer",
              "text": "Better than any scene Hollywood has produced in the last few years üòÇ",
              "score": 1,
              "created_utc": "2026-01-11 21:42:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz5tn30",
                  "author": "Etsu_Riot",
                  "text": "Hollywood doesn't make comedy any longer.",
                  "score": 1,
                  "created_utc": "2026-01-12 13:51:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny46e9n",
          "author": "pomonews",
          "text": "What a time to be alive.",
          "score": 12,
          "created_utc": "2026-01-07 01:06:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3ooyj",
          "author": "Hefty_Development813",
          "text": "Wheb you generate each separate clip, how does it keep the character the same? Like how is it the same little girl if they are separate gens?",
          "score": 15,
          "created_utc": "2026-01-06 23:33:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3qbiq",
              "author": "Dr_Karminski",
              "text": "LTX-2 supports inputting images. Every time I upload the same image (generated using nano banan pro), and then reuse the first paragraph of the prompt.",
              "score": 48,
              "created_utc": "2026-01-06 23:42:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny4fafb",
                  "author": "Hefty_Development813",
                  "text": "Ah sure nice thank you. Seems like a lot of potential for these little skit things",
                  "score": 11,
                  "created_utc": "2026-01-07 01:54:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny5513b",
                  "author": "Lover_of_Titss",
                  "text": "Did you have to do anything to keep the voices consistent?",
                  "score": 7,
                  "created_utc": "2026-01-07 04:20:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny5baqr",
                  "author": "Hunting-Succcubus",
                  "text": "Why nano banana? Many Local model are available .",
                  "score": 3,
                  "created_utc": "2026-01-07 05:00:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny4vca3",
          "author": "ryandury",
          "text": "It's impressive but the audio is still so obviously generated",
          "score": 15,
          "created_utc": "2026-01-07 03:22:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5zccu",
              "author": "Oer1",
              "text": "Obvious for people who are used to a.i",
              "score": 10,
              "created_utc": "2026-01-07 08:15:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny9u4qr",
              "author": "inagy",
              "text": "We are truly spoiled, aren't we? It's not much more than 3 years passed by since we had Stable Diffusion 1.5 and everyone was in awe what we got to play with locally. Look how far we have come. I think it's amazing we can do this locally.\n\nAnd as I usually say: this only gets better from here.\n\nKeeping up with the hardware will be the bigger problem.",
              "score": 9,
              "created_utc": "2026-01-07 21:06:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nya9edd",
                  "author": "FpRhGf",
                  "text": "The great progress we've seen in visuals/LLMs doesn't give me more hopes, since audio doesn't get the same treatment and is often neglected in the field of AI. \n\n I've been waiting for a general AI enhancer for audio ever since Topaz came out with their video enhancer back in 2020. It's crazy how we get talking robots and voice cloning before a simple audio quality enhancer.",
                  "score": 2,
                  "created_utc": "2026-01-07 22:12:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny5p17z",
              "author": "_VirtualCosmos_",
              "text": "still awesome for a 19b base model. Thinking about how far people got SDXL base to what is it today, this model has great potential if the community train it a lot.",
              "score": 7,
              "created_utc": "2026-01-07 06:44:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny5ur2f",
          "author": "rookan",
          "text": "Very funny! I would watch such videos every day!",
          "score": 3,
          "created_utc": "2026-01-07 07:34:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4lu5s",
          "author": "Eisegetical",
          "text": "i wish LTX could take custom audio and generate to that instead of trying to do it all in one. the video is great but the audio is absolutely terrible.",
          "score": 5,
          "created_utc": "2026-01-07 02:29:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny6bqm5",
              "author": "hleszek",
              "text": "See this: https://www.reddit.com/r/StableDiffusion/comments/1q627xi/kijai_made_a_ltxv2_audio_image_to_video_workflow/",
              "score": 5,
              "created_utc": "2026-01-07 10:10:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny4ubdk",
              "author": "New_Principle_6418",
              "text": "It can check banodoco discord",
              "score": 1,
              "created_utc": "2026-01-07 03:16:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny5gf5e",
                  "author": "ThisIsDanG",
                  "text": "I haven‚Äôt seen that on banodoco or the ltx documentation. Not sure if I‚Äôm missing it? Do you have a link by chance?",
                  "score": 1,
                  "created_utc": "2026-01-07 05:37:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny3lja9",
          "author": "Informal_Warning_703",
          "text": "Honestly, I don‚Äôt think these examples of the full model or pro, which almost no one will be capable of using are helpful.\n\nThis is certainly no indication of the quality people can expect at fp8 and fp4.",
          "score": 9,
          "created_utc": "2026-01-06 23:17:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3qr8y",
              "author": "Admirable-Star7088",
              "text": "According to [Nvidia](https://www.nvidia.com/en-us/geforce/news/rtx-ai-video-generation-guide/):\n\n>As a frontier model, LTX-2 uses significant amounts of video memory (VRAM) to deliver quality results. Memory use goes up as we increase resolution, framerate, length, or steps. Fortunately for users, ComfyUI and NVIDIA have collaborated to **optimize a weight streaming feature**, allowing users to offload parts of the workflow to system memory if your GPU runs out of VRAM, but this will come at a cost in performance.\n\nMy interpretation is that anyone with sufficient RAM can run the full model (BF16) at full quality, but with slower generation times. The question is whether this would lead to unreasonably long generation times or not. Some people around here claim that LTX 2 runs relatively fast even when using **only** RAM, this would mean a lot of people could run the full model at home.\n\nIt would also be kind of revolutionary if this is true.",
              "score": 17,
              "created_utc": "2026-01-06 23:44:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny5i01o",
                  "author": "wesarnquist",
                  "text": "I'm really glad I decided to go for 256GB RAM when the prices were still relatively low.",
                  "score": 13,
                  "created_utc": "2026-01-07 05:48:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny4vi99",
                  "author": "Olangotang",
                  "text": "Yeah, it's using Direct Storage to stream while inferencing, just like Flux 2.",
                  "score": 4,
                  "created_utc": "2026-01-07 03:23:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny5eig5",
                  "author": "Justgotbannedlol",
                  "text": "yeah fuckin right lmao\n\nif this doesn't run prohibitively slowly when exclusively on ram, it would be an unprecedented step function leap in the entire industry.",
                  "score": 0,
                  "created_utc": "2026-01-07 05:23:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny4m1ex",
              "author": "ThatsALovelyShirt",
              "text": "I ran it at fp8 and I get results about this good. Can even generate at 1080p on my 4090. Takes about a minute to generate 5s, when I include VFI and a sharpening pass.",
              "score": 12,
              "created_utc": "2026-01-07 02:30:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny4nbik",
                  "author": "Informal_Warning_703",
                  "text": "Yes, if you look below you'll see that I was able to get results that are pretty close in visual quality with fp8. The audio quality was a pretty big gap though. With the three generations I ran, none of the audio would have actually been usable.",
                  "score": 2,
                  "created_utc": "2026-01-07 02:37:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny3qimd",
              "author": "Dr_Karminski",
              "text": "https://preview.redd.it/cp7oybbiftbg1.jpeg?width=1200&format=pjpg&auto=webp&s=2d37eecfc4cfc5482a8f356d264775d9a519c7f9\n\nTry with this image bro",
              "score": 6,
              "created_utc": "2026-01-06 23:43:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny3wp0l",
                  "author": "Informal_Warning_703",
                  "text": "I tried a second time (see comment below) using two different renders, like you did. The results are better than I was expecting from a visual standpoint, but the audio issues mad the result unusable. With more tries or generating more separate chunks it may have eventually worked. Anyway, thanks for the demonstration.",
                  "score": 2,
                  "created_utc": "2026-01-07 00:15:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny3odbi",
              "author": "Informal_Warning_703",
              "text": "I just ran your exact prompt on the fp8 model. As you can see, there is no scene switching, the motion doesn't make much sense, and the only part of the audio that was coherent in the video was \"could you blow it up or knock it down?\" and the rest of the audio was gibberish.\n\nhttps://i.redd.it/64mu2667dtbg1.gif\n\nI guess we could speculate that if we found the right seed, the results would be better. But if you're using the API or online model do you even know the seed? (And probably 40% of my generations are just the slide-show problem, where there is no motion and just a slow zoom in, that many others have mentioned.)",
              "score": 3,
              "created_utc": "2026-01-06 23:32:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny3pm2a",
                  "author": "Ashamed-Variety-8264",
                  "text": "What scene switching you are talking about? OP generated two separate scenes.",
                  "score": 8,
                  "created_utc": "2026-01-06 23:38:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny3kwxe",
          "author": "Underrated_Mastermnd",
          "text": "How do you make the scenes consistent with the audio for each character? Are you using first and last frame or you're using a different technique?",
          "score": 2,
          "created_utc": "2026-01-06 23:14:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny46s3t",
              "author": "Commercial-Ad-3345",
              "text": "I was about to ask the same thingü§î",
              "score": 2,
              "created_utc": "2026-01-07 01:08:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny4a0k4",
              "author": "Informal_Warning_703",
              "text": "There‚Äôs not a ton of variation in the model to begin with, so that helps. But he‚Äôs editing two clips. So you would just de-link the audio and use it where necessary.",
              "score": 1,
              "created_utc": "2026-01-07 01:25:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny4k4co",
          "author": "JahJedi",
          "text": "So like to try it but need to finish some loras first",
          "score": 2,
          "created_utc": "2026-01-07 02:20:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny58etx",
          "author": "Thick-Consequence123",
          "text": "Is this I2V or T2V ?",
          "score": 2,
          "created_utc": "2026-01-07 04:41:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5f8s6",
              "author": "ThisIsDanG",
              "text": "This is definitely image to video man.",
              "score": 3,
              "created_utc": "2026-01-07 05:28:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny5ioix",
                  "author": "Thick-Consequence123",
                  "text": "Makes sense .thanks bro",
                  "score": 2,
                  "created_utc": "2026-01-07 05:53:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny5rdv6",
          "author": "Parogarr",
          "text": "Does ComfyUI support FP4? Because the provided workflow doesn't work for me when trying to use the FP4 model and I'm on a 5090",
          "score": 2,
          "created_utc": "2026-01-07 07:04:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5tomv",
          "author": "protector111",
          "text": "i dont understan what did u do to make voices consistent?",
          "score": 2,
          "created_utc": "2026-01-07 07:24:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny68r8v",
              "author": "Essar",
              "text": "They only generated one scene for each then spliced and interleaved them.",
              "score": 5,
              "created_utc": "2026-01-07 09:43:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny6aqav",
                  "author": "protector111",
                  "text": "Ok thanks.",
                  "score": 2,
                  "created_utc": "2026-01-07 10:01:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny3stqx",
          "author": "MikeToMeetYou",
          "text": "The steel does not work.",
          "score": 1,
          "created_utc": "2026-01-06 23:55:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny43kea",
          "author": "Extreme_Feedback_606",
          "text": "I‚Äôve been hearing good things about it. what is the minimum setup to run it smoothly?",
          "score": 1,
          "created_utc": "2026-01-07 00:50:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5apz1",
          "author": "rdsf138",
          "text": " Amazing.",
          "score": 1,
          "created_utc": "2026-01-07 04:57:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5mvaz",
          "author": "cre4tive",
          "text": "That was awesome",
          "score": 1,
          "created_utc": "2026-01-07 06:27:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny65wmm",
          "author": "Free_Scene_4790",
          "text": "With the official workflow and the included models in it, I can't run it; it keeps giving me an OOM error.\n\n\n\nAnd I have a 3090 and 96 GB of RAM, which I don't consider to be a small amount.\n\n\n\nWhat models are people using to be able to run it locally?",
          "score": 1,
          "created_utc": "2026-01-07 09:16:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny6hz2c",
              "author": "Free_Scene_4790",
              "text": "UPDATE (in case it helps anyone else):\n\n\n\nI finally managed to fix it by adding the commands --reserve-vram 10 --listen --auto-launch --disable-smart-memory --lowvram --fp8\\_e4m3fn-text-enc to the startup screen.",
              "score": 4,
              "created_utc": "2026-01-07 11:05:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny76lna",
                  "author": "fauni-7",
                  "text": "Thank you, it failed for me as well on a 4090, so I added only these and it worked, I did a 10 seconds video.\n\n¬†\\--reserve-vram 10 --lowvram",
                  "score": 2,
                  "created_utc": "2026-01-07 13:51:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny7aa4g",
                  "author": "MeikaLeak",
                  "text": "Thank you for this. Was killing me that everyone is running it on smaller cards than my 4090 but i only got OOMs thanks to the encoder",
                  "score": 1,
                  "created_utc": "2026-01-07 14:11:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny6c7hz",
          "author": "Lewd_Dreams_",
          "text": "is a edited video i mean you merged on davinci or premeire or is just 1 prompt generation without edit?",
          "score": 1,
          "created_utc": "2026-01-07 10:15:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyccor8",
          "author": "Poosley_",
          "text": "It can't spell destroy?",
          "score": 1,
          "created_utc": "2026-01-08 04:47:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyyjeb8",
          "author": "Fun_Firefighter_7785",
          "text": "Yes, just fun letting GLM 4.6 Flash making up some prompts, with topics you like. \n\n[https://youtu.be/Xqb5Tut0bHk?si=htgzeyZTeCSxErhT](https://youtu.be/Xqb5Tut0bHk?si=htgzeyZTeCSxErhT)",
          "score": 1,
          "created_utc": "2026-01-11 12:02:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny64ys8",
          "author": "Sudden_List_2693",
          "text": "I'm not sure if this is pair or not, but nothing available for local generation gives you a usable result.  \nSadly not even canny controlnet can help this model at least generate the audio for another video, which I was really hoping for, since not only does it not follow the input video (for some reason), but this model can simply not give you a bearable voice with more than half a coherent sentence.",
          "score": 1,
          "created_utc": "2026-01-07 09:07:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3ly9n",
          "author": "Perfect-Campaign9551",
          "text": "That lipsync isn't very good though...",
          "score": -3,
          "created_utc": "2026-01-06 23:19:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5drtq",
              "author": "DeliciousReference44",
              "text": "Come up with a model that does it better üòÖ",
              "score": 4,
              "created_utc": "2026-01-07 05:18:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q5w36v",
      "title": "LTX-2 on RTX 3070 mobile (8GB VRAM) AMAZING",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/3l4eo6k4usbg1",
      "author": "LSI_CZE",
      "created_utc": "2026-01-06 21:43:36",
      "score": 481,
      "num_comments": 62,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "No Workflow",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q5w36v/ltx2_on_rtx_3070_mobile_8gb_vram_amazing/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny3293k",
          "author": "LSI_CZE",
          "text": "\\- Challenge: The camera shows a woman on the street approaching a reporter with a microphone. The woman says into the microphone: \"This is locally on the RTX 3070 graphics card.\"  \n\\- Native workflow from COMFY BLOG\n\nI don't know if it was necessary, but I made adjustments according to the tips here:\n\n\n\n  \n\n\n[https://www.reddit.com/r/StableDiffusion/comments/1q5k6al/fix\\_to\\_make\\_ltxv2\\_work\\_with\\_24gb\\_or\\_less\\_of\\_vram/](https://www.reddit.com/r/StableDiffusion/comments/1q5k6al/fix_to_make_ltxv2_work_with_24gb_or_less_of_vram/)\n\n\n\n\\- Turn off the comfyui sampler live preview (set to NONE)\n\n\n\nWhen running comfyui, add the flag:\n\npython [main.py](http://main.py) \\--reserve-vram 4 --use-pytorch-cross-attention\n\n\n\nDuring generation, a number of errors appeared with the text encoder and then with LORA, but the result works!\n\nI believe that everything will be fine-tuned gradually, because the generation speed is amazing...\n\n20/20 \\[02:01<00:00, 6.07 s/it\n\n3/3 \\[01:19<00:00, 26.48 s/it\\]\n\nCommand executed in 440.18 seconds",
          "score": 76,
          "created_utc": "2026-01-06 21:44:33",
          "is_submitter": true,
          "replies": [
            {
              "id": "ny334pm",
              "author": "WildSpeaker7315",
              "text": "yessir thats the goodshit right there",
              "score": 22,
              "created_utc": "2026-01-06 21:48:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny3cfrm",
              "author": "Noeyiax",
              "text": "Finally a settings and configs, ty , best o7\n\nNice generation too",
              "score": 14,
              "created_utc": "2026-01-06 22:32:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny3qmue",
              "author": "2legsRises",
              "text": "> - Challenge: The camera shows a woman on the street approaching a reporter with a microphone. The woman says into the microphone: \"This is locally on the RTX 3070 graphics card.\"\n> \n> - Native workflow from COMFY BLOG\n> \n> \n> \n> I don't know if it was necessary, but I made adjustments according to the tips here:\n> \n> \n> \n> https://www.reddit.com/r/StableDiffusion/comments/1q5k6al/fix_to_make_ltxv2_work_with_24gb_or_less_of_vram/\n> \n> \n> \n> - Turn off the comfyui sampler live preview (set to NONE)\n> \n> \n> \n> When running comfyui, add the flag:\n> \n> \n> \n> python main.py --reserve-vram 4 --use-pytorch-cross-attention\n> \n> \n> \n> During generation, a number of errors appeared with the text encoder and then with LORA, but the result works!\n> \n> \n> \n> I believe that everything will be fine-tuned gradually, because the generation speed is amazing...\n> \n> \n> \n> 20/20 [02:01<00:00, 6.07 s/it\n> \n> \n> \n> 3/3 [01:19<00:00, 26.48 s/it]\n> \n> \n> \n> Command executed in 440.18 seconds\n\nthis is what this sub is about, ty for the information",
              "score": 9,
              "created_utc": "2026-01-06 23:44:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny3378x",
              "author": "One-Thought-284",
              "text": "Urm wow honestly amazing to get this level of quality! I'm on a 4060 8GB and not had it look that good so nice!",
              "score": 6,
              "created_utc": "2026-01-06 21:48:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny6be2h",
              "author": "dobomex761604",
              "text": "Doesn't work even with all these settings, 64gb RAM + 12gb vram, ooms after clip. Using latest updated Comfy.",
              "score": 5,
              "created_utc": "2026-01-07 10:07:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny3aksr",
              "author": "Rumaben79",
              "text": "Good job. My own generation looks boring compared to yours. I guess I need to learn how to prompt better. :D\n\nJust a small thing. --use-pytorch-cross-attention is not needed as pytorch attention is already the default with comfyui.\n\nI haven't tried flash attention yet since least I tried to compile it it wouldn't work. Xformers wanted to downgrade stuff last I tried it.. Sooo. :D Sage attention doesn't work.",
              "score": 4,
              "created_utc": "2026-01-06 22:23:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny3bbuo",
              "author": "Perfect-Campaign9551",
              "text": "Isn't it supposed to use sage attention?",
              "score": 3,
              "created_utc": "2026-01-06 22:27:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny3byex",
                  "author": "Rumaben79",
                  "text": "It's switching back to pytorch attention on my setup. I have '--use-sage-attention' in my launch parameters and it works with Wan 2.2.\n\nMy error is \"Error running sage attention: list indices must be integers or slices, not NoneType, using pytorch attention instead.\". It's shows that error multiple times during the generation.\n\nI'm seeing that OP is using 20 steps (and properly cfg 4?) but with the distilled lora in the workflow maybe it's okay to use 8 steps and a cfg of 1?\n\nI also connect the 'CFGGuider's model link to the rear of 'LoraLoaderModelOnly' node containing my distilled lora. Not absolutely sure if all I'm doing is right yet. haha :D\n\n![gif](giphy|43gjNdBlLQmgAnDMYW)",
                  "score": 1,
                  "created_utc": "2026-01-06 22:30:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyt1qs0",
              "author": "NeverLucky159",
              "text": "Looks great, thanks foe the info!",
              "score": 1,
              "created_utc": "2026-01-10 16:16:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny33cvf",
          "author": "DescriptionAsleep596",
          "text": "I'm downloading the model. Heard i2v has a problem, maybe. Thanks for the testing.",
          "score": 13,
          "created_utc": "2026-01-06 21:49:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny35uze",
              "author": "One-Thought-284",
              "text": "yeah I can't seem to get i2v to work on 4060 but t2i works",
              "score": 5,
              "created_utc": "2026-01-06 22:01:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny3b8z7",
              "author": "LSI_CZE",
              "text": "It doesn't work for me either, the camera only zooms in slowly and only the sound works.",
              "score": 5,
              "created_utc": "2026-01-06 22:26:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny4sor2",
                  "author": "Dirty_Dragons",
                  "text": "That's disappointing. \n\nMy primary use case for video gen is img2vid. I was about to download the model and use your settings.",
                  "score": 6,
                  "created_utc": "2026-01-07 03:07:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny3cqgs",
                  "author": "intermundia",
                  "text": "i2v works for me but ive got a 5090 so maybe is a ram issue?",
                  "score": 2,
                  "created_utc": "2026-01-06 22:33:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny6dcny",
                  "author": "Mysterious_Cable4996",
                  "text": "You can modulate the 'img\\_compression' of the source image, open the subgraph, check the 'LTXVPreprocess' node at the bottom. For me, that do the trick. A guy suggested adding 'A cinematic scene of ...' at the beginning of the prompt too.",
                  "score": 1,
                  "created_utc": "2026-01-07 10:25:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny34isp",
          "author": "Interesting8547",
          "text": "Sadly it still gives me that error every time (5070ti):\n\nhttps://preview.redd.it/b7rvzr06wsbg1.png?width=1101&format=png&auto=webp&s=62e6c2f8d298cd9ba32004790327cc64623b2bc3\n\n  \nI don't have such problem with Wan 2.2, despite going above VRAM.",
          "score": 18,
          "created_utc": "2026-01-06 21:54:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny40qpn",
              "author": "Perfect-Campaign9551",
              "text": "I always get this with I run vibevoice large model workflow and then try to run any other workflow after that. Any time I run the vibevoice workflow (when I want to run something else) I have to restart comfyui server entirely. I think some nodes have memory leaks",
              "score": 3,
              "created_utc": "2026-01-07 00:36:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny5da38",
              "author": "ANR2ME",
              "text": "Use the fp8 text encoder, the default one is in BF16/FP16  which need twice the size of fp8.",
              "score": 4,
              "created_utc": "2026-01-07 05:14:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny6ys59",
                  "author": "Interesting8547",
                  "text": "I'm using the fp8 text encoder. I've tried all the recommended things... still the same error. Updated Comfy, using the latest drivers.",
                  "score": 2,
                  "created_utc": "2026-01-07 13:06:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny3omwh",
              "author": "ImaginationKind9220",
              "text": "It's the same with every LTX release. There will be a few random posts saying it's amazing then a week later it's forgotten. I learned my lesson not to waste any time on it.",
              "score": 2,
              "created_utc": "2026-01-06 23:33:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny40eyr",
          "author": "Ferriken25",
          "text": "I'm having trouble installing the new nodes for LTX 2. Every time I check the list of missing nodes, I get an error message saying that ComfyUI is outdated, the cache is empty, etc. My ComfyUI version is 0.7.0, and already up to date. I'm using the portable version of ComfyUI.",
          "score": 8,
          "created_utc": "2026-01-07 00:34:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny7a92v",
              "author": "StayImpossible7013",
              "text": "They updated to 0.8.0 after your post and that should fix your problems.",
              "score": 2,
              "created_utc": "2026-01-07 14:11:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3693j",
          "author": "Spawndli",
          "text": "Can you use your own sound?",
          "score": 5,
          "created_utc": "2026-01-06 22:02:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny36njj",
              "author": "LSI_CZE",
              "text": "Not yet, but apparently it should work in time...",
              "score": 3,
              "created_utc": "2026-01-06 22:04:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny390vg",
                  "author": "Karumisha",
                  "text": "at this precise moment, kijai just did it lol",
                  "score": 16,
                  "created_utc": "2026-01-06 22:16:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny3p72k",
              "author": "Fun-Photo-4505",
              "text": "Yeah you can e.g kpop music, makes the woman sing.",
              "score": 4,
              "created_utc": "2026-01-06 23:36:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny34uqq",
          "author": "Aggravating-Ice5149",
          "text": "impressing¬†",
          "score": 3,
          "created_utc": "2026-01-06 21:56:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny7l4lb",
          "author": "Sarge1970",
          "text": "wow its really works with no errors  \n3070rtx 8Gb laptop 32Gb  \nit's magic  \n  \nPrompt executed in 559.33 seconds",
          "score": 3,
          "created_utc": "2026-01-07 15:07:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyrwyvd",
              "author": "VegetableRemarkable",
              "text": "wow i got a rtx5070 laptop with same ram and vram, gotta try it out",
              "score": 1,
              "created_utc": "2026-01-10 12:19:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny4aoky",
          "author": "Melodic_Possible_582",
          "text": "not bad considering wan 2.6 on the credit based websites are now throttling me to 15-30 minutes for one video.",
          "score": 3,
          "created_utc": "2026-01-07 01:29:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3yvkc",
          "author": "skyrimer3d",
          "text": "Sure 2026 starts with a bang, this is too good to be true.",
          "score": 2,
          "created_utc": "2026-01-07 00:26:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny46gve",
          "author": "DeltaWaffleSyrup",
          "text": "how did you update nodes",
          "score": 2,
          "created_utc": "2026-01-07 01:06:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny52mlo",
          "author": "Whispering-Depths",
          "text": "the crazy part is that someone can fine-tune it to not sound so tinny. This is nuts.",
          "score": 2,
          "created_utc": "2026-01-07 04:05:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny7dx9g",
          "author": "physalisx",
          "text": "#RTX threety seventeeeee...graphics",
          "score": 2,
          "created_utc": "2026-01-07 14:30:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny86rxr",
          "author": "Dogmaster",
          "text": "How much RAM is it using?\nMy poor laptop only has 16GB, with a 4060 8gb",
          "score": 2,
          "created_utc": "2026-01-07 16:46:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9zaw2",
          "author": "uncanny-agent",
          "text": "I need the gguf node to be updated so I can load gemma",
          "score": 2,
          "created_utc": "2026-01-07 21:28:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny340yg",
          "author": "JimmyDub010",
          "text": "Any idea what settings I can use for 4070 super? 12gb. didn't have time to look at the guide yet.",
          "score": 5,
          "created_utc": "2026-01-06 21:52:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3mao4",
          "author": "waldo3125",
          "text": "wtf - if i could run this on my 3080 (10gb) i would, especially if it's only around 90 seconds to generation",
          "score": 2,
          "created_utc": "2026-01-06 23:21:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4c9bf",
          "author": "Link1227",
          "text": "Meanwhile, I can't get it working :(",
          "score": 3,
          "created_utc": "2026-01-07 01:38:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4iyy6",
              "author": "Ferriken25",
              "text": "Looks like it doesn't work on portable version.",
              "score": 3,
              "created_utc": "2026-01-07 02:14:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny4l5qf",
                  "author": "Link1227",
                  "text": "OHHH maybe that's the issue!\n\nI finally got the gemma3 to work but now it says\n\nproj\\_linear.safetensors is missing.",
                  "score": 3,
                  "created_utc": "2026-01-07 02:26:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny5ulff",
          "author": "Formal_Drop526",
          "text": "I will save this",
          "score": 1,
          "created_utc": "2026-01-07 07:32:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny71bwk",
          "author": "iKnowNuffinMuch",
          "text": "I'm such a noob, I can't figure out why I'm getting the Mat1 and Mat2 shapes cannot be multiplied error, every run¬†",
          "score": 1,
          "created_utc": "2026-01-07 13:21:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nycilsf",
          "author": "Alpha_wolf_80",
          "text": "Can you share a link to your final workflow?",
          "score": 1,
          "created_utc": "2026-01-08 05:26:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycn843",
              "author": "LSI_CZE",
              "text": "It's native from Comfyui. No changes :)",
              "score": 1,
              "created_utc": "2026-01-08 05:59:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyebojk",
          "author": "Turbulent_Corner9895",
          "text": "do you need to offload model to system ram",
          "score": 1,
          "created_utc": "2026-01-08 13:51:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nymlu2l",
          "author": "jvachez",
          "text": "i have a python message, memory can't be read",
          "score": 1,
          "created_utc": "2026-01-09 17:06:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4fzcr",
          "author": "verocious_veracity",
          "text": "And you're not gonna share the workflow?",
          "score": 1,
          "created_utc": "2026-01-07 01:58:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4ijyp",
              "author": "JoNike",
              "text": "He mentioned it being the native workflow from comfy: https://raw.githubusercontent.com/Comfy-Org/workflow_templates/refs/heads/main/templates/video_ltx2_t2v.json",
              "score": 4,
              "created_utc": "2026-01-07 02:12:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny4icgd",
          "author": "No-Location6557",
          "text": "Quality looks fine!\n\nWhy is all the initial reports saying this model is low quality garbage?",
          "score": 1,
          "created_utc": "2026-01-07 02:11:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5e19u",
              "author": "ANR2ME",
              "text": "Probably a matter of prompting skills ü§î or may be they were thinking about the old LTX model without testing LTX-2 yet üòÖ",
              "score": 3,
              "created_utc": "2026-01-07 05:20:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny4n9kj",
          "author": "yamfun",
          "text": "Wow I thought 16gb vram is needed",
          "score": 1,
          "created_utc": "2026-01-07 02:37:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny6vdh2",
              "author": "lolxdmainkaisemaanlu",
              "text": "He has 64 GB RAM. Now I regret getting 32 GB RAM and thinking 64 is \"too much\"",
              "score": 5,
              "created_utc": "2026-01-07 12:45:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q6n04w",
      "title": "Reddit engagement in a nutshell.",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/wu42iwatxybg1.png",
      "author": "fruesome",
      "created_utc": "2026-01-07 18:16:29",
      "score": 480,
      "num_comments": 38,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q6n04w/reddit_engagement_in_a_nutshell/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny8t2lk",
          "author": "Mysterious-String420",
          "text": "Workflow for your image ?",
          "score": 78,
          "created_utc": "2026-01-07 18:25:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyb332b",
              "author": "Hunting-Succcubus",
              "text": "Comfyui when?",
              "score": 16,
              "created_utc": "2026-01-08 00:38:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nycr5k7",
                  "author": "No_Comment_Acc",
                  "text": "Which GPU?",
                  "score": 6,
                  "created_utc": "2026-01-08 06:29:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny94q9i",
          "author": "-AwhWah-",
          "text": "pls help i know there's been thousands of tutorials and how-to's everyday at this point but how do i install comfy? is it possible to get a perfectly consistent realtime instagram girl with voice and video, need full nsfw capabilities. Can i get it to run on my 4GB VRAM laptop???? pls how do i do it, one click installer is a little tricky if someone knows someting easier if possible, I really need it for catf‚Äî i mean‚Äî i need it for gooning im just a poor gooner, please please help, please guys i need it!!!",
          "score": 51,
          "created_utc": "2026-01-07 19:16:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny9ahr3",
              "author": "Enter_Name977",
              "text": "My GPU kinda homeless!",
              "score": 25,
              "created_utc": "2026-01-07 19:41:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyahk81",
                  "author": "Aiirene",
                  "text": "![gif](giphy|s5wFafpHxqKbIEERl9)",
                  "score": 9,
                  "created_utc": "2026-01-07 22:50:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyacyop",
              "author": "arbaminch",
              "text": "You forgot the best part: They need to ask Reddit about the easily Googled fundamentals, yet somehow they expect to turn their shitty newb generations into a decent income stream...",
              "score": 13,
              "created_utc": "2026-01-07 22:29:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nya3sc9",
          "author": "ChibiNya",
          "text": "\"Omg this new model is a game changer \" and they post basically 1girl. Try to make an ambitious thing to show off!",
          "score": 18,
          "created_utc": "2026-01-07 21:48:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny94ytv",
          "author": "protector111",
          "text": "https://i.redd.it/3adj890z8zbg1.gif\n\n1girl upvotes go up",
          "score": 15,
          "created_utc": "2026-01-07 19:17:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyak7d3",
          "author": "vault_nsfw",
          "text": "Workflow or downvote!",
          "score": 7,
          "created_utc": "2026-01-07 23:03:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycvay5",
              "author": "Awaythrowyouwilllll",
              "text": "Why not zoidberg?? ¬Ø\\\\\\_(„ÉÑ)_/¬Ø¬†",
              "score": 1,
              "created_utc": "2026-01-08 07:02:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nybxnc3",
          "author": "Ant_6431",
          "text": "Engagement is overrated",
          "score": 5,
          "created_utc": "2026-01-08 03:18:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nybwgis",
          "author": "mk8933",
          "text": "https://preview.redd.it/brwc8azml1cg1.png?width=238&format=png&auto=webp&s=395380a0596653280d86a7f887fb50e3f6436273\n\nAutomatic1111 when?",
          "score": 5,
          "created_utc": "2026-01-08 03:11:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nya4b0y",
          "author": "Mave_Traxis",
          "text": "Yeah. Most of the output posted is completely embarassing imo.",
          "score": 8,
          "created_utc": "2026-01-07 21:50:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8yiwj",
          "author": "VirtualAdvantage3639",
          "text": "I mean, are you seriously surprised that a hot chick gets more upvotes than some nerdy stuff about some rare niche case usage? Is this your first time on the internet?",
          "score": 11,
          "created_utc": "2026-01-07 18:49:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyafb2r",
              "author": "Fresh-Exam8909",
              "text": "You don't understand, we want to see average people in their boring ordinary life, like what we see every day in our own life. That's what we want. AI is great!\n\n;)",
              "score": 0,
              "created_utc": "2026-01-07 22:39:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyfxslc",
                  "author": "jorvaor",
                  "text": "It is interesting that I have seen way more images of boring ordinary people in the subreddit unstable diffusion than in this one.",
                  "score": 1,
                  "created_utc": "2026-01-08 18:17:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny8u92l",
          "author": "Informal_Warning_703",
          "text": "Because the majority of the questions people are asking are so dumb that it would make you want to give up on life if you didn‚Äôt just scroll right past them. Questions like\n\n‚ÄúWhere‚Äôs the workflow for LTX-2?‚Äù why didn‚Äôt you look in the fucking workflow templates before asking?\n\n‚ÄúHow do I install this thing that has a 1-click installer on the github page?‚Äù\n\n![gif](giphy|gKfyusl0PRPdTNmwnD)",
          "score": 20,
          "created_utc": "2026-01-07 18:30:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny913c6",
              "author": "aar550",
              "text": "Because they are hiding their modified workflow on their patreon subscription. \n\nDumb. Should make it a standard rule to post the workflow.",
              "score": 19,
              "created_utc": "2026-01-07 19:00:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyayjb1",
                  "author": "WhatIs115",
                  "text": "> Because they are hiding their modified workflow on their patreon subscription. \n\nHate this the most honestly. Just ban that shit.",
                  "score": 9,
                  "created_utc": "2026-01-08 00:15:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyas137",
              "author": "Winter_unmuted",
              "text": "A huge number of people on this sub are children. Like, preteens or early teens. A generation that was not raised using proper computers, trying to do something they see on social media from their phones, but cannot do on their phones. \n\n\nI find it too easy to assume everyone on reddit is more or less like me. But remember most of reddit is children.",
              "score": 9,
              "created_utc": "2026-01-07 23:42:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny964y6",
              "author": "arbaminch",
              "text": "> Please tell me what model was used to create this? -> Link to picture of entirely generic anime 1girl\n\nSometimes this sub makes we want to unplug the internet. Not even just mine. Like the whole internet.",
              "score": 10,
              "created_utc": "2026-01-07 19:22:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny9w1p3",
              "author": "Mysterious-String420",
              "text": "\\> ‚ÄúWhere‚Äôs the workflow for LTX-2?‚Äù why didn‚Äôt you look in the fucking workflow templates before asking?\n\nThis is actually a legitimate complaint for a LOT of users because the comfyui team have a different idea about what \"release schedule\" means. I'm using comfyui desktop and the templates are NOT updated yet. Only the API version appears.\n\nComfyui desktop is always the last one to actually get stuff. I think the ZIT template arrived in MID-DECEMBER or something, it was already obsolete compared to the shittiest civitai workflow!!!\n\nbut yeah, lazy fucks could use google a bit.",
              "score": 3,
              "created_utc": "2026-01-07 21:14:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nydg8j7",
                  "author": "shapic",
                  "text": "Excuse me, but wtf is comfyui desktop?!",
                  "score": 2,
                  "created_utc": "2026-01-08 10:10:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyc8fiv",
              "author": "MikePounce",
              "text": "Some do post solutions (to problems they encountered) unprompted üòá",
              "score": 1,
              "created_utc": "2026-01-08 04:20:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nybbix7",
          "author": "fistular",
          "text": "I downvote every single one.  Imdoingmypart!.jpg",
          "score": 4,
          "created_utc": "2026-01-08 01:21:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nycv33d",
          "author": "nietzchan",
          "text": "I just skip them 1girl posts on this sub unless they mention workflow or something new, like a new video model or something. Currently waiting for z-image Edit model release..",
          "score": 1,
          "created_utc": "2026-01-08 07:01:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydnlnb",
          "author": "NineThreeTilNow",
          "text": "I thought Reddit posting was about making a shitty pun because you're average as fuck and thinking it's the greatest thing you've done all year.\n\nOh wait, wrong sub. That's all the \"Popular\" subs.",
          "score": 1,
          "created_utc": "2026-01-08 11:13:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydo4k7",
          "author": "yamfun",
          "text": "There are surprisingly few ltx video sample for the bottom",
          "score": 1,
          "created_utc": "2026-01-08 11:18:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nye6ce9",
          "author": "EideDoDidei",
          "text": "Maybe controversial opinion, but I've never liked the post voting system on Reddit. Your post needs to make a positive impression from the get go, otherwise it'll be buried. Memes is one thing that usually ends up dominating almost every subreddit.\n\nI miss when forums were common. You could easily organize them so you've got a dedicated section for guides. And posts/threads were sorted based on activity, not popularity.",
          "score": 1,
          "created_utc": "2026-01-08 13:22:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfszbv",
          "author": "jacobpederson",
          "text": "I consider [myself lucky if my songs get 100 views on youtube :D](https://www.youtube.com/watch?v=qicC24NQPvs)  And yet . . . I have have gotten 80k views on a 1girl post before :D",
          "score": 1,
          "created_utc": "2026-01-08 17:56:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nytwz8z",
          "author": "South-Magazine6522",
          "text": "Gooners be gooning",
          "score": 1,
          "created_utc": "2026-01-10 18:43:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyc4hx6",
          "author": "andy_potato",
          "text": "Can work on GT650? I have 128 MB",
          "score": 1,
          "created_utc": "2026-01-08 03:56:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9kg6m",
          "author": "Anxious-Program-1940",
          "text": "They are the only posts that get really any engagement. Y‚Äôall like what y‚Äôall like üôÇ",
          "score": 0,
          "created_utc": "2026-01-07 20:25:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9facl",
          "author": "Choowkee",
          "text": "I will take 1girl images over posting low effort meme shitspots - what you are doing.",
          "score": -5,
          "created_utc": "2026-01-07 20:02:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8zhz6",
          "author": "yamfun",
          "text": "so how is the capability of ltx2 for the bottom aspect? \n\nis it as good as early october25 grok?",
          "score": -3,
          "created_utc": "2026-01-07 18:53:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q59ygl",
      "title": "LTX-2 is out! 20GB in FP4, 27GB in FP8 + distilled version and upscalers",
      "subreddit": "StableDiffusion",
      "url": "https://huggingface.co/Lightricks/LTX-2/tree/main",
      "author": "1filipis",
      "created_utc": "2026-01-06 05:25:05",
      "score": 442,
      "num_comments": 348,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q59ygl/ltx2_is_out_20gb_in_fp4_27gb_in_fp8_distilled/",
      "domain": "huggingface.co",
      "is_self": false,
      "comments": [
        {
          "id": "nxyp1gu",
          "author": "Choowkee",
          "text": "Examples from LTX team here FYI:\n\nhttps://ltx.io/model/model-blog/prompting-guide-for-ltx-2",
          "score": 88,
          "created_utc": "2026-01-06 06:15:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz9uvj",
              "author": "dreamyrhodes",
              "text": "Somehow AI voices always have this strange emphasis on the words.\n\nWhile graphically it's already impressive, for sound and voices we still have a long way to go.",
              "score": 15,
              "created_utc": "2026-01-06 09:26:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzf9m4",
                  "author": "mulletarian",
                  "text": "Must be a challenge to properly tag something like voices if you want to avoid using a person's name. \n\nWe'll have \"samevoice\" the same way we have \"sameface\".",
                  "score": 7,
                  "created_utc": "2026-01-06 10:16:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxznsql",
                  "author": "GoranjeWasHere",
                  "text": "dude at start of 2025 we had spagetti eating monsters and now we have good video WITH sound and voices mate.",
                  "score": 15,
                  "created_utc": "2026-01-06 11:30:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxyxol7",
              "author": "eruanno321",
              "text": "In the NT DAYTIME example, LTX exhibits an interesting interpretation of a ‚Äûcomforting hand‚Äù.",
              "score": 10,
              "created_utc": "2026-01-06 07:30:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxzza4b",
              "author": "_xxxBigMemerxxx_",
              "text": "The grandpa butterfly lmaoooooooooooooooo",
              "score": 7,
              "created_utc": "2026-01-06 12:54:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxys0vw",
              "author": "doomed151",
              "text": "holy shit",
              "score": 25,
              "created_utc": "2026-01-06 06:40:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxzcok7",
              "author": "_VirtualCosmos_",
              "text": "I really like how the model is designed to follow narrative-style prompting. I like how the prompts are written, they feel like reading a book.",
              "score": 5,
              "created_utc": "2026-01-06 09:52:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxzlvfn",
              "author": "Emotional_Egg_251",
              "text": "The built-in audio is nice, and visuals are good. Unfortunately their own, presumably cherry-picked examples show it not following the prompt too closely. A few I looked at:\n\n>the truck passes the cameras it pans left to follow the trucks reckless drive. dust and motion blur is around the truck, hand held feel to the camera as it tries to track its ride into the distance. the truck then drifts and turns around, then drives back towards the camera until seen in extreme close up.\n\nThe truck never passes the camera. The camera pans right, not left. The truck neither drives into the distance, nor turns around. (the sound is also seriously muted and sporadic for a monster truck)\n\n>The camera slowly pans right, revealing the grandfather in the garden wearing enormous butterfly wings, waving his arms in the air like he‚Äôs trying to take off. He shouts, ‚ÄúWheeeew!‚Äù as he flaps his wings with full commitment.\n\nInstead he's actually flying, and just makes laughing noises, which completely changes the scene.\n\n>one frog twitches, eyes darting. Suddenly ‚Äî *thwip!* ‚Äî its tongue snaps out, catching a fly mid-air and pulling it into its mouth.\n\nNone of this happens, which is pretty important.\n\n>\\[...\\] lowers its head in visible shame\n\nWhen it lowers its head, they all do.",
              "score": 8,
              "created_utc": "2026-01-06 11:14:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny13jbt",
                  "author": "Zestyclose839",
                  "text": "Prompt adherence is awful with every video gen model right now. This director tries to make extremely basic ads with Veo that flop every time:\n\n[https://www.instagram.com/sergiocilli/](https://www.instagram.com/sergiocilli/)",
                  "score": 1,
                  "created_utc": "2026-01-06 16:23:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny06fqc",
              "author": "Wilbis",
              "text": "That lipsync was truly awful, especially on the last clip.\n\nOtherwise looks great.",
              "score": 4,
              "created_utc": "2026-01-06 13:37:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0knuj",
                  "author": "Perfect-Campaign9551",
                  "text": "And honestly the audio all kind of sucks. But hey it's something",
                  "score": 1,
                  "created_utc": "2026-01-06 14:54:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny1xcb1",
                  "author": "mugen7812",
                  "text": "What kind of magic are Sora and Grok running to get good lipsync and audio?",
                  "score": 1,
                  "created_utc": "2026-01-06 18:37:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny0juga",
              "author": "Perfect-Campaign9551",
              "text": "That monster truck audio is horrible lol sounds like ass. The voices are all pretty bad honestly . But the tech is cool",
              "score": 8,
              "created_utc": "2026-01-06 14:50:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxylpd3",
          "author": "Time-Reputation-4395",
          "text": "This is how it's done. Here's hoping the Wan folks follow suit with an open source release of 2.5 now that 2.6 is out.",
          "score": 77,
          "created_utc": "2026-01-06 05:49:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxytzu2",
              "author": "protector111",
              "text": "We need to hype it as much as zit was hyped. spam the reddit with LTX so hard like wan is dead. Maybe then they will give us wan 2.6...",
              "score": 70,
              "created_utc": "2026-01-06 06:57:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxz5fli",
                  "author": "Head-Leopard9090",
                  "text": "Definitely",
                  "score": 9,
                  "created_utc": "2026-01-06 08:43:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny13gel",
                  "author": "_raydeStar",
                  "text": "You know what this feels like?  When I got dumped, so I dated a hot girl to get my ex jealous.",
                  "score": 3,
                  "created_utc": "2026-01-06 16:22:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxzhxhl",
                  "author": "Lucaspittol",
                  "text": "Nah, not a chinese model, so it is unlikely to happen",
                  "score": 2,
                  "created_utc": "2026-01-06 10:40:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyijpu7",
                  "author": "LoveByForce",
                  "text": "First we need to know whether it's worth hyping or not, and that's not going to be at least until ltxv2 or whatever runs in the Distorch Dual CLIP node. Until then, it's as much a mystery as Hunyuan Image 3.0 is.",
                  "score": 1,
                  "created_utc": "2026-01-09 01:36:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxyx2bt",
                  "author": "hurrdurrimanaccount",
                  "text": "why would they? they are making money with it now",
                  "score": -6,
                  "created_utc": "2026-01-06 07:24:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxysx2m",
              "author": "_VirtualCosmos_",
              "text": "I prefer to wait for Wan3 if they made it OSS",
              "score": 6,
              "created_utc": "2026-01-06 06:48:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxypj8t",
              "author": "hurrdurrimanaccount",
              "text": "never happening",
              "score": 6,
              "created_utc": "2026-01-06 06:20:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxyip7n",
          "author": "Specialist_Pea_4711",
          "text": "Finally, I was waiting for it eagerly since they announced it, super excited to test it.\n\nhttps://preview.redd.it/oo3lzoum1obg1.jpeg?width=1080&format=pjpg&auto=webp&s=b7053eb7825b53b3aa973ffb42361389d13560ed",
          "score": 25,
          "created_utc": "2026-01-06 05:26:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxykxib",
              "author": "Hoodfu",
              "text": "Uh so yeah. I'm not seeing any ltx-2 workflows in that directory. Am I missing something? I'm starting to wonder if their git was fully released yet. No ltx2 workflows in there and the module won't load on comfy start correctly. errors out even though I did all the requirements etc. [https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example\\_workflows](https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example_workflows) [https://github.com/Lightricks/ComfyUI-LTXVideo/issues/289](https://github.com/Lightricks/ComfyUI-LTXVideo/issues/289)",
              "score": 4,
              "created_utc": "2026-01-06 05:43:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxyow8n",
                  "author": "Specialist_Pea_4711",
                  "text": "They just updated workflows too - https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example_workflows",
                  "score": 11,
                  "created_utc": "2026-01-06 06:14:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxyoc1n",
                  "author": "ArkCoon",
                  "text": "I‚Äôm getting the same import error. I edited the file called ‚Äúmodel.py‚Äù and that fixed it, but there‚Äôs still no actual workflow for LTX2. It‚Äôs pretty strange that they spent so long preparing the model and had the ComfyUI release ready on day one, yet both the workflow and the library are broken, so nobody can actually use it. Did nobody test this before putting it out?\n\nEDIT: They just added the LTX2 workflow",
                  "score": 7,
                  "created_utc": "2026-01-06 06:10:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxyvez6",
                  "author": "ANR2ME",
                  "text": "Workflows got uploaded an hour ago.",
                  "score": 3,
                  "created_utc": "2026-01-06 07:10:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxynjhc",
                  "author": "hurrdurrimanaccount",
                  "text": "it hasnt been updated in over a month lmao",
                  "score": -2,
                  "created_utc": "2026-01-06 06:03:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxynlwl",
          "author": "BakaPotatoLord",
          "text": "Watch me try it with my GTX 1660 Super O\\_O",
          "score": 29,
          "created_utc": "2026-01-06 06:04:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz36i1",
              "author": "_VirtualCosmos_",
              "text": "I wish you good luck.",
              "score": 12,
              "created_utc": "2026-01-06 08:21:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny0q2k7",
              "author": "Wilbis",
              "text": "Watching a stream of that would be great as insomnia treatment.",
              "score": 3,
              "created_utc": "2026-01-06 15:20:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny76kas",
              "author": "GokuNoU",
              "text": "Genuinely let us know if there is progress on that front lmao. I got a spare card that this would be amazing to fool with on.",
              "score": 1,
              "created_utc": "2026-01-07 13:51:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nycnjcm",
                  "author": "BakaPotatoLord",
                  "text": "None, gave it a try today and the results are just what I expected. Unable to load the checkpoint, ComfyUI just crashes. 32 GB RAM is obviously not enough in my case, at least CLIP Text Encode is a success lol.\n\nI'm gonna wait for GGUFs",
                  "score": 2,
                  "created_utc": "2026-01-08 06:01:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxyq53i",
          "author": "q8019222",
          "text": "Is there a way to make a 16GB graphics card usable?",
          "score": 21,
          "created_utc": "2026-01-06 06:25:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxyz467",
              "author": "Neggy5",
              "text": "nvidia article says it does with offloading. which contradicts what the github page says",
              "score": 8,
              "created_utc": "2026-01-06 07:43:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxz3dm3",
                  "author": "_VirtualCosmos_",
                  "text": "These people used to employ huge datacenters seems to not know what wonders does the layer-offloading with these big models.",
                  "score": 2,
                  "created_utc": "2026-01-06 08:23:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxyqzxz",
              "author": "Radyschen",
              "text": "i think this will be a question most people have, including me. It can't possibly be restricted to zillionaires who can afford a 5090",
              "score": 18,
              "created_utc": "2026-01-06 06:32:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxz8cuk",
                  "author": "Electrical-Eye-3715",
                  "text": "Zillionaires buy rtx 6000 pro not 5090.",
                  "score": 23,
                  "created_utc": "2026-01-06 09:11:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxzpftd",
                  "author": "crowbar-dub",
                  "text": "Oh, the good ol' days in last summer when i bought mine and 128gb ram when prices were still for mortals.",
                  "score": 4,
                  "created_utc": "2026-01-06 11:43:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxznpp8",
                  "author": "raika11182",
                  "text": "You're right. It's for trillionairre companies who can afford a data center.",
                  "score": 1,
                  "created_utc": "2026-01-06 11:30:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxys4il",
              "author": "intLeon",
              "text": "And 12 for us peasants. Q2 quants when?\n\nEdit: fp8 distilled (27gb) worked on 12gb and clip is running on cpu.",
              "score": 10,
              "created_utc": "2026-01-06 06:41:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny56vk1",
              "author": "LordAcryl",
              "text": " I saw on twitter someone with 4070 mzke it work",
              "score": 2,
              "created_utc": "2026-01-07 04:31:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny7s3z6",
              "author": "Hot_Turnip_3309",
              "text": "yeah just plug it into the pci slot and hook up the power dumbshit",
              "score": 1,
              "created_utc": "2026-01-07 15:40:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxzaxyd",
              "author": "Cultural-Broccoli-41",
              "text": "This may be possible if offloading to DRAM is implemented...",
              "score": 1,
              "created_utc": "2026-01-06 09:36:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxyx3uc",
              "author": "hurrdurrimanaccount",
              "text": "it doesn't even run on 24gb vram so.. no.",
              "score": 0,
              "created_utc": "2026-01-06 07:25:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzad5k",
                  "author": "Naomi-ken-korem",
                  "text": "We will release a solution for 24gb soon  \n(LTX-2 Researcher)",
                  "score": 15,
                  "created_utc": "2026-01-06 09:30:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxyu0ql",
          "author": "wh33t",
          "text": "VIDEO AND AUDIO!!??",
          "score": 22,
          "created_utc": "2026-01-06 06:57:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz3yg9",
              "author": "_VirtualCosmos_",
              "text": "And not bad audio too, at least with voices. It reminds me to early VEO3 videos, tho LTX2 might be a bit worse.",
              "score": 18,
              "created_utc": "2026-01-06 08:28:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzfz0t",
                  "author": "InevitableJudgment43",
                  "text": "as someone who uses veo 3 daily, ltx 2 is far better visually by leaps and bounds. and the voices still sound tinny but are more expressive. Veo 3.1 quality has dipped. it's been surpassed by seedream.",
                  "score": 11,
                  "created_utc": "2026-01-06 10:23:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxzdopm",
                  "author": "Neamow",
                  "text": "It is pretty bad, let's not kid ourselves. It would need full audio replacement, from voice to foley.",
                  "score": 3,
                  "created_utc": "2026-01-06 10:02:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny0kvay",
                  "author": "Perfect-Campaign9551",
                  "text": "Ltx audio is really bad compared to veo audio",
                  "score": 1,
                  "created_utc": "2026-01-06 14:55:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxywwv8",
          "author": "Simple_Echo_6129",
          "text": "Takes around 68 seconds to generate a 5-second video on a 5090 for the example T2V workflow. Pretty impressive.",
          "score": 19,
          "created_utc": "2026-01-06 07:23:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxyypva",
              "author": "Jinkourai",
              "text": "hey can you share your workflow?",
              "score": 5,
              "created_utc": "2026-01-06 07:40:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxyz2q0",
                  "author": "Simple_Echo_6129",
                  "text": "It's the example T2V workflow built into ComfyUI once you install the LTX nodes.",
                  "score": 6,
                  "created_utc": "2026-01-06 07:43:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxz1yj5",
              "author": "Radyschen",
              "text": "they say it should do a 4 second video at 720p in 25 seconds, can you confirm (probably at 24 fps)? not that I have a 5090",
              "score": 3,
              "created_utc": "2026-01-06 08:10:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxz4wba",
                  "author": "Simple_Echo_6129",
                  "text": "On multiple runs it's taking around 42 seconds for a 1280x720 scene with 97 frames for me, on Windows.\n\n\nI'm reaching 1.44 it/s consistently.",
                  "score": 3,
                  "created_utc": "2026-01-06 08:38:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxz5abc",
                  "author": "FinBenton",
                  "text": "Im running to OOM on 5090 trying to do 720p with fp8 or fp4, 480p kinda runs.",
                  "score": 3,
                  "created_utc": "2026-01-06 08:41:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxz52h7",
                  "author": "Simple_Echo_6129",
                  "text": "> they say it should do a 4 second video at 720p in 25 seconds, can you confirm (probably at 24 fps)? not that I have a 5090\n\nBtw where did you read this quote? Thanks~",
                  "score": 2,
                  "created_utc": "2026-01-06 08:39:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxz3zty",
              "author": "_VirtualCosmos_",
              "text": "Using the distilled, right?",
              "score": 2,
              "created_utc": "2026-01-06 08:29:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxz5ww0",
                  "author": "Simple_Echo_6129",
                  "text": "Nope, using the default one. I'll try the distilled next.",
                  "score": 4,
                  "created_utc": "2026-01-06 08:47:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxz96yh",
                  "author": "Simple_Echo_6129",
                  "text": "The distilled version is faster, 30-ish seconds for 1280x720, 5 seconds video.",
                  "score": 3,
                  "created_utc": "2026-01-06 09:19:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxz5n4l",
              "author": "Head-Leopard9090",
              "text": "Really? Amazing! Imma try",
              "score": 2,
              "created_utc": "2026-01-06 08:45:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxyiw2f",
          "author": "1filipis",
          "text": "Comfy support is day-one. https://docs.ltx.video/open-source-model/integration-tools/comfy-ui\n\nPrerequisites\n\nBefore you begin setting up an LTX-2 workflow in ComfyUI, make sure you have:\n\n* CUDA-compatible GPU with 32GB+ VRAM\n\n* 100GB+ free disk space for models and cache\n\n* Python 3.10+ (usually included with ComfyUI)\n\nRecommended: ComfyUI Manager\n\nThis is the easiest method and handles dependencies automatically.\n\n* Open ComfyUI\n\n* Click the Manager button (or press Ctrl+M)\n\n* Select Install Custom Nodes\n\n* Search for ‚ÄúLTXVideo‚Äù\n\n* Click Install next to ComfyUI-LTXVideo\n\n* Wait for installation to complete\n\n* Restart ComfyUI",
          "score": 43,
          "created_utc": "2026-01-06 05:28:16",
          "is_submitter": true,
          "replies": [
            {
              "id": "nxyo75r",
              "author": "Hoodfu",
              "text": "yeah, this doesn't work. Those nodes haven't been updated for a good while now.",
              "score": 6,
              "created_utc": "2026-01-06 06:09:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxyoosj",
                  "author": "1filipis",
                  "text": "It's up now https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example_workflows",
                  "score": 7,
                  "created_utc": "2026-01-06 06:13:09",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxyjlsu",
              "author": "Radyschen",
              "text": "yea so i guess unless you have a 5090 you gotta wait for this one",
              "score": 18,
              "created_utc": "2026-01-06 05:33:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxyte4g",
                  "author": "_VirtualCosmos_",
                  "text": "I bet it works with much less VRAM, but taking a lot of time. I will test it in my 12 GB 4070ti later.",
                  "score": 9,
                  "created_utc": "2026-01-06 06:52:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxysp30",
                  "author": "comperr",
                  "text": "hehe",
                  "score": 3,
                  "created_utc": "2026-01-06 06:46:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxyonmo",
              "author": "andy_potato",
              "text": "The nodes and workflows have not been updated yet. Also the installation docs at [https://docs.ltx.video/open-source-model/integration-tools/comfy-ui](https://docs.ltx.video/open-source-model/integration-tools/comfy-ui) are completely wrong and outdated.",
              "score": 3,
              "created_utc": "2026-01-06 06:12:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxyov3o",
                  "author": "1filipis",
                  "text": "It's there for me https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example_workflows",
                  "score": 3,
                  "created_utc": "2026-01-06 06:14:34",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxzqlsz",
              "author": "Acceptable_Secret971",
              "text": "I wonder if it's actual CUDA or pytorch CUDA. In the second case there is a chance this will work on AMD. RDNA4 has int4 rather than fp4 and it along fp8 for AMD is not currently supported in ComfyUI, so GGUF model would be the best bet. Also I had issues with offloading with Qwen Image Edit on AMD, so OOM rather than partial load is possible.",
              "score": 2,
              "created_utc": "2026-01-06 11:52:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny0jsxw",
              "author": "Upset-Virus9034",
              "text": "no change for RTX 4090 24GbVram?",
              "score": 2,
              "created_utc": "2026-01-06 14:49:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxywmdr",
          "author": "No_Comment_Acc",
          "text": "Guys, Comfy is already updated with 6 workflows!",
          "score": 11,
          "created_utc": "2026-01-06 07:20:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny11xa1",
              "author": "jude1903",
              "text": "I updated comfy and still don't see the template :(",
              "score": 2,
              "created_utc": "2026-01-06 16:15:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny19f89",
                  "author": "No_Comment_Acc",
                  "text": "Are you using the portable version? It must be there. I suggest fresh install if updating does not work.",
                  "score": 1,
                  "created_utc": "2026-01-06 16:50:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxyoik7",
          "author": "ArkCoon",
          "text": "This really makes you appreciate WAN being a MoE model split into high and low noise",
          "score": 34,
          "created_utc": "2026-01-06 06:11:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzmvzi",
              "author": "Different_Fix_2217",
              "text": "Eh, that makes it such a pain to train though. I prefer the single model approach.",
              "score": 12,
              "created_utc": "2026-01-06 11:23:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxznkhh",
                  "author": "ArkCoon",
                  "text": "I'd rather have a model that I can use, but is harder to train, than a model that is easy to train, but I (and most people with consumer hardware) can't use.",
                  "score": 13,
                  "created_utc": "2026-01-06 11:29:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxyt5bp",
              "author": "_VirtualCosmos_",
              "text": "We need more MoE image/video/audio diffusers, they are great.",
              "score": 10,
              "created_utc": "2026-01-06 06:50:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxz1ok4",
          "author": "Cute_Pain674",
          "text": "oh boy i wish i had a 5090 right about now",
          "score": 9,
          "created_utc": "2026-01-06 08:07:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny03074",
          "author": "Fancy-Ad4197",
          "text": "Awesome! So excited to test this out, examples look really good compared to anything else open-source.",
          "score": 7,
          "created_utc": "2026-01-06 13:17:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny32arj",
              "author": "i-am-not-a_whore",
              "text": "Agreed, will be cool to see how this develops (also to see if/how Wan can respond, I don't think they can)",
              "score": 1,
              "created_utc": "2026-01-06 21:44:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxykigv",
          "author": "Fabix84",
          "text": "Finally, a native open video + audio model! I hope this will also convince WAN to release the WAN 2.5 wheights.",
          "score": 21,
          "created_utc": "2026-01-06 05:40:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxykkth",
          "author": "metal079",
          "text": "how fast is it?",
          "score": 5,
          "created_utc": "2026-01-06 05:40:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz3ywk",
          "author": "Sweet-Argument-7343",
          "text": "How does it compare to Wan 2.2 ?",
          "score": 6,
          "created_utc": "2026-01-06 08:29:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny26ua9",
              "author": "joseph_jojo_shabadoo",
              "text": "And can it boob?",
              "score": 6,
              "created_utc": "2026-01-06 19:20:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxzaiky",
          "author": "NineThreeTilNow",
          "text": "Watching people complain about other people doing good open source work always amazes me.",
          "score": 10,
          "created_utc": "2026-01-06 09:32:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyynxz",
          "author": "Odd-Mirror-2412",
          "text": "It's a great attempt. While the video and sound feel a bit out of sync, this is a major step forward.",
          "score": 4,
          "created_utc": "2026-01-06 07:39:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny01m1t",
              "author": "MFGREBEL",
              "text": "Probably adjustable settings in the subgraph, i watched the youtube videos from ltxs channel and they showcased it. Maybe something you could tweak in there?",
              "score": 2,
              "created_utc": "2026-01-06 13:09:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny35o3r",
                  "author": "FourtyMichaelMichael",
                  "text": "subgraphs with settings inside them..... suuuuuuuuuuuuuucccccckk.",
                  "score": 2,
                  "created_utc": "2026-01-06 22:00:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzeey0",
          "author": "martinerous",
          "text": "Would this even work on a 3090?\n\nAt first, does anyone have a solution to get past OOM at ClipTextEncode stage, possibly because of the huge gemma\\_3\\_12B\\_it.safetensors ?\n\nCan quantization save us, or am I now officially GPU-poor?",
          "score": 5,
          "created_utc": "2026-01-06 10:09:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzg8ja",
              "author": "One-Thought-284",
              "text": "Hah I presume it can be optimized to work on that but right now I've tried the GGUF file of Gemma and it doesn't work will see if the community releases something that can run on lower hardware I guess",
              "score": 5,
              "created_utc": "2026-01-06 10:25:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxz4o05",
          "author": "no-comment-no-post",
          "text": "https://preview.redd.it/fhcexzlgxobg1.png?width=815&format=png&auto=webp&s=aff3df880fc7216169a79173f9be4e431fd22ded\n\nAnyone else seeing this when running any of the I2V workflows?",
          "score": 5,
          "created_utc": "2026-01-06 08:35:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzanje",
              "author": "Naomi-ken-korem",
              "text": "What gemma model are you trying to load?",
              "score": 1,
              "created_utc": "2026-01-06 09:33:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2gnzw",
                  "author": "no-comment-no-post",
                  "text": "Gemma 3 IT, 24GB model was the only one I could find to download. Which should I be using?",
                  "score": 1,
                  "created_utc": "2026-01-06 20:05:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxzdry9",
              "author": "crinklypaper",
              "text": "turn off live previews",
              "score": 1,
              "created_utc": "2026-01-06 10:03:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2gtgs",
                  "author": "no-comment-no-post",
                  "text": "Great suggestion, didn‚Äôt help. That was the first thing I did prior to posting the error.",
                  "score": 1,
                  "created_utc": "2026-01-06 20:05:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzdrl5",
          "author": "rodinj",
          "text": "Is this censored like v1?",
          "score": 4,
          "created_utc": "2026-01-06 10:03:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxziql0",
              "author": "Upper-Reflection7997",
              "text": "Most likely will still have Ken and barbie doll body if naked.",
              "score": 5,
              "created_utc": "2026-01-06 10:47:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzto8l",
                  "author": "AIerkopf",
                  "text": "So in other words it's totally useless for most users.",
                  "score": 0,
                  "created_utc": "2026-01-06 12:15:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzg54b",
          "author": "lumos675",
          "text": "We Need GREAT KIJAI to make it way more optimised man. can someone inform him please about this release",
          "score": 9,
          "created_utc": "2026-01-06 10:24:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny01gui",
              "author": "MFGREBEL",
              "text": "THIS ü§£",
              "score": -2,
              "created_utc": "2026-01-06 13:08:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxyraow",
          "author": "protector111",
          "text": "ANyone know where to get the TE ?  they link oficial HF there is n comfyui format file.",
          "score": 3,
          "created_utc": "2026-01-06 06:34:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz020l",
              "author": "Informal_Warning_703",
              "text": "[https://huggingface.co/Comfy-Org/ltx-2/tree/main/split\\_files/text\\_encoders](https://huggingface.co/Comfy-Org/ltx-2/tree/main/split_files/text_encoders)\n\nHope you got a lot of ram.",
              "score": 4,
              "created_utc": "2026-01-06 07:52:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxz9p4o",
                  "author": "Naomi-ken-korem",
                  "text": "you need also the files from here  \n[https://huggingface.co/google/gemma-3-12b-it-qat-q4\\_0-unquantized/tree/main](https://huggingface.co/google/gemma-3-12b-it-qat-q4_0-unquantized/tree/main) (you can use the full safetensor from previous link) but you need the tokenizer and the jsons  \n(I am LTX-2 researcher)",
                  "score": 6,
                  "created_utc": "2026-01-06 09:24:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxz5ba3",
          "author": "crinklypaper",
          "text": "we finally hit a model with min 32gb requirements. I know we'll get it working but that's harsh.",
          "score": 3,
          "created_utc": "2026-01-06 08:42:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0c8v4",
              "author": "Nevaditew",
              "text": "It must be difficult to reach the quality of Sora 2 or Veo 3 with so little VRAM. Maybe in a few years, a better way will be found to optimize it without losing quality.",
              "score": 1,
              "created_utc": "2026-01-06 14:09:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxzbl1s",
          "author": "VirusCharacter",
          "text": "That's a bummer!!  \n  \nTraceback (most recent call last):  \n  File \"Q:\\\\ComfyUI\\_5090\\\\nodes.py\", line 2149, in load\\_custom\\_node  \nmodule\\_spec.loader.exec\\_module(module)  \n  File \"<frozen importlib.\\_bootstrap\\_external>\", line 995, in exec\\_module  \n  File \"<frozen importlib.\\_bootstrap>\", line 488, in \\_call\\_with\\_frames\\_removed  \n  File \"Q:\\\\ComfyUI\\_5090\\\\custom\\_nodes\\\\ComfyUI-LTXVideo\\\\\\_\\_init\\_\\_.py\", line 3, in <module>  \nfrom .easy\\_samplers import (  \n  File \"Q:\\\\ComfyUI\\_5090\\\\custom\\_nodes\\\\ComfyUI-LTXVideo\\\\easy\\_samplers.py\", line 12, in <module>  \nfrom .latents import LTXVAddLatentGuide, LTXVSelectLatents  \n  File \"Q:\\\\ComfyUI\\_5090\\\\custom\\_nodes\\\\ComfyUI-LTXVideo\\\\latents.py\", line 7, in <module>  \nfrom comfy.ldm.lightricks.vae.audio\\_vae import LATENT\\_DOWNSAMPLE\\_FACTOR  \nModuleNotFoundError: No module named 'comfy.ldm.lightricks.vae.audio\\_vae'\n\nCannot import Q:\\\\ComfyUI\\_5090\\\\custom\\_nodes\\\\ComfyUI-LTXVideo module for custom nodes: No module named 'comfy.ldm.lightricks.vae.audio\\_vae'",
          "score": 3,
          "created_utc": "2026-01-06 09:42:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzoo2u",
              "author": "shon161",
              "text": "It looks like your ComfyUI installation and its dependencies need to be updated.",
              "score": 1,
              "created_utc": "2026-01-06 11:37:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzrs7r",
                  "author": "VirusCharacter",
                  "text": "I was not on the master branch for some strange reason. Changing to master branch solved it",
                  "score": 2,
                  "created_utc": "2026-01-06 12:01:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzbp45",
          "author": "bullerwins",
          "text": "I was going to quantize to gguf, but I guess it doesn't make sense now that they have already released the fp8 and fp4 versions?  \nMaybe the q8 and q4 quantized from bf16 are still a bit better",
          "score": 3,
          "created_utc": "2026-01-06 09:43:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzs3zu",
              "author": "VirusCharacter",
              "text": "Fp4? Where? That's for 5xxx right?",
              "score": 3,
              "created_utc": "2026-01-06 12:04:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny57rzo",
              "author": "LordAcryl",
              "text": "Please quantize it to lower gb",
              "score": 2,
              "created_utc": "2026-01-07 04:37:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxyjbnx",
          "author": "omar07ibrahim1",
          "text": "ƒ∞s there pro or ultra ?",
          "score": 6,
          "created_utc": "2026-01-06 05:31:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxykexl",
              "author": "1filipis",
              "text": "nope",
              "score": 4,
              "created_utc": "2026-01-06 05:39:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxykkv4",
                  "author": "omar07ibrahim1",
                  "text": "How to get ultra quality?¬†",
                  "score": -1,
                  "created_utc": "2026-01-06 05:40:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxyjyvq",
          "author": "ArtDesignAwesome",
          "text": "Im assuming GGUF support will be quickly coming. Q8 üòçüòçüòç",
          "score": 5,
          "created_utc": "2026-01-06 05:36:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxyqpgb",
              "author": "ResponsibleTruck4717",
              "text": "fp4 is already 20gb.",
              "score": 7,
              "created_utc": "2026-01-06 06:29:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxyx9dz",
                  "author": "hurrdurrimanaccount",
                  "text": "and still doesn't work with 24gb vram. that 32gb card requirement is no joke",
                  "score": 3,
                  "created_utc": "2026-01-06 07:26:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny01pv0",
                  "author": "MFGREBEL",
                  "text": "Cant run it with the lora, encoder and vae. Its closer to 40gb at that point",
                  "score": 1,
                  "created_utc": "2026-01-06 13:09:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxyzj7w",
          "author": "ANR2ME",
          "text": "I wondered whether the instruct text encoder (gemma-3-12b-it) can be used to replace the base/pre-trained version (gemma-3-12b-pt) ü§î",
          "score": 2,
          "created_utc": "2026-01-06 07:47:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz9tzw",
              "author": "Naomi-ken-korem",
              "text": "the model was trained with the regular gemma version, but you can try and show us if it works :)",
              "score": 1,
              "created_utc": "2026-01-06 09:25:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxzdawb",
          "author": "Barbagiallo",
          "text": "So, you need space to run gemma13B and ltx-v2...  Do you think that a quantized Gemma could work? So I can let a small version of the text encoder to ram.",
          "score": 2,
          "created_utc": "2026-01-06 09:58:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzeaav",
              "author": "One-Thought-284",
              "text": "I'm trying this right now on a 4060 will see I guess..",
              "score": 3,
              "created_utc": "2026-01-06 10:07:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxzf6rk",
              "author": "One-Thought-284",
              "text": "No I get an error sadly doesn't look like a drop in replacement",
              "score": 3,
              "created_utc": "2026-01-06 10:16:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxze04w",
          "author": "PinkMelong",
          "text": "I am getting The size of tensor a (1100) must match the size of tensor b (151680) at non-singleton dimension 2 any idea what it is about? I am on 5090",
          "score": 2,
          "created_utc": "2026-01-06 10:05:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzghd9",
              "author": "lumos675",
              "text": "you must use their gemma model. until someone like GREAT KIJAI optimise it seems like this is the only solution. but i can not run it even on 5090 as well. now i am trying smaller res maybe i can run it.\n\n[https://huggingface.co/google/gemma-3-12b-it-qat-q4\\_0-unquantized/tree/main](https://huggingface.co/google/gemma-3-12b-it-qat-q4_0-unquantized/tree/main)",
              "score": 1,
              "created_utc": "2026-01-06 10:27:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzgxbe",
                  "author": "PinkMelong",
                  "text": "I see. I used comfy org's gemma with comfy default ltx2 t2i workflow. let me try their gemma model.",
                  "score": 1,
                  "created_utc": "2026-01-06 10:31:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzfxhq",
          "author": "protector111",
          "text": "anyone got it working? getting oom on 5090 even with fp4",
          "score": 2,
          "created_utc": "2026-01-06 10:22:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzmn4d",
              "author": "shon161",
              "text": "At what stage are you getting OOM and with what workflow ?",
              "score": 1,
              "created_utc": "2026-01-06 11:21:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxznihg",
                  "author": "protector111",
                  "text": "Default wf included with ltx custom node.  i managed to render 640 x 352 and frames 121",
                  "score": 1,
                  "created_utc": "2026-01-06 11:28:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxzphfd",
              "author": "FinBenton",
              "text": "Yeah use the fp8, works fine for me, I couldnt get fp4 running unless I used very low settings and results were not good.",
              "score": 1,
              "created_utc": "2026-01-06 11:44:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzqlyw",
                  "author": "protector111",
                  "text": "what res and how many frames? and what gpu u got?",
                  "score": 1,
                  "created_utc": "2026-01-06 11:52:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny02wxg",
                  "author": "windlep7",
                  "text": "How much ram do you have?",
                  "score": 1,
                  "created_utc": "2026-01-06 13:17:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny04pq1",
                  "author": "protector111",
                  "text": "looks like this was the  problem.. ithought lower size model will be easier on the vram and it is in fact times slower than fp8 model. Thanks again",
                  "score": 1,
                  "created_utc": "2026-01-06 13:27:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzgevi",
          "author": "artisst_explores",
          "text": "anyone got it working in comfyui yet ? im having textencoder issues. i downloaded full gemma repo into folder in textencoders but still ..this error, help pls   \n  \n ''LTXVGemmaEnhancePrompt\n\nCannot use chat template functions because tokenizer.chat\\_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat\\_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat\\_templating''",
          "score": 2,
          "created_utc": "2026-01-06 10:27:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1oqib",
              "author": "Potential_Wolf_632",
              "text": "You've accidentally downloaded PT instead of IT - PT does not understand templating.  I've been there before...\n\nGrab IT: [https://huggingface.co/google/gemma-3-12b-it/tree/main](https://huggingface.co/google/gemma-3-12b-it/tree/main)\n\nReplace all files and restart comfy as it will not know the shard has changed (reloading the tab won't do it).",
              "score": 5,
              "created_utc": "2026-01-06 17:59:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny49e6i",
                  "author": "artisst_explores",
                  "text": "woah! thanks a ton",
                  "score": 1,
                  "created_utc": "2026-01-07 01:22:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxzkz0g",
              "author": "Diecron",
              "text": "currently facing the same",
              "score": 3,
              "created_utc": "2026-01-06 11:07:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0625t",
                  "author": "artisst_explores",
                  "text": "pls let me know if u solve it",
                  "score": 1,
                  "created_utc": "2026-01-06 13:35:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxzq432",
              "author": "FinBenton",
              "text": "Just update comfy to the latest, then go to tempate manager and you find their official workflows that come with direct download links to right files, works great.",
              "score": 1,
              "created_utc": "2026-01-06 11:49:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny05ynw",
                  "author": "artisst_explores",
                  "text": "did them before posting here. did update all again, same issue... ''LTXVGemmaEnhancePrompt\n\nCannot use chat template functions because tokenizer.chat\\_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat\\_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat\\_templating''",
                  "score": 1,
                  "created_utc": "2026-01-06 13:34:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzgjq9",
          "author": "JahJedi",
          "text": "Next king of open waights for video and wan now need to realese somthing to?",
          "score": 2,
          "created_utc": "2026-01-06 10:28:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny86a2y",
              "author": "Neither_Aioli_3951",
              "text": "I don't think so, this thing needs like 64gb ram and a 5090 to run which is like a Small minority of people while wan 2.2 works on even 8gb cards.",
              "score": 1,
              "created_utc": "2026-01-07 16:44:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny8d3sm",
                  "author": "JahJedi",
                  "text": "People whit less run it now...",
                  "score": 1,
                  "created_utc": "2026-01-07 17:15:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzgmfo",
          "author": "ramonartist",
          "text": "ü§î The ComfyUI blog, doesn't mention the model perimeter sizes, or give Vram requirements, is there a reason why this important information was left out?",
          "score": 2,
          "created_utc": "2026-01-06 10:29:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzgrx5",
              "author": "One-Thought-284",
              "text": "32gb VRAM",
              "score": 1,
              "created_utc": "2026-01-06 10:30:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxzlrib",
          "author": "Suspicious-Pilot-636",
          "text": "Ugh, I think I'll just watch my 3080ti in silence :(",
          "score": 2,
          "created_utc": "2026-01-06 11:14:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzxen0",
              "author": "Lug_L",
              "text": "It works on my RTX 3080 10GB, I can make 720p video :)",
              "score": 1,
              "created_utc": "2026-01-06 12:42:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzyyxy",
                  "author": "Lug_L",
                  "text": "https://preview.redd.it/w80tioud7qbg1.png?width=1192&format=png&auto=webp&s=1957dc300ac28d488cd4a72d33cf41afec2c033b",
                  "score": 1,
                  "created_utc": "2026-01-06 12:52:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzm306",
          "author": "lumos675",
          "text": "This node provided by LTX-2 has millions of Bugs man.. Please fix it",
          "score": 2,
          "created_utc": "2026-01-06 11:16:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzmxlr",
              "author": "lumos675",
              "text": "I Tried the Distilled workflow now with fp8 distilled model i got this Error.. i did not change anything \n\nExpected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper\\_CUDA\\_\\_index\\_select)",
              "score": 1,
              "created_utc": "2026-01-06 11:23:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxznb4o",
                  "author": "lumos675",
                  "text": "at the moment i am using Claude Code to fix this issue myself for personal use though",
                  "score": 1,
                  "created_utc": "2026-01-06 11:26:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzmb62",
          "author": "protector111",
          "text": "Cannot use chat template functions because tokenizer.chat\\_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat\\_template attribute, please see the documentation at [https://huggingface.co/docs/transformers/main/en/chat\\_templating](https://huggingface.co/docs/transformers/main/en/chat_templating)",
          "score": 2,
          "created_utc": "2026-01-06 11:18:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzmgpn",
          "author": "SpendSufficient245",
          "text": "Can anyone help me with getting the gemma 3 safetensors file, on the hugging face page the file is split up in multiple files and I've never understood where to get the one that works (single file) with comfy. 99% of the time its linked in the comments somewhere. Thanks so much :-)",
          "score": 2,
          "created_utc": "2026-01-06 11:19:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzn3f4",
          "author": "FxManiac01",
          "text": "wow, great model, although I think we all need at least RTX 5090.. but what I did not find is - can it do first to last image transformations? This is something very userful for various video models out now, so this one if incapable, it would be big loss..",
          "score": 2,
          "created_utc": "2026-01-06 11:25:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxznerg",
          "author": "Rizzlord",
          "text": "5080 no chance even with fp4",
          "score": 2,
          "created_utc": "2026-01-06 11:27:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxznlhz",
          "author": "is_this_the_restroom",
          "text": "Can LTX2 local do portrait resolutions? all the examples  I'm seeing shows landscape res.",
          "score": 2,
          "created_utc": "2026-01-06 11:29:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzqc5h",
              "author": "FinBenton",
              "text": "Yeah I tested, can do any aspect ratio.",
              "score": 1,
              "created_utc": "2026-01-06 11:50:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxz3jic",
          "author": "mk8933",
          "text": "https://i.redd.it/ov4dn8hovobg1.gif",
          "score": 4,
          "created_utc": "2026-01-06 08:25:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyk63h",
          "author": "andy_potato",
          "text": "Why would you need 32+ GB of VRAM if you can just offload to RAM in ComfyUI?",
          "score": 4,
          "created_utc": "2026-01-06 05:37:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxytr20",
              "author": "leepuznowski",
              "text": "Even with a 5090 I have to offload to RAM when rendering 1080p with Wan2.2. Speed is still good at around 60s/it. for 81 Frames. Although at least 64 G RAM is needed.",
              "score": 7,
              "created_utc": "2026-01-06 06:55:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxz1crb",
                  "author": "Ricky_HKHK",
                  "text": "Even 720P in Wan 2.2 usually takes over 32GB. It's just the ram performance not greatly hit the time in Wan 2.2 so offloading to sytem memory doesn't hurt much, not sure about LTX-2 though.",
                  "score": 3,
                  "created_utc": "2026-01-06 08:04:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxynvu1",
              "author": "Netsuko",
              "text": "Because this slow as heck?",
              "score": 14,
              "created_utc": "2026-01-06 06:06:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxyof6a",
                  "author": "andy_potato",
                  "text": "Offloading to RAM has little impact on speed",
                  "score": -23,
                  "created_utc": "2026-01-06 06:11:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxyq44t",
              "author": "lazercheesecake",
              "text": "Why offload to ram when you can offload to Google drive",
              "score": 10,
              "created_utc": "2026-01-06 06:24:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxytkc5",
                  "author": "tac0catzzz",
                  "text": "why use ram, when you can use potatoes",
                  "score": 6,
                  "created_utc": "2026-01-06 06:54:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxzdxpg",
              "author": "martinerous",
              "text": "So, now I'm officially GPU-poor with only a 3090. It fails even to get past text encode, I assume because of gemma\\_3\\_12B\\_it.safetensors being 23GB?  \nCould quantized models save us?\n\nhttps://preview.redd.it/zqfdx35gdpbg1.png?width=485&format=png&auto=webp&s=55fc34e20dd16e09613393429b1a804fc1c28e25\n\n[](blob:https://www.reddit.com/d29900d1-a039-462c-8f15-898698afe6f6)",
              "score": 3,
              "created_utc": "2026-01-06 10:04:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxz8nl3",
          "author": "Weltleere",
          "text": "It's too big.",
          "score": 3,
          "created_utc": "2026-01-06 09:14:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyo6re",
          "author": "ISSAvenger",
          "text": "How‚Äôs the quality compared to Grok Imagine?",
          "score": 2,
          "created_utc": "2026-01-06 06:09:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny03avi",
          "author": "DeProgrammer99",
          "text": "Requires 32 GB VRAM? Let me know when there's a multi-GPU Vulkan version... I should've at least bought multiple of the same card, haha.",
          "score": 2,
          "created_utc": "2026-01-06 13:19:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny083w7",
          "author": "Erdeem",
          "text": "I'm not a fan of the built in audio, maybe someone can come up with a way of substituting voices with something from chatterbox. Does ltx2 do sound effects as well? If so is it on a separate channel than voices?",
          "score": 1,
          "created_utc": "2026-01-06 13:46:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny08tsa",
          "author": "Professional-Tax-866",
          "text": "Managed to finally generate a video without OOMing on 8GB 4060 TI / 64 GB ram with the default ComfyUI i2v workflow by reducing frames to 81 and resolution to 960x540. Took roughly 20 mins‚Ä¶",
          "score": 1,
          "created_utc": "2026-01-06 13:50:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0cd0i",
              "author": "Royal_Ad9801",
              "text": "Anything else that was modified? I get OOM on a 4090 24GB / 256GB of ram",
              "score": 1,
              "created_utc": "2026-01-06 14:10:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0f1ai",
                  "author": "Professional-Tax-866",
                  "text": "Only modified resolution and frame_count. Used the fp8 model and 2 loras included in the workflow. Running via SwarmUI. The results are not amazing though but I guess it is a prompting issue on my end :)",
                  "score": 1,
                  "created_utc": "2026-01-06 14:24:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny0cqv2",
                  "author": "CheeseWithPizza",
                  "text": "skill issue?",
                  "score": 1,
                  "created_utc": "2026-01-06 14:12:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny0hl2k",
          "author": "StuccoGecko",
          "text": "Where do we get the required VAE? Seems like every hub page is completely missing this.  Also, what other Clips can we use aside from Gemma",
          "score": 1,
          "created_utc": "2026-01-06 14:38:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0jm16",
          "author": "Holdthemuffins",
          "text": "So, compared to wan 2.2, it's.....?\n\nThoughts?",
          "score": 1,
          "created_utc": "2026-01-06 14:48:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0lx5a",
          "author": "Kompicek",
          "text": "Maybe its the workflow or some settings i dont know about, but honestly after 2 hours of generating, i find it pretty bad. Prompt following not good, generation is average and the audio is horrible.",
          "score": 1,
          "created_utc": "2026-01-06 15:00:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1gpid",
          "author": "popsikohl",
          "text": "Any info on how long of video it supports before repeating?",
          "score": 1,
          "created_utc": "2026-01-06 17:23:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1ne5r",
          "author": "jude1903",
          "text": "I got this error, but I have all these nodes, any idea why?\n\nhttps://preview.redd.it/gpjq7p21prbg1.png?width=586&format=png&auto=webp&s=de065f603fa9b1a6668b6f09dc736d41a6250041",
          "score": 1,
          "created_utc": "2026-01-06 17:53:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1nest",
              "author": "jude1903",
              "text": "https://preview.redd.it/umf8nef3prbg1.png?width=562&format=png&auto=webp&s=3425aae30d85f21584e264bf58465f07588b58bb",
              "score": 1,
              "created_utc": "2026-01-06 17:53:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2p4n7",
                  "author": "Weekly_Put_7591",
                  "text": "There should be some default entries in there. Most the files you need you'll download from here  \n[https://huggingface.co/Lightricks/LTX-2/tree/main](https://huggingface.co/Lightricks/LTX-2/tree/main)",
                  "score": 1,
                  "created_utc": "2026-01-06 20:44:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny9bg9e",
                  "author": "Broad-Lab-1833",
                  "text": "did you solve?",
                  "score": 1,
                  "created_utc": "2026-01-07 19:45:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1supk",
          "author": "Oni8932",
          "text": "i get this error.   \nmodule 'torch' has no attribute 'float4\\_e2m1fn\\_x2'  \nonline it says i have to update pytorch. should i update or maybe i can do something else to make it work? i'm using fp4 checkpoint btwe",
          "score": 1,
          "created_utc": "2026-01-06 18:17:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2q2bp",
              "author": "Weekly_Put_7591",
              "text": "Are you using ComfyUI version 0.8.0 ?",
              "score": 2,
              "created_utc": "2026-01-06 20:48:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny312jy",
                  "author": "Oni8932",
                  "text": "yes but at the end it seems it was comfy\\_kitchen missing and i have to update pytorch and cuda.",
                  "score": 1,
                  "created_utc": "2026-01-06 21:39:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny2ctb7",
          "author": "sdnr8",
          "text": "What's the difference between distilled and full? I noticed the size is the same",
          "score": 1,
          "created_utc": "2026-01-06 19:47:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2mnvj",
              "author": "Ramdak",
              "text": "I guess steps, distilled require less steps than the full model",
              "score": 1,
              "created_utc": "2026-01-06 20:33:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3jdg3",
          "author": "voertbroed",
          "text": "you have to use the garbage desktop version of comfyui? portable doesnt seem up to date for this",
          "score": 1,
          "created_utc": "2026-01-06 23:06:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3mfkh",
          "author": "heyholmes",
          "text": "Losing my mind. I can't get  a bunch of the nodes in the image to video workflow to load on runpod. I've recloned, Ive updated Comfy multiple times, I've used Gemini 3 to re-walk me through all possible steps. |\n\nCan't get rid of the following warning: ComfyUI is outdated, so some built-in nodes cannot be used.\n\nAny suggestions are very welcome!",
          "score": 1,
          "created_utc": "2026-01-06 23:22:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5rzbh",
          "author": "yamfun",
          "text": "Is it as good as early October grok imagine?",
          "score": 1,
          "created_utc": "2026-01-07 07:09:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny62hg4",
          "author": "No-Location6557",
          "text": "Can it do 10s locally?",
          "score": 1,
          "created_utc": "2026-01-07 08:44:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyimymt",
          "author": "Several_Honeydew_250",
          "text": "It's pretty quick, and the sound is decentish.  def 10x faster, i dunno about 18. How do i post a video lol, it's so funny.",
          "score": 1,
          "created_utc": "2026-01-09 01:53:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyofjy",
          "author": "fallingdowndizzyvr",
          "text": "Is it any good?",
          "score": 1,
          "created_utc": "2026-01-06 06:11:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz7yny",
          "author": "Green-Ad-3964",
          "text": "I've just read this on wccftech:\n\n\nIn addition to these, NVIDIA is also announcing a new Audio-to-Video model called LTX-2, which is going to be powered by RTX. This is the #1 open weights video model on the market right now and offers up to 4K video generation in just 20 seconds. With NVFP8 support, users will be able to see an impressive 2.0x performance gain.\n\n\nSo is there a specific version of ltx-2 to run on rtx?",
          "score": 1,
          "created_utc": "2026-01-06 09:07:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzb7hl",
              "author": "Naomi-ken-korem",
              "text": "the released comfy FLOWS and checkpoints can run on 5090RTX",
              "score": 3,
              "created_utc": "2026-01-06 09:39:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1lldq",
                  "author": "Green-Ad-3964",
                  "text": "Fantastic, thanks.",
                  "score": 1,
                  "created_utc": "2026-01-06 17:45:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzwzzz",
          "author": "lumos675",
          "text": "May i ask why you did not use smaller Gemma 12b model? i can see the gguf version is q4 is only 8 Gb even q8 is 13 gb only.  \nAlso why you did not release fp4 version distilled as well?",
          "score": 1,
          "created_utc": "2026-01-06 12:39:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzz0qa",
          "author": "seppe0815",
          "text": "das wurde doch nur ver√∂ffentlich, damit die Leute eine 5090 kaufen .... Gesponsert von Nvidia ,  haha",
          "score": 1,
          "created_utc": "2026-01-06 12:52:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny16jju",
          "author": "crowbar-dub",
          "text": "The quality is as low as OVI wan model. No improvement at all. Not in video quality and not in audio.",
          "score": 1,
          "created_utc": "2026-01-06 16:36:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxylssr",
          "author": "nakabra",
          "text": "No demo videos üò¢",
          "score": 0,
          "created_utc": "2026-01-06 05:50:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxyne2v",
              "author": "nok01101011a",
              "text": "There is one on their GitHub https://github.com/Lightricks/LTX-2 and it‚Äôs pretty promising",
              "score": 9,
              "created_utc": "2026-01-06 06:02:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxynvps",
                  "author": "nakabra",
                  "text": "The most impressive for me is, believe it or not, the audio. \nLooks quite natural, not compressed at all, at least in this video.",
                  "score": 3,
                  "created_utc": "2026-01-06 06:06:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxyplm0",
              "author": "Choowkee",
              "text": "https://ltx.io/model/model-blog/prompting-guide-for-ltx-2",
              "score": 5,
              "created_utc": "2026-01-06 06:20:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxyrdwg",
                  "author": "nakabra",
                  "text": "Neat",
                  "score": 2,
                  "created_utc": "2026-01-06 06:35:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny0path",
          "author": "Perfect-Campaign9551",
          "text": "Not impressed by any of the audio it's all very robotic sounding and reverb-y. Can't believe they would have expected people to pay for this on their main site for the last few months.",
          "score": 0,
          "created_utc": "2026-01-06 15:17:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz74vh",
          "author": "metallica_57625",
          "text": "Wait, so I'm confused. I opened the LTX2 workflow in confyui and it's telling me I have to pay per generation.  Is that how it's supposed to work locally or am I missing something.",
          "score": 0,
          "created_utc": "2026-01-06 08:59:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxza2le",
              "author": "Naomi-ken-korem",
              "text": "here are the comfy flows that you can run on your machine:  \n[https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example\\_workflows](https://github.com/Lightricks/ComfyUI-LTXVideo/tree/master/example_workflows)",
              "score": 1,
              "created_utc": "2026-01-06 09:28:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxzbp4e",
              "author": "VirusCharacter",
              "text": "This: [https://www.reddit.com/r/StableDiffusion/comments/1q59ygl/comment/nxyow8n/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/r/StableDiffusion/comments/1q59ygl/comment/nxyow8n/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",
              "score": 1,
              "created_utc": "2026-01-06 09:43:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxzal57",
          "author": "moarveer2",
          "text": "32gb VRAM rofl no, us 16gb VRAM peasants will be waiting for Kijai or some other magician to help us out.",
          "score": 0,
          "created_utc": "2026-01-06 09:33:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzasza",
          "author": "Confusion_Senior",
          "text": "20gb in fp4 is a weird choice because only works for a 5090 since others 5xxx are 16gb but at the same time doesn‚Äôt fit in 16gb. Perhaps offloading a bit may work",
          "score": 0,
          "created_utc": "2026-01-06 09:35:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzbysh",
              "author": "BWeebAI",
              "text": "The 4090 has 24GB VRAM. Needing 32GB, only 5090 owners can run the workflow.",
              "score": -2,
              "created_utc": "2026-01-06 09:46:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzccff",
                  "author": "Confusion_Senior",
                  "text": "4090 is not native fp4, fp8 takes 27",
                  "score": 5,
                  "created_utc": "2026-01-06 09:49:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzovtl",
          "author": "a_beautiful_rhind",
          "text": "Oh damn.. so I have to run it on multi-gpu from the start?",
          "score": 0,
          "created_utc": "2026-01-06 11:39:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz2vz9",
          "author": "andy_potato",
          "text": "Claiming \"day-one\" support for ComfyUI is simply not true.\n\nAt the time you posted this the latest release of ComfyUI is still 0.7.0. All the required fixes / updates to run LTX are only available in the master branch or haven't even been merged yet.\n\nCould have waited another day with that announcement instead of wasting everybody's time dealing with the resulting Comfy errors.",
          "score": -8,
          "created_utc": "2026-01-06 08:18:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q6lzok",
      "title": "most powerfull multi lora available for qwen image edit 2511 train on gaussian splatting",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/v1zy4i5srybg1.gif",
      "author": "Affectionate-Map1163",
      "created_utc": "2026-01-07 17:41:09",
      "score": 427,
      "num_comments": 66,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q6lzok/most_powerfull_multi_lora_available_for_qwen/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nya2ub8",
          "author": "AHEKOT",
          "text": "Vibecoded quick PoC node for my project and looks like it really works) \n\nhttps://preview.redd.it/1qa0p3t1zzbg1.png?width=2356&format=png&auto=webp&s=a41d8068f53654e4645909f1d65b0060972e3361",
          "score": 44,
          "created_utc": "2026-01-07 21:43:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nya7hf1",
              "author": "Sixhaunt",
              "text": "THIS is what showing it off really looks like. The video was cutting between frames so fast that I couldnt tell how accurate the results were but from your image that's impressive",
              "score": 14,
              "created_utc": "2026-01-07 22:04:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nybq67p",
              "author": "mastaquake",
              "text": "That's actually pretty cool. you should publish this.",
              "score": 7,
              "created_utc": "2026-01-08 02:38:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyd4gsy",
                  "author": "AHEKOT",
                  "text": "[https://github.com/AHEKOT/ComfyUI\\_VNCCS\\_Utils](https://github.com/AHEKOT/ComfyUI_VNCCS_Utils) it's not yet published to comfy registry, so only manual install for now.",
                  "score": 8,
                  "created_utc": "2026-01-08 08:22:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nya8nq4",
              "author": "Shorties",
              "text": "I wonder if that door would persist between generations since its not visible in the original image",
              "score": 5,
              "created_utc": "2026-01-07 22:09:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyabs30",
                  "author": "AHEKOT",
                  "text": "no, it imagine that door, so it not preserved between generations. But it's the best we got for now.",
                  "score": 5,
                  "created_utc": "2026-01-07 22:23:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyanq0l",
                  "author": "Sixhaunt",
                  "text": "if yo need another view that includes the door you could probably just use that new version as the original",
                  "score": 5,
                  "created_utc": "2026-01-07 23:20:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyb6077",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 3,
              "created_utc": "2026-01-08 00:52:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyd4hhz",
                  "author": "AHEKOT",
                  "text": "[https://github.com/AHEKOT/ComfyUI\\_VNCCS\\_Utils](https://github.com/AHEKOT/ComfyUI_VNCCS_Utils) it's not yet published to comfy registry, so only manual install for now.",
                  "score": 2,
                  "created_utc": "2026-01-08 08:23:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyc3qah",
              "author": "HappyImagineer",
              "text": "Would you share this node?",
              "score": 3,
              "created_utc": "2026-01-08 03:52:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyd4i7i",
                  "author": "AHEKOT",
                  "text": "[https://github.com/AHEKOT/ComfyUI\\_VNCCS\\_Utils](https://github.com/AHEKOT/ComfyUI_VNCCS_Utils) it's not yet published to comfy registry, so only manual install for now.",
                  "score": 3,
                  "created_utc": "2026-01-08 08:23:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nybamjx",
              "author": "Darkstorm-2150",
              "text": "got a github ?",
              "score": 2,
              "created_utc": "2026-01-08 01:16:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyd4hvv",
                  "author": "AHEKOT",
                  "text": "[https://github.com/AHEKOT/ComfyUI\\_VNCCS\\_Utils](https://github.com/AHEKOT/ComfyUI_VNCCS_Utils) it's not yet published to comfy registry, so only manual install for now.",
                  "score": 2,
                  "created_utc": "2026-01-08 08:23:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nycsgoi",
              "author": "juandann",
              "text": "I'm interested to use your node, would you share it with us?",
              "score": 2,
              "created_utc": "2026-01-08 06:39:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyd4iml",
                  "author": "AHEKOT",
                  "text": "[https://github.com/AHEKOT/ComfyUI\\_VNCCS\\_Utils](https://github.com/AHEKOT/ComfyUI_VNCCS_Utils) it's not yet published to comfy registry, so only manual install for now.",
                  "score": 3,
                  "created_utc": "2026-01-08 08:23:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyaabzc",
              "author": "UnicornJoe42",
              "text": "Looks interesting. Is it just 2 visual selection graphs transforming to prompt?",
              "score": 1,
              "created_utc": "2026-01-07 22:17:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyabyuh",
                  "author": "AHEKOT",
                  "text": "Yes, simple widget where you click at points.",
                  "score": 3,
                  "created_utc": "2026-01-07 22:24:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyfbss3",
              "author": "BluJayM",
              "text": "Yo this is absolutely dope but I do have an honest question‚Ä¶\nVibe coded? I‚Äôm a traditional software engineer but having a ton of hangups with using AI in my workflow so I‚Äôm looking for new perspectives (pun intended). Did you just throw a bunch of requests at a coding AI and it just worked? Any recommendations?",
              "score": 1,
              "created_utc": "2026-01-08 16:42:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyfeo9d",
                  "author": "AHEKOT",
                  "text": "And I've never hidden this fact)) After all, we are in a sub dedicated to AI.\n\nThe first thing I can recommend is to install Copilot in VS Code or use Antigravity from Google. These utilities can work as agents, understanding the structure of your project.\n\nThe next step is to find the model that works best for you. Gemini handled the widget based on the image and logic I described to it in three clarifying prompts. However, if the solution is not obvious and the AI does not know it for sure, it will still come down to trial and error. For example, I am currently working on FaceDetailer for qwen-image-edit, and such a node will require much more than three prompts.",
                  "score": 2,
                  "created_utc": "2026-01-08 16:54:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny8jdnp",
          "author": "LocoMod",
          "text": "Big if works as intended. Well done.",
          "score": 16,
          "created_utc": "2026-01-07 17:43:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8o4px",
          "author": "Toclick",
          "text": " I like that it doesn‚Äôt mess with the color palette and contrast and keeps them close to the original. 2509 used to do that all the time. But the greenery looks odd, almost like SD 1.5",
          "score": 6,
          "created_utc": "2026-01-07 18:04:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny93nve",
          "author": "ThatsALovelyShirt",
          "text": "Can you use this in reverse? Generate a bunch of views of a scene, and then generate a radiance field or something from it or something?",
          "score": 3,
          "created_utc": "2026-01-07 19:11:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nya29oj",
              "author": "Silonom3724",
              "text": "Yes but it needs to be VERY precise in order to get a good result.",
              "score": 4,
              "created_utc": "2026-01-07 21:41:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny9z9cy",
          "author": "oromis95",
          "text": "First 2511 post I'm actually impressed by.",
          "score": 3,
          "created_utc": "2026-01-07 21:28:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8k5k5",
          "author": "Lower-Cap7381",
          "text": "DAMN DUDE Lets seeee you guys cooking",
          "score": 2,
          "created_utc": "2026-01-07 17:47:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8lj30",
          "author": "davidl002",
          "text": "This is great!",
          "score": 2,
          "created_utc": "2026-01-07 17:53:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8rqlr",
          "author": "Enshitification",
          "text": "Nice job! I tried your workflow with the new Lightning 8-step LoRA and it seems to work fine also.",
          "score": 2,
          "created_utc": "2026-01-07 18:20:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8wg0v",
          "author": "skyrimer3d",
          "text": "i have to check this, if it's as good as it looks it's crazy what we can do with this, i had a room i wanted to \"map\" and this would be so perfect.",
          "score": 2,
          "created_utc": "2026-01-07 18:40:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyd8v9w",
          "author": "Impressive-Still-398",
          "text": "Dude, you're the fucking goat.",
          "score": 2,
          "created_utc": "2026-01-08 09:03:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8xjiy",
          "author": "physalisx",
          "text": "That grandma is funny. She goes from super tall to dwarf :D\n\nWould be nice to see these with comparison to native results without the lora. Because qwen edit can do these things already without, it's unclear how much better (if at all) it is with this.",
          "score": 3,
          "created_utc": "2026-01-07 18:45:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyaqmg6",
          "author": "mugen7812",
          "text": "I will probably kiss you on the lips if it works as intended. Was using another multiple angles lora, and sometimes it misfired",
          "score": 2,
          "created_utc": "2026-01-07 23:35:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8ocff",
          "author": "Michoko92",
          "text": "Exactly what I needed yesterday. Can't wait to try it. Thanks for the great timing!üòâüôè",
          "score": 1,
          "created_utc": "2026-01-07 18:05:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8y0rb",
          "author": "Neonsea1234",
          "text": "when you train a lora for 2511, do you train it on base image model or on the edit model?",
          "score": 1,
          "created_utc": "2026-01-07 18:47:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny96ee3",
              "author": "Rune_Nice",
              "text": "They're training on the edit model.\n\n\"This is the first multi-angle camera control LoRA for¬†Qwen-Image-Edit-2511.\"\n\nLook at their huggingface link:\n\n# Training Details\n\n|Parameter|Value|\n|:-|:-|\n|**Training Platform**|[fal.ai Qwen Image Edit 2511 Trainer](https://fal.ai/models/fal-ai/qwen-image-edit-2511-trainer)|\n|**Base Model**|[Qwen/Qwen-Image-Edit-2511](https://huggingface.co/Qwen/Qwen-Image-Edit-2511)|\n|**Training Data**|3000+ Gaussian Splatting renders|\n|**Camera Poses**|96 unique positions (4√ó8√ó3)|\n|**Data Source**|Synthetic 3D renders with precise camera control|\n|**Dataset & Training**|Built by Lovis Odin at fal|",
              "score": 1,
              "created_utc": "2026-01-07 19:23:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny99go8",
          "author": "Enshitification",
          "text": "I used Prompt Builder nodes from the Inspire Pack node set to make prompt pulldowns for each category; azimuth, elevation, and distance. It's very easy to do. Just edit the ComfyUI/custom_nodes/comfyui-inspire-pack/resources/prompt-builder.yaml. You can add the whole list of permutations, or make three separate groups for the categories and concatenate them as I did.     \n     \nEdit: This node works way better for this.     \nhttps://github.com/kambara/ComfyUI-PromptPalette",
          "score": 1,
          "created_utc": "2026-01-07 19:37:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyaib9z",
              "author": "Enshitification",
              "text": "https://preview.redd.it/j2p0vqjmb0cg1.png?width=356&format=png&auto=webp&s=45b447b7b82b124e88ed551983b72fb165db2646",
              "score": 2,
              "created_utc": "2026-01-07 22:53:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nya815n",
              "author": "Angelotheshredder",
              "text": "https://preview.redd.it/onluilg330cg1.png?width=349&format=png&auto=webp&s=cd92ac30e018cd5a1efd3309b4c9f74739f8ae17",
              "score": 1,
              "created_utc": "2026-01-07 22:06:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nya912u",
                  "author": "Enshitification",
                  "text": "That's one way to do it, but it's redundant. You can also do a list of the 8 azimuths, 4 elevations, and 3 distances as separate lists and concatenate them.",
                  "score": 5,
                  "created_utc": "2026-01-07 22:11:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny9f9o9",
          "author": "Goodis",
          "text": "How well does it handle text? If i have a schampoo bottle f.eg and change angles for the product shot will it keep the text intact?",
          "score": 1,
          "created_utc": "2026-01-07 20:02:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9fd1s",
          "author": "satatchan",
          "text": "Great work. Would be nice to control angle with precise values. Or with additional reference cube which will correspond to specific camera position and rotation.",
          "score": 1,
          "created_utc": "2026-01-07 20:02:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9gu1l",
          "author": "DescriptionAsleep596",
          "text": "Just tested it, really promising!",
          "score": 1,
          "created_utc": "2026-01-07 20:09:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9uf3d",
          "author": "Better-Interview-793",
          "text": "Wow that‚Äôs really cool!",
          "score": 1,
          "created_utc": "2026-01-07 21:07:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9zca1",
          "author": "bhasi",
          "text": "The angle switch works, but it introduces severe grid and banding issues",
          "score": 1,
          "created_utc": "2026-01-07 21:28:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyadxn1",
          "author": "SEOldMe",
          "text": "could be useful...Thank you",
          "score": 1,
          "created_utc": "2026-01-07 22:33:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyahlg3",
          "author": "External-Lead-4727",
          "text": "well done, really nice angle outputs and simple!",
          "score": 1,
          "created_utc": "2026-01-07 22:50:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyalt15",
          "author": "ogreUnwanted",
          "text": "are we able to run multiple loras? I currently use the lightning 4 step lora",
          "score": 1,
          "created_utc": "2026-01-07 23:11:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyao9vs",
              "author": "Angelotheshredder",
              "text": "https://preview.redd.it/7ovb5oftg0cg1.jpeg?width=2242&format=pjpg&auto=webp&s=df96093adc39271a9fc4901884e65efaede9755d\n\nyes you can, no problem at all",
              "score": 2,
              "created_utc": "2026-01-07 23:23:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyau9kw",
                  "author": "ogreUnwanted",
                  "text": "sweet!",
                  "score": 1,
                  "created_utc": "2026-01-07 23:53:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyd94uw",
          "author": "jazzamp",
          "text": "I tried it, looks like it's only good for landscape.",
          "score": 1,
          "created_utc": "2026-01-08 09:05:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydgf4q",
          "author": "Upset-Virus9034",
          "text": "so you add each camera prompt manually right?",
          "score": 1,
          "created_utc": "2026-01-08 10:12:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydr3sw",
          "author": "NineThreeTilNow",
          "text": "Gaussian Splatting is a pretty good idea for getting all of those stable angles on a scene.\n\nYou need a lot of data to get those splats though. They're real or synthetic?",
          "score": 1,
          "created_utc": "2026-01-08 11:41:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyds8xy",
          "author": "cosmicr",
          "text": "Would it be possible to produce a gaussian splat from generated images? Great idea!",
          "score": 1,
          "created_utc": "2026-01-08 11:50:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyecubg",
          "author": "Nevaditew",
          "text": "The best Lora of angles so far. Could you share the folder of all reference images? It would be easier to find them manually than to watch a GIF of them all.  \n.......\n\nit would be useful to be able to add a second reference image. For example, if I want to zoom out on a character where only their head is visible, I'd like the AI ‚Äã‚Äãto have a full-body image of the character to use as a reference. I tried several ways but I couldn't get it to work.",
          "score": 1,
          "created_utc": "2026-01-08 13:57:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyftvdi",
          "author": "Extreme-Leg-5652",
          "text": "Great work, thanks for sharing",
          "score": 1,
          "created_utc": "2026-01-08 18:00:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nymqdef",
          "author": "MistaPlatinum3",
          "text": "At last, angles work on oat pigs. I could not get move angles on this one on any qwen edit models with every angle lora. Fabulous work!!!\n\nhttps://preview.redd.it/cmd4dzx1zccg1.png?width=1217&format=png&auto=webp&s=83d6d203fac1b00e8f7323bc8643191b038f0ad6",
          "score": 1,
          "created_utc": "2026-01-09 17:27:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyyzrpd",
          "author": "Grindora",
          "text": "output i get is low res :/",
          "score": 1,
          "created_utc": "2026-01-11 13:58:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0utlx",
          "author": "yoncah",
          "text": "awesome! thanks!",
          "score": 1,
          "created_utc": "2026-01-11 19:21:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6mfu4",
          "author": "BrutalAthlete",
          "text": "Can we please get the data public too?",
          "score": 1,
          "created_utc": "2026-01-12 16:15:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8mknx",
          "author": "Current-Rabbit-620",
          "text": "Wrong title",
          "score": 1,
          "created_utc": "2026-01-07 17:57:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q94nlk",
      "title": "WOW!! I accidentally discovered that the native LTX-2 ITV workflow can use very short videos to make longer videos containing the exact kind of thing this model isn't supposed to do (example inside w/prompt and explanation itt)",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1q94nlk/wow_i_accidentally_discovered_that_the_native/",
      "author": "Parogarr",
      "created_utc": "2026-01-10 13:55:21",
      "score": 416,
      "num_comments": 213,
      "upvote_ratio": 0.97,
      "text": "BEFORE MAKING THIS THREAD, I was Googling around to see if anyone else had found this out. I thought for sure someone had stumbled on this. And they probably have. I probably just didn't see it or whatever, but I DID do my due diligence and search before making this thread.\n\nAt any rate, yesterday, while doing an ITV generation in LTX-2, I meant to copy/paste an image from a folder but accidentally copy/pasted a GIF I'd generated with WAN 2.2. To my surprise, despite GIF files being hidden when you click to load via the file browser, you can just straight-up copy and paste the GIF you made into the LTX-2 template workflow and use that as the ITV input, and it will actually go frame by frame and add sound to the GIF.\n\n**But THAT is not the reason this is useful by itself.** Because if you do that, it won't change the actual video. It'll **just add sound.**\n\nHowever, let's say you use a 2 or 3-second GIF. Something just to establish a basic motion. Let's say a certain \"position\" that the model doesn't understand. It can add time to that following along with what came before.\n\nThus, a 2-second clip of a 1girl moving up and down (I'll be vague about why) can easily become a 10-second with dialogue and the correct motion because it has the first two seconds or less (or more) as reference.\n\nIdeally, the shorter the GIF (33 frames works well) the better. The least amount you need to have the motion and details you want captured. Then of course there is some luck, but I have consistently gotten decent results in the 1 hour I've played around with this. But I have NOT put effort into making the video quality itself better. That I would imagine can be easily done via the ways people usually do it. I threw this example together to prove it CAN work.\n\nThe video output likely suffers from poor quality only because I am using much lower res than recommended.\n\n***Exact steps I used:***\n\nWan 2.2 with a LORA for ... something that rhymes with \"cowbirl monisiton\"\n\nI created a gif using 33 frames, 16fps.\n\nCopy/pasted GIF using control C and control V into the LTX-2 ITV workflow. Enter prompt, generate.\n\nUsed the following prompt: A woman is moving and bouncing up very fast while moaning and expressing great pleasure. She continues to make the same motion over and over before speaking. The woman screams, \"\\[WORDS THAT I CANNOT SAY ON THIS SUB MOST LIKELY. BUT YOU'LL BE ABLE TO SEE IT IN THE COMMENTS\\]\"\n\nI have an example I'll link in the comments on Streamable. Mods, if this is unacceptable, please feel free to delete, and I will not take it personally.\n\n*Current Goal:* Figuring out how to make a workflow that will generate a 2-second GIF and feed it automatically into the image input in LTX-2 video.\n\n***EDIT:*** if nothing else, this method also appears to **guarantee** non-static outputs. I don't believe it is capable of doing the \"static\" non-moving image thing when using this method, as it has motion to begin with and therefore cannot switch to static.\n\n***EDIT2:*** It turns out it doesn't need to be a GIF. There's a node in comfy that has an output of \"image\" type instead of video. Since MP4s are higher quality, you can save the video as a 1-2 second MP4 and then convert it that way. The node is from **VIDEO HELPER SUITE** and looks like this\n\nhttps://preview.redd.it/7bt3j4hugjcg1.png?width=445&format=png&auto=webp&s=74aa0585c18609c9ed41f5dae9f413b5acabb740\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q94nlk/wow_i_accidentally_discovered_that_the_native/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "nyshsux",
          "author": "Responsible_Back_473",
          "text": "Title: major technology breakthrough.¬†\nContent: p*rn.",
          "score": 276,
          "created_utc": "2026-01-10 14:33:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyslamz",
              "author": "Touitoui",
              "text": "Are there any other kind of major breakthroughs?",
              "score": 97,
              "created_utc": "2026-01-10 14:52:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nytvopl",
                  "author": "HardenMuhPants",
                  "text": "as the name suggests, the major breakthrough is in my pants.",
                  "score": 35,
                  "created_utc": "2026-01-10 18:37:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyvkh1g",
                  "author": "Dragon_yum",
                  "text": "Yes but you won‚Äôt find them here",
                  "score": 2,
                  "created_utc": "2026-01-10 23:40:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyt10jn",
              "author": "Keyflame_",
              "text": "80% of the progress on diffusion AI is made by hornballs, let them be hornballs. They make progress for the rest of us.",
              "score": 82,
              "created_utc": "2026-01-10 16:12:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyufyrt",
                  "author": "Olangotang",
                  "text": "*Furries",
                  "score": 6,
                  "created_utc": "2026-01-10 20:15:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyyl5gv",
                  "author": "South_Two_5657",
                  "text": "It's like they say.. \"Horniness is there mother of invention\".",
                  "score": 1,
                  "created_utc": "2026-01-11 12:16:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyuqj0n",
                  "author": "suspicious_Jackfruit",
                  "text": "This is a really naive take that is parroted on here regularly and is simply wrong and confirmation bias. I would imagine next to 0.0001% of diffusion papers with breakthrough techniques and models are created with porn creation as the target, in fact as you know, most models actively try and avoid it. You can enjoy your prawn toast all you want but don't kid yourself into thinking it's some sort of scientific progress to bust a nut to bouncy 1girls all day",
                  "score": -9,
                  "created_utc": "2026-01-10 21:08:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyt6r9l",
              "author": "Sadale-",
              "text": "What else we're gonna use video generation models for?",
              "score": 21,
              "created_utc": "2026-01-10 16:40:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyw606r",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": -4,
                  "created_utc": "2026-01-11 01:34:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyshx34",
              "author": "Parogarr",
              "text": "lmao",
              "score": 26,
              "created_utc": "2026-01-10 14:33:48",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nytn4ba",
              "author": "Arkrus",
              "text": "Honestly, whatever drives the breakthroughs doesn't matter, as long as its nothing totally vile.",
              "score": 2,
              "created_utc": "2026-01-10 17:57:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyuy7qv",
              "author": "LQ-69i",
              "text": "Jokes aside, I have to thank the gooning community and all the degenerates on the internet for most of the workflows, models and the passion the give/provide to the open source generative field and how accessible they make it for others",
              "score": 1,
              "created_utc": "2026-01-10 21:46:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nywiedd",
              "author": "Ylsid",
              "text": "It checks out",
              "score": 1,
              "created_utc": "2026-01-11 02:41:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyubqxq",
              "author": "Clarku-San",
              "text": "Reads like r/copypasta",
              "score": 1,
              "created_utc": "2026-01-10 19:54:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyse4qg",
          "author": "Justify_87",
          "text": "Tldr:\n\n- LTX-2 ITV accepts animated GIFs via copy & paste, even though GIFs are hidden in the file dialog.\n- The workflow reads the GIF frame by frame and adds audio.\n- Very short GIFs (2‚Äì3 seconds, ~33 frames) can be extended into much longer videos with consistent motion.\n- This effectively lets you ‚Äúteach‚Äù the model motion patterns it normally struggles with.\n- Clean, minimal motion clips give the best results.\n- Goal: build a workflow that auto-generates a short GIF and feeds it directly into LTX-2.\n- Side effect: outputs are never static, since motion is always present.",
          "score": 154,
          "created_utc": "2026-01-10 14:12:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nysebi9",
              "author": "Parogarr",
              "text": "Yes, thank you! \n\nI'm trying to figure out how to combine my wan and LTX workflows together so I don't have to keep going back and forth.",
              "score": 20,
              "created_utc": "2026-01-10 14:13:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nytt2vw",
                  "author": "No_Damage_8420",
                  "text": "that was GPT :)",
                  "score": 4,
                  "created_utc": "2026-01-10 18:25:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nysh24y",
              "author": "Parogarr",
              "text": "(DON'T GO TO THIS URL UNLESS YOU ARE WILLING TO SEE SOMETHING SPICY)\n\nHere is an example of how my recent generation came out after upping to 720p. Keep in mind my prompt is shit. With a better prompt, I'd likely get better results. But this is a huge shift in the direction I'd like to go. It's putting together the pieces to have WAN 2.2 output with sound and speaking\n\n(WARNING: DON'T BE AT WORK)\n\n[https://streamable](https://streamable) DOT com SLASH xdfcx6",
              "score": 24,
              "created_utc": "2026-01-10 14:28:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nysl8ig",
                  "author": "GaiusVictor",
                  "text": "UNH, UHN, UHN, AHH, AHH, AHH, AHH\n\nThe dialogue is impressive, though. Not convincing, but impressive.",
                  "score": 34,
                  "created_utc": "2026-01-10 14:52:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nysl55f",
                  "author": "yoomiii",
                  "text": "sounds like a monkey haha",
                  "score": 37,
                  "created_utc": "2026-01-10 14:51:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nysnwdq",
                  "author": "Draufgaenger",
                  "text": "Damn... and I have just the workflow to turn THIS into VR180 3D... I guess I know what I'm testing tonight for science",
                  "score": 13,
                  "created_utc": "2026-01-10 15:06:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyshugu",
                  "author": "Parogarr",
                  "text": "Note: I am rushing these out for proof of concept using garbage prompts and the first thing that generates. I'm **SURE** quality and outcome can be vastly better than this with more dialogue and stuff happening up to 20 seconds long. But the most positive thing I've noticed remains to be that I have now completely eliminated even the possibility of getting a static image.\n\n*ANOTHER WAY* of using this is to take an image you want to do i2v, extend it to just 2 seconds as a GIF (or even 1.5 seconds, anything to get motion) and then use that as the base for the generation. This will guarantee non-static output.",
                  "score": 8,
                  "created_utc": "2026-01-10 14:33:24",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nysx42d",
                  "author": "hurrdurrimanaccount",
                  "text": "lmao that's awful quality",
                  "score": 3,
                  "created_utc": "2026-01-10 15:54:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nysjl0q",
                  "author": "Open-Leadership-435",
                  "text": "# There's nothing here! <== it doesn't work :(",
                  "score": -11,
                  "created_utc": "2026-01-10 14:43:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nysnmb1",
              "author": "Draufgaenger",
              "text": "I think it was well worth the read :)",
              "score": 6,
              "created_utc": "2026-01-10 15:05:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyslp1q",
          "author": "skyrimer3d",
          "text": "Translation: it took us 5 days to hack pr0n into a video model that didn't know a thing about it, love this community. I mean seriously, thanks OP.",
          "score": 109,
          "created_utc": "2026-01-10 14:54:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyul0yh",
              "author": "Murky-Relation481",
              "text": "It definitely knows about it, its just lacking a lot of understanding. Basically it has the sex education of someone raised in Alabama vs. the rest of the developed world.",
              "score": 11,
              "created_utc": "2026-01-10 20:41:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyum74k",
                  "author": "PentaOwl",
                  "text": "It is supposed to go in the ear, right?",
                  "score": 8,
                  "created_utc": "2026-01-10 20:47:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nysq2ht",
          "author": "Parogarr",
          "text": "https://preview.redd.it/lwadtxb0hjcg1.png?width=445&format=png&auto=webp&s=b0f2f3fe122214323c9ac11ba5c6d6f5267ac46e\n\n  \nThis node will let you use MP4s which make even higher quality videos since GIF has weird compression shit going on.\n\nIt's from the Video Helper Suite.",
          "score": 26,
          "created_utc": "2026-01-10 15:18:24",
          "is_submitter": true,
          "replies": [
            {
              "id": "nyt4sn1",
              "author": "GasolinePizza",
              "text": "The builtin \"Load Video\" works fine for loading MP4s, you don't need custom nodes for this.",
              "score": 5,
              "created_utc": "2026-01-10 16:30:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyt52q3",
                  "author": "Parogarr",
                  "text": "How do you connect the nodes though the output type then doesn't match input.\n\n  \nEDIT: Referring to this \n\nhttps://preview.redd.it/vs83p9qeujcg1.png?width=109&format=png&auto=webp&s=342e497a169a0c13a74a0f6523962380ab158e20",
                  "score": 3,
                  "created_utc": "2026-01-10 16:32:06",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nysuu7c",
              "author": "LiveLaughLoveRevenge",
              "text": "Thanks - I was just testing this myself and also battling the GIF compression effects!  \n\nWill try this now too.\n\nI'm also trying to just use image/webp as the file format export from WAN (using VHS video combine node) and it seems to work too?  I need to test a bit more",
              "score": 2,
              "created_utc": "2026-01-10 15:42:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nysy7ig",
          "author": "Perfect-Campaign9551",
          "text": "Someone already did this with Jensen Huang video and continued the video but they didn't share how. Gate keeping lol\n\nAlso you could literally just load a video in Comfy and then there is a node to select only certain number of frames, you could use that instead of trying to make a short 2 second video",
          "score": 22,
          "created_utc": "2026-01-10 15:59:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nysyzzi",
              "author": "Parogarr",
              "text": "Yes, I realize that now. Apologies for my ignorance. There are a lot of things I don't know.",
              "score": 14,
              "created_utc": "2026-01-10 16:03:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyt00sr",
                  "author": "Perfect-Campaign9551",
                  "text": "Nope I appreciate your post since that other guy didn't share how he did it",
                  "score": 17,
                  "created_utc": "2026-01-10 16:08:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyxeez4",
              "author": "hugo4711",
              "text": "Wasn‚Äôt that made with the V2V workflow?",
              "score": 2,
              "created_utc": "2026-01-11 05:57:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyuysl6",
              "author": "Maskwi2",
              "text": "I hope someone finds the way soon :)¬†",
              "score": 1,
              "created_utc": "2026-01-10 21:49:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nysh2z1",
          "author": "Parogarr",
          "text": "(DON'T GO TO THIS URL UNLESS YOU ARE WILLING TO SEE SOMETHING SPICY)\n\nHere is an example of how my recent generation came out after upping to 720p. Keep in mind my prompt is shit. With a better prompt, I'd likely get better results. But this is a huge shift in the direction I'd like to go. It's putting together the pieces to have WAN 2.2 output with sound and speaking\n\n(WARNING: DON'T BE AT WORK)\n\n[https://streamable](https://streamable) DOT com SLASH xdfcx6",
          "score": 12,
          "created_utc": "2026-01-10 14:29:04",
          "is_submitter": true,
          "replies": [
            {
              "id": "nysu28c",
              "author": "Anaalmoes",
              "text": "Opened it at work, regret nothing. This does open some opportunities, especially if you can combine it with wans movement.",
              "score": 4,
              "created_utc": "2026-01-10 15:39:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nysu7vb",
                  "author": "Parogarr",
                  "text": "I've been getting much better outputs since I switched from GIF to MP4 using the video suite node. GIF actually lowers the quality badly.",
                  "score": 7,
                  "created_utc": "2026-01-10 15:39:48",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nytvw9c",
              "author": "lordpuddingcup",
              "text": "any other examples... for research what else can it handle?",
              "score": 1,
              "created_utc": "2026-01-10 18:38:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nysitke",
          "author": "goddess_peeler",
          "text": "Are we just talking about giving an I2V workflow a batch of input images instead of a single one? \n\nYes, that is something you can do. You don‚Äôt have to use animated gifs.",
          "score": 10,
          "created_utc": "2026-01-10 14:38:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nysjfwt",
              "author": "goddess_peeler",
              "text": "https://www.reddit.com/r/StableDiffusion/comments/1q7uq7y/comment/nyiuonk/",
              "score": 3,
              "created_utc": "2026-01-10 14:42:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nysj1cc",
              "author": "Parogarr",
              "text": "I tried doing this using WAN 2.2 ITV and it doesn't work. The GIF causes errors. So I think LTX-2 might have capability that WAN 2.2 doesn't in regard to creating a short video as a GIF and using that as the input.",
              "score": 1,
              "created_utc": "2026-01-10 14:40:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nytb7x3",
                  "author": "physalisx",
                  "text": "No, it just takes the input frames like every other model. You're not giving a \"GIF\" to the model, you're handing it a batch of frames.",
                  "score": 4,
                  "created_utc": "2026-01-10 17:01:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nysdvrr",
          "author": "LiveLaughLoveRevenge",
          "text": "Interesting thing here is that people keep talking about how WAN gives better results, but LTX runs better and has sound.  This sounds like it has potential to really combine the best of both worlds, albeit in a complex workflow.",
          "score": 14,
          "created_utc": "2026-01-10 14:10:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nysmrfg",
          "author": "PromptAfraid4598",
          "text": "https://preview.redd.it/rt2roz4xdjcg1.png?width=2324&format=png&auto=webp&s=06633377ae9932f494687741df87bdf86a929542",
          "score": 14,
          "created_utc": "2026-01-10 15:00:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyyjb5r",
              "author": "ANR2ME",
              "text": "i wondered how audio-to-audio works ü§î was it extending the audio? or may be can add voices (lyrics) into a music?",
              "score": 1,
              "created_utc": "2026-01-11 12:01:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyt19mg",
          "author": "Keyflame_",
          "text": ">Thus, a 2-second clip of a 1girl moving up and down (I'll be vague about why) can easily become a 10-second with dialogue and the correct motion because it has the first two seconds or less (or more) as reference.\n\n![gif](giphy|xMn70dXhSnwioa0XtX)",
          "score": 16,
          "created_utc": "2026-01-10 16:14:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyt6ggh",
          "author": "Parogarr",
          "text": "***UPDATE:*** Using this method (GIF or just loading the first 17 frames of an MP4 or however you wanna do it) lets you **completely** disable the image compression. The quality seems higher except for the woman's face here, but I believe that's because it's a distance shot. I'm going to try for a closer shot and see if that gives me the kind of result I actually like\n\n[https://streamable](https://streamable) DOT com SLASH aynxj6\n\n(DO NOT WATCH IF AT WORK)",
          "score": 7,
          "created_utc": "2026-01-10 16:38:36",
          "is_submitter": true,
          "replies": [
            {
              "id": "nyt6srz",
              "author": "Parogarr",
              "text": "u/IONaut \n\nyour idea was really good. Starting new thread because I can't find you anymore lol. Disabling the image compression definitely helps, and like we hypothesized, I don't believe there is any downside since there is information spread across 9 or 17 frames (starting to think/believe 17 is the sweet spot)",
              "score": 3,
              "created_utc": "2026-01-10 16:40:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyt74dg",
                  "author": "IONaut",
                  "text": "Nice!",
                  "score": 3,
                  "created_utc": "2026-01-10 16:41:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nytl89i",
          "author": "Parogarr",
          "text": "Okay I think I'm happy with where I've gotten things.\n\n\\#1: Disable this node (if you're using a video input)\n\nhttps://preview.redd.it/8cnj8p33yjcg1.png?width=758&format=png&auto=webp&s=5fbd7c58572bfcb9c4135931dd8f8b449e63b607\n\nAll this does is decrease the quality and doesn't even work anyway because when I was doing ITV on static images they gave me static results even **with** this fucking thing lmao. And since you're going to be using multiple frames of video, it doesn't need this anymore to make motion happen.\n\n\\#2: Try to stick to 17 frames. That seems to be the sweet spot. Maybe a bit longer if the motion/maneuver isn't quite catching on. I've found 17-33 to be the best\n\n\\#3: **RESULT**\n\n**(PEOPLE AT WORK DO NOT CLICK THIS.**\n\n**DO NOT CLICK IF AT WORK.**\n\n**DO NOT CLICK IF NEAR KIDS)**\n\n[**https://streamable.com/9zdddk**](https://streamable.com/9zdddk)\n\n(***WARNING DON'T WATCH IF AT WORK)***\n\n**Conclusion**: Using WAN 2.2 to generate a 17-frame video enables LTX-2 to be used to do anything WAN 2.2 can do but with sound until LTX-2 finally gets better LORAs or whatever. However, the **raw quality** will never be able to match WAN 2.2, but that's a sacrifice that must be made for sound.",
          "score": 7,
          "created_utc": "2026-01-10 17:49:00",
          "is_submitter": true,
          "replies": [
            {
              "id": "nyx577s",
              "author": "doctor_house_md",
              "text": "I was at work, now I'm unemployed, making goon vids",
              "score": 2,
              "created_utc": "2026-01-11 04:52:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nysu2md",
          "author": "wumr125",
          "text": "Cutting edge gooning",
          "score": 11,
          "created_utc": "2026-01-10 15:39:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyuusjf",
              "author": "Maskwi2",
              "text": "I learned that word like few days ago on this forum. Albo booba.\nI like both now.¬†",
              "score": 1,
              "created_utc": "2026-01-10 21:29:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nysd3m5",
          "author": "Spamuelow",
          "text": "I havent tried ltx yet but had been wondering about stuff like this from what ive seen in bits from people talking about it (ltx).\n\nDoes it voice clone? So it will continue a video with what you tell them to say in the prompt but the same voice from an input video?",
          "score": 4,
          "created_utc": "2026-01-10 14:06:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nysiedu",
              "author": "IONaut",
              "text": "Kijai has a workflow that allows you to input audio. I took his audio input portion and added it into the subgraph in the standard image to video workflow provided by comfy. Now I have a workflow where I can use clone voices from VibeVoice or even music and the character will lip sync it. Next I want to add a VibeVoice node in the workflow so there's no back and forth at all.",
              "score": 11,
              "created_utc": "2026-01-10 14:36:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nysioze",
                  "author": "Spamuelow",
                  "text": "Im gonna try making some alternate film scenes, see how well it does",
                  "score": 5,
                  "created_utc": "2026-01-10 14:38:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nytk7ny",
                  "author": "djtubig-malicex",
                  "text": "I ported the important bits from kijai's audio example into the Lightricks LTX2 I2V workflow and exposed some extra controls on the subgraph to choose between using the input audio or just generating new audio.\n\nhttps://pastebin.com/BVvDH1Rb",
                  "score": 3,
                  "created_utc": "2026-01-10 17:44:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nysyzyo",
                  "author": "Perfect-Campaign9551",
                  "text": "Don't do it - VibeVoice is a huge RAM leaker, it will probably start causing OOMs",
                  "score": 2,
                  "created_utc": "2026-01-10 16:03:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nytczk4",
                  "author": "Fluffy-Maybe-5077",
                  "text": "What about chatterbox it should be way faster than vibevoice",
                  "score": 1,
                  "created_utc": "2026-01-10 17:09:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nysitui",
                  "author": "Parogarr",
                  "text": "Can that be combined with this? This is mostly useful for getting correct motion. Even 1 second of motion is probably enough. I'm going to experiment with just 16 frames. It seems like the shorter the input, the less VRAM overhead anyway.",
                  "score": 1,
                  "created_utc": "2026-01-10 14:38:58",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nysdgw9",
              "author": "Parogarr",
              "text": "I'm not sure.",
              "score": 0,
              "created_utc": "2026-01-10 14:08:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyse3xz",
                  "author": "redditscraperbot2",
                  "text": "It actually does voice clone you can vae encode the audio too",
                  "score": 5,
                  "created_utc": "2026-01-10 14:12:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyswbw8",
          "author": "FrenzyXx",
          "text": "I read somewhere you can also use reference images for specific time stamps, FFLF kind of, but theoretically also for a middle frame etc.. Anybody know more about this?",
          "score": 4,
          "created_utc": "2026-01-10 15:50:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nytc3pw",
              "author": "martinerous",
              "text": "[https://www.reddit.com/r/StableDiffusion/comments/1q7gzrp/ltx2\\_multi\\_frame\\_injection\\_works\\_minimal\\_clean/](https://www.reddit.com/r/StableDiffusion/comments/1q7gzrp/ltx2_multi_frame_injection_works_minimal_clean/)",
              "score": 1,
              "created_utc": "2026-01-10 17:05:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nytrp2j",
                  "author": "FrenzyXx",
                  "text": "Thank you",
                  "score": 1,
                  "created_utc": "2026-01-10 18:19:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyy15nv",
          "author": "Abject-Recognition-9",
          "text": "https://preview.redd.it/9pp9aruepocg1.png?width=585&format=png&auto=webp&s=bbadfbd6e4a185037a45cade6c5e5c7cb9ddbbb7\n\ncongrat you found one of my first and favourite LTX2 use :)  \nlet me add some info for random readers:  \nhere my settings for 10 seconds vid (249 frames):  \nit use 0,5 audio/video from the start,  and 3 seconds at the end  \n(so basically inpainting the middel section)  \nenough to learn the concept, movement and voice type  \nand to keep the movement consistet through the entire clip (start/end)  \nif i want a different ending (so inpainting the end only) i just simply change the \"end\\_time\" to exceed the total amount of frames.  \ni'm using short AI generated videos as input, to extend them, those are usually shorter than 10seconds  \nso i duplicate the input to match the total length as showed in the next pic",
          "score": 4,
          "created_utc": "2026-01-11 09:16:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyy1f3r",
              "author": "Abject-Recognition-9",
              "text": "https://preview.redd.it/tp9q1cbqtocg1.jpeg?width=2415&format=pjpg&auto=webp&s=af41f3537c2d6e0ad2e4c0cbebcef093c770ad6c",
              "score": 1,
              "created_utc": "2026-01-11 09:18:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyy7hdg",
                  "author": "kaiyoti",
                  "text": "can you share the json file for this?",
                  "score": 1,
                  "created_utc": "2026-01-11 10:15:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz9im55",
              "author": "GrungeWerX",
              "text": "Can you share some video examples so we can see the results? (That will determine if I toss this into my to-study list. I've already got a huge backlist I'm going through as I type this)",
              "score": 1,
              "created_utc": "2026-01-13 00:30:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nysci06",
          "author": "rookan",
          "text": "Cna you share your workflow file?",
          "score": 9,
          "created_utc": "2026-01-10 14:02:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyt7hli",
          "author": "Odd-Mirror-2412",
          "text": "That's right. This model has potential as V2A model. With fine-tuning, we can achieve even better results!",
          "score": 3,
          "created_utc": "2026-01-10 16:43:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nysjzf1",
          "author": "WildSpeaker7315",
          "text": "hmm i been uploading 161 frames from wan videos but a gif could be interesting",
          "score": 2,
          "created_utc": "2026-01-10 14:45:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nysk7ly",
              "author": "Parogarr",
              "text": "How is that done? I searched for V2V workflows but didn't find any.",
              "score": 1,
              "created_utc": "2026-01-10 14:46:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyskmy4",
                  "author": "WildSpeaker7315",
                  "text": "this is my workflow..\n\n[https://files.catbox.moe/tmfi76.json](https://files.catbox.moe/tmfi76.json)\n\nits nothing sepcial at all, just bare in mind it has to be 8x+1 frames, i.e 9 / 17 / 81/161",
                  "score": 5,
                  "created_utc": "2026-01-10 14:49:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nysq0x5",
          "author": "Machspeed007",
          "text": "Yep, you can also load mp4 videos but it only ads audio to the movie as far as I can tell, no modifications to the original movie, which would have been great. I'm using the VHS node Load Video which has an image output and just connect that to the I2V LTX2 workflow.\n\nIt can be used to lengthen the original videos just that the characters don't sync with the speech audio at all.",
          "score": 2,
          "created_utc": "2026-01-10 15:18:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nysqi8u",
              "author": "Parogarr",
              "text": "Using this right?\n\nhttps://preview.redd.it/mel654mdhjcg1.png?width=445&format=png&auto=webp&s=e91305000092f00cad6b2ce6aa3c1857d388cdfe\n\nI just updated OP to say this can be done as you wrote that. It's amazing how much better LTX-2 is now. The ITV by default is DOA imho. Just static ouput 90% of the time for me until you feed it a short video\n\nEDIT: Yeah, it only adds audio. But that's why the goal is to generate only about a second or two. Just so that LTX-2 knows what you want. It's almost the same as ITV except now it knows motion. I'm starting to find that 1 second is better than 2 as well.",
              "score": 1,
              "created_utc": "2026-01-10 15:20:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyssivr",
                  "author": "Machspeed007",
                  "text": "yes, that one. What's nice about this node is that you can easily skip the first n frames for any movie and load the last lets say 65 frames. The total number of frames of the movie is displayed with dark grey in the frame\\_load\\_cap field you just substract 65 frames from that and put the result in the skip\\_first\\_frames field.",
                  "score": 3,
                  "created_utc": "2026-01-10 15:31:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nythdfw",
          "author": "97buckeye",
          "text": "Did I see someone mention using LTX to give audio to a video you've already created in Wan 2.2? If so, how does that work? I don't want to extend the original video, just give it audio.",
          "score": 2,
          "created_utc": "2026-01-10 17:30:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nytja3d",
              "author": "Parogarr",
              "text": "That's actually really easy. Just set the length of the video = to the video you're inputting. The video will remain 100% the same but have audio. However, don't expect mouths to move. Dialogue won't sync. It won't change the source video AT ALL.",
              "score": 3,
              "created_utc": "2026-01-10 17:39:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyub6nd",
          "author": "Emergency-Support535",
          "text": "Crazy find! Thanks for sharing this detailed workflow. Definitely going to try the short GIF method for more dynamic video outputs. Appreciate it!",
          "score": 2,
          "created_utc": "2026-01-10 19:51:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyuur17",
          "author": "Radiant_Teaching_811",
          "text": "I'm having pretty good hitrate with a simple prompt and using very different WAN created inputs.   \nI'm using a bit of ahead of the curve portable install with working separated files, Distilled Q8 unet (20GB) and Gemma3 GGUFs (Q3 \\~5GB / Q4 \\~7GB depending on model), there are even smaller ones. Using the LTX-2 workflow (I have promoted some settings to be on the top level). 64GB RAM and 16GB 5070 Ti. Final times some 80 sec for 193 frames / 24 fps.\n\nhttps://preview.redd.it/p9ytx0qoalcg1.png?width=1006&format=png&auto=webp&s=37c244d09525189d6cf057e2e909d2d91c8dbdb9",
          "score": 2,
          "created_utc": "2026-01-10 21:29:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nywrmov",
              "author": "Machspeed007",
              "text": "What node do you use to losd gemma3 gguf?",
              "score": 1,
              "created_utc": "2026-01-11 03:32:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz02g1s",
                  "author": "Radiant_Teaching_811",
                  "text": "For this to work I needed to merge PR #399 and #402 of the City96 GGUF custom node. This will likely be merged officially if it's not already done. I made a new folder for these as I've also copied the tokenizer.model and gemma\\_3\\_12B\\_it\\_mmproj.gguf as the model might need these two.\n\nhttps://preview.redd.it/hfsp6mi76rcg1.png?width=688&format=png&auto=webp&s=216c3c343d4b631131173023d39fac65a85dd31a",
                  "score": 2,
                  "created_utc": "2026-01-11 17:13:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyxeocm",
          "author": "Dry_Positive8572",
          "text": "So basically LTX-2 I2V does support v2v even though developers never officially announce v2v.",
          "score": 2,
          "created_utc": "2026-01-11 05:58:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nysbc4d",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-10 13:56:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nysc73c",
              "author": "protector111",
              "text": "you better delete this coment or you post is going down.",
              "score": 2,
              "created_utc": "2026-01-10 14:01:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyscifw",
                  "author": "Parogarr",
                  "text": "okay, deleted it. I just wanted to show some proof that it works.",
                  "score": 2,
                  "created_utc": "2026-01-10 14:02:55",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nysdppe",
                  "author": "Parogarr",
                  "text": "Hey, quick ?\n\n  \nIf I do that thing where I link but don't have the link hyperlinked (meaning I put a space and then put the end of the link) would that be okay? Because then I'm not directly linking.",
                  "score": 1,
                  "created_utc": "2026-01-10 14:09:53",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nysbguo",
              "author": "Parogarr",
              "text": "I'm gonna attempt to generate the GIF at 1280X720 instead of 800x800 and then use 1280x720 in LTX2 instead of 800x800",
              "score": 1,
              "created_utc": "2026-01-10 13:56:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyscyv8",
                  "author": "Parogarr",
                  "text": "Wow! Quality goes up A LOT when using 720p as a base. A LOT. I wish I could share examples. Is there a way I can?",
                  "score": 2,
                  "created_utc": "2026-01-10 14:05:33",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nysknw6",
          "author": "Hopeful_Signature738",
          "text": "Coward Musician?",
          "score": 1,
          "created_utc": "2026-01-10 14:49:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nysksvc",
              "author": "Parogarr",
              "text": "Almost.\n\n  \nAnother hint: BowBurl Gozition Fex",
              "score": 1,
              "created_utc": "2026-01-10 14:50:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyt4abs",
          "author": "GasolinePizza",
          "text": "...aka temporal extension/outpainting.\n\nLTX supporting that isn't new, but the NSFW affinity might be the new part, here (at least to me)",
          "score": 1,
          "created_utc": "2026-01-10 16:28:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyt7cd4",
              "author": "Parogarr",
              "text": "I'm finding 17 frames to be the sweet spot. 9 is too short / not enough info and 33 causes the video to change too much and lose consistency. But what I do like about this is that #1: it guarantees you almost never have a static output (haven't had one yet) and #2: you can get rid of the image compression node.",
              "score": 5,
              "created_utc": "2026-01-10 16:42:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyu0f05",
                  "author": "GasolinePizza",
                  "text": "I might try that out. I messed around with a pure V2V flow earlier and was just trying to add audio with it this morning, after a friend asked, but had zero luck.\n\n(Although I did get some really goddamn funny sound effects, as if sex was a Batman comic complete with comical \"capow\" sounds on-impact).\n\nDo you use explicit text prompts, or have you usually been playing the sly \"she's just trying to push him over with a hip tug of war fight\" kind of thing?\n\nI'm curious whether the community will either have LTX eventually break via loras or end up being a \"not technically explicit\"-description kinda prompt + a explicit seed-frames/clip route",
                  "score": 1,
                  "created_utc": "2026-01-10 18:59:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyto7lo",
          "author": "FlyingAdHominem",
          "text": "Now where to find good starting vids, ü§î.",
          "score": 1,
          "created_utc": "2026-01-10 18:02:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nytpfuw",
              "author": "Parogarr",
              "text": "make 'em with Wan 2.2",
              "score": 3,
              "created_utc": "2026-01-10 18:08:39",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nyyk3b4",
              "author": "ANR2ME",
              "text": "p0rnhub üòè",
              "score": 1,
              "created_utc": "2026-01-11 12:07:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyty36f",
          "author": "jhnprst",
          "text": "so this would open up the way to extend ltx-2 videos by feeding last X frames as start of next iteration, wonder how long many iterations that would last, WAN deteriorates after a few iterations..",
          "score": 1,
          "created_utc": "2026-01-10 18:48:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyuiqsi",
          "author": "ArtfulGenie69",
          "text": "This sounds like the video version of how you can diffuse in krita over and over and even with a bad model it does better each time with what it did. Very cool that multiple images can guide the full gen like the this.\n\n\nOne more thing for someone to try as well... LTX2 should be a first frame last frame model. If you can send the start with multiple frames can you seed the end too? One or the other or both at once? You could have a lot of control with two videos.¬†",
          "score": 1,
          "created_utc": "2026-01-10 20:29:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyur8te",
          "author": "Choowkee",
          "text": "This combined with the uncensored text encoder is a big step forward. Really starting to see the potential with LTX2.",
          "score": 1,
          "created_utc": "2026-01-10 21:12:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyuupm6",
              "author": "Parogarr",
              "text": "uncensored TE? Any idea how I can get that please?",
              "score": 1,
              "created_utc": "2026-01-10 21:29:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyuv4sl",
                  "author": "Choowkee",
                  "text": "https://civitai.com/models/2292336/ltx-2-nsfw-text-encoder-gemma-3-12b-abliterated",
                  "score": 2,
                  "created_utc": "2026-01-10 21:31:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyuuuky",
          "author": "nadhari12",
          "text": "For the love of god I cannot keep the face consistent on i2V did anyone face the same issue?",
          "score": 1,
          "created_utc": "2026-01-10 21:30:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyuwnaf",
              "author": "Radiant_Teaching_811",
              "text": "Check if any of my above settings make a change, try lowering the image compression.",
              "score": 1,
              "created_utc": "2026-01-10 21:39:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyvgs3u",
          "author": "Sunnytoaist",
          "text": "Where does one go as a complete beginner to learn this stuff ?",
          "score": 1,
          "created_utc": "2026-01-10 23:20:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyx5osv",
              "author": "doctor_house_md",
              "text": "I would try asking Perplexity",
              "score": 1,
              "created_utc": "2026-01-11 04:55:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nywxrx7",
          "author": "NES64Super",
          "text": "Any idea how to extend audio?",
          "score": 1,
          "created_utc": "2026-01-11 04:08:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nysdo68",
          "author": "intermundia",
          "text": "Well this is certainly an interesting stroke if accidental genius. But now to replicate it. Hmm",
          "score": 1,
          "created_utc": "2026-01-10 14:09:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nysdw1u",
              "author": "Parogarr",
              "text": "It's easy. Just copy/paste a GIF into the load image thing. You can't do it via clicking and file browser. It won't accept GIFs that way. But pressing the node and then Control V for some reason works.",
              "score": 3,
              "created_utc": "2026-01-10 14:10:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nysjm2o",
                  "author": "fauni-7",
                  "text": "Copy from where? A web browser?",
                  "score": 1,
                  "created_utc": "2026-01-10 14:43:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyt5xjy",
          "author": "madhu_23",
          "text": "Can I run this smoothly on NVIDIA 3060 RTX 12 VRAM ?  I want LTX model but I don't have better graphics card",
          "score": 1,
          "created_utc": "2026-01-10 16:36:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyuwbrw",
              "author": "desktop4070",
              "text": "How much desktop memory? I recall some comments saying 48GB or 64GB desktop RAM is more important for LTX-2 than having 12GB or 16GB VRAM, but I might be mistaken.",
              "score": 1,
              "created_utc": "2026-01-10 21:37:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nysjg99",
          "author": "fauni-7",
          "text": "I dragged and dropped a gif and got this: \"LTXVImgToVideoInplace\n\nInvalid number of frames: Encode input must have 1 + 8 \\* x frames (e.g., 1, 9, 17, ...). Please check your input.\"",
          "score": 0,
          "created_utc": "2026-01-10 14:42:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyt5bzu",
              "author": "GasolinePizza",
              "text": "The number of frames still has to match the `8*n + 1` constraint. Nothing to do with GIF or not, it's the amount of frames you're passing in",
              "score": 2,
              "created_utc": "2026-01-10 16:33:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyskhdj",
              "author": "Parogarr",
              "text": "Don't drag and drop that doesn't work either. You have to press Control C on the GIF file itself. Then left click the node. And press Control V.",
              "score": 1,
              "created_utc": "2026-01-10 14:48:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyslzex",
                  "author": "fauni-7",
                  "text": "Ctrl+c where?",
                  "score": 2,
                  "created_utc": "2026-01-10 14:56:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q1k0ee",
      "title": "The out-of-the-box difference between Qwen Image and Qwen Image 2512 is really quite large",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/mo50p0dkztag1.png",
      "author": "ZootAllures9111",
      "created_utc": "2026-01-02 00:32:03",
      "score": 415,
      "num_comments": 107,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q1k0ee/the_outofthebox_difference_between_qwen_image_and/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nx8qkby",
          "author": "Contigo_No_Bicho",
          "text": "How much VRAM and RAM does Qwen 2512 require? Can you share workflow?",
          "score": 14,
          "created_utc": "2026-01-02 12:19:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx9v60h",
              "author": "ThatsALovelyShirt",
              "text": "Something like 28GB for FP8, less than that for smaller quants. Might be able to use block swap to get FP8 on 24GB VRAM. Not sure.",
              "score": 10,
              "created_utc": "2026-01-02 16:13:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxak9a7",
              "author": "ectoblob",
              "text": "You don't need a new / custom workflow just use the same workflow as you use with older Qwen image model version.",
              "score": 1,
              "created_utc": "2026-01-02 18:10:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx65o5s",
          "author": "ZootAllures9111",
          "text": "Prompt:\n>a candid amateur photograph of a young Caucasian woman in her early to mid-20s with vibrant, long, straight, fiery red-orange hair cascading over her shoulders. She is positioned center-right, looking directly at the camera with a playful expression. Her head is tilted left, her right hand resting on her head, fingers pushing into her hair. She has light green eyes with bold, black winged eyeliner, shaped dark brown eyebrows, and light freckles across her nose and cheeks. She wears a strapless, form-fitting top in a dark brown color. Visible tattoos include a large black and grey sunflower on her right forearm; a circular design in an ornate, baroque-style frame below her right elbow; a small, partially visible dark tattoo on her left shoulder; and a sun with a face rising above clouds on her lower left arm. She is outdoors under a covered porch/awning attached to a building with light beige vertical siding and a paneled metal roof. In the background is a white-framed window, a chain-link fence, and a grassy area. String lights with black, wireframe, geometric diamond shades hang from the awning, and a traditional brass wall lantern is mounted on the wall. The ground has dry grass, a white gutter downspout with a black shovel leaning at its base. The upper left corner shows a blue sky with wispy clouds. The photo is taken in bright, natural daylight. The shallow depth of field, sharp focus, and high-angle perspective suggest a smartphone selfie.  \n\nSeed: 411478554767843  \nCFG: 4  \nSampler / Scheduler: DPM++ 2S Ancestral Linear Quadratic  \n50 steps for both @ native 1140x1472, using the BF16 versions of both models.",
          "score": 27,
          "created_utc": "2026-01-02 00:34:01",
          "is_submitter": true,
          "replies": [
            {
              "id": "nx7vyp0",
              "author": "fauni-7",
              "text": "What was your shift value BTW?",
              "score": 3,
              "created_utc": "2026-01-02 07:39:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx82byf",
                  "author": "ZootAllures9111",
                  "text": "just standard 3.5. I think the new 2512 workflow generally has it at 3.1 though, not sure how much of a difference it would make on either.",
                  "score": 3,
                  "created_utc": "2026-01-02 08:39:35",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx7m30f",
              "author": "fauni-7",
              "text": "Looks good. Do you not get the texture effect with the bf16?\nYesterday I actually had a lot of fun with 2512, it's a huge improvement.\nI like uni_pc. Using gguf Q8.",
              "score": 1,
              "created_utc": "2026-01-02 06:12:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx7su6o",
                  "author": "ZootAllures9111",
                  "text": "BF16 is closest to like, the disassembled diffusers original AFAIK",
                  "score": 2,
                  "created_utc": "2026-01-02 07:10:28",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nx7n1lz",
                  "author": "protector111",
                  "text": "Fp16 is clean. Fp8 is bad",
                  "score": 1,
                  "created_utc": "2026-01-02 06:20:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx78ggj",
              "author": "zhl_max1111",
              "text": "https://preview.redd.it/mu05wx1r6vag1.png?width=1901&format=png&auto=webp&s=53a953042a4f5261b2ad91308951c606af8ea6bf",
              "score": -14,
              "created_utc": "2026-01-02 04:33:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx79jh9",
                  "author": "ZootAllures9111",
                  "text": "why would you post a gen with no info about the model used lol?",
                  "score": 12,
                  "created_utc": "2026-01-02 04:40:55",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx6h7m0",
          "author": "LiveMinute5598",
          "text": "Looks pretty amazing on Z image Turbo incase you need a comparison:\n\nhttps://storage.picshapes.com/ai-gen-results/results/78f0c4f9-03c9-4f3f-b329-37000f223f48.png",
          "score": 31,
          "created_utc": "2026-01-02 01:42:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx6hwu4",
              "author": "ZootAllures9111",
              "text": "I mean no, the actual same seed / literal same resolution as Qwen version on Z-Image [is this, I generated it myself earlier lol.](https://i.imgur.com/zfJW0ss.png) But yes Z does fine on this prompt as you'd expect, although I think it's a bit more sterile and distill-y than the Qwen 2512 equivalent. Anyways I have absolutely no idea why you thought you needed to post this comment lmao.",
              "score": 6,
              "created_utc": "2026-01-02 01:47:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx8ewdr",
                  "author": "Pepa489",
                  "text": "Same seed across different model families does not mean anything",
                  "score": 16,
                  "created_utc": "2026-01-02 10:38:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx8eht5",
                  "author": "Arch666Angel",
                  "text": "Both Z-Images have worse prompt following than the Qwen one tbh",
                  "score": 9,
                  "created_utc": "2026-01-02 10:34:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx6o2v5",
                  "author": "xbobos",
                  "text": "And the creation time is about 1/5th?",
                  "score": -10,
                  "created_utc": "2026-01-02 02:24:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxc8167",
              "author": "rbrtwtrs",
              "text": "That looks great. 2512 is great for realism but tends to bring out the ugly.",
              "score": 1,
              "created_utc": "2026-01-02 23:00:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxcasa4",
              "author": "IrisColt",
              "text": "I see that Qwen is¬†looksmogged by Z image.",
              "score": 1,
              "created_utc": "2026-01-02 23:15:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx7hc5h",
              "author": "Ill_Ease_6749",
              "text": "looking bad than qwen",
              "score": 1,
              "created_utc": "2026-01-02 05:35:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx7jt12",
              "author": "jadhavsaurabh",
              "text": "Wow üòØ",
              "score": -5,
              "created_utc": "2026-01-02 05:54:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx7tjfk",
                  "author": "LiveMinute5598",
                  "text": "If you want to test drive z-image for free: \nhttps://picshapes.com/",
                  "score": -10,
                  "created_utc": "2026-01-02 07:16:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx7vp9e",
          "author": "LyriWinters",
          "text": "Qwen image is notoriously bad at creating eyes if you specify the eye color. And it does one western face pretty much. Spotted it was qwen image within 0.5 seconds when I saw the eyes and the face.\n\nIf you use any lora the issue dissapears.",
          "score": 8,
          "created_utc": "2026-01-02 07:36:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7wmj0",
          "author": "LyriWinters",
          "text": "Does the same lightning lora work with Qwen image 2512?",
          "score": 2,
          "created_utc": "2026-01-02 07:45:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7x62j",
              "author": "Ill_Ease_6749",
              "text": "they made new 4 step but we can use old 8 step also",
              "score": 1,
              "created_utc": "2026-01-02 07:50:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx8kwrl",
                  "author": "alb5357",
                  "text": "Maybe the new 4 step at 50% strength and using 8 steps?",
                  "score": -1,
                  "created_utc": "2026-01-02 11:32:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx8m6pb",
          "author": "FinBenton",
          "text": "Qwen is definitely at its best with around 50 steps, using turbo loras will get decent results fast but you will lose a lot of the variety in images with those.",
          "score": 2,
          "created_utc": "2026-01-02 11:43:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx98nmv",
          "author": "NanoSputnik",
          "text": "We need 12 steps lightning lora with cfg support. I think it will be the sweet spot. 4 steps is tool little, 40 is too slow.",
          "score": 2,
          "created_utc": "2026-01-02 14:17:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx9bmk7",
          "author": "Green-Ad-3964",
          "text": "https://preview.redd.it/9mdwxpvv5yag1.png?width=1800&format=png&auto=webp&s=577a113a39cc7ff34acc4a037158b9845d314005\n\nthis is my attempt with your prompt in ZIT....imo it's better (more natural lighting and hair) even than 2512...",
          "score": 6,
          "created_utc": "2026-01-02 14:34:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx9jp1q",
              "author": "Ok-Significance-90",
              "text": "How did you create a 1800 x 1800 px image with ZIT? If I do a second pass with ZIT for upscaling, I get blurriness and heavy artifacts (like JPEG artifacts).\n\nWould you share your workflow? It looks amazing quality wise!!",
              "score": 2,
              "created_utc": "2026-01-02 15:18:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxbwurp",
                  "author": "ZootAllures9111",
                  "text": "Traditional hi-res-fix style upscaling in ComfyUI works absolutely fine with Z. [Like this sort of set up basically.](https://i.imgur.com/jmqyyTE.png)",
                  "score": 2,
                  "created_utc": "2026-01-02 22:03:07",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nx9vcb2",
                  "author": "Green-Ad-3964",
                  "text": "It's not mine, I found it here. As soon as I come back home I'll share it. It produces outstanding pics, IMHO.",
                  "score": 1,
                  "created_utc": "2026-01-02 16:14:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxaxkac",
                  "author": "Nextil",
                  "text": "Not sure what they used but many are using SeedVR2 for upscaling. It's very good.",
                  "score": 1,
                  "created_utc": "2026-01-02 19:11:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx9qcbd",
          "author": "Choowkee",
          "text": ">Thread exclusively to showcase QWEN\n\n>people posting ZIT versions when not asked\n\nZIT bros are becoming more annoying day by day.",
          "score": 4,
          "created_utc": "2026-01-02 15:50:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxeceqz",
              "author": "Ill_Ease_6749",
              "text": "agreed",
              "score": 0,
              "created_utc": "2026-01-03 06:57:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx85whm",
          "author": "dcmomia",
          "text": "worrkflow?",
          "score": 1,
          "created_utc": "2026-01-02 09:13:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxan15n",
          "author": "ectoblob",
          "text": "yes, it does not create that same cartoony clone face every time now. Which is nice. But some facial expressions looks exaggerated and some things like red cheeks looks strangely overdone, just like Qwen Image original version does eye colors.",
          "score": 1,
          "created_utc": "2026-01-02 18:23:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxe4x8u",
          "author": "No_Comment_Acc",
          "text": "Qwen is still very plasticky looking. All realism went to Z Image.",
          "score": 1,
          "created_utc": "2026-01-03 05:57:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxevw92",
          "author": "Kooky-Menu-2680",
          "text": "Guys , do you think we need and edit model for the 2512 or 2511 is more than enough?",
          "score": 1,
          "created_utc": "2026-01-03 09:46:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxg917u",
          "author": "AlexGSquadron",
          "text": "I think z image turbo is better and performs much faster",
          "score": 1,
          "created_utc": "2026-01-03 15:24:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxy7e45",
          "author": "Puzzled-Valuable-985",
          "text": "https://preview.redd.it/a17rtrf6mnbg1.png?width=1088&format=png&auto=webp&s=8fef307d6131e16b60b5807823b5a5a06af7b966\n\nZit, no Lora, just workflow.",
          "score": 1,
          "created_utc": "2026-01-06 04:10:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxy7i9y",
              "author": "Puzzled-Valuable-985",
              "text": "https://preview.redd.it/hkxrz9cdmnbg1.png?width=1088&format=png&auto=webp&s=fe0ed7ca0f249058ddb8617b95a3343c314a62b5\n\nZit - apenas mais uma varia√ß√£o do mesmo fluxo de trabalho",
              "score": 1,
              "created_utc": "2026-01-06 04:11:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxy7ri0",
              "author": "Puzzled-Valuable-985",
              "text": "https://preview.redd.it/fcl2xv2nmnbg1.png?width=1088&format=png&auto=webp&s=bed344de45aa5b9496e552fdc7146e6f18ecf9ec\n\nZit - outro fluxo de trabalho",
              "score": 1,
              "created_utc": "2026-01-06 04:13:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxy824j",
              "author": "Puzzled-Valuable-985",
              "text": "https://preview.redd.it/kuo4agf1nnbg1.png?width=1232&format=png&auto=webp&s=b76c8c0046147b38c91b9a5b8df30e3224275bfc\n\nZit - outro fluxo de trabalho no estilo garota-trabalhando",
              "score": 1,
              "created_utc": "2026-01-06 04:14:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx7lxnj",
          "author": "Rustmonger",
          "text": "It‚Äôs a big enough leap I‚Äôm not sure why they didn‚Äôt just make it version 2600 or something. It seems worthy of more than a single digit increase.",
          "score": -5,
          "created_utc": "2026-01-02 06:11:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7mxfe",
              "author": "nymical23",
              "text": "I realize you might be joking, but in case someone doesn't know, 2512 is YYMM format, so version Dec 2025.",
              "score": 28,
              "created_utc": "2026-01-02 06:19:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx7sr2t",
                  "author": "ZootAllures9111",
                  "text": "announcing the AMD Qwyzen 5 2600!",
                  "score": -1,
                  "created_utc": "2026-01-02 07:09:43",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx7tqsl",
              "author": "Ill_Ease_6749",
              "text": "not worthy to run on ur potato pc?",
              "score": -3,
              "created_utc": "2026-01-02 07:18:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx84a93",
          "author": "RiccardoPoli",
          "text": "did u use light2x lora / lenovo / instagirl lora?",
          "score": 0,
          "created_utc": "2026-01-02 08:58:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx8i6v1",
              "author": "ZootAllures9111",
              "text": "No loras. There's a comment elsewhere I left with the settings and prompt.",
              "score": 0,
              "created_utc": "2026-01-02 11:08:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx8dcgc",
          "author": "Substantial_Plum9204",
          "text": "Is there an Image to Image variant as well? No right? Would love to use it similar to nano banana pro.",
          "score": 0,
          "created_utc": "2026-01-02 10:24:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx910rg",
              "author": "ron_krugman",
              "text": "That's Qwen-Image-Edit 2511, which was released last week.",
              "score": 1,
              "created_utc": "2026-01-02 13:32:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx9gpmp",
                  "author": "Substantial_Plum9204",
                  "text": "But the difference is huge between 2511 and 2512 right?",
                  "score": 1,
                  "created_utc": "2026-01-02 15:02:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxb19xr",
              "author": "Relevant_Eggplant180",
              "text": "You can do image to image with it no problem. I have tried it and the results are good. But if you mean image edit, like add this to the image, that is not available yet.",
              "score": 1,
              "created_utc": "2026-01-02 19:29:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx8likz",
          "author": "alb5357",
          "text": "Thanks, useful comparison.\n\nRegarding the ZiT comparison, I think yes, ZiT can look amazing while following the prompt, but ends up being less useful due to lack of flexibility.\n\n\nLike, great at what it does and at that speed, but it can't be a workhorse tool because the distillation has limited it, which is fine, but not enough.",
          "score": 0,
          "created_utc": "2026-01-02 11:37:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx9g01f",
          "author": "Hearcharted",
          "text": "![gif](giphy|4Ckhq1ZeLEo4Fufvyo)\n\naka Baddie Creator 3000",
          "score": 0,
          "created_utc": "2026-01-02 14:58:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7jts8",
          "author": "jadhavsaurabh",
          "text": "Wow",
          "score": -1,
          "created_utc": "2026-01-02 05:54:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzj0un",
      "title": "Continuous video with wan finally works!",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1pzj0un/continuous_video_with_wan_finally_works/",
      "author": "intLeon",
      "created_utc": "2025-12-30 14:08:15",
      "score": 410,
      "num_comments": 313,
      "upvote_ratio": 0.98,
      "text": "https://reddit.com/link/1pzj0un/video/268mzny9mcag1/player\n\nIt finally happened. I dont know how a lora works this way but I'm speechless! Thanks to kijai for implementing key nodes that give us the merged latents and image outputs.  \nI almost gave up on wan2.2 because of multiple input was messy but here we are.\n\nI've updated my allegedly famous workflow to implement SVI to civit AI. (I dont know why it is flagged not safe. I've always used safe examples)  \n[https://civitai.com/models/1866565](https://civitai.com/models/1866565)\n\nFor our >!cencored!< friends (0.9);  \n[https://pastebin.com/vk9UGJ3T](https://pastebin.com/vk9UGJ3T)\n\nI hope you guys can enjoy it and give feedback :)",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pzj0un/continuous_video_with_wan_finally_works/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "nwqt9kc",
          "author": "F1m",
          "text": "I just tested this out and my first impression is that it works really well. Using fp8 models instead of the gguf it took 7 mins to create a 19 sec video on a 4090. It looks pretty seamless. Thank you for putting together the workflow.",
          "score": 48,
          "created_utc": "2025-12-30 15:33:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nws133b",
              "author": "Radiant_Silver_4951",
              "text": "Seeing this kind of speed and clean output on a 4090 makes the whole setup feel worth it and honestly pushes me to try fp8 right now since seven minutes for a smooth nineteen second clip is kind of wild.",
              "score": 9,
              "created_utc": "2025-12-30 18:57:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwquxu0",
              "author": "intLeon",
              "text": "Cheers buddy, dont hesitate to share your outputs on the civit üññ",
              "score": 13,
              "created_utc": "2025-12-30 15:41:31",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwr4egq",
              "author": "v1TDZ",
              "text": "Only 7 minutes? Haven't been toying with WAN for a while, but my 3080Ti used like an hour for only 5 seconds last I tried it (first iteration of WAN, so it's a while ago).\n\nThink I'll have to give this a go again soon|!",
              "score": 11,
              "created_utc": "2025-12-30 16:26:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwruxzd",
                  "author": "F1m",
                  "text": "The workflow uses speedup loras, which decrease the steps needed to generate a video, so it shortens generation time quite a bit. The trade off is movement is degraded, but I am not seeing too much of an impact with this workflow.",
                  "score": 10,
                  "created_utc": "2025-12-30 18:29:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwud2iv",
                  "author": "drallcom3",
                  "text": "> but my 3080Ti used like an hour for only 5 seconds\n\nThere are a lot of things you can do to speed up WAN 2.2. It's quite tricky.\n\nhttps://rentry.org/wan22ldgguide",
                  "score": 1,
                  "created_utc": "2025-12-31 02:08:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwrsakn",
                  "author": "chudthirtyseven",
                  "text": "yeah that's the difference between wan2.1 and wan2.2.",
                  "score": -2,
                  "created_utc": "2025-12-30 18:17:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwrfkge",
              "author": "MoreColors185",
              "text": "it works really well yes, needs more testing but consistence is pretty good.",
              "score": 8,
              "created_utc": "2025-12-30 17:18:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwrzwrh",
                  "author": "F1m",
                  "text": "Agreed, I've done about 10 videos so far and they each flow better than anything I have tried in the past. I've noticed some blurring as the videos goes along, but upscaling fixes it for the most part.",
                  "score": 4,
                  "created_utc": "2025-12-30 18:52:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxindrl",
              "author": "Fineous40",
              "text": "Where did you download the fp8 models? I can only find the fp16.",
              "score": 1,
              "created_utc": "2026-01-03 22:14:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqgbax",
          "author": "Some_Artichoke_8148",
          "text": "Ok. I‚Äôll being Mr Thickie here but what it is that this has done ? What‚Äôs the improvement ? Not criticising - just want to understand. Thank you !",
          "score": 21,
          "created_utc": "2025-12-30 14:25:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqh4zv",
              "author": "intLeon",
              "text": "SVI takes last few latents of previous generated video and feeds them into the next videos latent and with the lora it directs the video that will be generated.\n\nSubgraphs help me put each extension in a single node that you can go inside to edit part specific loras and extend it further by duplicating one from the workflow.\n\nPrevious versions were more clean but comfyui frontend team removed a few features so you have to see a bit more cabling going on now.",
              "score": 30,
              "created_utc": "2025-12-30 14:30:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nws60g8",
                  "author": "mellowanon",
                  "text": "is possible for it to loop a video? By feeding the latents for the beginning and end frames for a new video.\n\nOther looping workflows only take one first and last frame, so looping is usually choppy and sudden.",
                  "score": 3,
                  "created_utc": "2025-12-30 19:20:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwr2v0k",
                  "author": "Some_Artichoke_8148",
                  "text": "Thanks for the reply. Ok ‚Ä¶. So does that mean you can prompt a longer video and it produces it in one gen ?",
                  "score": 4,
                  "created_utc": "2025-12-30 16:18:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nws5nli",
                  "author": "Different-Toe-955",
                  "text": "So it sounds like it takes some of the actual internal generation data and feeds it into the next section of video, to help eliminate the \"hard cut\" to a new video section, while maintaining speed/smoothness of everything? (avoiding when it cuts to the next 5 second clip and say the speed of a car changes)",
                  "score": 2,
                  "created_utc": "2025-12-30 19:19:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwrwpod",
                  "author": "stiveooo",
                  "text": "Wow so you are saying that someone finally made it so the Ai looks at the few seconds before making a new clip? Instead of only the last frame?¬†",
                  "score": 3,
                  "created_utc": "2025-12-30 18:37:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwrkeco",
                  "author": "Yasstronaut",
                  "text": "I‚Äôm confused why a lora is needed for this though I‚Äôve been using the last few frames as input for next few frames for months now - and weighting the frames (by increasing the denoise progressively) and have been seeing similar results to what you posted",
                  "score": 1,
                  "created_utc": "2025-12-30 17:40:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwr8h5a",
          "author": "ansmo",
          "text": "Great work! I have good results with 333steps. High WITH the wan2.1lightx2v lora at 1.5 and cfg 3, Low with light lora twice. Slowmo isn't a problem with these settings. It's exciting to see a true successor to 2.1 FUN/VACE.",
          "score": 8,
          "created_utc": "2025-12-30 16:45:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwboql",
              "author": "Old-Artist-5369",
              "text": "Do you mean 3 steps high with lightx2v at cfg 1.5, 3 with lightx2v high at cfg 3, and then 3 with light x2v low?",
              "score": 3,
              "created_utc": "2025-12-31 11:17:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx15wr7",
                  "author": "ansmo",
                  "text": "**High** lightx2v@1.5 cfg3, **Low** light@1 cfg1, **Low** light@1 cfg1. 3 steps each. I apologize for not making that more clear.",
                  "score": 3,
                  "created_utc": "2026-01-01 04:20:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwvafsq",
              "author": "kayteee1995",
              "text": "wait what?!?! 333 steps?",
              "score": 1,
              "created_utc": "2025-12-31 05:41:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwr1pxk",
          "author": "Perfect-Campaign9551",
          "text": "So, what about character likeness over time? that's been a flaw we've been noticing in other continuous workflows. Do like 5 extensions (20 or so seconds) and does the character still look the same?",
          "score": 6,
          "created_utc": "2025-12-30 16:13:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr5kt2",
              "author": "intLeon",
              "text": "Start image is always kept as a latent but overall latent quality degrades over time so I would say 30s/45s with lightx2v lora's and low steps. Then it suddenly has ribbon like artifacts and very rapid movements.\n\nEdit: these dont happen without custom loras",
              "score": 2,
              "created_utc": "2025-12-30 16:31:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqknfu",
          "author": "broadwayallday",
          "text": "SVI is definitely a game changer woohooo",
          "score": 5,
          "created_utc": "2025-12-30 14:49:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwu87hl",
          "author": "Le_Singe_Nu",
          "text": "After a few hours wrestling with Comfy, I got it to work. I'm still waiting on the first generation, but I have to say this: \n\n**I deeply appreciate your commitment to making the fucking nodes line up** **on the grid.**\n\nIt always annoys me when I *must* sort out a workflow. As powerful as Comfy is, it's confusing enough with all its spaghetti everywhere. \n\nI salute you.",
          "score": 6,
          "created_utc": "2025-12-31 01:40:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvg4l0",
              "author": "intLeon",
              "text": "Hehe it was a nightmare before but I figured you could snap them if you had the setting enabled.",
              "score": 3,
              "created_utc": "2025-12-31 06:26:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqjio5",
          "author": "additionalpylon2",
          "text": "It's Christmas everyday. I can hardly keep up with all this. \n\nOnce we consumer peasants get the real hardware we are going to be cooking.",
          "score": 10,
          "created_utc": "2025-12-30 14:43:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxhewgi",
              "author": "Fineous40",
              "text": "I can‚Äôt wait for the AI bubble to burst. I wanna H200 for a grand.",
              "score": 1,
              "created_utc": "2026-01-03 18:39:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nws7578",
          "author": "foxdit",
          "text": "This is awesome! I've edited the workflow so that now you can regenerate individual segments that don't come out looking as good. That way you don't have to retry the whole thing from scratch if the middle segment sucks.",
          "score": 5,
          "created_utc": "2025-12-30 19:26:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwbv8l",
              "author": "Old-Artist-5369",
              "text": "Nice!  I was thinking along the same lines.  Could you share?",
              "score": 1,
              "created_utc": "2025-12-31 11:18:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqe8bv",
          "author": "Complete-Box-3030",
          "text": "Can we run this on rtx 3060 12gb vram",
          "score": 12,
          "created_utc": "2025-12-30 14:13:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqeenz",
              "author": "intLeon",
              "text": "It should work, nothing special. Just same quantized wan2.2 I2V a14b models with an extra lora put in subgraphs and with an initial ZIT node.",
              "score": 12,
              "created_utc": "2025-12-30 14:14:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwqeq64",
                  "author": "Complete-Box-3030",
                  "text": "Does it work on smooth mix models",
                  "score": 1,
                  "created_utc": "2025-12-30 14:16:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwqy5l2",
          "author": "Underbash",
          "text": "Maybe I'm just dumb but I'm missing the \"WanImageToVideoSVIPro\" and ImageBatchExtendWithOverlap\" nodes and for the life of my cannot find them anywhere. Google is literally giving me nothing.",
          "score": 4,
          "created_utc": "2025-12-30 15:56:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqyf0l",
              "author": "intLeon",
              "text": "They are in kijai's nodes. Try updating the package if you already have it.",
              "score": 7,
              "created_utc": "2025-12-30 15:58:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwr071v",
                  "author": "Underbash",
                  "text": "That seemed to work. Thanks!",
                  "score": 3,
                  "created_utc": "2025-12-30 16:06:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwtbdqe",
          "author": "PestBoss",
          "text": "Also am I being stupid here?\n\nThe node pack I'm missing is apparently:\ncomfyui-kjnodes, WanImageToVideoSVIPro\n\nWanImageToVideoSVIPro in subgraph 'I2V-First'\n\n\nIn ComfyUI manager it's suggesting that the missing node pack is KJNodes but I have that installed.\n\nIf I check the properties of the outlined node in I2V-First, it's cnr-id is \"comfyui-kjnodes\"\n\n\nSo what do I install? Is it kijai wanvideowrapper or is my kjnodes not working correctly, or is this some kind of documentation error?\n\nIf I check in kjnodes via manager on the nodes list, there is no WanImageToVideoSVIPro entry.\n\nIf I check in wanvideowrapper via manager on the nodes list, there is no WanImageToVideoSVIPro entry either.",
          "score": 4,
          "created_utc": "2025-12-30 22:39:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtngxo",
              "author": "Particular_Pear_4596",
              "text": "Same here, comfyui manager fails to authomatically install the WanImageToVideoSVIPro node, so I deleted the old subfolder \"comfyui-kjnodes\" in the \"custom\\_nodes\" subfolder in my comfyui folder, then manually installed the KJNodes nodes as explained here: [https://github.com/kijai/ComfyUI-KJNodes](https://github.com/kijai/ComfyUI-KJNodes) (scroll down to \"Installation\"), restarted comfyui and it now works. Have no idea why comfyui manager fails to update the KJNodes nodes and I have to do it manually.",
              "score": 5,
              "created_utc": "2025-12-30 23:44:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwx8l4j",
                  "author": "PestBoss",
                  "text": "Yes it's all getting a bit daft now.\n\nI deleted KJNodes, then Manager wouldn't re-install nightly, a github clone error... only the 1.2.2 would work.\n\nI'm a bit tired of the CUI team messing with all these things. I never had an issue like this before, and despite all the UI/UX work, the error mode/failure modes are still utterly opaque.\nWhy not state exactly what the error is. Is this an safety mode, is it a git clone issue? Some syntax? A bug?\n\n\nSo I changed the security profile to weak (no idea what it *actually* does, only what it implies it does), and that seemed to let it install, but then it's disabled. If I try enable it just errors in the manager.\n\n\nUtterly stupid that a simple git clone won't work.\n\nIf this node pack makes it into the manager list and the Comfy Registry, it should just work.\nIf it doesn't, don't have it on the list.\nIf this is an issue with it being a nightly, then CUI should say it's disabling the node because of the security level or something!?\n\n\nI've never had an issue like this before, so clearly another nice UI/UX 'feature' that actually breaks things and makes life MORE difficult.",
                  "score": 1,
                  "created_utc": "2025-12-31 15:00:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwtbn5f",
              "author": "intLeon",
              "text": "Try to update kjnodes if you have comfyui manager. The node is very new, like 2 days old.",
              "score": 2,
              "created_utc": "2025-12-30 22:40:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwtu8cr",
                  "author": "NomadGeoPol",
                  "text": "I have same error, I updated everything but still broken WanImageToVideoSVIPro node.",
                  "score": 1,
                  "created_utc": "2025-12-31 00:21:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwtgos7",
              "author": "osiris316",
              "text": "Yep. I am having the same issue and went through the same steps that you did but I am still getting an error related to WanImageToVideoSVIPro",
              "score": 2,
              "created_utc": "2025-12-30 23:07:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxhf0wz",
              "author": "Fineous40",
              "text": "I had to manually download install these nodes for it to work.",
              "score": 1,
              "created_utc": "2026-01-03 18:40:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqecrd",
          "author": "Jero9871",
          "text": "Thanks, seems great, I will check it out later. How long can you extend the video?",
          "score": 3,
          "created_utc": "2025-12-30 14:14:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqgexo",
              "author": "intLeon",
              "text": "In theory there is no limit as long as you follow the steps in the workflow notes but Im guessing the stacking number of images might cause a memory hit. If you've got some decent amount of vram it could hit/pass a minute mark but I didnt test it myself so quality might degrade over long periods.",
              "score": 4,
              "created_utc": "2025-12-30 14:26:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwr3y99",
          "author": "WildSpeaker7315",
          "text": "im curious why its taking so long, per segment, like over 10 mins @ Q8 1024x800 when it takes me 10 mins to usually make a 1280x720 video, i'll update comment with my thoughts on the results tho :) - ye i enabled sage",
          "score": 3,
          "created_utc": "2025-12-30 16:24:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrb1ve",
              "author": "WildSpeaker7315",
              "text": "took too long for 19 seconds, 2902 seconds, decent generation but something is off",
              "score": 1,
              "created_utc": "2025-12-30 16:57:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwrm20f",
                  "author": "WildSpeaker7315",
                  "text": "did it with a different workflow 1900s, same resolution, weird",
                  "score": 1,
                  "created_utc": "2025-12-30 17:48:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwrux64",
              "author": "intLeon",
              "text": "Yeah thats too long for 19s video. Id suggest opening a new browser during generation and switch there and see if that makes a difference.. Or turn offncivitai if its open in a tab.",
              "score": 1,
              "created_utc": "2025-12-30 18:29:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwrtz8s",
          "author": "ArkCoon",
          "text": "Amazing! This is pretty much seamless! I tried FineLong a few days ago and was very disappointed. It didn't work at all for me, but this works perfectly and best thing is that it doesn't slow down the generation. Finelong would make the high noise model like 5 times slower and the result would be terrible",
          "score": 3,
          "created_utc": "2025-12-30 18:24:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwwbcxr",
          "author": "robomar_ai_art",
          "text": "https://i.redd.it/zx3o8zcbwiag1.gif\n\nI did this one, amazing workflow.",
          "score": 3,
          "created_utc": "2025-12-31 11:14:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqfczc",
          "author": "ANR2ME",
          "text": "Did i saw 2 egg yolks coming out ü§î and disappearing egg shell üòÇ\n\n\nAnyway, the consistency looks good enough üëç",
          "score": 5,
          "created_utc": "2025-12-30 14:20:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqfqa8",
              "author": "intLeon",
              "text": "Yup this workflow is focused on efficiency and step count is set to 1 + 3 + 3 (7) steps but you are free to increase number of steps. It literally was one of the first things I generated if not the actual first.",
              "score": 5,
              "created_utc": "2025-12-30 14:22:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwrnjey",
                  "author": "_Enclose_",
                  "text": "> 1 + 3 + 3 (7)\n\nold school cool",
                  "score": 3,
                  "created_utc": "2025-12-30 17:55:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwqoqoc",
          "author": "BlackSheepRepublic",
          "text": "Why is it so choppy?",
          "score": 2,
          "created_utc": "2025-12-30 15:10:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqr37m",
              "author": "Wilbis",
              "text": "Wan generates at 16fps",
              "score": 6,
              "created_utc": "2025-12-30 15:22:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwqqevn",
              "author": "intLeon",
              "text": "Probably the number of steps. 1 high without lightx2v, 3 high and 3 low with lightx2v. You could increase them to get better motion/quality. You could also modify the workflow to not use lightx2v but that causes more noise in low steps like 20 total in my experience.",
              "score": 3,
              "created_utc": "2025-12-30 15:19:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqtya5",
          "author": "ShittyLivingRoom",
          "text": "Does it work on WanGP?",
          "score": 2,
          "created_utc": "2025-12-30 15:36:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwquq5z",
              "author": "intLeon",
              "text": "Its a workflow for comfyui so it may not work if there isnt at least a hidden comfyui layer at the backend.",
              "score": 2,
              "created_utc": "2025-12-30 15:40:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwr1zrm",
          "author": "Perfect-Campaign9551",
          "text": "A lot of your video example suffer from SLOW MOTION ARGH",
          "score": 2,
          "created_utc": "2025-12-30 16:14:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr31pn",
              "author": "intLeon",
              "text": "Yeah I didnt have time to test the lightning lora variations. Could be fixed with more no lora steps and total steps as well as using some trigger words in the prompts to make things faster.\n\nCould also add a slowmo tag to no lora negative conditioning.",
              "score": 1,
              "created_utc": "2025-12-30 16:19:50",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwrwbsw",
              "author": "NessLeonhart",
              "text": "Pass the output through a VFI node. Set the interpolation to 3, But the saved video to 60fps instead of 48. \n\nSmoother, faster motion.",
              "score": 1,
              "created_utc": "2025-12-30 18:35:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx1j0oe",
                  "author": "Perfect-Campaign9551",
                  "text": "Pretty sure you'll still sacrifice TIME when you do that, the video will just get shorter.",
                  "score": 2,
                  "created_utc": "2026-01-01 06:09:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwrxypc",
          "author": "jiml78",
          "text": "Have you considered adding PainterI2V to help with motion, specifically the slowmo aspect of it.",
          "score": 2,
          "created_utc": "2025-12-30 18:43:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwrzhg4",
          "author": "wrecklord0",
          "text": "Hey I gave that a try, I don't understand the 1 step with no lora? Is there a reason for it?\n\nIt worked much better for me by bypassing the no-lora entirely and setting a more standard 4 steps with high lora and 4 step with low lora in each of the subgraphs.",
          "score": 2,
          "created_utc": "2025-12-30 18:50:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwscrnm",
              "author": "intLeon",
              "text": "It was to beat slow motion but yeah, it is literally 0 degradation if there is no phase 1. I will update workflow once I see if theres something else to be done about slomo.\n\nEdit: it doesnt degrade with the phase too, I had a lora enabled and it reduced the quality.",
              "score": 1,
              "created_utc": "2025-12-30 19:53:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nws0o4m",
          "author": "sunamutker",
          "text": "Thank you for a great workflow . In my generated videos it seems like at every new stage it defaults back to the original image., Like I am seeing clips of the same scene.  As if the anchor samples are much stronger than the prev\\_samples? Any idea, or am I an idiot?",
          "score": 2,
          "created_utc": "2025-12-30 18:55:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwschue",
              "author": "intLeon",
              "text": "Did you modify the workflow? Extended subgraphs nodes take extra latents with previous latents set to 1 to fix that",
              "score": 1,
              "created_utc": "2025-12-30 19:51:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwsh1qd",
                  "author": "sunamutker",
                  "text": "No I dont think so. I had some issues installing the custom node. But the workflow should be the same.",
                  "score": 1,
                  "created_utc": "2025-12-30 20:13:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwtxczi",
                  "author": "ExpandibleWaist",
                  "text": "I'm having same issue, anything else to adjust? I updated everything, uninstalled and reinstalled the nodes. Every 5 second clip resets to initial image and starts over",
                  "score": 1,
                  "created_utc": "2025-12-31 00:38:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwtyqpu",
              "author": "nsfwvenator",
              "text": "u/intLeon I'm getting the same issue. The face keeps resetting back to the original anchor for each subgraph, even though it has the prev\\_samples and source\\_images wired from the previous step. The main thing I changed was using fp8 instead of gguf.\n\nI have the following versions:\n\n* KJNodes - 1.2.2\n* WanVideoWrapper - 1.4.5",
              "score": 1,
              "created_utc": "2025-12-31 00:45:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwvflwg",
                  "author": "intLeon",
                  "text": "You dont need wan wrapper. Im downloading fp8 models to test further. Is there any weird logs in the console?\n\nIf you mean image switching mid video to a slightly different state like a cut that happenened on fp8 scaled model or if I set the model shift to 5. It doesnt happen on gguf with model shift set to 8 which is the default setting.",
                  "score": 1,
                  "created_utc": "2025-12-31 06:21:52",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwso7q8",
          "author": "MrHara",
          "text": "Cleared up the workflow a bit (removing the no-lora step), changed to lcm/sgm_uniform and ran the combination of 1022 low+high at 1 strength and lightx2v_I2V_14B_480p_cfg_step_distill_rank64_bf16 at 2.5 strength on high only to solve some of the slowdown. Can recommend for getting good motion, but I wonder if PainterI2V or something newer is better even.\n\nCan't test extensively as for some reason iteration speeds are going a bit haywire in the setup on my measly 3080 but quite interesting.",
          "score": 2,
          "created_utc": "2025-12-30 20:48:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwt7mm7",
              "author": "Tystros",
              "text": "how much did your changes improve the slow motion?",
              "score": 1,
              "created_utc": "2025-12-30 22:20:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwwqdod",
                  "author": "MrHara",
                  "text": "For me it's the best smooth motion I've tried. I haven't tried PainterI2V or the time scale node yet tho.",
                  "score": 1,
                  "created_utc": "2025-12-31 13:13:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwtti2y",
              "author": "intLeon",
              "text": "No lora wasnt the issue btw. It was a lora I forgot enabled. Having 2 no lora steps as in 2 + 2 + 2 or 3 for low noise fixes most issues.",
              "score": 1,
              "created_utc": "2025-12-31 00:17:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwwq7cx",
                  "author": "MrHara",
                  "text": "That gives me awful prompt adherence and characters have a tendency to act like they have tremors. I'm gonna stick to two samplers, 1+3 or 2+5 split. With the loras I use I get smooth motion and no jittery stuff.",
                  "score": 1,
                  "created_utc": "2025-12-31 13:12:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwynbtk",
              "author": "bossbeae",
              "text": "This is the best Set up I've seen so far, mostly fixes the motion and keeps prompt adherence",
              "score": 1,
              "created_utc": "2025-12-31 19:14:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwt4on8",
          "author": "additionalpylon2",
          "text": "So far this is phenomenal. Great job putting this together.\n\nI just need to figure out how to get some sort of end\\_image implementation for a boomerang effect and its golden.",
          "score": 2,
          "created_utc": "2025-12-30 22:06:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwtm4m3",
          "author": "WestWordHoeDown",
          "text": "For the life of me, I can not find the WanImageToVideoSVIPro custom node. Any help would be appreciated.",
          "score": 2,
          "created_utc": "2025-12-30 23:36:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwto3um",
              "author": "intLeon",
              "text": "Kjnodes, update if you already have it installed.",
              "score": 3,
              "created_utc": "2025-12-30 23:47:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwtzs2w",
                  "author": "WestWordHoeDown",
                  "text": "That was the first thing I tried, no luck. Will try again later. Thank you.",
                  "score": 1,
                  "created_utc": "2025-12-31 00:51:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwvj3h0",
          "author": "bossbeae",
          "text": "The transition Between Each generation has never been smoother for me but There's definitely a slow motion issue tied to the SVI lora's, I can run a nearly identical setup with the same Lightning Lora's And the normal wan image to video node with no slow motion at all but as soon as I add in the SVI Lora's and the wan image to video SVI Pro node There's Very noticeable slow motion, I am also noticing that prompt adherence is very weak compared to that same setup without the SVI lora's, I'm struggling to get any significant motion\n\nI should add I'm running on a two sampler setup, the third sampler adds so much extra time to each generation I'm trying to avoid it,",
          "score": 2,
          "created_utc": "2025-12-31 06:50:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvjboo",
              "author": "intLeon",
              "text": "Can you increase the no lora steps to two instead of disabling it? It is supposed to squeeze more motion out of high with lightx2v steps.\n\nEven one step does wonders but 2 worked better in my case.",
              "score": 1,
              "created_utc": "2025-12-31 06:52:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwvuvwn",
                  "author": "bossbeae",
                  "text": "I tried both suggestions and while they solve the slow motion I'm still not getting any prompt adherence, If I prompt something as simple as this person walks towards the camera, which would work fine without the SVI Lora more often than not the person just stands there and moves their arms, if I raise the CFG it just turns into body horror\n\nI'm wondering if it has to do with the anchor image\n\nI'm going to keep working at it, It's such a massive improvement I want to get it working well",
                  "score": 1,
                  "created_utc": "2025-12-31 08:39:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwvoqzl",
              "author": "foxdit",
              "text": "Just do 2 HIGH steps (2.0 or 3.0 cfg, no speedup lora) and 4 LOW (w/ speedup lora, 1.0 cfg). If you need faster motion than that, use the new experimental Motion Scaling node (look at the front page of this reddit) and set time scale to 1.2-1.5.\n\nThis has been a fairly easy problem to solve in my experience.",
              "score": 1,
              "created_utc": "2025-12-31 07:41:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwgxas",
          "author": "Jero9871",
          "text": "Okay, now some feedback, I tested it extensively. First of all, I love your workflow, it's great.\n\nWhat is really good is that there is no color correction needed like if you extend videos with VACE.   \nOne downside is, it always tries to get back to the initial anchor image, so rotating shots etc are more complicated (but it can even be mixed with vace and extended with vace fun for example).\n\nLora order matters a little bit, I get better results if I load the speedup loras at first and after that the SVI lora and then the rest, but that might be just me.\n\nI had some artifacts that get much better with more steps, so I am using 11 step workflow for now.",
          "score": 2,
          "created_utc": "2025-12-31 12:02:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxhhm9",
          "author": "PestBoss",
          "text": "For anyone who can't get onto CivitAI, here are the links for the actual SVI LoRA.\n\nhttps://huggingface.co/Kijai/WanVideo_comfy/tree/main/LoRAs/Stable-Video-Infinity/v2.0\n\nI'd assumed these were fairly standard but it seems you need these specific ones, so if you're having issues with those sourced elsewhere?\n\nThanks for posting the link OP.",
          "score": 2,
          "created_utc": "2025-12-31 15:46:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwymby7",
          "author": "xPiNGx",
          "text": "Thanks for sharing!",
          "score": 2,
          "created_utc": "2025-12-31 19:09:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqgxkj",
          "author": "Wallye_Wonder",
          "text": "This is really exciting. A 15 seconds clip takes about 10 mins on my 4090 48gb vram. It only uses 38gb of vram but almost 80gb of ram. I‚Äôm not sure why it wouldn‚Äôt use all 48gb vram.",
          "score": 2,
          "created_utc": "2025-12-30 14:29:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqhuar",
              "author": "intLeon",
              "text": "I think you should have some more room to improve. 4 parts (19s) takes 10 mins for me on a 4070ti 12gb. I would try to get at least sage to work on a new workflow. Did it on my companies pc and it was worth it. Vram usage might be because models fit and you have extra space. Also native models could also work a bit faster and may provide higher quality if you have extra vram. You could even go for higher resolutions.",
              "score": 2,
              "created_utc": "2025-12-30 14:34:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwu7qt5",
                  "author": "Wallye_Wonder",
                  "text": "i was using bf16 instead of gguf, maybe thats why the slow speed.",
                  "score": 1,
                  "created_utc": "2025-12-31 01:37:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwr8frj",
              "author": "Neamow",
              "text": "> 4090 48gb vram\n\nThe what?",
              "score": 1,
              "created_utc": "2025-12-30 16:44:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwyx2cr",
                  "author": "Bulky_Astronomer7264",
                  "text": "Modded most likely",
                  "score": 1,
                  "created_utc": "2025-12-31 20:06:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwqj2u1",
          "author": "zekuden",
          "text": "Can you make looping videos?",
          "score": 2,
          "created_utc": "2025-12-30 14:40:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqk3co",
              "author": "intLeon",
              "text": "It may not work with this workflow. Each part after the first takes a latent reference from first input image and motion from the previous video. And first few frames are somehow masked to not be affected by the noise. So I cant think of a way to mask last frames for now.",
              "score": 3,
              "created_utc": "2025-12-30 14:46:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwqlirq",
                  "author": "zekuden",
                  "text": "Oh I see, I appreciate your informative reply, thank you!\n\nIs there any way in general to make looping videos in wan?",
                  "score": 3,
                  "created_utc": "2025-12-30 14:54:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwqo0wm",
                  "author": "shapic",
                  "text": "I think the question is more about combining this thing with FLF",
                  "score": 1,
                  "created_utc": "2025-12-30 15:07:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwrc24z",
              "author": "Life_Yesterday_5529",
              "text": "Same image as start and end frame and a strong prompt? Does not work with SVI but with classic I2V.",
              "score": 1,
              "created_utc": "2025-12-30 17:01:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwsdb3i",
          "author": "yaxis50",
          "text": "A year from now I wonder how much this achievement will have aged, very cool either way.¬†",
          "score": 2,
          "created_utc": "2025-12-30 19:55:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwu834r",
          "author": "Underbash",
          "text": "I don't know what the deal is or if I've got something set-up wrong, but ~~it really doesn't seem to want to play nice with any kind of lora. As soon as I add any kind of lora at all, it goes crazy during the first stage and produces a horribly distorted mess.~~\n\nEdit: Forgot to mention, it always seems to sort itself out on the first \"extend\" step, with the loras working fine at that point, although by that point any resemblance to the initial image is pretty much gone since the latent it's pulling from is so garbled. But something about that \"first\" step is just not cooperating.\n\nEdit 2: It still is misbehaving even without loras, but in the form of flashing colors. With no loras, the image isn't distorted but it keep flashing between different color tints with every frame, like every frame is either the correct color, has a blue cast, or has an orange cast. Very bizarre.",
          "score": 2,
          "created_utc": "2025-12-31 01:39:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvgai9",
              "author": "intLeon",
              "text": "Happened to me as well, do you have the exact same loras? Even switching to 1030 high lora caused my character to lose their mind.",
              "score": 1,
              "created_utc": "2025-12-31 06:27:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwvh64t",
                  "author": "Underbash",
                  "text": "Idk I tried a couple different ones and it did it with all of them.",
                  "score": 1,
                  "created_utc": "2025-12-31 06:34:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwqrr2l",
          "author": "BlackSheepRepublic",
          "text": "What post-process software can up frame rate to 21 without mucking up the quality?",
          "score": 1,
          "created_utc": "2025-12-30 15:25:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqsbdq",
              "author": "intLeon",
              "text": "You can use comfyui interpolation rife nodes to multiply framerate (usually by 2 or 4 works for 30/60 fps). I will implement a better save method and interpolation option if I get some free time this weekend.",
              "score": 4,
              "created_utc": "2025-12-30 15:28:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwqycna",
                  "author": "Fit-Palpitation-7427",
                  "text": "Whats the highest quality we cqn get out of wan? Can we do 1080p, 1440p, 2160p?",
                  "score": 1,
                  "created_utc": "2025-12-30 15:57:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwrvyxb",
              "author": "NessLeonhart",
              "text": "Film VFI or rife VFI nodes, easy. Just set the multiplier (2x, 4x, etc) and send the video through it. Make sure to change the output frame rate to match the new frame rate. \n\nYou can also do cool stuff like set it to 3x but set the output to 60fps. It makes a video that‚Äôs 48fps and plays it back at 60, which often fixes the ‚Äúslow motion‚Äù nature of many WAN outputs.",
              "score": 1,
              "created_utc": "2025-12-30 18:34:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqzpsn",
          "author": "freebytes",
          "text": "I am missing the node WanImageToVideoSVIPro.  Where do I get this?  I do not see it in the custom node manager.",
          "score": 1,
          "created_utc": "2025-12-30 16:04:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr0gw7",
              "author": "intLeon",
              "text": "https://www.reddit.com/r/StableDiffusion/s/r12qQ9QVRz\nKijai's nodes",
              "score": 1,
              "created_utc": "2025-12-30 16:07:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwr08r3",
          "author": "ICWiener6666",
          "text": "Where kijai workflow",
          "score": 1,
          "created_utc": "2025-12-30 16:06:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr0q6e",
              "author": "intLeon",
              "text": "I dont like the wan video wrapper because it has its own data types instead of native ones so I dont use it :(",
              "score": 5,
              "created_utc": "2025-12-30 16:08:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nws3w5k",
                  "author": "Tystros",
                  "text": "I appreciate that you use the native nodes. Kijai himself says people should use the native nodes when possible and not his wrapper nodes.",
                  "score": 2,
                  "created_utc": "2025-12-30 19:10:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwrcfy0",
          "author": "Neonsea1234",
          "text": "where do you actually load the video models on this workflow? in the main loader node, I just have x2 high/low loras + clip and vae.",
          "score": 1,
          "created_utc": "2025-12-30 17:03:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrmnso",
              "author": "intLeon",
              "text": "At the very left there are model loader nodes. You should switch to load diffusion model nodes if you dont have gguf",
              "score": 1,
              "created_utc": "2025-12-30 17:51:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwsbamk",
                  "author": "Neonsea1234",
                  "text": "ah yeah I got it working, was unfamiliar with the nesting of nodes like this. Works great",
                  "score": 2,
                  "created_utc": "2025-12-30 19:46:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx3275t",
                  "author": "Some_Artichoke_8148",
                  "text": "sadly I can't get this workflow to work, I've been messing about with it for hours and gemini cant solve it either - shame would have liked to have tried it. \n\nhttps://preview.redd.it/fv52qamk2rag1.jpeg?width=1203&format=pjpg&auto=webp&s=4c046cb0a1589565b25210de827adc6a2d160d69",
                  "score": 1,
                  "created_utc": "2026-01-01 14:43:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwrk29m",
          "author": "NoBoCreation",
          "text": "What are you using to run your workflows?",
          "score": 1,
          "created_utc": "2025-12-30 17:39:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrnpeh",
              "author": "intLeon",
              "text": "They are comfyui workflows ü§î So I have a portable comfyui setup with sage + torch",
              "score": 1,
              "created_utc": "2025-12-30 17:56:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nws4f7y",
                  "author": "NoBoCreation",
                  "text": "Someone recently has been telling me about comfyui. Is it reletively easy to learn? How much does it cost?",
                  "score": 1,
                  "created_utc": "2025-12-30 19:13:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwsbf9x",
          "author": "NeatUsed",
          "text": "how is this different from the usual? i know ling videos had a problem with consistency. Basically a character turning around with their back and after they turn back their face is different. How do you keep face consistency?",
          "score": 1,
          "created_utc": "2025-12-30 19:46:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwsdbqw",
              "author": "intLeon",
              "text": "This workflow uses kijai's node which keeps the reference latent from first image all times and also uses an extra SVI lora so customized latents dont get messy artifacts.\n\nEdit: replaced the workflow preview video with an 57 seconds one. Looks okay to me.",
              "score": 1,
              "created_utc": "2025-12-30 19:55:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwsogq2",
          "author": "Glad-Hat-5094",
          "text": "I'm getting a lot of errors when running this workflow like the one below. Did anyone else get these errors?\n\nPrompt outputs failed validation:  \nCLIPTextEncode:  \n\\- Return type mismatch between linked nodes: clip, received\\_type(MODEL) mismatch input\\_type(CLIP)",
          "score": 1,
          "created_utc": "2025-12-30 20:49:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwt0yp8",
              "author": "intLeon",
              "text": "Make sure your comfyui is up to date and right models are selected for clip node.",
              "score": 1,
              "created_utc": "2025-12-30 21:48:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwt0d70",
          "author": "MalcomXhamster",
          "text": "This is not porn for some reason.",
          "score": 1,
          "created_utc": "2025-12-30 21:45:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwt0q3z",
              "author": "intLeon",
              "text": "Username checks out. Well you are free to add custom lora's to each part but Id wanna see some sfw generations in the civit page as well ;-;",
              "score": 1,
              "created_utc": "2025-12-30 21:47:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwt8f8s",
          "author": "PestBoss",
          "text": "Nice work.\n\nA shame it's all been put into sub-graphs despite stuff like prompts, seeds, per-section sampling/steps, all ideally being things you'd set/tweak per section, especially in a workflow as much about experimentation as production flow.\n\nIt actually means I have to spend more time unbundling it all and rebuilding it, just to see how it actually works.\n\n\nTo sum up on steps. Are you doing:\n\n1 high noise without a lora\n3 high noise with a lora\n3 low noise with a lora\n\n?\n\nIs this a core need of the SVI process or you just tinkering around?\n\nIe, can I just use 2+2 as normal, and live with the slower motion?",
          "score": 1,
          "created_utc": "2025-12-30 22:24:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwt9zj3",
              "author": "intLeon",
              "text": "You can set them from outside thanks to promote widget feature and I wanted to keep the subgraph depth at 1 except for the save subgraph in each node.\n\nAlso you can go inside subgraphs, you dont need to unpack them.\n\nFor steps no lora brings more motion and can help avoid slowmotion.",
              "score": 1,
              "created_utc": "2025-12-30 22:32:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwtakl9",
          "author": "Green-Ad-3964",
          "text": "Thanks, this seems outstanding for wan 2.2. What are the best \"adjustments\" for a blackwell card (5090) on windows to get the maximum efficiency? Thanks again.",
          "score": 1,
          "created_utc": "2025-12-30 22:35:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtbfaj",
              "author": "intLeon",
              "text": "I dont have enough experience with blackwell series but sage attention makes the most difference in previous cards. Id suggest giving a shot to sage 3.",
              "score": 2,
              "created_utc": "2025-12-30 22:39:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwtbi4x",
          "author": "DMmeURpet",
          "text": "Can we use key frames for this and it fill the gaps between images",
          "score": 1,
          "created_utc": "2025-12-30 22:39:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtcooc",
              "author": "intLeon",
              "text": "Currently I have not seen end image support in wanImageToVideoSVIPro node. It only generates a latent from previous latents end.",
              "score": 1,
              "created_utc": "2025-12-30 22:46:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwtg1ko",
          "author": "sepalus_auki",
          "text": "I need a method which doesn't need ComfyUI.",
          "score": 1,
          "created_utc": "2025-12-30 23:03:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtgb19",
              "author": "intLeon",
              "text": "I dont know if svi team has their own wrapper for that but even without kjnodes it would be too difficult to try for me.",
              "score": 1,
              "created_utc": "2025-12-30 23:05:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwtjtnr",
          "author": "foxdit",
          "text": "I've tentatively fixed the slow-mo issue with my version of this workflow. It uses 2 samplers for each segment: 2 steps HIGH (no Lightx2v, cfg 3.0), 4 steps LOW (w/ lightx2v, cfg 1). That alone handles most of the slow-mo. BUT, I went one step further with the new Motion Scale node, added to HIGH model:\n\nhttps://www.reddit.com/r/StableDiffusion/comments/1pz2kvv/wan_22_motion_scale_control_the_speed_and_time/\n\nUsing 1.3-1.5 time scale seems to do the trick.",
          "score": 1,
          "created_utc": "2025-12-30 23:24:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtkdou",
              "author": "intLeon",
              "text": "Im around the same settings now but testing 2 + 2 + 3. Low lora seems to have TAA like side effects. Motion scale felt a little unpredictable for now. Especially since its a batch job and things could go sideways any moment Ill look for something safer.",
              "score": 1,
              "created_utc": "2025-12-30 23:27:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwto11v",
                  "author": "foxdit",
                  "text": "My edited workflow has lots of quality of life features for that sort of thing. It sets fixed seeds across the board, with individual EasySeed nodes controlling the seed value for each of them. This allows you to keep segments 1 and 2, but reroll on segment 3 and continue from there if you thought the segment came out bad initially. You'll never have to restart the whole gen from scratch if one segment doesn't look right--you just regen that individual one. As long as you don't change any values from the earlier \"ok\" segments, it'll always regen a brand new seeded output for the segment you're resuming from. It works great and as someone on a slow GPU, it's a life saver.",
                  "score": 1,
                  "created_utc": "2025-12-30 23:47:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwtka42",
          "author": "tutman",
          "text": "Is there a workflow for a 12VRAM and I2V? Thanks!",
          "score": 1,
          "created_utc": "2025-12-30 23:26:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtkl20",
              "author": "intLeon",
              "text": "I have a 4070ti with 12gb vram and this is an I2V based workflow.",
              "score": 1,
              "created_utc": "2025-12-30 23:28:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwtlr6n",
          "author": "HerrgottMargott",
          "text": "This is awesome! Thanks for sharing!\nFew questions, if you don't mind answering:\n1. Am I understanding correctly that this uses the last latent instead of the last frame for continued generation?\n2. Could the same method be used with a simpler workflow where you generate a 5 second video and then input the next starting latent manually?\n3. I'm mostly using a gguf model where the lightning loras are already baked in. Can I just bypass the lightning loras while still using the same model I'm currently using or would that lead to issues?\n\nThanks again! :)",
          "score": 1,
          "created_utc": "2025-12-30 23:34:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtodix",
              "author": "intLeon",
              "text": "1- yes\n2- maybe if you save the latent or convert video to latent then feed it, but requires a reference latent as well\n3- probably\n\nEnjoy ;)",
              "score": 2,
              "created_utc": "2025-12-30 23:49:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwttyoa",
          "author": "Mirandah333",
          "text": "Why it ignores completely the first image (suposed to be the 1st frame)? Something am I missing? :(((",
          "score": 1,
          "created_utc": "2025-12-31 00:19:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtuznn",
              "author": "intLeon",
              "text": "Is load image output connected into encode subgraph?\n\n(Also dont forget to go in encode subgraph by double clicking and setting the resize mode to crop instead of stretch)",
              "score": 2,
              "created_utc": "2025-12-31 00:25:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwvuqoh",
                  "author": "Mirandah333",
                  "text": "For the first time, after countless workflows and attempts, I‚Äôm getting fantastic results: no hallucinations, no unwanted rapid movements. Everything is very smooth and natural. And not only in the full-length output, but also in the shorter clips (I set up a node to save each individual clip before joining everything together at the end, so I could follow each stage). I don‚Äôt know if this is due to some action of SVI Pro on each individual clip, but the result is amazing. And you‚Äôve given me the best gift of the year! Because the SVI Pro workflows I tested here before didn‚Äôt work! Truly, thank you very much. No more pay for Kling or Hailuo! (Even paying this shit, i had hallucinations all the time!)",
                  "score": 2,
                  "created_utc": "2025-12-31 08:37:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwudkdi",
          "author": "prepperdrone",
          "text": "r/NeuralCinema posted an SVI 2.0 workflow a few days ago.  I will take a look at both tonight.  One thing I wish you could do is feed it anchor images that aren't the starting image.  Is that possible somehow?",
          "score": 1,
          "created_utc": "2025-12-31 02:11:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvg0w3",
              "author": "intLeon",
              "text": "It would be. You can duplicate the encode node and feed a new image into it. Then use the output latent on the node you want. It may still try to adapt to previous latent so you need to set motion latent count to 0 in the subgraph. Or you can let it run and see what happens ü§î Could end up with a smoother transition.",
              "score": 1,
              "created_utc": "2025-12-31 06:25:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwvwpuy",
          "author": "IrisColt",
          "text": "The video is continuous, but still... uncanny... it's like the first derivative of the video isn't.",
          "score": 1,
          "created_utc": "2025-12-31 08:56:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww6z55",
              "author": "intLeon",
              "text": "I mean we still need something like z image for videos kind of compact fast and high quality output systems. There is also bit of a luck involved with seeds and lightx2v loras.",
              "score": 2,
              "created_utc": "2025-12-31 10:33:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwwn5u7",
                  "author": "IrisColt",
                  "text": "...aside from the eggshell disappearing trick, heh... ;)",
                  "score": 2,
                  "created_utc": "2025-12-31 12:51:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwwphqv",
          "author": "witcherknight",
          "text": "All red nodes, updated comfyUi but nothing seems to work, Nodes are still missing ??",
          "score": 1,
          "created_utc": "2025-12-31 13:07:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwwifq",
              "author": "intLeon",
              "text": "Delete kjnodes package from custom nodes folder and reinstall it.",
              "score": 1,
              "created_utc": "2025-12-31 13:52:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwx6bs3",
          "author": "Kindly-Annual-5504",
          "text": "Is it somehow possible to use SVI with something like Wan 2.2 Rapid AIO (I2V), which only uses the low noise model of Wan? I tried it myself, but it doesn't seem to work or I did something wrong.",
          "score": 1,
          "created_utc": "2025-12-31 14:48:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxj3oi",
              "author": "intLeon",
              "text": "Ive never tested it. Each lora should work on their noise level but idk.",
              "score": 2,
              "created_utc": "2025-12-31 15:54:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwxmli2",
                  "author": "Kindly-Annual-5504",
                  "text": "Yeah, other low noise loras do work fine with Rapid AIO, but this one seems to have issues or it's me. My generated video looks bad, it has strange artifacts, even when I'm not using the extended thing. With normal i2v everything is fine.",
                  "score": 1,
                  "created_utc": "2025-12-31 16:11:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwx964g",
          "author": "Fresh-Exam8909",
          "text": "Thousand thanks for this!\n\n~~The only things:~~\n\n~~- The ZIT image creates a back view image of the soldier, but the video shows the soldier from front. Is it suppose to be like that?~~\n\n~~- Every 5 seconds there is a change of perspective in the video, and I don't know why.~~\n\n~~I'm using the default prompts that comes with the workflow.~~\n\n  \nadded:\n\nI was able to make it work with OP help.This with the full wan2.2 on a 4090. My mistake was that I used the T2V models instead of the required I2V models. \n\nGreat workflow!",
          "score": 1,
          "created_utc": "2025-12-31 15:04:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxiwls",
              "author": "intLeon",
              "text": "Id suggest using gguf models and lora's linked in the civit.",
              "score": 2,
              "created_utc": "2025-12-31 15:53:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwxmka6",
                  "author": "Fresh-Exam8909",
                  "text": "You're right. I never use guf model. So I guess I need to find matching lora's for wan2.2 full model or wait a few months for a setup that will work with the full model.\n\nThanks!",
                  "score": 1,
                  "created_utc": "2025-12-31 16:11:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwxku6j",
          "author": "Fristi_bonen_yummy",
          "text": "I have kept all the settings at their defaults, except I am bypassing (ctrl B) the Z-I-T node and I connected the \\`Load image\\` node with my own image. For some reason the output does not seem to have used my initial image at all. I'm not sure why; maybe the cfg of 4.0 in I2V-First? Takes quite a while to generate, so experimenting with a lot of different settings will take some time and I figured maybe someone here ran into the same thing.",
          "score": 1,
          "created_utc": "2025-12-31 16:03:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxncvz",
              "author": "intLeon",
              "text": "If you are using the right models and connected your image into encode subgraph it should work. Also what does it say in console after \"got prompt\" when you queue a new generation?",
              "score": 2,
              "created_utc": "2025-12-31 16:15:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwxu5gx",
                  "author": "Fristi_bonen_yummy",
                  "text": "I seem to be a complete idiot and to have downloaded the T2V GGUF models instead of the I2V ones... I assume that will fix it, oops.",
                  "score": 1,
                  "created_utc": "2025-12-31 16:49:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwxllq1",
          "author": "PestBoss",
          "text": "Also you have to dig two levels deep to just see a preview of what you're working on, because for some reason the save node is made into a sub-graph.\n\nSurely it'd be nicer to have the vhs combiner top-levelled so you can see it's preview after each section, right there in the overall project running?\n\nIf the intention is to make this a true workflow in the broadest sense, I shouldn't need to dig two levels deep, or even leave the UI to check output folders, the previews should be right there.\n\nThe default build behaviour of CUI workflows mean a preview is present as you work. So hiding it seems counter-intuitive to a good workflow design.\n\n\nIn my case I'd left it a while and didn't see that it was generating utterly daft videos haha.\nTime to change the seeds.",
          "score": 1,
          "created_utc": "2025-12-31 16:07:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxm67j",
              "author": "intLeon",
              "text": "Those saves are temp and not clamped correctly so when you put them together you need yo cut from the latter a little. Its still a WIP honestly but you are right about the final part being hidden.\n\nI have temp and output folders up to see whats going on so will think of this.",
              "score": 1,
              "created_utc": "2025-12-31 16:09:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwxvoze",
          "author": "eatonaston",
          "text": "Very good work‚Äîtruly amazing. Would it be possible to bypass the LightX2V LoRAs? I‚Äôd like to compare the quality differences in both motion and image fidelity. I‚Äôve tried bypassing them and increasing the steps to 25 (5+10+10), but I‚Äôm getting artifacts.",
          "score": 1,
          "created_utc": "2025-12-31 16:56:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxwo8a",
              "author": "intLeon",
              "text": "It requires more I guess :(\n\n- you need to go in each I2V node\n- bypass first ksampler\n- enable add noise in the second ksampler\n- set cfg to 3.5/4 on both active ksamplers\n\n- bypass lightx2v loras in model loader\n\nSet total steps to something like 20, high no lora steps to 0 and high end step to 10.",
              "score": 2,
              "created_utc": "2025-12-31 17:01:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx021o9",
          "author": "spartanoverlord",
          "text": "Really great workflow! I was able to reconfigure it for my needs and string 8 x 97 frame subgraph / videos into an almost 50s video.\n\nhowever, Im noticing similarly to my own testing without the SVI addition in the past, after the 20s-ish mark even if i were to stay at 81 frames / run, contrast starts to slowly go and quality starts to slowly tank, Have you come across a similar thing? \n\nMy assumption is that since its reusing the end of the latents where the quality is \"worse\" than the start of each run, to start the next one, it slowly just degrades, and the longer you string them the worse the result gets.",
          "score": 1,
          "created_utc": "2025-12-31 23:59:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx06ix1",
              "author": "intLeon",
              "text": "Depends on the model, lightx2v and other loras as well as resolution. I am assuming the lora training may not work for beyond 81 frames because noone goes there due to artifacts.\n\nSomeone posted a 2 minute video on civit. Ive hit 1 minute mark myself but these are mostly relatively static shots. It needs more tests to determine how powerful it is but for below 30s it works almost always.",
              "score": 1,
              "created_utc": "2026-01-01 00:26:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx0hbtc",
                  "author": "spartanoverlord",
                  "text": "youre totally right, it looks like one of my old character weight adjustment lora was the problem, it compounded the lora every run and was the result of the issues. I disabled it and now theres maybe a less than 5% shift in contrast between the start and the end of a 1min clip, not even noticeable unless you A/B start to end, way way better than before, thanks for the suggestion!",
                  "score": 2,
                  "created_utc": "2026-01-01 01:34:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx5u0ck",
                  "author": "Particular_Pear_4596",
                  "text": "I posted the 2 min vid. With random seeds for each 5s part it's mostly luck to have a consistent long vid and it should be something relatively static. I changed the workflow to be 50 parts long, not 4 (4 min instead of 20 sec), and to save the whole vid after every 5s part, not just each 5s part, and comfyui crashed after part 24 (\\~2 min vid), cause my virtual memory was full (\\~150 GB pagefile.sys), so make sure you increase virtual memory to at least 200GB (Windows 10/11). I quess if I set fixed seeds (not random) in each 5s subgraph I'll be able to manually change the seed for the first \"bad\" part, then repeat the whole generation, then change the seed for the next bad part and so on until I get a randomly long consistent vid, it's just a matter of how much time you want to waste. I quess there should be a way to save the current state after each 5s part and start from the saved state and not repeat the whole generation from the start, but I don't know how. Also I made an alternative workflow where one prompt feeds all subgraphs, so I don't have to copy-paste a new prompt in each 50 subgraphs if i want to generate another very long monotonous vid.",
                  "score": 2,
                  "created_utc": "2026-01-01 23:28:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx0895l",
          "author": "RogLatimer118",
          "text": "I got it running on a 4070s 12gb after fiddling and getting all the models set up in the right locations. But the transitions aren't that smooth; it's almost like separate 5 second videos with a transition between them, but there is very clearly a disjointed phase out/in rather than a continuing bit of motion. Are the descriptions below each 5 second segment supposed to cover only that 5 seconds, or the entire range of the video? Is there any setting to improve the continuity as one segment shifts to the next 5 second segment?",
          "score": 1,
          "created_utc": "2026-01-01 00:37:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx08t0s",
              "author": "intLeon",
              "text": "Make sure to ;\n- use I2V models\n- use gguf models if possible\n- use the lora's linked in the civit including the right svi and lightx2v\n\nIt should not be seperate at all, some rare hiccups or too much motion are normal every now and then in a few generations.",
              "score": 1,
              "created_utc": "2026-01-01 00:40:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx0quem",
                  "author": "RogLatimer118",
                  "text": "Thanks so much for the rapid reply, and also for putting this together (it's gorgeous on a structural level!). I believe I used all of the loras and models you had as defaults in the workflows, and I did not change any of the parameters. I also did not activate any of the Bypassed nodes.\n\nI'm on a 12GB 4070super so it's not fast, but it does work - about 44min for output size 832x832 . On the prompts, should I duplicate the same prompt across all the segments? Or should I be trying to \"continue\" the motion within each segment for the next 5 seconds of prompting only? Should I be duplicating the seed to be identical at each segment or does that not matter?\n\nIn my video, I took a front view of somebody walking, and just smiling and looking side to side as they walk. At each segment, it sort of rapidly fades/transitions - there's no break in the video, but say the head position suddenly is pointing a different way and it continues to the next segment where the same thing occurs, etc.",
                  "score": 1,
                  "created_utc": "2026-01-01 02:37:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx0i99m",
          "author": "aeroumbria",
          "text": "  \nI don't know why but I tried to replicate the workflow in the pastebin and only got extremely garbled outputs:\n\nhttps://preview.redd.it/falhiskj6nag1.png?width=484&format=png&auto=webp&s=d9d7545b33bfa6a319eb2d89d994a81ad801502e\n\nThe only changes are that I don't use GGUF and I downloaded SVI 2.0 Pro from \\`vita-video-gen/svi-model\\` instead of Kijai. Is this not supposed to work with the official SVI files?",
          "score": 1,
          "created_utc": "2026-01-01 01:40:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx0j8l0",
              "author": "intLeon",
              "text": "The SVI is the issue, get it from Kijai's repo.\n\nGGUFs somehow work better and try to use the same lightx2v loras for less artifacts, they matter a lot.",
              "score": 1,
              "created_utc": "2026-01-01 01:46:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx5qkfq",
          "author": "PestBoss",
          "text": "I've been cutting and shutting this workflow a fair bit today playing with settings.\n\nIt's hard to keep track.\n\nBut does anyone get weird behaviour if 1 step of the high no lora is used? In a number of my videos of a soldier running around it's moving to the feet and watching those only.\n\nHowever if I use 2 steps it's fine.\n\nAlso I've swizzled from the latest speed up LoRA back to some more original ones which seem to give more consistency, and work better with a 2,2,2 steps setup.\n\nIn a few recent tests the 2,2,2 gives coherent, nicely paced videos, which is nice... though I feel my prompts now need to be far more detailed to get things looking correct.\n\n\nIf we could now somehow use FLF2V with the SVI2.0 node/lora then this would be pretty great.",
          "score": 1,
          "created_utc": "2026-01-01 23:09:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx5slil",
              "author": "intLeon",
              "text": "No lora sampling jumpstarts generation to have extra motion but it takes 2x time of a lora step and lora steps refine better on low steps so Im actually running it for least time most efficiency kind of thing.\n\nI think we need a custom node for that, we could request it from kijai. I probably could edit it myself but I dont have a node package repo and its extra work.",
              "score": 1,
              "created_utc": "2026-01-01 23:20:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx8aaba",
          "author": "music2169",
          "text": "Is this for i2v or t2v? Cause I don‚Äôt see an option for uploading a starting image in the workflow",
          "score": 1,
          "created_utc": "2026-01-02 09:55:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx8bwt0",
              "author": "intLeon",
              "text": "There is, you need to bypass ZIT and load your image into load image on the very left. Then connect it to encode node. (Resize works as stretch, go into encoder subgraph to make it crop)",
              "score": 2,
              "created_utc": "2026-01-02 10:10:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxbeocn",
          "author": "thetinytrex",
          "text": "Thanks for sharing! I'm still new to comfyui but I got the workflow to run and I'm confused. The video keeps jumping back to my reference image instead of continuing from the previous video output. It's like I generated 4 separate videos independently and it stitched them together. I went into the necessary subgraphs and only added loras + changed the output to match my image and set it to crop. What could I be missing? I didn't make any changes to other settings like steps.",
          "score": 1,
          "created_utc": "2026-01-02 20:34:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxbijkj",
              "author": "intLeon",
              "text": "Is the svi lora linked in there? Also are you using the gguf models and exact same lightx2v loras?\n\nAlso make sure you are using I2V models.",
              "score": 2,
              "created_utc": "2026-01-02 20:53:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxbvb8b",
                  "author": "thetinytrex",
                  "text": "Ah! Thanks for the quick response! I think it was because I used the wrong SVI model SVI\\_Wan2.2-I2V-A14B\\_lora\\_HIGH\\_v2.0\\_rank\\_128\\_fp16 instead of the SVI\\_v2\\_PRO version. Managed to generate a 20s video in 25min with my 3080ti.",
                  "score": 1,
                  "created_utc": "2026-01-02 21:55:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxcc84q",
          "author": "intermundia",
          "text": "Ooh shiny",
          "score": 1,
          "created_utc": "2026-01-02 23:23:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxcceid",
              "author": "intLeon",
              "text": "New version is up :)",
              "score": 1,
              "created_utc": "2026-01-02 23:24:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxcdtvx",
                  "author": "intermundia",
                  "text": "Sweet. What's new?",
                  "score": 1,
                  "created_utc": "2026-01-02 23:32:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxh51ti",
          "author": "Fineous40",
          "text": "Looks great so far. \n\nAny recommendations for changing video resolution? That seems to dramatically change generation time For me anyway. I generated a 20 sec video in about 10 minutes with a 4090 at your default resolution 480X832. Only changing the resolution to 480X480, after 30 minutes generation wasn't even half done. Changing the resolution back brought back the generation speed.",
          "score": 1,
          "created_utc": "2026-01-03 17:55:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxh7iln",
              "author": "intLeon",
              "text": "Thats weird, it should've been faster at 480x480. Make sure to open up an empty tab and close civit if its open. Comfyui interface sometimes slows down the generation. Otherwise less pixels = less time.",
              "score": 1,
              "created_utc": "2026-01-03 18:06:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxhbog1",
                  "author": "Fineous40",
                  "text": "I know it should go faster that‚Äôs why I commented. I tried all those things. For some reason it doesn‚Äôt like 480X480 for me but I am still trying things out.",
                  "score": 1,
                  "created_utc": "2026-01-03 18:25:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxkeesf",
          "author": "Nevaditew",
          "text": "Hopefully they'll find a way to create a perfect loop with this method ‚ôæÔ∏è",
          "score": 1,
          "created_utc": "2026-01-04 03:55:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxspgxl",
          "author": "ryukbk",
          "text": "Playing with SVI 2.0 Pro as well and getting impressed, for some reason in my case I don't need face enhance / detailer that much, might be a side effect of slower motion though.\n\nMy request for developers is, the ability to use multiple latents as key frames for SVI just like ComfyUI-Wan22FMLF does for a single generation pass. I can give SVI a starting frame but the ability to give other key frames, not just an ending frame, in infinite video gen is the holy grail for me. (and stable face/etc consistent detailer as well)",
          "score": 1,
          "created_utc": "2026-01-05 10:49:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxsw5l8",
              "author": "intLeon",
              "text": "Saw a pull request at the kjnodes for end frame. Someone mentioned mid frames. Its probably possible but Im not sure how well it would work.",
              "score": 2,
              "created_utc": "2026-01-05 11:45:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxuinro",
                  "author": "ryukbk",
                  "text": "Thanks, here we go [https://github.com/kijai/ComfyUI-KJNodes/pull/474](https://github.com/kijai/ComfyUI-KJNodes/pull/474) Probably simply adding an end frame would not work as it would interfere with what SVI is doing, hope it would be worked out soon with mid key frames",
                  "score": 1,
                  "created_utc": "2026-01-05 17:09:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nws6i59",
          "author": "Darqsat",
          "text": "I dunno but whatever I do it looks absolutely awful. I downloaded your recommended loras and my output video is a choppy mess with distorted character. Nothing really close to your video here.\n\nAnd it takes endeless time. I do 480x720 81 frames 8 steps in about 45s on 5090 with sage attention. It gives me about 4-6 sec/it. With your workflow my sec/it ups to 60-300.\n\nThe overall workflow duration is more than 10 minutes.\n\nUPD: I forgot that my NSFW model already have lightX2 loras so turned them off. It helped. Took 5 minutes but i have weird shapes on top of NSFW places now :D SVI does this? shows white/yellow oval over tits and you know what.\n\nUPD: Okay, seems like NSFW models work pretty bad for some reason. Tried your model from workflow and its better. But probably need NSFW loras now. s/it dropped back to 6-7 which is great. Takes about 4 minutes to complete that workflow.\n\nSeems interesting SVI workflow, thank you. I made it better with Tensort RIFE. It works pretty quick on my 5090.",
          "score": 1,
          "created_utc": "2025-12-30 19:23:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwsbuyw",
              "author": "intLeon",
              "text": "Thats to prevent you from getting coal.\n\nJokes aside initial no lightx2v high step could be causing that byt otherwise you get slowmo, Im still experimenting before an update.",
              "score": 1,
              "created_utc": "2025-12-30 19:48:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwt7zad",
                  "author": "Darqsat",
                  "text": "Nsfw not working at all. Constant oval shapes on top of those zones. Ping me if you know what can cause that and how to avoid it. In general looks good. I can recommend adding Clean VRAM used nodes from Easy-Use. At least I did at the end to add Tensorrt RIFE. With RIFE v49 and 32 frames the video looks smooth.",
                  "score": 1,
                  "created_utc": "2025-12-30 22:22:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwrebtk",
          "author": "TheTimster666",
          "text": "https://preview.redd.it/8bzo3moejdag1.png?width=382&format=png&auto=webp&s=f8cb41af5fb802e582dfb5bffbe4ae5f687a70b8",
          "score": 0,
          "created_utc": "2025-12-30 17:12:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrmhn0",
              "author": "intLeon",
              "text": "You are welcome to try higher resolutions and more steps üòÖ",
              "score": 3,
              "created_utc": "2025-12-30 17:50:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqjquo",
          "author": "Choowkee",
          "text": ">allegedly famous\n\nReally now...?",
          "score": -6,
          "created_utc": "2025-12-30 14:44:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqkjtm",
              "author": "intLeon",
              "text": "I mean its one of the most downloaded workflows among the wan2.2 I2V A14B. I hope you guys can move it further up ;)",
              "score": 10,
              "created_utc": "2025-12-30 14:48:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwqn142",
                  "author": "Choowkee",
                  "text": "Not with this weird attitude of yours. \n\nKijai released the lora 3 weeks ago, your title makes it sound like its something that was *just* released or thats it something driven by your workflow lol.",
                  "score": -17,
                  "created_utc": "2025-12-30 15:01:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwrdyis",
          "author": "hurrdurrimanaccount",
          "text": "it's still slowmo, not really that good",
          "score": -1,
          "created_utc": "2025-12-30 17:10:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrk6tm",
              "author": "intLeon",
              "text": "Thats the lightx2v loras. You can look for alternatives or disable lora nodes, set cfg for 2nd and 3rd phase to higher.\n\nEdit: using 2 no lora steps with a 2 + 2 + 2 sampling works.",
              "score": 2,
              "created_utc": "2025-12-30 17:39:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nws58sk",
          "author": "Tystros",
          "text": "Could you adjust your workflow so that it's easy to set one fixed seed for everything? currently it all seems to be set to randomize in all the sub graphs.",
          "score": -1,
          "created_utc": "2025-12-30 19:17:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwser91",
              "author": "foxdit",
              "text": "This is exactly what I did. I set everything to a fixed seed, then added an EasySeed node into each subgraph, titled \"Start from Here\". You just click it and it resumes the process from that segment, rather than starting over from scratch. That way, if segment #3 of 5 is bad, you just regen that specific one rather than starting over just because a middle piece is bad. You can just reroll the individual seeds as many times as you need to get a good segment, then continue on from there.",
              "score": 3,
              "created_utc": "2025-12-30 20:02:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwsc64n",
              "author": "intLeon",
              "text": "Im not sure, since they have similar latents you might get repetative motion during other parts. I guess only solution would be to load workflow through the job list.",
              "score": 1,
              "created_utc": "2025-12-30 19:50:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwscs5l",
                  "author": "Tystros",
                  "text": "you could also make it so that there can be one fixed seed X, but in the subgraphs it's X+1, X+2 etc",
                  "score": 1,
                  "created_utc": "2025-12-30 19:53:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q2mhcr",
      "title": "Z-Image-Turbo be like",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/sk08bypwn2bg1.jpeg",
      "author": "Melodic_Possible_582",
      "created_utc": "2026-01-03 05:42:50",
      "score": 407,
      "num_comments": 107,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q2mhcr/zimageturbo_be_like/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nxe3d0f",
          "author": "JamesMCC17",
          "text": "Yep models prefer a War and Peace length description.",
          "score": 120,
          "created_utc": "2026-01-03 05:45:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxl9f8q",
              "author": "Additional-Shoe-651",
              "text": "https://preview.redd.it/h5588c5seabg1.png?width=1024&format=png&auto=webp&s=8485797a2a30b19f49741e17bc48d890344f4b58",
              "score": 18,
              "created_utc": "2026-01-04 07:45:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxe42w5",
              "author": "Melodic_Possible_582",
              "text": "a good thing i like about it though is that once you want to dial something in precisely you can do a few words adjustments to get close to what you want.",
              "score": 31,
              "created_utc": "2026-01-03 05:50:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxet5qy",
                  "author": "dreamyrhodes",
                  "text": "Collect prompt elements in wildcards organized by topics and have a variance.",
                  "score": 17,
                  "created_utc": "2026-01-03 09:22:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxevdzb",
              "author": "CX-001",
              "text": "I'm confused as to what you guys are generating. Most of my prompts are like 4 or 5 sentences. Spend most of the time tweaking the description or finding tags that work. Generated wildcards are neat, i do use those sometimes, but the bulk is still hand-typed.\n\nMaybe the only exception is when i see a cool complicated drawing that i'll pass thru a chat AI for a description in photoreal style. Sometimes you get an interesting interpretation.",
              "score": 15,
              "created_utc": "2026-01-03 09:42:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxfp67x",
                  "author": "Sharlinator",
                  "text": "They‚Äôre generating 1girl, anime, big booba",
                  "score": 16,
                  "created_utc": "2026-01-03 13:33:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxghslr",
                  "author": "dtdisapointingresult",
                  "text": "Basically in more varied models, when you're in \"exploration/discovery mode\", you just give a basic description of the elements you know you want in the image, and there's enough variance in the model to give you different outputs.\n\nSo you can leave it generating like 20 images, come back, and pick 2 different ones as good candidates to continue iterating on. Most will be similar, but there's more variety.\n\nWith ZIT, this isn't possible. If you generate 20 images, it will generate almost the same image 20 times. No variations in pose, objects, clothing, etc. Therefore you cannot use ZIT to explore. You gotta use custom nodes to create prompt variety, or use img2img from another model's gens, etc.",
                  "score": 9,
                  "created_utc": "2026-01-03 16:07:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxfrs8x",
              "author": "Umbaretz",
              "text": "Except after some length they start to lose context, or get other unwanted effects (chroma) And you have to experiment with that.",
              "score": 1,
              "created_utc": "2026-01-03 13:49:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxgrxxu",
          "author": "michaelsoft__binbows",
          "text": "https://preview.redd.it/1x8epj3xz5bg1.png?width=690&format=png&auto=webp&s=d91e73d03c9850b48c06a972e8044ce0f782f798",
          "score": 27,
          "created_utc": "2026-01-03 16:54:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxewgof",
          "author": "dead-supernova",
          "text": "Btw you can use your native language because it understand many languages because of qwen 3 used as text encoder",
          "score": 18,
          "created_utc": "2026-01-03 09:51:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxgbshc",
          "author": "Caesar_Blanchard",
          "text": "I've seen some simple images on Civitai with literal Holy Bibles written in it",
          "score": 16,
          "created_utc": "2026-01-03 15:38:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxjuro1",
              "author": "inagy",
              "text": "Even these newer models can't accept infinite amount of text. eg. [Z-image's recommended maximum is 1024 tokens](https://huggingface.co/Tongyi-MAI/Z-Image-Turbo/discussions/8). Past that you are just speaking to the void.",
              "score": 8,
              "created_utc": "2026-01-04 02:03:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxenh9d",
          "author": "aziib",
          "text": "tbh i just use chatgpt to make the prompt for z-image turbo because how long the prompt is.",
          "score": 11,
          "created_utc": "2026-01-03 08:32:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxe5jzd",
          "author": "Zaeblokian",
          "text": "I actually like it. English isn‚Äôt my native language, so I have to keep checking the dictionary all the time, and that‚Äôs how I learn. It‚Äôs a good workout for the brain.",
          "score": 73,
          "created_utc": "2026-01-03 06:02:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxeay0u",
              "author": "CommercialOpening599",
              "text": "I'm already bilingual and I don't. I spent years learning danbooru tags crafting and now I'm supposed to switch to natural language instead...",
              "score": 52,
              "created_utc": "2026-01-03 06:45:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxebxhy",
                  "author": "red__dragon",
                  "text": "What bugs me about NLP is that there's no good reference for what effect a term or phrase will have on the prompt. \n\nWill \"beach\" also make the skin tanned? Will \"climbing\" put snow on the mountain? Does \"outline\" indicate a drawing or sketch, or a literal line out of bounds? Etc. \n\nThe cumulative weight of everything in the prompt together *should* guide the model, sure, but many of the DiT models now also have a certain \"common sense\" programming whispering in their ears and telling it things I didn't say or suggest. \n\nAt least with danbooru you could literally go to the booru, find the tag, and see what images showed up for them. Then you know what to expect. With NLP you just...hope your common sense is the same as what the model trainers are using.",
                  "score": 56,
                  "created_utc": "2026-01-03 06:53:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxer7he",
                  "author": "rinkusonic",
                  "text": "It would be funny if someone learned english through this and started talking in tags.\n\n\n7am, meeting, important meeting, multiple people, formal suit, looking at each other, (serious face:1.6), long table, chairs, multiple chairs, successfull meeting, see you later",
                  "score": 47,
                  "created_utc": "2026-01-03 09:05:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxepgan",
                  "author": "VantomPayne",
                  "text": "I've been here since 1.5 days, I can tell that among the current newest models, even Chroma take some booru tags that doesn't really mean the same thing in natural languages, so it is likely that the chinese models like ZIT and Qwen are not trained with the booru dataset at all. But the ZIT team has asked the NAI creator for their dataset so perhaps we will get something in the end.",
                  "score": 3,
                  "created_utc": "2026-01-03 08:50:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxerzxh",
              "author": "AnalConnoisseur69",
              "text": "English isn't my native language, but it's my dominant language. But even then, when some nerd (the impressive kind) comes in with: \"first of all, you can create a ControlNe-\", I'm like \"Hold up, hold up, hold up, what...?\". Still don't know what that is.",
              "score": 5,
              "created_utc": "2026-01-03 09:12:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxer2sj",
              "author": "Gaia2122",
              "text": "Try prompting in your own language. You might be surprised.",
              "score": 2,
              "created_utc": "2026-01-03 09:04:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxfmqd1",
                  "author": "Toclick",
                  "text": "I did try. A lot of things turned out inaccurate and far from what I wanted. But once I translated my prompt into English, the image came out exactly the way I needed.",
                  "score": 5,
                  "created_utc": "2026-01-03 13:18:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxf0upf",
                  "author": "Zaeblokian",
                  "text": "That‚Äôs impossible. In my own language I know about twenty thousand words, while in English ‚Äî maybe fifteen hundred. And even that I‚Äôm not sure about. Lol",
                  "score": 0,
                  "created_utc": "2026-01-03 10:28:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nximyw7",
              "author": "yaxis50",
              "text": "GoonABC",
              "score": 1,
              "created_utc": "2026-01-03 22:12:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxem39t",
              "author": "vilzebuba",
              "text": "funnily, for some reason it can understand different language besides of english. found for yourself it understand russian lol",
              "score": 1,
              "created_utc": "2026-01-03 08:20:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxebesu",
          "author": "GoodBlob",
          "text": "Maybe its because I do mostly anime stuff, but I really don't like z-image. Its just feels flat worse then illustrious and the slight increase in quality isn't worth the complications or crazy prompting. Not to mention not being able to create specific characters",
          "score": 23,
          "created_utc": "2026-01-03 06:49:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxefpvw",
              "author": "AshLatios",
              "text": "Waiting for the base version to roll out. I'm sure vendors like WaiAni and others will do wonders.",
              "score": 24,
              "created_utc": "2026-01-03 07:26:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxenuzg",
              "author": "janeshep",
              "text": "I prefer straightfoward, bullet-point-like prompts as well. But to be honest I still do them for Z-Image, give them to chatGPT and GPT makes them warandpeacey for me.",
              "score": 19,
              "created_utc": "2026-01-03 08:36:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxfi47v",
                  "author": "Trick_Statement3390",
                  "text": "I have my own set up in LM studio that does it for me üòÖ",
                  "score": 2,
                  "created_utc": "2026-01-03 12:47:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxexzzp",
              "author": "JohnSchneddi",
              "text": "THing is I just want something that is better at dealing with liiustrious flaws. One is prompt understanding. I still prefer keywords, but I find it best to use keywords and descriptions together.",
              "score": 4,
              "created_utc": "2026-01-03 10:04:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxfpdrq",
              "author": "Sharlinator",
              "text": "Well yes, it‚Äôs because you‚Äôre doing anime stuff.",
              "score": 2,
              "created_utc": "2026-01-03 13:35:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxe4tku",
          "author": "Naud1993",
          "text": "I'm too lazy to type a description like that. And also I have to store the prompt in a text file because of Windows file length limit, which is annoying. Does it give good results with short prompts?",
          "score": 7,
          "created_utc": "2026-01-03 05:56:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxe5jus",
              "author": "Melodic_Possible_582",
              "text": "yes.  you can still get good results with short prompts.  sometimes even better because i've noticed that my longer prompts destroy image quality sometimes.  long prompts are good to do if what you're trying to do doesn't work.  An example might be: front view, from above.  Somehow if this didn't work then you might have to write: the camera is situated from above the eye level and looking down on the subject.  So this is 4 words vs 15 words.  they add up.",
              "score": 6,
              "created_utc": "2026-01-03 06:02:00",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nxh3ihy",
              "author": "Freonr2",
              "text": "ZIT already has Qwen3 4B loaded, it can be used to enhance the prompt.",
              "score": 1,
              "created_utc": "2026-01-03 17:48:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxfrl41",
          "author": "Hi7u7",
          "text": "Is this just a meme, or is it real?\n\n\n\nI'm a noob, and I usually write short prompts, using only the necessary words and short tags with Z-IMAGE. Doesn't Z-IMAGE work the same way as SDXL?\n\n\n\nIf I'm doing it wrong, how do I make longer prompts? I mean, if I want a person sitting in a chair, do I absolutely have to add more details to the scene?",
          "score": 2,
          "created_utc": "2026-01-03 13:48:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxfxb9k",
              "author": "Melodic_Possible_582",
              "text": "its real.  i wanted to add that info, but felt many people here were experienced people already.  it does work the same way.  its just that the long prompts allow for fine tuning without changing the overall image much.",
              "score": 2,
              "created_utc": "2026-01-03 14:21:29",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nxhwtrp",
              "author": "ImLonelySadEmojiFace",
              "text": "I see it more like tag based works, but you gain some real control over the image by going with a longer natural language description. Try combining them! If something in your image doesnt end up the way you like just describe it naturally and it ought to turn out really well. \n\nI noticed for text especially its important to be detailed. If i prompt something simple like \"The word 'x' is visible on the image\" itll misspell the word, generate it several times over on the same image. If however i prompt it like \"To the top left, angled at 45 degrees in handwritten cursive the text 'x' can be seen\" itll generate it correctly. It starts running into issues once I have more than three our four locations displaying text that is a few words long at least, but anything below works great.",
              "score": 2,
              "created_utc": "2026-01-03 20:03:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxhdgco",
              "author": "No-Zookeepergame4774",
              "text": "Z-Image uses a very different text encoder and trained captioning style than SDXL, it really likes detailed natural language prompts (both the paper on the creators‚Äô Huggingface space actually use an LLM prompt enhancer to flesh out user prompts.) That said, it can work with shorter, or tag-based prompts, but they may not always be the best way to get what you want out of it.",
              "score": 1,
              "created_utc": "2026-01-03 18:33:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxhyu3k",
              "author": "ItsBlitz21",
              "text": "I‚Äôm such a noob I haven‚Äôt even used SD yet. Can you explain this meme to me",
              "score": 1,
              "created_utc": "2026-01-03 20:13:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxikv55",
              "author": "Comrade_Derpsky",
              "text": "Tags *can* work (it will also make coherent pictures with no prompt), but prompting with tags isn't really playing to Z-Image's strengths. What it wants is a precise natural language description of the image. That's what Z-Image is trained on and if you prompt it this way you'll have much more control over the image. \n\nThe qwen3b text encoder is orders of magnitude smarter than the CLIP models SDXL uses and can understand detailed descriptions extremely well.",
              "score": 1,
              "created_utc": "2026-01-03 22:01:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxfyx3q",
          "author": "Doc_Exogenik",
          "text": "Like it, can describe each characters.",
          "score": 2,
          "created_utc": "2026-01-03 14:30:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxfjps2",
          "author": "Justify_87",
          "text": "I switched back to flux dev with res_2s and beta57 till the freaking base model gets released. Much more reliable and I don't need to be a scientist to stack loras",
          "score": 4,
          "created_utc": "2026-01-03 12:58:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxezp5x",
          "author": "aimasterguru",
          "text": "I use this prompt builder - [https://promptmania.site/](https://promptmania.site/) its good for detailed prompts.",
          "score": 2,
          "created_utc": "2026-01-03 10:18:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxe65zf",
          "author": "magik_koopa990",
          "text": "Me sucking balls with video gen...\n\n\nAI video, please stop making the person talking",
          "score": 3,
          "created_utc": "2026-01-03 06:06:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxeo8jo",
              "author": "narkfestmojo",
              "text": "a bit off topic, but having same issue with WAN 2.2\n\nI tried 'chewing, talking, moving mouth' in negative prompt, worked somewhat OK, but not perfect, would like to find the magic negative prompt that solves this.",
              "score": 3,
              "created_utc": "2026-01-03 08:39:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxgglki",
                  "author": "throttlekitty",
                  "text": "Describing facial expressions isn't a magic bullet, but it works great. \"lips are pursed while concentrating on...\", or \"arches an eyebrow while...\"\n\nLike if you're prompting for multiple actions, stuff like this can help anchor it into the prompt without adding flowery language. \"...has a determined expression\" early in the prompt, and then later \"...expression changes to disappointment.",
                  "score": 1,
                  "created_utc": "2026-01-03 16:01:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxezjzx",
              "author": "Noiselexer",
              "text": "Haha yes, all nsfw vids the ppl are talking non stop so stupid.",
              "score": 2,
              "created_utc": "2026-01-03 10:17:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxg3cig",
          "author": "hurrdurrimanaccount",
          "text": "what? all newer NL models are like this. goddamn the ZIT shilling is getting out of hand",
          "score": 2,
          "created_utc": "2026-01-03 14:54:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxesdn0",
          "author": "AdministrativeBlock0",
          "text": "Install Ollama and an ablated/uncensored/josified Qwen 3 model, and just prompt it to \"expand this tag prompt to be detailed text.. <prompt>\". There's ComfyUI nodes for doing it as part of a flow.",
          "score": 2,
          "created_utc": "2026-01-03 09:15:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxetvxh",
              "author": "dreamyrhodes",
              "text": "Requires you to load another model into the GPU",
              "score": 3,
              "created_utc": "2026-01-03 09:29:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxf85fx",
                  "author": "Baturinsky",
                  "text": "You can run the text model on cpu. As the text is relatively small, it does not take that long.",
                  "score": 3,
                  "created_utc": "2026-01-03 11:29:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxf67wq",
              "author": "nymical23",
              "text": "Instead of installing ollama, install llama.cpp and use something like [ComfyUI-Prompt-Manager](https://github.com/FranckyB/ComfyUI-Prompt-Manager).",
              "score": 3,
              "created_utc": "2026-01-03 11:13:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxh3v4t",
                  "author": "Freonr2",
                  "text": "ollama is just a (bad) llama.cpp wrapper.  \n\nI would think they are interchangeable and the custom nodes just call the openai completions endpoint and you can use any LLM hosting software for that (vllm, llama.cpp, ollama, sglang, LM Studio, etc).\n\nIf the nodes are actually hard coded to ollama specifically then that's fairly braindead design.  If they use openai package can call just about anything with the HTTP completions endpoint.",
                  "score": 3,
                  "created_utc": "2026-01-03 17:50:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxfxoik",
              "author": "Square_Empress_777",
              "text": "Any links to the uncensored versions?",
              "score": 1,
              "created_utc": "2026-01-03 14:23:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxh8is3",
                  "author": "AdministrativeBlock0",
                  "text": "They're in the Ollama models library.",
                  "score": 1,
                  "created_utc": "2026-01-03 18:11:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxh3pvx",
              "author": "Freonr2",
              "text": "Why not just use the Qwen3 4B that is already loaded?\n\nIs it really that censored or hard to jailbreak?",
              "score": 1,
              "created_utc": "2026-01-03 17:49:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxhe137",
              "author": "No-Zookeepergame4774",
              "text": "Or just do that using the QwenVL node set for ComfyUI, instead of adding another program to the mix, if you aren't using Ollama outside of ComfyUI.",
              "score": 1,
              "created_utc": "2026-01-03 18:35:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxfh6wa",
          "author": "Confusion_Senior",
          "text": "Use qwen 3 for prompt expansion",
          "score": 1,
          "created_utc": "2026-01-03 12:41:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxh2keg",
          "author": "Etsu_Riot",
          "text": "No really. I write relatively small prompts mostly. It supports everything, including old prompts from previous models.",
          "score": 1,
          "created_utc": "2026-01-03 17:44:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxh76p6",
          "author": "rodinj",
          "text": "What does it require? Seems to work fine with my simple prompts, but mastering it sounds neat",
          "score": 1,
          "created_utc": "2026-01-03 18:05:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxhbjcz",
          "author": "Tyler_Zoro",
          "text": "Prompt: girl\n\nhttps://preview.redd.it/083poxo7d6bg1.png?width=1088&format=png&auto=webp&s=3d39f00f57e4a4d216453b8de505e02eafc786c8",
          "score": 1,
          "created_utc": "2026-01-03 18:24:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxjdp03",
          "author": "raindownthunda",
          "text": "Using an LLM (like qwen3 or mistral) to write prompts is the way!",
          "score": 1,
          "created_utc": "2026-01-04 00:30:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxk8640",
          "author": "niffuMelbmuR",
          "text": "I use OLlama to write my prompts, it's about the only way to get a lot of diversity out of ZIT.",
          "score": 1,
          "created_utc": "2026-01-04 03:19:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxkpxwf",
          "author": "JazzlikeLeave5530",
          "text": "I'd love a model that can work with both. I know some can. Tags for specific parts and natural language for the more complex stuff that can't be explained with tags.",
          "score": 1,
          "created_utc": "2026-01-04 05:10:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxkw61l",
          "author": "TheMagic2311",
          "text": "True, for newbies too, use QwenVL to get details and modify it for perfect results",
          "score": 1,
          "created_utc": "2026-01-04 05:55:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxqyrau",
          "author": "Baccipagano80",
          "text": "M",
          "score": 1,
          "created_utc": "2026-01-05 02:52:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxf681y",
          "author": "BorinGaems",
          "text": "And yet it's way easier to get great output with shorter prompt on zit than on illustrious where instead it often becomes a deluge of tags.",
          "score": 1,
          "created_utc": "2026-01-03 11:13:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxgawwl",
          "author": "Traditional_Boss5031",
          "text": "AJAJJAA",
          "score": 0,
          "created_utc": "2026-01-03 15:33:42",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q916xs",
      "title": "You can add audio to existing videos with LTX2",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/mozeqd7c3icg1",
      "author": "Roggies",
      "created_utc": "2026-01-10 10:51:41",
      "score": 403,
      "num_comments": 62,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q916xs/you_can_add_audio_to_existing_videos_with_ltx2/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nyrny8a",
          "author": "WildSpeaker7315",
          "text": "yeah i posted a workflow the other day uploading a video, ppl just get mad.. :/ lol if you wanna do more for it, put the video info into a node that takes it frame rate then make that the framerate for LTX2 , most videos are 32 or 24 but if you missmatch the framerates it sounds , and plays like ass.",
          "score": 17,
          "created_utc": "2026-01-10 11:02:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyroip6",
              "author": "protector111",
              "text": "Mad for what?",
              "score": 4,
              "created_utc": "2026-01-10 11:07:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyroz68",
                  "author": "WildSpeaker7315",
                  "text": "no idea but it has negative upvotes i think and people didnt care lol but it does work pretty well for none talking, if you feed around 41 frames into it with motion it can continue that motion then speak ontop of it, seems pretty decent.",
                  "score": 7,
                  "created_utc": "2026-01-10 11:11:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyrqe4d",
              "author": "Roggies",
              "text": "Yeah I had that earlier but there was a video I tested it where the cop car was chasing the man in slow mo, and the sound was bad :P so I made the FPS a numerical input for me to speed it up for LTX to generate better",
              "score": 3,
              "created_utc": "2026-01-10 11:24:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyrqmdp",
                  "author": "WildSpeaker7315",
                  "text": "ah you did match it, didnt notice. good job im gonna remove my link people should just use ur workflow",
                  "score": 1,
                  "created_utc": "2026-01-10 11:26:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nys4szr",
              "author": "Perfect-Campaign9551",
              "text": "It sounds like ass by default anyway lol",
              "score": 1,
              "created_utc": "2026-01-10 13:16:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyxooz8",
              "author": "ThatsALovelyShirt",
              "text": "Here's a ComfyUI node I made to resample FPS of an input video. Can either upsample or downsample, and uses Torch to make it fast:\n\nhttps://pastebin.com/raw/DM8rzkVv",
              "score": 1,
              "created_utc": "2026-01-11 07:22:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyrny3l",
          "author": "Maskwi2",
          "text": "That's sweet! Thanks for sharing.\nI wish we were at the point where this would actually be a generated video as well :)¬†",
          "score": 17,
          "created_utc": "2026-01-10 11:02:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyvjusl",
              "author": "No-Business-7545",
              "text": "have you tried from a still",
              "score": 1,
              "created_utc": "2026-01-10 23:37:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyrvy69",
          "author": "ANR2ME",
          "text": "Since the video got masked to prevent modifications, that also mean it can't adjust the lipsync (in the case there is conversation), right? ü§î",
          "score": 2,
          "created_utc": "2026-01-10 12:11:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyryzba",
              "author": "Sudden_List_2693",
              "text": "What is we de-mask only the face though?  \nThough LTX will probably mess up the face.",
              "score": 3,
              "created_utc": "2026-01-10 12:34:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyrwd5a",
              "author": "Roggies",
              "text": "For now, yes it doesn't change lip sync as my goal when doing this was to just add sound to some scenes I did with WAN. Normally if I wanted speech I would use Veo or LTX directly.\n\nI'll try it out later and see if it works. For now, you can experiment and try it out! To bypass the latent mask inside the subgraph (around the bottom left part).",
              "score": 2,
              "created_utc": "2026-01-10 12:14:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyser48",
          "author": "Ok_Entrepreneur4166",
          "text": "I tried this workflow in comfyui but has issues getting it running. The SimpleMath node needed to be replace which seems okay now, but when trying to run there is an error at the CFG in your subgroup. \n\nhttps://preview.redd.it/dxcxaukx5jcg1.png?width=732&format=png&auto=webp&s=3b51751435d4bf3b0f97dd08d95495a0adb570dd",
          "score": 2,
          "created_utc": "2026-01-10 14:15:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nysks8u",
              "author": "Roggies",
              "text": "That's very weird. :O I didn't touch that part. Most of the workflow is from the first iteration of the Text to Video template from comfy. I'm not sure if they changed the template since Day 1",
              "score": 1,
              "created_utc": "2026-01-10 14:49:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyrq5il",
          "author": "intLeon",
          "text": "Only good use of the model for me so far..",
          "score": 4,
          "created_utc": "2026-01-10 11:21:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyrqoj5",
              "author": "Roggies",
              "text": "Yeah, I prefer WAN's motion so I thought of trying this, and it worked pretty ok :)",
              "score": 4,
              "created_utc": "2026-01-10 11:26:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyrohvd",
          "author": "vault_nsfw",
          "text": "How long can those videos be? (Never used LTX)",
          "score": 1,
          "created_utc": "2026-01-10 11:07:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyrqi5b",
              "author": "Roggies",
              "text": "Not too sure, I think LTX has a limit of 20 seconds, but I think its more about how much VRAM you have to store the frames.",
              "score": 3,
              "created_utc": "2026-01-10 11:25:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nysbyny",
                  "author": "sirdrak",
                  "text": "You can do longer videos if you have the necessary amount of VRAM.",
                  "score": 2,
                  "created_utc": "2026-01-10 13:59:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyrq9nv",
              "author": "intLeon",
              "text": "I've seen 20s long videos. Dont know if there's a limit.",
              "score": 1,
              "created_utc": "2026-01-10 11:22:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyrr5z6",
          "author": "PhotoRepair",
          "text": "this is bonkers good!",
          "score": 1,
          "created_utc": "2026-01-10 11:30:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyrw82z",
          "author": "Odd-Mirror-2412",
          "text": "I've been waiting for this. Thank you!",
          "score": 1,
          "created_utc": "2026-01-10 12:13:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyrwfb8",
          "author": "314kabinet",
          "text": "It should be possible to add video to existing audio too!",
          "score": 1,
          "created_utc": "2026-01-10 12:15:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyrxx3i",
              "author": "Roggies",
              "text": "There are workflows out there on this Reddit for that :)",
              "score": 4,
              "created_utc": "2026-01-10 12:26:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyry4ut",
          "author": "Valtared",
          "text": "I tried and it works pretty well. Only thing is that it turned a 6 sec video into a slower 8 sec videos, I need to check the frame maths (original wan is 32 fps because I interpolate).",
          "score": 1,
          "created_utc": "2026-01-10 12:28:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyryylk",
              "author": "Roggies",
              "text": "Check the video load, I've hard locked it to 25 fps for my test on that workflow.  \nYou can change the fps on the Load Video and the fps at the bottom of the Text2Video SubGraph node.\n\nSo, you should probably set 32 fps for both of this setting.  \nYeah, the workflow isn't optimized :) Sorry",
              "score": 2,
              "created_utc": "2026-01-10 12:34:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nys2eqq",
          "author": "gwynnbleidd2",
          "text": "For some reason I can't find simplemathfloat+ node anywhere. I installed the comfy essenitials manager linked to but node still missing",
          "score": 1,
          "created_utc": "2026-01-10 12:59:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nys4qdf",
              "author": "Roggies",
              "text": "Oh weird. I guess you can use the built in float node from comfy core (I have no idea this existed! I've always used Simple Math Float), and promote the value out as the fps",
              "score": 1,
              "created_utc": "2026-01-10 13:15:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nys6ptw",
          "author": "extra2AB",
          "text": "For some reason when I tried using your workflow, yes it does generate sound of cars and stuff properly, but for some reason, along with that, it also adds a piano music to it.\n\nI tried writing MUSIC in the negative prompt, yet it still seems to be adding the music for some reason.",
          "score": 1,
          "created_utc": "2026-01-10 13:28:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nys87ro",
              "author": "Roggies",
              "text": "Yeah these models always tend to add music. I had the same issue with early days of Veo :) Maybe it's a seed problem",
              "score": 1,
              "created_utc": "2026-01-10 13:37:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nystsag",
                  "author": "extra2AB",
                  "text": "I even used your exact seed too.\n\ndon't know what the issue is, I will give it more tries.",
                  "score": 1,
                  "created_utc": "2026-01-10 15:37:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nys73mb",
          "author": "Valtared",
          "text": "Do you need to add a prompt or will the the IA guess the appropriate sounds ?",
          "score": 1,
          "created_utc": "2026-01-10 13:30:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nys8aod",
              "author": "Roggies",
              "text": "I assume writing a prompt helps out the model. So far I've just copied the same prompt I used to make the Wan videos into it and it turned out ok",
              "score": 1,
              "created_utc": "2026-01-10 13:37:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nysggel",
                  "author": "Valtared",
                  "text": "I tried no prompt on a romantic video and it only added cheesy saxo music ;)",
                  "score": 1,
                  "created_utc": "2026-01-10 14:25:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nys9z1d",
          "author": "1Neokortex1",
          "text": "Thanks bro!\nI needed something like this,but the sound generators are there are limited.\nDoes anyone know of any others than wan, just in case this doesnt work??",
          "score": 1,
          "created_utc": "2026-01-10 13:47:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nysg1tw",
          "author": "serendipity777321",
          "text": "Can I do it on freepik or higgsfield? I'm too lazy to setup the pod and workflow",
          "score": 1,
          "created_utc": "2026-01-10 14:23:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nysyuet",
          "author": "Noeyiax",
          "text": "Ty I appreciate youuuu üëç",
          "score": 1,
          "created_utc": "2026-01-10 16:02:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyt6mq2",
          "author": "scubadudeshaun",
          "text": "This is cool, I was wondering about that.  I wish the LTX audio was better quality.  I usually use mmaudio but the timing isn't always in sync, so I end up post processing in video editing software to sync the timing from several mmaudio generations.",
          "score": 1,
          "created_utc": "2026-01-10 16:39:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyup128",
              "author": "Maskwi2",
              "text": "It will be in the next release that's coming within the month. That's what CEO said at least.¬†",
              "score": 1,
              "created_utc": "2026-01-10 21:01:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyu0sez",
          "author": "lordpuddingcup",
          "text": "So for the people that love WAN... WAN + LTX For audio addon",
          "score": 1,
          "created_utc": "2026-01-10 19:01:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyuk65i",
          "author": "FantasticFeverDream",
          "text": "I'm sure this will beat MMaudio",
          "score": 1,
          "created_utc": "2026-01-10 20:36:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyv8ke6",
          "author": "FxManiac01",
          "text": "interesting! will it also \"recreate\" videos? Like if we put wan2.2 video of person not talking and want LTX2 make them talk.. will it recreate wan2.2 video so lips are moving and syncing with audio generated?",
          "score": 1,
          "created_utc": "2026-01-10 22:38:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nywvanu",
          "author": "DeliciousGorilla",
          "text": "I‚Äôve made real live action short films before, had fun doing foley in my garage for certain scenes, and buying stock audio for other parts (coincidentally, one was a car driving on a dirt road). Looks like foley artist is another job about to be less desirable. Not yet, but soon enough.",
          "score": 1,
          "created_utc": "2026-01-11 03:54:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxic1m",
          "author": "shibeprime",
          "text": "Now take stuff from [Gifs You Can Hear](https://www.reddit.com/r/GifsYouCanHear/) and run it through , let me know how it goes",
          "score": 1,
          "created_utc": "2026-01-11 06:27:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1585a",
          "author": "appenz",
          "text": "Not bad, but not quite at the level of non-open-source models like Mirelo [https://www.mirelo.ai/](https://www.mirelo.ai/)",
          "score": 1,
          "created_utc": "2026-01-11 20:08:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyrtrzy",
          "author": "Kiyushia",
          "text": "generate with wan 2.2 > add audio with ltx2. cool!",
          "score": 1,
          "created_utc": "2026-01-10 11:53:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nys359r",
          "author": "RepresentativeRude63",
          "text": "Oh that‚Äôs nice to knowü´∂ can we use it to lipsync? Generate random talking avatar with wan and actual talking with ltx ? Please someone try this",
          "score": 0,
          "created_utc": "2026-01-10 13:05:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyryy9a",
          "author": "ready-eddy",
          "text": "Welp, rip foley/sound designers.",
          "score": -5,
          "created_utc": "2026-01-10 12:34:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nys1j02",
              "author": "protector111",
              "text": "sound quality is beyond garbage (by comercial standards). this is just a toy for now.",
              "score": 15,
              "created_utc": "2026-01-10 12:53:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyt33k0",
                  "author": "Opposite-Station-337",
                  "text": "I wasn't expecting to be able to run something this capable on 16gb vram and 32 system memory for another year. It may feel like a demo/toy, but I have a feeling the difference between now and *then* isn't that long.",
                  "score": 1,
                  "created_utc": "2026-01-10 16:22:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q5epih",
      "title": "Z-Image *perfect* IMG2IMG designed for character lora's - V2 workflow (including LORA training advice)",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1q5epih",
      "author": "RetroGazzaSpurs",
      "created_utc": "2026-01-06 10:08:31",
      "score": 395,
      "num_comments": 107,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q5epih/zimage_perfect_img2img_designed_for_character/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nxziwez",
          "author": "Upper-Reflection7997",
          "text": "The skin looks too noisy and static a crt tv.",
          "score": 85,
          "created_utc": "2026-01-06 10:49:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzr6a9",
              "author": "BeAlch",
              "text": "It's turning any woman into - an older than original - Anne Hathaway",
              "score": 35,
              "created_utc": "2026-01-06 11:57:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxzj60w",
              "author": "RetroGazzaSpurs",
              "text": "can change to normal vae if dont like the fluxultra vae look, plus turn the skin detailer off",
              "score": 10,
              "created_utc": "2026-01-06 10:51:41",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "ny04mbt",
              "author": "edisson75",
              "text": "May be I am wrong, but I used to get that noise skin when the image size, height and with, were not divisible by 64. A solution may be resize or crop the reference image and latent so both can be divisible by 64.",
              "score": 2,
              "created_utc": "2026-01-06 13:27:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny05iqn",
                  "author": "Upper-Reflection7997",
                  "text": "what are the appropriate resolution sizes from z image you recommended. I've been using the standard sdxl recommended resolutions sizes for the longest time for all image models.",
                  "score": 3,
                  "created_utc": "2026-01-06 13:32:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny0fney",
                  "author": "GraftingRayman",
                  "text": "makes no difference if the size is divisible by 64, there is too much noise with lora's on zimage, hopefully resolved if the base image is released.\n\nhowever i have found less noise if there are 60+ images being used to train the lora, the more images the less the noise.",
                  "score": 2,
                  "created_utc": "2026-01-06 14:27:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny0f9n7",
                  "author": "RetroGazzaSpurs",
                  "text": "this is definitely something worth looking into, i do find that changing dimensions has huge difference in outputs in zimage",
                  "score": 1,
                  "created_utc": "2026-01-06 14:25:51",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxznyi8",
              "author": "jonbristow",
              "text": "How would you fix that",
              "score": 0,
              "created_utc": "2026-01-06 11:32:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxzi0pu",
          "author": "Grand0rk",
          "text": "Amazing. That Asian woman became a white woman in one simple click.",
          "score": 32,
          "created_utc": "2026-01-06 10:41:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxziefn",
              "author": "RetroGazzaSpurs",
              "text": "thats genuinely the crazy part of this WF, complete style and pose transfer on such low denoise between people that look nothing alike",
              "score": 4,
              "created_utc": "2026-01-06 10:45:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny0342r",
          "author": "polawiaczperel",
          "text": "Heroin Lora",
          "score": 24,
          "created_utc": "2026-01-06 13:18:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny03djr",
              "author": "polawiaczperel",
              "text": "Oh shit, you trained it on yourself? I am so sorry.",
              "score": 3,
              "created_utc": "2026-01-06 13:19:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny04scv",
          "author": "edisson75",
          "text": "Thanks a lot for sharing.",
          "score": 8,
          "created_utc": "2026-01-06 13:27:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzlsht",
          "author": "its_witty",
          "text": "What do you mean by: '512 resolution only' ... 'upscale to 4000px'?",
          "score": 4,
          "created_utc": "2026-01-06 11:14:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzmkr0",
              "author": "RetroGazzaSpurs",
              "text": "upscale your lora images to 4000px on the longest side, but only train on 512 resolution in ai toolkit",
              "score": 2,
              "created_utc": "2026-01-06 11:20:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny1n69i",
                  "author": "the_bollo",
                  "text": "Why?",
                  "score": 6,
                  "created_utc": "2026-01-06 17:52:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzkeaf",
          "author": "HashTagSendNudes",
          "text": "I‚Äôve been using the fp32 and it‚Äôs been way better than the fp16 I train my Loras at 768 with no caption for character Loras results have been great, before I used the fp32 I just ran double sampler for fp16 and ifor the second pass set the Denoise to 0.15 and just added like , detailed skin, add detail and that seemed to do the job fairly well",
          "score": 5,
          "created_utc": "2026-01-06 11:02:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny07025",
              "author": "SuicidalFatty",
              "text": "no caption ? no any caption describing the image or just no trigger word with other caption ?",
              "score": 2,
              "created_utc": "2026-01-06 13:40:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0hjcf",
                  "author": "RetroGazzaSpurs",
                  "text": "0 caption across the board, no trigger words, no captions - works very well for me with z-image only",
                  "score": 4,
                  "created_utc": "2026-01-06 14:37:59",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxzkmer",
              "author": "RetroGazzaSpurs",
              "text": "interesting will have to try fp32, ive seen others say they think it makes a difference",
              "score": 1,
              "created_utc": "2026-01-06 11:04:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny1tszj",
                  "author": "HashTagSendNudes",
                  "text": "For me it‚Äôs night and day honestly I was like why are my Lora‚Äôs coming out bad? Then I tried the fp32 same prompt way better",
                  "score": 1,
                  "created_utc": "2026-01-06 18:21:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny35jmm",
              "author": "No-Educator-249",
              "text": "You mean you only got better results when training Z-Image LoRAs using fp32 precision? That's interesting to know, as from my own training runs, fp32 doesn't make a difference in SDXL, as it only increases memory use and compute time. However, SD 1.5 does benefit from fp32. I got better LoRAs when using fp32 precision to train them.\n\nI also want to add that training without captions increases the risk of overfitting. Using a single \"trigger word\" in the very beginning of the caption followed by a simple description of the character or person alongside the background works best to prevent overfitting in the case of training a person. I just verified this myself in a new training run of a previous SDXL LoRA I did some time ago.",
              "score": 1,
              "created_utc": "2026-01-06 21:59:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny3ure8",
              "author": "TechnicianOver6378",
              "text": "> I just ran double sampler for fp16\n\nCan you explain more about what this means? I have a pretty good working knowledge of ComfyUI and most concepts, but I have only recebtkt begun running locally--First GPU for christmas!",
              "score": 1,
              "created_utc": "2026-01-07 00:05:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny89p9k",
              "author": "Quirky_Bread_8798",
              "text": "When you say fp32, you mean in the training options in AI Toolkit, right?",
              "score": 1,
              "created_utc": "2026-01-07 16:59:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny0bsx1",
          "author": "mission_tiefsee",
          "text": "maybe state what you are trying to do, then maybe drop a word or two about the workflow. Is the lora essential to your img2img workflow? It seems like you made a character lora and then used img2img to change arbitrary chars into you lora'd character. right?\n\nOr maybe not? When i do img2img i take an image, convert to latent space, feed into a sampler and adjust the denoise value. Half of your post ist describing a lora creation workflow.\n\nYou clearly put work in there. It is just that i have no idea, what actually you are trying to present here. Looking at your linked post, it might involve a SAM based workflow (wich would be quite interesting, so why not mention it here too?)\n\nthis is just a feedback post, feel free to ignore.",
          "score": 4,
          "created_utc": "2026-01-06 14:07:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0gev2",
              "author": "RetroGazzaSpurs",
              "text": "it is mainly a workflow designed for people who are interested in using a character lora to transform a person in an image to someone else while keeping composition, theme, style, background, etc mostly the same\n\nit works well with any well-made lora, i thought i would just include my lora parameters aswell incase someone wants to exactly follow what i'm doing\n\nthe SAM section of the WF is a second pass that only inpaints the face and helps restore the face particularly at distance",
              "score": 2,
              "created_utc": "2026-01-06 14:31:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny2jv1w",
                  "author": "mission_tiefsee",
                  "text": "Thank you! Makes sense!",
                  "score": 2,
                  "created_utc": "2026-01-06 20:20:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny2qozq",
          "author": "Character_Title_876",
          "text": "# AILab_QwenVL\n\nAllocation on device  \nThis error means you ran out of memory on your GPU.  \n  \nTIPS: If the workflow worked before you might have accidentally set the batch\\_size to a large number.",
          "score": 3,
          "created_utc": "2026-01-06 20:51:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny03fi1",
          "author": "moarveer2",
          "text": "big thanks for this but a bit of explanation on the workflow would be nice, it's huge and i barely understand what goes where and what every block of nodes does.",
          "score": 3,
          "created_utc": "2026-01-06 13:20:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0fyu4",
              "author": "RetroGazzaSpurs",
              "text": "to be honest i spent so long messing around with it i expected most people would just want to use it as a plug and play - tbh the only thing i would recommend messing with is probably just denoise strength and image sizing",
              "score": 1,
              "created_utc": "2026-01-06 14:29:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny6blki",
                  "author": "moarveer2",
                  "text": "i got the hang of it and it's great but took me a while lol",
                  "score": 2,
                  "created_utc": "2026-01-07 10:09:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny0i64k",
          "author": "Cold_Development_608",
          "text": "![gif](giphy|rdma0nDFZMR32)\n\nExcellent workflow - The best I have seen.  \nBypassed QWENVL nodes.",
          "score": 3,
          "created_utc": "2026-01-06 14:41:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2jpo5",
          "author": "Ok-Page5607",
          "text": "sounds amazing! I‚Äòm also deep into img2img with zimg. I know the hustle it takes to achieve good results, especially with loras! I'm looking forward to testing your workflow. Thanks for sharing!",
          "score": 3,
          "created_utc": "2026-01-06 20:19:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzwdgq",
          "author": "Rance_Mulliniks",
          "text": "One of those actually looks like the character you are trying to generate. I am having better results with QWEN.",
          "score": 2,
          "created_utc": "2026-01-06 12:35:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0c5oj",
          "author": "Shyt4brains",
          "text": "This looks good. Can't wait to test it later. Thanks.",
          "score": 2,
          "created_utc": "2026-01-06 14:09:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0e0z9",
          "author": "skyrimer3d",
          "text": "Very impressed with this, LLM node gave me errors so i just deleted it and entered the prompt manually and worked really well, thanks for this workflow.",
          "score": 2,
          "created_utc": "2026-01-06 14:19:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0fmor",
              "author": "RetroGazzaSpurs",
              "text": "glad you like it, make sure to experiment with different sizes and cropping etc, you can get very different results",
              "score": 1,
              "created_utc": "2026-01-06 14:27:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyjiotw",
          "author": "jalbust",
          "text": "Thanks",
          "score": 2,
          "created_utc": "2026-01-09 04:51:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0n1lc",
          "author": "iamthenightingale",
          "text": "I've been using a similar method myself and i figured out how to stop the excessive grain. I don't know if it'll help you but I use:\n\n1. Anything at 100% denoise (8step)\n\n2. Heun at 90% noise (8-step) to get the face shape in - The heun makes a sort of 'Vaseline on the lens' version of the image with perfect face structure 95% of the time \n\n3. DPM++ SDE at 27% (4-step) to bring in just enough the details/grain. \n\nSteps 2 and 3 bring over the composition and colour almost completely. For whatever reason, Heun always seems to bring out likenesses the best no matter what model is used (Flux included).",
          "score": 2,
          "created_utc": "2026-01-06 15:06:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0dt1f",
          "author": "false79",
          "text": "Is it me or is turning every woman into Anne Hathaway a downgrade from the original, lol",
          "score": 3,
          "created_utc": "2026-01-06 14:18:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1ji0h",
              "author": "sabin357",
              "text": "It certainly didn't help that they all looked like an Anne that has aged a good amount & lived a hard life.",
              "score": 2,
              "created_utc": "2026-01-06 17:35:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny00uks",
          "author": "bickid",
          "text": "I've never seen Anne Hathaway look this ugly, something went very wrong in your workflow, lol.",
          "score": 5,
          "created_utc": "2026-01-06 13:04:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0178b",
              "author": "RetroGazzaSpurs",
              "text": "share your WF and perfect lora if you have one",
              "score": -1,
              "created_utc": "2026-01-06 13:06:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny0xbgw",
                  "author": "GanondalfTheWhite",
                  "text": "The people here are drunk, man. This is some of the best work I've seen. These people are just too used to overly smooth AI skin on all their AI gooner waifus and they don't remember what real people look like.\n\nThe skin might be slightly overtextured but TBH it looks way more believable than 99% of super airbrushed plasticky skin in typical AI portraits.",
                  "score": 13,
                  "created_utc": "2026-01-06 15:54:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzjc89",
          "author": "xbobos",
          "text": "great job! It works well.",
          "score": 2,
          "created_utc": "2026-01-06 10:53:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzjs1z",
          "author": "Xxtrxx137",
          "text": "a link to vae files would be nice",
          "score": 1,
          "created_utc": "2026-01-06 10:56:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzk6oe",
              "author": "RetroGazzaSpurs",
              "text": "linked in the original post linked above!",
              "score": 1,
              "created_utc": "2026-01-06 11:00:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxzklhw",
                  "author": "Xxtrxx137",
                  "text": "those seem different from the ones in this workflow\n\ni have been using them but you have two different ones in this workflow",
                  "score": 1,
                  "created_utc": "2026-01-06 11:03:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzs0st",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-06 12:03:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzt9ee",
              "author": "RetroGazzaSpurs",
              "text": "comfycore node pack",
              "score": 1,
              "created_utc": "2026-01-06 12:12:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxzutth",
          "author": "Helpful-Orchid-2437",
          "text": "What learning rate did you use for lora training?",
          "score": 1,
          "created_utc": "2026-01-06 12:24:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzv59d",
              "author": "RetroGazzaSpurs",
              "text": "default",
              "score": 2,
              "created_utc": "2026-01-06 12:26:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny0ght2",
          "author": "teasider",
          "text": "Works partially great. I Cant get over the 2nd qwen node for the face. Getting this error:\n\n> AILab_QwenVL\n> function 'cint8_vector_quant' not found",
          "score": 1,
          "created_utc": "2026-01-06 14:32:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0h6jc",
              "author": "RetroGazzaSpurs",
              "text": "other people have had that problem for some reason\n\ntry doing what this guy did, it fixed it for him\n\n  \n[https://www.reddit.com/r/StableDiffusion/comments/1q5epih/comment/ny0e0z9/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/r/StableDiffusion/comments/1q5epih/comment/ny0e0z9/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",
              "score": 2,
              "created_utc": "2026-01-06 14:36:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny0hbqw",
                  "author": "RetroGazzaSpurs",
                  "text": "although of course better to get it working so its automatic - im not sure why the second node is glitching when the first one is fine",
                  "score": 1,
                  "created_utc": "2026-01-06 14:36:52",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny0slcw",
          "author": "singfx",
          "text": "Cool workflow! The results are a bit uncanny, maybe try prompting a white woman that resembles Anne Hathaway more initially.",
          "score": 1,
          "created_utc": "2026-01-06 15:32:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0tiup",
          "author": "Cold_Development_608",
          "text": "Do you think the seeds should be the same ?",
          "score": 1,
          "created_utc": "2026-01-06 15:37:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0x89t",
              "author": "RetroGazzaSpurs",
              "text": "can try, not sure if makes a difference",
              "score": 1,
              "created_utc": "2026-01-06 15:54:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny14rpr",
          "author": "According-Leg434",
          "text": "perchance org had good time of celebrity making but then yeah also got removed too bad",
          "score": 1,
          "created_utc": "2026-01-06 16:28:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1536j",
          "author": "No-Bat9958",
          "text": "How do you even put this into comfyui? Sorry, but Im new and have no clue. all I have is a text file now",
          "score": 1,
          "created_utc": "2026-01-06 16:30:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny16rph",
              "author": "RetroGazzaSpurs",
              "text": "simply rename it to .json instead of .txt then drag and drop your json file into comfyui",
              "score": 1,
              "created_utc": "2026-01-06 16:37:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3bzfz",
          "author": "IrisColt",
          "text": "Again... I kneel, it's mind-blowing...",
          "score": 1,
          "created_utc": "2026-01-06 22:30:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4s0ed",
              "author": "RetroGazzaSpurs",
              "text": "nice to see someone enjoyingü´°",
              "score": 2,
              "created_utc": "2026-01-07 03:03:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3fu35",
          "author": "hibana883",
          "text": "What's the prompt with the girl laying on the tennis court?",
          "score": 1,
          "created_utc": "2026-01-06 22:48:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4s31m",
              "author": "RetroGazzaSpurs",
              "text": "Put the picture through the Qwen node included in the workflow",
              "score": 2,
              "created_utc": "2026-01-07 03:03:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3hixu",
          "author": "whatupmygliplops",
          "text": "Why not just do face swap?",
          "score": 1,
          "created_utc": "2026-01-06 22:57:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4k4c8",
              "author": "Cold_Development_608",
              "text": "Run this worklow, you will junk all the previous face swaps hacks. Form ROOP to ....",
              "score": 2,
              "created_utc": "2026-01-07 02:20:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3t1tl",
          "author": "ofrm1",
          "text": "Why are you being mean to Anne Hathaway? Lol",
          "score": 1,
          "created_utc": "2026-01-06 23:56:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny7b7qt",
          "author": "goodssh",
          "text": "How about we wait for zimage-edit",
          "score": 1,
          "created_utc": "2026-01-07 14:16:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny80oa5",
          "author": "weskerayush",
          "text": "There seem to be some problem with workflow. I have 3070Ti 8GB and 32GB and I am getting stuck in Ksampler for about half an hour now. 30 mins passed and only 33% Ksapmler progress. Stuck in this- (RES4LYF) rk\\_type: res\\_3s. My img is of 1049\\*1062 and rest of the settings are same as your WF. I tried for 2 days and same problem is occurring. I have used ZiT before and tried many WFs and imgs generated within a min.",
          "score": 1,
          "created_utc": "2026-01-07 16:19:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny83prd",
              "author": "RetroGazzaSpurs",
              "text": "change the qwen vl to a fp8 and see if it helps",
              "score": 1,
              "created_utc": "2026-01-07 16:33:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny9vm37",
                  "author": "weskerayush",
                  "text": "But it's stuck on the ksampler and not on qwen node",
                  "score": 1,
                  "created_utc": "2026-01-07 21:13:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny9mwxn",
          "author": "XMohsen",
          "text": "Hello, thanks for the workflow.   \nI have a question which may be related or not, but I'm more curious about your lora (method).   \nhow you trained it ? in comfy ?  \nhow is it ? i mean normal generation without this wf. i would like to see result of this training method.",
          "score": 1,
          "created_utc": "2026-01-07 20:35:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyja95u",
              "author": "RetroGazzaSpurs",
              "text": "On ai toolkit with the settings provided above and everything else default",
              "score": 1,
              "created_utc": "2026-01-09 04:00:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyjvjuz",
          "author": "Style-yourself",
          "text": "Hello and thanks for for sharing. I'm  new to this and I'm struggling creating the dataset in terms of face consistency. What metod do you use to create dataset for LoRA training starting from a Reference Image? I presume this is one of the most important steps for a quality LoRA. Thanks",
          "score": 1,
          "created_utc": "2026-01-09 06:25:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny08ard",
          "author": "Sea-Rope-3538",
          "text": "Amazing man! I like it! The skin looks too noisy in second pass, but overral image works well. I¬¥m testing diferents Samplers like ClownSharkSampler, do u test it? I will reduce the noise in lightroom and upscale with topaz to see what i can get, thank u",
          "score": 1,
          "created_utc": "2026-01-06 13:47:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0gop1",
              "author": "RetroGazzaSpurs",
              "text": "i tried other samplers, but i ended up just reverting to default advanced ksampler, i might try clownshark for sure as it usually provides great results",
              "score": 2,
              "created_utc": "2026-01-06 14:33:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny194rc",
          "author": "Upper_Basis_4208",
          "text": "How you make her look old ?\nLol",
          "score": 1,
          "created_utc": "2026-01-06 16:48:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1trxx",
              "author": "RetroGazzaSpurs",
              "text": "Not really, she is 40, i think she looks 40 in most of these",
              "score": 1,
              "created_utc": "2026-01-06 18:21:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny1ufy3",
                  "author": "WizardSleeve65",
                  "text": "She looks awful on the bike XD",
                  "score": 2,
                  "created_utc": "2026-01-06 18:24:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny2dsbd",
                  "author": "EternalBidoof",
                  "text": "Maybe 40 year old women who have been doing hard drugs for 20 years.",
                  "score": 2,
                  "created_utc": "2026-01-06 19:51:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny059bt",
          "author": "AwakenedEyes",
          "text": "\"no trigger no caption, nothing\" isn't an advertisement of feature, it's an admission of not knowing how to train a LoRA. \n\nHey look! I am driving this car, no need for breaks, no hands!!!",
          "score": -5,
          "created_utc": "2026-01-06 13:30:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0o0r4",
              "author": "ImpressiveStorm8914",
              "text": "While your comment is an admission that nobody should take you seriously when you don't even know how to spell 'brakes'. :-D",
              "score": 4,
              "created_utc": "2026-01-06 15:10:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0povc",
                  "author": "AwakenedEyes",
                  "text": "Hey give me a \"break\" it's my second language. ;-)",
                  "score": 1,
                  "created_utc": "2026-01-06 15:18:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny0fe3m",
              "author": "RetroGazzaSpurs",
              "text": "i've tried both extensively, i prefer none dk what to tell you",
              "score": 2,
              "created_utc": "2026-01-06 14:26:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxzkt9j",
          "author": "Infamous-Price4262",
          "text": "Hello redditors | can anyone tell if its possible to make a lora on 8gb vram and 16gb ram ? and what setting needed without getting oom and how much time will it take to make one lora ?",
          "score": 0,
          "created_utc": "2026-01-06 11:05:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzn4tl",
              "author": "weskerayush",
              "text": "I have seen video that it's possible. Tried myself too but one or the other error always occurred during downloading and preparing the environment. I tried thrice but it didn't worked for me, always some error but those are errors of preparing environment and not the training itself. \nTry to do it and see if it works. Be aware that it downloads around 30Gb once it starts the process so Be patient. \nAlso, train imgs on bucket size of 512. Don not go above that or you may run into OOM. 2500 steps. Low Vram, fp8 float. You do not need to caption any photos as it works fine.",
              "score": 0,
              "created_utc": "2026-01-06 11:25:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxznhz3",
                  "author": "Infamous-Price4262",
                  "text": "Did you made , Or not ?",
                  "score": 1,
                  "created_utc": "2026-01-06 11:28:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q6k2a3",
      "title": "Definition of insanity (LTX 2.0 experience)",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/imh8xunpbybg1",
      "author": "Silly_Goose6714",
      "created_utc": "2026-01-07 16:31:39",
      "score": 394,
      "num_comments": 67,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q6k2a3/definition_of_insanity_ltx_20_experience/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny85uth",
          "author": "Itchy_Ambassador_515",
          "text": "Great dialogue haha! Which model version are you using, like fp8, fp4 etc",
          "score": 29,
          "created_utc": "2026-01-07 16:42:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny869b3",
              "author": "Silly_Goose6714",
              "text": "The one from the template, dev fp8",
              "score": 15,
              "created_utc": "2026-01-07 16:44:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny8b928",
                  "author": "_raydeStar",
                  "text": "This is cool!! I have a 4090 and I must be doing something wrong, my test gen took me like an hour.",
                  "score": 6,
                  "created_utc": "2026-01-07 17:07:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyde7sn",
              "author": "Lucky-Necessary-8382",
              "text": "Lads, look it up where is company located behind this model. Thank me later",
              "score": -1,
              "created_utc": "2026-01-08 09:52:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny94i6s",
          "author": "lolxdmainkaisemaanlu",
          "text": "I got happy reading the RTX 3060 12GB part because I have that too but then I read.... 80 GB RAM :((((",
          "score": 9,
          "created_utc": "2026-01-07 19:15:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyb7222",
              "author": "RogLatimer118",
              "text": "Theoretically the pagefile is for extending virtual memory, although at much slower speed. So it might work with a large pagefile plus existing smaller RAM.",
              "score": 4,
              "created_utc": "2026-01-08 00:58:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny9amv0",
              "author": "Silly_Goose6714",
              "text": "Maybe it works with less, you can always lower the resolution and length. Use the option --novram and have a large pagefile",
              "score": 2,
              "created_utc": "2026-01-07 19:42:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny8o0cr",
          "author": "3r0Van",
          "text": "Vaas is devaastated..!!! Lol..!!! ü§òüèº",
          "score": 8,
          "created_utc": "2026-01-07 18:03:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9mucw",
          "author": "SubtleAesthetics",
          "text": "I really like how expressive the outputs are with this model, also if you use a workflow with an audio input + image, and say \"the person is singing\", they really get into it if it's a uptempo track for example.\n\nWe waited for wan 2.5 for a while but this is even better.  24fps, longer gens, no slow mo, more expressive.  also, I have been able to do 10s+ gens with a 4080 (16GB) and 64GB RAM, you dont even need a 5090 or RTX 6000, which is nice.",
          "score": 5,
          "created_utc": "2026-01-07 20:35:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny9sjzf",
              "author": "Rare-Site",
              "text": "How? my system has 24gb vram, 64gb ram and i still get a OOM! Is there a different workflow from kaija?",
              "score": 2,
              "created_utc": "2026-01-07 21:00:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nya0365",
                  "author": "SubtleAesthetics",
                  "text": "maybe the resolution is set too high, but i've had no issues with 120-200 frames total and at a size like 900x700 for example",
                  "score": 3,
                  "created_utc": "2026-01-07 21:32:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny89pd7",
          "author": "GoranjeWasHere",
          "text": "How did you do it ? What comfyui did you use ? any modifications ?\n\nI sit here with 5090 and for me generating like 3 seconds take like 15 minutes at 1100x700",
          "score": 6,
          "created_utc": "2026-01-07 16:59:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8bubi",
              "author": "Silly_Goose6714",
              "text": "I'm using \"--reserve-vram 5\" line. You need to have a lot of RAM and a large pagefile",
              "score": 7,
              "created_utc": "2026-01-07 17:09:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny8ephk",
                  "author": "GoranjeWasHere",
                  "text": "Thanks I found my issue. I was using official workflow from ltx workflow folder instead of using template from comfyui templates.\n\nNow i get generations in seconds after loading up model.",
                  "score": 10,
                  "created_utc": "2026-01-07 17:22:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny8gmqv",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 2,
                  "created_utc": "2026-01-07 17:31:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny8cimd",
          "author": "embrionida",
          "text": "This one was quite funny",
          "score": 5,
          "created_utc": "2026-01-07 17:12:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8h20m",
          "author": "SkirtSpare4175",
          "text": "Great prompt",
          "score": 3,
          "created_utc": "2026-01-07 17:33:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8n955",
          "author": "Plane_Platypus_379",
          "text": "My problem with LTX2 so far has been mouth movement.  No matter what I do, the characters really move their jaw.  It doesn't seem natural.",
          "score": 3,
          "created_utc": "2026-01-07 18:00:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyad7b0",
          "author": "Frogy_mcfrogyface",
          "text": "DAMN! 16:21 for that res and fps on a 3060 is great :o can't wait to try it out on my 5060ti 16gb.¬†",
          "score": 3,
          "created_utc": "2026-01-07 22:30:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyb9rvd",
          "author": "EpicNoiseFix",
          "text": "All the LTX tests are giving PS4 video game cut scene vibes. Anyone else?",
          "score": 3,
          "created_utc": "2026-01-08 01:12:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyd18e3",
              "author": "Old-Artist-5369",
              "text": "That one felt like Far Cry to me",
              "score": 2,
              "created_utc": "2026-01-08 07:54:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny885bz",
          "author": "Hearcharted",
          "text": "![gif](giphy|Kcw5bmss1LxiIYylkG)",
          "score": 4,
          "created_utc": "2026-01-07 16:52:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyabsyk",
          "author": "LockeBlocke",
          "text": "AI in general has an overacting problem. A lack of subtlety. As if it were trained on millions of low attention span tiktok videos.",
          "score": 4,
          "created_utc": "2026-01-07 22:23:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8v3xm",
          "author": "physalisx",
          "text": ">A rugged, intimidating bald man with a mohawk hairstyle, facial scar, and earring stands in the center of a lush tropical jungle. Dense palm trees, ferns, and vibrant green foliage surround him. Dappled sunlight filters through the canopy, creating dynamic lighting across his face and red tank top\n\nIs it necessary for an I2V prompt with LTX to verbosely describe what's in the initial picture? I see this a lot, people also do it heavily with Wan, where it is actually completely unnecessary and probably only reduces prompt adherence.",
          "score": 2,
          "created_utc": "2026-01-07 18:34:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8vwwi",
              "author": "Silly_Goose6714",
              "text": "I don't believe so but it's worked, If it hadn't worked, I would have asked it to stop doing it.",
              "score": 2,
              "created_utc": "2026-01-07 18:38:08",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "ny982kn",
              "author": "Ramdak",
              "text": "Kinda yeah, you need to \"constrain\" what freedom the generation will have in order to achieve good results, even in i2v.  \nI made simple prompts work, but depending on the image  the model will do whatever it feels to. Like adding a second character, an odd camera motion, and so on.  \nThis was always a thing with LTX.",
              "score": 2,
              "created_utc": "2026-01-07 19:31:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyau63y",
              "author": "thegreatdivorce",
              "text": "Defining the subjects helps constrain the generation, including with WAN, unless you have a very static scene. ¬†",
              "score": 2,
              "created_utc": "2026-01-07 23:53:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyblhm8",
          "author": "Jota_be",
          "text": "I just tested it with a 5080, 32GB of DDR4 RAM, and changed ltx to dev-fp8 and gemma3 to e4m3fn.\n\nTo make it work, I found the solution on Reddit in one of the hundreds of posts to start Comfyui with my configuration: \n\n.\\\\python\\_embeded\\\\python.exe -s ComfyUI\\\\main.py --windows-standalone-build --lowvram --cache-none --reserve-vram 8\n\nTimes with your same prompt:\n\n5s duration: 378s generation\n\n10s duration: 457s generation\n\n15s duration: 600s generation",
          "score": 2,
          "created_utc": "2026-01-08 02:14:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nybs86t",
              "author": "ANR2ME",
              "text": "You probably doesn't need to use reserve-vram anymore when using lowvram. That reserve-vram will only make ComfyUI not to be able to use your whole VRAM (ie. it tells ComfyUI to leave 8GB VRAM alone for other applications to use).",
              "score": 2,
              "created_utc": "2026-01-08 02:49:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyd5m6e",
          "author": "jg_vision",
          "text": "Worked great on RT 5090 , thanks for sharing",
          "score": 2,
          "created_utc": "2026-01-08 08:33:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydzzvd",
          "author": "Old-Day2085",
          "text": "Looks nice! I am new to this. Can you help me with first answering if LTX 2.0 will work on my setup having RTX 4080 16GB with 32GB RAM? I want to use portable ComfyUI. I managed to do image to 5-second video with 1280x720 resolution on WAN 2.2 full model using the same system.",
          "score": 2,
          "created_utc": "2026-01-08 12:44:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyecfv9",
              "author": "Silly_Goose6714",
              "text": "Is less demanding than wan, set a large pagefile and try",
              "score": 1,
              "created_utc": "2026-01-08 13:55:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyfc17q",
                  "author": "Old-Day2085",
                  "text": "Thanks!",
                  "score": 1,
                  "created_utc": "2026-01-08 16:43:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny8ngoj",
          "author": "Signal_Confusion_644",
          "text": "Same Specs PC, i was testing with 10 secs and veeery good. But need to try 15.\n\nThe only problem is that VAE DECODE takes too long.",
          "score": 2,
          "created_utc": "2026-01-07 18:01:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny86bt1",
          "author": "HolidayEnjoyer32",
          "text": "so this is way slower than wan2.2, right? yeah i know 8 fps more and sound, but still. 16 minutes for 15 sec of video is insane. i remember ltx 0.97 being very, very fast.",
          "score": 2,
          "created_utc": "2026-01-07 16:44:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny87gvm",
              "author": "Silly_Goose6714",
              "text": "It's incredibly fast\n\nYou can't even make an 1280 x 704 361 frames video with a RTX 3060 using wan.",
              "score": 13,
              "created_utc": "2026-01-07 16:49:54",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "ny87lze",
              "author": "UnicornJoe42",
              "text": "It's 3060..",
              "score": 6,
              "created_utc": "2026-01-07 16:50:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny8sm8s",
              "author": "jib_reddit",
              "text": "I did 20 second infinite talk WAN video and it took 3 hours on my 3090 at higher steps/ quality .",
              "score": 1,
              "created_utc": "2026-01-07 18:23:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nybpy2r",
              "author": "ANR2ME",
              "text": "It's faster than Wan2.2. Someone said it only took 1 minute to generate something that usually took 5 minutes on Wan2.2.",
              "score": 0,
              "created_utc": "2026-01-08 02:37:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyacl8c",
          "author": "tomakorea",
          "text": "He got fat somehow",
          "score": 1,
          "created_utc": "2026-01-07 22:27:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyal66g",
          "author": "Perfect-Campaign9551",
          "text": "That voice does not match that character at all lol",
          "score": 1,
          "created_utc": "2026-01-07 23:07:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8iq69",
          "author": "spacev3gan",
          "text": "Can it work on AMD GPUs? I have a 9070. I have tried different work-arounds, using ComfyUi's built-in workflow, with no success.",
          "score": 0,
          "created_utc": "2026-01-07 17:40:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8jkg3",
              "author": "Silly_Goose6714",
              "text": "Are you using base nodes? Can you use other models?",
              "score": 2,
              "created_utc": "2026-01-07 17:44:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nya204r",
          "author": "kjames2001",
          "text": "Haven't been active on this sub for a long time, just returned to comfyui. Anyone kindly explain where/how I can find the workflow on this post?",
          "score": 0,
          "created_utc": "2026-01-07 21:40:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nya2tra",
              "author": "Silly_Goose6714",
              "text": "https://preview.redd.it/e6ks31h3zzbg1.png?width=642&format=png&auto=webp&s=aaed3355615ea18974e48917bc733dbcd65a4108",
              "score": 1,
              "created_utc": "2026-01-07 21:43:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nycw3bg",
                  "author": "kjames2001",
                  "text": "The one saying ltx 2 api or ltx text to video?",
                  "score": 0,
                  "created_utc": "2026-01-08 07:09:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyay3zz",
          "author": "Tystros",
          "text": "what do you mean with \"**the only change is VAE decode is LTXV Spatio Temporal Tiled Vae Decode\"? what did you change about the VAE decode?**",
          "score": 0,
          "created_utc": "2026-01-08 00:13:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyazlld",
              "author": "Silly_Goose6714",
              "text": "The node. I'm using this node instead the core one",
              "score": 2,
              "created_utc": "2026-01-08 00:20:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyb892m",
                  "author": "Tystros",
                  "text": "what difference does it make?",
                  "score": 0,
                  "created_utc": "2026-01-08 01:04:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nye77wd",
          "author": "Limp-Victory-4494",
          "text": "Que incrivel, tenho um r5 3600 32gb de ram, 3060 12gb, eu consigo fazer isso tranquilamente ? Eu tamb√©m queria saber de algum tutorial ensinando bem do inicio mesmo, sou bem leigo mas queria aprender sobre isso",
          "score": 0,
          "created_utc": "2026-01-08 13:27:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny878ed",
          "author": "ProfessionalGain2306",
          "text": "At the end of the video, it seemed to me that his fingers were \"fused\" in the middle.",
          "score": -3,
          "created_utc": "2026-01-07 16:48:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyai3e6",
              "author": "Great-Investigator30",
              "text": "If you don't like something, make a LORA to fix it",
              "score": -1,
              "created_utc": "2026-01-07 22:52:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nybqhoo",
                  "author": "ANR2ME",
                  "text": "Or changing the seed sometimes works in fixing finger/limbs issue.",
                  "score": 1,
                  "created_utc": "2026-01-08 02:40:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q5jgnl",
      "title": "LTX-2 runs on a 16GB GPU!",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/59jm88zwjqbg1",
      "author": "Budget_Stop9989",
      "created_utc": "2026-01-06 14:04:29",
      "score": 374,
      "num_comments": 191,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q5jgnl/ltx2_runs_on_a_16gb_gpu/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny0bq09",
          "author": "Volkin1",
          "text": "I just tried it with the FP4 and got 1 min render time at 720p and it only costed me 3GB VRAM with forced streaming from RAM.",
          "score": 67,
          "created_utc": "2026-01-06 14:06:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0wakq",
              "author": "Perfect-Campaign9551",
              "text": "Isn't FP4 going to just massacre the model and have bad results?",
              "score": 11,
              "created_utc": "2026-01-06 15:50:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0wtrp",
                  "author": "Volkin1",
                  "text": "Well not quite. This should be the special nvidia NV-FP4 version which is different from the regular basic FP4. The quality should be comparable to that of FP8/FP16.",
                  "score": 15,
                  "created_utc": "2026-01-06 15:52:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny1k8x2",
                  "author": "Genocode",
                  "text": "Its close to Q4\\_K\\_M which many people use for Wan2.2, but with Wan2.2 it takes 8gb lmao.",
                  "score": 4,
                  "created_utc": "2026-01-06 17:39:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny0c45t",
              "author": "Budget_Stop9989",
              "text": "Wow, that‚Äôs really fast. I‚Äôm going to test the FP4 version next.",
              "score": 7,
              "created_utc": "2026-01-06 14:08:51",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "ny1k0wk",
              "author": "Fytyny",
              "text": "it is super fast until you change the prompt",
              "score": 5,
              "created_utc": "2026-01-06 17:38:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1l1zc",
                  "author": "Volkin1",
                  "text": "On my end it keeps the text encoder in ram so i haven't noticed that problem when changing prompt.",
                  "score": 1,
                  "created_utc": "2026-01-06 17:42:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny1625u",
              "author": "jude1903",
              "text": "I updated comfyui and the newest templates won't show up, when I downloaded manually and used it the nodes aren't available, any tips?",
              "score": 3,
              "created_utc": "2026-01-06 16:34:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny3gx7r",
                  "author": "No-Property3068",
                  "text": "I had to update the dependencies manually from the update folder so that it shows up\nThe annoying thing is if I update from the manager it ruins it again and I have to update the dependencies again \nI tried to run on my 4070Ti but it kept giving me errors about not enough Vram, even after lowering the resolution and duration so much, I gave up and I'll try again later",
                  "score": 2,
                  "created_utc": "2026-01-06 22:54:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny0c7jh",
              "author": "PrettyVacation29",
              "text": "At this moment I have no internet no test it by myself (üò≠) can u show us FP8 vs FP4 result?",
              "score": 1,
              "created_utc": "2026-01-06 14:09:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0cb2s",
                  "author": "Volkin1",
                  "text": "I just made a post about my FP4 result.",
                  "score": 2,
                  "created_utc": "2026-01-06 14:09:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny0evq7",
              "author": "ANR2ME",
              "text": "How much RAM does it use? more than 64GB?",
              "score": 1,
              "created_utc": "2026-01-06 14:23:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0k6ks",
                  "author": "Volkin1",
                  "text": "For the moment on my end it consumed around 50GB+",
                  "score": 10,
                  "created_utc": "2026-01-06 14:51:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny0jqoy",
              "author": "masterlafontaine",
              "text": "How did you force it? Did you run on comfy-ui?",
              "score": 1,
              "created_utc": "2026-01-06 14:49:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0leln",
                  "author": "Volkin1",
                  "text": "I used the --novram comfy startup argument command.",
                  "score": 1,
                  "created_utc": "2026-01-06 14:57:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny1o3fq",
              "author": "Santhanam_",
              "text": "3gb vram? Misspelt? Possible on 3050 4gb vram?",
              "score": 1,
              "created_utc": "2026-01-06 17:56:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1p95n",
                  "author": "Volkin1",
                  "text": "No, no misspell. 3 GB VRAM was used when i was streaming the weights from RAM memory, but it used 50+ GB RAM for this. Also, I was using the FP4 model which was made for 50 series cards. I don't know if someone managed to run this on a 4GB vram gpu.",
                  "score": 2,
                  "created_utc": "2026-01-06 18:01:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny0iicb",
              "author": "jadhavsaurabh",
              "text": "Bro fp4 can u share all specs old ltx was running on my madmc but video wasnt good with humans",
              "score": -1,
              "created_utc": "2026-01-06 14:43:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0laso",
                  "author": "Volkin1",
                  "text": "RTX 5080, 64GB RAM, Linux, default comfy workflow and the fp4 model",
                  "score": 4,
                  "created_utc": "2026-01-06 14:57:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny0dlnc",
          "author": "3deal",
          "text": "I love this. Maybe Wan will retaliate by publishing Wan2.5",
          "score": 30,
          "created_utc": "2026-01-06 14:16:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0e4xe",
              "author": "No_Comment_Acc",
              "text": "I am afraid Z Image will retaliate faster than Wan, like they did right after Flux 2 releaseü§£",
              "score": 10,
              "created_utc": "2026-01-06 14:19:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0nu8t",
                  "author": "juandann",
                  "text": "isn't Z-Image is image generator? And we now talking about video generator?",
                  "score": 18,
                  "created_utc": "2026-01-06 15:09:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny0fp52",
                  "author": "Segaiai",
                  "text": "Z-Image was actually better than Flux 2 in certain areas though. I have a feeling LTX2 could take some wind out of even a Z-Image Omni release, considering it's quite possible it could dethrone the closest we've gotten to the SDXL of video. It's just too different an animal for Z-Image to try to take a bite from.",
                  "score": 2,
                  "created_utc": "2026-01-06 14:28:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny1duxg",
                  "author": "Lollerstakes",
                  "text": "I am out of the loop - is there a Z video model coming? Or why do you think it would somehow rival LTX 2 which is a video+audio model, and Z image is t2i/i2i?",
                  "score": 1,
                  "created_utc": "2026-01-06 17:10:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny0xl1s",
                  "author": "Domskidan1987",
                  "text": "With another gay API workflow I have to pay for?",
                  "score": -8,
                  "created_utc": "2026-01-06 15:55:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1l2wl",
          "author": "martinerous",
          "text": "Update: \n\nuse Kijai's fixes from here [https://www.reddit.com/r/StableDiffusion/comments/1q5k6al/fix\\_to\\_make\\_ltxv2\\_work\\_with\\_24gb\\_or\\_less\\_of\\_vram/](https://www.reddit.com/r/StableDiffusion/comments/1q5k6al/fix_to_make_ltxv2_work_with_24gb_or_less_of_vram/)\n\nand also can use [https://huggingface.co/unsloth/gemma-3-12b-it-bnb-4bit/tree/main](https://huggingface.co/unsloth/gemma-3-12b-it-bnb-4bit/tree/main) Gemma quants - they work fast and do not cause CPU offloading.\n\nDo not use the default Comfy UI LTX-2 image-to-video template - it's 2x slower (at least for me) and has a LoRA that corrupts the output at the upscaling stage. Use LTX-2\\_I2V\\_Distilled\\_wLora.json from LTX own GitHub - it's fast! 1088p 5s video generated in under 200s on 3090, unbelievable!\n\n  \n\\-----------------------\n\nGot image-to-video semi-working on a 3090. The lessons learned - they are using insane text encoder, non quantized, 20GB, it takes more time to encode the prompt than to generate the video, especially when ComfyUI offloads the encoder model to system RAM.\n\nThe default ComfyUI LTX-2 distill image-to-video template has the node LTX Audio Text Encoder Loader - that will not work if you don't have 32 GB RAM. It will either fail with OOM, or, if you use --reserve-vram, it will fail complaining that tensors are on different devices. I suspect that if you set this value higher, it offloads enough of Gemma to system RAM to avoid accidental overshooting, but then it seems to use the CPU instead of GPU for the text encoding phase.\n\nSo, use the node from the LTX own workflow in their GitHub repository. However, that workflow has additional dependencies on third-party nodes. Those can be installed. Also, inside the Input group, disable the Enhancer node - seems that it causes even more OOM issues.\n\nAnyway, use LTX Gemma 3 Model Loader instead of TX Audio Text Encoder Loader.\n\nI downloaded a smaller Unsloth quantized Gemma model, but not sure, that might actually cause the slowdown because it requested to install also compressed-tensors.\n\nhttps://preview.redd.it/pdsf5pehlrbg1.png?width=547&format=png&auto=webp&s=310dc601d1d930a2b75c29618d98e8b3af3b8b36\n\nNow the text encoder eats all of my 96GB system RAM and seems to process the prompt on the CPU, which is sloooow.\n\nMake sure to disable Preview (set to none) in Comfy settings, otherwise it will fail with mat and mat2 shapes error.\n\nThen finally it worked, yay!\n\nBut it does not free the memory, so you cannot launch it repeatedly unless you restart ComfyUI (the unloading buttons in the toolbar does not seem to always do the job).",
          "score": 15,
          "created_utc": "2026-01-06 17:43:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nybj4pf",
              "author": "DeProgrammer99",
              "text": "Did all that (including the embeddings\\_connector.py edit and using the bnb-4bit quant) and got [this error](https://github.com/Lightricks/ComfyUI-LTXVideo/issues/318) from the LTXVImgToVideoInplace node, on my RTX 4060 Ti (16 GB). Tried both Kijai's workflow and [LTX's](https://github.com/Lightricks/ComfyUI-LTXVideo/blob/master/example_workflows/LTX-2_I2V_Distilled_wLora.json), but of course both failed since they use that same node. ComfyUI and all nodes are up-to-date, too. Might be because I'm using CUDA 12.6; they \"recommend\" CUDA 12.7+.\n\nEdit: Nope, updated to CUDA 13.1 (and updated torch to 2.9.1+cuda130 and had to manually reinstall several other packages) and it still throws that cudaErrorInvalidValue error.\n\nEdit again: Turns out I just needed `--disable-pinned-memory` on the command line to get it to work. With the I2V distilled FP8 model, I was able to generate a 65-frame 640x352 video in 83 seconds (63 seconds for a retry) thanks to this hard-to-google comment: [https://www.reddit.com/r/comfyui/comments/1pqh9qg/comment/nuu7vs0/](https://www.reddit.com/r/comfyui/comments/1pqh9qg/comment/nuu7vs0/)",
              "score": 2,
              "created_utc": "2026-01-08 02:01:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2isop",
              "author": "Different-Toe-955",
              "text": "thanks for the info",
              "score": 1,
              "created_utc": "2026-01-06 20:15:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2q1ir",
              "author": "Rare-Site",
              "text": "Thanks for the Help.  \nwhere do i find Kijai's fixes?",
              "score": 1,
              "created_utc": "2026-01-06 20:48:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2qnqd",
                  "author": "martinerous",
                  "text": "[https://www.reddit.com/r/StableDiffusion/comments/1q5k6al/fix\\_to\\_make\\_ltxv2\\_work\\_with\\_24gb\\_or\\_less\\_of\\_vram/](https://www.reddit.com/r/StableDiffusion/comments/1q5k6al/fix_to_make_ltxv2_work_with_24gb_or_less_of_vram/)",
                  "score": 2,
                  "created_utc": "2026-01-06 20:51:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny15kpr",
          "author": "martinerous",
          "text": "Turns out the large Gemma text encoder used in LTX-2 comes from the repository with a warning:\n\n```\nThe checkpoint in this repository is unquantized, please make sure to quantize with Q4_0 with your favorite tool\n```\n\nLTX, why would you do this to us and make us download 20GB unquantized text encoder model?\n\nThat's in LTX own ComfyUI workflow.\n\nThe ComfyUI template has a single safetensors file, but it's still over 20GB and ends up with OOM even on a 24 GB VRAM.",
          "score": 10,
          "created_utc": "2026-01-06 16:32:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny49r36",
              "author": "stddealer",
              "text": "It's probably because vanilla ComfyUI doesn't support GGML quants (those used in GGUF files) by default.\n\n Gemma3 was trained to perform losslessly at Q4_0 quantization, but for that you need a backend that supports the Q4_0 type.",
              "score": 2,
              "created_utc": "2026-01-07 01:24:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny5x2eh",
                  "author": "martinerous",
                  "text": "Yesterday I tried this one: [https://huggingface.co/unsloth/gemma-3-12b-it-bnb-4bit/tree/main](https://huggingface.co/unsloth/gemma-3-12b-it-bnb-4bit/tree/main)  \nand it works well with LTX.",
                  "score": 1,
                  "created_utc": "2026-01-07 07:54:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny1jhqm",
              "author": "No_Comment_Acc",
              "text": "I have problems even with 48 Gb of VRAM. Generation works but I get a shit ton of errors in the log. Hopefully, they'll fix these issues asap.",
              "score": 0,
              "created_utc": "2026-01-06 17:35:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny0v3jk",
          "author": "EideDoDidei",
          "text": "Unless I'm mistaken \"--reserve-vram 10\" makes ComfyUI reserve 10GB VRAM for other applications. So you're essentially only using 6GB VRAM for making the video. I'm surprised you have to reserve that much VRAM for other stuff, but still impressive it's working fine without ridiculously high generation times.",
          "score": 6,
          "created_utc": "2026-01-06 15:44:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2iq5x",
              "author": "Different-Toe-955",
              "text": "You are right. I normally set --reserve-vram to 0.75 so I can max out VRAM and minimize system choppiness since I only have 1 gpu.",
              "score": 2,
              "created_utc": "2026-01-06 20:14:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny0c120",
          "author": "Interesting8547",
          "text": "226 seconds that's very fast for that resolution.  So I think Wan 2.2 might be dethroned...\n\nThough 7 mins looks like too long for Wan 2.2 even at 8 steps. Though I like that we would be able to generate videos with sound on LTX-2 .",
          "score": 11,
          "created_utc": "2026-01-06 14:08:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0jsup",
              "author": "Dwansumfauk",
              "text": "no throne until create boobas",
              "score": 30,
              "created_utc": "2026-01-06 14:49:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0m0gm",
                  "author": "kabachuha",
                  "text": "Give LoRA trainers some time",
                  "score": 9,
                  "created_utc": "2026-01-06 15:00:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny0yvr5",
              "author": "GasolinePizza",
              "text": "Prompt adherence is kind of weak compared to WAN, unfortunately.\nIt is better at getting things temporally placed within the scene (via the prompt) nicely, but as far as coordinating actions it seems to be notably worse =\\",
              "score": -1,
              "created_utc": "2026-01-06 16:01:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny0ce62",
          "author": "Pantheon3D",
          "text": "I'm gonna try the full unquantized version with an rtx 4070ti super 16gb vram and 128gb ddr5 ram\n\nEdit: I don't know if it will work",
          "score": 5,
          "created_utc": "2026-01-06 14:10:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0cli9",
              "author": "Pantheon3D",
              "text": "Currently downloading 60gb worth of models but I'm almost done",
              "score": 2,
              "created_utc": "2026-01-06 14:11:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0gtnz",
                  "author": "Pantheon3D",
                  "text": "update:\n\n1. it took 213 seconds to generate a 3 second video at 1280x720 and used 81gb ram\n2. 303 seconds to generate a 9 second video at 1280x720. i can't go higher sadly. vram is maxed out but there's still 40gb ram left to use\n3. ***480p is unuseable. i don't recommend trying***\n4. 1920x1080 at 110 frames =  400 seconds",
                  "score": 8,
                  "created_utc": "2026-01-06 14:34:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1kvoo",
          "author": "False_Suspect_6432",
          "text": "the LTX-2 fp4 gives this error: module 'torch' has no attribute 'float4\\_e2m1fn\\_x2'",
          "score": 4,
          "created_utc": "2026-01-06 17:42:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1vgb0",
              "author": "pro-digits",
              "text": "me to on this one, hoping a smart redditor gives help",
              "score": 1,
              "created_utc": "2026-01-06 18:28:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny0d9tz",
          "author": "Keem773",
          "text": "Interesting, if this keeps up then Wan will be dethroned asap!",
          "score": 6,
          "created_utc": "2026-01-06 14:15:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0kcse",
              "author": "witcherknight",
              "text": "lol looks garbage compared to Wan",
              "score": -3,
              "created_utc": "2026-01-06 14:52:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0r2f0",
                  "author": "Dzugavili",
                  "text": "Nah, the lip sync is fantastic. The delivery is good too, I've found infinitetalk can be a bit over the top.",
                  "score": 5,
                  "created_utc": "2026-01-06 15:25:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1pyw2",
          "author": "skyrimer3d",
          "text": "I'll skip the hype for now and let kijai and other magicians come with the goods in a few days, just knowing it actually works on 16gb VRAM is good enough, in a week this sub is going to be flooded with hot waifu vids with robotic voices every few posts no doubt.",
          "score": 7,
          "created_utc": "2026-01-06 18:04:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0kw1e",
          "author": "CurrentMine1423",
          "text": "https://preview.redd.it/fkp7x4catqbg1.png?width=1348&format=png&auto=webp&s=31dcb8a45c75a4b489e291748fa8b280f7f22f63\n\nI got this error.",
          "score": 3,
          "created_utc": "2026-01-06 14:55:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0pi58",
              "author": "Corleone11",
              "text": "Yeah me too. It works again after disabling the enhance prompt node.",
              "score": 1,
              "created_utc": "2026-01-06 15:18:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0ql69",
                  "author": "CurrentMine1423",
                  "text": "where is this node? I can't find it. I'm using comfyui default template",
                  "score": 2,
                  "created_utc": "2026-01-06 15:23:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny0vi79",
              "author": "Rumaben79",
              "text": "I get this error when I'm getting too close to my vram limit. Increasing the '--reserve-vram' value fixes this.",
              "score": 1,
              "created_utc": "2026-01-06 15:46:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny6nmrg",
              "author": "DuHal9000",
              "text": "eu tbm! ainda nao sei resolver",
              "score": 1,
              "created_utc": "2026-01-07 11:50:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny0vffr",
          "author": "martinerous",
          "text": "So, for img-to-video, the reserve parameter trick got me past the OOM in the clip text encoder node.\n\nHowever, now I get \"Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\" in text encoding.\n\nHow to get past that?\n\nI wish someone created a smaller gemma3 version. I tried to merge it from different HF shards, but it kept failing with \"invalid tokenizer\", so there is some secret sauce in that gemma\\_3\\_12B\\_it.safetensors.",
          "score": 3,
          "created_utc": "2026-01-06 15:46:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1imfw",
              "author": "No_Comment_Acc",
              "text": "I have issues too. Looks like the workflows have not been optimized at all.",
              "score": 2,
              "created_utc": "2026-01-06 17:31:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1jgxf",
                  "author": "Corleone11",
                  "text": "Yeah, same problem here. What I don't get is why they reference a smaller gemma file in the notes on the left while you still have to use the larger model. This really doesn't add up.",
                  "score": 2,
                  "created_utc": "2026-01-06 17:35:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1ptu9",
          "author": "skocznymroczny",
          "text": "I have 64GB RAM, 16GB 5070Ti but still getting OOM no matter what I do. Can you share your exact workflow and other settings?",
          "score": 3,
          "created_utc": "2026-01-06 18:04:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4a6id",
              "author": "Ok_Grapefruit_3795",
              "text": "The man posted a video of a CLOWN telling us it works on a 16gb gpu. I'm sure it's just trolling, still funny though.",
              "score": 0,
              "created_utc": "2026-01-07 01:26:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nys46q1",
                  "author": "Existing_Glove_3066",
                  "text": "Surely he is mocking us hhhh what a ragebait !",
                  "score": 1,
                  "created_utc": "2026-01-10 13:12:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny2s6fg",
          "author": "JimmyDub010",
          "text": "hoping that wan2gp can add it with all the same profiles so I can run it on 4070 super 12gb.",
          "score": 3,
          "created_utc": "2026-01-06 20:58:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2y2fk",
          "author": "Friendly-Fig-6015",
          "text": "possible run on rtx 5060 ti 16gb y 32gb ram?",
          "score": 3,
          "created_utc": "2026-01-06 21:25:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny46t6p",
          "author": "Ok_Grapefruit_3795",
          "text": "Am I the only one to think this is a troll post?",
          "score": 3,
          "created_utc": "2026-01-07 01:08:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0vpez",
          "author": "themoregames",
          "text": "Great. Now make it run on 8GB",
          "score": 4,
          "created_utc": "2026-01-06 15:47:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0c56z",
          "author": "SuicidalFatty",
          "text": "system RAM ?",
          "score": 2,
          "created_utc": "2026-01-06 14:09:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0ch7r",
              "author": "Budget_Stop9989",
              "text": "64GB RAM",
              "score": 6,
              "created_utc": "2026-01-06 14:10:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny0dnjp",
                  "author": "3deal",
                  "text": "You are rich !",
                  "score": 9,
                  "created_utc": "2026-01-06 14:17:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny0n0lz",
          "author": "juandann",
          "text": "what is the unit of --reserve-vram parameter? Is it GB or MB?\n\nEDIT: also, can you upload the full resolution? thanks",
          "score": 2,
          "created_utc": "2026-01-06 15:05:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0nn9f",
              "author": "Valuable_Issue_",
              "text": "GB, if you have 16GB VRAM and use --reserve-vram 6, comfy will see it as having 10GB VRAM. The default is 1.",
              "score": 1,
              "created_utc": "2026-01-06 15:09:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny12tfn",
          "author": "poopoo_fingers",
          "text": "https://preview.redd.it/0qq1muib8rbg1.png?width=1064&format=png&auto=webp&s=c6a9fe456a7bbb8b802bf8a0b6caa53d560b5578\n\nDoes anyone have any idea what this error means?",
          "score": 2,
          "created_utc": "2026-01-06 16:19:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny13wyr",
          "author": "Libellechris",
          "text": "Help me please!  As a beginner, specifically where do I find the lower quant files that run on a 16GB VRAM GPU?  Thanks",
          "score": 2,
          "created_utc": "2026-01-06 16:24:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny162gj",
          "author": "jude1903",
          "text": "I updated comfyui and the newest templates won't show up, when I downloaded manually and used it the nodes aren't available, any tips?",
          "score": 2,
          "created_utc": "2026-01-06 16:34:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1jttq",
          "author": "Fancy-Restaurant-885",
          "text": "Am training a lora to test right now.",
          "score": 2,
          "created_utc": "2026-01-06 17:37:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1o5e1",
          "author": "skyrimer3d",
          "text": "That's the news i've waiting for all day, thanks!",
          "score": 2,
          "created_utc": "2026-01-06 17:56:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny232px",
          "author": "X_Code_X",
          "text": "I cant even install the custom nodes from the manager. Desktop version comfyui, updated. Anyone else?",
          "score": 2,
          "created_utc": "2026-01-06 19:02:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2dhew",
          "author": "Consistent_Cod_6454",
          "text": "Please which of the model are you using with the 16 gigs Vram‚Ä¶ i have a 16gigs Vram with 64gb Ram, wondering which would be the best option",
          "score": 2,
          "created_utc": "2026-01-06 19:50:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2i6gi",
          "author": "Different-Toe-955",
          "text": "Hell yeah I'm glad a text to video+audio model came out since it seems like wan 2.5 isn't going to be made open source.",
          "score": 2,
          "created_utc": "2026-01-06 20:12:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2priq",
          "author": "ggRezy",
          "text": "is this i2v? because i average about 30 minutes for i2v on wan 2.2",
          "score": 2,
          "created_utc": "2026-01-06 20:47:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2xvow",
          "author": "ProjectEchelon",
          "text": "https://imgur.com/a/T6FxrDj\n\nThis shouldn't be tough, but nearly every LTX node is highlighted red. I ran the LTX-Video manual install script along with all the requirements and also installed every LTX custom node from the ComfyUI Manager. I'm missing something obvious for this to be such an error-fest. When running, it pops the error: \"Cannot execute because a node is missing the class_type property.: Node ID '#102'\"",
          "score": 2,
          "created_utc": "2026-01-06 21:24:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny32lru",
          "author": "sdnr8",
          "text": "I got this error: LTXVGemmaCLIPModelLoader\n\nNo files matching pattern 'tokenizer.model' found under...",
          "score": 2,
          "created_utc": "2026-01-06 21:46:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6byu2",
          "author": "Impossible-Ad-3798",
          "text": "How ypu loaded the gemma 3 12b, I cant get passt that",
          "score": 2,
          "created_utc": "2026-01-07 10:12:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6qtm0",
          "author": "Tablaski",
          "text": "16Gb vram / 32 gb RAM also. Just ran 1st T2V video using the official example workflow. \n\nI m very confused... the 1rst sampling pass was very fast (520p) but the 2nd (spatial upscaling / distilled lora) was VERY slow. And the output was really meh\n\nDo we really need that 2nd sampling pass ? What for ? At What resolution are the latents generated in the first pass ?\n\nI don't understand shit to this workflow really",
          "score": 2,
          "created_utc": "2026-01-07 12:14:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0diwu",
          "author": "Forsaken-Truth-697",
          "text": "But can you create something that is useful?\n\nThats a different thing.",
          "score": 4,
          "created_utc": "2026-01-06 14:16:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2w85m",
              "author": "Noiselexer",
              "text": "You mean nsfw? üòÇ",
              "score": 1,
              "created_utc": "2026-01-06 21:16:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny0msay",
          "author": "Hearcharted",
          "text": "![gif](giphy|x0npYExCGOZeo)",
          "score": 2,
          "created_utc": "2026-01-06 15:04:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0dcis",
          "author": "Keem773",
          "text": "What does the  --reserve-vram line do?",
          "score": 3,
          "created_utc": "2026-01-06 14:15:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0esb4",
              "author": "Silly_Goose6714",
              "text": "It reserve VRAM",
              "score": 16,
              "created_utc": "2026-01-06 14:23:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0f1v2",
                  "author": "9_Taurus",
                  "text": "Where do you put it? Thanks.",
                  "score": 1,
                  "created_utc": "2026-01-06 14:24:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny0fu6f",
              "author": "ANR2ME",
              "text": "It tells ComfyUI not to use that amount of VRAM, so other applications (ie. Desktop or Browsers with hardware acceleration enabled) that need VRAM too can use it.\n\n```\n--reserve-vram RESERVE_VRAM\n                        Set the amount of vram in GB you want to reserve for\n                        use by your OS/other software. By default some amount\n                        is reserved depending on your OS.\n\n```",
              "score": 4,
              "created_utc": "2026-01-06 14:28:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny7ya2s",
              "author": "freebytes",
              "text": "That reserves video RAM for the operating system.  (Not to be confused with preventing unloading of memory for use by the model.)  So, if you have the reservation at 4GB and have 24GB of VRAM, then up to 20GB will be used for the processing in ComfyUI.  It is placed on the command line that launches the application.  If you launch via a batch file, open the file in Notepad++ and edit the comfyui launch line in it.",
              "score": 2,
              "created_utc": "2026-01-07 16:08:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny0dcb8",
          "author": "Grindora",
          "text": "almost done downloading models, cant wait to tryyy it! :))) i got 5090 & 64gb ram will update here!",
          "score": 1,
          "created_utc": "2026-01-06 14:15:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0f1nt",
              "author": "Lower-Cap7381",
              "text": "You already have enough to run it",
              "score": 1,
              "created_utc": "2026-01-06 14:24:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0h0lk",
                  "author": "Grindora",
                  "text": "https://preview.redd.it/tcixtodppqbg1.png?width=761&format=png&auto=webp&s=76c3552631b163923501485a63ad95fee372dadc\n\nah damn, i got this, any idea why?",
                  "score": 1,
                  "created_utc": "2026-01-06 14:35:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny0fmjf",
          "author": "blownawayx2",
          "text": "Can‚Äôt wait to get my 5090 using this!!",
          "score": 1,
          "created_utc": "2026-01-06 14:27:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0m2h0",
          "author": "Old_Estimate1905",
          "text": "Great, but i just dont know of this AI tin can sound is usefull. I personaly cant stand that bad sound",
          "score": 1,
          "created_utc": "2026-01-06 15:01:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0yt1a",
          "author": "Ykored01",
          "text": "Cool i have same gpu, 5070ti 64gb ram ddr5, im getting oom, do you have more ram? Or are u using a custom workflow? Mind sharing ur steps please üôè",
          "score": 1,
          "created_utc": "2026-01-06 16:01:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1ethi",
          "author": "False_Suspect_6432",
          "text": "the i2v ignores the uploaded image. It shows it only in the first frame and then ignores it and creates everything from the prompt",
          "score": 1,
          "created_utc": "2026-01-06 17:14:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2du7m",
              "author": "Machspeed007",
              "text": "Hou have to describe the image shortly before anything else.",
              "score": 1,
              "created_utc": "2026-01-06 19:52:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny1ge4x",
          "author": "False_Suspect_6432",
          "text": "the  --reserve-vram 4  solution in 5070Ti 16Gb works like a charm! (apart of my problem that it totally ignores the uploaded image))",
          "score": 1,
          "created_utc": "2026-01-06 17:21:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1gmjs",
          "author": "Comic-Engine",
          "text": "Wild",
          "score": 1,
          "created_utc": "2026-01-06 17:22:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2u5x8",
          "author": "ProfessionalGain2306",
          "text": "I can't use my laptop right now. üò≠ \nBut I have a working laptop with 2GB of video memory. Is it possible to generate videos on it? \nEven if it's 720p and short 60-second videos, the rendering process will take half an hour. How can I set this up on a \"boring\" laptop? \nI urgently need reference images for my YouTube channel.",
          "score": 1,
          "created_utc": "2026-01-06 21:07:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny30pna",
          "author": "N1tr0x69",
          "text": "Would it work with my 5070 12gb with the same parameter --reserve-vram 10 ??",
          "score": 1,
          "created_utc": "2026-01-06 21:37:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3icfw",
          "author": "JimmyDub010",
          "text": "Still waiting for a gradio. come on wan2gp. Comfy is way over my head especially only having 12gb vram 32gb ram. it would blow up my computer trying this model.",
          "score": 1,
          "created_utc": "2026-01-06 23:01:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4px3j",
          "author": "elswamp",
          "text": "did you change any settings?",
          "score": 1,
          "created_utc": "2026-01-07 02:52:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny56rp1",
          "author": "FitContribution2946",
          "text": "ive been running on a 4090 and i have to clean the vram between EVERY generation",
          "score": 1,
          "created_utc": "2026-01-07 04:31:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyriccd",
          "author": "Intelligent_Tank_727",
          "text": "I can comfirm that this that adding  \"reserve-vram\": \"10\" to comfy.settings.json (desktop version of comfyui) did the trick and start to work. Rtx5070ti and 32gb ram.",
          "score": 1,
          "created_utc": "2026-01-10 10:11:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nytzu1m",
          "author": "Intelligent_Tank_727",
          "text": "wan 2.2 is still superior in generation, this is literaly basic gen requares insane accuracy in promts..",
          "score": 1,
          "created_utc": "2026-01-10 18:56:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0c3dr",
          "author": "One-Thought-284",
          "text": "Awesome good job pioneer haha, urm how do I set reserve vram, I'm going to attempt lower resolution with my 8gb GPU ;)",
          "score": 1,
          "created_utc": "2026-01-06 14:08:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0d0z6",
              "author": "One-Thought-284",
              "text": "Using FP4 its actually processing a video at 420x420 resolution currently, not tried reserve VRAM yet but thats using an 8GB 4060 so will see if it completes (32gb normal RAM)",
              "score": 3,
              "created_utc": "2026-01-06 14:13:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny0i27i",
              "author": "One-Thought-284",
              "text": "I posted my 8GB VRAM test so far, working though thanks!",
              "score": 1,
              "created_utc": "2026-01-06 14:40:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny0ij11",
              "author": "psilonox",
              "text": "you need to edit the .bat file or however you start comfyui, normally it will say \"python main.py\" and you need to add \"python main.py --reserve-ram 6\" (6 being whatever you want to not use)\n\nif youre using the experimental amd gpu standalone it will look more like \".\\\\python\\_embeded\\\\python.exe -s ComfyUI\\\\main.py --windows-standalone-build --reserve-ram 6\"",
              "score": 1,
              "created_utc": "2026-01-06 14:43:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0jb82",
                  "author": "One-Thought-284",
                  "text": "Okay awesome thanks! How do you know how much to reserve?",
                  "score": 1,
                  "created_utc": "2026-01-06 14:47:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny0r6wf",
          "author": "ImprovementCheap7411",
          "text": "How come I can never get these updates immediately? I updated comfy but I don't see LTX-2 in there, I also downloaded their workflow but I don't have the special nodes, anyone can help? :/",
          "score": 1,
          "created_utc": "2026-01-06 15:26:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0s0w7",
              "author": "ImprovementCheap7411",
              "text": "It says I'm on version 0.7.0 if that helps, and it says no updates available. Using CloudFlare DNS",
              "score": 1,
              "created_utc": "2026-01-06 15:30:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1as78",
                  "author": "Valuable_Issue_",
                  "text": "The portable version isn't always the latest. The latest is done through the git clone instructions (haven't tried seeing how portable works with latest latest updates, there might be a way to do it but not sure).\n\nIt's actually really simple and personally I find it better than portable. After installing conda, I just do\n\n>conda create -n comfy python=3.13 -y\n\n>git clone https://github.com/comfyanonymous/ComfyUI comfy\n\n>cd comfy\n\n>pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu130\n\n>pip install -r requirements.txt\n\nAnd then you just use it normally, to update you just do (also make sure conda env is always activated)\n\n>git pull\n\n>pip install -r requirements.txt\n\nAnd you can also make a startup powershell/bat script\n\n>conda activate comfy\n\n>python ./comfy/main.py --disable-metadata --reserve-vram 2 --async-offload 2 --fast fp16_accumulation  --novram\n\nThis way I find it a lot easier to just delete the comfy environment from conda with conda --remove n comfy and reinstall without worrying about anything, or even run multiple environments with different names from the same comfy folder (keeping custom nodes etc).",
                  "score": 2,
                  "created_utc": "2026-01-06 16:56:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny1yonb",
              "author": "generate-addict",
              "text": "You'll have to switch your comfy to the nightly branch.",
              "score": 1,
              "created_utc": "2026-01-06 18:43:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny3w1uq",
              "author": "freebytes",
              "text": "If you are using the manager for the updates, there is a drop down labeled 'Update' on the left.  Choose the nightly version, not the stable.",
              "score": 1,
              "created_utc": "2026-01-07 00:12:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny0ul36",
          "author": "Domskidan1987",
          "text": "Has this just killed Wan2.2?",
          "score": 0,
          "created_utc": "2026-01-06 15:42:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0wtzg",
              "author": "Perfect-Campaign9551",
              "text": "no. It doesn't have near enough control at the moment. And honestly the audio kind of sucks",
              "score": -2,
              "created_utc": "2026-01-06 15:52:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny701c2",
                  "author": "Domskidan1987",
                  "text": "After using it yesterday I agree with this statement it‚Äôs prompt adherence and overall control is not very good.",
                  "score": 1,
                  "created_utc": "2026-01-07 13:14:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny0x0tv",
                  "author": "Domskidan1987",
                  "text": "Ugh probably not even worth downloading the model and testing, I got a 5090 with 128 gigs of system ram.",
                  "score": -5,
                  "created_utc": "2026-01-06 15:53:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny2odot",
          "author": "ZodiacKiller20",
          "text": "My testing with a 5090 - it works amazingly well and will dethrone wan 2.2. \n\nIts heavily censored including the gemma encoder but we have the tech to abliterate and quantise gemma and make uncensored loras (LTX github gives us lora training tools including audio).\n\nSeems likely we'll soon see a whole load of new uncensored models built from this.",
          "score": 0,
          "created_utc": "2026-01-06 20:41:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q0dygk",
      "title": "Subject Plus+ (Vibes) ZIT LoRA",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1q0dygk",
      "author": "MikirahMuse",
      "created_utc": "2025-12-31 14:14:19",
      "score": 370,
      "num_comments": 28,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q0dygk/subject_plus_vibes_zit_lora/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwx0blw",
          "author": "MikirahMuse",
          "text": "# [NEW RELEASE] Subject Plus v1 ‚Äî Moody Photographic Realism LoRA (Z-Image)\n\nJust released **Subject Plus v1**, a Z-Image LoRA trained for **moody, aesthetically consistent photographic realism**.\n\nThis version intentionally shifts away from neutral, stock-photo realism and toward a more **cinematic, photographer-driven look**. It is **intentionally slightly overfit** to lock in this aesthetic across scenes, rather than maximize flexibility.\n\nBecause of this, it performs best **below full strength**.\n\n## Works well for\n- Studio & environmental portraits  \n- Editorial / lifestyle images  \n- Product shots with atmosphere  \n- Landscapes & architecture  \n\n## Technical notes\n- DSLR-style sharpness without harsh micro-contrast  \n- Natural lighting behavior with preserved shadow detail  \n- Strong subject separation and depth cues  \n\n## Important usage note\n- **LoRA strength:** ~**0.7 recommended**  \n- The model is intentionally overfit to stabilize the look  \n- Pushing it toward **1.0 may introduce artifacts or reduce realism**\n\n## Prompt guidance\n- 500‚Äì1300 characters recommended  \n- Weak prompts and poor base workflows will be more visible  \n\nüîó **CivitAI link:**  \nhttps://civitai.com/models/2234406?modelVersionId=2551211",
          "score": 37,
          "created_utc": "2025-12-31 14:14:42",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nwzmneu",
          "author": "peabody624",
          "text": "Damn these are professional grade",
          "score": 11,
          "created_utc": "2025-12-31 22:27:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwx31ci",
          "author": "tomhermans",
          "text": "Really nice.",
          "score": 7,
          "created_utc": "2025-12-31 14:30:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwx6n3f",
          "author": "Agreeable-Warthog547",
          "text": "Looks good",
          "score": 6,
          "created_utc": "2025-12-31 14:50:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwx8epx",
          "author": "Aggravating-Mix-8663",
          "text": "They look amazing!\n\nCan you share your LoRA training process please?",
          "score": 8,
          "created_utc": "2025-12-31 15:00:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx4k7x9",
              "author": "MikirahMuse",
              "text": "I will say the dataset was 2K trained for 6k steps. Changed the weighting to high noise for the last 1k.",
              "score": 1,
              "created_utc": "2026-01-01 19:28:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwzg97p",
          "author": "reditor_13",
          "text": "Really well done!",
          "score": 2,
          "created_utc": "2025-12-31 21:50:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx09p5c",
          "author": "steelow_g",
          "text": "These are legit quality. Gunna try this out tomorrow. Is your wf embedded in these that i can test out?",
          "score": 2,
          "created_utc": "2026-01-01 00:45:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx0kiu3",
          "author": "The1870project",
          "text": "Great picture!",
          "score": 2,
          "created_utc": "2026-01-01 01:55:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx14ihl",
          "author": "moahmo88",
          "text": "Better than real!",
          "score": 2,
          "created_utc": "2026-01-01 04:10:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1btf6",
          "author": "Comed_Ai_n",
          "text": "Woah!!",
          "score": 2,
          "created_utc": "2026-01-01 05:07:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx2pqyg",
          "author": "Danmoreng",
          "text": "https://preview.redd.it/zyuypfzrmqag1.png?width=1152&format=png&auto=webp&s=02a03e0af06c59ec748e8e0ad45097d34ce310f5\n\nNice. \n\n    high class black white photography from the 60s of Albert Einstein, sbjpls <lora:subjectplus_vibes_v1:0.3>\n    Steps: 7, Sampler: euler, CFG scale: 1, Seed: 2472, Size: 1152x1536, Model: z_image_turbo-Q8_0.gguf Version: stable-diffusion.cpp",
          "score": 2,
          "created_utc": "2026-01-01 13:15:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx8in8o",
              "author": "GalaxyTimeMachine",
              "text": "Qwen Image 2512, only 4 step lora.  \nHe was even old in his younger years.\n\nhttps://preview.redd.it/ae8dx68w5xag1.png?width=2144&format=png&auto=webp&s=cff27b5b385df7f475b2222eab4b9b2353ffc12e",
              "score": 1,
              "created_utc": "2026-01-02 11:12:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx8iqo8",
              "author": "GalaxyTimeMachine",
              "text": "https://preview.redd.it/465na3p16xag1.png?width=2144&format=png&auto=webp&s=7dd93f295e90d0716cad21f309ef99ee05f73011",
              "score": 1,
              "created_utc": "2026-01-02 11:13:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx3i190",
          "author": "DigidyneDesignStudio",
          "text": "You‚Äôre all just gonna make porn and you know it.",
          "score": 2,
          "created_utc": "2026-01-01 16:14:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx3rh30",
          "author": "Alisomarc",
          "text": "![gif](giphy|oYtVHSxngR3lC)",
          "score": 2,
          "created_utc": "2026-01-01 17:04:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx2w36e",
          "author": "Paraleluniverse200",
          "text": "This looks crazy good, wish you could bring a chroma version",
          "score": 1,
          "created_utc": "2026-01-01 14:02:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx3scot",
          "author": "Low_Measurement7946",
          "text": "‰∏çÈîô",
          "score": 1,
          "created_utc": "2026-01-01 17:09:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx43tdt",
          "author": "Noiselexer",
          "text": "Damn",
          "score": 1,
          "created_utc": "2026-01-01 18:07:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx4g0d5",
          "author": "dreamyrhodes",
          "text": "For some reason this makes the skin and hair look embossed even when bringing weight down to 0.6\n\nhttps://preview.redd.it/ckluzjngdsag1.jpeg?width=1516&format=pjpg&auto=webp&s=701f5e3ae0637cbd50d6c7782d8ce02838378d6d\n\nSteps: 9, Sampler: Euler a, Schedule type: Simple, CFG scale: 1, Shift: 6, Seed: 4110107372, Size: 896x1152, Model hash: 20c8f96ad6, Model: jibMixZIT\\_v10",
          "score": 1,
          "created_utc": "2026-01-01 19:07:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx4jf9t",
              "author": "MikirahMuse",
              "text": "Try with 8 steps and use the Zhang scheduler.",
              "score": 1,
              "created_utc": "2026-01-01 19:24:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx4l7i2",
                  "author": "dreamyrhodes",
                  "text": "I am using Forge, there is no Zhang. Steps don't change the outcome. Tried 5-15.",
                  "score": 1,
                  "created_utc": "2026-01-01 19:33:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxzdsfk",
                  "author": "SvenVargHimmel",
                  "text": "The Zhang scheduler ... oh, what is the Zhang scheduler.  Which node pack provides this?",
                  "score": 1,
                  "created_utc": "2026-01-06 10:03:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx61axa",
          "author": "pencil_the_anus",
          "text": ">[Oh must have been a script error. The actual workflow is in the Discord](https://civitai.com/models/2234406?modelVersionId=2551211&dialog=commentThread&commentId=1062324).\n\nCould you share the WF here please? I don't want to join YET ANOTHER Discord chat room.",
          "score": 1,
          "created_utc": "2026-01-02 00:09:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxux7a5",
              "author": "Soggy-Excitement-54",
              "text": "the wf is not in the discord",
              "score": 1,
              "created_utc": "2026-01-05 18:15:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx8igdk",
          "author": "GalaxyTimeMachine",
          "text": "Qwen Image 2512, only 4 step lora\n\nhttps://preview.redd.it/u1hgm1xi5xag1.png?width=2144&format=png&auto=webp&s=14dd92d222f85c5e2c91b5fc6b0fdd2e20c3d45b",
          "score": 1,
          "created_utc": "2026-01-02 11:10:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q5k6al",
      "title": "Fix to make LTXV2 work with 24GB or less of VRAM, thanks to Kijai",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/bl4p8vpynqbg1",
      "author": "Different_Fix_2217",
      "created_utc": "2026-01-06 14:32:46",
      "score": 352,
      "num_comments": 217,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q5k6al/fix_to_make_ltxv2_work_with_24gb_or_less_of_vram/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny0okue",
          "author": "protector111",
          "text": "*And its ability to continue videos is pretty crazy (it copies voices scarily well)*  \n*This was continued from a real video and its scary accurate:*¬†[*https://files.catbox.moe/46y2ar.mp4*](https://files.catbox.moe/46y2ar.mp4)¬†*pretty much did his voice perfectly off of just a few seconds.*    **HOW????**",
          "score": 75,
          "created_utc": "2026-01-06 15:13:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny14sus",
              "author": "lordpuddingcup",
              "text": "Wait‚Ä¶. What?!?!!??",
              "score": 16,
              "created_utc": "2026-01-06 16:28:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny1yg4t",
              "author": "mugen7812",
              "text": "this was insane wtffff",
              "score": 13,
              "created_utc": "2026-01-06 18:42:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny0wlhm",
              "author": "Different_Fix_2217",
              "text": "Encode video / audio as latent and use that as the input. Daisy chain it into a sampler to continue it and its the same as if it was something it generated itself.",
              "score": 24,
              "created_utc": "2026-01-06 15:51:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny2vv1o",
                  "author": "Sixhaunt",
                  "text": "please can you post a workflow or atleast screenshot the relevant area since it's not working for others?",
                  "score": 18,
                  "created_utc": "2026-01-06 21:15:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny15gia",
                  "author": "protector111",
                  "text": "i tried and it didnt work. can yo ushare the wf please? it just makes new video like vide2video but thats not continuation of previous one.\n\nhttps://preview.redd.it/wxpf70aparbg1.png?width=1778&format=png&auto=webp&s=aa4ae3a11e37dc7a05ea679739772fd2d9c26929",
                  "score": 13,
                  "created_utc": "2026-01-06 16:32:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny3ln6j",
                  "author": "Perfect-Campaign9551",
                  "text": "Does that mean it CAN use input reference audio then?",
                  "score": 7,
                  "created_utc": "2026-01-06 23:18:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny14xef",
                  "author": "lordpuddingcup",
                  "text": "L  have a workflow I wanna see if it can nail my wife‚Äôs accent lol",
                  "score": 5,
                  "created_utc": "2026-01-06 16:29:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny2ym70",
                  "author": "Eydahn",
                  "text": "Can you please post an example workflow with that?",
                  "score": 5,
                  "created_utc": "2026-01-06 21:27:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny4cq2c",
              "author": "Perfect-Campaign9551",
              "text": "Can you change it so he says \"I'm a greedy asshole who hates gamers and that long lost idea of making the world a better place? Ya that was always bullshit. I want money\"",
              "score": 6,
              "created_utc": "2026-01-07 01:40:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny5u82v",
              "author": "desktop4070",
              "text": "I think Jensen has to already be in the training data and the model might have picked up that his voice is associated with his presentations. But I could be wrong, and maybe the model actually is that insane.",
              "score": 3,
              "created_utc": "2026-01-07 07:29:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny5uczs",
                  "author": "protector111",
                  "text": "yesturday on discord LTX team confirmed it can do video continuation with voice cloning",
                  "score": 3,
                  "created_utc": "2026-01-07 07:30:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny49em2",
              "author": "GetOutOfTheWhey",
              "text": "bruh im scared, hollywood didnt prepare us for this AI apocalypse",
              "score": 2,
              "created_utc": "2026-01-07 01:22:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny5tmod",
              "author": "Terrible_Scar",
              "text": "Can you guys share this please,?¬†",
              "score": 1,
              "created_utc": "2026-01-07 07:23:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny5u0wh",
                  "author": "protector111",
                  "text": "OP wont share it. i dont have it. LTX team said to me yesturday that they will make a workflow for us to do this",
                  "score": 6,
                  "created_utc": "2026-01-07 07:27:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2oi6i",
              "author": "reeight",
              "text": "wow, uncanny valley there",
              "score": 1,
              "created_utc": "2026-01-06 20:41:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny9iq44",
                  "author": "Cheesuasion",
                  "text": "I do not think it means what you think it means.\n\nhttps://en.wikipedia.org/wiki/Uncanny_valley",
                  "score": 4,
                  "created_utc": "2026-01-07 20:17:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nydfkfu",
              "author": "Far_Pea7627",
              "text": "dk where you see this scarily good lipsync are you blind?\n\nit barely articulate 1 right word of the audio speech although the lips motion are good, stop exagerrating for attention please be precise.",
              "score": -4,
              "created_utc": "2026-01-08 10:04:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nydkr1b",
                  "author": "protector111",
                  "text": "U cant be serious. Lipsynch is perfect and that wasnt even the point. The point is it continues video by cloning the voice",
                  "score": 1,
                  "created_utc": "2026-01-08 10:50:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny0pios",
          "author": "__ThrowAway__123___",
          "text": "Can confirm this also works on 30xx cards (tested on 3090ti)",
          "score": 36,
          "created_utc": "2026-01-06 15:18:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny14i1g",
              "author": "Acrobatic_Ferret_951",
              "text": "3090 user here too. I followed the above instructions above but when I try to  generate, comfy crashes on me",
              "score": 7,
              "created_utc": "2026-01-06 16:27:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny277s5",
                  "author": "martinerous",
                  "text": "I just found that Unsloth Gemma 4bit quant also works quite well to get past the OOM issues during text encoding phase:¬†[https://huggingface.co/unsloth/gemma-3-12b-it-bnb-4bit/tree/main](https://huggingface.co/unsloth/gemma-3-12b-it-bnb-4bit/tree/main)\n\nAnd still --reserve-vram 4 flag also is needed for some reason, to push ComfyUI into the shared GPU memory area instead of crashing.",
                  "score": 12,
                  "created_utc": "2026-01-06 19:21:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny29cvk",
                  "author": "dr_lm",
                  "text": "3090 user here with 64GB system RAM, the fix above worked for me. I did have to use \n\n--preview-method none\n\nTo stop a mat1/mat2 multiplication error. \n\nInference times depend heavily upon whether the prompt changes, because it takes so long to move models around memory to encode the prompt. \n\nAt 1920 x 1088 x 121 frames (at 24fps, so 5s video), with a new prompt it takes 317s, reusing the prompt, 213s. So, remarkably fast.\n\nETA: Just got 177s with a reused prompt. I think my PC is so close to the line in terms of memory that the inference times are highly variable.\n\nETA2: Just trying some 720p videos at 121 frames and getting 60-70s per generation with reused prompt, 160s with a new prompt.",
                  "score": 13,
                  "created_utc": "2026-01-06 19:31:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny1wysr",
                  "author": "ThellraAK",
                  "text": "I am way out of date and just getting back into it. \n\nIs your GPU also what's rendering your desktop? \n\nI run into a lot of issues when I am not using my iGPU for rendering the desktop, and the discreet GPU for just generating images.",
                  "score": 1,
                  "created_utc": "2026-01-06 18:35:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny1bmnc",
              "author": "kh3t",
              "text": "How much time it takes you on 3090ti?",
              "score": 1,
              "created_utc": "2026-01-06 16:59:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny1z1t6",
              "author": "psilent",
              "text": "What kinds of speed are you getting?",
              "score": 1,
              "created_utc": "2026-01-06 18:45:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny0hmle",
          "author": "goddess_peeler",
          "text": "Please share a link to the original post or thread.",
          "score": 10,
          "created_utc": "2026-01-06 14:38:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0kups",
              "author": "Skyline34rGt",
              "text": "https://preview.redd.it/pwr7vzr9tqbg1.png?width=708&format=png&auto=webp&s=9fb7ec6dbccfdf9c70ae337c1e2c5de8083097ae",
              "score": 12,
              "created_utc": "2026-01-06 14:55:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny0jtip",
              "author": "Different_Fix_2217",
              "text": "Its the bandoco discord.",
              "score": 4,
              "created_utc": "2026-01-06 14:49:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny0zedj",
          "author": "Volkin1",
          "text": "Thank you.  \nI tired the other alternative with the --novram and without any other modifications.\n\nThis allowed me to run the model in default 720p settings with only 3 GB VRAM  and 50GB RAM used. Pretty much streamed almost all of the weights from RAM, but it worked so well.",
          "score": 10,
          "created_utc": "2026-01-06 16:04:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3e7nr",
              "author": "Key_Highway_8728",
              "text": "I thought you were joking.. this actually generated 5 second video with less than 6GB memory used in 231 seconds \n\n![gif](giphy|Fkmgse8OMKn9C)",
              "score": 10,
              "created_utc": "2026-01-06 22:40:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny3ti2j",
                  "author": "Volkin1",
                  "text": "Yeah the video model is amazing. I got some issues with the LLM gemma model, but hopefully Comfy will fix it soon. Another issue is the comfy official vs the ltx2 official workflow. Both give very different results but ltx wf has a built in prompt enhancer that seems very good.",
                  "score": 2,
                  "created_utc": "2026-01-06 23:59:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny5hgua",
              "author": "Consistent_Cod_6454",
              "text": "with which of the models and which gemma please? i have a 16VRAm and 64RAM",
              "score": 1,
              "created_utc": "2026-01-07 05:44:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny5i2qm",
                  "author": "Volkin1",
                  "text": "The built-in Comfy workflow from templates.\n\nAny model. FP16 / FP8 / FP4, although FP8 seems to be a sweet spot. Acceleration not yet working in Comfy but if you have 50 series gpu, you can try the FP4.\n\nText encoder: [https://huggingface.co/Comfy-Org/ltx-2/tree/main/split\\_files/text\\_encoders](https://huggingface.co/Comfy-Org/ltx-2/tree/main/split_files/text_encoders)",
                  "score": 1,
                  "created_utc": "2026-01-07 05:49:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny212a4",
          "author": "Radyschen",
          "text": "call me if somebody knows that it can run on 16 VRAM/64 RAM",
          "score": 15,
          "created_utc": "2026-01-06 18:53:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyczjmz",
              "author": "nevermore12154",
              "text": "It sure can. Even runs (not so effective) on my non rtx laptop 4gb vram 32gb 2667mhz.",
              "score": 2,
              "created_utc": "2026-01-08 07:39:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny0nndl",
          "author": "Last_Ad_3151",
          "text": "Still getting an OOM with the text encoder and I've tried a bunch of things, including this. No joy. Next step - sell the house and buy an RTX Pro 6000.",
          "score": 13,
          "created_utc": "2026-01-06 15:09:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0onhq",
              "author": "Different_Fix_2217",
              "text": "That is with --reserve-vram 4?  \nTry --fp8\\_e4m3fn-unet as well. If that does not work then I guess you don't have enough ram. You prob need like 64GB minimum cause gemma is big. Hopefully someone adds gguf support for it.",
              "score": 5,
              "created_utc": "2026-01-06 15:13:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny0s7vq",
                  "author": "Last_Ad_3151",
                  "text": "Running a 4090 with 128GB system RAM. It's something else.",
                  "score": 5,
                  "created_utc": "2026-01-06 15:31:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyyy8fy",
                  "author": "Intelligent_Tank_727",
                  "text": "i run this default comfy workflow with 20gb genma and 32gb system ram rtx5070ti non distiled fp8 runs in 200s for 121frames.  Oom gone after reserve-vram. I did test 10 and 4 value both work.",
                  "score": 1,
                  "created_utc": "2026-01-11 13:48:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny0ytdn",
              "author": "Skyline34rGt",
              "text": "You can try smaller text encoder - [https://huggingface.co/GitMylo/LTX-2-comfy\\_gemma\\_fp8\\_e4m3fn/tree/main](https://huggingface.co/GitMylo/LTX-2-comfy_gemma_fp8_e4m3fn/tree/main)\n\n(didnt tested it, just see)",
              "score": 2,
              "created_utc": "2026-01-06 16:01:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny13eyn",
                  "author": "ArkCoon",
                  "text": "how do I even get this dumbass clip loader to load it? It doesn't accept this.\n\nEDIT: I found a fix. Switch out the \"Gemma 3 model loader\" with the \"LTXV Audio Text Encoder Loader.\" That one accepts the regular model",
                  "score": 18,
                  "created_utc": "2026-01-06 16:22:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny66u2w",
                  "author": "activemotionpictures",
                  "text": "Where do I get the LTX-Audio to VAE? It's giving me an error on the official Comfy UI template to have that node active. Please help.   \n(I also followed your guide for lower Vram. I'm using an RT 3060 12 GB Vram)",
                  "score": 1,
                  "created_utc": "2026-01-07 09:25:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2xzxt",
              "author": "HauntingBit3617",
              "text": "i only have a blackwell 4000 and its doing 720p talking vids in no time - those fixes worked - no need to sell your house",
              "score": 1,
              "created_utc": "2026-01-06 21:24:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny0hpnk",
          "author": "Lower-Cap7381",
          "text": "Amazing man I think 16 gb vram will be just a dream",
          "score": 5,
          "created_utc": "2026-01-06 14:38:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5hhh5",
              "author": "Shambler9019",
              "text": "I'll give it a week",
              "score": 1,
              "created_utc": "2026-01-07 05:44:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyd1ghj",
              "author": "juandann",
              "text": "no dreaming, with --novram flag you can run this model too. I have the same specs can do 720p max at 500 frames, for 1080p at max 200 frames with all on 25 fps. Generation time actually much faster than wan 2.2",
              "score": 1,
              "created_utc": "2026-01-08 07:56:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny15fl3",
          "author": "marcoc2",
          "text": "Are you saying you created these videos in less than 10 seconds?",
          "score": 4,
          "created_utc": "2026-01-06 16:31:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1c8j4",
          "author": "NordRanger",
          "text": "I am getting this error when trying to load Gemma:   \n  \nExpected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "score": 5,
          "created_utc": "2026-01-06 17:02:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4y39h",
              "author": "vectorcrawlie",
              "text": "Gemini told me this is because Gemma has issues using both vram and ram because of a bug. I switched to using the unsloth quantized gemma model mentioned elsewhere in this thread.",
              "score": 1,
              "created_utc": "2026-01-07 03:37:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyk9rx4",
              "author": "rasimgunduz",
              "text": "Did you manage to solve the problem? I'm experiencing the same issue.",
              "score": 1,
              "created_utc": "2026-01-09 08:27:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3el78",
          "author": "throwthrowaway_20",
          "text": "How do you use that text encoder? It just says it's missing \"tokenizer.model\", which leads me back to the huge model from here: [https://huggingface.co/google/gemma-3-12b-it-qat-q4\\_0-unquantized/tree/main](https://huggingface.co/google/gemma-3-12b-it-qat-q4_0-unquantized/tree/main)\n\nI can't seem to get it to load a single safetensors text encoder.",
          "score": 4,
          "created_utc": "2026-01-06 22:42:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3udua",
              "author": "CrowPrestigious7990",
              "text": "Use this:  \n[https://huggingface.co/GitMylo/LTX-2-comfy\\_gemma\\_fp8\\_e4m3fn/blob/main/gemma\\_3\\_12B\\_it\\_fp8\\_e4m3fn.safetensors](https://huggingface.co/GitMylo/LTX-2-comfy_gemma_fp8_e4m3fn/blob/main/gemma_3_12B_it_fp8_e4m3fn.safetensors)\n\nPlace in the safe dir as comfy and then restart it. \n\nThen swap it out in the workflow, it shouldn't take up as much memory.\n\nAlso launch comfy in --novram mode.",
              "score": 2,
              "created_utc": "2026-01-07 00:03:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny9he87",
                  "author": "Dreamgirls_ai",
                  "text": "thanks! I did, but it still says tokenizer.model is missing :(",
                  "score": 1,
                  "created_utc": "2026-01-07 20:11:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny5ex4p",
          "author": "FitContribution2946",
          "text": "this post should be PINNED on /StableDiffusion.. this is the MOST HELPFUL post you will find. Thank you",
          "score": 4,
          "created_utc": "2026-01-07 05:26:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny26w12",
          "author": "martinerous",
          "text": "And I just found that Unsloth Gemma 4bit quant also works quite well to get past the OOM issues during text encoding phase: [https://huggingface.co/unsloth/gemma-3-12b-it-bnb-4bit/tree/main](https://huggingface.co/unsloth/gemma-3-12b-it-bnb-4bit/tree/main)",
          "score": 4,
          "created_utc": "2026-01-06 19:20:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny344ip",
              "author": "sdnr8",
              "text": "noob here. how exactly do i download this, and where does it go?",
              "score": 2,
              "created_utc": "2026-01-06 21:53:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2czw5",
              "author": "Nervous_Hamster_5682",
              "text": "which node did you use for text encoder? gguf clip loader did not work for me.",
              "score": 1,
              "created_utc": "2026-01-06 19:48:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2dwts",
                  "author": "martinerous",
                  "text": "This was the replacement I did in LTX repository workflow example LTX-2\\_I2V\\_Distilled\\_wLora.json.\n\nhttps://preview.redd.it/9zqikjly9sbg1.png?width=528&format=png&auto=webp&s=a8f2e28bfd07589ec12ba1d21857d853b235e377\n\nI tried the same in the ComfyUI workflow template for LTX image to video, but somehow that one gives me a bit corrupted videos. The LTX own workflow works well - 1088p 5 second video on RTX 3090 in just 184 seconds, unbelievable.",
                  "score": 1,
                  "created_utc": "2026-01-06 19:52:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2pgnd",
              "author": "tylerninefour",
              "text": "I tried that same model earlier with the same node and kept getting this error:\n\n> Exception Type: NotImplementedError ‚Äî \n> Exception Message: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.\n\nTried troubleshooting the error with Gemini but haven't had any success thus far.",
              "score": 1,
              "created_utc": "2026-01-06 20:46:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3jysq",
          "author": "Mundane_Existence0",
          "text": "Getting this error when trying the [v2v workflow](https://github.com/Lightricks/ComfyUI-LTXVideo/blob/master/example_workflows/LTX-2_V2V_Detailer.json):\n\nhttps://preview.redd.it/7qwqp4kh9tbg1.png?width=1229&format=png&auto=webp&s=3eacd7975de85893b4fcbd0668cca2512548f4fd",
          "score": 5,
          "created_utc": "2026-01-06 23:09:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5c903",
          "author": "GrungeWerX",
          "text": "All I get is this error: LTXVGemmaCLIPModelLoader\n\nNo files matching pattern 'tokenizer.model' found under G:\\\\Users\\\\GrungeWerX\\\\Documents\\\\ComfyUI w11\\\\ComfyUI\\_windows\\_portable\\\\ComfyUI\\\\models\n\nhttps://preview.redd.it/u0ucdgia1vbg1.png?width=1616&format=png&auto=webp&s=7ea51c40d40950fcb04d8cd556760c4a35851c6d",
          "score": 3,
          "created_utc": "2026-01-07 05:07:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5srfw",
              "author": "Prudent_Appearance71",
              "text": "Has anyone solved this problem?",
              "score": 3,
              "created_utc": "2026-01-07 07:16:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny72j7n",
                  "author": "rugia813",
                  "text": "[https://www.reddit.com/r/StableDiffusion/comments/1q5r23b/comment/ny3fedo/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/r/StableDiffusion/comments/1q5r23b/comment/ny3fedo/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",
                  "score": 1,
                  "created_utc": "2026-01-07 13:28:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny6oani",
              "author": "Bandit-level-200",
              "text": "Cause it thinks you're going to load another gemma model in another format so it thinks it needs the tokenizer.model file, I had to download the model they linked and all its files. which is this model https://huggingface.co/google/gemma-3-12b-it-qat-q4_0-unquantized/tree/main",
              "score": 1,
              "created_utc": "2026-01-07 11:55:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyb7jrm",
                  "author": "GrungeWerX",
                  "text": "Dude, that's a 20+ GB model, which is why everyone's trying to download a smaller model.",
                  "score": 1,
                  "created_utc": "2026-01-08 01:00:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1qiav",
          "author": "lumos675",
          "text": "how did you use this?  \n[https://huggingface.co/GitMylo/LTX-2-comfy\\_gemma\\_fp8\\_e4m3fn/blob/main/gemma\\_3\\_12B\\_it\\_fp8\\_e4m3fn.safetensors](https://huggingface.co/GitMylo/LTX-2-comfy_gemma_fp8_e4m3fn/blob/main/gemma_3_12B_it_fp8_e4m3fn.safetensors)  \nthis gives mat error",
          "score": 3,
          "created_utc": "2026-01-06 18:07:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny24u9l",
              "author": "Upset-Virus9034",
              "text": "can you make this work? i am downloading still not tried yet, i am on RTX 4090 24vram",
              "score": 2,
              "created_utc": "2026-01-06 19:11:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny1v6ys",
          "author": "Rumaben79",
          "text": "The fp8 clip doesn't seem to save any system ram. Actually it seem the same or worse than with fp16 (swap is used more). Wierd. Vram usage is the same as well.\n\nMaybe the nodes are just buggy.\n\nWhat does help a little though is bypassing the upscaler passes.\n\nI'm sure it'll get better after a few comfyui updates. :D\n\nAnother thing if people don't already know. If you're using the below workflow with the distilled lora (default):\n\n[https://github.com/Comfy-Org/workflow\\_templates/blob/main/templates/video\\_ltx2\\_t2v.json](https://github.com/Comfy-Org/workflow_templates/blob/main/templates/video_ltx2_t2v.json)\n\nYou only have to use 8 steps and put your cfg down to 1. Perhaps this workflow was kept this way so you would have the option of both.",
          "score": 3,
          "created_utc": "2026-01-06 18:27:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8dnuv",
              "author": "Glad-Hat-5094",
              "text": "I'm using that workflow and I don't know how to get it to randomise the seed for a different output, I have set everything set to random but after the first generation of 20 steps it ignores the first part everytime after that almost like it is the same seed. Have you experienced this?",
              "score": 1,
              "created_utc": "2026-01-07 17:17:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny9bzp9",
                  "author": "Rumaben79",
                  "text": "Yes it seemed buggy for me. Extracting the Subgraph helped for me but I always do that lol I hate subgraphs because I use the old comfyui look. :)",
                  "score": 0,
                  "created_utc": "2026-01-07 19:48:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny38kfs",
          "author": "CrowPrestigious7990",
          "text": "I used the FP8 quantized Gemma model:  \n[https://huggingface.co/GitMylo/LTX-2-comfy\\_gemma\\_fp8\\_e4m3fn/blob/main/gemma\\_3\\_12B\\_it\\_fp8\\_e4m3fn.safetensors](https://huggingface.co/GitMylo/LTX-2-comfy_gemma_fp8_e4m3fn/blob/main/gemma_3_12B_it_fp8_e4m3fn.safetensors)\n\nand launched comfy via \\`\\`--novram\\`\\`\\`flag. \n\nThat got it 'working' but I'm not having the same luck in terms of quality.\n\nGPU: RTX 5080  \nRAM: 32GB DDR5  \nCPU: 7600x",
          "score": 3,
          "created_utc": "2026-01-06 22:13:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5omdb",
              "author": "Consistent_Cod_6454",
              "text": "which version of the ltx model are you using? how many gb is it? is it the fp8?",
              "score": 1,
              "created_utc": "2026-01-07 06:41:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny6av30",
                  "author": "CrowPrestigious7990",
                  "text": "This verson:  \n[https://huggingface.co/Lightricks/LTX-2/blob/main/ltx-2-19b-distilled-fp8.safetensors](https://huggingface.co/Lightricks/LTX-2/blob/main/ltx-2-19b-distilled-fp8.safetensors)\n\nComes up to around 27GB and yes its FP8 destilled.",
                  "score": 1,
                  "created_utc": "2026-01-07 10:02:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny39rok",
          "author": "zimzaderk",
          "text": "this is driving me nuts all i get is this mat1 and mat2 shapes cannot be multiplied (1024x62208 and 188160x3840) error no matter what i swap or add or change",
          "score": 3,
          "created_utc": "2026-01-06 22:19:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4bb3a",
              "author": "elswamp",
              "text": "use standard video resolution",
              "score": 1,
              "created_utc": "2026-01-07 01:32:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny4g1s9",
              "author": "Gold-Cat-7686",
              "text": "If you didn't figure it out already, make sure to turn off previews by going to ComfyUI settings (not ComfyUIManager) and turning setting \"Live preview method\" to \"none\".",
              "score": 1,
              "created_utc": "2026-01-07 01:58:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny4v684",
              "author": "Dogluvr2905",
              "text": "It's the gemma model... you have to use 5 part .pt version right now.",
              "score": 1,
              "created_utc": "2026-01-07 03:21:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3syn5",
          "author": "Valuable_Weather",
          "text": "no files matching pattern 'model\\*.safetensors' found under d:\\\\aistuff\\\\comfyui\\\\models",
          "score": 3,
          "created_utc": "2026-01-06 23:56:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4i5g5",
          "author": "coffca",
          "text": "When you say use --reserve-vram 4 as a argument for comfy and disable previews in settings. What exactly does it means? Do I type \"--reserve-vram 4 \" on the run file?",
          "score": 3,
          "created_utc": "2026-01-07 02:09:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5ooba",
              "author": "Consistent_Cod_6454",
              "text": "yes",
              "score": 2,
              "created_utc": "2026-01-07 06:41:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny5yuc9",
          "author": "VirtualWishX",
          "text": "Thanks for sharing!üôè  \nSadly I did some tests with my RTX 5090 32GB VRAM, and the likeness is not even close, also in most cases it looks like plastic shiny person... I'm sure I'm doing something wrong but, I tried different settings and different images, but no luck so far... the speed is sure insane, but for such a no-likeness quality it doesn't matter.",
          "score": 3,
          "created_utc": "2026-01-07 08:10:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1k4hr",
          "author": "incognataa",
          "text": "That fp8 gemma doesn't work with the ltx node.",
          "score": 2,
          "created_utc": "2026-01-06 17:38:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2b0fx",
          "author": "AirwolfPL",
          "text": "Thanks! Works perfectly.\n\nAnd results are amazing. My new favourite local video-gen model!",
          "score": 2,
          "created_utc": "2026-01-06 19:39:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny38yci",
          "author": "Toclick",
          "text": "As I understand it, it has some issues with vertical videos?",
          "score": 2,
          "created_utc": "2026-01-06 22:15:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6ctu2",
          "author": "activemotionpictures",
          "text": "Where can I download the LTX Audio vae? My text won't work and the workflow gets truncated because of this error node. Please help.",
          "score": 2,
          "created_utc": "2026-01-07 10:20:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygdljy",
          "author": "FxManiac01",
          "text": "How do you make faces of real people not look like a dog shit? ie here: [https://files.catbox.moe/g9wbfp.mp4](https://files.catbox.moe/g9wbfp.mp4)\n\nthis is exactly what I am getting with official template but man.. wan 2.2 does way better... but here sound + speed is super trooper, but how to improve quality?\n\nWhat is even native resolution for LTX 2?",
          "score": 2,
          "created_utc": "2026-01-08 19:25:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyk9zq0",
          "author": "rasimgunduz",
          "text": "# LTXVGemmaEnhancePrompt\n\nExpected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper\\_CUDA\\_\\_index\\_select)    I'm getting an error. Does anyone know the solution?",
          "score": 2,
          "created_utc": "2026-01-09 08:29:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nykpxgz",
              "author": "Ill_Tour2308",
              "text": "SAme problem, Used all available Gemma, still same problem, Works yesterday, today not.",
              "score": 1,
              "created_utc": "2026-01-09 10:53:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nym3mno",
          "author": "ninjazombiemaster",
          "text": "I must be missing something because I tried doing this stuff (using 4 bit unsloth Gemma encoder instead of fp8) the fastest I could get 5 second 720p videos was like 18 seconds on my 5090 using the fp8 distilled 8 step base + 3 step upscale. How on earth are you getting 7 seconds with a 4090?",
          "score": 2,
          "created_utc": "2026-01-09 15:45:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny625ma",
          "author": "KvAk_AKPlaysYT",
          "text": "12GB VRAM wen?",
          "score": 2,
          "created_utc": "2026-01-07 08:41:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny16sth",
          "author": "1filipis",
          "text": "It fits in many different ways, but what do you mean by realtime, exactly?",
          "score": 1,
          "created_utc": "2026-01-06 16:38:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1dvwa",
          "author": "OddResearcher1081",
          "text": "Can confirm these changes work. \n\nI am using the LTX 2 fp4 version and the smaller version of the text encoder on an RTX 3090",
          "score": 1,
          "created_utc": "2026-01-06 17:10:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1gjkf",
              "author": "MisterBlackStar",
              "text": "That's weird, the fp4 version shouldn't work on the 3090.",
              "score": 0,
              "created_utc": "2026-01-06 17:22:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1mvev",
                  "author": "OddResearcher1081",
                  "text": "I am now trying the fp8 version. The few tests I have done so far are not very good. The video isn‚Äôt very sharp. The camera movement is nice. Some of the audio is garbled. This is obviously a work in progress for the LTX dev crew. The FP8 non-distilled model failed.",
                  "score": 1,
                  "created_utc": "2026-01-06 17:51:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1wtpu",
          "author": "SuperGeniusWEC",
          "text": "Interesting!  are you saying that it takes 5 seconds to render are are you saying it renders 5 seconds of video?",
          "score": 1,
          "created_utc": "2026-01-06 18:35:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny249hn",
          "author": "Upset-Virus9034",
          "text": "Does this work around works for all ? or any specific one ?\n\nhttps://preview.redd.it/9jekogcg2sbg1.png?width=1100&format=png&auto=webp&s=edc6743f390ec33bc54363f774540e43e6d7feb3",
          "score": 1,
          "created_utc": "2026-01-06 19:08:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2zkt0",
              "author": "AirwolfPL",
              "text": "Works for all of above workflows.",
              "score": 1,
              "created_utc": "2026-01-06 21:32:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2afq1",
          "author": "Nervous_Hamster_5682",
          "text": "3090 user here, with 64 gb ram. It works for me using op instructions. Speed is quite good btw.",
          "score": 1,
          "created_utc": "2026-01-06 19:36:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2jzez",
          "author": "martinerous",
          "text": "One more finding - if using the default ComfyUI template, this LoRA in the upscaler corrupts the output for me. It becomes with colored patches and wobbly sound.\n\nhttps://preview.redd.it/72zuv3v5fsbg1.png?width=481&format=png&auto=webp&s=c2785542c7d2138448a0fe57c63bfb4d0bbf8a3d\n\nThis LoRA seems absent from the LTX own workflow, which does not have corruption issues. If I disable it in the ComfyUI template workflow, it works fine. However, it seems slower than the LTX one. I'm now trying to figure out why.",
          "score": 1,
          "created_utc": "2026-01-06 20:20:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2xn2s",
          "author": "Puzzled_Fisherman_94",
          "text": "yooooo thanks for the fp8 gemma, legend!",
          "score": 1,
          "created_utc": "2026-01-06 21:23:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4mg4n",
          "author": "Perfect-Campaign9551",
          "text": "The upscaler gives me a hugging face 404 page",
          "score": 1,
          "created_utc": "2026-01-07 02:33:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4oup1",
          "author": "AaronTuplin",
          "text": "He's clearly not even eating the cookie.  \nBooo! /s\n\n![gif](giphy|zhJ55GsXRajxm)",
          "score": 1,
          "created_utc": "2026-01-07 02:46:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4t0d8",
          "author": "Glad-Hat-5094",
          "text": "Are you asking us to paste this in embeddings\\_connector.py also?\n\n\"use --reserve-vram 4 as a argument for comfy and disable previews in settings.\"\n\nOr are you actually asking us to go into settings and turn that off?",
          "score": 1,
          "created_utc": "2026-01-07 03:09:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4viyy",
              "author": "Dogluvr2905",
              "text": "the latter... or you can also use        --preview-method none       as an addt'l startup argument.",
              "score": 2,
              "created_utc": "2026-01-07 03:23:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny51hec",
                  "author": "Glad-Hat-5094",
                  "text": "So just to conform do not add \"use --reserve-vram 4 as a argument for comfy and disable previews in settings.\" in the embeddings\\_connector.py file?",
                  "score": 1,
                  "created_utc": "2026-01-07 03:58:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny5dacv",
          "author": "gone_to_plaid",
          "text": "Thanks for this.  I can get it to run but most videos are just the initial frame with a slow zoom in.  Only fractional movement.  I in my 10 runs, only one video actually has movement, so I'm not sure what I'm doing wrong.",
          "score": 1,
          "created_utc": "2026-01-07 05:14:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5neft",
          "author": "GrungeWerX",
          "text": "3090 here. Are u using distilled, fp8, or full?",
          "score": 1,
          "created_utc": "2026-01-07 06:31:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6ex97",
          "author": "Signal_Confusion_644",
          "text": "Woah, this put my RTX3060 12Gb to work with LTX2.\n\nIm impressed. Great work.",
          "score": 1,
          "created_utc": "2026-01-07 10:39:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nya5mqd",
          "author": "Unique_Dog6363",
          "text": "Thanks to kijai and where is the same kijai workflow that you used for this video!",
          "score": 1,
          "created_utc": "2026-01-07 21:56:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyarufj",
          "author": "Dear-Aardvark7222",
          "text": "Is that normal? I use rtx3090+64gb and generate 121 frames 1920x1088 in 10 minutes with fp8 model and unsloth gemma. I had huge problems to make gemma work but now with unsloth finally can generate, but I have a feeling it's not 100% how it should be.  \n  \n\\[MultiGPU Core Patching\\] text\\_encoder\\_device\\_patched returning device: cuda:0 (current\\_text\\_encoder\\_device=cuda:0)\n\nLoading weights: 100%|‚ñà| 1065/1065 \\[00:14<00:00, 72.64it/s, Materializing param=model.vision\\_tower.vision\\_model.post\\_la\n\nCLIP/text encoder model load device: cuda:0, offload device: cpu, current: cpu, dtype: torch.float16\n\nRequested to load \\_LTXVGemmaTextEncoderModel\n\nloaded completely; 10850.52 MB usable, 10827.30 MB loaded, full load: False\n\nFound quantization metadata version 1\n\nDetected mixed precision quantization\n\nUsing mixed precision operations\n\nmodel weight dtype torch.bfloat16, manual cast: torch.bfloat16\n\nmodel\\_type FLUX\n\nunet unexpected: \\['audio\\_embeddings\\_connector.learnable\\_registers', 'audio\\_embeddings\\_connector.transformer\\_1d\\_blocks.0.attn1.k\\_norm.weight', 'audio\\_embeddings\\_connector.transformer\\_1d\\_blocks.0.attn1.q\\_norm.weight', 'audio\\_embeddings\\_connector.transformer\\_1d\\_blocks.0.attn1.to\\_k.bias', 'video\\_embeddings\\_connector.transformer\\_1d\\_blocks.0.ff.net.0.proj.bias', 'video\\_embeddings\\_connector.transformer\\_1d\\_blocks.0.ff.net.0.proj.weight', 'video\\_embeddings\\_connector.transformer\\_1d\\_blocks.0.ff.net.2.bias', \n\n...... lots of lines  \n'video\\_embeddings\\_connector.transformer\\_1d\\_blocks.1.attn1.to\\_v.bias', 'video\\_embeddings\\_connector.transformer\\_1d\\_blocks.1.attn1.to\\_v.weight', 'video\\_embeddings\\_connector.transformer\\_1d\\_blocks.1.ff.net.0.proj.bias', 'video\\_embeddings\\_connector.transformer\\_1d\\_blocks.1.ff.net.0.proj.weight', 'video\\_embeddings\\_connector.transformer\\_1d\\_blocks.1.ff.net.2.bias', 'video\\_embeddings\\_connector.transformer\\_1d\\_blocks.1.ff.net.2.weight'\\]\n\nVAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16\n\nno CLIP/text encoder weights in checkpoint, the text encoder model will not be loaded.\n\nRequested to load LTXAV",
          "score": 1,
          "created_utc": "2026-01-07 23:41:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyaxu8y",
          "author": "truci",
          "text": "Looks like it‚Äôs time to try LTXV2 now. Tyvm",
          "score": 1,
          "created_utc": "2026-01-08 00:12:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydln5c",
          "author": "alitadrakes",
          "text": "Which model do you download for working with rtx 3090?",
          "score": 1,
          "created_utc": "2026-01-08 10:57:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyhx3mt",
          "author": "Ecstatic-Sail5165",
          "text": "Wait, what do you mean SEVEN SECONDS? It takes 10 minutes minimum with the risk to crash the pc with my 4090...",
          "score": 1,
          "created_utc": "2026-01-08 23:38:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyijmol",
          "author": "-becausereasons-",
          "text": "I've tried the comfy and the ltx workflows; and keep getting random errors... \n\n\nLTXVGemmaEnhancePrompt\n'num_crops'",
          "score": 1,
          "created_utc": "2026-01-09 01:35:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyjugw3",
          "author": "diptosen2017",
          "text": "can someone pls help me with the ksampler issue?? i have 16gb vram and have 128gb of ram...yet when the model reaches the sampler section it says this error. here is are the images, also i am using all distilled models. \n\nhttps://preview.redd.it/k5dtibfcn9cg1.jpeg?width=1600&format=pjpg&auto=webp&s=9a5d0419a16841274706429010189f959bd9cd8d",
          "score": 1,
          "created_utc": "2026-01-09 06:16:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyt0ym4",
              "author": "Pleasant-Bug-8114",
              "text": "add --disable-pinned-memory to the launcher",
              "score": 1,
              "created_utc": "2026-01-10 16:12:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyk69tm",
          "author": "wonderflex",
          "text": "Edit: Ignore - I found out that this is not, but I'll leave up the comment in case anybody else gets confused.\n\n  \nIs this the FP8 distilled version?\n\nhttps://preview.redd.it/jwp8h7h35acg1.png?width=647&format=png&auto=webp&s=74b6ad2aa334544973998c5a06c48db77430a958",
          "score": 1,
          "created_utc": "2026-01-09 07:55:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyk6ibl",
              "author": "alitadrakes",
              "text": "nope, thats not distilled",
              "score": 1,
              "created_utc": "2026-01-09 07:57:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyl9xvy",
          "author": "extra2AB",
          "text": "Sadly doesn't seem to work for me, if I use the official provided Gemma 3 Quantized models, it just crashes my ComfyUI and if I use some another Gemma 3 model, it gives mat1 and mat2 multiplication error.\n\n(even after disabling preview through arguement as well as setting and using --reserve-vram)\n\nI search on the official github issue, and they say using the official Gemma 3 models fixes the mat1 and mat 2 error, but if I do so, then My comfyUI just crashed.\n\nI have 3090Ti and 64GB RAM. Python 12, pytorch 2.7.0+cu128\n\nif someone can help me with details about python version, pytorch/Cuda versions, etc on which it works and maybe also transformers version, that would be helpful.",
          "score": 1,
          "created_utc": "2026-01-09 13:16:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyzaqoe",
          "author": "Intelligent_Tank_727",
          "text": "Al i can tell that those example workflows give oom errors, but default comfyui template workflow does not. generation speeds are 150-200s 121frames so its fine.  But yess you have to be some sort of promt engineer to make it work..",
          "score": 1,
          "created_utc": "2026-01-11 14:59:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny14hio",
          "author": "According-Leg434",
          "text": "its a tragic to see as 8gb card user of how pity ai resources are",
          "score": 0,
          "created_utc": "2026-01-06 16:27:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1bg29",
              "author": "Netsuko",
              "text": "There's just always gonna be a cutoff. Sadly, when it comes to AI, VRAM is simply the end all be all.",
              "score": 6,
              "created_utc": "2026-01-06 16:59:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1psuc",
                  "author": "According-Leg434",
                  "text": "so when i upgrade gpu if that enough 16vram will be sufficent somwhow?",
                  "score": 0,
                  "created_utc": "2026-01-06 18:03:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny3w63d",
          "author": "Geesle",
          "text": "ANyone tried on amd card?",
          "score": 1,
          "created_utc": "2026-01-07 00:12:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyg24xz",
              "author": "p53ud0nym42",
              "text": "Even with these settings i get an OOM on an 9700xtx with rocm 7.1. Also sadly didn't find a guide yet how to run it.",
              "score": 1,
              "created_utc": "2026-01-08 18:36:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny0ipiu",
          "author": "Perfect-Campaign9551",
          "text": "I think consistency is going to be the flaw though. People want more than just 5 second videos we need the tools to build actual scenes. With Wan first frame last frame, and edit models like Qwen you can build scenes with consistency, but if you rely on Ltx for your audio how can you get consistent? I still think it's always better to build the final video outside of comfy",
          "score": -2,
          "created_utc": "2026-01-06 14:44:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0kkhq",
              "author": "Different_Fix_2217",
              "text": "It does up to 20 seconds, and video extension works (and it copies voices scarily well) This was continued from a real video and its scary accurate: [https://files.catbox.moe/46y2ar.mp4](https://files.catbox.moe/46y2ar.mp4) pretty much did his voice perfectly off of just a few seconds.",
              "score": 31,
              "created_utc": "2026-01-06 14:53:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny0orny",
                  "author": "protector111",
                  "text": "please share this wf!",
                  "score": 8,
                  "created_utc": "2026-01-06 15:14:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny3vqv1",
                  "author": "Erdeem",
                  "text": ">  does up to 20 seconds, and video extension works (and it copies voices scarily well) This was continued from a real\n\nSomone needs to create a workflow that includes the extension with the generation",
                  "score": 3,
                  "created_utc": "2026-01-07 00:10:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny0lrly",
                  "author": "candid-eighty",
                  "text": "Oh wow. You might append this to your original post. That‚Äôs wild.",
                  "score": 3,
                  "created_utc": "2026-01-06 14:59:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny151ow",
              "author": "lordpuddingcup",
              "text": "Check the literal examples of it extending real video‚Ä¶ now put it in a loop",
              "score": 2,
              "created_utc": "2026-01-06 16:30:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny1k68c",
              "author": "InevitableJudgment43",
              "text": "Use applio or elevenlabs to alter the voices. Most of the audio video models currently change voices, from generation to generation.",
              "score": 2,
              "created_utc": "2026-01-06 17:38:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1qopg",
                  "author": "Perfect-Campaign9551",
                  "text": "You aren't going to be able to sync the voice to the video if the video already is created. The video has to sync to the voice, meaning we need ability to give LTX the audio we want to use and not let it generate the audio itself. Is that possible?",
                  "score": 1,
                  "created_utc": "2026-01-06 18:07:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny6nsfk",
          "author": "nevermore12154",
          "text": "can 4gb vram and 32 gb ram work? üò¢üòµ‚Äçüí´",
          "score": 0,
          "created_utc": "2026-01-07 11:51:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyft3ew",
              "author": "Due_Yam5689",
              "text": "on my gtx 1050 3gb vram and 32gb+swap works well... ü§£",
              "score": 1,
              "created_utc": "2026-01-08 17:57:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nykwe8a",
                  "author": "nevermore12154",
                  "text": "Oh my i just got it run yesterday (incredibly slow tho) üòÜi think i can do up to 8s of 540p or 6s of 720p without oom. But its so slow (for my machine)",
                  "score": 1,
                  "created_utc": "2026-01-09 11:46:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny93ldl",
          "author": "Sugar_Short",
          "text": "Isn't this an api paid model?",
          "score": 0,
          "created_utc": "2026-01-07 19:11:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0pc7k",
          "author": "flasticpeet",
          "text": "I don't know man. The Confuscious jokes are pretty racist. It's not the jokes themselves, but the fake Asian accent, weird bowing, and historical racial trope is pretty insulting.\n\nIt would be like a video of a black person eating a watermelon telling jokes with a \"hood\" accent. The jokes themselves may not be insulting, but the context is.\n\nI get that they're \"harmless\" jokes, I grew up with it. I'm just letting you know your fly is down.",
          "score": -17,
          "created_utc": "2026-01-06 15:17:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0r4r3",
              "author": "External_Quarter",
              "text": "> I'm just letting you know your fly is down.\n\nYeah, about that...",
              "score": 3,
              "created_utc": "2026-01-06 15:25:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny0vvnw",
                  "author": "flasticpeet",
                  "text": "I'm not calling the OP a racist, or a bad person, I'm just pointing out the aesthetic is racist, and I stand on that. \n\nI'm willing to take criticism as much as I give it. Please let me know what you find wrong about my opinion.",
                  "score": -6,
                  "created_utc": "2026-01-06 15:48:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pze07a",
      "title": "A mysterious new year gift",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/59g5evn7bbag1.png",
      "author": "chrd5273",
      "created_utc": "2025-12-30 09:43:07",
      "score": 343,
      "num_comments": 92,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pze07a/a_mysterious_new_year_gift/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwpeinf",
          "author": "Proper-Employment263",
          "text": "Please be **Z-Image Omni**, **Z-Image Base**, and **Z-Image Edit**.\n\n**Edit:** **Qwen Image Edit 2512** is also welcome.",
          "score": 171,
          "created_utc": "2025-12-30 09:44:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwpj86e",
              "author": "ResponsibleTruck4717",
              "text": "Be the Z-image for video generation.",
              "score": 58,
              "created_utc": "2025-12-30 10:27:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwpslxp",
                  "author": "intLeon",
                  "text": "Z.. video?",
                  "score": 31,
                  "created_utc": "2025-12-30 11:49:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwqdn46",
                  "author": "shivdbz",
                  "text": "It will be z video",
                  "score": 6,
                  "created_utc": "2025-12-30 14:10:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwq1i3t",
              "author": "fruesome",
              "text": "Could be Wan Video\n\nMy guess based on AMA they did recently and majority asked for Wan Video",
              "score": 9,
              "created_utc": "2025-12-30 12:56:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwq2yjp",
                  "author": "HashTagSendNudes",
                  "text": "I doubt they will release a updated wan, rumor has it they are making to much via api, do I hope they release it ? 100% yes but ü§∑üèº",
                  "score": 10,
                  "created_utc": "2025-12-30 13:06:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwrgciw",
              "author": "Arcival_2",
              "text": "X-Audio or Y-text I think...Or worse MAI-UI-2B/8B.",
              "score": 1,
              "created_utc": "2025-12-30 17:21:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwukzx1",
              "author": "gomico",
              "text": "it's the Tongyi team so it can't be Qwen, should be a Z-image or WAN model",
              "score": 1,
              "created_utc": "2025-12-31 02:54:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwvbb2n",
              "author": "Witty_Mycologist_995",
              "text": "Please be Z-Image-Noob",
              "score": 1,
              "created_utc": "2025-12-31 05:47:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwwro77",
              "author": "shivdbz",
              "text": "Qwen is not tongai lB product",
              "score": 1,
              "created_utc": "2025-12-31 13:21:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwpytls",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2025-12-30 12:37:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwporhz",
          "author": "Sir_McDouche",
          "text": "Half-life 3 confirmed!",
          "score": 44,
          "created_utc": "2025-12-30 11:17:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqnuv6",
              "author": "mattjb",
              "text": "Star Citizen finally done!",
              "score": 18,
              "created_utc": "2025-12-30 15:06:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwstg27",
                  "author": "HardenMuhPants",
                  "text": "GTA 6 only postponed 2 years!",
                  "score": 5,
                  "created_utc": "2025-12-30 21:13:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwpstbq",
              "author": "International-Try467",
              "text": "IENDOFNSOWNJDCIFNIRBE R FHALF LIFE 4 JDFBDKANKSNFOFKE9RBFKFBIDJSIAVSHFJRBDJDNRIR GABEN JNDIDNDOENEKRNOFJFISJSIDJFOFNZOABJWKDFIFUHH DOORS OF STONEISW JFJRBDIWBSOBF",
              "score": -4,
              "created_utc": "2025-12-30 11:51:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwrjqil",
                  "author": "WhyIsTheUniverse",
                  "text": "Upvoted for posterity‚Äôs sake.",
                  "score": 1,
                  "created_utc": "2025-12-30 17:37:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpf6ci",
          "author": "BlackSwanTW",
          "text": "Z-Image-Turbo 2 üó£Ô∏è",
          "score": 99,
          "created_utc": "2025-12-30 09:50:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwpg5us",
              "author": "HornyGooner4401",
              "text": "We're getting GTA 6 before Z-Image base/edit",
              "score": 85,
              "created_utc": "2025-12-30 09:59:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nws7vzl",
                  "author": "Wild-Perspective-582",
                  "text": "Still not yet a Half Life 3",
                  "score": 2,
                  "created_utc": "2025-12-30 19:29:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpkm0x",
          "author": "Betadoggo_",
          "text": "lol  \n[https://github.com/modelscope/DiffSynth-Studio/pull/1166](https://github.com/modelscope/DiffSynth-Studio/pull/1166)",
          "score": 27,
          "created_utc": "2025-12-30 10:39:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwprvs6",
              "author": "noyart",
              "text": "Cant wait! ü§§¬†",
              "score": 4,
              "created_utc": "2025-12-30 11:44:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwt9qkb",
              "author": "Whispering-Depths",
              "text": "they are milking this shit soooo hard",
              "score": 5,
              "created_utc": "2025-12-30 22:30:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwr035z",
              "author": "martinerous",
              "text": "GGUF when? - Qwen.",
              "score": 3,
              "created_utc": "2025-12-30 16:05:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwphsb4",
          "author": "Luiguie171",
          "text": "https://preview.redd.it/1ivxkjopgbag1.jpeg?width=1220&format=pjpg&auto=webp&s=6e7939c6173e15358317e1f4ca27220fb1ee88fe\n\nThe duality of men",
          "score": 103,
          "created_utc": "2025-12-30 10:13:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwprk61",
              "author": "noyart",
              "text": "I want by gooooooner generator now üò§üò§üò§üßªüò≠",
              "score": 20,
              "created_utc": "2025-12-30 11:41:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwq5ml2",
                  "author": "mk8933",
                  "text": "Best of the best...is still SDXL...people are sleeping on it.",
                  "score": -14,
                  "created_utc": "2025-12-30 13:23:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwqbwe7",
              "author": "blastcat4",
              "text": "It's getting to be like every big Chinese game that has a leaks community.",
              "score": 1,
              "created_utc": "2025-12-30 14:00:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpfbko",
          "author": "Skyline34rGt",
          "text": "Probably Qwen Image v2 - they teasing it from a week - [https://x.com/cherry\\_cc12/status/2004741644810383684](https://x.com/cherry_cc12/status/2004741644810383684)\n\n[https://x.com/cherry\\_cc12/status/2004105860247965910](https://x.com/cherry_cc12/status/2004105860247965910)\n\n[https://x.com/cherry\\_cc12/status/2004109818874024246](https://x.com/cherry_cc12/status/2004109818874024246)",
          "score": 46,
          "created_utc": "2025-12-30 09:51:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwq3uq4",
              "author": "SirTeeKay",
              "text": "I mean, if it looks like this I can wait a bit longer for Z-Image.",
              "score": 5,
              "created_utc": "2025-12-30 13:12:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwqsr6f",
              "author": "NowThatsMalarkey",
              "text": ">https://x.com/cherry_cc12/status/2004105860247965910\n\nThe ‚Äúrealism‚Äù looks terrible compared to Z-Image Turbo. It‚Äôll probably be just as big as Flux.2-dev and therefore dead on arrival.",
              "score": -10,
              "created_utc": "2025-12-30 15:30:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nws239g",
                  "author": "materialist23",
                  "text": "Lmao",
                  "score": 1,
                  "created_utc": "2025-12-30 19:02:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwphao0",
          "author": "Noeyiax",
          "text": "![gif](giphy|fCtaS8rQDRF9C|downsized)",
          "score": 9,
          "created_utc": "2025-12-30 10:09:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqanmp",
              "author": "poopoo_fingers",
              "text": "1: cut a hole in a box",
              "score": 1,
              "created_utc": "2025-12-30 13:53:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqucvv",
          "author": "Perfect-Campaign9551",
          "text": "       (‚Ä¢ _ ‚Ä¢)\n       <)   >\n        |__|\n       / |  \\\n      /      \\",
          "score": 11,
          "created_utc": "2025-12-30 15:38:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrppgt",
              "author": "JohnnyLeven",
              "text": "       (‚Ä¢ _ ‚Ä¢)\n       < ) ) >\n        |__|\n       /   \\\n      /     \\",
              "score": 8,
              "created_utc": "2025-12-30 18:05:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwt4qgi",
              "author": "rinkusonic",
              "text": "Can you put it on his chest just like how zimage generates?",
              "score": 1,
              "created_utc": "2025-12-30 22:06:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpexo1",
          "author": "FitEgg603",
          "text": "He is playing with our emotions",
          "score": 15,
          "created_utc": "2025-12-30 09:47:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwprk4m",
              "author": "Mean-Credit6292",
              "text": "LET THE EDIT OUT!",
              "score": 3,
              "created_utc": "2025-12-30 11:41:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpgc75",
          "author": "Striking-Long-2960",
          "text": "The Audio model?",
          "score": 8,
          "created_utc": "2025-12-30 10:00:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpf92h",
          "author": "NordRanger",
          "text": "https://preview.redd.it/wzgiq9plcbag1.jpeg?width=680&format=pjpg&auto=webp&s=d2705e93aced59f405982876ddcf7324c9034372",
          "score": 8,
          "created_utc": "2025-12-30 09:50:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpgmmk",
          "author": "Skystunt",
          "text": "I hate how ai devs tease things in cryptic tweets to build hype",
          "score": 23,
          "created_utc": "2025-12-30 10:03:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwph8l0",
              "author": "ready-eddy",
              "text": "Because it works..",
              "score": 6,
              "created_utc": "2025-12-30 10:08:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwphvrv",
                  "author": "a_beautiful_rhind",
                  "text": "they conditioned me. every time I see that, I know it will be a letdown",
                  "score": 20,
                  "created_utc": "2025-12-30 10:14:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwqapiy",
              "author": "hurrdurrimanaccount",
              "text": "people will fall for it all the time. i hate that companies are building that \"rockstar\" kind of personality.\n\nmy guy you make ai models",
              "score": 1,
              "created_utc": "2025-12-30 13:53:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpgnrm",
          "author": "Nid_All",
          "text": "Qwen Image 2",
          "score": 4,
          "created_utc": "2025-12-30 10:03:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwsh0xf",
              "author": "RazsterOxzine",
              "text": "Qwen Image 2531.",
              "score": 1,
              "created_utc": "2025-12-30 20:13:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwprrm8",
          "author": "SweetLikeACandy",
          "text": "Qwen-Image-2512 probably, but I don't mind if it's Z-Image Base :D",
          "score": 4,
          "created_utc": "2025-12-30 11:43:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpjjus",
          "author": "physalisx",
          "text": "This is probably about an LLM. \n\nIf there was any image/video involved, that would be in the tweet, not an ASCII stick figure.",
          "score": 3,
          "created_utc": "2025-12-30 10:30:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpemo1",
          "author": "Major_Specific_23",
          "text": "Qwen image 2? I'm happy if it's qwen image 2 or zimage omni base. 0 complaints",
          "score": 6,
          "created_utc": "2025-12-30 09:45:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpigsq",
          "author": "AIDivision",
          "text": "Its another LLM model, don't get your hopes up.",
          "score": 5,
          "created_utc": "2025-12-30 10:20:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwq2nln",
              "author": "SirTeeKay",
              "text": "I mean... I wouldn't mind Qwen VL 2 or something along those lines.",
              "score": -2,
              "created_utc": "2025-12-30 13:04:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwqgz8g",
                  "author": "ETman75",
                  "text": "Qwen3 VL already exists‚Ä¶",
                  "score": 7,
                  "created_utc": "2025-12-30 14:29:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpvpc0",
          "author": "skyrimer3d",
          "text": "great if it's qwen 2 image, great model that needs more lora love.",
          "score": 4,
          "created_utc": "2025-12-30 12:14:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nws1lh9",
              "author": "Agile-Role-1042",
              "text": "Isn't Qwen a heavy model to train on?",
              "score": 1,
              "created_utc": "2025-12-30 18:59:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwt5m82",
              "author": "rinkusonic",
              "text": "I don't know why but I have never been able to generate a good image with qwen t2i. I kept trying every few weeks. I just gave up 2 days ago and freed my storage of 40 gb of models.",
              "score": 1,
              "created_utc": "2025-12-30 22:10:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwt7vpx",
                  "author": "skyrimer3d",
                  "text": "it mostly can but needs a ton of loras to look ok, something that ZIT does by default. Try lenovo , boreal and cinematic loras, they help a lot, also iphone and samsung loras are good.",
                  "score": 1,
                  "created_utc": "2025-12-30 22:21:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpyskh",
          "author": "Cold_Development_608",
          "text": "![gif](giphy|3j1cQmHH21pMEmgd0O)\n\nModel eppo varuven, eppadi varuvennu yarukkum theriyathu, aana vara vendiya nerathula correct a varuven.",
          "score": 2,
          "created_utc": "2025-12-30 12:37:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwq0tdk",
          "author": "Chemical-Load6696",
          "text": "Please be suno weights",
          "score": 2,
          "created_utc": "2025-12-30 12:52:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwq1r5i",
          "author": "ANR2ME",
          "text": "May be API only model üòÇ",
          "score": 2,
          "created_utc": "2025-12-30 12:58:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqi47p",
          "author": "Nokai77",
          "text": "Please... ZIE!",
          "score": 2,
          "created_utc": "2025-12-30 14:35:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwr0aq2",
          "author": "Great_Traffic1608",
          "text": "wan2.5-2.6",
          "score": 2,
          "created_utc": "2025-12-30 16:06:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpq2ee",
          "author": "Odd-Mirror-2412",
          "text": "ZIB please!",
          "score": 3,
          "created_utc": "2025-12-30 11:28:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpwdr2",
          "author": "chrd5273",
          "text": "More hints from modelscope; at least it seems like an image model. Qwen Image 2512 or Z image base?\n\nhttps://preview.redd.it/wprylix53cag1.jpeg?width=1080&format=pjpg&auto=webp&s=156efa904bfcf40c0ad98e50186fb0b97be3cecb",
          "score": 3,
          "created_utc": "2025-12-30 12:19:39",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nwpfdso",
          "author": "fauni-7",
          "text": "Omg omg...!",
          "score": 2,
          "created_utc": "2025-12-30 09:51:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwplhcu",
          "author": "Tall-Animator2394",
          "text": "its qwen image 2 [https://github.com/modelscope/DiffSynth-Studio/pull/1166](https://github.com/modelscope/DiffSynth-Studio/pull/1166)",
          "score": 2,
          "created_utc": "2025-12-30 10:47:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpgesq",
          "author": "Consistent-Mastodon",
          "text": "Wan2.2-2?",
          "score": 1,
          "created_utc": "2025-12-30 10:01:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwse80r",
          "author": "Technical_Ad_440",
          "text": "would love open source music finally",
          "score": 1,
          "created_utc": "2025-12-30 19:59:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwsodvi",
          "author": "zodoor242",
          "text": "Crystal Pepsi 2?",
          "score": 1,
          "created_utc": "2025-12-30 20:49:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvg4ka",
          "author": "seifai",
          "text": "Qwen 2512",
          "score": 1,
          "created_utc": "2025-12-31 06:26:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwph2s2",
          "author": "protector111",
          "text": "FYI Chinese new year is late February 2026",
          "score": 1,
          "created_utc": "2025-12-30 10:07:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwphc9v",
              "author": "Striking-Warning9533",
              "text": "As a Chinese, this is not usually what they meant. We call the Chinese NY as spring fes, And on English social media and at this time, it is almost meant to be Jan 1.",
              "score": 30,
              "created_utc": "2025-12-30 10:09:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwpjg1h",
                  "author": "physalisx",
                  "text": "Thank you for the insight",
                  "score": 2,
                  "created_utc": "2025-12-30 10:29:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwppmfm",
                  "author": "protector111",
                  "text": "I was just joking, but Thanks for the explanation :)",
                  "score": 0,
                  "created_utc": "2025-12-30 11:24:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwphgzs",
              "author": "Skyline34rGt",
              "text": "Don't worry, they operate from USA xD",
              "score": 1,
              "created_utc": "2025-12-30 10:10:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwppjye",
                  "author": "protector111",
                  "text": "Oh so its coming soon then xD",
                  "score": 0,
                  "created_utc": "2025-12-30 11:24:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwphsyc",
          "author": "HashTagSendNudes",
          "text": "I swear watch it be a sound model or a llm ü•πüíî",
          "score": 1,
          "created_utc": "2025-12-30 10:13:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwucxjn",
          "author": "AppealThink1733",
          "text": "Qwen's model has fallen far behind the latest open-source updates regarding LLM. I hope they make a turnaround.",
          "score": 0,
          "created_utc": "2025-12-31 02:07:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqnj4r",
          "author": "Acceptable_Home_",
          "text": "There was crazy Half life 3 ahh situation in this sub, more hopium for us",
          "score": -1,
          "created_utc": "2025-12-30 15:04:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpkgon",
          "author": "FitEgg603",
          "text": "\nIf the gift isn‚Äôt worthwhile, there‚Äôs no point in offering it. Creating unnecessary hype around a weak or irrelevant diffusion model serves no purpose. What we actually want is the Z-Image base model only‚Äîno LLMs, no Qwen2, or anything related.",
          "score": -9,
          "created_utc": "2025-12-30 10:38:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q6zb57",
      "title": "LTXV-2 now works on Wan2GP on as little as 10GB VRAM.",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/9pdi9nilb1cg1",
      "author": "Different_Fix_2217",
      "created_utc": "2026-01-08 02:16:18",
      "score": 338,
      "num_comments": 81,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q6zb57/ltxv2_now_works_on_wan2gp_on_as_little_as_10gb/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nyc92wp",
          "author": "wakalakabamram",
          "text": "It's generating 10 second 480p videos in 41 seconds on a 5080 with 64GB of RAM. Absolutely wild!",
          "score": 52,
          "created_utc": "2026-01-08 04:24:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycqbov",
              "author": "Practical-Elk-1579",
              "text": "So you happen to have a link or a workflow sir ? :( can't find infos",
              "score": 10,
              "created_utc": "2026-01-08 06:23:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nycw3gv",
              "author": "HornyGooner4401",
              "text": "Would it run with the same amount of VRAM but 32GB RAM?",
              "score": 6,
              "created_utc": "2026-01-08 07:09:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyd3ba4",
                  "author": "thebaker66",
                  "text": "I got it running with 8gb VRAM 32GB Ram but I'm cautious as I think it swaps to paging file which might cause a lot of wear on your disk drive?\n\nSo yeah it can run, pretty fast indeed but personally I'd wait for the GGUF's at least. It doesn't seem worth it to me unless you have at least 64gb of RAM.. or maybe I'm just paranoid.",
                  "score": 5,
                  "created_utc": "2026-01-08 08:12:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyd04jz",
              "author": "__Maximum__",
              "text": "Not any video, though. It can only do screaming and screaming singing.",
              "score": 3,
              "created_utc": "2026-01-08 07:44:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nycic55",
              "author": "DisorderlyBoat",
              "text": "Dang for real that is wild! Is that with audio input or just text? That sounds blazing fast I can't imagine a 5090",
              "score": 4,
              "created_utc": "2026-01-08 05:24:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyciijz",
                  "author": "wakalakabamram",
                  "text": "> audio input\n\nNo option to input audio. That's I2V.",
                  "score": 3,
                  "created_utc": "2026-01-08 05:25:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyd9594",
                  "author": "ANR2ME",
                  "text": "Someone was able to generate 5 seconds video within 8 seconds on 5090 using ComfyUI üòÅ That's almost real-time!",
                  "score": 5,
                  "created_utc": "2026-01-08 09:05:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyd13cx",
              "author": "Vivarevo",
              "text": "Pump the slob. Pump it! We must advance the death of shortform video of youtube/tiktok/insta. For the sake of humanity.",
              "score": 6,
              "created_utc": "2026-01-08 07:52:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyfxhlb",
              "author": "Perfect-Campaign9551",
              "text": "10 second 720p (1280x720) video on RTX3090 takes 60 seconds after warmup.\n\nKeep in mind LTX2 doesn't \"render\" at your resolution. It renders at 1/2 the resolution you give it and then it does an internal upscale step.",
              "score": 2,
              "created_utc": "2026-01-08 18:16:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyeqzpm",
              "author": "Lettuphant",
              "text": "I havent figured out the UI... Are you just meant to increase the video length the usual way and the sliding window takes over? I think I need someone to make a video of how to use this in WanGP lol.\n\nOh... Is it turn up video length, and steps, and provide anchor images?",
              "score": 1,
              "created_utc": "2026-01-08 15:08:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyfl3jj",
              "author": "kh3t",
              "text": "outstanding. can it handle higher resolutions?",
              "score": 1,
              "created_utc": "2026-01-08 17:22:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nymx1wf",
              "author": "JimmyDub010",
              "text": "That's awesome! running it here on a 4070 super. takes about 3 minutes, but surely better than nothing.",
              "score": 1,
              "created_utc": "2026-01-09 17:57:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nycl83i",
          "author": "SlipperyKitty69x",
          "text": "Fuck I about to go to bed and see this...",
          "score": 17,
          "created_utc": "2026-01-08 05:44:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyd3dsn",
          "author": "Remarkable_Garage727",
          "text": "anyone have it running on a 3090, care to share a install vid? or instruction. thanks",
          "score": 10,
          "created_utc": "2026-01-08 08:13:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyixeyr",
              "author": "The_Cat_Commando",
              "text": "for most of these packages just get [StabilityMatrix](https://github.com/LykosAI/StabilityMatrix/releases)\n\nextract to a place you want a portable install then run it,\n\nthen simply select the Wan2GP package (also maybe comfy, ostris trainer etc.)\n\nit makes it dead simple to play with all these things and share the model folders between them.",
              "score": 2,
              "created_utc": "2026-01-09 02:49:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyk9yet",
                  "author": "Remarkable_Garage727",
                  "text": "thanks",
                  "score": 1,
                  "created_utc": "2026-01-09 08:28:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nycrhpl",
          "author": "doogyhatts",
          "text": "I am using the distilled model on Wan2GP.   \nTested just now for a T2V output at 832x480, 241 frames, which took 1m 37s on a 5080.",
          "score": 7,
          "created_utc": "2026-01-08 06:32:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycw9gs",
              "author": "HornyGooner4401",
              "text": "How much RAM do you have and what FPS does it run on?",
              "score": 3,
              "created_utc": "2026-01-08 07:10:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nycx2s7",
                  "author": "doogyhatts",
                  "text": "64gb system ram. 24 fps.",
                  "score": 3,
                  "created_utc": "2026-01-08 07:17:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nybw3t2",
          "author": "Toclick",
          "text": "Kind of ironic that a tool named after Wan just added support for a video model some people call a Wan killer.",
          "score": 12,
          "created_utc": "2026-01-08 03:09:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycn9t3",
              "author": "JazzlikeLeave5530",
              "text": "It's just vestigial really. The program has supported more than Wan for a long time. It has Z-Image, Qwen, LTX, Hunyuan, etc. Almost all of them I think, if not all of them.",
              "score": 11,
              "created_utc": "2026-01-08 05:59:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nydakxb",
              "author": "RobbinDeBank",
              "text": "And this community is called StableDiffusion. The names are mostly used to describe the vibes.",
              "score": 11,
              "created_utc": "2026-01-08 09:19:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nye5u48",
              "author": "johnfkngzoidberg",
              "text": "It‚Äôs advertising. All of the LTX posts are just ads",
              "score": -2,
              "created_utc": "2026-01-08 13:19:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyj25iu",
                  "author": "JazzlikeLeave5530",
                  "text": "What? Wan2GP has existed for a long time before LTX and there's not even a way to give them money. Really shit ad if it is one lol",
                  "score": 2,
                  "created_utc": "2026-01-09 03:14:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nycn2m5",
          "author": "ShittyLivingRoom",
          "text": "After downloading the model in wangp it's giving an error saying that triton is missing, any idea on how to fix this?",
          "score": 3,
          "created_utc": "2026-01-08 05:58:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycpq07",
              "author": "tubbymeatball",
              "text": "Having the same problem here unfortunately. Someone help us :(",
              "score": 2,
              "created_utc": "2026-01-08 06:18:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nycwm27",
                  "author": "ShittyLivingRoom",
                  "text": "Found the solution!\n\nOn the wangp directory go to command prompt and type: \n\npip install triton-windows==3.5.1.post24\n\nconda activate wan2gp\n\npip install triton-windows==3.5.1.post24",
                  "score": 8,
                  "created_utc": "2026-01-08 07:13:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nycsgdr",
                  "author": "ShittyLivingRoom",
                  "text": "Yeah.. please let me know if you find a solution!",
                  "score": 2,
                  "created_utc": "2026-01-08 06:39:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nycmd65",
          "author": "DelinquentTuna",
          "text": "lol, cute",
          "score": 5,
          "created_utc": "2026-01-08 05:53:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyd3w6p",
          "author": "MartinByde",
          "text": "Do we have loras for this LTXV already?",
          "score": 2,
          "created_utc": "2026-01-08 08:17:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyd4q6t",
              "author": "Different_Fix_2217",
              "text": "Someone posted one earlier [https://civitai.com/models/2287974/clair-obscur-expedition-33-ltx-2?modelVersionId=2574779](https://civitai.com/models/2287974/clair-obscur-expedition-33-ltx-2?modelVersionId=2574779)",
              "score": 6,
              "created_utc": "2026-01-08 08:25:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nydhmo8",
          "author": "Darkmeme9",
          "text": "I am just gonna wait a little, until most is well and fixed .",
          "score": 2,
          "created_utc": "2026-01-08 10:23:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyhnkda",
          "author": "Peemore",
          "text": "OK this made me lol.",
          "score": 2,
          "created_utc": "2026-01-08 22:50:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nycl5in",
          "author": "protector111",
          "text": "Now make em  sit by the fire and say \"comfy bad! ai bad! ram good! no ram cause ai bad!\" and one drops DDR5 stick on fire to make it biger xD",
          "score": 2,
          "created_utc": "2026-01-08 05:44:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycyjg6",
              "author": "Appropriate_Math_139",
              "text": "can't post video replies here, so posted on banodoco instead... [https://discord.com/channels/1076117621407223829/1309520535012638740/1458724351385014375](https://discord.com/channels/1076117621407223829/1309520535012638740/1458724351385014375)",
              "score": 2,
              "created_utc": "2026-01-08 07:30:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nybqxnu",
          "author": "intermundia",
          "text": "quality is subpar but if you're RAM poor its a great solution for free gens.",
          "score": 3,
          "created_utc": "2026-01-08 02:42:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyc1ldx",
              "author": "Different_Fix_2217",
              "text": "? It can do the same resolutions / steps and such that comfy does. It just won't have as many options as comfy does of course, its for people who are having trouble getting comfy to work / troubleshooting it.",
              "score": 12,
              "created_utc": "2026-01-08 03:40:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nycmj8w",
                  "author": "DelinquentTuna",
                  "text": "The videos often get mutilated by reddit's conversion and compression.  Maybe you could share a link to the original somehow?",
                  "score": 3,
                  "created_utc": "2026-01-08 05:54:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nycbeg5",
                  "author": "intermundia",
                  "text": "Yeah i see. It's more enthusiasts level.",
                  "score": -7,
                  "created_utc": "2026-01-08 04:39:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nycsqn3",
              "author": "Different_Fix_2217",
              "text": "Oh you mean in comparison to sora 2?\n\nLTXV can look really good with the full model (fp16 non distilled) at high res but you will need a really good gpu like a RTX 6000 and / or a ton of ram (160GB or so?) and patience:  \n[https://files.catbox.moe/uju19s.mp4](https://files.catbox.moe/uju19s.mp4)\n\nThe default comfy / wangp stuff is for fast generations on lower end gpus which still can look very good:  \n[https://www.reddit.com/r/StableDiffusion/comments/1q6m285/ltx\\_is\\_actualy\\_insane\\_music\\_is\\_added\\_in\\_post\\_but/](https://www.reddit.com/r/StableDiffusion/comments/1q6m285/ltx_is_actualy_insane_music_is_added_in_post_but/)  \n[https://www.reddit.com/r/StableDiffusion/comments/1q6k2a3/definition\\_of\\_insanity\\_ltx\\_20\\_experience/](https://www.reddit.com/r/StableDiffusion/comments/1q6k2a3/definition_of_insanity_ltx_20_experience/)",
              "score": 3,
              "created_utc": "2026-01-08 06:42:09",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nyci0lg",
              "author": "Segaiai",
              "text": "Honestly, the quality of this video doesn't feel much different than all the recent Sora gens.",
              "score": 3,
              "created_utc": "2026-01-08 05:22:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyco1fl",
                  "author": "AndrewH73333",
                  "text": "Well Sora is using massive servers and is a paid product. This is run locally and for free.",
                  "score": 7,
                  "created_utc": "2026-01-08 06:05:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nycigiw",
                  "author": "intermundia",
                  "text": "Has sora quality dropped recently I've never used it",
                  "score": 1,
                  "created_utc": "2026-01-08 05:25:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nye64ci",
          "author": "Striking-Long-2960",
          "text": "This shouldn't make me so happy\n\n[https://streamable.com/jzbhot](https://streamable.com/jzbhot)",
          "score": 1,
          "created_utc": "2026-01-08 13:21:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyjj7js",
              "author": "MoreColors185",
              "text": "Is that ltx2??",
              "score": 1,
              "created_utc": "2026-01-09 04:55:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyjwrv8",
                  "author": "Striking-Long-2960",
                  "text": "Yes ing2vid",
                  "score": 1,
                  "created_utc": "2026-01-09 06:34:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyfp3gb",
          "author": "ATFGriff",
          "text": "I can only run the distilled version with 10 GB of VRAM",
          "score": 1,
          "created_utc": "2026-01-08 17:40:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfxqfs",
          "author": "fractaldesigner",
          "text": "i noticed all the apes lips were moving when only one ape was actually talking.",
          "score": 1,
          "created_utc": "2026-01-08 18:17:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygxw0g",
          "author": "Upbeat_Waltz8738",
          "text": "Managed to get the distilled model running on an RTX 3070 8GB and 32GB of RAM with Wan2GP. Generation is actually surprisingly quick",
          "score": 1,
          "created_utc": "2026-01-08 20:55:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nylvxxx",
          "author": "Ylsid",
          "text": "That made me laugh my ass off",
          "score": 1,
          "created_utc": "2026-01-09 15:10:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyder2f",
          "author": "DELOUSE_MY_AGENT_DDY",
          "text": "Can anyone compare the distilled vs. default model? Which is better?",
          "score": 1,
          "created_utc": "2026-01-08 09:57:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nycd9p9",
          "author": "C_C_Jing_Nan",
          "text": "The only people that hate comfy are the ones that want to be spoon fed everything. üòÇüëåüèº",
          "score": -12,
          "created_utc": "2026-01-08 04:51:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyclqjn",
              "author": "SlipperyKitty69x",
              "text": "I downvoted  to upvote",
              "score": 1,
              "created_utc": "2026-01-08 05:48:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nycifi1",
              "author": "luciferianism666",
              "text": "When you point out the obvious your comment gets downvoted lol",
              "score": -3,
              "created_utc": "2026-01-08 05:25:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q64ghf",
      "title": "LTX2 AI2V Yet another test",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/itjwenokiubg1",
      "author": "jordek",
      "created_utc": "2026-01-07 03:28:55",
      "score": 327,
      "num_comments": 126,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q64ghf/ltx2_ai2v_yet_another_test/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny4y76y",
          "author": "DescriptionAsleep596",
          "text": "Holy, this is promising!",
          "score": 52,
          "created_utc": "2026-01-07 03:38:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny54o96",
              "author": "lordpuddingcup",
              "text": "Like it really does its shocking how good it is already, without any custom loras and shit really yet even",
              "score": 11,
              "created_utc": "2026-01-07 04:17:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nydakh7",
              "author": "Lucky-Necessary-8382",
              "text": "Also there could be some advanced Mossad-style hidden feature primed to spring into action later.",
              "score": 1,
              "created_utc": "2026-01-08 09:18:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny5ctvo",
          "author": "DrBearJ3w",
          "text": "–®–æ–π–≥—É,–ì–µ—Ä–∞—Å–∏–º–æ–≤, –≥–¥–µ –±–ª* GGUF",
          "score": 95,
          "created_utc": "2026-01-07 05:11:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5xoje",
              "author": "Jeksxon",
              "text": "Hahahaha",
              "score": 8,
              "created_utc": "2026-01-07 08:00:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyc60mb",
              "author": "Nakidka",
              "text": "this",
              "score": 1,
              "created_utc": "2026-01-08 04:05:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny572j2",
          "author": "DisorderlyBoat",
          "text": "That is impressive! So cool it does audio and image to video, that's really dope for a local model.",
          "score": 22,
          "created_utc": "2026-01-07 04:33:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5c5k2",
              "author": "ANR2ME",
              "text": "It's also faster than Wan2.2 (probably thanks to fp4 model), it also support longer video (20 sec) and higher FPS (50 FPS) out of the box.",
              "score": 18,
              "created_utc": "2026-01-07 05:06:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny5kvtj",
                  "author": "DisorderlyBoat",
                  "text": "That's crazy! I hope I can run it on my 4090 lol",
                  "score": 3,
                  "created_utc": "2026-01-07 06:11:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny5qnec",
                  "author": "ItsAMeUsernamio",
                  "text": "How many steps are you supposed to run? The default workflow has 20 + 3 and that takes longer than 2+2 steps Wan. That‚Äôs with FP4 + the distilled lora on 5060Ti. Should I use the FP8 distilled model instead?",
                  "score": 3,
                  "created_utc": "2026-01-07 06:58:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny5i6hm",
          "author": "Lamassu-",
          "text": "Shoigu! Gerasimov! Where's the f\\*\\*\\*ing ammo?",
          "score": 21,
          "created_utc": "2026-01-07 05:50:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyb3ino",
              "author": "newbie80",
              "text": "LOL. The whole airplane thing was just a cover up.",
              "score": 2,
              "created_utc": "2026-01-08 00:40:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny5q5oj",
          "author": "HornyGooner4401",
          "text": "https://preview.redd.it/un0zjwdekvbg1.jpeg?width=500&format=pjpg&auto=webp&s=449993762f9ff3d176c5be6123eaf98a252a15b6",
          "score": 19,
          "created_utc": "2026-01-07 06:54:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5c9kb",
          "author": "ANGRYLATINCHANTING",
          "text": "Rest in Piss, Pringles",
          "score": 40,
          "created_utc": "2026-01-07 05:07:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny502ti",
          "author": "BoneDaddyMan",
          "text": "we're cooked",
          "score": 38,
          "created_utc": "2026-01-07 03:49:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny53vhd",
              "author": "read-well",
              "text": " Heard this from a lot of people recently, but today I believe we're cooked as well...",
              "score": 23,
              "created_utc": "2026-01-07 04:12:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny58bg8",
                  "author": "BoneDaddyMan",
                  "text": "I would 100% believe this is a real video if it wasn't posted in an AI subreddit",
                  "score": 20,
                  "created_utc": "2026-01-07 04:41:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny5fwws",
          "author": "AccountantOk9904",
          "text": "Is that Yevgeny?",
          "score": 17,
          "created_utc": "2026-01-07 05:33:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny80wyl",
              "author": "Jeksxon",
              "text": "Prigozhin, yeah.",
              "score": 6,
              "created_utc": "2026-01-07 16:20:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny8k37c",
                  "author": "AccountantOk9904",
                  "text": "RiP to a true Russian patriot",
                  "score": -4,
                  "created_utc": "2026-01-07 17:46:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny54k7f",
          "author": "tcdoey",
          "text": "I see why people hate and fear AI, but I love this.",
          "score": 14,
          "created_utc": "2026-01-07 04:17:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5jpjc",
              "author": "plHme",
              "text": "I don‚Äôt understand why actually. It‚Äôs just development. Back in the days when the car was invented people thought they could die from the high speed. Nothing to fear either AI or cars :)",
              "score": -9,
              "created_utc": "2026-01-07 06:01:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny754pb",
                  "author": "Servus_of_Rasenna",
                  "text": "Cars kill with higher rates than some wars, actually. So maybe you should",
                  "score": 3,
                  "created_utc": "2026-01-07 13:43:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny6963v",
                  "author": "dw82",
                  "text": "Cars weren't used to convince the masses to act against their interests.",
                  "score": 7,
                  "created_utc": "2026-01-07 09:47:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny7gdcp",
                  "author": "AlreadyBannedLOL",
                  "text": "Back in the days when cars were still something new MANY people got killed before we make the traffic rules we have today. With a magnitude more cars today we have 4-5 times less deaths compared to early 20th century. At some point there over 30000 deaths annually in the US.\n\nNow prepare to be shocked - the automobile industry blamed pedestrians.¬†\n\n¬†It‚Äôs not just development.¬†",
                  "score": 2,
                  "created_utc": "2026-01-07 14:43:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny58x4d",
          "author": "Toclick",
          "text": "Have you tried an audio with Russian language as input?",
          "score": 4,
          "created_utc": "2026-01-07 04:45:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny67u0g",
              "author": "jordek",
              "text": "Not yet, but I did some tests with the i2v workflow and it can created pretty good German, so other languages might work as well.",
              "score": 1,
              "created_utc": "2026-01-07 09:34:55",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "ny7s5jv",
              "author": "protector111",
              "text": "the model can generate t2v in Russian (its pretty bad quality TTS though)",
              "score": 1,
              "created_utc": "2026-01-07 15:40:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny5c2dc",
          "author": "Vladmerius",
          "text": "This is actually a MASSIVE game changer and would help me significantly with making my own movies. I don't have any problem recording all the dialogue myself if I can just have the AI generated characters synch with the audio. This is awesome as hell.¬†",
          "score": 4,
          "created_utc": "2026-01-07 05:06:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny7s8gw",
              "author": "protector111",
              "text": "how is this better than wananimate?",
              "score": 1,
              "created_utc": "2026-01-07 15:40:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny65cnn",
          "author": "TheRealMoofoo",
          "text": "Not bad‚Ä¶but where booba?!",
          "score": 4,
          "created_utc": "2026-01-07 09:11:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny6iszb",
              "author": "Upper-Reflection7997",
              "text": "You don't want to see that body horror bro unless you like seeing barbie dolls with pepperoni and buttons for nipples.",
              "score": 3,
              "created_utc": "2026-01-07 11:12:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny6nhy6",
                  "author": "StickStill9790",
                  "text": "Rule 34",
                  "score": 2,
                  "created_utc": "2026-01-07 11:49:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny5ml3a",
          "author": "Disastrous_Pea529",
          "text": "So you can do lip sync too??  What languages does it support ?",
          "score": 2,
          "created_utc": "2026-01-07 06:24:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5y9nm",
          "author": "protector111",
          "text": "my images dont move with this wf for some reason",
          "score": 2,
          "created_utc": "2026-01-07 08:05:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny6g2hl",
              "author": "Mirandah333",
              "text": "Here the same. The workflow didnt work for me",
              "score": 1,
              "created_utc": "2026-01-07 10:49:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny7dlmv",
                  "author": "Vicullum",
                  "text": "After trying this out I found you need a very specific head shot for this to work. If it's zoomed in or out too much they won't lip sync and all you'll get is a static image with a voiceover.",
                  "score": 2,
                  "created_utc": "2026-01-07 14:28:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny7dhj4",
          "author": "Vicullum",
          "text": "After trying this out I found you need a very specific head shot for this to work. If it's zoomed in or out too much they won't lip sync and all you'll get is a static image with a voiceover.",
          "score": 2,
          "created_utc": "2026-01-07 14:28:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nycdnq0",
              "author": "Opposite-Station-337",
              "text": "You probably didn't match resolutions. Something wrong with the resizer. Matching it got me out of that loop.",
              "score": 1,
              "created_utc": "2026-01-08 04:53:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyagmgn",
          "author": "Arnazes",
          "text": "it worked with tiled vae and --reserve-vram 4096 on my rtx 3090!",
          "score": 2,
          "created_utc": "2026-01-07 22:45:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6olzl",
          "author": "ResponsibleKey1053",
          "text": "What a choice of audio! Love it.",
          "score": 4,
          "created_utc": "2026-01-07 11:57:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny60fo4",
          "author": "Artforartsake99",
          "text": "Wow this is open source?",
          "score": 2,
          "created_utc": "2026-01-07 08:25:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5v1w1",
          "author": "MobileHelicopter1756",
          "text": "russian propaganda will be on the next level",
          "score": 1,
          "created_utc": "2026-01-07 07:36:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny63h9j",
              "author": "Erhan24",
              "text": "Right, luckily no other country or entity will make use of this. Thanks for your analysis.",
              "score": 0,
              "created_utc": "2026-01-07 08:53:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny63l5q",
                  "author": "MobileHelicopter1756",
                  "text": "‚ÄúOthers do bad, so we can continue to do bad too!‚Äù\n\nPerfect logic",
                  "score": -5,
                  "created_utc": "2026-01-07 08:54:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny4zdz9",
          "author": "Better-Interview-793",
          "text": "Nice!\nCan you share the prompt you used?",
          "score": 1,
          "created_utc": "2026-01-07 03:45:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4zs1n",
              "author": "jordek",
              "text": "\"video of a  men talking in rage. he is gesticulating, looking at the viewer and around the scene, he has a expressive body language. the men raises his voice in this intense scene, talking desperate.\"\n\nTo prevent static image output I messed around with cfg and compression values based on another users comment.",
              "score": 11,
              "created_utc": "2026-01-07 03:47:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny50aw6",
                  "author": "ExpandYourTribe",
                  "text": "What CFG did you find worked best? Were the compression values of the image or somewhere in the ComfyUI workflow?",
                  "score": 2,
                  "created_utc": "2026-01-07 03:50:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny50ual",
                  "author": "Better-Interview-793",
                  "text": "Cool, thank you (:",
                  "score": 1,
                  "created_utc": "2026-01-07 03:54:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny51msv",
          "author": "DescriptionAsleep596",
          "text": "But in my test, somehow it's getting blurry easily. I'm using kijai's workflow.",
          "score": 1,
          "created_utc": "2026-01-07 03:58:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5277z",
              "author": "jordek",
              "text": "In KJ's workflow is just one sampler stage. That was also the reason I copied the audio part into the original workflow. Also the detailer loras help to reduce blurriness.\n\nAbove video looks good on a phone screen but not so much on a desktop. later I'll test with Wan 2.2 v2v pass to improve details with 1.5-2.5 denoise.",
              "score": 2,
              "created_utc": "2026-01-07 04:02:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny53s56",
                  "author": "DescriptionAsleep596",
                  "text": "It's way faster than Wan 2.2, supports lip-sync, and even more. We'll wait for a more refined workflow. For sure, LTX-2 is much more powerful than Wan 2.2 in the future.",
                  "score": 1,
                  "created_utc": "2026-01-07 04:12:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny5o9vd",
                  "author": "Something_231",
                  "text": "Can you please share your workflow?",
                  "score": 1,
                  "created_utc": "2026-01-07 06:38:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny53oxj",
          "author": "Summerio",
          "text": "Possible to use a  character lora in this workflow?",
          "score": 1,
          "created_utc": "2026-01-07 04:11:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5emde",
          "author": "Known-Success-4649",
          "text": "Could this workflow work on an nvidia rtx a4000  16gb VRAM and 164gb RAM?",
          "score": 1,
          "created_utc": "2026-01-07 05:24:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny7530w",
              "author": "ArtificialAnaleptic",
              "text": "Currently doing a test run on a 4070ti Super 16gb with 128gb system RAM. I'm launching with:\n\npython main.py --reserve-vram 10 --disable-smart-memory --lowvram --fp8_e4m3fn-text-enc\n\nI had to swap out the LTXV Audio Text Encoder node for the LTX Gemma 3 model loader (I assume because of the --fp8_e4m3fn-text-enc but could be wrong) but it's currently running consuming about 50GB or RAM and 70% of my VRAM.\n\nWill update if it completes/works but the job is running.\n\nEDIT:\n\nSo it eventually went to 60+GB RAM usage but that's fine for me. It swapped to tiled VAE as it maxed out VRAM with the regular VAE. \n\nIt finished, but the using i2v the video just slowly zooms slightly towards the face with no other motion of the character. \n\nGoing to have to run some more tests. I found this with the original i2v model that sometimes you get no movement of the subject so there may be a setting to help with this or it may just be a case of doing a few extra runs.",
              "score": 1,
              "created_utc": "2026-01-07 13:42:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny5grb3",
          "author": "LyriWinters",
          "text": "jfc it is really really good",
          "score": 1,
          "created_utc": "2026-01-07 05:39:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5u4db",
          "author": "EuphoricTrainer311",
          "text": "where exactly does kijai post all his workflows? I know OP uploaded it as well, but I just want to find the original source.",
          "score": 1,
          "created_utc": "2026-01-07 07:28:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5vc7w",
          "author": "iiulium",
          "text": "You can see the teeth changing...so not so perfect",
          "score": 1,
          "created_utc": "2026-01-07 07:39:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5z5kl",
          "author": "CeraRalaz",
          "text": "‚ÄúWHERE IS ZIT BASE MODEL?!‚Äù",
          "score": 1,
          "created_utc": "2026-01-07 08:13:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6611n",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-07 09:17:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny68pnb",
              "author": "jordek",
              "text": "Had also OOM troubles with the other workflow in the VAE decode stage. There it helped to lower the VAE Decode node temporal\\_size from 4096 to 1024. Above workflow doesn't use that node.",
              "score": 1,
              "created_utc": "2026-01-07 09:43:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny66px7",
          "author": "eggplantpot",
          "text": "I'M MAD AS HELL",
          "score": 1,
          "created_utc": "2026-01-07 09:24:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6ci5q",
          "author": "Luigisopa",
          "text": "https://preview.redd.it/ovs9vu4pkwbg1.jpeg?width=1170&format=pjpg&auto=webp&s=12ef1b209717a42c3a470e77e5da84a9ff9aae9d",
          "score": 1,
          "created_utc": "2026-01-07 10:17:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6wkw8",
          "author": "coverednmud",
          "text": "Keep going, I'm listening. Intently.",
          "score": 1,
          "created_utc": "2026-01-07 12:52:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6x8zc",
          "author": "kujasgoldmine",
          "text": "Love it! Will be perfect when anyone can do I2V that includes audio, especially if you can give it a cloned voice to keep things consistent. That's when we can start to make movies easily!",
          "score": 1,
          "created_utc": "2026-01-07 12:57:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyeuxq4",
              "author": "Fluffy-Maybe-5077",
              "text": "We already can [https://www.reddit.com/r/StableDiffusion/comments/1q627xi/kijai\\_made\\_a\\_ltxv2\\_audio\\_image\\_to\\_video\\_workflow/](https://www.reddit.com/r/StableDiffusion/comments/1q627xi/kijai_made_a_ltxv2_audio_image_to_video_workflow/)",
              "score": 1,
              "created_utc": "2026-01-08 15:26:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny6zj5w",
          "author": "Vivarevo",
          "text": " why you chose to use assassinated war criminal",
          "score": 1,
          "created_utc": "2026-01-07 13:11:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny70p4p",
              "author": "jordek",
              "text": "Hot take, but the assassinated war criminal might help to assassinate the other war criminal who assassinated him.",
              "score": 2,
              "created_utc": "2026-01-07 13:17:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny7q9y0",
          "author": "FxManiac01",
          "text": "this is great, but generally speaking, but what is best approach in situation when I download the workflow and comfy throws this at me: \n\nhttps://preview.redd.it/rvtb1c1n4ybg1.png?width=1052&format=png&auto=webp&s=c8a258be39bd5394f0fedcaa2a5dffebca83e3e3\n\nlike I gave it to claude to do the job, find it etc.. but I guess there is some better way? or not? thanks, quite new to comfy...",
          "score": 1,
          "created_utc": "2026-01-07 15:31:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8lyix",
          "author": "lucassuave15",
          "text": "this was something only possible with paid closed source models, very impressive",
          "score": 1,
          "created_utc": "2026-01-07 17:54:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8t92w",
          "author": "goatonastik",
          "text": "impressive!",
          "score": 1,
          "created_utc": "2026-01-07 18:26:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny97hys",
          "author": "prozacgod",
          "text": "Is it just me or ... are his teeth changing every time he opens and closes his mouth.\n\n\nAnd now my teeth are hurting...\n(maybe I can pull them out and smoke them to feel better)",
          "score": 1,
          "created_utc": "2026-01-07 19:28:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9kt5u",
          "author": "Zestyclose-Move6357",
          "text": "IMG real good model for animating wild animals",
          "score": 1,
          "created_utc": "2026-01-07 20:26:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9pzay",
          "author": "NickMcGurkThe3rd",
          "text": "Any idea why i am getting:\n\nCannot read properties of undefined (reading 'target\\_id')\n\nwhen trying to run your workflow?",
          "score": 1,
          "created_utc": "2026-01-07 20:49:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyacrqa",
              "author": "Arnazes",
              "text": "just open subgraph and download models",
              "score": 1,
              "created_utc": "2026-01-07 22:28:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyadmtz",
          "author": "Relative_Mouse7680",
          "text": "Very impressive and expressive acting. Is the audio from ltx2 itself? I'm not familiar with comfy and workflows, what is it that your workflow did that the LTX2 model didn't/couldn't do natively?",
          "score": 1,
          "created_utc": "2026-01-07 22:32:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyaszxb",
          "author": "Gohan472",
          "text": "Damn! That looks good! No visible lip-sync issues that I can see.",
          "score": 1,
          "created_utc": "2026-01-07 23:47:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nybtlsl",
          "author": "Kiyushia",
          "text": "anyone know if its possible to run offloading to other gpu? i have another gpu and i would like to use it as \\`extra ram\\`",
          "score": 1,
          "created_utc": "2026-01-08 02:56:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nycrvz6",
          "author": "NeverLucky159",
          "text": "Can you achieve consistency with this? E. G. Make a character and keep it through scenes talking to other people etc. Like a short movie",
          "score": 1,
          "created_utc": "2026-01-08 06:35:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydtsg7",
          "author": "Psy_pmP",
          "text": "–ê—Ö—É–µ—Ç—å! –ê —á—Ç–æ –∑–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏? –ö–∞–∫ —Ç–∞–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å?",
          "score": 1,
          "created_utc": "2026-01-08 12:01:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6732x",
          "author": "Derispan",
          "text": "https://www.youtube.com/watch?v=w6-ckQhRmYQ <3",
          "score": 1,
          "created_utc": "2026-01-07 09:27:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny6925w",
              "author": "jordek",
              "text": "[Network (1976) 1080p - You've got to get mad](https://www.youtube.com/watch?v=qnuIzJoj3jM)\n\nAnd for completeness, the original Clip from the Network",
              "score": 6,
              "created_utc": "2026-01-07 09:46:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny8emz5",
                  "author": "gavjof",
                  "text": "Thanks. Couldn't remember the title",
                  "score": 1,
                  "created_utc": "2026-01-07 17:22:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny4y70b",
          "author": "casey_otaku",
          "text": "–ù–∞—Å 5090 —á–µ–ª–æ–≤–µ–∫ –∏ –º—ã –∏–¥–µ–º —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è! üòÇ\n–£ –º–µ–Ω—è —Ç–æ–ª—å–∫–æ 3060, –Ω–∞ 12 –≥–∏–≥–æ–≤, –º–Ω–µ –Ω–µ —Å–≤–µ—Ç–∏—Ç –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å?",
          "score": -1,
          "created_utc": "2026-01-07 03:38:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5b3wv",
              "author": "ANR2ME",
              "text": "There was a post someone testing LTX-2 using `--novram` argument on ComfyUI, and it only use 3GB VRAM üòÇ but it use 50GB system RAM if i'm not mistaken ü§î",
              "score": 2,
              "created_utc": "2026-01-07 04:59:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny5c977",
                  "author": "Rich_Consequence2633",
                  "text": "I'm doing it with 12gb vram and 32gb RAM at 720p. Using --lowvram",
                  "score": 8,
                  "created_utc": "2026-01-07 05:07:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nydutic",
              "author": "Psy_pmP",
              "text": "–£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç. \n–ù—É–∂–Ω–æ –ø—Ä–æ–ø–∏—Å–∞—Ç—å \n-- reserve-vram 4 –∏ --cache-none\n\nReserve 8 —Ç–æ—á–Ω–æ —Å—Ä–∞–±–æ—Ç–∞–ª. –ù–∞ 4 —Å–∫–æ—Ä–æ—Å—Ç–∏ –±–æ–ª—å—à–µ, –Ω–æ –Ω–∞ –∞–ø—Å–∫–µ–π–ª–µ –≤—ã–ª–µ—Ç–µ–ª. –ü–æ–∫–∞ —Ç–µ—Å—Ç–∏—Ä—É—é. \n\n–ò —Ñ–∞–π–ª –ø–æ–¥–∫–∞—á–∫–∏ –Ω—É–∂–µ–Ω –±–æ–ª—å—à–æ–π. \n\n–û–±—â–∞—è –ø–∞–º—è—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ 90–≥–± –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å.(Ram+–ø–æ–¥–∫–∞—á–∫–∞)",
              "score": 2,
              "created_utc": "2026-01-08 12:09:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nye33yy",
                  "author": "casey_otaku",
                  "text": "–ò –∫–∞–∫, –æ–Ω–æ —Ç–æ–≥–æ —Å—Ç–æ–∏—Ç? –Ø —Ç–æ–ª—å–∫–æ wan.2.2 —Ä–∞—Å–ø—Ä–æ–±–æ–≤–∞–ª) —Ä–µ–∞–ª—å–Ω–æ –ª—É—á—à–µ?",
                  "score": 1,
                  "created_utc": "2026-01-08 13:03:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny4z50q",
              "author": "jordek",
              "text": "I dunno if the 3060 works but there are some people doing low vram tests with 8GB (?).\n\nWith better cache options in future updates this should become approachable.",
              "score": 1,
              "created_utc": "2026-01-07 03:44:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny69zid",
          "author": "proderis",
          "text": "Every voice ive heard from this sounds like its trained on black and white movies from the 60s",
          "score": 0,
          "created_utc": "2026-01-07 09:54:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny6akkz",
              "author": "jordek",
              "text": "It is the original audio from 1976 movie The Network.",
              "score": 6,
              "created_utc": "2026-01-07 10:00:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny6r1st",
                  "author": "proderis",
                  "text": "Ohh i sit corrected then",
                  "score": 1,
                  "created_utc": "2026-01-07 12:15:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny6pj8d",
              "author": "WhatsTheGoalieDoing",
              "text": "Have you ever seen a movie from before 1980?\n\nAlso, black and white movie from the 60s, lol. The last classic black and white film to win best picture was filmed in 58 and 59.\n\nThank you though, it helps me make sense of why so many people generate absolute shit when there is such a dearth of cultural knowledge.",
              "score": 2,
              "created_utc": "2026-01-07 12:04:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny6r3e0",
                  "author": "proderis",
                  "text": "ok",
                  "score": 0,
                  "created_utc": "2026-01-07 12:15:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny7vq2w",
          "author": "Fair-Zombie-1678",
          "text": "Ow yeah !!: https://youtu.be/ngBZSE6irOA?si=jNunxfcUq7IRp7Lx",
          "score": 0,
          "created_utc": "2026-01-07 15:56:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5ph7f",
          "author": "_VirtualCosmos_",
          "text": "Omg, I kind of miss that idiot. This is one cursed idea, love it haha.",
          "score": -1,
          "created_utc": "2026-01-07 06:48:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny688sj",
              "author": "jordek",
              "text": "Right, it's good that he rots in hell, but he was kind of an entertainer.",
              "score": 1,
              "created_utc": "2026-01-07 09:38:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny6fnre",
          "author": "DongayKong",
          "text": "@grok is this real?",
          "score": -1,
          "created_utc": "2026-01-07 10:45:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny7jqxc",
          "author": "-Dubwise-",
          "text": "Sounds like a black and white 1950s film. Doesn‚Äôt match the video at all.",
          "score": -1,
          "created_utc": "2026-01-07 15:00:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q5a66x",
      "title": "LTX-2 open source is live",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1q5a66x/ltx2_open_source_is_live/",
      "author": "ltx_model",
      "created_utc": "2026-01-06 05:35:59",
      "score": 323,
      "num_comments": 88,
      "upvote_ratio": 0.98,
      "text": "In late 2024 we introduced LTX-2, our multimodal model for synchronized audio and video generation. We committed to releasing it as fully open source, and **today that's happening**.\n\n**What you're getting:**\n\n* Full model weights (plus a distilled version)\n* A set of LoRAs and IC-LoRAs\n* A modular trainer for fine-tuning¬†\n* RTX-optimized inference across NVIDIA cards\n\nYou can run LTX-2 directly in ComfyUI or build your own custom inference setup. We can‚Äôt wait to see the amazing videos you create, and even more, we‚Äôre looking forward to seeing how you adapt LTX-2 inside ComfyUI - new node graphs, LoRA workflows, hybrid pipelines with SD, and any other creative work you build.\n\nHigh-quality open models are rare, and open models capable of production-grade results are rarer still. We're releasing LTX-2 because we think the most interesting work happens when people can modify and build on these systems. It's already powering some shipped products, and we're excited to see what the community builds with it.\n\n**Links:**\n\nGitHub: [https://github.com/Lightricks/LTX-2](https://github.com/Lightricks/LTX-2)   \nHugging Face: [https://huggingface.co/Lightricks/LTX-2](https://huggingface.co/Lightricks/LTX-2)  \nDocumentation: [https://docs.ltx.video/open-source-model/](https://docs.ltx.video/open-source-model/)¬†\n\n",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q5a66x/ltx2_open_source_is_live/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "nxyl8ig",
          "author": "goddess_peeler",
          "text": "There goes my well-planned week.",
          "score": 68,
          "created_utc": "2026-01-06 05:45:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxymfcs",
              "author": "ltx_model",
              "text": "Sorry not sorry....",
              "score": 83,
              "created_utc": "2026-01-06 05:55:05",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nxzosfo",
              "author": "protector111",
              "text": "only if u have 5090 and want to generate 5 seconds videos in 480p of mediocre quality. But they do have sound...",
              "score": -14,
              "created_utc": "2026-01-06 11:38:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzrf6e",
                  "author": "kabachuha",
                  "text": "?? I have a 5090 and with the default native ComfyUI workflow (with the official distill lora) they generate in 40-50 seconds, in 720p. For 8 seconds maybe under two minutes. Very fast model.",
                  "score": 7,
                  "created_utc": "2026-01-06 11:59:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxynawy",
          "author": "Perfect-Campaign9551",
          "text": "Someone clone this repo before it gets taken down for business reasons or something",
          "score": 26,
          "created_utc": "2026-01-06 06:02:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxys719",
              "author": "goddess_peeler",
              "text": "```\n@echo off\nsetlocal enabledelayedexpansion\necho ============================================\necho Cloning LTX-2 Repositories\necho ============================================\necho.\nREM Clone the main LTX-2 repositories first\necho Cloning main LTX-2 GitHub repository...\ngit clone https://github.com/Lightricks/LTX-2.git LTX-2-GitHub\nif !errorlevel! equ 0 (\necho Successfully cloned GitHub LTX-2 repository to LTX-2-GitHub\nset /a count+=1\n) else (\necho Failed to clone GitHub LTX-2 repository\n)\necho.\necho Cloning main LTX-2 HuggingFace repository...\ngit clone https://huggingface.co/Lightricks/LTX-2 LTX-2-HuggingFace\nif !errorlevel! equ 0 (\necho Successfully cloned HuggingFace LTX-2 repository to LTX-2-HuggingFace\nset /a count+=1\n) else (\necho Failed to clone HuggingFace LTX-2 repository\n)\necho.\necho ============================================\necho Cloning LoRA Repositories\necho ============================================\necho.\nset \"repos[0]=https://huggingface.co/Lightricks/LTX-2-19b-IC-LoRA-Canny-Control\"\nset \"repos[1]=https://huggingface.co/Lightricks/LTX-2-19b-IC-LoRA-Depth-Control\"\nset \"repos[2]=https://huggingface.co/Lightricks/LTX-2-19b-IC-LoRA-Detailer\"\nset \"repos[3]=https://huggingface.co/Lightricks/LTX-2-19b-IC-LoRA-Pose-Control\"\nset \"repos[4]=https://huggingface.co/Lightricks/LTX-2-19b-LoRA-Camera-Control-Dolly-In\"\nset \"repos[5]=https://huggingface.co/Lightricks/LTX-2-19b-LoRA-Camera-Control-Dolly-Out\"\nset \"repos[6]=https://huggingface.co/Lightricks/LTX-2-19b-LoRA-Camera-Control-Dolly-Left\"\nset \"repos[7]=https://huggingface.co/Lightricks/LTX-2-19b-LoRA-Camera-Control-Dolly-Right\"\nset \"repos[8]=https://huggingface.co/Lightricks/LTX-2-19b-LoRA-Camera-Control-Jib-Down\"\nset \"repos[9]=https://huggingface.co/Lightricks/LTX-2-19b-LoRA-Camera-Control-Jib-Up\"\nset \"repos[10]=https://huggingface.co/Lightricks/LTX-2-19b-LoRA-Camera-Control-Static\"\nset count=0\nfor /L %%i in (0,1,10) do (\necho Cloning LoRA repository %%i of 10...\ngit clone !repos[%%i]!\nif !errorlevel! equ 0 (\necho Successfully cloned !repos[%%i]!\nset /a count+=1\n) else (\necho Failed to clone !repos[%%i]!\n)\necho.\n)\necho ============================================\necho Clone operation complete\necho Successfully cloned repositories\necho ============================================\npause\n```",
              "score": 3,
              "created_utc": "2026-01-06 06:42:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzorpd",
                  "author": "psychananaz",
                  "text": "windows couldn't even do bash scripting right smh",
                  "score": 6,
                  "created_utc": "2026-01-06 11:38:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny11z6t",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 1,
                  "created_utc": "2026-01-06 16:16:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxyuqlc",
          "author": "Different_Fix_2217",
          "text": "Seems really good so far:  \n[https://files.catbox.moe/kvmiem.mp4](https://files.catbox.moe/kvmiem.mp4)",
          "score": 24,
          "created_utc": "2026-01-06 07:04:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0onz3",
              "author": "StuccoGecko",
              "text": "hmm....lots of examples of 3d/animated style. Is it bad at photorealism?",
              "score": 2,
              "created_utc": "2026-01-06 15:14:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny36tlp",
                  "author": "kemb0",
                  "text": "My first video from a photo was great but after that mine all seem to be getting worse and worse to the point now where I just have a static shot with audio playing in the background. I don't know what's going on.",
                  "score": 1,
                  "created_utc": "2026-01-06 22:05:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxzoztq",
              "author": "protector111",
              "text": "do oyu have rtx 6000? how didi u render 8 sec in 4k ? i cant even render 5 sec 720p on 5090 with fp4",
              "score": 1,
              "created_utc": "2026-01-06 11:40:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxysc4e",
          "author": "lumos675",
          "text": "Huge Thanks to LTX team for this great release",
          "score": 21,
          "created_utc": "2026-01-06 06:43:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxylpw7",
          "author": "Better-Interview-793",
          "text": "Finally! Thank you for your effort, can‚Äôt wait to try it!",
          "score": 12,
          "created_utc": "2026-01-06 05:49:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz7dtx",
          "author": "kabachuha",
          "text": "Thank you for the work and for deciding not to keep the model behind the closed doors. Your model is worth hyping as much as possible. Wan dominance in videogen should be destroyed!",
          "score": 13,
          "created_utc": "2026-01-06 09:01:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0delc",
          "author": "Valtared",
          "text": "Thanks a lot ! Please make it so we can offload the text encoder on the CPU so that we can use our 16 GB Vram GPUs :)",
          "score": 10,
          "created_utc": "2026-01-06 14:15:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxymiiu",
          "author": "the_friendly_dildo",
          "text": "Any word on when the comfyui nodes and workflows will drop?",
          "score": 6,
          "created_utc": "2026-01-06 05:55:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxynghf",
              "author": "Hoodfu",
              "text": "Edit: they updated their github afterwards, the nodes load now. They imply that the models will auto download, but of course they don't. --- old message - They mention this repo in the documentation but there's no ltx2 workflows there in the examples folder and it clearly hasn't been updated for ltx2. So clearly there's some kind of big disconnect. I can't get the nodes to load in the latest comfyui. They have issues open for those bugs, and there's been pull requests open for them for weeks. So not sure what's up with it.  [https://github.com/Lightricks/ComfyUI-LTXVideo](https://github.com/Lightricks/ComfyUI-LTXVideo)",
              "score": 7,
              "created_utc": "2026-01-06 06:03:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxyow96",
                  "author": "ArkCoon",
                  "text": "They just added the LTX2 workflows literally 2 minutes after your comment",
                  "score": 10,
                  "created_utc": "2026-01-06 06:14:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2got6",
              "author": "JimmyDub010",
              "text": "Comfy sucks and takes way too much time for setup where I'm sure pinokio will have a better gradio UI sooner rather than later.",
              "score": -6,
              "created_utc": "2026-01-06 20:05:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxypz6c",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 11,
          "created_utc": "2026-01-06 06:23:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxyuujf",
              "author": "poopoo_fingers",
              "text": "Wait, so no offloading?",
              "score": 2,
              "created_utc": "2026-01-06 07:05:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxyp75y",
          "author": "Terraria_lover",
          "text": "So how does this compare to Wan 2.2? better consistent animation or about the same for anyone who has the hardware to test this?",
          "score": 4,
          "created_utc": "2026-01-06 06:17:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxysm5p",
              "author": "lordpuddingcup",
              "text": "It has audio",
              "score": 12,
              "created_utc": "2026-01-06 06:45:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxyxd4z",
                  "author": "Skyline34rGt",
                  "text": "and 20sec",
                  "score": 12,
                  "created_utc": "2026-01-06 07:27:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2jyqc",
              "author": "EternalBidoof",
              "text": "Animation is hit or miss. Wan seems much better at this. But the speed is great, so you can run through 2-3 animations in the amount of time it takes WAN to output 1, but sometimes not even 1 of those 3 is good.",
              "score": 2,
              "created_utc": "2026-01-06 20:20:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny4nbfp",
              "author": "theoffmask",
              "text": "Just run 3 image-video tests. I used the same image and prompt to test Veo 3.1, Kling 2.6, WAN 2.5 and maybe Seedance and other video models before. All I can say is LTX-2 is astonishing, except for lipsync.",
              "score": 2,
              "created_utc": "2026-01-07 02:37:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxywno1",
          "author": "No_Comment_Acc",
          "text": "Guys, Comfy is already updated with 6 workflows!",
          "score": 5,
          "created_utc": "2026-01-06 07:21:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzahrr",
          "author": "NineThreeTilNow",
          "text": "Watching people complain about other people doing good open source work always amazes me. \n\nKeep up the good work.",
          "score": 13,
          "created_utc": "2026-01-06 09:32:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz0fn7",
          "author": "Mother_Scene_6453",
          "text": "https://preview.redd.it/l8j334ohqobg1.png?width=872&format=png&auto=webp&s=7968c1e75f860d9247d4da62e24bb9004e602ec5\n\nAnyone else getting this?",
          "score": 4,
          "created_utc": "2026-01-06 07:55:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz3oeq",
              "author": "DolanPlsHavMerci",
              "text": "Try setting live previews to none in comfy settings",
              "score": 3,
              "created_utc": "2026-01-06 08:26:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxyums4",
          "author": "CommercialOpening599",
          "text": "https://preview.redd.it/mqftrx53hobg1.jpeg?width=480&format=pjpg&auto=webp&s=162f4487c182a63a0ea70fac2dd00ad3025310d9",
          "score": 6,
          "created_utc": "2026-01-06 07:03:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyvvv7",
          "author": "vAnN47",
          "text": "thanks for keeping the promise!",
          "score": 6,
          "created_utc": "2026-01-06 07:14:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0p3p9",
          "author": "panospc",
          "text": "Is it possible to use your own audio and have LTX-2 do the lip-sync, similar to InfiniteTalk?",
          "score": 3,
          "created_utc": "2026-01-06 15:16:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny28e5r",
              "author": "ltx_model",
              "text": "It's a conditioning mask, essentially. Try using \"LTXV Set Audio Video Mask By Time\" node to define a starting time that's close to zero and an end time that's big enough to cover the entire video, set \"mask\\_audio\" to False and mask\\_video to True. Basically all the audio latents will be masked and the first video latent too.",
              "score": 6,
              "created_utc": "2026-01-06 19:27:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny2alhu",
                  "author": "seeKAYx",
                  "text": "Amazing!",
                  "score": 2,
                  "created_utc": "2026-01-06 19:37:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxz5zn3",
          "author": "memorex-1",
          "text": "Minimum requirements ?",
          "score": 5,
          "created_utc": "2026-01-06 08:48:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0ch6x",
          "author": "Devajyoti1231",
          "text": "Need to 14b video+5b audio separate models to be able to run it in 16gb vram cards :/",
          "score": 2,
          "created_utc": "2026-01-06 14:10:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1jhbo",
          "author": "SweatyNovel2356",
          "text": "Forgive me for this question... How do I get Gemma3 up and running for the workflow. I downloaded all of the files and put them into a folder (with the name I thought appropriate) tried in text encoder and clip folders and no dice. Tried a safetensors version of the model. Nope.",
          "score": 2,
          "created_utc": "2026-01-06 17:35:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1tvsn",
          "author": "James_Reeb",
          "text": "Great üåü can we train our Loras ?",
          "score": 2,
          "created_utc": "2026-01-06 18:21:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny26a46",
              "author": "ltx_model",
              "text": "Yes, we have trainer resources here:   \n[https://github.com/Lightricks/LTX-2/tree/main/packages/ltx-trainer](https://github.com/Lightricks/LTX-2/tree/main/packages/ltx-trainer)",
              "score": 5,
              "created_utc": "2026-01-06 19:17:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny2nuhd",
                  "author": "James_Reeb",
                  "text": "Big Thanks ‚ù§Ô∏è",
                  "score": 2,
                  "created_utc": "2026-01-06 20:38:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzkrls",
          "author": "MechTorfowiec",
          "text": "I used to be a real artist you know...\n\nMy stuff was in published books you know...\n\nNow computer does everything for me and I'm spending a free day proompting funny video memes about games released around 1999 - 2002.\n\nThe future is now.",
          "score": 3,
          "created_utc": "2026-01-06 11:05:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny6xq9z",
              "author": "No_Comment_Acc",
              "text": "I used to a translator. Welcome to the club :)",
              "score": 2,
              "created_utc": "2026-01-07 13:00:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxz5ple",
          "author": "GirlSeekingTS",
          "text": "Let's go!! Finally ex‚Å§cited to see a decent open-source mo‚Å§del from the LTX te‚Å§am",
          "score": 2,
          "created_utc": "2026-01-06 08:45:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyo94y",
          "author": "cointalkz",
          "text": "I love you",
          "score": 3,
          "created_utc": "2026-01-06 06:09:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzddj9",
          "author": "Zueuk",
          "text": "can it still extend generated videos?",
          "score": 1,
          "created_utc": "2026-01-06 09:59:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny05tev",
          "author": "Its-all-redditive",
          "text": "I‚Äôll test this with fp8 and bf16 at 1080p and 4K if anyone wants to provide some good testing prompts. I‚Äôll use the two stage pipeline.",
          "score": 1,
          "created_utc": "2026-01-06 13:33:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0kayq",
          "author": "Bitter-College8786",
          "text": "Does it support videos longer than 6 seconds? I see 5-6s videos as examples in this subreddit",
          "score": 1,
          "created_utc": "2026-01-06 14:52:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0o4t0",
          "author": "StuccoGecko",
          "text": "been asking this on almost every LTX-2 post...where is the vae file?",
          "score": 1,
          "created_utc": "2026-01-06 15:11:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1qw0u",
              "author": "lumos675",
              "text": "baked inside the model",
              "score": 3,
              "created_utc": "2026-01-06 18:08:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxz4qsu",
          "author": "FinBenton",
          "text": "idk Im prob doing something wrong but I got it working fp8 and fp4 i2v but best resolution I can do is 480p before OOM on 5090 and quality is horrible mess.",
          "score": 1,
          "created_utc": "2026-01-06 08:36:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzd958",
              "author": "crinklypaper",
              "text": "its not trained on low quality it seems. works better on higher resolutions",
              "score": 1,
              "created_utc": "2026-01-06 09:58:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzfns8",
                  "author": "FinBenton",
                  "text": "Yeah I can push like 800x600 with t2v but there is a lot of problems with extra limbs and that kinda stuff, higher resolutions are just running out of VRAM.\n\ne. well actually I can do 720p with fp8 model with 121 frames. Generic postures work ok but if person is laying down it all kinda falls apart and there is bunch of artifacts especially with mouth and face.",
                  "score": 1,
                  "created_utc": "2026-01-06 10:20:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxyo0gp",
          "author": "s-mads",
          "text": "Awesome! Thanks for sharing this.",
          "score": 1,
          "created_utc": "2026-01-06 06:07:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny087om",
          "author": "silenceimpaired",
          "text": "It‚Äôs just so hard to be excited about this model when looking at the license",
          "score": 1,
          "created_utc": "2026-01-06 13:47:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nya01s7",
              "author": "SkyNetLive",
              "text": "Crap. You are right. Almost shot myself there.",
              "score": 2,
              "created_utc": "2026-01-07 21:31:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxyrpca",
          "author": "jazzamp",
          "text": "No portrait aspect ratio? Eh!",
          "score": 0,
          "created_utc": "2026-01-06 06:38:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny6xyph",
              "author": "No_Comment_Acc",
              "text": "It does work in portrait orientation.",
              "score": 1,
              "created_utc": "2026-01-07 13:01:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny7vxcp",
                  "author": "jazzamp",
                  "text": "I checked on their official website and that's what it says. I uploaded a portrait and it gave me a landscape. Maybe it's different offline",
                  "score": 1,
                  "created_utc": "2026-01-07 15:57:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxynl59",
          "author": "alerikaisattera",
          "text": "[Except that it's not actually open-source, but proprietary available AI misrepresnted as such](https://huggingface.co/Lightricks/LTX-2/blob/main/LICENSE)",
          "score": -11,
          "created_utc": "2026-01-06 06:04:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxyofz4",
              "author": "Different_Fix_2217",
              "text": "I mean its pretty fair. Annual revenue of 10M+ needs to get a commercial license. I'll take that over not having weights at all like wan2.6.",
              "score": 19,
              "created_utc": "2026-01-06 06:11:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxypl87",
                  "author": "goddess_peeler",
                  "text": "Sure, but let‚Äôs call things what they are. Not open source.\n\n**Edited to add:**  \nChildren, this is not commentary on whether LTX-2 is good or bad, or whether the *license* is good or bad.  \nIt's a comment about semantics. Open Source is one thing. The terms of this license are something else. These are simple facts, not value judgements.",
                  "score": 8,
                  "created_utc": "2026-01-06 06:20:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxyozmu",
                  "author": "alerikaisattera",
                  "text": "It may be fair, but whether it's fair or not is irrelevant to the fact that proprietary software must not be misrepresented as open-source",
                  "score": 5,
                  "created_utc": "2026-01-06 06:15:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxyp1l0",
              "author": "goddess_peeler",
              "text": "Agreed. Not open source. Free as in ‚Äúfree beer.‚Äù Gratis, not libre.\n\nThe license, as summarized by Claude:\n\n‚Äî-\n\n**Core License Terms:**\n- Free for non-commercial use and small businesses\n- Companies with **$10M+ annual revenue must obtain a paid commercial license** from Lightricks\n- Non-exclusive, worldwide, royalty-free for eligible users\n- Released January 5, 2026\n\n**What You Can Do:**\n- Use, modify, create derivatives, and distribute the model\n- Host as a service (SaaS)\n- Fine-tune and create derivative works\n- Own outputs you generate (with caveats)\n\n**Important Restrictions:**\n- All derivatives must be distributed under this same license (copyleft/viral)\n- Cannot use for commercial competing products without separate license\n- Cannot use outputs or model without disclosing it's AI-generated\n- Extensive acceptable use policy prohibiting harmful uses (minors, deepfakes, weapons, discrimination, medical advice, law enforcement predictions, malware, etc.)\n\n**Distribution Requirements:**\n- Must include full license text with any distribution\n- Must pass along all use restrictions to downstream users\n- Must mark modified files\n- Retain copyright notices\n\n**Other Notable Terms:**\n- No warranty (AS IS)\n- Licensor can remotely restrict usage for violations\n- NY law governs, disputes go to ICC arbitration\n- Violation of $10M threshold triggers liquidated damages (2x owed fees)\n- License terminates if you sue Lightricks over IP\n\n**Bottom line:** Free for you to use and modify given your use case, but this is a restrictive license that requires derivatives to remain under the same terms and has strong commercial use limitations for larger entities.",
              "score": 4,
              "created_utc": "2026-01-06 06:16:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxysr7k",
                  "author": "lordpuddingcup",
                  "text": "And most people should be fine for that if your a 10m company get a fuckin license",
                  "score": 1,
                  "created_utc": "2026-01-06 06:47:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny2e7vh",
          "author": "DescriptionAsleep596",
          "text": "Fuck Wan... Where can I donate to the LTX team?",
          "score": -1,
          "created_utc": "2026-01-06 19:53:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny32984",
              "author": "Consistent_Cod_6454",
              "text": "It is ungrateful to trash talk WAN.. their team have done a lot for the community",
              "score": 8,
              "created_utc": "2026-01-06 21:44:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny4rbp4",
                  "author": "DescriptionAsleep596",
                  "text": "No. They took advantage of the community's contributions and betrayed its members.",
                  "score": 1,
                  "created_utc": "2026-01-07 02:59:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q0h7zp",
      "title": "Z-IMAGE TURBO khv mod, pushing z to limit",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1q0h7zp",
      "author": "DevKkw",
      "created_utc": "2025-12-31 16:36:10",
      "score": 322,
      "num_comments": 53,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q0h7zp/zimage_turbo_khv_mod_pushing_z_to_limit/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwxros5",
          "author": "DevKkw",
          "text": "**details and download on** [civitai](https://civitai.com/models/2264784/zit-khv?modelVersionId=2549250)\n\nEdit---\n\nWorkflow is same as the workflow included in civitai model page.\n\nFor those image prompt is:\n\n`(Generate an hyperrealistic photograph with maximum quality and refinement. Sharp where sharpness matters, smooth gradients without banding, accurate colors, and professional finish. Focus on realism. Technical excellence in every aspect of the photograph.) (A visceral strikingly hyperrealistic and intensely vibrant high-resolution photograph with crystal clarity and subtle cinematic grain), (A realistic vibrant colors photo, cinematic still)`\n\n`A hyperrealistic raw, evocative studio photograph capturing a Close-up, extreme detail, SUBJECT.`\n\n`The composition is carefully calibrated to maximize the visual impact. The shallow depth of field make a captivating and profoundly unsettling photograph.`\n\n`Camera Settings: f/2.8, ISO 800, 1/250th second shutter speed, high dynamic range (HDR) ‚Äì to capture the full range of colors and details in the scene.`\n\n`Photorealistic image, sharp focus, depth of field, bokeh.`\n\n  \nwhere SUBJECT is what you want.\n\ndragonfly eye\n\ncat tongue\n\nclown fish\n\nhuman purple eye\n\n  \netc.",
          "score": 27,
          "created_utc": "2025-12-31 16:37:05",
          "is_submitter": true,
          "replies": [
            {
              "id": "nwxxvm0",
              "author": "Dr-Moth",
              "text": "On Civit, your F1 car image is amazing.",
              "score": 6,
              "created_utc": "2025-12-31 17:07:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwy1zda",
                  "author": "DevKkw",
                  "text": "thank you",
                  "score": 2,
                  "created_utc": "2025-12-31 17:28:23",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwxuri6",
              "author": "jazzamp",
              "text": "I'm downloading right away. I'm trusting you üî•",
              "score": 5,
              "created_utc": "2025-12-31 16:52:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwy0bkl",
              "author": "zthrx",
              "text": "Can you share the workflow for the dragonfly? there is no workflow in png",
              "score": 1,
              "created_utc": "2025-12-31 17:20:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwy3rak",
                  "author": "DevKkw",
                  "text": "added details in frist comment.",
                  "score": 1,
                  "created_utc": "2025-12-31 17:37:13",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwzwv6v",
              "author": "no-comment-no-post",
              "text": "Sorry, I must be slow, but I cannot find your workflow. Would you mind linking directly please?",
              "score": 1,
              "created_utc": "2025-12-31 23:27:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx00atv",
                  "author": "DevKkw",
                  "text": "Follow link in the frist comment, on civitai page you found some images with workflow, download it at drag in comfyUI.",
                  "score": 0,
                  "created_utc": "2025-12-31 23:48:34",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwxvbc7",
          "author": "littlegreenfish",
          "text": "Best non-sexualiazed showcase of AI images I have seen. The details are incredible. I can't imagine what the next 2-3 updates will achieve. \n\nCat teefs are a bit weird but, this is still crazy.",
          "score": 42,
          "created_utc": "2025-12-31 16:55:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwyjppu",
              "author": "Der_Hebelfluesterer",
              "text": "The carrots are cocks in disguise!",
              "score": 2,
              "created_utc": "2025-12-31 18:56:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwy8vzb",
              "author": "Incognit0ErgoSum",
              "text": "> Best non-sexualiazed showcase of AI images I have seen.\n\nAgreed. It would have to be sexualized to be better.",
              "score": 12,
              "created_utc": "2025-12-31 18:01:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx0ft5w",
              "author": "machstem",
              "text": "The purple eye, the left of it feels like it should lead to a nose bridge but is actually on the right side.  Gave me a double take.\n\nThe snail is the better one. I don't know enough about them to find the nuances.\n\nThe fish eye is off a bit too\n\nThe dog has human tongue, its a little off-putting\n\nThese photos are pretty amazing displays of what can be done",
              "score": 2,
              "created_utc": "2026-01-01 01:24:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwxrol0",
          "author": "ThiagoAkhe",
          "text": "Mind = blown",
          "score": 16,
          "created_utc": "2025-12-31 16:37:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx0d5x6",
          "author": "Sudden_List_2693",
          "text": "https://preview.redd.it/qz5sg4m31nag1.png?width=1000&format=png&auto=webp&s=4447336a154ab4fb114a9d680548a1ebf5aa4de9\n\n\n\n\n\nCat tongue is the worst example I've ever seen.  \nThey look nothing like that-",
          "score": 8,
          "created_utc": "2026-01-01 01:07:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx0ivja",
              "author": "Lost_Cod3477",
              "text": "there are also teeth",
              "score": 2,
              "created_utc": "2026-01-01 01:44:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwyh1bu",
          "author": "Conscious_Arrival635",
          "text": "cat tongue is too human like lol",
          "score": 6,
          "created_utc": "2025-12-31 18:42:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxy16p",
          "author": "primeye55",
          "text": "Where I can try Z-Image ?",
          "score": 4,
          "created_utc": "2025-12-31 17:08:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxyry3",
              "author": "DevKkw",
              "text": "With comfyUI. You know it?",
              "score": 5,
              "created_utc": "2025-12-31 17:12:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwy0c2q",
                  "author": "primeye55",
                  "text": "Yep, but comfyUI is running locally on my PC, but I have only 8gm of vram..",
                  "score": 0,
                  "created_utc": "2025-12-31 17:20:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwyb5vw",
          "author": "lacerating_aura",
          "text": "Can you make the process of modification public. I see that only pruned model is available on civit. I would like to make this modification on fp32 model.",
          "score": 3,
          "created_utc": "2025-12-31 18:13:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwynxao",
          "author": "the_bollo",
          "text": "I tried a few dozen generations with the base model and again with your fine tune. I'm not really seeing any notable difference to be honest. Also the finetune is 50% smaller than ZIT so I'm concerned its lost some capabilities.",
          "score": 3,
          "created_utc": "2025-12-31 19:18:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwyzx28",
              "author": "DevKkw",
              "text": "50% size smaller and no notable difference isn't a goal? Especially for who have low vram?\nCan you tell sampler and scheduler you use? Maybe some of these work better than other. I do more test on these way. Thak you for giving feedback.",
              "score": 1,
              "created_utc": "2025-12-31 20:21:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx36j4r",
          "author": "Live-North-6210",
          "text": "It just feels like a different seed, it doesnt exactly feel like a step up. Idk if that made sense.",
          "score": 3,
          "created_utc": "2026-01-01 15:10:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxw52v",
          "author": "Major_Specific_23",
          "text": "would you mind sharing more details? this looks very good. did you modify the weight of the layers?",
          "score": 2,
          "created_utc": "2025-12-31 16:59:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxmu90x",
              "author": "Complete-Box-3030",
              "text": "Do you have something for qwen edit 2511",
              "score": 1,
              "created_utc": "2026-01-04 15:02:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwxx6qm",
              "author": "DevKkw",
              "text": "You right, I worked on the layer, try to pushing out it to maximize clear and minimal details, without destroying text capability",
              "score": 0,
              "created_utc": "2025-12-31 17:04:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwytwgl",
                  "author": "myst3rie",
                  "text": "You have the workflow ?",
                  "score": 2,
                  "created_utc": "2025-12-31 19:49:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwzsiev",
          "author": "ZootAllures9111",
          "text": "IDK, these all look dull and grey to me in a way that Z doesn't normally.",
          "score": 2,
          "created_utc": "2025-12-31 23:01:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx70hho",
          "author": "Forsaken-Interest961",
          "text": "—Ç–æ–ª—å–∫–æ –æ—ã–±–∫–∞ –∏ —Å—Ç—Ä–µ–∫–æ–∑–∞ –ø–æ—Ö–æ–∂–∏ –Ω–∞ –Ω–∞—Å—Ç–æ—è—â–∏—Ö",
          "score": 2,
          "created_utc": "2026-01-02 03:41:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxw3bg",
          "author": "3deal",
          "text": "https://preview.redd.it/mx7qearulkag1.png?width=2835&format=png&auto=webp&s=f597de857ef49424a06fdab37c170336ae7e506b\n\nI saw this on civitai, i don't see a lot of difference with the vanilla model, can you share more compare please ?",
          "score": 3,
          "created_utc": "2025-12-31 16:58:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx0gbsc",
              "author": "Lost_Cod3477",
              "text": "on pants in KHV picture you can see degradation of model",
              "score": 3,
              "created_utc": "2026-01-01 01:27:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwxycs8",
              "author": "DevKkw",
              "text": "The smoke in background, the moon details, the energy around hand.\nZoom in to see. If you have prompt to try, let me know.",
              "score": -3,
              "created_utc": "2025-12-31 17:10:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwypi9m",
          "author": "InternationalOne2449",
          "text": "Nothing special really.",
          "score": 3,
          "created_utc": "2025-12-31 19:26:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwy5ii3",
          "author": "Lewd_Dreams_",
          "text": "I love flux 2 but this macro lens is good too?",
          "score": 2,
          "created_utc": "2025-12-31 17:45:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwy9io9",
          "author": "a_beautiful_rhind",
          "text": "Possible to release this as a lora? I'd like to use it with nunchaku.",
          "score": 1,
          "created_utc": "2025-12-31 18:05:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx0yqf9",
          "author": "Green-Ad-3964",
          "text": "some of the best examples I've ever seen from genAI. I'll test this model ASAP. Is this good also for I2I or only T2I?",
          "score": 1,
          "created_utc": "2026-01-01 03:30:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx3wglc",
          "author": "leepuznowski",
          "text": "Tried your prompt using Qwen Image 2512. Results are pretty good. Maybe a bit heavy on the HDR look, but overall solid.\n\nhttps://preview.redd.it/o16th1eiwrag1.png?width=1328&format=png&auto=webp&s=d93955b40b6881e52dc013caea174ad22d36bc95",
          "score": 1,
          "created_utc": "2026-01-01 17:30:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx3wr17",
              "author": "leepuznowski",
              "text": "https://preview.redd.it/3zz2uuoswrag1.png?width=1328&format=png&auto=webp&s=8628aaed427198a47f8a0f5b0d95444299ff66f4\n\neye",
              "score": 2,
              "created_utc": "2026-01-01 17:32:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxv3ctj",
                  "author": "zhl_max1111",
                  "text": "Can you share the method for making the skin look so realistic?",
                  "score": 1,
                  "created_utc": "2026-01-05 18:43:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx3wj9s",
              "author": "leepuznowski",
              "text": "another\n\nhttps://preview.redd.it/s7kfm0llwrag1.png?width=1328&format=png&auto=webp&s=211ac1d45606ecff5780554c89cc57d56840400c",
              "score": 1,
              "created_utc": "2026-01-01 17:31:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx3wmfb",
              "author": "leepuznowski",
              "text": "more\n\nhttps://preview.redd.it/kykxbhlowrag1.png?width=1328&format=png&auto=webp&s=d74a03bbd2ba971a9d82a381e60701075754edb6",
              "score": 1,
              "created_utc": "2026-01-01 17:31:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx3wome",
              "author": "leepuznowski",
              "text": "https://preview.redd.it/hy71cbnqwrag1.png?width=1328&format=png&auto=webp&s=81b6086fa678606376beb2a00e52914d6c9b9f0e",
              "score": 1,
              "created_utc": "2026-01-01 17:32:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxc4ze8",
          "author": "lumos675",
          "text": "I wish there was a Zvideo as well and never would look back to Wan 2.2 anymore",
          "score": 1,
          "created_utc": "2026-01-02 22:44:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxvqjp",
          "author": "3deal",
          "text": "the images are very good.  \nHow about loras ? Do they work with this model ?",
          "score": 1,
          "created_utc": "2025-12-31 16:57:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxwlh2",
              "author": "DevKkw",
              "text": "I don't know about lora, I saw many lora degraded base model, sorry.",
              "score": 1,
              "created_utc": "2025-12-31 17:01:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwyohwz",
          "author": "wrapped_in_clingfilm",
          "text": "Fuck me",
          "score": 1,
          "created_utc": "2025-12-31 19:20:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxw0gc",
          "author": "Significant-Pause574",
          "text": "Most interesting.",
          "score": 0,
          "created_utc": "2025-12-31 16:58:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q5cut2",
      "title": "[Official Tutorial] how to use LTX-2 - I2V & T2V on your local Comfy",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/1ylzsk2nrobg1",
      "author": "ltx_model",
      "created_utc": "2026-01-06 08:11:28",
      "score": 304,
      "num_comments": 124,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial - Guide",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q5cut2/official_tutorial_how_to_use_ltx2_i2v_t2v_on_your/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny4cmb6",
          "author": "StuccoGecko",
          "text": "\"how to\"  \nskips installation process and starts from a fully functioning workflow at the start of the video.  \nthanks bud.",
          "score": 19,
          "created_utc": "2026-01-07 01:40:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz33nk",
          "author": "Acceptable_Home_",
          "text": "Are ggufs out yet?",
          "score": 30,
          "created_utc": "2026-01-06 08:20:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3zqg2",
              "author": "Nevaditew",
              "text": "16 hours and nothing. what is going on",
              "score": 4,
              "created_utc": "2026-01-07 00:31:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny4033s",
              "author": "Freonr2",
              "text": "Well, nvfp4 is.",
              "score": 3,
              "created_utc": "2026-01-07 00:32:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny1r10f",
              "author": "aar550",
              "text": "12 gb vram üò≠",
              "score": 4,
              "created_utc": "2026-01-06 18:09:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1znpa",
                  "author": "llamabott",
                  "text": "Is that a yes?",
                  "score": 3,
                  "created_utc": "2026-01-06 18:47:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nylew4h",
              "author": "Ill_Key_7122",
              "text": "Yes:\n\n[https://huggingface.co/vantagewithai/LTX-2-GGUF](https://huggingface.co/vantagewithai/LTX-2-GGUF)\n\n[https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/tree/main](https://huggingface.co/unsloth/gemma-3-12b-it-GGUF/tree/main)",
              "score": 1,
              "created_utc": "2026-01-09 13:44:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxz5ieb",
          "author": "Thuannguyenhn",
          "text": "Where can I do text encoding? I've tried using gemma\\_3\\_12B\\_it.safetensors but it's not working",
          "score": 8,
          "created_utc": "2026-01-06 08:44:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz850s",
              "author": "bnlae-ko",
              "text": "Same, getting something size error",
              "score": 2,
              "created_utc": "2026-01-06 09:09:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzcb8o",
                  "author": "Umbaretz",
                  "text": "Tensor size mismatch? Same.",
                  "score": 4,
                  "created_utc": "2026-01-06 09:49:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny00fe6",
                  "author": "jingtianli",
                  "text": "FileNotFoundError: No files matching pattern 'tokenizer.model' found under E:\\\\ComfyUI\\_windows\\_portable\\\\ComfyUI\\\\models\n\n  \nThis is the Error I got",
                  "score": 4,
                  "created_utc": "2026-01-06 13:01:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxzj49x",
                  "author": "No-Dot-6573",
                  "text": "Disable live preview. Error with video helper suite.",
                  "score": 1,
                  "created_utc": "2026-01-06 10:51:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny1bxww",
              "author": "No_Mixture_7383",
              "text": "error sigen nodos en rojo., alguien  podido?",
              "score": -1,
              "created_utc": "2026-01-06 17:01:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxzq2mg",
          "author": "anydezx",
          "text": "It's fantastic that the LTX-2 developers're publishing the best configurations for using your own models; this should serve as an example for all release models. It saves users a lot of time when testing a model and seeing its capabilities and uses in real-world situations. Also, many beginners watch Ytubers who post content without knowing what they're doing, simply because they have the premise (there're exceptions). Perhaps you could add the typical information about cloning repositories and where to download models and their location to the introductory video. I know it's in the workflows and easy for most, but many beginners ask where everything goes. I just installed it; I'm quite busy and will test it another day. If you want to try it, first update ComfyUI to the latest Nightly build, restart, and then simply drag any official workflow to the manager and select \"Install missing custom nodes.\" Restart again, download everything, and place them in the corresponding folders. Some links may be broken, but they've already published many models and versions on huggingface. Refresh the window by pressing the letter R. I look forward to seeing your examples. By the way, the voice feature looks great!üëå",
          "score": 5,
          "created_utc": "2026-01-06 11:48:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzzlyo",
              "author": "GreyScope",
              "text": "Using this repo for beginners is trying to run before they can walk. It's not gatekeeping , comfyui is technical and there's no way around that, ppl need to get the basic skills and use them . Repo owners shouldn't need to tell people how to walk (to continue the metaphor). \n\nIf you had seen the workflow , you'd see that it tells you where models go.",
              "score": 1,
              "created_utc": "2026-01-06 12:56:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny04lfi",
                  "author": "anydezx",
                  "text": "If you had seen the workflow, you would have noticed that some links're expired and that, for now, there's only support for the Nightly version. If you teach a child to walk, they'll fall less, and you'll reduce the number of unnecessary Reddit posts with the same question. A good tutorial should be enough for all types of users (I've taught university class on other topics several times). I understand that ComfyUI has a steep learning curve, but if you explain things in a way that 99% of users can understand, we'd see more and more excellent posts instead of \"I have an OEM\" or \"My output's just a black image!\"üëä",
                  "score": 2,
                  "created_utc": "2026-01-06 13:26:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny2oehp",
                  "author": "ltx_model",
                  "text": "It's a fair point. This tutorial is aimed at people who are already familiar with Comfy. There's a lot more people out there who are new to Comfy -- making a tutorial for them isn't a crazy idea.",
                  "score": 2,
                  "created_utc": "2026-01-06 20:41:17",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny17kuu",
          "author": "candid-eighty",
          "text": "Adding things like block swapping and other memory-management features to the nodes would be helpful. A lot of people have found command line arguments that help, but they don't allow much control.\n\nThis could really unlock longer and higher res videos for people with low VRAM.",
          "score": 5,
          "created_utc": "2026-01-06 16:41:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz7irh",
          "author": "djtubig-malicex",
          "text": "I'll see how it goes with the 256gb ram M3 ultra mac studio",
          "score": 3,
          "created_utc": "2026-01-06 09:03:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1biu5",
              "author": "9elpi8",
              "text": "Please let me know.",
              "score": 3,
              "created_utc": "2026-01-06 16:59:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny1drsh",
              "author": "No_Mixture_7383",
              "text": "no",
              "score": 0,
              "created_utc": "2026-01-06 17:09:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxz50pp",
          "author": "Head-Leopard9090",
          "text": "No one talks about vram‚Ä¶",
          "score": 9,
          "created_utc": "2026-01-06 08:39:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz9cvo",
              "author": "RO4DHOG",
              "text": "No one reads the manual\n\nhttps://preview.redd.it/q1qbgkso5pbg1.png?width=591&format=png&auto=webp&s=fd188795b03a90f39e3b3e22ae442a82742ac40f",
              "score": 27,
              "created_utc": "2026-01-06 09:21:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzdmwq",
                  "author": "Head-Leopard9090",
                  "text": "Thank you",
                  "score": 1,
                  "created_utc": "2026-01-06 10:01:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxz5iqf",
              "author": "Informal_Warning_703",
              "text": "32gb if you look at Comfy workflows. An nvidia page \\*implies\\* 8-16gb is possible: [https://www.nvidia.com/en-us/geforce/news/rtx-ai-video-generation-guide/](https://www.nvidia.com/en-us/geforce/news/rtx-ai-video-generation-guide/)\n\nBut that's not possible with the current workflows or models. The text encoder along hits OOM error for me on 16gb.",
              "score": 11,
              "created_utc": "2026-01-06 08:44:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzafrr",
                  "author": "intLeon",
                  "text": "Clip ggufs have been out for older models. I use Q4 for wan for example. I am sure they will squeeze everything out eventually.\n\nEdit: it seems to run using only 8gbs of vram during clip. Make sure to have bitsandbytes pip package installed.\n\nWelp its using cpu for clip..\n\nEdit2: It worked on 12GB Vram. First generation took 312s with sage enabled for 480x832@121 frames (bypassed prompt enhancer) using distilled fp8. Enhancer throws error because it requires clip to run on gpu.\n\nEdit3: It takes 50~ seconds to generate 480x832@121 frames text-2-video on my 4070ti using fp8 distilled model with sage enabled except for the clip text encode time (runs on cpu somehow but I believe it will be fixed)",
                  "score": 3,
                  "created_utc": "2026-01-06 09:31:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxz44db",
          "author": "WildSpeaker7315",
          "text": "was this 720p demonstration on 16gb vram or a lot more?",
          "score": 2,
          "created_utc": "2026-01-06 08:30:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz4m7j",
              "author": "Informal_Warning_703",
              "text": "A lot more. I can't even get the CLIP node to encode the prompts without hitting OOM on 16gb VRAM.",
              "score": 4,
              "created_utc": "2026-01-06 08:35:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxz5je6",
                  "author": "Smilysis",
                  "text": "Is it possible to offload the model to ram? I have 8gb vram but 32gb ram xd",
                  "score": 3,
                  "created_utc": "2026-01-06 08:44:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxz5jj6",
                  "author": "WildSpeaker7315",
                  "text": "figured as much, damn and thats the end of the fun for a lot of us not sure we will see gguf here - to be fair nothing stops us, haha",
                  "score": 1,
                  "created_utc": "2026-01-06 08:44:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxz5d6a",
              "author": "BWeebAI",
              "text": "Needs >= 32GB VRAM",
              "score": 4,
              "created_utc": "2026-01-06 08:42:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny8zzcm",
                  "author": "RobMilliken",
                  "text": "I've got this to run with my 3090 16gb VRAM 64gb RAM laptop with this underrated post and the default workflow for I2V:   \n  \n[https://www.reddit.com/r/StableDiffusion/comments/1q5k6al/fix\\_to\\_make\\_ltxv2\\_work\\_with\\_24gb\\_or\\_less\\_of\\_vram/](https://www.reddit.com/r/StableDiffusion/comments/1q5k6al/fix_to_make_ltxv2_work_with_24gb_or_less_of_vram/) . Making one line change and using the starting line as:  \n  \npython [main.py](http://main.py) \\--reserve-vram 4 --preview-method none\n\nI didn't use the reduced clip but I can't add additional Loras without an out of memory GPU issue so may use the reduced clip and see if some of the lora's will load.\n\nInterestingly, one may be able in the future with LTX-2 as it is now to clone both a video and audio (voice) according to the post as well - with an, at this writing, to-do written workflow. This is a pretty nice advance.",
                  "score": 1,
                  "created_utc": "2026-01-07 18:55:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxz6vbk",
          "author": "alitadrakes",
          "text": "I hear 32gb vram is needed but can this run on 24gbvram?",
          "score": 2,
          "created_utc": "2026-01-06 08:56:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz8lx4",
              "author": "Informal_Warning_703",
              "text": "I saw someone in another comment in another thread say they were getting OOM with 24gb vram.",
              "score": 3,
              "created_utc": "2026-01-06 09:13:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny0fmno",
              "author": "intLeon",
              "text": "You can, I've a 12gb card and for me the clip is running on cpu, idk if it understands that it wont fit in vram or something. Just enable system fallback from nvidia settings\n\nclip I'm using;  \n[https://huggingface.co/google/gemma-3-12b-it-qat-q4\\_0-unquantized/tree/main](https://huggingface.co/google/gemma-3-12b-it-qat-q4_0-unquantized/tree/main)\n\nThe distilled fp8 model takes around a minute to generate a 5s 480x832 resolution video except the cpu clip encode part. And I cant run the enhancer since it requires clip to be in vram but it will be fixed once we get gguf clips I hope.",
              "score": 2,
              "created_utc": "2026-01-06 14:27:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxz83lm",
          "author": "Skyline34rGt",
          "text": "It's much more complicated than I thought xD",
          "score": 2,
          "created_utc": "2026-01-06 09:08:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzt35q",
          "author": "DeerWoodStudios",
          "text": "Possible to run this on a 2 RTX 3090 and 128 GB of Ram ?",
          "score": 2,
          "created_utc": "2026-01-06 12:11:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0wfyp",
          "author": "singfx",
          "text": "We're just 6 days into 2026 and we get this gem. this year in AI is gonna be crazy!",
          "score": 2,
          "created_utc": "2026-01-06 15:50:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2lr0b",
          "author": "lordforex",
          "text": "NICE... I can't wait to try this on my new nVidia DGX Spark",
          "score": 2,
          "created_utc": "2026-01-06 20:28:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny308in",
          "author": "HonestoJago",
          "text": "I was able to get it to work running a blackwell pro but they won't let me upload the video here. Had to do a subfolder in the text encoders folder with the full gemma-3 weights and config files. Really good quality 1280x704, five seconds long, using around 70gb vram. \n\nhttps://preview.redd.it/ynb24endssbg1.png?width=428&format=png&auto=webp&s=b815d403cc8976247675734e5f469949651f564d",
          "score": 2,
          "created_utc": "2026-01-06 21:35:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4am4v",
              "author": "QikoG35",
              "text": "Which text encoder did you use?",
              "score": 1,
              "created_utc": "2026-01-07 01:29:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny94h3z",
                  "author": "HonestoJago",
                  "text": "Sorry just saw this. I used this one, which I believe is the one recommended in the workflow: https://huggingface.co/google/gemma-3-12b-it-qat-q4_0-unquantized",
                  "score": 2,
                  "created_utc": "2026-01-07 19:15:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny941ml",
              "author": "CA-ChiTown",
              "text": "70GB VRAM - a $15,000 PC ???",
              "score": 1,
              "created_utc": "2026-01-07 19:13:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny94vai",
                  "author": "HonestoJago",
                  "text": "I should‚Äôve clarified that‚Äôs how much it used with everything loaded at once without quants.",
                  "score": 1,
                  "created_utc": "2026-01-07 19:17:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny5jek2",
          "author": "rm-rf-rm",
          "text": "Stupid question - i'll need to wait for GGUF to run on apple silicon?",
          "score": 2,
          "created_utc": "2026-01-07 05:59:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6ucl7",
          "author": "ouyhu685",
          "text": "anyone get this error: LTXVGemmaCLIPModelLoader\n\nError while deserializing header: header too large ?",
          "score": 2,
          "created_utc": "2026-01-07 12:38:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz5pzy",
          "author": "Linkpharm2",
          "text": "Minimum vram? I have a 16gb 4080, hopefully that's enough..",
          "score": 1,
          "created_utc": "2026-01-06 08:46:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz7uiq",
              "author": "exomniac",
              "text": "Double that",
              "score": 4,
              "created_utc": "2026-01-06 09:06:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxz8c4k",
              "author": "FinBenton",
              "text": "even 32GB 5090 is kinda pushing it, dual 5090 would be great for this.",
              "score": 1,
              "created_utc": "2026-01-06 09:11:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxz6rh5",
          "author": "Mundane_Existence0",
          "text": "Can LTX do vid2vid?",
          "score": 1,
          "created_utc": "2026-01-06 08:55:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0s53s",
              "author": "singfx",
              "text": "they've just released this as well: [http://reddit.com/r/StableDiffusion/comments/1q5iova/ltx2\\_incontext\\_workflow\\_basically\\_controlnet/](http://reddit.com/r/StableDiffusion/comments/1q5iova/ltx2_incontext_workflow_basically_controlnet/)",
              "score": 1,
              "created_utc": "2026-01-06 15:30:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxz8cs6",
              "author": "Informal_Warning_703",
              "text": "They have a workflow for it here: [https://github.com/Lightricks/ComfyUI-LTXVideo/blob/master/example\\_workflows/LTX-2\\_V2V\\_Detailer.json](https://github.com/Lightricks/ComfyUI-LTXVideo/blob/master/example_workflows/LTX-2_V2V_Detailer.json)",
              "score": 1,
              "created_utc": "2026-01-06 09:11:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxz9hn3",
                  "author": "Mundane_Existence0",
                  "text": "Neat, thanks. Wonder how good it is. Guess will have to wait until it uses less VRAM.",
                  "score": 1,
                  "created_utc": "2026-01-06 09:22:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzeft2",
          "author": "Upper-Reflection7997",
          "text": "Damn.... so will i be able to run any of the models on a 5090 plus 64gb of ddr5 ram? The vram limit is 31.5gb on my pc? Do I need to buy more ram? Also 100gb of storage? Gotta move several old downoaded large models into the my hard drive.  There is pretty brutal ngl for lightricks.",
          "score": 1,
          "created_utc": "2026-01-06 10:09:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzyfpy",
              "author": "Pleasant-Money5481",
              "text": "Acheter de la RAM en ce moment c'est genre sur-c√¥t√© \\^\\^.",
              "score": 1,
              "created_utc": "2026-01-06 12:48:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2hzod",
                  "author": "No_Mixture_7383",
                  "text": "aqui es puro VRAM no RAM comun",
                  "score": 1,
                  "created_utc": "2026-01-06 20:11:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny1dxkb",
              "author": "No_Mixture_7383",
              "text": "si se puede pero lo ideal seria una RTX 6000 PRO Blackwell o varias de echo",
              "score": 1,
              "created_utc": "2026-01-06 17:10:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2hvpv",
              "author": "No_Mixture_7383",
              "text": "el full solo es para RTX 6000 PRO Blackwell,, pero los otros 3 si los puede",
              "score": 1,
              "created_utc": "2026-01-06 20:10:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxzkcvd",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-06 11:01:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzl3uq",
              "author": "ArkCoon",
              "text": "for some reason ComfyUI straight up doesn't download the latest files from the repo that are required for LTX2 to work. I had to manually download all the files from [this PR](https://github.com/comfyanonymous/ComfyUI/pull/11632/files). Idk why this happens and it's definitely not recommended to manually download stuff but I'm not aware of any other way to get it working. If anyone knows please do let me know",
              "score": 1,
              "created_utc": "2026-01-06 11:08:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny1mllx",
          "author": "No_Mixture_7383",
          "text": "Ayuda  Gemma me sale nodo rojo y no me aparece en instalaciones de nodos en el manager, a alguien le sucedio?",
          "score": 1,
          "created_utc": "2026-01-06 17:49:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2efrz",
          "author": "Wanderson90",
          "text": "Can I use 5070ti and 32gb RAM? üôèüôèüôèüôè",
          "score": 1,
          "created_utc": "2026-01-06 19:54:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2hdwi",
              "author": "No_Mixture_7383",
              "text": "no minimo una 4090 que son las que tienen 24gb VRAM",
              "score": 2,
              "created_utc": "2026-01-06 20:08:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2pfmi",
          "author": "RoboticBreakfast",
          "text": "I've only done a quick look at the workflow, but it seems like it should be possible to use their audio generation for other models (like Wan 2.2). It looks like it just uses the video latents to generate audio, so I'm curious if we could mod this to work with other video models...",
          "score": 1,
          "created_utc": "2026-01-06 20:46:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny327n7",
          "author": "No_Mixture_7383",
          "text": "I updated and in the Template Browser, I navigated to Video and NO LTX-2 template appears.",
          "score": 1,
          "created_utc": "2026-01-06 21:44:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3qoip",
          "author": "blownawayx2",
          "text": "On my 5090, the LTX Enhancer node fails telling me the json files aren‚Äôt where they should be. Are they not supposed to be in the same directory as the text encoder?",
          "score": 1,
          "created_utc": "2026-01-06 23:44:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny6tn8z",
              "author": "No_Comment_Acc",
              "text": "Seems to me that the default workflow folder is: D:\\\\ComfyUI\\\\ComfyUI\\_windows\\_portable\\\\ComfyUI\\\\user\\\\default\\\\workflows",
              "score": 1,
              "created_utc": "2026-01-07 12:33:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3s7gd",
          "author": "Traslogan",
          "text": "There's some kind of issue where comfyUI always find something outdated preventing the use of the GemmaCLIP and audio custom nodes",
          "score": 1,
          "created_utc": "2026-01-06 23:52:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4nm28",
          "author": "merkidemis",
          "text": "What version of ComfyUI is this compatible with? I tried loading the workflows from github and am getting a lot of \"loadWorkflowWarning.outdatedVersion\" errors. The LTXV nodes refuse to load in 0.7.0",
          "score": 1,
          "created_utc": "2026-01-07 02:39:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8d9zb",
              "author": "thatsadsid",
              "text": "Same error... Can't get the nodes tk load",
              "score": 1,
              "created_utc": "2026-01-07 17:16:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny5790y",
          "author": "ExpandYourTribe",
          "text": "Is there any way to randomize the seed so you can batch several to run overnight? I tried setting the RandomNoise node ‚Äúcontrol after generate‚Äù to randomize but it doesn‚Äôt seem to work. I‚Äôm using the T2I ComfyUI default template workflow.",
          "score": 1,
          "created_utc": "2026-01-07 04:34:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny93gdu",
              "author": "RoughPresent9158",
              "text": "yes :) . In the \"Samplers\" subgraph, you can use the last control to switch the mode from 'Fixed' to 'Increment' or 'Randomize.' This effectively changes the seed for the first generation, which is the most critical step.\n\nhttps://preview.redd.it/seiqz5tq7zbg1.png?width=828&format=png&auto=webp&s=df44f22f068d4053209167f9408c79b7e9b822f1",
              "score": 2,
              "created_utc": "2026-01-07 19:10:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny5j6rz",
          "author": "Icy-Cat-2658",
          "text": "Maybe I'm doing something wrong, but this tutorial leaves out how to install the proper node and what the ComfyUI version requirements are.  I've tried the workflows in the linked repo and there's no `ComfyUI-LTXVideo` node that automatically downloads all of the models.",
          "score": 1,
          "created_utc": "2026-01-07 05:57:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny77fap",
          "author": "RetroTy",
          "text": "Thanks for posting this! Is there a workflow for lip‚Äësyncing an audio file with LTX‚Äë2, similar to Infinite Talk?",
          "score": 1,
          "created_utc": "2026-01-07 13:55:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyfv9le",
              "author": "Due-Atmosphere-5653",
              "text": "Did you find anything like this?",
              "score": 1,
              "created_utc": "2026-01-08 18:06:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nygqg11",
                  "author": "RetroTy",
                  "text": "Not yet, but I'm hoping it is just a matter of time before it shows up.",
                  "score": 1,
                  "created_utc": "2026-01-08 20:22:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nydl24h",
          "author": "CompetitionWinter",
          "text": "hello, I see there is a retake tool in ltx2. [https://www.runcomfy.com/models/ltx/ltx-2/retake-video](https://www.runcomfy.com/models/ltx/ltx-2/retake-video) where I can find the worfklow?",
          "score": 1,
          "created_utc": "2026-01-08 10:52:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyejpgv",
          "author": "Ok-Seaweed3286",
          "text": "Super excited! It runs really fast! Will there be a FFLF workflow?",
          "score": 1,
          "created_utc": "2026-01-08 14:32:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyh5i4d",
          "author": "WrongPerformance2936",
          "text": "Qualcuno riesce a farlo funzionare su MacBook Pro M4 Pro? ho 48 gb di ram ma non riesco a farlo funzionare",
          "score": 1,
          "created_utc": "2026-01-08 21:29:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyjqldb",
          "author": "Correct_Ad2989",
          "text": "too much install hassle, i'll wait Comfyui integrates a stable easy workflow in their template list.",
          "score": 1,
          "created_utc": "2026-01-09 05:46:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyk5dfi",
          "author": "LankyAd9481",
          "text": "It just blue screens of death for me yay",
          "score": 1,
          "created_utc": "2026-01-09 07:47:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzd9uq",
          "author": "ImaginationKind9220",
          "text": "Using that much resources for a 5 secs video is not worth it.",
          "score": 1,
          "created_utc": "2026-01-06 09:58:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0f50d",
          "author": "Perfect-Campaign9551",
          "text": "Everyone complaining about the vram requirements this is exactly why we don't get things like Wan 2.5 because a good video model isn't going to run on consumer hardware, face reality bros",
          "score": 0,
          "created_utc": "2026-01-06 14:25:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nya9f30",
              "author": "ReasonableDust8268",
              "text": "Once the GGUF's are out this will run like butter lil bro",
              "score": 1,
              "created_utc": "2026-01-07 22:12:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxz40ah",
          "author": "andy_potato",
          "text": "There is no release version of ComfyUI that supports LTX-2 yet. Using the latest version 0.7.0 the LTX nodes will NOT load.",
          "score": -5,
          "created_utc": "2026-01-06 08:29:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz4vrs",
              "author": "Informal_Warning_703",
              "text": "If you've updated Comfy within the last 2 hours, just use the template workflows.",
              "score": 5,
              "created_utc": "2026-01-06 08:37:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxz6py3",
                  "author": "andy_potato",
                  "text": "Not true if you stick to release versions (as any sane person should)\n\nhttps://preview.redd.it/0r13lcn21pbg1.png?width=241&format=png&auto=webp&s=98a792ef281170e47af7eb0344d7cffa36cf0872",
                  "score": 0,
                  "created_utc": "2026-01-06 08:55:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pyvw0q",
      "title": "Fal has open-sourced Flux2 dev Turbo.",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1pyvw0q/fal_has_opensourced_flux2_dev_turbo/",
      "author": "Budget_Stop9989",
      "created_utc": "2025-12-29 19:38:56",
      "score": 285,
      "num_comments": 116,
      "upvote_ratio": 0.97,
      "text": "https://preview.redd.it/kzd4n7gs37ag1.png?width=903&format=png&auto=webp&s=ab81e3133b7d4a0922d6ebfe03296eb87b30dbeb\n\n[fal/FLUX.2-dev-Turbo ¬∑ Hugging Face](https://huggingface.co/fal/FLUX.2-dev-Turbo)\n\n",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pyvw0q/fal_has_opensourced_flux2_dev_turbo/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "nwlq6j1",
          "author": "jib_reddit",
          "text": "Sub second generation... is that on a B200 or something?",
          "score": 57,
          "created_utc": "2025-12-29 20:03:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm5si9",
              "author": "strigov",
              "text": "Especially when we mention that turbo LoRA itself weights 2.76 Gb... Yeah, it's possible))",
              "score": 7,
              "created_utc": "2025-12-29 21:20:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwllyhe",
          "author": "Budget_Stop9989",
          "text": "https://preview.redd.it/1k9qc2la57ag1.png?width=1622&format=png&auto=webp&s=077b5b27362da79096f8d8d927b259f863096481\n\nIt ranked 8th on Artificial Analysis, beating Nano Banana, and it‚Äôs currently the highest-ranked open-source model.",
          "score": 93,
          "created_utc": "2025-12-29 19:43:32",
          "is_submitter": true,
          "replies": [
            {
              "id": "nwmr19g",
              "author": "Hoodfu",
              "text": "https://preview.redd.it/u512aman58ag1.jpeg?width=1360&format=pjpg&auto=webp&s=18842f870791b976b749b5e06cffff8248031dd9\n\nGiven that it's only 8 steps, it's also crazy good at text. I was expecting it to take a much bigger hit compared to the full model.  prompt: \\*\\*Text-to-Image Prompt:\\*\\*\n\nA 3:4 vertical conspiracy-style infographic poster with light tan paper texture background and subtle grain overlay. Bold black sans-serif typography throughout.\n\n\\*\\*TOP HEADLINE:\\*\\* Giant text reading \"BATMAN IS SECRETLY MARRIED TO A DUMPLING\" in heavy black sans-serif, slightly tilted for dramatic effect.\n\n\\*\\*NODE LAYOUT (Two columns, 6 nodes total):\\*\\*\n\n\\*\\*Node 1 (Top Left):\\*\\* Caption: \"BRUCE WAYNE HAS NEVER BEEN SEEN EATING DUMPLINGS IN PUBLIC\" ‚Äî Flat vector cartoon of Batman looking nervously away from a steaming dim sum basket, sweating, thick outlines, exaggerated guilty expression.\n\n\\*\\*Node 2 (Top Right):\\*\\* Caption: \"THE BATCAVE SUSPICIOUSLY CONTAINS A KITCHEN\" ‚Äî Simple icon of a wok next to bat-shaped cookware, muted sage green accents.\n\n\\*\\*Node 3 (Middle Left):\\*\\* Caption: \"GOTHAM CITY'S CHINATOWN CRIME RATE: MYSTERIOUSLY LOW\" ‚Äî Cartoon of a happy dumpling with a tiny wedding ring, pink pastel background circle.\n\n\\*\\*Node 4 (Middle Right):\\*\\* Caption: \"ALFRED REFUSES TO COMMENT ON 'MRS. WAYNE'\" ‚Äî Flat illustration of a butler figure with finger over lips, charcoal suit, suspicious eyebrow raised.\n\n\\*\\*Node 5 (Lower Left):\\*\\* Caption: \"BATMAN IS FAMOUSLY EMOTIONALLY UNAVAILABLE ‚Äî EXCEPT TO CARBS\" ‚Äî Cartoon Batman tenderly holding a plump dumpling under moonlight, heart icons.\n\n\\*\\*Node 6 (Lower Right):\\*\\* Caption: \"BOTH ARE SOFT ON THE INSIDE, TOUGH ON THE OUTSIDE\" ‚Äî Split comparison icon of Batman cowl and steamed bun, red accent highlighting.\n\n\\*\\*ARROWS:\\*\\* Curved red arrows with hand-drawn aesthetic connecting nodes in illogical zigzag patterns, implying false causation.\n\n\\*\\*BOTTOM BANNER:\\*\\* Bold conclusion banner reading \"THE EVIDENCE IS IRREFUTABLE. WAKE UP, GOTHAM.\" in heavy black text on muted pink ribbon banner.\n\n\\*\\*Style:\\*\\* Flat vector cartoon illustrations, thick black outlines, slight paper grain texture, whimsical children's-book aesthetic with sinister undertones, deadpan comedic tone, pastel red/pink/sage/charcoal accent palette.",
              "score": 46,
              "created_utc": "2025-12-29 23:07:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwmy2iw",
                  "author": "FotografoVirtual",
                  "text": "But it's missing the 'Alfred refuses to comment on Mrs. Wayne' element. Is this LoRA worth it overall? Here's the **Z-Image** generation for comparison (seed=1):\n\nhttps://preview.redd.it/qj9m8e7cc8ag1.png?width=1600&format=png&auto=webp&s=eba150864ff9aa8d00976d97b500c623c21351e4",
                  "score": 16,
                  "created_utc": "2025-12-29 23:46:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwmtex7",
                  "author": "IrisColt",
                  "text": "I kneel",
                  "score": 4,
                  "created_utc": "2025-12-29 23:20:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwlms0i",
              "author": "_raydeStar",
              "text": "Whoah. Have you played with it? How fast is it?",
              "score": 9,
              "created_utc": "2025-12-29 19:47:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwlq2cg",
              "author": "Clear_University5148",
              "text": "Wait, why would it be better than the original flux2 dev if its a distillation?",
              "score": 9,
              "created_utc": "2025-12-29 20:03:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwm8lum",
                  "author": "PuppyGirlEfina",
                  "text": "Turbo models often have better alignment than their base models, which can result in them winning on many benchmarks.",
                  "score": 24,
                  "created_utc": "2025-12-29 21:34:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwm959v",
                  "author": "mcosta85xx",
                  "text": "When the creators of Z-Image state that the base model will have worse quality than the heavily distilled Z-Image-Turbo, then this sounds pretty much the same. \n\nIt depends on the definition of \"better\". It won't do everything better, but if it does the things better you are interested in...",
                  "score": 23,
                  "created_utc": "2025-12-29 21:36:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwmwm19",
                  "author": "ANR2ME",
                  "text": "Distilled usually faster with slightly quality difference, since it use less steps.",
                  "score": 1,
                  "created_utc": "2025-12-29 23:38:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwlqut5",
              "author": "krectus",
              "text": "Seeing as it‚Äôs lower than Flux 2 flex and Flux 2 flex kinda sucks, so I dunno. A good option to have and I‚Äôm sure it does some things well but this leaderboard isn‚Äôt too reliable.",
              "score": 9,
              "created_utc": "2025-12-29 20:07:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwmrnbk",
              "author": "tomakorea",
              "text": "How can it even beat the original flux 2 dev model while being faster ?",
              "score": 1,
              "created_utc": "2025-12-29 23:11:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwllahi",
          "author": "Structure-These",
          "text": "Does it do boobs",
          "score": 119,
          "created_utc": "2025-12-29 19:40:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwllocx",
              "author": "Regular-Forever5876",
              "text": "that's ma' boy",
              "score": 58,
              "created_utc": "2025-12-29 19:42:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwmlgz3",
              "author": "blahblahsnahdah",
              "text": "Appears so (softcore NSFW warning):\n\nhttps://files.catbox.moe/zcgrx0.png\n\n8 steps Euler, 42 seconds on 3090. I'm not a gooner so if you need any further testing you'll need to do it yourself. But yeah, looks like Fal trained it to do booba.",
              "score": 29,
              "created_utc": "2025-12-29 22:38:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwms8jr",
                  "author": "tomakorea",
                  "text": "42 seconds it's not fast but still an improvement I guess",
                  "score": 6,
                  "created_utc": "2025-12-29 23:14:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwp74ho",
                  "author": "zthrx",
                  "text": "Can you share the workflow? so you use 20gig models plus 3gig of lora on top?",
                  "score": 1,
                  "created_utc": "2025-12-30 08:34:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwpqa41",
                  "author": "Hot-Employ-3399",
                  "text": "This is officially great new year present ü•≥",
                  "score": 1,
                  "created_utc": "2025-12-30 11:30:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwmr5cy",
                  "author": "FourtyMichaelMichael",
                  "text": "I thought it would be titties... and you posted mammories.",
                  "score": -6,
                  "created_utc": "2025-12-29 23:08:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwp35h1",
              "author": "JazzlikeLeave5530",
              "text": "Boobs are too easy, people really need to benchmark with dick, which many of the models struggle with unless you use a lora. Not enough cock lovers getting shit done lol semi jokingly but also for real",
              "score": 12,
              "created_utc": "2025-12-30 07:57:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwpid44",
                  "author": "TwistedBrother",
                  "text": "A penis, like a hand, is actually fantastically complex to render. Many different positions, shapes, transformations to consider relative to the stationary skull structure of a face.",
                  "score": 5,
                  "created_utc": "2025-12-30 10:19:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwlosac",
              "author": "Jackster22",
              "text": "WE ABOUT TO FIND OUT",
              "score": 14,
              "created_utc": "2025-12-29 19:57:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwlqcrb",
              "author": "Zenshinn",
              "text": "Asking the real questions.",
              "score": 14,
              "created_utc": "2025-12-29 20:04:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwmns7y",
                  "author": "this_is_a_long_nickn",
                  "text": "It‚Äôs good to see other man of culture gathered here",
                  "score": 4,
                  "created_utc": "2025-12-29 22:50:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwn302i",
              "author": "tppiel",
              "text": "![gif](giphy|SSF70KZ7zatmLLAYxV|downsized)",
              "score": 10,
              "created_utc": "2025-12-30 00:13:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwlnrhf",
          "author": "ArachnidDesperate877",
          "text": "so is this a lora or a distilled model??",
          "score": 10,
          "created_utc": "2025-12-29 19:52:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwlouuf",
              "author": "rendered_lunatic",
              "text": "lora",
              "score": 15,
              "created_utc": "2025-12-29 19:57:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwlq25j",
                  "author": "ArachnidDesperate877",
                  "text": "I don't get it, then why is it ranked 8th on Artificial Analysis???",
                  "score": 18,
                  "created_utc": "2025-12-29 20:03:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwmuvhg",
              "author": "Nextil",
              "text": "Distillation has multiple meanings. With LLMs it typically refers to lower-dimension models trained to mimic a larger one using a teacher-student loop, but with these diffusion models it's usually a LoRA/finetune trained to mimic the effects of CFG and higher step counts, and now it often involves an RL stage to increase preference alignment.\n\nI know FLUX.2 is huge, but I'd rather they keep doing the latter because smaller parameter counts do seem to significantly reduce prompt comprehension and don't necessarily improve the speed, whereas these 4/8-step LoRAs make inference very fast with very little impact on quality when done correctly.",
              "score": 2,
              "created_utc": "2025-12-29 23:28:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwms1it",
          "author": "Frosty-Aside-4616",
          "text": "It‚Äôs a lora so you still need a ton of Vram for the model itself right?",
          "score": 10,
          "created_utc": "2025-12-29 23:13:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwln3tn",
          "author": "HolidayEnjoyer32",
          "text": "24gb vram and 32gb ram enough to run flux 2 dev with this lora?",
          "score": 15,
          "created_utc": "2025-12-29 19:49:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwlo7cm",
              "author": "molbal",
              "text": "Yes, this does not change VRAM requirements",
              "score": 16,
              "created_utc": "2025-12-29 19:54:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwm1gmp",
              "author": "Valuable_Issue_",
              "text": "I can run FP8 on 10GB VRAM 32GB RAM and 54GB pagefile. I switched to Q4KM due to faster loading times and fewer issues with ComfyUI being slow with offloading/loading the text encoder (which somehow got even worse now, even a Z image workflow will randomly slow down).\n\nI ended up making a Diffusers backend for the text encoder based off this https://github.com/ariG23498/custom-inference-endpoint\n\nand running it separately from ComfyUI (still on same PC) and it is much faster at loading and encoding the prompt.\n\n> mistral-text-encoding-api - Loaded Mistral text encoder (6.53s) \n\n>dtype=torch.bfloat16 device=auto\n\n>mistral-text-encoding-api - Loaded tokenizer in 3.23s\n\n>2025-12-29 20:36:32,122 [INFO] mistral-text-encoding-api - \n\n>Warmed up in 28.42s \n\nComfyUI takes FOREVER to load the text encoder/encode prompt, I don't have the GGUF for it downloaded though so can't benchmark it again but here's an older comparison (this is just changing prompt, doesn't include load times which are even worse for comfy):\n\n>mistral-text-encoding-api - Encoded in 18670.10 ms\n\n>20/20 [5.77s/it]\n\n>Prompt executed in 179.45 seconds\n\nVS Normal workflow:\n\n>Prompt executed in 218.38 seconds\n\nAnd when Normal WF decides to offload weirdly:\n\n>Prompt executed in 313.18 seconds\n\nHere's Qwen Edit at Q8 with white image as reference 1024x1024.\n\n> 8/8 [00:55<00:00,  6.92s/it]\n\n> Prompt executed in 58.34 seconds\n\nFlux 2 at Q4KM follows prompts a lot better than Qwen edit at Q8 while being the same size on disk and each step actually taking around the same time, so I'd say it's worth trying over Qwen. Flux 2 Q8 actually takes around the same time per step it's just that the load time was very annoying.\n\nHere's Flux 2 Q4KM with no reference image 1024x1024 (this is ofc 16 steps vs 8 for qwen): \n\n> 16/16 [01:43<00:00,  6.44s/it]\n\n> Prompt executed in 104.61 seconds\n\nWith reference image and step distill lora (reference image slows down gen time a fair bit):\n\n> 8/8 [01:28<00:00, 11.02s/it]\n\n> Prompt executed in 90.54 seconds",
              "score": 15,
              "created_utc": "2025-12-29 20:59:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwm8l5d",
                  "author": "HolidayEnjoyer32",
                  "text": "i just tried flux 2 dev with the default workflow from comfyui (flux 2 dev fp8) and it will not run. just stops right after loading the model and nothing happens. comfyui logs crash.",
                  "score": 3,
                  "created_utc": "2025-12-29 21:34:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwm53tc",
          "author": "Hoodfu",
          "text": "https://preview.redd.it/6ubxjz52p7ag1.jpeg?width=1920&format=pjpg&auto=webp&s=e34f66026d02516051e33412e5cd23943123198d\n\nGood stuff. dpmpp\\_sde / beta / 8 steps / guidance 2.5 - 33 seconds (15 seconds if I use euler a) with flux 2 dev fp16 (90 gigs of vram used for TE and model). Great stuff. Let you iterate at a reasonable clip and then switch to full model for max quality. I tried with flux guidance 4, but then the text is less reliable, so 2.5 is best.",
          "score": 16,
          "created_utc": "2025-12-29 21:17:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwn9ewi",
              "author": "Wallye_Wonder",
              "text": "90gb of VRAM? now I have to buy a pro6000",
              "score": 7,
              "created_utc": "2025-12-30 00:47:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwm3kpy",
          "author": "DullDay6753",
          "text": "anyone got a workflow for this, just adding the lora in a standard flux2 workflow gives bad results",
          "score": 6,
          "created_utc": "2025-12-29 21:09:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm6bs6",
              "author": "Hoodfu",
              "text": "https://preview.redd.it/399rqpd7n7ag1.png?width=3048&format=png&auto=webp&s=144d377a3075290ca5f5b89fa90699f87b9b4dd1\n\nThis is working well for me.",
              "score": 10,
              "created_utc": "2025-12-29 21:23:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwow8dq",
                  "author": "Winter_unmuted",
                  "text": "Are you sure you aren't just seeing flux2dev with fewer steps? \n\nTry feeding all settings except model (without the lora) into another sampler. I did that... and the images were the same. The lora was failing to load because it isn't in the usual format or something.",
                  "score": 3,
                  "created_utc": "2025-12-30 06:55:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwnldcy",
                  "author": "Nextil",
                  "text": "This doesn't follow their recommendations. They use a guidance scale of 2.5 and custom sigmas (1.0, 0.6509, 0.4374, 0.2932, 0.1893, 0.1108, 0.0495, 0.00031).",
                  "score": 5,
                  "created_utc": "2025-12-30 01:54:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwmjte2",
                  "author": "_raydeStar",
                  "text": "Prompt?\n\nI resent that fact that the photo you generated is so fly, yet you did not share it.",
                  "score": 2,
                  "created_utc": "2025-12-29 22:29:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwmv80k",
                  "author": "Sudden_List_2693",
                  "text": "You should set guidance to 2.5.",
                  "score": 1,
                  "created_utc": "2025-12-29 23:30:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwn07tm",
          "author": "NebulaBetter",
          "text": "I got a bunch of \"lora key not loaded: transformer.double\\_stream\\_modulation\\_img.linear.lora\\_A.weight\" etc, etc... seems to not work for me, no idea why (I disabled it for now). I tried different lora loaders, etc.\n\nhttps://preview.redd.it/trxehvope8ag1.png?width=1753&format=png&auto=webp&s=65b3445a764e13802cada560b566e9a77df4e304",
          "score": 5,
          "created_utc": "2025-12-29 23:57:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnndpe",
              "author": "Wurzelrenner",
              "text": "same problem for me",
              "score": 3,
              "created_utc": "2025-12-30 02:05:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwow11p",
              "author": "Winter_unmuted",
              "text": "Yeah same for me. I think it's because it's in Fal's custom lora format. I even tried converting it with [this tool](https://github.com/cutecaption/FAL-converter-script-UI) but no dice. \n\nAt first I thought it was working but just giving garbage results.... but it turns out I was just seeing Flux2 dev with 4 steps. \n\nHopefully someone figures out how to load fal loras into comfyui. until then... shrug.",
              "score": 3,
              "created_utc": "2025-12-30 06:53:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwozqtx",
                  "author": "ByteZSzn",
                  "text": "[https://www.reddit.com/r/StableDiffusion/comments/1pzbrg1/flux2\\_turbo\\_lora\\_corrected\\_comfyui\\_lora\\_keys/](https://www.reddit.com/r/StableDiffusion/comments/1pzbrg1/flux2_turbo_lora_corrected_comfyui_lora_keys/) \n\ni did it here works now :)",
                  "score": 4,
                  "created_utc": "2025-12-30 07:26:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwq4k3m",
              "author": "sntrpc",
              "text": "try just adding this in the .bat file cl launch args ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n    --use-pytorch-cross-attention",
              "score": 1,
              "created_utc": "2025-12-30 13:16:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwls1v3",
          "author": "khronyk",
          "text": ">This model inherits the FLUX [dev] Non-Commercial License from the base model.",
          "score": 15,
          "created_utc": "2025-12-29 20:13:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwn1pkz",
          "author": "andy_potato",
          "text": "\"This model inherits the¬†[FLUX \\[dev\\] Non-Commercial License](https://huggingface.co/black-forest-labs/FLUX.2-dev/blob/main/LICENSE.txt)¬†from the base model\"\n\nInstant skip.",
          "score": 14,
          "created_utc": "2025-12-30 00:06:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnok5f",
              "author": "Winter_unmuted",
              "text": "What are all you people selling with this stuff?\n\nI legitimately don't understand. Are you churning out AI slop internet ads or something?",
              "score": 9,
              "created_utc": "2025-12-30 02:11:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwnsqps",
                  "author": "Serprotease",
                  "text": "IMO, it‚Äôs mostly about control and ownership. ¬†\n\nFor most users, it‚Äôs fine. But if you do Lora it could be. If you‚Äôre doing full fine tune (Rundiffusion, noobAi, etc.) or serve the model then it‚Äôs a non starter.¬†\n\nFor example, it went a bit unnoticed, but stabilityAI used their license rules to pull all models, Lora and fine tunes from Sd cascade to sd 3.5 from civitai.¬†\n\nNon commercial licenses are mostly fine, until they aren‚Äôt.¬†\nThe EU could bring the hammer down and force Bfl to monitor their model usage closely for example and pick and choose where it‚Äôs available (Not where nsfw Lora are available, for an obvious use case)\n\nIn my case, I‚Äôll try this model, but I know that I better spend my time looking at Qwen models, Lora‚Äôs, doc because I know I will not be rugged pull.¬†",
                  "score": 5,
                  "created_utc": "2025-12-30 02:34:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwmrxy2",
          "author": "Revolutionalredstone",
          "text": "Nice - but at this point were all just waiting for zimg base :D",
          "score": 11,
          "created_utc": "2025-12-29 23:12:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlrhru",
          "author": "Valtared",
          "text": "So it's a DMD Lora, what should be the workflow in ComfyUI ?",
          "score": 3,
          "created_utc": "2025-12-29 20:10:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm85fp",
              "author": "Hoodfu",
              "text": "[https://www.reddit.com/r/StableDiffusion/comments/1pyvw0q/comment/nwm6bs6/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/r/StableDiffusion/comments/1pyvw0q/comment/nwm6bs6/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",
              "score": 1,
              "created_utc": "2025-12-29 21:31:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwmsmdy",
          "author": "2legsRises",
          "text": "its the lora not a stand alone checkpoint?",
          "score": 3,
          "created_utc": "2025-12-29 23:16:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwnie26",
          "author": "anydezx",
          "text": "I did some quick tests and I really like this LoRa. It's well-trained and doesn't affect the text or the hands. I can't imagine how long it takes to train, and I'm very grateful to fal-ai. In my opinion, it's one of the best low-steps LoRas (please uses more steps) I've seen, and it gives a boost to this Flux2 Dev model, which many thought was dead. Apologies for not posting examples; I always test things with private projects and I don't have permission to publish them. My only issue's that, in the same amount of time, I can create two images with Qwen Image Edit 2509 or 2511 versus one image with Flux2 Dev under the same conditions, and Qwen Image Edit 2509 maintains better character consistency. 2511 isn't suitable for this. 2511's a disaster at maintaining realistic characters; they ruined it with so much LoRa, but it's better for other uses. Although Flux2 Dev's better for text, posters, anime, and advertising‚Äîand perhaps that's what you need!‚úåÔ∏è",
          "score": 5,
          "created_utc": "2025-12-30 01:38:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwos9ol",
              "author": "Perfect-Campaign9551",
              "text": "Qwen has bad skin textures though",
              "score": 3,
              "created_utc": "2025-12-30 06:22:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwowhbe",
                  "author": "anydezx",
                  "text": "Both Qwen Image Edit 2509 and 2511 and Flux2 Dev're terrible at texturing skin. If you want realistic skin textures, you'll have to refine them afterward with another model; there're many options, so use whichever one you prefer. Even though Qwen Image Edit and Flux2 Dev're large models doesn't mean they can do everything. People don't understand that to achieve that kind of adherency responsiveness and multi-image editing, you have to overtrain something, and in both cases lose skin quality's sacrificed. That's where smaller models shine as refiners. Z Image Turbo's good for many tasks, but in my case, it's a model I don't even use, since for my projects with Qwen, SD XL, some Flux models, WAN 2.2, TTS, some music generators, etc... I use a wide variety of tools, that's more than enough for me. The key's for each user to take advantage of the strengths of each model and use what works best for their needs or projects!üëå",
                  "score": 2,
                  "created_utc": "2025-12-30 06:57:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwnpvkd",
          "author": "Winter_unmuted",
          "text": "EDIT: new comparison with the Comfyui version of the LORA. Now it looks great! slightly more speed per iteration (6..93 s/it base, 6.58 s/it with LORA) plus the expected decrease of time from 8 steps instead of 20. \n\nhttps://preview.redd.it/7w64yac5qcag1.jpeg?width=2048&format=pjpg&auto=webp&s=d36cbf097ebc9a77c9ab93a4dc275277b8d39400\n\n63% faster! 2:18 for the 20 steps vs 0:52 with the Lora.",
          "score": 4,
          "created_utc": "2025-12-30 02:19:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx9nvzl",
              "author": "CA-ChiTown",
              "text": "Quality looks slightly lower with the LoRA",
              "score": 1,
              "created_utc": "2026-01-02 15:38:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxbmuim",
                  "author": "Winter_unmuted",
                  "text": "yeah of course. All turbo loras do that. But you can iterate faster, then remove the lora on the best of your iterations to see how the full model works.",
                  "score": 2,
                  "created_utc": "2026-01-02 21:14:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwoi2pz",
          "author": "suresh_deora_seducer",
          "text": "Look at the size of the model ~64GB , when we have zit and qwen like SOTA models , Who cares.",
          "score": 5,
          "created_utc": "2025-12-30 05:05:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwm9iwd",
          "author": "VegetableRemarkable",
          "text": "Still sticking to ZIT",
          "score": 6,
          "created_utc": "2025-12-29 21:38:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwmjpef",
              "author": "blahblahsnahdah",
              "text": "So?",
              "score": 6,
              "created_utc": "2025-12-29 22:29:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwpxays",
              "author": "Lucas_02",
              "text": "Z-Image turbo with its muddy glossy visual artifacts will never reach the level of details of Flux 2 üòÇ",
              "score": 2,
              "created_utc": "2025-12-30 12:26:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwnp1l6",
              "author": "Sudden_List_2693",
              "text": "Didn't so far, now makes even less sense.  \nThe quality is like SD1.5 compared to ZIT.  \nWell maybe except for \"generate a realistic photo of a Taylor Swift rip-off\"",
              "score": 0,
              "created_utc": "2025-12-30 02:14:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwmr3q5",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2025-12-29 23:08:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwn5mjx",
          "author": "76vangel",
          "text": "Is this yet usable in Comfy? If yes, then how?",
          "score": 1,
          "created_utc": "2025-12-30 00:27:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nws4q6o",
              "author": "Nextil",
              "text": "https://huggingface.co/ByteZSzn/Flux.2-Turbo-ComfyUI/blob/main/Flux2TurboComfyv2.safetensors",
              "score": 1,
              "created_utc": "2025-12-30 19:14:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwng6pl",
          "author": "wh33t",
          "text": "Flux2 Kontext2 Turbo when?",
          "score": 1,
          "created_utc": "2025-12-30 01:25:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwodifn",
          "author": "Antique_Bit_1049",
          "text": "Great. Can't wait to see their training dataset.",
          "score": 1,
          "created_utc": "2025-12-30 04:35:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwoiuhy",
          "author": "yamfun",
          "text": "can this perform Edit ?",
          "score": 1,
          "created_utc": "2025-12-30 05:11:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nws1opv",
              "author": "Brave-Hold-9389",
              "text": "Yes",
              "score": 1,
              "created_utc": "2025-12-30 19:00:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwp8ghl",
          "author": "unarmedsandwich",
          "text": "How does it compare to 4 step pi-flux2?\nhttps://huggingface.co/Lakonik/pi-FLUX.2",
          "score": 1,
          "created_utc": "2025-12-30 08:47:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwql66z",
          "author": "AlexGSquadron",
          "text": "I am new to this, can anyone tell me how to use this in comfyui?",
          "score": 1,
          "created_utc": "2025-12-30 14:52:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwslyaj",
          "author": "dummyreddituser",
          "text": "I'm experimenting with turbo LoRA, but resulting image after upscaling has grainy appearance.\n\nMy basic workflow (real life workflow, not ComfyUi workflow):\n\nGenerated an image in 1280x720 using Flux2 Dev (gguf Q8\\_0) with turbo LoRA by FAL AI, and upscale it by 3x using SeedVR.\n\nIf I generate an image using Z-Image or Flux2 Dev (gguf Q8\\_0, but without LoRA) with same resolution and SeedVR settings, results are very good.\n\nI tried changing prompt guidance and model sampling (ModelAuraFlow node, if I remember right) but up to now, no way to elliminate this effect completely.\n\nIt seems like all images generated by this LoRA are grainy, and this effect will be amplified by SeedVR.\n\nI like the results of this LoRA, but with this problem, this is only useful to preview things before generating them in Flux 2 Dev full model.\n\n  \nIs it only me?",
          "score": 1,
          "created_utc": "2025-12-30 20:37:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpe9rb",
          "author": "Kooky-Menu-2680",
          "text": "Thanx to Z image ü§£ü§£",
          "score": 1,
          "created_utc": "2025-12-30 09:41:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlsyzu",
          "author": "Anxious-Program-1940",
          "text": "![gif](giphy|BWPQlW8R5Muuk)",
          "score": -8,
          "created_utc": "2025-12-29 20:17:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwls2af",
          "author": "Fantastic_Tip3782",
          "text": "Wow it still looks like shit even in open-source mode!",
          "score": -13,
          "created_utc": "2025-12-29 20:13:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwlw17p",
              "author": "anybunnywww",
              "text": "Is there a training code for the adapter and the config? Otherwise, the X post is misleading because there is no open source here. The old tianweiy/dmd2 repo has no up-to-date flux dev support.",
              "score": 2,
              "created_utc": "2025-12-29 20:32:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwlxts8",
                  "author": "Fantastic_Tip3782",
                  "text": "I don't know or care, Flux sucks ass and I'm only here to make that joke",
                  "score": -15,
                  "created_utc": "2025-12-29 20:41:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwlx0vw",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -1,
          "created_utc": "2025-12-29 20:37:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm4q91",
              "author": "LumbarJam",
              "text": "https://preview.redd.it/erh5o58el7ag1.png?width=1665&format=png&auto=webp&s=cbee5509cbbd156ffc4c391ea2294e874cb82967\n\nNo rocket science ... just Flux.2 Dev on the standard workflow, with LORA node.",
              "score": 2,
              "created_utc": "2025-12-29 21:15:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwm96mw",
                  "author": "HolidayEnjoyer32",
                  "text": "just tried the default flux2 dev comfyui workflow and it just doesn't work. model loaded, then nothing happens. so annoying.",
                  "score": 2,
                  "created_utc": "2025-12-29 21:36:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwlnwlu",
          "author": "Verittan",
          "text": "The only thing I hear about Flux is Flux chin and plastic skin. Is this an issue with dev Turbo or has it been fixed?",
          "score": -6,
          "created_utc": "2025-12-29 19:52:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwltxtf",
              "author": "Dezordan",
              "text": "Flux 2 still kind of has a plastic skin, but better than Flux 1 Dev (not sure about Krea version). You are better off using LoRAs with it anyway. As for chin, they fixed it as far as I can see.",
              "score": 3,
              "created_utc": "2025-12-29 20:22:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwlp5ya",
              "author": "lordpuddingcup",
              "text": "That was flux 1 flux 2 is better I think",
              "score": 3,
              "created_utc": "2025-12-29 19:59:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwp19ks",
          "author": "Xamanthas",
          "text": "Open-weights* and adapter not a full on its own model. Open sourced would be data and training code",
          "score": -2,
          "created_utc": "2025-12-30 07:40:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pxp309",
      "title": "WAN2.1 SCAIL pose transfer test",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/k095n4prix9g1",
      "author": "Aneel-Ramanath",
      "created_utc": "2025-12-28 11:20:59",
      "score": 283,
      "num_comments": 54,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Animation - Video",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pxp309/wan21_scail_pose_transfer_test/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwddzn2",
          "author": "DeliciousGorilla",
          "text": "![gif](giphy|14kqI3Y4urS3rG)\n\nThese dancing videos remind me of the OG CG baby.",
          "score": 47,
          "created_utc": "2025-12-28 15:01:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nweerpu",
              "author": "Dzugavili",
              "text": "Someone needs to go full circle and use this as a WAN driving video.",
              "score": 11,
              "created_utc": "2025-12-28 18:07:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwg8e8c",
                  "author": "Zenshinn",
                  "text": "https://i.redd.it/lkm1umox41ag1.gif",
                  "score": 17,
                  "created_utc": "2025-12-28 23:30:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwd5fs2",
          "author": "andy_potato",
          "text": "For me 600 frames at 576p take about 30 minutes on a 4090",
          "score": 12,
          "created_utc": "2025-12-28 14:10:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwf3plg",
              "author": "RepresentativeRude63",
              "text": "16fps or 24 fps? If 16, classic 1 min for every second video. My best results are like that too. Wish I found a way to 1 min for every 5-10 seconds than I would go all the way to opensource",
              "score": 2,
              "created_utc": "2025-12-28 20:05:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwgef2e",
                  "author": "andy_potato",
                  "text": "the FPS have no impact on the rendering time. That's just how you encode your video at the end. The important point is the number of frames (600).",
                  "score": 2,
                  "created_utc": "2025-12-29 00:02:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwifs0a",
              "author": "donkeykong917",
              "text": "How did you get it to 600 frames?\n\nMax I can is around 410 frames. \n\nLet me check my resolution.",
              "score": 1,
              "created_utc": "2025-12-29 08:01:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwik2jm",
                  "author": "andy_potato",
                  "text": "I don‚Äôt think there is a frame limit, you just need enough frames to drive the motion.\n\nMy original video is 40 seconds at 30fps means a total of 1,200 frames. I skip every other frame resulting in 600 frames actually rendered by SCAIL. Finally I interpolate the video back to 30fps and upscale it from 576p to 720p. Works without problems, just the whole process is much slower than SteadyDancer. Quality is on another level though",
                  "score": 2,
                  "created_utc": "2025-12-29 08:41:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwjr3wb",
              "author": "music2169",
              "text": "Without using context windows or with it?",
              "score": 1,
              "created_utc": "2025-12-29 14:21:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwjrftg",
                  "author": "andy_potato",
                  "text": "Using a context window of 12 or so. Didn‚Äôt change the default settings of the Kijai workflow here",
                  "score": 1,
                  "created_utc": "2025-12-29 14:23:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwdfjco",
              "author": "FightingBlaze77",
              "text": "How long would you think it would take on a 4070?",
              "score": 1,
              "created_utc": "2025-12-28 15:10:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwgeqqp",
                  "author": "andy_potato",
                  "text": "At least double the time. Depends on whether your 4070 is a 12 or 16 GB variant. I guess SCAIL won't run on 12 GB only, at least not without using a lower quality model.",
                  "score": 3,
                  "created_utc": "2025-12-29 00:04:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwetpl6",
                  "author": "Sagonator",
                  "text": "I mean, the 4070 is around 50% slower so, an hour? Dunno if vram is a part of the equation though.",
                  "score": 2,
                  "created_utc": "2025-12-28 19:17:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nweaq74",
          "author": "Hearcharted",
          "text": "![gif](giphy|eKNrUbDJuFuaQ1A37p)",
          "score": 4,
          "created_utc": "2025-12-28 17:48:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwgqi8m",
              "author": "FetusExplosion",
              "text": "Now let's see Paul Allen's WAN2.1 SCAIL pose transfer test.",
              "score": 4,
              "created_utc": "2025-12-29 01:07:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwdoglh",
          "author": "Exotic_Youth_4696",
          "text": "Can I have that dancing video?",
          "score": 3,
          "created_utc": "2025-12-28 15:57:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwdosgj",
              "author": "Exotic_Youth_4696",
              "text": "found it, Thanks [https://www.youtube.com/shorts/oPQuVb1tahE](https://www.youtube.com/shorts/oPQuVb1tahE)",
              "score": 4,
              "created_utc": "2025-12-28 15:59:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwct0k8",
          "author": "Itchy_Ambassador_515",
          "text": "looks phenominal! which GPU and time it took",
          "score": 6,
          "created_utc": "2025-12-28 12:44:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwh4hdx",
              "author": "Aneel-Ramanath",
              "text": "5090, render time is 1hr:10mins at 512x896 res, about 800 frames",
              "score": 4,
              "created_utc": "2025-12-29 02:27:21",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwdx9ts",
              "author": "Mountain-One-811",
              "text": "they should delete posts without this information, just spam at this point",
              "score": 5,
              "created_utc": "2025-12-28 16:41:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwh4lk4",
                  "author": "Aneel-Ramanath",
                  "text": "chill dude, have some chilled lemon tea to cool your brains.",
                  "score": 2,
                  "created_utc": "2025-12-29 02:28:02",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwfhmk2",
          "author": "Zenshinn",
          "text": "I've been testing it and it has a bunch of issues. Face consistency is the biggest one. Sometimes the background will morph for no reason. And then from time to time limbs will disappear/reappear in a different position.\n\nHopefully the release version will fix these issues.",
          "score": 2,
          "created_utc": "2025-12-28 21:13:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwflqsj",
              "author": "donkeykong917",
              "text": "Face and hands is an issue for sure especially if it isn't in close view but movement wise it's spot on. If it detects more people in open pose it can try to fill itself. \n\nMy solution to faces is put a mask on like so\n\nhttps://youtube.com/shorts/sWzrl5ROwbk?si=NRS8ZOwQVmMqix5c",
              "score": 2,
              "created_utc": "2025-12-28 21:33:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwg8mq2",
                  "author": "Segaiai",
                  "text": "Just to make sure I understand, but are you basically saying to avoid the face issues, one should put a bag over their head? Or do you mean \"mask\" as a technical term?",
                  "score": 2,
                  "created_utc": "2025-12-28 23:31:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwgxhtd",
                  "author": "andy_potato",
                  "text": "You don‚Äôt have to mask or brownbag the faces. Just don‚Äôt include them in your DWPose output. The Kijai workflow has a switch for that",
                  "score": 1,
                  "created_utc": "2025-12-29 01:47:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwdf33w",
          "author": "sukebe7",
          "text": "Black Panthers promotional video?",
          "score": 1,
          "created_utc": "2025-12-28 15:07:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwg2m6c",
          "author": "IrisColt",
          "text": "It looks like the same panther head was blatantly photoshopped into the image three times.",
          "score": 1,
          "created_utc": "2025-12-28 22:59:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkrx0d",
          "author": "Neighborhood-Brief",
          "text": "Does anyone know what can cause unwanted camera moves that are not in the motion clip?  \nIve been playing with this in the last couple of days and often when I push the resolution a to 1280x736 I get strong camera dolly/push-in's.  \nI even have a separate clip with still camera just playing a checker board still frame for the duration and feeding in through Uni3C.  \nStill I get the move. I think its from some resolution mismatch maybe as when I go down to the regular max res the camera move is not there.  Any ideas what could make it happen like that?",
          "score": 1,
          "created_utc": "2025-12-29 17:23:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwto500",
          "author": "M_4342",
          "text": "will this work with 5060 ti 16gb for short clips, 5 sec ? and what times can i expect.\n\n  \nCan some also share a tutorial or where I can try this ? thanks",
          "score": 1,
          "created_utc": "2025-12-30 23:48:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwue62y",
              "author": "Aneel-Ramanath",
              "text": "I've not tried these on a 5060, so I cannot answer that question, these GPU's do not scale linearly, so it's difficult to predict, it all depends on the resolution and frame range, but yeah, you should be able to run them with the fp8 model. just search for WAN2.1 SCAIL on YT, you will get loads of tutorials.",
              "score": 1,
              "created_utc": "2025-12-31 02:14:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nweehzx",
          "author": "One-Employment3759",
          "text": "Why are they wearing heels.\n\n\nDid you prompt it, or is just because of if too many bops in training data?",
          "score": 1,
          "created_utc": "2025-12-28 18:06:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwguax7",
              "author": "CapsAdmin",
              "text": "I think it's an asian male celebrity thing.",
              "score": 1,
              "created_utc": "2025-12-29 01:28:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwh566u",
              "author": "Aneel-Ramanath",
              "text": "the SACIL model only animated, it does not create the images, the reference image is created in Nano Banana, maybe the word fashion has added those heels to them , not sure.",
              "score": 1,
              "created_utc": "2025-12-29 02:31:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pyrfro",
      "title": "I made Soprano-80M: Stream ultra-realistic TTS in <15ms, up to 2000x realtime, and <1 GB VRAM, released under Apache 2.0!",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/5f12axpt86ag1",
      "author": "eugenekwek",
      "created_utc": "2025-12-29 16:56:08",
      "score": 281,
      "num_comments": 60,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pyrfro/i_made_soprano80m_stream_ultrarealistic_tts_in/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwlo6cg",
          "author": "harderisbetter",
          "text": "this is awesome, thanks!!  any plans for voice cloning and comfy implementation?",
          "score": 16,
          "created_utc": "2025-12-29 19:54:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwo01fx",
              "author": "eugenekwek",
              "text": "Unfortunately, I'm not very familiar with comfy, but I'd appreciate any community support on this! As for voice cloning, this is planned for a future release, so stay tuned!",
              "score": 6,
              "created_utc": "2025-12-30 03:14:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwl6ql3",
          "author": "urekmazino_0",
          "text": "Can you train any language?",
          "score": 9,
          "created_utc": "2025-12-29 18:32:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnvykn",
              "author": "eugenekwek",
              "text": "Not for right now. I know this is the most popular feature everyone has been asking for though, so I'm going to post the training code soon!",
              "score": 4,
              "created_utc": "2025-12-30 02:52:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwoigz0",
                  "author": "SpaceNinjaDino",
                  "text": "I would love if other languages worked like LoRAs to not bloat or skew the English core. Or have a separate international model. \n\nThe more requested feature is actually multi speaker and emotion weight triggers.",
                  "score": 2,
                  "created_utc": "2025-12-30 05:08:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwoem21",
                  "author": "tonyhart7",
                  "text": "I love to clone myself",
                  "score": 1,
                  "created_utc": "2025-12-30 04:42:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwmvrqw",
              "author": "tomakorea",
              "text": "Best question",
              "score": 1,
              "created_utc": "2025-12-29 23:33:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwlfhza",
          "author": "rinkusonic",
          "text": "i hope the word gabagool is generated every 3 sentences.",
          "score": 17,
          "created_utc": "2025-12-29 19:12:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnxt9q",
              "author": "eugenekwek",
              "text": "Gabagool? Ova here!",
              "score": 5,
              "created_utc": "2025-12-30 03:02:16",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwmv79m",
              "author": "ArtfulGenie69",
              "text": "Yeah but at a high pitch than the mobsters baritone voices haha",
              "score": -1,
              "created_utc": "2025-12-29 23:30:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwku45r",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 7,
          "created_utc": "2025-12-29 17:34:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnv6rf",
              "author": "eugenekwek",
              "text": "I'm not familiar with KoboldCPP, but all the components in Soprano follow standard architectures, so I believe it shouldn't be too difficult!",
              "score": 3,
              "created_utc": "2025-12-30 02:47:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nworvhe",
          "author": "SanDiegoDude",
          "text": "/u/eugenekwek FYI, I made a comfyUI node for your model: https://github.com/SanDiegoDude/ComfyUI-Soprano-TTS/tree/main\n\nI had to monkeypatch around lmdeploy to use transformers instead for comfy compatibility. not quite as fast as your native build (but still stupid fast). For folks who want to try it, read the readme, don't try to install it in the manager (it won't work that way).",
          "score": 7,
          "created_utc": "2025-12-30 06:19:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtxiyc",
              "author": "harderisbetter",
              "text": "Is there a sample voice file in the deployed node that perhaps can be replaced with a different sample and then that way you can get voice cloning? or some other hack? thanks!!!",
              "score": 2,
              "created_utc": "2025-12-31 00:39:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwlvc7n",
          "author": "RepresentativeRude63",
          "text": "For voice clone searchers use rvc. Fast generate with this feed to rvc to change voice rvc is super fast too ü´°",
          "score": 8,
          "created_utc": "2025-12-29 20:29:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwo1er6",
              "author": "eugenekwek",
              "text": "Yeah, you can combine Soprano with RVC as a temporary solution for voice cloning. In the future, I'm planning to add native voice cloning support, so RVC won't be needed anymore.",
              "score": 5,
              "created_utc": "2025-12-30 03:22:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwp0prl",
                  "author": "LevelStill5406",
                  "text": "how does this work? do i create a voice model with RVC that I can use in Soprano?\n\nWith how good Soprano sounds, i might want to use it in my app immediately, though i want to use my own voices.",
                  "score": 1,
                  "created_utc": "2025-12-30 07:35:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwmz1d6",
              "author": "diogodiogogod",
              "text": "you can use chatterbox or cosy voice 3 VC as well. RVC needs training on the target voice.   \n  \nedit: But... if you are going to use chatterbox or cozy, makes no sense to use them as a second step instead of generating TTS directly... since what you want is speed with this new soprano model, then for speed RVC is the real choice, yes.",
              "score": 1,
              "created_utc": "2025-12-29 23:51:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwomc3b",
                  "author": "RepresentativeRude63",
                  "text": "Plus there is a huge repo for rvc models ;)",
                  "score": 1,
                  "created_utc": "2025-12-30 05:36:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwltbyo",
          "author": "Dogluvr2905",
          "text": "very nice...clean, crisp, and fast.  If it's possible to train / clone voices...it'd be amazing.",
          "score": 5,
          "created_utc": "2025-12-29 20:19:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwo1qwj",
              "author": "eugenekwek",
              "text": "Thank you! Voice cloning is in the works!",
              "score": 2,
              "created_utc": "2025-12-30 03:24:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwn1kv1",
          "author": "HerculeTheChamp",
          "text": "That Soprano, never had the makings of a varsity LLM",
          "score": 3,
          "created_utc": "2025-12-30 00:05:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpgk85",
          "author": "Successful_Potato137",
          "text": "For everyone who wants to test it locally there is a PR with the code to launch a gradio server:\n\n[https://github.com/ekwek1/soprano/pull/10/commits/a11bdd4782df44ad3346eb15ec264f1fe4db14db](https://github.com/ekwek1/soprano/pull/10/commits/a11bdd4782df44ad3346eb15ec264f1fe4db14db)\n\nAbolutely insane the speed of this TTS.  Congratulations.",
          "score": 5,
          "created_utc": "2025-12-30 10:02:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkyxiq",
          "author": "Incognit0ErgoSum",
          "text": "Impressive!",
          "score": 3,
          "created_utc": "2025-12-29 17:56:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwo1gpj",
              "author": "eugenekwek",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2025-12-30 03:22:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwl8w4u",
          "author": "Tystros",
          "text": "can it run in realtime on one CPU thread?",
          "score": 2,
          "created_utc": "2025-12-29 18:41:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnzkww",
              "author": "eugenekwek",
              "text": "Theoretically yes, but it's not currently implemented. I do have plans for realtime CPU streaming though!",
              "score": 2,
              "created_utc": "2025-12-30 03:12:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwnzt99",
                  "author": "Tystros",
                  "text": "a simple stand-alone native cpu library would be great. something that could easily be used by other software, without requiring any python dependencies etc",
                  "score": 2,
                  "created_utc": "2025-12-30 03:13:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwnw8ra",
          "author": "Underrated_Mastermnd",
          "text": "THAT SOUNDS REALLY GOOD! It doesn't sound unintentionally robotic. The cadence of the speech sounds normal  and inflections when speaking at the end of each sentence or giving emotion sounds like an average person. Better than most TTS and video gen models. Are there instructions to voice clone?",
          "score": 2,
          "created_utc": "2025-12-30 02:53:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwo23cb",
              "author": "eugenekwek",
              "text": "Thank you! It's currently a single-speaker model, but native voice cloning is planned in the future!",
              "score": 1,
              "created_utc": "2025-12-30 03:26:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwnzq24",
          "author": "EndlessZone123",
          "text": "If I can finetune on my own datasets that would make me instantly switch.",
          "score": 2,
          "created_utc": "2025-12-30 03:13:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwo26uh",
              "author": "eugenekwek",
              "text": "Training support is one of the most requested features, so I will be releasing the training code soon!",
              "score": 2,
              "created_utc": "2025-12-30 03:27:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwoe9lw",
          "author": "inaem",
          "text": "I saw it on hf and was disappointed to see no training, looking forward to the training code \n\nPlease don‚Äôt disappear on us like the others",
          "score": 2,
          "created_utc": "2025-12-30 04:40:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlo2xz",
          "author": "skyrimer3d",
          "text": "mandatory ConfyWhen?",
          "score": 1,
          "created_utc": "2025-12-29 19:53:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwls0tj",
          "author": "xb1n0ry",
          "text": "I just lost my shit when I generated this in the demo\nMeeeeeeeeeeeeeeoooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooowwwwwwwwww",
          "score": 2,
          "created_utc": "2025-12-29 20:13:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwz6prv",
              "author": "SpaceNinjaDino",
              "text": "Yeah, this seems to easily go off the robot rails even with \"Hey Hello, this is a test.\"",
              "score": 1,
              "created_utc": "2025-12-31 20:59:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwmw8up",
          "author": "ArtfulGenie69",
          "text": "Do you think you can release a training script for it? It's so small it would be nice to have some specific trained voices or try to make it handle longer readings.¬†",
          "score": 1,
          "created_utc": "2025-12-29 23:36:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwnvl5n",
          "author": "Cultured_Alien",
          "text": "Running this on zero GPU is pretty much overkill. I'm interested in cpu performance.",
          "score": 1,
          "created_utc": "2025-12-30 02:50:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnwn60",
              "author": "eugenekwek",
              "text": "Yeah it probably is lol, but it's also the only free GPU on Spaces, so I just decided to go for it. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø",
              "score": 2,
              "created_utc": "2025-12-30 02:55:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpv53c",
          "author": "Odd-Mirror-2412",
          "text": "Great start! I'll wait for the update.",
          "score": 1,
          "created_utc": "2025-12-30 12:10:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwrpx69",
          "author": "Motorola68020",
          "text": "‚ÄúSoprano automatically generates each sentence independently, and then stitches the results together.‚Äù\n\nThis results in fairly robotic speech no? Each sentence is unaware of previous sentences?",
          "score": 1,
          "created_utc": "2025-12-30 18:06:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwsqaby",
          "author": "Wevvie",
          "text": "Is there API support for front ends like SillyTavern? I'd love to run a fast, high-quality local narrator for my RPGs.",
          "score": 1,
          "created_utc": "2025-12-30 20:58:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwta2yl",
          "author": "mitchins-au",
          "text": "Wow a TTS with code and weights available on announcement! Thanks OP",
          "score": 1,
          "created_utc": "2025-12-30 22:32:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwuuefb",
          "author": "Grindora",
          "text": "How to install this on windows pls? Does it have gradio ui?",
          "score": 1,
          "created_utc": "2025-12-31 03:51:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvgwug",
          "author": "Eraxor",
          "text": "Can I run this with Blackwell cards as well? I get issues with torch and cuda :/",
          "score": 1,
          "created_utc": "2025-12-31 06:32:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx9be9g",
          "author": "St_Mim",
          "text": "It is really good! Yes sometimes she starts singing but she is a soprano so it is expected‚Ä¶ jokes aside, thank you for sharing it!",
          "score": 1,
          "created_utc": "2026-01-02 14:33:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlcgx0",
          "author": "foxdit",
          "text": "Seems (and SOUNDS) great! Would love to see a ComfyUI integration.",
          "score": 1,
          "created_utc": "2025-12-29 18:58:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwoofvw",
              "author": "JoNike",
              "text": "I asked Opus 4.5 to take a stab at it, if you're so incline as to give it a try. https://github.com/jo-nike/ComfyUI-SopranoTTS\n\nTho you should probably install via git and not via the manager, not sure it's fully working there yet (never published a node before)\n\nhttps://i.imgur.com/C6VymlV.png",
              "score": 2,
              "created_utc": "2025-12-30 05:51:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwosqko",
                  "author": "foxdit",
                  "text": "Oh holy wow! I will give it a try! Thank you!",
                  "score": 1,
                  "created_utc": "2025-12-30 06:26:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwo1o9e",
              "author": "eugenekwek",
              "text": "Thank you, I would love to see this too! Unfortunately, I don't know ComfyUI well, so I can't implement this myself, but hopefully somebody in the community can. :)",
              "score": 1,
              "created_utc": "2025-12-30 03:24:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwlyumi",
          "author": "Fantastic_Tip3782",
          "text": "Needs Kobold/ST integration stat!",
          "score": -1,
          "created_utc": "2025-12-29 20:46:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmsi3e",
          "author": "MasqueradeDark",
          "text": "Awesome work, mate! The big question however with every single new TTS always is predominently - is it trainable to other languages than English. Because if the answer is yes, congrats! You just made a terrific homerun! If the answer is no, then congrats again! You did well, but probably won't take off like other 100000 super fast TTS's (even though, not fast as yours)",
          "score": 0,
          "created_utc": "2025-12-29 23:15:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwp01p2",
          "author": "nntb",
          "text": "sounds... tin like...",
          "score": 0,
          "created_utc": "2025-12-30 07:29:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr3arh",
              "author": "DelinquentTuna",
              "text": "The groxaxo fork adds a FlashSR process that doesn't add too much latency but does open up the frequency range a bit.",
              "score": 1,
              "created_utc": "2025-12-30 16:21:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwp8lbw",
          "author": "Zokenista",
          "text": "Bro this is Sickk, i was looking for this kinda model",
          "score": 0,
          "created_utc": "2025-12-30 08:48:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwm52vf",
          "author": "-becausereasons-",
          "text": "Genuinely a great sounding model! Is there a Comfy node? :p",
          "score": -1,
          "created_utc": "2025-12-29 21:17:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q3jqzc",
      "title": "Chroma Radiance is a Hidden Gem",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1q3jqzc",
      "author": "FortranUA",
      "created_utc": "2026-01-04 07:29:33",
      "score": 270,
      "num_comments": 89,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q3jqzc/chroma_radiance_is_a_hidden_gem/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nxl88qf",
          "author": "FortranUA",
          "text": "https://preview.redd.it/21e9lyxvcabg1.png?width=1152&format=png&auto=webp&s=13c9933b8ebd9734b8f0fa2fba0866b575b69f1b\n\nbonus",
          "score": 59,
          "created_utc": "2026-01-04 07:34:48",
          "is_submitter": true,
          "replies": [
            {
              "id": "nxlhalb",
              "author": "mission_tiefsee",
              "text": "they have big hands. Or the gpu is really small ;)\n\nedit: changed second mentioning of hands to gpu. I was still sleepy before...",
              "score": -4,
              "created_utc": "2026-01-04 08:56:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxm5evj",
                  "author": "Occsan",
                  "text": "I think your joke missed the target GPU.",
                  "score": 8,
                  "created_utc": "2026-01-04 12:27:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxlcxtw",
          "author": "physalisx",
          "text": "Are you talking about the regular Radiance or the newer x0 strain?\n\nThe x0 is interesting on its own as well, the level of realistic detail is absolutely insane, beats everything else, but coherence seems to be broken pretty badly, so you'll get a lot of body horror etc. I really hope they'll be able to fix that.",
          "score": 11,
          "created_utc": "2026-01-04 08:16:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxm08lp",
              "author": "FortranUA",
              "text": "Not sure about body horror, because hard poses that Zit, for example, can't generate, x0 is generating without any problem",
              "score": 8,
              "created_utc": "2026-01-04 11:45:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxm1e2t",
                  "author": "physalisx",
                  "text": "I had run some prompts that came out fine in Chroma HD and older versions of Chroma, and they were unusable in x0. Specifically with multiple subjects involved and more complex poses. I also remember seeing in lodestones discord people talking about this, I don't think it's just me. But I will maybe try your sampler settings etc to see if it helps.",
                  "score": 3,
                  "created_utc": "2026-01-04 11:55:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxn1is0",
              "author": "red__dragon",
              "text": "I think this is where I fall off in following Radiance. What is regular vs x0 here, and why is one being favored over the other?",
              "score": 7,
              "created_utc": "2026-01-04 15:39:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxopa3m",
                  "author": "physalisx",
                  "text": "I don't know much about it either, from what I gather x0 a different training methodology that lodestone is favoring now, they're also applying it to the new z-image based model they're training.",
                  "score": 2,
                  "created_utc": "2026-01-04 20:10:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxnse6r",
              "author": "_half_real_",
              "text": "I wonder how it would work as a refiner, although it might be a bit slow for that.",
              "score": 1,
              "created_utc": "2026-01-04 17:44:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxpoy5r",
          "author": "NineThreeTilNow",
          "text": "People have long trashed Chroma as a model, but in terms of uncensored gore and violence, it does it all. \n\nFrom there you have an actual base to use first image last image to make some crazy videos in Wan. \n\nThe model is good at more stuff than nudity. That's just the reason it's known. It will handle really good horror stuff that's very NSFW in design and Wan will do a decent job animating. \n\nI haven't tested prompting Radiance but the Flux Chroma is pretty good if prompted correctly.",
          "score": 9,
          "created_utc": "2026-01-04 22:56:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxlgkpj",
          "author": "Umbaretz",
          "text": "Would be cool to see a comparison with regular chroma.",
          "score": 9,
          "created_utc": "2026-01-04 08:49:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxmkc02",
          "author": "martinerous",
          "text": "Have you tried also Uncanny Photorealism Chroma finetune? It's quite impressive for some cases. [https://civitai.com/models/2086389/uncanny-photorealism-chroma](https://civitai.com/models/2086389/uncanny-photorealism-chroma)",
          "score": 6,
          "created_utc": "2026-01-04 14:06:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny39fp5",
              "author": "Structure-These",
              "text": "Which cases?  I just cant get chroma to do anything and god it takes forever to generate",
              "score": 1,
              "created_utc": "2026-01-06 22:18:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny3acfi",
                  "author": "martinerous",
                  "text": "I like that finetune particularly for mundane older faces. For example:\n\nhttps://preview.redd.it/ul7ays311tbg1.png?width=1920&format=png&auto=webp&s=728c2c171b4496399cafab10c9056b1e2e844db1",
                  "score": 2,
                  "created_utc": "2026-01-06 22:22:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxlh3do",
          "author": "Major_Specific_23",
          "text": "That's quite a bit of effort to get it to run and it looks the same like your other loras... I don't get what's so special about chroma",
          "score": 14,
          "created_utc": "2026-01-04 08:54:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxm67nq",
              "author": "Lucaspittol",
              "text": "It is more flexible than most things currently available and, unlike Z-Image, it is fully uncensored.",
              "score": 13,
              "created_utc": "2026-01-04 12:34:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxnm769",
                  "author": "SDSunDiego",
                  "text": "Really hoping Z-Image's base model is not as restricted as the turbo mode. Training the de-distilled z-image turbo model on NSFW stuff has really been disappointing.",
                  "score": 1,
                  "created_utc": "2026-01-04 17:15:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxlsg8z",
              "author": "AltruisticList6000",
              "text": "Its prompting support wide variety of prompt styles and concepts that other models don't understand (like ZIT). And no, not just nsfw but regular stuff. I also prefer its textures over ZIT which creates very grainy images (even vector style or anime etc.) and has a weird low gamma/low contrast look that almost always needs post processing nodes to make it work.\n\nBut yeah Chroma's coherency on details is not the best, that's why the flash heun distill loras are there, they speed chroma up and improve details. The details still not always as coherent as ZIT but at least has good creativity and seed variance and way better than SDXL. + It also does native 1080p and other high resolutions with ease, especially with lenovo or other high res trained realism loras.",
              "score": 9,
              "created_utc": "2026-01-04 10:37:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxnvd6x",
                  "author": "a_beautiful_rhind",
                  "text": "haha.. I love the low contrast look because it makes it seem less like AI. I intentionally use cfg normalization nodes to do it to other models. Super high contrast crushes detail and turns images plastic/CGI.",
                  "score": 1,
                  "created_utc": "2026-01-04 17:58:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxqav1w",
              "author": "Hoodfu",
              "text": "Stuff like Zit is still generally doing simple composition and don't adhere much to camera specs or settings. Chroma supports all of that. Camera settings, image composition language, fish eye, depth of field, Dutch angles etc. these new models all have trouble with that stuff and often go with centered subjects and boring images (other than the very high visual fidelity that zit seems to have down )",
              "score": 4,
              "created_utc": "2026-01-05 00:45:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxmav6i",
              "author": "VantomPayne",
              "text": "Chroma is basically pony for flux-adjacent models, if you know you know.",
              "score": 4,
              "created_utc": "2026-01-04 13:07:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxlpc3t",
              "author": "physalisx",
              "text": "It's a porn model, that's what.",
              "score": 5,
              "created_utc": "2026-01-04 10:09:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxm68m7",
                  "author": "Lucaspittol",
                  "text": "\"Porn-capable\".",
                  "score": 11,
                  "created_utc": "2026-01-04 12:34:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxnlkv9",
              "author": "SDSunDiego",
              "text": "Chroma is like SDXL's base model. It basically has zero censorship. There is no other model like it out today besides the original SDXL model. This makes the training really flexible. You can basically train it to do anything. Again, no other model out today has this feature.\n\nBut just like the SDXL base model, it needs finetuning to make it really special. Its hobbyist model in the sense that it needs a lot of work to make it look great. It has some of the best prompting that I've seen for NSFW stuff.\n\nA commenter called it a 'porn model' which describes its capabilities perfectly.\n\nI'm currently using: [https://civitai.com/models/2086389/uncanny-photorealism-chroma](https://civitai.com/models/2086389/uncanny-photorealism-chroma) and doing LoRA trainings.",
              "score": 2,
              "created_utc": "2026-01-04 17:12:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxmcgut",
              "author": "ArmadstheDoom",
              "text": "There's nothing special about it, now that we have Z-Image. Theoretically, it was meant to be a porn capable model, but the reality is that as a base model it's not that great, and the general pitch to the community was 'you can fine tune it yourselves!' Which is a losing proposition in 2025, let alone 2026. It's one thing for a model to be fine-tuneable, it's another for it to be 'you need to do it yourself!' \n\nIt's a very slow model because of its architecture; the reason Flux doesn't use CFG is because having a negative prompt immediately doubles the generation time, and so Chroma being a distillation of Schnell is slower than just using Dev. As a porn model though, you get better stuff with Wan or Qwen, if you want to spend that kind of generation time. \n\nBut Z-Image gave us a faster model that's easier to train on, and when the base model comes out there really will be no point to Chroma as a model. It was an idea, an experiment, but it put paid to the idea that a model can create a fanbase on the back of the idea that people will train it themselves. It needs to be a good model first, and it's just kinda mid. \n\nIt's not that it's a bad model. It's just not that special and we already have faster models of superior or comparable quality that are easier to train. If Civitai adding an option to train loras on its site didn't increase adoption, nothing will.",
              "score": -14,
              "created_utc": "2026-01-04 13:18:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxnmoix",
                  "author": "SDSunDiego",
                  "text": "Z-Image's training for NSFW is absolute trash even when using the de-distilled model. ChromaHD runs circles around Z-Image in this regard. Hopefully the Z-Image's base model is more flexible then the turbo model. Obviously, training a distilled model is not ideal but still.",
                  "score": 4,
                  "created_utc": "2026-01-04 17:17:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxmv4in",
                  "author": "hurrdurrimanaccount",
                  "text": "yeah most of that is simply not true.",
                  "score": 9,
                  "created_utc": "2026-01-04 15:07:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxmuku2",
                  "author": "Nepharios",
                  "text": "I don‚Äôt know why you are being downvoted, that is a pretty accurate summary of how I feel about Chroma since it came out‚Ä¶",
                  "score": -6,
                  "created_utc": "2026-01-04 15:04:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxla9nr",
          "author": "Dulbero",
          "text": "I would love to try it, thing is i already struggle with my 16GB VRAM for this model. I use the Chroma HD FP8 - the small\\_rev3 version from silver. Anything beyond 8-12 steps is just too slow (i use the flash loras too and get mixed results, but most of the time it turns out bad)\n\nI wonder if the prompt adherence of Radiance worth it as you mention, but i might just wait till it is \"officially\" released. There are just too many releases  it's hard to tell if they were just experimenting with something or if the model is \"consumer ready\".",
          "score": 6,
          "created_utc": "2026-01-04 07:52:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxlog1m",
              "author": "luciferianism666",
              "text": "I run Radiance on my 8gb card üòí",
              "score": 7,
              "created_utc": "2026-01-04 10:01:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxm6izz",
              "author": "Lucaspittol",
              "text": "I run non-quantised Chroma1-HD on a 12GB 3060 and generate good images in 8 steps, each taking under a minute. I suppose your 16GB GPU is better than mine.",
              "score": 3,
              "created_utc": "2026-01-04 12:36:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxnbsc3",
                  "author": "AltruisticList6000",
                  "text": "BF16? How much RAM do you have? I have 16gb VRAM and if I do full bf16 chroma I will get an instant crash with OOM so I can only use fp8 or gguf q8. Besides this OOM, fp8 chroma barely worked because the texnt encoder would be loaded in bf16 despite having fp8 TE model, had to use command line flag to force if to load in fp8 and save up RAM.",
                  "score": 1,
                  "created_utc": "2026-01-04 16:28:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxnw2ri",
              "author": "a_beautiful_rhind",
              "text": "https://github.com/feffy380/comfyui-chroma-cache worth a try.",
              "score": 1,
              "created_utc": "2026-01-04 18:01:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxm5vsc",
          "author": "EroticManga",
          "text": "I can find something very last-gen in every one of these images.\n\nCloseups of young women are not a useful model metric. \n\nIf you are talking up a model it's often valuable to attempt the same subject or style in different models and give us a direct comparison.",
          "score": 5,
          "created_utc": "2026-01-04 12:31:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxpy7h9",
              "author": "FortranUA",
              "text": "The portraits are there to demonstrate facial fidelity, but full-body shots are included too.   \nAs for variety, I just started populating my Discord with more examples since I spent most of my time testing the training itself.   \nA direct A/B comparison is tricky because Chroma and Z-image respond to prompts very differently. A prompt optimized for Z-image often produces poor results on Chroma, so a side-by-side comparison wouldn't be entirely fair. Each model has its pros depending on what you're trying to achieve",
              "score": 3,
              "created_utc": "2026-01-04 23:43:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxlgtmh",
          "author": "rinkusonic",
          "text": "This model has been on my mind ever since I first used it. The results were all right but it looked more like cgi than ai. I read up on it a little and from what I could understand, it produces bad results if the prompt relies on the model to fill in all the details. It's Dealing with pixels instead of latents. I tried it again with the improved version but no luck. Need to figure out it's prompt structure.",
          "score": 3,
          "created_utc": "2026-01-04 08:52:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxn3hx3",
              "author": "red__dragon",
              "text": "> it produces bad results if the prompt relies on the model to fill in all the details\n\nI do agree this is both a weakness and a flexibility for the model. It is incredibly uncreative, and at the same time that does let you do more with a prompt than with a model that steers results toward its own bias. It just means that prompts written by yourself will take more time to curate than those written by an LLM or something that can subtly enhance them with extra details. And I tend toward the former myself for more precise control over the prompt anyway.",
              "score": 1,
              "created_utc": "2026-01-04 15:49:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxnacpa",
          "author": "Calm_Mix_3776",
          "text": "These look really nice! I've been putting off trying Chroma Radiance as it was still training last time I checked. How far into the training is it? Your post makes me want to try it out.\n\nI really like your UltraReal LoRAs, especially the GrainScape one. Did train one for Chroma? I'm using the Flux one which seems to work fine with it. Would training one with Chroma yield better results and compatibility?\n\nBTW, not only Chroma Radiance, but Chroma as a family of models are really great, including [HD](https://civitai.com/models/1330309/chroma), and especially the [2K](https://huggingface.co/silveroxides/Chroma-LoRAs/tree/main/2k-test_2025-09-09_22-24-41) version which provides higher fidelity and resolution than HD. Even with the Z-Image hype, my No.1 favorite model at the remains [UnCanny Photorealism](https://civitai.com/models/2086389/uncanny-photorealism-chroma?modelVersionId=2517681), which is one of the best Chroma fine-tunes I've came across. It does wonderful images when coupled with a few LoRAs, one of which being your GrainScape UltraReal LoRA.\n\nOk, I think I'm going to try Radiance now with your new LoRAs. Keep up the awesome work!",
          "score": 3,
          "created_utc": "2026-01-04 16:21:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxrv55x",
          "author": "FlyingAdHominem",
          "text": "Love that you posted this! can't wait for it to go more mainstream.",
          "score": 3,
          "created_utc": "2026-01-05 06:14:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxlhbz5",
          "author": "mission_tiefsee",
          "text": "how is the speed?",
          "score": 2,
          "created_utc": "2026-01-04 08:56:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxm7fet",
              "author": "torac",
              "text": "Takes a lot of steps, making it somewhat slow compared to workflows focused on speed. In the end, it‚Äôs all relative.\n\nThe normal Chroma has Speed LoRas, which make 15-20 steps per gen feasible.\n\nChroma Radiance has no Speed LoRas, afaik. Last I talked to someone, it seems like 40 steps for good generations, though I have no personal experience. Much slower than stuff like z-image-turbo or Qwen with the 4/8-step LoRa, but those are specifically meant for speed.",
              "score": 5,
              "created_utc": "2026-01-04 12:43:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxnc70d",
                  "author": "AltruisticList6000",
                  "text": "Can't Chroma flash loras be used with radiance?",
                  "score": 1,
                  "created_utc": "2026-01-04 16:30:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxlzvzn",
              "author": "FortranUA",
              "text": "I'd say not bad, faster than qwen. With some configs I gen in around 300sec",
              "score": 3,
              "created_utc": "2026-01-04 11:42:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxm63bq",
                  "author": "Abject-Recognition-9",
                  "text": "300 seconds for an image.\nreally ..\nain't no time for this",
                  "score": 9,
                  "created_utc": "2026-01-04 12:33:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxlmlu1",
          "author": "AJent-of-Chaos",
          "text": "I have a 3060 (12 GB VRAM), do you think I can try the FP8 (10.4 GB) model or should I stick to the Q6 (8.2 GB) model? It getting offloaded all the time would be very slow, right?",
          "score": 2,
          "created_utc": "2026-01-04 09:45:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxlq560",
              "author": "Alisomarc",
              "text": "[chroma\\_radiance\\_x0\\_q8.gguf](https://huggingface.co/Danrisi/ChromaRadiance_x0_Latest28.31_GGUF/blob/main/chroma_radiance_x0_q8.gguf)  for sure[](https://huggingface.co/Danrisi/ChromaRadiance_x0_Latest28.31_GGUF/resolve/main/chroma_radiance_x0_q8.gguf?download=true)",
              "score": 3,
              "created_utc": "2026-01-04 10:16:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxm0y51",
              "author": "ImpressiveStorm8914",
              "text": "Using the workflow provided above at default settings (with only a change in Clip/Text Encoder), the Q6 worked for me. Q8 gave me an OOM.",
              "score": 3,
              "created_utc": "2026-01-04 11:51:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxm8306",
                  "author": "AJent-of-Chaos",
                  "text": "Thanks for testing.¬†",
                  "score": 2,
                  "created_utc": "2026-01-04 12:48:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxlpwo9",
              "author": "ImpressiveStorm8914",
              "text": "I'm about to try the Q8 on the same card so I'll let you know how it goes. I'm going to try it in Forge Neo first, then Comfy if that fails.",
              "score": 2,
              "created_utc": "2026-01-04 10:14:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxlrbln",
          "author": "Hearcharted",
          "text": "![gif](giphy|drchHia8J8GmbWjReO)\n\nLOL WTHeck is going on in the 1st IMG üòÇ",
          "score": 2,
          "created_utc": "2026-01-04 10:27:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxnubh7",
          "author": "a_beautiful_rhind",
          "text": ">Lenovo (Realism + Fix files): \n>NiceGirls (Characters): \n\nYea man.. I've been converted. Is radiance slower? Is it better? I run the lenovo lora at 1.0\n\nAm also basing on https://civitai.com/models/2182526/gonzalomo-chroma?modelVersionId=2521239 and applying those 2 lora. \n\n15 steps, dpmpp_2m_alt and bong_tangent. chroma cache .3/1, compiled FP8 and suddenly we have 10s images + no more auto-anime. 6-7s on 3090@ 896x1152.\n\nThere is promise too from https://github.com/silveroxides/ComfyUI-QuantOps\nOnce int8 + triton compiles, that will be better than FP8 on non-fp8 cards. It's GGUF quality but slightly faster kernel. Right now I'm using sage attention since it doesn't compile.\n\nHappy that I stuck with this model instead of giving up on it. NSFW is much better than z-image and prompt understanding beats XL. My speedups cause a little scuff but it's whatever.\n\nOnly changes to comfy code needed to run lora? I can apply flash to it as well?",
          "score": 2,
          "created_utc": "2026-01-04 17:53:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxnyy38",
          "author": "Royal_Carpenter_1338",
          "text": "wow well done danrisi",
          "score": 2,
          "created_utc": "2026-01-04 18:13:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxqb975",
          "author": "Hoodfu",
          "text": "Can you comment on where radiance is compared to chroma as far as training? How early or late in the plan is lodestone with it at this point? With chroma you would see 24 or 48 to mark the iterations. With radiance it's just x0.",
          "score": 2,
          "created_utc": "2026-01-05 00:47:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxr9hp9",
              "author": "FortranUA",
              "text": "I asked Lodestone. He said that will just train x0 more. Imo hard to say where x0 now on 100% progress bar, but i'd say around 70%, cause model feels just a little bit undertrained",
              "score": 2,
              "created_utc": "2026-01-05 03:52:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxrch8i",
                  "author": "Hoodfu",
                  "text": "Very cool, thanks.",
                  "score": 2,
                  "created_utc": "2026-01-05 04:10:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxqtaiq",
          "author": "Majestic_Ratio1681",
          "text": "hey OP. i'm having trouble loading the x0 Radiance model in Flow to try and train a LoRA. did you have to do anything special to get this to work? cheers.\n\nedit: to be specific\n\n    RuntimeError: Error(s) in loading state_dict for Chroma:\n    ¬†¬†¬†¬†¬†¬†¬†Missing key(s) in state_dict: \"img_in.weight\", \"img_in.bias\", \"final_layer.linear.weight\", \"final_layer.linear.bias\". ¬†\n    ¬†¬†¬†¬†¬†¬†¬†Unexpected key(s) in state_dict: \"__32x32__\", \"__x0__\", \"img_in_patch.bias\", \"img_in_patch.weight\", \"nerf_blocks.0.norm.scale\", \"nerf_blocks.0.param_generator.bias\", \"nerf_blocks.0.param_generator.weight\", \"ne\n    rf_blocks.1.norm.scale\", \"nerf_blocks.1.param_generator.bias\", \"nerf_blocks.1.param_generator.weight\", \"nerf_blocks.2.norm.scale\", \"nerf_blocks.2.param_generator.bias\", \"nerf_blocks.2.param_generator.weight\", \"nerf_bl\n    ocks.3.norm.scale\", \"nerf_blocks.3.param_generator.bias\", \"nerf_blocks.3.param_generator.weight\", \"nerf_final_layer_conv.conv.bias\", \"nerf_final_layer_conv.conv.weight\", \"nerf_final_layer_conv.norm.scale\", \"nerf_image\n    _embedder.embedder.0.bias\", \"nerf_image_embedder.embedder.0.weight\".",
          "score": 2,
          "created_utc": "2026-01-05 02:23:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxr93db",
              "author": "FortranUA",
              "text": "did u download weights manually?",
              "score": 2,
              "created_utc": "2026-01-05 03:50:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxrcuc5",
                  "author": "Majestic_Ratio1681",
                  "text": "yes i did, was that a mistake? are you able to clue me in on just rough steps to get up and running w/ a train? i've got a dataset prepared (JSONL file) + training configs (1 based on the current one in master branch, one based on the experimental branch). at the moment i'm getting jammed on what seems to be mismatch between the model arch and the training code's representation of the model, + a few weird things like \"use\\_x0\" not being declared in 'ChromaParams'",
                  "score": 1,
                  "created_utc": "2026-01-05 04:12:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxlewue",
          "author": "Mission_Slice_8538",
          "text": "Nice ? Is it runnable in decent time on a 3070 laptop ? (8GB VRAM)",
          "score": 4,
          "created_utc": "2026-01-04 08:34:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxlurci",
              "author": "PetiteKawa00x",
              "text": "Yes you can with fp8 or gguf.  \nChroma is a fairly slow model, so it depends on what you define by decent time.",
              "score": 5,
              "created_utc": "2026-01-04 10:57:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxlf5sl",
              "author": "HardLejf",
              "text": "No",
              "score": 9,
              "created_utc": "2026-01-04 08:37:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxlcauc",
          "author": "endthissufferingpls",
          "text": "How do you train a LORA on it and then call it in Comfy, so as to always generate consistent characters?\n\nThe difficulty for me using Chroma and Z-Image were the LORAs",
          "score": 2,
          "created_utc": "2026-01-04 08:10:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxm6y61",
              "author": "Lucaspittol",
              "text": "I'm not sure about Radiance, but regular Chroma loras train easily. Most people get bad results because they overdo their ranks or use bad captioning. A typical realistic human character can work at rank 2-4, if it wears some intricate clothing, you can do 8 or 16; 32 or above is a waste of compute, except if your dataset is massive (1000+ images).",
              "score": 3,
              "created_utc": "2026-01-04 12:39:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxliksm",
          "author": "DanzeluS",
          "text": "\nThe model is not very trainable and lacks strong coherence.\nBeing heavily distilled already and operating in pixel space, it suffers from poor scalability, fragile training dynamics, and limited capacity for deep fine-tuning or stylistic abstraction",
          "score": 2,
          "created_utc": "2026-01-04 09:08:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxmvo25",
          "author": "poopoo_fingers",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2026-01-04 15:10:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxmvul3",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 1 day on [**2026-01-05 15:10:18 UTC**](http://www.wolframalpha.com/input/?i=2026-01-05%2015:10:18%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/StableDiffusion/comments/1q3jqzc/chroma_radiance_is_a_hidden_gem/nxmvo25/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FStableDiffusion%2Fcomments%2F1q3jqzc%2Fchroma_radiance_is_a_hidden_gem%2Fnxmvo25%2F%5D%0A%0ARemindMe%21%202026-01-05%2015%3A10%3A18%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201q3jqzc)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-01-04 15:11:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxninxh",
          "author": "silenceimpaired",
          "text": "Interesting ‚Ä¶wonder when it will be done cooking.",
          "score": 1,
          "created_utc": "2026-01-04 16:59:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxnje3m",
          "author": "Redeemed01",
          "text": "So, you can use every chroma lora for it?",
          "score": 1,
          "created_utc": "2026-01-04 17:03:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxpp1sf",
              "author": "FortranUA",
              "text": "If you mean using Chroma HD LoRAs, then no. I've retrained my LoRAs for Radiance now",
              "score": 3,
              "created_utc": "2026-01-04 22:57:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxru2rb",
                  "author": "Redeemed01",
                  "text": "Hm, which trainer did you use for it?",
                  "score": 1,
                  "created_utc": "2026-01-05 06:05:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxroemo",
          "author": "NineThreeTilNow",
          "text": "I wish OneTrainer would build a module to let someone drag and drop the code to train a new set of models without waiting for an update. I much prefer the UI.",
          "score": 1,
          "created_utc": "2026-01-05 05:23:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxrut44",
          "author": "kharzianMain",
          "text": "Chroma always looks great but getting it going and knowing where to get the current files always is confusing. Thanks for the links",
          "score": 1,
          "created_utc": "2026-01-05 06:11:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxujrhk",
          "author": "sarnara2",
          "text": "Hello Danrisi,\n\nI hope you‚Äôre doing well. I‚Äôm writing to ask whether you could further train z image‚Äôs **lenovo\\_z.safetensors** and release it as a **single checkpoint**, similar to your previous **UltraReal Fine-Tune (flux d) fp16**. I really need a consolidated, Danrisi-focused z image model.\n\n**Why I‚Äôm requesting this:**\n\n**1) Speed**  \nModels other than z image take far too long on my setup. I just tested **Danrisi ChromaRadiance**, and it took about **2 hours** to generate one image. The result felt roughly similar to z image for my use, so I prefer z image because it can finish within **\\~4 minutes**.\n\n**2) Stability and convenience**  \nCompared to using LoRAs, an integrated fine-tuned checkpoint feels slightly more stable, and it‚Äôs also much easier than managing multiple LoRAs.\n\n**3) LoRA stacking issues on z image (lenovo + NiceGirls)**  \nWith z image, it‚Äôs difficult to apply both the **lenovo** LoRA and **NiceGirls** LoRA together. If I force both, they often don‚Äôt work properly and I get very noticeable artifacts.  \nIdeally, I would love a fully merged **Z-UltraReal Fine-Tune** that combines **NiceGirls, lenovo, Olympus, 2000s Analog Core**, and other trained LoRAs/checkpoints. But if that‚Äôs too much work, I would still be extremely grateful for at least a **lenovo-integrated** z image checkpoint.\n\n**Additional question:**  \nOn your Hugging Face page ([https://huggingface.co/Danrisi]()), is there a **model card or documentation** for **NiceGirls\\_v2\\_Zimage**? I couldn‚Äôt find any information. I‚Äôve been experimenting with the LoRA, and it‚Äôs fun, but it feels a bit different from your ‚Äú2000s core‚Äù direction. A model card or any explanation (recommended settings, trigger words, example prompts, limitations, etc.) would really help.\n\nThank you for your time, and I‚Äôd appreciate any guidance on whether this is possible.",
          "score": 1,
          "created_utc": "2026-01-05 17:14:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxlencc",
          "author": "Oer1",
          "text": "![gif](giphy|12s2PXFPfJXUcHHjWR|downsized)\n\nThe furry",
          "score": 1,
          "created_utc": "2026-01-04 08:32:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q0jxa1",
      "title": "Z-Image Still Undefeated",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/gp0s02ox1lag1.png",
      "author": "the_bollo",
      "created_utc": "2025-12-31 18:29:10",
      "score": 268,
      "num_comments": 103,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q0jxa1/zimage_still_undefeated/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwzfqk4",
          "author": "beauchomps",
          "text": "My issue with ZIT is it quickly overbakes when you add in Loras",
          "score": 56,
          "created_utc": "2025-12-31 21:48:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx07n78",
              "author": "Dark_Pulse",
              "text": "Part of this may be that we're working on a de-distilled model.\n\nI said back when that stuff came out \"Treat this as temporary, acting like this is the real thing is a bad idea\" and I stand by that.\n\nKeep your datasets, keep your training data, just expect shit will probably overburn and get screwy until we can train against the base model (and the resulting finetunes).",
              "score": 22,
              "created_utc": "2026-01-01 00:33:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx0xpxe",
              "author": "khronyk",
              "text": "This is why so many of us are patiently and excitedly awaiting the base model. The low step count of turbo will be reintroduced using Loras but we will get a model that is extremely fine-tunable without breaking down.",
              "score": 10,
              "created_utc": "2026-01-01 03:23:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwzq6f0",
              "author": "ZootAllures9111",
              "text": "It's a classic problem with inference on distilled models. Flux was also like this.",
              "score": 13,
              "created_utc": "2025-12-31 22:47:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx18zc6",
              "author": "rinkusonic",
              "text": "I started good results after decreasing to lora strength between 0.4 to 0.6.",
              "score": 5,
              "created_utc": "2026-01-01 04:44:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx1icr6",
                  "author": "beauchomps",
                  "text": "Oh yeah definitely I run most of them from .2 to max .6 but if I‚Äôm trying for a consistent character I can‚Äôt really do too much",
                  "score": 2,
                  "created_utc": "2026-01-01 06:03:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx46j9d",
              "author": "pixllvr",
              "text": "I can't remember for the life of me where I found the thread, but I learned that if you set up your loras like this (see attached) it combines loras much much better than if you were to use a LoraStack node or something similar. I posted my workflow yesterday if you wanna try it out [here](https://www.reddit.com/r/StableDiffusion/comments/1q0bvvs/zit_studio_generate_inpaint_detailer_upscale/)\n\nhttps://preview.redd.it/glz2wgh75sag1.png?width=525&format=png&auto=webp&s=18b40ae02919126b863593b8a3164f77d63cae7c",
              "score": 3,
              "created_utc": "2026-01-01 18:21:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwzplkr",
              "author": "Confident_Ad2351",
              "text": "This is a deal breaker for me and why I am still using SDXL because it works reasonably well with LORAs and i have a well established library of them.",
              "score": 12,
              "created_utc": "2025-12-31 22:44:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx21jj8",
              "author": "dobutsu3d",
              "text": "So true, we will need to wait for the next release, even with 2 loras only the degradation is so noticeable. But this model is amazing",
              "score": 2,
              "created_utc": "2026-01-01 09:15:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx3nhf6",
              "author": "Next_Program90",
              "text": "That's my biggest pain with it as well. I tried Adapter 1, 2 & Undistilled... still unhappy. I hope 2512 will finally train better.",
              "score": 2,
              "created_utc": "2026-01-01 16:43:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx0y1e7",
              "author": "pigeon57434",
              "text": "its almost as if its not a base model what a shocker",
              "score": 1,
              "created_utc": "2026-01-01 03:26:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx1ikln",
                  "author": "beauchomps",
                  "text": "Yeah I‚Äôm on the same page there I can‚Äôt wait for the base release",
                  "score": 3,
                  "created_utc": "2026-01-01 06:05:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx083f9",
              "author": "Toby101125",
              "text": "Rocking two loras at 0.5 just fine. Maybe lower the CFG?",
              "score": -7,
              "created_utc": "2026-01-01 00:36:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx1vuis",
                  "author": "PwanaZana",
                  "text": "Isn't the CFG always at 1 because it's distilled?",
                  "score": 4,
                  "created_utc": "2026-01-01 08:14:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx1kmc1",
          "author": "Significant-Baby-690",
          "text": "NSFW is non existent .. but it's unmatched for animals. Tits instead of tits.",
          "score": 13,
          "created_utc": "2026-01-01 06:23:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx32873",
              "author": "AiCocks",
              "text": "in my testing without any Loras Qwen produces way better nipples compared to Zimage",
              "score": 5,
              "created_utc": "2026-01-01 14:43:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx3sy0m",
                  "author": "yaxis50",
                  "text": "How many tests have you performed Dr. Aereola?¬†",
                  "score": 3,
                  "created_utc": "2026-01-01 17:12:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwyl247",
          "author": "MadPelmewka",
          "text": "It‚Äôs been a year since Tongyi said they‚Äôd release the base, edit, and non-turbo checkpoints. Yeah, time to start joking about it - New Year has already passed in China.",
          "score": 69,
          "created_utc": "2025-12-31 19:03:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwz46jr",
              "author": "Wallye_Wonder",
              "text": "But the Chinese new year is still two months away.",
              "score": 53,
              "created_utc": "2025-12-31 20:45:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx07pwo",
          "author": "FlyingAdHominem",
          "text": "Chroma is still my go to. Not as consistently decent as Z but when Chroma gets it it really gets it.",
          "score": 13,
          "created_utc": "2026-01-01 00:33:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx07ut6",
              "author": "the_bollo",
              "text": "I haven't messed with Chroma yet. What's it best for in your opinion?",
              "score": 7,
              "created_utc": "2026-01-01 00:34:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx08ax0",
                  "author": "FlyingAdHominem",
                  "text": "Across the board better in terms of quality, just hard to get it to work, steeper learning curve and it's slower with more misses. Uncanny Checkpoint is good for photorealism.",
                  "score": 6,
                  "created_utc": "2026-01-01 00:37:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx0s791",
              "author": "toothpastespiders",
              "text": "Same here. I really, really, like Z-Image. But at the moment Chroma seems to generally give me better results when I just randomly throw a mess of loras and random ideas at it. Which might not be the typical workflow but I find it fun.",
              "score": 5,
              "created_utc": "2026-01-01 02:46:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx118le",
                  "author": "FlyingAdHominem",
                  "text": "Ditto, and there are so many loras to choose from given that flux loras work decently with Chroma.",
                  "score": 3,
                  "created_utc": "2026-01-01 03:47:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwzudao",
          "author": "SackManFamilyFriend",
          "text": "Nah, stop using turbo Lora and give people more than 10hrs to get the settings down. I'm really enjoying it.",
          "score": 11,
          "created_utc": "2025-12-31 23:12:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx0y6sg",
              "author": "pigeon57434",
              "text": "but its still 20B parameters its WAYYYYYYYYY larger of a model so if its like 1% better then that doesnt really seem worth it to me",
              "score": 5,
              "created_utc": "2026-01-01 03:27:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx275pi",
          "author": "Ken-g6",
          "text": "ZIT got hands, but Wan (as a static image generator) got hands and feet.¬†",
          "score": 4,
          "created_utc": "2026-01-01 10:16:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx27h8r",
              "author": "alb5357",
              "text": "Ya, why don't more folk talk about wan image",
              "score": 3,
              "created_utc": "2026-01-01 10:19:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwzheeg",
          "author": "_VirtualCosmos_",
          "text": "I did some tests with CFG 4 and 50 steps and qwen said on its huggingface and the results are awesome. Extremely detailed images at only 1328x1328, matching not only ZiT but Nanobanana and GPT-Image. But it's slow AF. Now playing with the new Lightning Lora, and the quality downgrades significatively but still a great improvement over the original model.",
          "score": 6,
          "created_utc": "2025-12-31 21:57:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwzs4zo",
              "author": "Comfortable_Aide386",
              "text": "lora 4 steps downgrades¬†veeeeery much the quality.",
              "score": 7,
              "created_utc": "2025-12-31 22:59:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwzugnm",
                  "author": "_VirtualCosmos_",
                  "text": "Yeah, it's like as if the image was rushed xDD",
                  "score": 3,
                  "created_utc": "2025-12-31 23:13:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx14irb",
              "author": "rinkusonic",
              "text": "It's the same with qwen image edit 2511. The original 4 cfg with 20 steps generates the best results. But takes time.",
              "score": 2,
              "created_utc": "2026-01-01 04:10:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx348bg",
              "author": "AiCocks",
              "text": "I trained a low effort auto captioned Lora overnight (12000 steps), and with that Lora I get the same realism I got with CFG 4 and 50 steps at CFG 1 and 8 Steps usind the turbo Lora.",
              "score": 1,
              "created_utc": "2026-01-01 14:56:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx037bd",
          "author": "Big0bjective",
          "text": "Qwen is great at everything what ZIT isn't and vice versa feels like.",
          "score": 3,
          "created_utc": "2026-01-01 00:06:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx33gaz",
          "author": "AiCocks",
          "text": "Qwen Image is actually amazing. The problem is that the results when only using the Turbo Loras are bad. I trained a character Lora overnight (12000 steps) and with that Lora the results are are amazing even when using the turbo Lora.",
          "score": 3,
          "created_utc": "2026-01-01 14:51:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwz7c7q",
          "author": "michael-65536",
          "text": "I think the best thing is a combination of both.\n\nQwen is better for establishing composition and respoding flexibly to complex prompts (and having a name which doesn't sound stupid), zim-t is better for detail, lighting, atmosphere and texture (and not looking stereotypically 2023 AI / cartoony).",
          "score": 6,
          "created_utc": "2025-12-31 21:02:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1ag1h",
          "author": "RayHell666",
          "text": "Tribalism is for dumb people.",
          "score": 5,
          "created_utc": "2026-01-01 04:55:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwzp772",
          "author": "xbobos",
          "text": "**\"Every image model has a plan till they get punched in the mouth\"** \\-- Zimage",
          "score": 5,
          "created_utc": "2025-12-31 22:41:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx28u69",
              "author": "alb5357",
              "text": "What does that mean?",
              "score": 1,
              "created_utc": "2026-01-01 10:33:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwzuhcr",
          "author": "LQCLASHER",
          "text": "Hey I was wondering how to get z image working on my Google android phone my phone is definitely powerful enough to run it.",
          "score": 2,
          "created_utc": "2025-12-31 23:13:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx0455u",
              "author": "HardenMuhPants",
              "text": "Been trying to run it on my apple 1 but it keeps giving me out of money errors.¬†",
              "score": 1,
              "created_utc": "2026-01-01 00:12:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwytsjm",
          "author": "Structure-These",
          "text": "Isn‚Äôt it hard to make assumptions until people learn how to prompt for it",
          "score": 5,
          "created_utc": "2025-12-31 19:48:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwyuxrj",
              "author": "the_bollo",
              "text": "Qwen Image has been out since August (this new release doesn't change prompting). People understand how to prompt it, and it's just natural language prompting anyway.",
              "score": 11,
              "created_utc": "2025-12-31 19:55:02",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwz0sss",
              "author": "CommercialOpening599",
              "text": "That didn't stop Z-Image from being miles ahead from day 1",
              "score": 12,
              "created_utc": "2025-12-31 20:26:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwz13pa",
                  "author": "Structure-These",
                  "text": "Oh I agree I‚Äôm messing with Qwen now and it‚Äôs way too big and so you‚Äôre stuck with a 4 step Lora that is still meh relative to z image",
                  "score": 2,
                  "created_utc": "2025-12-31 20:28:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwzq075",
                  "author": "ZootAllures9111",
                  "text": "Miles ahead at what though? Solo portraits of people? If that sure, if lots of other stuff no, not really, Z prompt adherence falls apart outside the fairly narrow range of content it's specifically meant to be good at.",
                  "score": 4,
                  "created_utc": "2025-12-31 22:46:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwzrxfg",
          "author": "javierthhh",
          "text": "Z-image hyped me up not gonna lie. But the more I play with it the more disappointed I get. Doesn‚Äôt do Loras all that well and combining Loras is almost impossible. NSFW is definitely bad since genitalia is not a thing for Z-image, and the Loras for genitalia have the same problem as other Lora‚Äôs where they override each other. I guess it‚Äôs good for memes of celebrities though.",
          "score": 4,
          "created_utc": "2025-12-31 22:57:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx0alv4",
              "author": "SWAGLORDRTZ",
              "text": "if the specific position of the nsfw composition wise is stable in training data, zit handles it very well",
              "score": 2,
              "created_utc": "2026-01-01 00:51:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx7c2g0",
                  "author": "djtubig-malicex",
                  "text": "Yeh still need better nsfw lora for ZIT. Plenty options for Qwen Image, and kinda wild it even works extremely well with Qwen Image Edit",
                  "score": 1,
                  "created_utc": "2026-01-02 04:57:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx3s9yu",
              "author": "dreamyrhodes",
              "text": "Genitalia can be created with exact description (labia, clitoris, glans etc details). It doesn't reach the quality of SDXL finetunes such as Illustrious tho.",
              "score": 1,
              "created_utc": "2026-01-01 17:09:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwyq2sk",
          "author": "hurrdurrimanaccount",
          "text": "qwen has arguably gotten worse somehow. maybe it's the default comfy workflow but it's just so flux'd and artificial looking. they are straight up lying saying that they made it \"more realistic\". unless they mean oversaturated slop.",
          "score": 5,
          "created_utc": "2025-12-31 19:29:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwztkxv",
              "author": "ChipsAreClips",
              "text": "I think looking at millions of ai pictures messes some with people‚Äôs heads. I know it has with mine. I have gone back and looked at some creations I thought were incredible at the time that now make me ill. I see it in the AI subs and on CivitAI too. I think we all are going to go through a lot of adjustments to our tastes and sense of real",
              "score": 7,
              "created_utc": "2025-12-31 23:08:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx00m3f",
                  "author": "nomorebuttsplz",
                  "text": "every time a new sota model comes out I think \"ok now it's finally perfectly photorealistic.\" But this has been happening every 3-6 months now for a year and a half. SDXL, Flux, Z Image, Qwen, each one I think is perfect but the more I use it the more I see the problems.",
                  "score": 6,
                  "created_utc": "2025-12-31 23:50:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx3sgep",
              "author": "dreamyrhodes",
              "text": "Much slop in the training data. That lowers the quality and removes realistic details.",
              "score": 1,
              "created_utc": "2026-01-01 17:10:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwz7kaz",
              "author": "Hoodfu",
              "text": "https://preview.redd.it/cyyzxa5ktlag1.jpeg?width=3024&format=pjpg&auto=webp&s=16dc90b238c24ddfa1451c590064071f4b8acab3\n\nI'm pretty happy with what I'm getting out of it. Slop is the last word I'd use for it.",
              "score": -11,
              "created_utc": "2025-12-31 21:03:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwz8i91",
                  "author": "nomorebuttsplz",
                  "text": "it's ok but airbrushed looking",
                  "score": 10,
                  "created_utc": "2025-12-31 21:08:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwz8oyp",
                  "author": "the_bollo",
                  "text": "I mean, it's coherent and anatomically correct, but it's nowhere near a realistic depiction.",
                  "score": 6,
                  "created_utc": "2025-12-31 21:09:52",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwz4rx7",
          "author": "Icuras1111",
          "text": "So far I am not seeing anything special from Qwen 2512. \n\nEDIT: I think the fp8 version is not very impressive, very plastic a lot of the time. The bf16 is a lot better.",
          "score": 6,
          "created_utc": "2025-12-31 20:48:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwzqr82",
              "author": "Winter_unmuted",
              "text": "small incremental improvement over the last qwen for certain tasks. \n\nYall spoiled, expecting every model to be a revolutionary change. \n\nAnd this whole weird tribalism thing is getting so tired.\n\n> \"Hey, I got a cool new impact socket wrench set that is great for removing stripped nuts and bolts without much working space\"\n\n ...\n\n> \"Yeah but can it cut these 2x4s nice and clean? No? Bandsaw wins over everything *again!*\"\n\nYou are allowed to like multiple models for different tasks. They aren't rivals for your heart or something.",
              "score": 16,
              "created_utc": "2025-12-31 22:50:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwzsywt",
                  "author": "intermundia",
                  "text": "Exactly. Why are people treating these models like a sports team they need to support for life? Use whatever gets the job done.",
                  "score": 7,
                  "created_utc": "2025-12-31 23:04:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwzc9q4",
          "author": "Guilty_Emergency3603",
          "text": "Maybe on classic 1 Mpx , but sorry Qwen 2512 blows Zit on high res generations > 1.5 Mpx\n\nif not a close-up eyes on zit are messed up when they look still clean on Qwen.",
          "score": 2,
          "created_utc": "2025-12-31 21:29:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwzocig",
          "author": "jigendaisuke81",
          "text": "Qwen would be better staying in its field, superior prompt adherence + working with more complex prompts than zit. I think it was a mistake for them to try to finetune it to compete with ZIT.\n\nA Qwen-Image that just has a lot more knowledge across a lot more areas sounds amazing to me.",
          "score": 3,
          "created_utc": "2025-12-31 22:37:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx00i70",
              "author": "Choowkee",
              "text": "...who said they wanted to compete with ZIT?",
              "score": 3,
              "created_utc": "2025-12-31 23:49:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx042z8",
                  "author": "jigendaisuke81",
                  "text": "The main change they made was directly the thing that ZIT did better than them, which they specifically stated.",
                  "score": 0,
                  "created_utc": "2026-01-01 00:11:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx2a16q",
              "author": "alb5357",
              "text": "Queen was amazing but ugly photorealism, even with loras. \n\nI tried denoising with WAN last steps but that still couldn't cover the qwen ugliness. \n\nI haven't tried this yet, but if it's got Qwen adherence and flexibility + trainability with Z-image aesthetics then it's a beast.",
              "score": 1,
              "created_utc": "2026-01-01 10:46:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx42bau",
              "author": "Ok_Artist_9691",
              "text": "why would qwen try to compete with z-image, aren't they made by the same company (**Alibaba)**?",
              "score": 0,
              "created_utc": "2026-01-01 18:00:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx46jdl",
          "author": "LD2WDavid",
          "text": "Block layering works but this is a distilled model, mind this...",
          "score": 1,
          "created_utc": "2026-01-01 18:21:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1s5hl",
          "author": "yamfun",
          "text": "Still no Edit, useless until they release edit",
          "score": 1,
          "created_utc": "2026-01-01 07:36:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1tglq",
              "author": "sammoga123",
              "text": "I hope it's more worthwhile than Qwen Edit 2511, which really disappointed me considering how long it took to release it.",
              "score": 1,
              "created_utc": "2026-01-01 07:49:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx7ckph",
                  "author": "djtubig-malicex",
                  "text": "I dunno. Qwen Edit 2511 with lightning LoRA and some extras has been amazing compared to Flux Kontext. But I am running on a goddamn M3 Ultra Mac Studio!",
                  "score": 1,
                  "created_utc": "2026-01-02 05:00:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwz0nim",
          "author": "gxmikvid",
          "text": "i'll get crucified but posts like this feel like astroturfing\n\nz-image never worked for me, not the recommended settings, not me messing with it, fucking nothing\n\nmore steps result in saturation issues, less results in lower quality, no middle ground\n\nchanging size gives the model an aneurysm\n\nquen and flux throws OOMs on a 12gb gpu with quantization\n\nthe only \"large\" model that worked for me was sd3.5L, and i didn't even have to quantize it, just truncate it to fp8, you can REALLY mess with it\n\nsad nobody makes fine tunes for it other than [freek](https://civitaiarchive.com/models/918840?modelVersionId=1028461) (generalist model, the furry is just for marketing) but even then civitai nuked every sd3 model there was",
          "score": -7,
          "created_utc": "2025-12-31 20:25:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwzohfx",
              "author": "a_beautiful_rhind",
              "text": "XL is still kinda undefeated for fast gens. ZiT is the first contender. All the \"big\" models work for me but the required speedups take a huge bite out of quality.\n\nI try them, I use them for a while and eventually I slither back. If I had some 4xxx or 5xxx GPU maybe I'd sing a different tune.",
              "score": 3,
              "created_utc": "2025-12-31 22:37:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwzxrww",
                  "author": "gxmikvid",
                  "text": "yeah sdxl is nice\n\nthe default was ass when it came out (the vae had issues, it wasn't trained on a lot of stuff), switched to xl because of freek (a model maker) and because people made a better vae for it\n\nhis [sd3.5L model](https://civitaiarchive.com/models/918840?modelVersionId=1028461) is more than enough proof for me that sd3.5L is well worth it (furry for marketing, it's general purpose)\n\nyou can lobotomize it to fp8, so just truncate bits from fp16 to fp8, no quantization needed\n\nreacts very well to loras and training\n\nyou can manhandle it, i'm talking unet mods like perturbed attention, perpneg, almost any sampler/scheduler (beta + ddim is a stable base), the structure is not as rigid as people say (because i saw some people say it is, it's not, nowhere near)\n\nit understands from gibberish to exact prompting\n\nit takes more time per step but reacts well to gpu optimized samplers so you can shave some time off\n\nit can generate in 15-20 steps if you smoke some crack and do some custom stuff, not the \"prompt it and go\" type fast of z-image but it's the price of flexibility",
                  "score": 2,
                  "created_utc": "2025-12-31 23:33:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwz2qx4",
              "author": "the_bollo",
              "text": "I'm not on the ZIT payroll or anything. I usually resist the hype train because every week someone's like \"this is a game changer!\" However, ZIT has got me excited about image generation again and it's objectively a very good model. You've probably already tried this but the default workflow is simple and \"just works\" [https://comfyanonymous.github.io/ComfyUI\\_examples/z\\_image/](https://comfyanonymous.github.io/ComfyUI_examples/z_image/)\n\nThat said, 12GB vRAM is a significant limitation since the model itself is a little over 12GB. I wish you luck!",
              "score": 5,
              "created_utc": "2025-12-31 20:37:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwz712i",
                  "author": "gxmikvid",
                  "text": "thank you but i tried that already, with offloading, fp8 quant, fp8 \"lobotomy\" style, everything\n\nit runs but the results are bad\n\nmy mentality is \"improve before you expand\" which is something that newer model developers seem to forget\n\nand i just like to dig into the guts of these models, and as you can imagine the models mentioned above are... well a good analogy is: you open someone and find out that everything has a calcium plaque on and in it, or just gluing legos\n\nsd3 still has some of that redneck energy, it's flexible in silent ways you might not even notice but make a world of difference\n\nand no, i cannot fine tune it, i don't have a nice dataset (yet)",
                  "score": 1,
                  "created_utc": "2025-12-31 21:00:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwzbb7u",
              "author": "GregBahm",
              "text": "Are you saying Qwen, Flux, and Z-Image are all falsely supported in this image gen community because nobody in the image gen community has more than 12gb of memory?\n\nThat's such a weird take... I have a modern video card but my understanding is that you can just go online and use a variety of cloud hosted services if you can't find a local card with more memory.\n\nThe appeal of ZIT over Qwen is it produces image quality that is competitive with Qwen but like 30x faster.\n\nBut Qwen Image Edit still seems to be the best in class as far as I can tell.",
              "score": 2,
              "created_utc": "2025-12-31 21:23:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwzdnaz",
                  "author": "gxmikvid",
                  "text": "that's a weird way to not understand what i wrote\n\n>more steps result in saturation issues, less results in lower quality, no middle ground  \n\n\n>changing size gives the model an aneurysm\n\nthe \"mo' bigge' mo' bette' \" solution did not help the underlying problems either\n\nmany structural problems make it inconsistent across hardware/implementation/intiger type (look up how these operations are accelerated, really interesting)\n\nsome weird \"calcified\" parts of the structure in weird places give weird behaviors too (think: controlnet, weird resolution, sampler/scheduler difference, guidance type difference)\n\ni understand that it's fast, i understand the appeal, but for fuck's sake NNs are made for generalization",
                  "score": 0,
                  "created_utc": "2025-12-31 21:36:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwzqyun",
              "author": "Winter_unmuted",
              "text": "> i'll get crucified but posts like this feel like astroturfing\n\nNah it's just people treating img gen models like sports teams for some reason.",
              "score": 1,
              "created_utc": "2025-12-31 22:52:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q09n1b",
      "title": "Qwen-Image-2512¬†is¬†here",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/fldbgot7liag1.jpeg",
      "author": "Artefact_Design",
      "created_utc": "2025-12-31 10:11:45",
      "score": 260,
      "num_comments": 30,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q09n1b/qwenimage2512_is_here/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwwaz1e",
          "author": "Fluffy_Bug_",
          "text": "FP8 Safetensors\n\n[https://huggingface.co/Comfy-Org/Qwen-Image\\_ComfyUI/blob/main/split\\_files/diffusion\\_models/qwen\\_image\\_2512\\_fp8\\_e4m3fn.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/blob/main/split_files/diffusion_models/qwen_image_2512_fp8_e4m3fn.safetensors)\n\nBF16\n\n[https://huggingface.co/Comfy-Org/Qwen-Image\\_ComfyUI/blob/main/split\\_files/diffusion\\_models/qwen\\_image\\_2512\\_bf16.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/blob/main/split_files/diffusion_models/qwen_image_2512_bf16.safetensors)",
          "score": 27,
          "created_utc": "2025-12-31 11:10:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxd94f",
              "author": "jib_reddit",
              "text": "I should have asked Santa for a new 8TB SSD...",
              "score": 19,
              "created_utc": "2025-12-31 15:25:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwxiaca",
              "author": "Green-Ad-3964",
              "text": "It would be interesting to see if dfloat 11 can reduce the full model (40GB) to fit 32GB of a 5090",
              "score": 4,
              "created_utc": "2025-12-31 15:50:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx1jgyg",
                  "author": "Series-Curious",
                  "text": "I cry in 5060",
                  "score": 1,
                  "created_utc": "2026-01-01 06:13:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwwb672",
          "author": "kpop4ever0",
          "text": "Excited, can't wait to see it's performance compared to ZIT. More competition please !!",
          "score": 15,
          "created_utc": "2025-12-31 11:12:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwx0ks",
              "author": "FinBenton",
              "text": "I can see some people prefer ZIT but from testing, Qwen gives like infinite amount of variability between generations. I used ZIT to exhaustion and I feel like I'w seen everything it can do so this feels like fresh air again. And if you are doing anime styles then base model at 10-12 steps is pretty fast and good without speedup loras.",
              "score": 10,
              "created_utc": "2025-12-31 13:55:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwy195g",
                  "author": "Sudden_List_2693",
                  "text": "And you can use the turbo 4-steps for the upscaling.",
                  "score": 1,
                  "created_utc": "2025-12-31 17:24:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx7rtqm",
                  "author": "Ononimos",
                  "text": "Any chance you can give me your recommended starter workflow?",
                  "score": 1,
                  "created_utc": "2026-01-02 07:01:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwyyizq",
          "author": "marcoc2",
          "text": "Zit base it is the only thing I care now",
          "score": 6,
          "created_utc": "2025-12-31 20:14:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwwtvk5",
          "author": "AshLatios",
          "text": "Can it do anime images?",
          "score": 3,
          "created_utc": "2025-12-31 13:35:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwy13pw",
              "author": "_raydeStar",
              "text": "After testing, it's kinda meh with styles.\n\nI like the prompt adherence more than Z, less than Flux2. \n\nI'm on the fence about this one. I'm leaning back to Z quite honestly - it's a solid release though.",
              "score": 3,
              "created_utc": "2025-12-31 17:24:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwy2hnc",
                  "author": "AshLatios",
                  "text": "I really hope someday wai ani makes a derivative of Z or Qwen.",
                  "score": 2,
                  "created_utc": "2025-12-31 17:30:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwwwzhh",
          "author": "Redeemed01",
          "text": "Before it gets spammed, lora training when?",
          "score": 3,
          "created_utc": "2025-12-31 13:54:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwx592d",
              "author": "Dezordan",
              "text": "It's just a finetune of Qwen Image, so any trainer that supports LoRA for Qwen Image should work all the same",
              "score": 11,
              "created_utc": "2025-12-31 14:42:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwzxuh3",
                  "author": "gillyguthrie",
                  "text": "Related question, does that mean a QIE 2509 LoRA will work with the QIE 2511 model?",
                  "score": 1,
                  "created_utc": "2025-12-31 23:33:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nww8dsa",
          "author": "VCamUser",
          "text": ">Qwen-Image-2512 is here\n\nWhere ?",
          "score": 4,
          "created_utc": "2025-12-31 10:46:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww8t8s",
              "author": "Harouto",
              "text": "[https://huggingface.co/Qwen/Qwen-Image-2512](https://huggingface.co/Qwen/Qwen-Image-2512)",
              "score": 14,
              "created_utc": "2025-12-31 10:50:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwxxux9",
          "author": "Rare-Winter5523",
          "text": "LTX2 video, where are you?",
          "score": 1,
          "created_utc": "2025-12-31 17:07:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwyg4nl",
              "author": "JahJedi",
              "text": "Jan next year i hope.",
              "score": 1,
              "created_utc": "2025-12-31 18:38:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwywml1",
              "author": "Dogluvr2905",
              "text": "It's already available on paid sites (e.g., wavespeed.ai) so if you want to try it, you can try it there.  It's 'Ok'.",
              "score": 1,
              "created_utc": "2025-12-31 20:04:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx0pp90",
          "author": "2legsRises",
          "text": "very awesome quality, nice",
          "score": 1,
          "created_utc": "2026-01-01 02:29:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxd1c4t",
          "author": "Pale_Reputation_511",
          "text": "I don get how to use these things with comfyui , any kind of guide to a total noob?",
          "score": 1,
          "created_utc": "2026-01-03 01:44:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwwretz",
          "author": "Whispering-Depths",
          "text": "still a 40-80b param model right?",
          "score": 1,
          "created_utc": "2025-12-31 13:20:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwwx94",
              "author": "Dezordan",
              "text": "Qwen Image, including Edit models, were always 20B param models. You probably meant their size, which is a different thing.",
              "score": 8,
              "created_utc": "2025-12-31 13:54:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwwtisy",
              "author": "Niwa-kun",
              "text": "main is 40gb, and the scaled is 20gb",
              "score": 1,
              "created_utc": "2025-12-31 13:33:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwy5a9f",
                  "author": "RayHell666",
                  "text": "params not weight",
                  "score": 3,
                  "created_utc": "2025-12-31 17:44:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwy679a",
          "author": "hurrdurrimanaccount",
          "text": "it looks like it has even more HDR/slop skin now",
          "score": 0,
          "created_utc": "2025-12-31 17:49:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwz9s57",
          "author": "Perfect-Campaign9551",
          "text": "Qwen sucks. Always oversaturated images. AI gloss on them",
          "score": -4,
          "created_utc": "2025-12-31 21:15:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx3i8b5",
              "author": "MissPerfectFoot",
              "text": "There is a custom node which fixes this issue quite well:\nhttps://youtu.be/FMnN-duS6hQ?si=ZPLIKli0lksTMBP1",
              "score": 1,
              "created_utc": "2026-01-01 16:15:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q07foa",
      "title": "BEST ANIME/ANYTHING TO REAL WORKFLOW!",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1q07foa",
      "author": "OneTrueTreasure",
      "created_utc": "2025-12-31 07:50:33",
      "score": 231,
      "num_comments": 84,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1q07foa/best_animeanything_to_real_workflow/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwvvm98",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/07caa4dw5iag1.png?width=2048&format=png&auto=webp&s=812c1eab86914da31d0681cdde1a5a6226c4379a\n\nzoom in",
          "score": 22,
          "created_utc": "2025-12-31 08:45:59",
          "is_submitter": true,
          "replies": [
            {
              "id": "nww52fa",
              "author": "OneTrueTreasure",
              "text": "![gif](giphy|58pz2Z0LJSVLzobf5P)",
              "score": 13,
              "created_utc": "2025-12-31 10:15:57",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwwannm",
              "author": "mk8933",
              "text": "![gif](giphy|HFpU6ykvMDCR3NqOzW)",
              "score": 2,
              "created_utc": "2025-12-31 11:07:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx2nmpg",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 1,
                  "created_utc": "2026-01-01 12:58:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwvvpjj",
          "author": "xbobos",
          "text": "https://preview.redd.it/qwg2dna36iag1.png?width=1472&format=png&auto=webp&s=e23615f7362db12f042219a553687a0162276295",
          "score": 12,
          "created_utc": "2025-12-31 08:46:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwpw4o",
              "author": "Competitive_Ad_5515",
              "text": "This is actually much better! It's approaching that slightly crunchy cosplay wig aesthetic that gives it a realistic vibe",
              "score": 7,
              "created_utc": "2025-12-31 13:10:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwza36l",
              "author": "foxdit",
              "text": "Simple z-image i2i at lowish denoise and higher shift yes? Increase cfg to 1.5 or 2.0 to fix the noise on the hair for this sort of process. A seedVR2 upscale will also fix it. Otherwise a very good realism.",
              "score": 1,
              "created_utc": "2025-12-31 21:17:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx1mjqu",
                  "author": "OneTrueTreasure",
                  "text": "Can you send me a workflow for this? I want to play around with it and test :)",
                  "score": 1,
                  "created_utc": "2026-01-01 06:41:30",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwvwcwf",
              "author": "OneTrueTreasure",
              "text": "you can put in the negative for their eyes not to close, or skip the whole SD1.5 inpainting part by bypassing the associated nodes",
              "score": 1,
              "created_utc": "2025-12-31 08:52:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwvx4ia",
                  "author": "xbobos",
                  "text": "I think the gaze towards the front camera ruins realism.",
                  "score": 3,
                  "created_utc": "2025-12-31 09:00:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwvrbkk",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/or4q80cnyhag1.png?width=2048&format=png&auto=webp&s=ab5c36a42066ec06977850c626b5af4adbfbadaa\n\nEmilia from Re:Zero",
          "score": 11,
          "created_utc": "2025-12-31 08:05:19",
          "is_submitter": true,
          "replies": [
            {
              "id": "nwwk31i",
              "author": "bickid",
              "text": "Can you generate the exact same Emilia, but non-Asian? Just wondering if the model has a bias here. thx",
              "score": 2,
              "created_utc": "2025-12-31 12:28:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwwkk7n",
                  "author": "OneTrueTreasure",
                  "text": "yes, you will just need to bypass all the face detailer nodes, add in the prompts \"European female, American girl, Western woman etc\" into the the text prompt at the top (above the Z-image part)",
                  "score": 5,
                  "created_utc": "2025-12-31 12:31:46",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nwwkrk8",
                  "author": "OneTrueTreasure",
                  "text": "you might also need to change the \"load diffusion model\" node to Z-image-turbo (the base/regular one) the checkpoint I'm using is biased towards Asian faces so\n\ncan also try to change the SD1.5 checkpoint model to something other than MajicMix instead of disabling it, like CyberRealisticv6",
                  "score": 2,
                  "created_utc": "2025-12-31 12:33:20",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nxdw0aw",
                  "author": "willjerk4karma",
                  "text": "I've tried doing exactly that but its really hard. Emilia, like most anime girls, has a really soft face with very Asian-adjacent features so even when you specify \"Caucasian facial structure\" it still gives a mostly Asian result.",
                  "score": 1,
                  "created_utc": "2026-01-03 04:52:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nww748d",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/a6hpubgepiag1.png?width=2048&format=png&auto=webp&s=f96ed893a3c42850c9bc3e66bbc24ab2bd09ba5e",
          "score": 8,
          "created_utc": "2025-12-31 10:35:06",
          "is_submitter": true,
          "replies": [
            {
              "id": "nww76qc",
              "author": "OneTrueTreasure",
              "text": "![gif](giphy|PYKHHsvE6kskgwqIIB)",
              "score": 6,
              "created_utc": "2025-12-31 10:35:44",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwzpdem",
              "author": "The-Crawling-Chaos",
              "text": "The dress says the honeymoon will be unforgettable. Her pupils say there will be tentacles involved.",
              "score": 2,
              "created_utc": "2025-12-31 22:42:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx1mp29",
                  "author": "OneTrueTreasure",
                  "text": "LMAO",
                  "score": 2,
                  "created_utc": "2026-01-01 06:42:53",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwvr94y",
          "author": "OneTrueTreasure",
          "text": "High quality example\n\nhttps://preview.redd.it/lz3s02giyhag1.png?width=2048&format=png&auto=webp&s=a819d50d0a2e1e690e905d3a0f7399ed64181695",
          "score": 5,
          "created_utc": "2025-12-31 08:04:40",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nwwajmm",
          "author": "LuxDragoon",
          "text": "Looks good, but not real enough.",
          "score": 4,
          "created_utc": "2025-12-31 11:06:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwc9wq",
              "author": "OneTrueTreasure",
              "text": "You can swap out the models/loras/checkpoints to your liking, and also skip/bypass the face detailer part. I think using a different Z-Image checkpoint will help too, as well as playing around with the steps. I am also looking for better options and still testing things :) hopefully Z-image edit is very good so we can skip all these and just prompt for it with one model",
              "score": 2,
              "created_utc": "2025-12-31 11:22:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwe9hx",
          "author": "OneTrueTreasure",
          "text": "Just by changing the Z-Image diffusion model to \"BeyondRealityZ\" and the SD1.5 face detailer checkpoint to \"Cyberrealisticv6\" you will get this kinda image!\n\nhttps://preview.redd.it/krapu5wz0jag1.png?width=2048&format=png&auto=webp&s=267deb85bc700571a12f40b5f9d3af63d473067c",
          "score": 4,
          "created_utc": "2025-12-31 11:40:14",
          "is_submitter": true,
          "replies": [
            {
              "id": "nwx52m8",
              "author": "ywis797",
              "text": "please what prompt",
              "score": 1,
              "created_utc": "2025-12-31 14:41:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx1mrdv",
                  "author": "OneTrueTreasure",
                  "text": "no prompt it does it all for you lol, it's anime image to realistic image bro",
                  "score": 1,
                  "created_utc": "2026-01-01 06:43:30",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwvvguy",
          "author": "xbobos",
          "text": "https://preview.redd.it/6nlhk45p5iag1.png?width=1256&format=png&auto=webp&s=60fc55730da16371068394b52b94942785ebbb4f",
          "score": 3,
          "created_utc": "2025-12-31 08:44:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvw5q7",
              "author": "OneTrueTreasure",
              "text": "Nice!",
              "score": 1,
              "created_utc": "2025-12-31 08:51:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nww8tt5",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/gem1eem8siag1.png?width=2048&format=png&auto=webp&s=4acb0c43c247bd7918ca3ff59da1a8ec1ff09604",
          "score": 5,
          "created_utc": "2025-12-31 10:50:59",
          "is_submitter": true,
          "replies": [
            {
              "id": "nwzre7l",
              "author": "The-Crawling-Chaos",
              "text": "This has an oil painting look to it more so than realistic. But her imperfect teeth really add to the overall aesthetic. That‚Äôs the kind of details that will make images come to life (and by that I mean look to be actually real).",
              "score": 1,
              "created_utc": "2025-12-31 22:54:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwvr5y2",
          "author": "NanoSputnik",
          "text": "Nah, palstic sameface from sd15 era. Nobody will think these are real cosplay photos. Game screenshots for UE5 photomode at best.",
          "score": 9,
          "created_utc": "2025-12-31 08:03:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvrpmo",
              "author": "NanoSputnik",
              "text": "For the reference this is how real cosplay looks \n\nhttps://preview.redd.it/yoz1zkvbzhag1.png?width=2848&format=png&auto=webp&s=9fc76b31a5981bb43151773c210f1392a34d7532",
              "score": 9,
              "created_utc": "2025-12-31 08:08:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwvsh3u",
                  "author": "OneTrueTreasure",
                  "text": "I've been to anime cons, so I know they don't look this perfect. I want pretty real life anime girls not the ones I can find outside haha",
                  "score": 7,
                  "created_utc": "2025-12-31 08:16:04",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwvsadf",
              "author": "OneTrueTreasure",
              "text": "It's cause I had to switch the images to lower res jpg to post on Runninghub so they lost quality. You can also change the Skinfix Qwen Lora to higher strength.\n\nHere is a full png version of the first picture\n\nhttps://preview.redd.it/9k2jc9z80iag1.png?width=2048&format=png&auto=webp&s=44e11b0eeac46b893aa2d67d99720909add0e558",
              "score": 2,
              "created_utc": "2025-12-31 08:14:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwcx1v",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/giopikmpyiag1.png?width=2048&format=png&auto=webp&s=ca157d4a285e4ae409f1d48fe2aeef4351503eb2",
          "score": 2,
          "created_utc": "2025-12-31 11:28:14",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nwy7llz",
          "author": "-lq_pl-",
          "text": "Thanks for Asuka content, but I like the drawn version much better. What was your prompt/workflow for making that?",
          "score": 2,
          "created_utc": "2025-12-31 17:55:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1jj2a",
              "author": "OneTrueTreasure",
              "text": "Sorry bro I just went on Pinterest and looked up AI anime girl lmao",
              "score": 2,
              "created_utc": "2026-01-01 06:13:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx2ooqn",
                  "author": "OneTrueTreasure",
                  "text": "If I had to guess though it's the Cunnyfunky Lora since I've generated similar images to that before, try that",
                  "score": 2,
                  "created_utc": "2026-01-01 13:07:10",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxq6ibp",
          "author": "MrChilli2020",
          "text": "Im a noob but i had a lot of luck starting this past week using something called Visionary with Z-image and added some High detailed Lora. some images looked real just from that. I tried some loras such as God P and mysticX but I noticed the girl in the end looked like a porn star over me just wanting the body parts down there to look better. \n\nI'll try this out. i get some crazy stuff from hentai workflows when compared to zimage which seems to just focus on asian girls standing :)",
          "score": 2,
          "created_utc": "2026-01-05 00:23:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxykxtp",
              "author": "OneTrueTreasure",
              "text": "hope it works! working on a version two right now and it's even better realism wise than this one :)",
              "score": 1,
              "created_utc": "2026-01-06 05:43:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwvt74s",
          "author": "3deal",
          "text": "It doesn't look real at all.",
          "score": 6,
          "created_utc": "2025-12-31 08:22:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvtqko",
              "author": "OneTrueTreasure",
              "text": "Please send a better workflow because I want in on it too :)",
              "score": 1,
              "created_utc": "2025-12-31 08:28:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwaiv1",
          "author": "shadowtheimpure",
          "text": "How the hell do you use this workflow? I had Comfy manager install missing nodes and it still complains that three nodes are missing, all of which include 'SeedVR2'. I tried googling and installing from the ComfyUI SeedVR2 github with zero success.",
          "score": 2,
          "created_utc": "2025-12-31 11:06:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwbvln",
              "author": "OneTrueTreasure",
              "text": "SEEDVR should be in Comfy manager already. Here is a reddit post with a workflow [https://www.reddit.com/r/comfyui/comments/1pi2i67/when\\_an\\_upscaler\\_is\\_so\\_good\\_it\\_feels\\_illegal/](https://www.reddit.com/r/comfyui/comments/1pi2i67/when_an_upscaler_is_so_good_it_feels_illegal/)\n\nThere are also some Chinese nodes you can swap in with English ones because they are hard to find. For example there is \"text box\" node, just put in any \"text\" node with \"string\" as the output and reconnect it . You will just have to type in \"Anime characters transformed into realistic live-action\" into it. \n\nI just started using Comfy like two days ago so it's not really the best workflow tbh. Runpod has so many Chinese nodes and models that are super hard to find and I usually just swap them out for similar things in Comfy. Sorry for the trouble friend",
              "score": 3,
              "created_utc": "2025-12-31 11:18:55",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwww4ce",
              "author": "bloopy901",
              "text": "Any luck? Im running into the same issue.",
              "score": 1,
              "created_utc": "2025-12-31 13:49:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwww8ic",
                  "author": "shadowtheimpure",
                  "text": "None whatsoever. I gave up, because I ran out of time.",
                  "score": 1,
                  "created_utc": "2025-12-31 13:50:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwx8hlf",
          "author": "leppie",
          "text": "I would use Illustrious as a first pass, takes no time and you can get a decent 1:1 match. Samples: https://imgur.com/a/4bbAqT4",
          "score": 2,
          "created_utc": "2025-12-31 15:00:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1je3w",
              "author": "OneTrueTreasure",
              "text": "actually looks good, do you have an associated workflow? I'd love to play around with this :)",
              "score": 1,
              "created_utc": "2026-01-01 06:12:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwvz91z",
          "author": "ihcgnil",
          "text": "will the workflows u posted work in comfyui?",
          "score": 1,
          "created_utc": "2025-12-31 09:20:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvzf74",
              "author": "OneTrueTreasure",
              "text": "yes, just download the .json file or generate an image on RunningHub and drag the outputted image into Comfy :)",
              "score": 1,
              "created_utc": "2025-12-31 09:22:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nww4hp9",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/kjpjiy4wkiag1.png?width=2048&format=png&auto=webp&s=cc2a5ebda362218696ef78b87e05c49cf0b0c694",
          "score": 1,
          "created_utc": "2025-12-31 10:10:31",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nww8710",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/4pvt3ma6riag1.png?width=2048&format=png&auto=webp&s=d761194d68fca9c13df1dc67e3b85a79aa21f735",
          "score": 1,
          "created_utc": "2025-12-31 10:45:07",
          "is_submitter": true,
          "replies": [
            {
              "id": "nwwxp6v",
              "author": "Whispering-Depths",
              "text": "https://i.imgur.com/RTSivor.png",
              "score": -1,
              "created_utc": "2025-12-31 13:59:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwmp57",
          "author": "Roongx",
          "text": "bookmarked",
          "score": 1,
          "created_utc": "2025-12-31 12:47:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwnbif",
              "author": "OneTrueTreasure",
              "text": "enjoy! hope it works for you :)",
              "score": 1,
              "created_utc": "2025-12-31 12:52:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwz2bcu",
          "author": "foxdit",
          "text": "TBH my anime->realism results with simple i2i and playing with denoise/shift values to maximize image adherence vs. realism have been stellar. It, however, is a time consuming process. But the results are fairly indistinguishable from reality. If your LORA gets you \"pretty close\" to photo realism, an extra pass with like 0.3 denoise from z-image would probably achieve photorealism. Worth playing around with.",
          "score": 1,
          "created_utc": "2025-12-31 20:35:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1jrgu",
              "author": "OneTrueTreasure",
              "text": "I'd love your workflow and play around with it!  Always looking for better options :)",
              "score": 1,
              "created_utc": "2026-01-01 06:15:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx3quqw",
                  "author": "foxdit",
                  "text": "It's not special. Load image -> VAE encode -> latent into sampler, 0.5 denoise to start, 3-6 shift, prompt describing details of image with \"realism, amateur photo\" tags. I do use the DetailDaemon sampler. The point being, z-image does anime->realism out of the box really well, it's just time consuming. A good lora for it + an i2i pass at low denoise would probably be a pretty quick way to get very good results.",
                  "score": 1,
                  "created_utc": "2026-01-01 17:01:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwz4ccn",
          "author": "Witty_Mycologist_995",
          "text": "has anyone made real to anime?",
          "score": 1,
          "created_utc": "2025-12-31 20:46:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1mgcb",
              "author": "OneTrueTreasure",
              "text": "That is much easier to do brotha, there are tons of workflows that can do that. You can use pretty much every model to turn a person into an anime character, you just need to prompt it in like \"anime, illustration etc\" and use loras.",
              "score": 1,
              "created_utc": "2026-01-01 06:40:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx3l31s",
                  "author": "Witty_Mycologist_995",
                  "text": "i think anime to real is easier i can just ask qwen image edit to do it. but qwen image edit has a bad anime style",
                  "score": 1,
                  "created_utc": "2026-01-01 16:31:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx1m41v",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/zigis04unoag1.png?width=1476&format=png&auto=webp&s=538e3083ffc45f64328df09cf6970f1849e5f0a1\n\nFor people having trouble with SEEDVR2, it seems like I was using the version from a couple weeks or a month ago or something. The new one looks something like this. You just need to connect it exactly like this (Only dit and vae)",
          "score": 1,
          "created_utc": "2026-01-01 06:37:28",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nx8dbyv",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/pgwzamw6xwag1.png?width=2048&format=png&auto=webp&s=91c1345fbd83aea9134b5f885e58f6c2c19c03cd\n\nIt can do Non-Asian btw",
          "score": 1,
          "created_utc": "2026-01-02 10:24:03",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nx9tlq4",
          "author": "Consistent_Pick_5692",
          "text": "tried to install the missing nodes and my whole COMFYUI got ruined, any other wf?",
          "score": 1,
          "created_utc": "2026-01-02 16:06:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxe78zk",
              "author": "OneTrueTreasure",
              "text": "Have you tried the workflow on google drive? I can't help you much without knowing what went wrong exactly, sorry friend",
              "score": 1,
              "created_utc": "2026-01-03 06:15:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwxzmir",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -1,
          "created_utc": "2025-12-31 17:16:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1jn04",
              "author": "OneTrueTreasure",
              "text": "I have never even watched Evangelion I just went on Pinterest and looked up AI anime girls haha",
              "score": 1,
              "created_utc": "2026-01-01 06:14:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx2njps",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 1,
                  "created_utc": "2026-01-01 12:57:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwz314i",
          "author": "UpGacha",
          "text": "https://preview.redd.it/ejc5bs76plag1.jpeg?width=914&format=pjpg&auto=webp&s=d288a09da4e23e1b0a63cf8e80eba03bf46c4e47",
          "score": -2,
          "created_utc": "2025-12-31 20:39:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}