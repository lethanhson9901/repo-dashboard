{
  "metadata": {
    "last_updated": "2025-12-31 08:39:57",
    "time_filter": "week",
    "subreddit": "StableDiffusion",
    "total_items": 50,
    "total_comments": 1411,
    "file_size_bytes": 1275741
  },
  "items": [
    {
      "id": "1puszuc",
      "title": "Former 3D Animator trying out AI, Is the consistency getting there?",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/yiesmxvwu69g1",
      "author": "BankruptKun",
      "created_utc": "2025-12-24 17:45:43",
      "score": 4225,
      "num_comments": 461,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Animation - Video",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1puszuc/former_3d_animator_trying_out_ai_is_the/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nvr1chg",
          "author": "coffee_ape",
          "text": ">3D animator.\n\n>the sweater.\n\n>the armpits.\n\nTop tier choices. I know what you are.\n\n![gif](giphy|qIVDzdFFfUiBe22WON|downsized)",
          "score": 884,
          "created_utc": "2025-12-24 17:55:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvr3c3q",
              "author": "BankruptKun",
              "text": "haha, i felt that since the posts here were slightly spicy but SFW, i should create something that is appealing like skin, videogames and anime often portray skin a lot so i went with that, but i do have to say there's a certain niche to this fetish. glad u liked it.",
              "score": 224,
              "created_utc": "2025-12-24 18:06:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvr8i4s",
                  "author": "Spamuelow",
                  "text": "\n\nhttps://preview.redd.it/b3ulgzpg479g1.jpeg?width=842&format=pjpg&auto=webp&s=dd8fc51538208c730e82c7f38853972041ab46f9",
                  "score": 256,
                  "created_utc": "2025-12-24 18:33:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvrph5f",
                  "author": "Critical_Concert_689",
                  "text": "I see she comes equipped with the virgin slayer sweater. Well played, sir.",
                  "score": 37,
                  "created_utc": "2025-12-24 20:09:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvrbftk",
                  "author": "coffee_ape",
                  "text": "![gif](giphy|KX7khoMaKYRXlZWDd6)\n\nInner me.",
                  "score": 64,
                  "created_utc": "2025-12-24 18:49:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvsm6bl",
                  "author": "HelpRespawnedAsDee",
                  "text": "I could honestly stare at this for hours. Do you have an ig or other channel to follow?",
                  "score": 6,
                  "created_utc": "2025-12-24 23:33:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvsola2",
                  "author": "Traditional-Dingo604",
                  "text": "This is beautiful work regardless",
                  "score": 1,
                  "created_utc": "2025-12-24 23:50:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvr8m2x",
              "author": "hello-xworld",
              "text": "I see Kobeni, I upvote",
              "score": 22,
              "created_utc": "2025-12-24 18:34:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvru9rz",
                  "author": "WantonKerfuffle",
                  "text": "I read that as Kenobi first",
                  "score": 10,
                  "created_utc": "2025-12-24 20:37:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvrl4m6",
              "author": "Taki_Minase",
              "text": "![gif](giphy|7q8Yajg93O11JP70jm)",
              "score": 5,
              "created_utc": "2025-12-24 19:44:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvrli30",
                  "author": "coffee_ape",
                  "text": "Prison school :D",
                  "score": 1,
                  "created_utc": "2025-12-24 19:46:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvtniq8",
              "author": "odrea",
              "text": "We are cooked chat ðŸ’€\n\n![gif](giphy|vsxe4XnAlf8pW|downsized)",
              "score": 1,
              "created_utc": "2025-12-25 04:12:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvuunnm",
              "author": "JohnWangDoe",
              "text": "He's a man of culture",
              "score": 1,
              "created_utc": "2025-12-25 11:19:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvv0deg",
              "author": "Kirigaya_Mitsuru",
              "text": "And this is just the beginning...\n\nCant wait for better AI technologies especially FDVR like things. hehe",
              "score": 1,
              "created_utc": "2025-12-25 12:17:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrnvpa",
          "author": "iamjayalastor",
          "text": "![gif](giphy|xzG4bMGnjWhDV8yefe|downsized)",
          "score": 77,
          "created_utc": "2025-12-24 19:59:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvr1xer",
          "author": "7satsu",
          "text": "My feedback in relation to the entire description and post shall be one word:   \nNice",
          "score": 184,
          "created_utc": "2025-12-24 17:58:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvr3hw4",
              "author": "BankruptKun",
              "text": "thank you, this was my first attempt with ai, i felt people would call it cringe but i guess i am feeling confident now.",
              "score": 41,
              "created_utc": "2025-12-24 18:07:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvrgkq0",
                  "author": "AirGief",
                  "text": "Nothing cringe here, I re-watched it 3 times. Amazing quality and has that \"is she real?\" kind of effect.",
                  "score": 23,
                  "created_utc": "2025-12-24 19:17:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvsyzjt",
                  "author": "fibercrime",
                  "text": "bro you should see the kind of stuff people post on this sub confidently. youâ€™re already in the top 10% in my opinion.\n\nand awesome username haha",
                  "score": 5,
                  "created_utc": "2025-12-25 01:03:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvt2re5",
                  "author": "Real_Win_353",
                  "text": "Yea no, this is very good. Every visual medium gets pushed to the limit by deviants, gooners and artists. Sometimes at the same time!",
                  "score": 1,
                  "created_utc": "2025-12-25 01:32:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvv8j6e",
                  "author": "bowtuckle",
                  "text": "I got inceptioned into reading attempt as armpit. Bravo sir!",
                  "score": 1,
                  "created_utc": "2025-12-25 13:28:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvrkwvg",
                  "author": "Negative_Space77",
                  "text": "How did you made this?",
                  "score": 1,
                  "created_utc": "2025-12-24 19:42:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvr9ci5",
          "author": "MonstaGraphics",
          "text": "\"You're taking jobs away from 3D Animators!\"\n\nI am the 3D Animator\n\n\"Oh...\"",
          "score": 395,
          "created_utc": "2025-12-24 18:38:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrl5m0",
              "author": "InternationalOne2449",
              "text": "https://preview.redd.it/sf6vv2k0h79g1.jpeg?width=686&format=pjpg&auto=webp&s=4b1cec319bc0df1b49f5628a9cfba732757ccc6c",
              "score": 88,
              "created_utc": "2025-12-24 19:44:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvs06oh",
                  "author": "peternic30",
                  "text": "I AM THE 3D ANIMATOR!",
                  "score": 29,
                  "created_utc": "2025-12-24 21:12:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvuh248",
                  "author": "jmbaf",
                  "text": "Lol I can hear this expression",
                  "score": 1,
                  "created_utc": "2025-12-25 08:50:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvrln6b",
              "author": "BankruptKun",
              "text": "literally was about to start delivery jobs, feedback has been good, so gonna keep learning to improve now. i actually expected people to hate it cause some people may not like the 3D render mix. but thanks i guess this style is working.",
              "score": 88,
              "created_utc": "2025-12-24 19:47:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvrvppo",
                  "author": "nakedmedia",
                  "text": "Ai slop is unacceptable, AI as a tool you developed off of your own work is what it should be regulated to. This is exactly how AI should be used if at all.",
                  "score": 52,
                  "created_utc": "2025-12-24 20:46:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvui0yd",
                  "author": "Basic_Record5112",
                  "text": "I see. You render it in blender, Maya, Daz. Iâ€™m an idiot. Thank you!",
                  "score": 2,
                  "created_utc": "2025-12-25 09:01:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvrz0h4",
                  "author": "dennismfrancisart",
                  "text": "As a 2D/3D/AI/3D-Printer, I wholeheartedly approve of this message",
                  "score": 2,
                  "created_utc": "2025-12-24 21:05:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvsq03c",
              "author": "Other_b1lly",
              "text": "The 3D animator is able to use all the tools without complaining.",
              "score": 2,
              "created_utc": "2025-12-25 00:00:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw5odho",
              "author": "jjjbabajan",
              "text": "Yeah, making your RuneScape character spin around doesnâ€™t really make you an animator, but sure.",
              "score": 1,
              "created_utc": "2025-12-27 07:33:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw6aia3",
                  "author": "MonstaGraphics",
                  "text": "Yeah, the output he produced is super trivial, requires no knowledge, and anyone can do it in a few seconds! Even a monkey can do it. Hey, why don't you make a similar video just to show us how easy it all is? C'mon, I'll wait here.",
                  "score": 1,
                  "created_utc": "2025-12-27 11:09:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvuduf8",
              "author": "pgndu",
              "text": "Hurgh it's the amount of work, condescending pos",
              "score": 1,
              "created_utc": "2025-12-25 08:15:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvxcom6",
                  "author": "MonstaGraphics",
                  "text": "I'm a condescending piece of shit? Why? Where am I condescending?",
                  "score": 1,
                  "created_utc": "2025-12-25 21:23:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvrb67c",
          "author": "PyrZern",
          "text": "I get it. You like armpits.\n\nI'm not complaining <3",
          "score": 59,
          "created_utc": "2025-12-24 18:48:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw4biyy",
              "author": "BankruptKun",
              "text": "in SFW work best i can do is armpit and face detailing. otherwise its hard. but yes even tho i do professionally it is something weirdly good.",
              "score": 1,
              "created_utc": "2025-12-27 01:34:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvr2rzs",
          "author": "mrgonuts",
          "text": "Your new girlfriend looks nice",
          "score": 110,
          "created_utc": "2025-12-24 18:03:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvry1jy",
              "author": "DEVIL_S1NGH",
              "text": "OUR GIRLFRIEND",
              "score": 80,
              "created_utc": "2025-12-24 21:00:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvr2rai",
          "author": "fakezero001",
          "text": "Good job dude. And keep going.",
          "score": 33,
          "created_utc": "2025-12-24 18:03:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvr3nlj",
              "author": "BankruptKun",
              "text": "thanks.",
              "score": 7,
              "created_utc": "2025-12-24 18:07:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvt04fv",
                  "author": "verocious_veracity",
                  "text": "Maybe highlight other parts as well for science.",
                  "score": 3,
                  "created_utc": "2025-12-25 01:12:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvr0alj",
          "author": "Nooreo",
          "text": "I dont know much about 3D workflows. But this is very good. Share with us your workflow",
          "score": 53,
          "created_utc": "2025-12-24 17:49:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvr2s7a",
              "author": "BankruptKun",
              "text": "my workflow is still very simplistic and not organized yet. i only started mixing 3d with ai about 3 months ago, so i am still learning.\n\nbasically:\n\n1. **pose:** i use my 3d models as a reference to feed the ai the exact pose i want.\n2. **skin:** i feed skin texture references from my offline library (i have about 20tb of hyperrealistic texture maps i collected).\n3. **style:** i mix comfyui with qwen to draw out the \"anime-ish\" feel.\n4. **face/hair:** i use a custom anime-style lora here. this takes a lot of iterations to get right.\n5. **refinement:** i regenerate the face and clothing many times using specific cosplay & videogame references.\n6. **video:** this is the hardest part. i am using a home-brewed lora on comfyui for movement, but as you can see, i can only manage stable clips of about 6 seconds right now, which i merged together.\n\nstill testing things out.",
              "score": 139,
              "created_utc": "2025-12-24 18:03:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvr435b",
                  "author": "grmndzr",
                  "text": "pretty cool. have you tried using wananimate for movement? you could try feeding it some of your 3d animations, it does a pretty solid job of capturing motion and mapping it to your reference.",
                  "score": 22,
                  "created_utc": "2025-12-24 18:10:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvrblnn",
                  "author": "Vijayi",
                  "text": "Actually, you stitched them together really well. In my opinion, the problem isnt the 6-second limit; 6 seconds is plenty for a lot of things. The issue is how people stitch the result together. In most of what I see out there, the cuts are very obvious. Look at cinemaâ€”hiding the cut is an art form, and I think that's the key here. Even if consumer GPUs could generate 10, 20, or 30 seconds, you would still need stitch cuts.\nRegarding the workflow itself, I was thinking about something similar. I don't have as much animation experience as you, so my version is a bit rough and clunky, but still: In any 3D environment (Maya, Blender, Unreal, doesn't matter), create a character base for LoRA from different angles with rough outlines. Then ControlNetâ€”using whatever model you like. Cherry-pick the best results. Faceswap to achieve consistency. For motionâ€”again, use any 3D package. Need SFW? Blender, Unreal, Cascneur. Need NSFW? Daz, VaM... there are heaps of free assets and scenes. Ow and actually if you have full body vr tracking and/or something like ultralip, learning/do animation can be qute fun.\nThanks for sharing, it actually turned out really great!\n\nUpd: almost forgot, recently thinking about Omniverse Audio2Face and mesh to metahuman for facial animation. Dont have time for this atm, absolutely want to explore when i find free time.",
                  "score": 12,
                  "created_utc": "2025-12-24 18:50:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvr6qd4",
                  "author": "Sioluishere",
                  "text": "20tb? In this day and age!",
                  "score": 5,
                  "created_utc": "2025-12-24 18:24:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvr69ee",
                  "author": "VitusApollo",
                  "text": "I'm just starting out too, if you'd be open to sharing an in-depth guide sometime with settings etc, I'd really appreciate it. This is way better than things I've done, it's shocking you're so new at it. Way to go!",
                  "score": 3,
                  "created_utc": "2025-12-24 18:21:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvrk9jy",
                  "author": "lazyspock",
                  "text": "I know you probably know it, as I'm a very very amateur Comfy user, but have you tried to:\n\n- Generate the first 5 or 6 seconds video\n- Export the last frame of the video (ffmpeg does that in a millisecond)\n-Use this last frame as the basis for a new 5-second generation (with a new prompt to continue the movement from the previous video) \n-Repeat that a few times\n- Stitch the resulting videos together in the end\n\nI've been doing that with reasonable success. The consistency can be affected sometimes but you can simply try a new generation. And, of course, you cannot get a 2 minutes video this way, but I've done 30 seconds just fine",
                  "score": 2,
                  "created_utc": "2025-12-24 19:39:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvs8jax",
                  "author": "filtersweep",
                  "text": "You could probably accomplish the same thing in Grok with the right prompt",
                  "score": 1,
                  "created_utc": "2025-12-24 22:03:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvsux4n",
                  "author": "myst3rie",
                  "text": "Creating this quality video with 12go ram is crazy. I tried and failed a lot. Do you have the workflow for the 6sec part ? (even if I can't completely use it, it would be a nice Christmas gift lol)",
                  "score": 1,
                  "created_utc": "2025-12-25 00:34:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvszvku",
                  "author": "Miaomiaokittymiao",
                  "text": "Were there any videos in particular you used to learn these tools you listed? Interested in duplicating your workflow",
                  "score": 1,
                  "created_utc": "2025-12-25 01:10:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvv3ws4",
                  "author": "Carnivore_Crunch",
                  "text": "Any chance you could share what the 3d model looked like at the start before you did anything to it?",
                  "score": 1,
                  "created_utc": "2025-12-25 12:50:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvx5xkw",
                  "author": "K-Max",
                  "text": "Which video model are you using for the movement / animation that you applied the lora on? Wan 2.2?",
                  "score": 1,
                  "created_utc": "2025-12-25 20:41:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvrvv3w",
              "author": "Odd_Judgment_3513",
              "text": "Looks really great",
              "score": 1,
              "created_utc": "2025-12-24 20:47:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvtg5wd",
              "author": "ArtfulGenie69",
              "text": "It's probably like take a kinda crappy model and pose it then get a good angle in blender view finder.  Then you just render an image.  Now take the image and run it through nano-b or qwen or whatever and make it more real with the texture or use zimage for a pass to get it more real and then send it through wan.  Also lately you can use things like that scail to get it to move that smoothly just use a video of someone doing that motion.",
              "score": 1,
              "created_utc": "2025-12-25 03:14:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvr5lo0",
          "author": "Hearcharted",
          "text": "![gif](giphy|UWvGI9iE4hg7DqcbQP)\n\nCloud's lost sister?",
          "score": 25,
          "created_utc": "2025-12-24 18:18:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrb60d",
              "author": "Johnycantread",
              "text": "If cloud and tifa had a child.",
              "score": 9,
              "created_utc": "2025-12-24 18:48:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvrzj37",
                  "author": "FirTree_r",
                  "text": "This looks like Yuffie's outfit, more than Tifa.",
                  "score": 1,
                  "created_utc": "2025-12-24 21:09:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvrm09a",
              "author": "BankruptKun",
              "text": "now that you posted this, man lol yes the eyes looks bit like that.",
              "score": 3,
              "created_utc": "2025-12-24 19:49:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvsud9h",
                  "author": "Hearcharted",
                  "text": "XD",
                  "score": 1,
                  "created_utc": "2025-12-25 00:30:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvtfoe7",
              "author": "ArtfulGenie69",
              "text": "stepbro?",
              "score": 2,
              "created_utc": "2025-12-25 03:10:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvr4etg",
          "author": "kinetic_text",
          "text": "Creatives are right to feel threatened but technical artists who understand colornscience, meshes, 3D, lighting, etc, etc will SOAR with generative tools. Absolutely CONQUER. This preview is proof positive of that. YIKES!!!",
          "score": 91,
          "created_utc": "2025-12-24 18:11:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvr7mk8",
              "author": "BankruptKun",
              "text": "it does feel like it but the market is bit of in consolidation for both 3D artist and Digital field of  work cause of the ai boom,  \nthis year 2025 i was totally unemployed cause the market was dry, the clients who paid me to rig/model/texture would never ring me back and studios contracts wont pay the rent, this year end i picked up ai, will see if my work bears fruit or gotta find a different route. Im now chasing quality over quantity.   \nSo far feedback looks good, i will try to see how to generate a revenue now if its good enough as standard.",
              "score": 42,
              "created_utc": "2025-12-24 18:29:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvrzq17",
                  "author": "Dirty_Dragons",
                  "text": "It's unfortunate you're in this situation now.\n\nI have no experience in 3D animation and the only thing I think I know is that it can take a very long time to render anything and requires very powerful hardware.\n\nKnowing how to use a tool that saves time and money while making a quality product is a very important skill.\n\nWe're at the start of a new technological shift. There is definitely money to be made if you can catch the wave.",
                  "score": 11,
                  "created_utc": "2025-12-24 21:10:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvtdjor",
                  "author": "i_have_chosen_a_name",
                  "text": "So far AI has only shown it can win in quantity over quality. \n\nBut we have not seen somebody make something so good and then claim that without AI it would be less good. Not claim that without AI it would be more expensive or take more man hours. No, claim that without AI it would not have been possible to make it.\n\nI hope that is okay, and I hope that means that people will give up quantity and start aiming for quality.\n\nHigher quality at the same cost, maybe higher quality at a slightly lower cost.\n\nI don't know but we will find out. All these models are so new and they are being developed at such high speeds, it's normal that the tool makers and the workflow makers are just waiting till it slows down a bit.\n\nAny time spend in building tools right now or a workflow might be wasted when the next model comes out that does things slightly differently but better and then you have to rebuild again.\n\n\nThis explains why there aren't to many good AI tools for production yet. But in the next 5 years that will change. However in the next 5 years we will also find out the true resource cost of the better models, because right now all compute is subsidized. You might be using OpenAI sora for free, but it might very well cost them a 100 dollars in elecricity for 15 seconds of video. They know, we don't. \n\nBut with the opensource tools you do know. Hopefully within 5 years the opensource models will fully catch up with the big tech companies. \n\nRight now it's just slop time. However we might already once in a while see quality but we don't realize it was AI because the people that used it as one of their tools in their toolset wisely kept their mouth shut about their AI usage.\n\nJust like with CGI, you only notice when it's bad.",
                  "score": 4,
                  "created_utc": "2025-12-25 02:54:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvsf3tj",
                  "author": "lewdroid1",
                  "text": "I fear the AI bubble burst is around the corner. So much money is being poured into AI, and yet, folks can't make money if no one has money to spend, so having a dry employment market is not sustainable.",
                  "score": 4,
                  "created_utc": "2025-12-24 22:45:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvsn3cd",
                  "author": "Sensitive-Designer-6",
                  "text": "You could always make pornograms",
                  "score": 4,
                  "created_utc": "2025-12-24 23:39:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvs1n62",
              "author": "thelizardlarry",
              "text": "This is certainly magical, but I think what a lot of people donâ€™t get is that Creatives have clients who say things like â€œItâ€™s perfect, but change just thisâ€, and this is where GenAI is really frustrating. The control is getting better, but this wouldnâ€™t pass tech check in a real studio, and fixing it can become more of a problem than doing it the â€œtraditionalâ€ way. In a couple years this might be a whole different story.",
              "score": 13,
              "created_utc": "2025-12-24 21:21:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvs9794",
                  "author": "Kitchen_Interview371",
                  "text": "This is true. When people talk about the time that it takes to generate a video (eg, 50 seconds on a H200), theyâ€™re typically talking about a single generation. They donâ€™t talk about the fact that you need to do 50 iterations and review them all to find one that mostly matches the clientâ€™s specifications.\n\nBut itâ€™s getting betterâ€¦",
                  "score": 5,
                  "created_utc": "2025-12-24 22:07:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvs99r6",
                  "author": "kinetic_text",
                  "text": "Agree. Lack of ability to edit and control are maddening. The tradeoff is that the speed completely new outputs...and the baseline visual and movement quality are astonishing",
                  "score": 2,
                  "created_utc": "2025-12-24 22:07:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvrdhku",
              "author": "hurrdurrimanaccount",
              "text": "but.. this isn't even good in any way? it's 1girl, standing, doing stretches.\nno one cares about that.",
              "score": -12,
              "created_utc": "2025-12-24 19:00:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvrhn4d",
                  "author": "steelow_g",
                  "text": "Change the girl to any character and itâ€™s usable anywhere? Everyone cares about that. Sit down.",
                  "score": 6,
                  "created_utc": "2025-12-24 19:24:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvrfbh8",
                  "author": "kinetic_text",
                  "text": "This isn't good? Are you trying to bait me? I think it's outstanding. The render quality, the features of the girl are absolutely ideal. Her movement might be a little floaty, but convincing enough. And visually is in that zone where I genuinely can't tell if it's generative video or a hyper realistic 3D render. Most of what we're seeing these days is a tech demo. But as a creative community we are definitely headed to lighter, faster, better productions. It's exciting and scary, everything that's probably all been said before.",
                  "score": 8,
                  "created_utc": "2025-12-24 19:10:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvrhxsm",
                  "author": "eggs-benedryl",
                  "text": "You not liking the subject doesn't mean it isn't well done... Like obviously",
                  "score": 7,
                  "created_utc": "2025-12-24 19:25:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvr74kz",
          "author": "tofuchrispy",
          "text": "The movements are a bit too perfect if you are asking specifically if it looks like a real human. I donâ€™t assume you are going exactly for human movement with slight imperfections and jitter in the movement. But rather an idealized version that can be more defined as an artistic way.",
          "score": 11,
          "created_utc": "2025-12-24 18:26:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvtzs8h",
              "author": "Mestizo3",
              "text": "Yeah this has the worst of both worlds tbh. It looks less real than pure AI videos. The movement is uncanny valley, the skin doesn't feel real, no wonder this artist couldn't find work.",
              "score": -1,
              "created_utc": "2025-12-25 05:55:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvvyg95",
                  "author": "Kaiel2",
                  "text": "U ok bro?",
                  "score": 2,
                  "created_utc": "2025-12-25 16:22:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvrqapr",
              "author": "Elzzie",
              "text": "I agree, somehow is feels a bit creepy to me. Not sure why though.",
              "score": -2,
              "created_utc": "2025-12-24 20:14:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvtfggu",
                  "author": "Paxelic",
                  "text": "Imperfections make perfect.\n\nI'm sure they'll eventually use a noise scatter within the movements to generate some sort of randomness. Similar to how others defeat uncanny valley. It's been done before, just a matter of when and how not if.",
                  "score": 2,
                  "created_utc": "2025-12-25 03:09:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvr3g3t",
          "author": "ctimmermans",
          "text": "You clearly have experience",
          "score": 34,
          "created_utc": "2025-12-24 18:06:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvr3zut",
              "author": "BankruptKun",
              "text": "thanks, so people are liking this. which means i guess i will keep at this style.",
              "score": 24,
              "created_utc": "2025-12-24 18:09:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvra3xh",
          "author": "Noeyiax",
          "text": "![gif](giphy|nuRXXyy020kta)",
          "score": 18,
          "created_utc": "2025-12-24 18:42:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrpg8u",
          "author": "brucebay",
          "text": "that is how Gen AI should be used, help your vision come through using your experience and skills. not a toll on your future   but a tool for your future. well done.",
          "score": 9,
          "created_utc": "2025-12-24 20:09:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvruj0t",
              "author": "BankruptKun",
              "text": "thank you.",
              "score": 3,
              "created_utc": "2025-12-24 20:39:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrs68p",
          "author": "TheFrontierzman",
          "text": "We get it. You like armpits.",
          "score": 14,
          "created_utc": "2025-12-24 20:25:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrkq8s",
          "author": "fantafrags",
          "text": "Sideboob ftw",
          "score": 8,
          "created_utc": "2025-12-24 19:41:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvr9k40",
          "author": "Clean_Mastodon5285",
          "text": "Very impressive, reminds me of a Final Fantasy  characters. I see a lot of money in your future.",
          "score": 5,
          "created_utc": "2025-12-24 18:39:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvune5n",
          "author": "Slight_Expression_73",
          "text": "AI armpits is the new trend?",
          "score": 6,
          "created_utc": "2025-12-25 10:00:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrojpe",
          "author": "daanpol",
          "text": "3D animator here as well. I did the same thing a while back and your workflow can do a lot! This is a very crudely animated woman that is spiced up with a layer of Ai. The original render looks like a gta IV character. It's such a boost to get to the right results. I used to have to hand draw SubSurfaceScattering maps like crazy, use a renderfarm, use all kinds of post process techniques to get the colorspace and the color terminator on the skin justttt rightttt. Not anymore, just plop it in comfy and 10 minutes later out rolls 4k realism that's pretty damn consistent if you use a character and style lora.\n\nhttps://preview.redd.it/uvzxqi54k79g1.jpeg?width=2048&format=pjpg&auto=webp&s=1b25dedade35b8a501d84eeb6c8a931654a67dc2",
          "score": 5,
          "created_utc": "2025-12-24 20:03:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrud8m",
              "author": "BankruptKun",
              "text": "lora is best suited for 3d renders to be fixed, i think so too, and thats what i am trying to make but sometimes there are issue with the moving poses is all but for still images LORAs are 3D profession'ss best friend.",
              "score": 3,
              "created_utc": "2025-12-24 20:38:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvs34kv",
                  "author": "daanpol",
                  "text": "Yea the consistency is really getting there. I am experimenting a lot with SCAIL at the moment and it is making character animation perfectly easy. I love that it is unlocking more creativity for me, I am less encumbered by huge technical boundaries (like owning a freaking motioncapture studio and face rig) and am just able to create now.",
                  "score": 2,
                  "created_utc": "2025-12-24 21:30:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvr35ht",
          "author": "SukaYebana",
          "text": "why she hot",
          "score": 15,
          "created_utc": "2025-12-24 18:05:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvr44ir",
              "author": "New-Camp2105",
              "text": "Bro she's on fire.",
              "score": 12,
              "created_utc": "2025-12-24 18:10:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvrovoi",
              "author": "asdf_lord",
              "text": "delicious armpits",
              "score": 9,
              "created_utc": "2025-12-24 20:05:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvvzcdw",
                  "author": "bunaciunea_lumii",
                  "text": "would lick them, not gonna lie",
                  "score": 1,
                  "created_utc": "2025-12-25 16:28:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvr5z8k",
          "author": "Direct_Turn_1484",
          "text": "I know very little of the animation industry, but man this looks very close to having very realistic humans in VR and games. More than we have now, because itâ€™s getting close, but this feels like the next jump.",
          "score": 5,
          "created_utc": "2025-12-24 18:20:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuiqpu",
          "author": "thesilversurfer_213",
          "text": "Armpit fetish?",
          "score": 3,
          "created_utc": "2025-12-25 09:09:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvs296h",
          "author": "RainManCZE",
          "text": "https://preview.redd.it/kduoh2c1z79g1.jpeg?width=320&format=pjpg&auto=webp&s=8028071d6340dc3240afa9ef7eefb1f3c6fcfa1a",
          "score": 9,
          "created_utc": "2025-12-24 21:25:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvr7hci",
          "author": "NetimLabs",
          "text": "It struggles a bit with keeping the complex texture of her clothes.\nYou can see the artifacts when she moves too fast.\n\nThe movements are great, albeit a bit slow.",
          "score": 3,
          "created_utc": "2025-12-24 18:28:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvr7y5z",
          "author": "henk717",
          "text": "Something does give me that 3D character vibe from it, but at the same time it looks photorealistic.  \nTried looking really hard if I could pinpoint why I have that opinion and I think I got it.  \nWith you coming from a 3D character background your basis is the kind of character that would look really good in a video game and is also budget friendly to render with the typical 3D character facial structures. And then converted to look lifelike.\n\nMaybe its because 3D is in your post, but its like my brain picks up the japanese RPG character / this is samus kinda vibe from the original model since its such a common design in games. Theres a subtle pattern to it that stands out due to how designed she feels.\n\nSo i'd actually encourage you to try and explore making the 3D model less perfect or less 3D. Maybe you can blend it in with a reference photo to add some realism to the AI.",
          "score": 3,
          "created_utc": "2025-12-24 18:31:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvr9v00",
              "author": "BankruptKun",
              "text": "thanks for the critique. you nailed the 'jrpg' vibe , that definitely comes from my heavy reliance on the 3d base of the character model.\n\nfor example, i use the 3d reference mostly for control. if i just prompt \"make the girl sit,\" the ai hallucinates random anatomy. but using the 3d model gives me the exact pose i need.\n\nso the workflow is: 3d pose -> render -> refine in comfyui with custom loras.\n\ni agree it looks too \"perfect\" right now, but i'm intentionally leaning into that 3d look to keep the character consistent. whenever i try to make it too messy/realistic, the video stability falls apart. still trying to find the balance.",
              "score": 3,
              "created_utc": "2025-12-24 18:41:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrhe4x",
          "author": "Silent_Ad9624",
          "text": "Congratulations! I'm not an expert, but I think it is pretty good.",
          "score": 3,
          "created_utc": "2025-12-24 19:22:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvssfb1",
          "author": "DeviousCham",
          "text": "I definitely get \"high quality final-fantasy like  character model\" rather than \"that's a human\"",
          "score": 3,
          "created_utc": "2025-12-25 00:17:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvr31nf",
          "author": "zekuden",
          "text": "This is cool, what model did you train a Lora on?",
          "score": 4,
          "created_utc": "2025-12-24 18:04:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvr65ta",
              "author": "Julzjuice123",
              "text": "Also curious about that.",
              "score": 2,
              "created_utc": "2025-12-24 18:21:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvsghoe",
              "author": "BankruptKun",
              "text": "to answer the question, in simple form i create and pose with my 3d model, then throw my lora which i trained for 4k realistic texture and hair generation on top, i am learing myself u can say this is one of the products of experiment.  but its relatively simple if u have a data set of a character in 3d format.",
              "score": 2,
              "created_utc": "2025-12-24 22:54:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvtvt4q",
                  "author": "Fun-Photo-4505",
                  "text": "I think they mean't what model did you train on, as in Wan 2.1, wan 2.2, Zimage etc",
                  "score": 2,
                  "created_utc": "2025-12-25 05:20:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvw61ws",
                  "author": "Current_Cellist_4533",
                  "text": "Lol your answers sound A LOT like gatekeeping to be honest",
                  "score": 1,
                  "created_utc": "2025-12-25 17:08:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvr6gdj",
          "author": "Essar",
          "text": "I can't tell, because you have almost no variation in action or appearance in your shots. She's always wearing the same clothes and doing absolutely nothing except occasionally showing off her armpits.",
          "score": 5,
          "created_utc": "2025-12-24 18:22:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrc7vd",
              "author": "Thesleepingjay",
              "text": "The consistency of the appearance is probably the most impressive part.",
              "score": 3,
              "created_utc": "2025-12-24 18:53:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvrstl9",
                  "author": "Essar",
                  "text": "There are a dozen ways to get consistency like this, because nothing is happening. If she was shown in different scenarios, doing different things with different backgrounds, then that would be interesting.\n\n  \nConsistency is difficult because not EVERYTHING should be consistent. You want the person to be consistent, not the place, not the clothes and not the pose.",
                  "score": 4,
                  "created_utc": "2025-12-24 20:28:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvr5xuv",
          "author": "mekkula",
          "text": "Very nice. Is the dress baked into the LoRA, or will it work with a differend dress?",
          "score": 2,
          "created_utc": "2025-12-24 18:20:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrea45",
              "author": "BankruptKun",
              "text": "this was a test, in honestly she can change cloths but i am facing issue with her hair as the lighting and reflection is bit off if i change the room color and cloth type. its issue with my personalised lora.",
              "score": 1,
              "created_utc": "2025-12-24 19:05:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvr7lzb",
          "author": "Trinityofwar",
          "text": "What GPU are you using?",
          "score": 2,
          "created_utc": "2025-12-24 18:29:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvreicx",
              "author": "BankruptKun",
              "text": "i got a titan x maxwell, to render i use [vast.ai](http://vast.ai)",
              "score": 3,
              "created_utc": "2025-12-24 19:06:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvskj4z",
                  "author": "Trinityofwar",
                  "text": "Nice. I would love it if you shared your workflow.",
                  "score": 1,
                  "created_utc": "2025-12-24 23:21:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvr7qjg",
          "author": "EmotionalSprinkles57",
          "text": "What kind of 3d animator are you?",
          "score": 2,
          "created_utc": "2025-12-24 18:29:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrerbu",
              "author": "BankruptKun",
              "text": "who spends fixing topology cause client wants iteration for 30th time for free.",
              "score": 5,
              "created_utc": "2025-12-24 19:07:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvr7wp8",
          "author": "Swimming_Dragonfly72",
          "text": "What is the approximate pipeline? \n\n I guess it textured 3D model -> AI img2img concept ; 3D animation to wan animate? What model do you use?\n\nHow it looks in high-dynamic scenes like actions fighting/running?",
          "score": 2,
          "created_utc": "2025-12-24 18:30:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrfvrg",
              "author": "BankruptKun",
              "text": "pipeline is roughly: 3d model -> pose -> feed ai reference shots + skin texture -> refine w/ custom lora.\n\nno wan used yet. this is a custom mix i'm hacking together. honestly, the pipeline is a bit constrained because i'm running an ancient titan x maxwell at home. i have to rely on cloud rendering, so i try to keep the workflow lightweight to save money.\n\nhigh dynamic scenes are a nightmare right now. it gets very glitchy. unless the 3d pose reference is perfect, the hair and cloth consistency shatters instantly. even when i use 3d meshes for the clothes to ground it, the ai finds new ways to glitch. that's why i kept this one front-facingâ€”turning angles breaks the illusion immediately",
              "score": 5,
              "created_utc": "2025-12-24 19:14:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvr8sb9",
          "author": "Distinct-Question-16",
          "text": "(Im not a 3d animator) She looks perfect but AI is playing tricks with the opera glove material and probably the dress material around neck. Sometimes the material is soft - and you could attribute this to motion blur on moves but this isnt at all true - because in some frames she stops, and in a moment  the material comes to be stripped vertically and sharp again.\n\nOh theres a part where some long hair just stops and she reverses rotation around it, it feels physically impossible..\n\nHowever this is just noticeable i think because you're asking for it, otherwise I wouldnt see anything wrong.",
          "score": 2,
          "created_utc": "2025-12-24 18:35:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrg9ym",
              "author": "BankruptKun",
              "text": "what you pointed out is true, i generally dont do too much movement, i do skin renders , there are noticeable glitches as u described specially with hair, when i have to create video renders, this is because of my current lora my pipeline is not perfect.",
              "score": 1,
              "created_utc": "2025-12-24 19:16:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvr9bak",
          "author": "shulgin11",
          "text": "Well we certainly have similar tastes haha. Great job man would love to see more",
          "score": 2,
          "created_utc": "2025-12-24 18:38:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvra9zs",
          "author": "Canadian_Border_Czar",
          "text": "Did you use AI to generate the movement or is that 3D animation?Â \n\n\nNot sure if your hardware can handle it but it needs a bit more overlap when interpolating frames. At 16s you can see the hair \"blow back\", then it kind of floats there and her shoulder moves back to it.\n\n\nI may be wrong, but IMO this means it is no longer considering why the hair was blown back and just working with it.Â \n\n\nAnyways, thanks for the armpits... er I mean cool video. Plausible deniability is good when Taylor finally sues everyone.",
          "score": 2,
          "created_utc": "2025-12-24 18:43:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrbdvh",
              "author": "BankruptKun",
              "text": "lol, thanks.\n\ni actually have to rent a gpu server for this. at home i have an ancient titan x maxwell, so i can't render these heavy workflows locally.\n\nbecause of the cloud costs, i'm capped at 6 seconds max for now. i kinda burn through my budget just re-iterating frames for now. but there are several issues that need fix, its not uncanny from the feedback i got but has that 3D lockin vibe.",
              "score": 2,
              "created_utc": "2025-12-24 18:49:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrgx7i",
          "author": "Ubrhelm",
          "text": "Nice.Can you show a render of the character before using the ui?",
          "score": 2,
          "created_utc": "2025-12-24 19:19:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvri0bg",
              "author": "BankruptKun",
              "text": "https://preview.redd.it/t9uqzb2sd79g1.png?width=535&format=png&auto=webp&s=486177171998a25568c5c280b49c5ddc987cc52f\n\nim 3months in, i do not have the best pipeline to show, but those who are curious i use the 3D model as base then rifine with LORA.",
              "score": 8,
              "created_utc": "2025-12-24 19:26:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvriqvi",
                  "author": "Ty_Lee98",
                  "text": "Wow these pits are GREAT.",
                  "score": 4,
                  "created_utc": "2025-12-24 19:30:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvwgzb2",
                  "author": "starfries",
                  "text": "Wait this also looks incredible though.",
                  "score": 1,
                  "created_utc": "2025-12-25 18:13:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvrj1wl",
          "author": "four_clover_leaves",
          "text": "Hey, itâ€™s amazing, well done. What models did you use for video generation and image generation?\n\nI see you mentioned Qwen, but Qwen doesnâ€™t usually have that realistic look, so I assume you used refinement models. What models, apart from Qwen and custom LoRa for skin texture, did you use, if itâ€™s not a secret? ðŸ™‚",
          "score": 2,
          "created_utc": "2025-12-24 19:32:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrjbgy",
          "author": "roger_ducky",
          "text": "Your advantage is youâ€™re already great at rigging. Which means you have much finer control of poses and movement than 90% of the hobbyists.\n\nBeing able to generate character LoRAs via the models is also a â€œshortcutâ€ people canâ€™t typically do.\n\nIf youâ€™re worried about lighting, maybe use same character in different labeled lighting to help generalize the LoRA?",
          "score": 2,
          "created_utc": "2025-12-24 19:33:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrlfn4",
          "author": "zombiecorp",
          "text": "Amazing! I love seeing 3D used as inout for AI. Itâ€™s a complementary match. Hope to see more of your work.",
          "score": 2,
          "created_utc": "2025-12-24 19:45:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvroa7v",
              "author": "BankruptKun",
              "text": "https://preview.redd.it/0x5sxo7tj79g1.png?width=1185&format=png&auto=webp&s=c0af5daa66833cece6c06a3c5b713b37e72c75f8\n\nto grasp the simplicity of workflow just think of 3D model used as guideline or holding hands to generate trained lora on top of with+ 4k hyper realistic Texture collection to boost the final output.",
              "score": 2,
              "created_utc": "2025-12-24 20:02:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvrx8ts",
                  "author": "zombiecorp",
                  "text": "Very cool",
                  "score": 1,
                  "created_utc": "2025-12-24 20:55:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvroozj",
          "author": "gunthersnazzy",
          "text": "Too tier costume, my freak!",
          "score": 2,
          "created_utc": "2025-12-24 20:04:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrpffu",
              "author": "BankruptKun",
              "text": "this outfit was trending on twitter, often for gacha game characters, went with it cause it had that tease shot for skin texture.",
              "score": 2,
              "created_utc": "2025-12-24 20:08:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrqffj",
          "author": "Larmor77",
          "text": "![gif](giphy|1yMvhR4M47Okw4n8tt)",
          "score": 2,
          "created_utc": "2025-12-24 20:14:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrtlah",
          "author": "Brodieboyy",
          "text": "That's a lot of armpit shots....\n\n![gif](giphy|QxcSqRe0nllClKLMDn)",
          "score": 2,
          "created_utc": "2025-12-24 20:33:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrw6sm",
          "author": "astorasword",
          "text": "Love the character, as an amateur myself with no knowledge on this area at all and just eye balling it I feel I must learn to do this at least the basics",
          "score": 2,
          "created_utc": "2025-12-24 20:49:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvs3eiv",
          "author": "CrapoCrapo25",
          "text": "Eyebrows never moved.",
          "score": 2,
          "created_utc": "2025-12-24 21:32:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvs43v5",
              "author": "BankruptKun",
              "text": "yep, its bugged as of now WIP, 3d models under the hood so have to keep  them still so hair renders properly the  personalized LORA i use on top of my 3d model has some issue with the hair and eyebros overlapping.",
              "score": 2,
              "created_utc": "2025-12-24 21:36:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvs4xbt",
          "author": "Desperate-Grocery-53",
          "text": "Who would have thought, a real artist picks up AI and results are much better than all the slob. Well done!",
          "score": 2,
          "created_utc": "2025-12-24 21:41:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvs6ncm",
          "author": "CyberHaxer",
          "text": "If the data is trained on certain objects/models it will stay consistent. If not, it will just guess and forget if you do one 360 rotation.",
          "score": 2,
          "created_utc": "2025-12-24 21:51:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvscfhm",
          "author": "darktaylor93",
          "text": "This account started off as 3D but and started incorporating AI.  Honestly the 3D work was already in the top 1% but adding AI didn't hurt.\n\nhttps://www.tiktok.com/@monna_haddid_official?_r=1&_t=ZS-92V4rl4b9h2",
          "score": 2,
          "created_utc": "2025-12-24 22:27:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvsfguy",
              "author": "BankruptKun",
              "text": "seems indeed few  people have started to blend the workflow with 3D&Ai, i picked up ai cause i dont have super great hardware myself im on a maxwell artitecture GPU, i use a decade old server card with some fixed buget on cloud render, thus to save cost effectively i thought \"what if i use ai to render my 3d models\", so the idea seems to be picking up for a better cause.",
              "score": 1,
              "created_utc": "2025-12-24 22:47:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvsoexe",
          "author": "bnrt1111",
          "text": "Hair is  a bit stiff, and the movements are too perfect with no speed ups and slow downs",
          "score": 2,
          "created_utc": "2025-12-24 23:49:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsxzo1",
          "author": "Radiant_Abalone4041",
          "text": "\\>skin: i feed skin texture references from my offline library (i have about 20tb of hyperrealistic texture maps i collected).\n\nDoes this mean you tell Qwen Image Edit or Nano Banana to replace the texture with a reference texture?",
          "score": 2,
          "created_utc": "2025-12-25 00:56:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvt3ssr",
          "author": "-crepuscular-",
          "text": "I'm surprised by all the comments saying she looks real.  She doesn't look real to me at all.  There are some obvious problems like her hair being made of relatively thick, even strips on her head, but her face is just uncanny valley territory and I can't put my finger on why.\n\nShe looks like a video game character, but a very advanced one.",
          "score": 2,
          "created_utc": "2025-12-25 01:40:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvxlccm",
              "author": "HeftyCompetition9218",
              "text": "Humans tend to have extremely subtle communication in their eyes that this AI doesnâ€™t have. I found this performance easier to watch than watching a human perform similarly due to this.",
              "score": 1,
              "created_utc": "2025-12-25 22:15:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvthny7",
          "author": "Crierlon",
          "text": "You are better off using AI in CGI for production workloads for now.\n\nThey not have auto rigging and itâ€™s only getting better.",
          "score": 2,
          "created_utc": "2025-12-25 03:26:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvu7ehn",
          "author": "dictionizzle",
          "text": "I am an AI enthusiast, but most stuff I have seen feels like AI slop. I cannot imagine what we will get when AI works with specialists.",
          "score": 2,
          "created_utc": "2025-12-25 07:08:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvxzil2",
          "author": "Simple_Duty_4441",
          "text": "\"ai art is shitty.\"\n\nthe shitty art in question:",
          "score": 2,
          "created_utc": "2025-12-25 23:47:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0icuf",
          "author": "Matheesha_BW",
          "text": "This is rare. An artist who use AI as a tool like it's intend to be. not like all other artist who can't even stand the word \"AI\". Lol\n\nAmazing work",
          "score": 2,
          "created_utc": "2025-12-26 12:17:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3eqk0",
          "author": "rz2k",
          "text": "Similar workflow is currently used in CyberAgent but instead of custom 3D models they scan real people and then feed into AIs. https://www.cyberagent.co.jp/en/news/detail/id=26503\n\nThis is used in ads and film production.",
          "score": 2,
          "created_utc": "2025-12-26 22:17:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3xhbq",
              "author": "BankruptKun",
              "text": "my current workflow is yes similar, but i use a bit of long lazy method, they look more professional and they are literally using thousand of cameras and proper Photogrammetry tech.",
              "score": 1,
              "created_utc": "2025-12-27 00:08:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw4ipye",
          "author": "BankruptKun",
          "text": "Posting the workflow of what i am doing here:  \n  \n[https://www.reddit.com/r/StableDiffusion/comments/1pwlt52/former\\_3d\\_animator\\_here\\_again\\_clearing\\_up\\_some/](https://www.reddit.com/r/StableDiffusion/comments/1pwlt52/former_3d_animator_here_again_clearing_up_some/)",
          "score": 2,
          "created_utc": "2025-12-27 02:20:20",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nw501ct",
          "author": "SolidStudy5645",
          "text": "I think I get armpit guys now",
          "score": 2,
          "created_utc": "2025-12-27 04:15:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw5ulft",
              "author": "omphteliba",
              "text": "Same.",
              "score": 1,
              "created_utc": "2025-12-27 08:33:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwu1y50",
          "author": "z3speed4me",
          "text": "The side boob is consistently consistent",
          "score": 2,
          "created_utc": "2025-12-31 01:03:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrdvtd",
          "author": "hurrdurrimanaccount",
          "text": "it's..okay? i don't get what the other commenters see, thirst trap aside.",
          "score": 3,
          "created_utc": "2025-12-24 19:03:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrefn4",
          "author": "Slight_Tone_2188",
          "text": "How would my wife compete with this now!?",
          "score": 3,
          "created_utc": "2025-12-24 19:06:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvsg6hy",
              "author": "Ok-Application-8747",
              "text": "Same way you compete with Jungkook and Alexander Skaarsgard my guy",
              "score": 1,
              "created_utc": "2025-12-24 22:52:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvxkiu9",
              "author": "HeftyCompetition9218",
              "text": "Same way a pane of glass competes with a human being. Are you a pane of glass? If you are youâ€™re right, what on earth will you do with your wife.",
              "score": 1,
              "created_utc": "2025-12-25 22:10:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrierj",
          "author": "nakabra",
          "text": "\"Former\" 3d animator?",
          "score": 2,
          "created_utc": "2025-12-24 19:28:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvr6ex8",
          "author": "uniquelyavailable",
          "text": "Outstanding quality. I could never make anything like this, leaves me awestruck.",
          "score": 3,
          "created_utc": "2025-12-24 18:22:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrlps7",
          "author": "Dull_Wrongdoer_3017",
          "text": "![gif](giphy|l0HUg6Ypas42ubkXu|downsized)",
          "score": 2,
          "created_utc": "2025-12-24 19:47:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsbyyj",
          "author": "SuperGeniusWEC",
          "text": "The answer is no.  Working with and testing new models on an almost daily/weekly basis I can tell you that if you first hand that if you think you'll have any level of control, and by that I mean consistency (which includes adding random artifacts, fingers, backgrounds, changing color schemes ad infinitum) as one had in previous animation you're in for a big helping of frustration - and might grind the enamel off of your teeth in the process. Don't be fooled by demos - they're all cooked to look great and get people excited about a breakthrough (maybe THIS time it's the real deal!?) The reality is that you can't get output even close to what they're showing in their demos - that's because these models only work on very narrow sets of circumstances",
          "score": 2,
          "created_utc": "2025-12-24 22:24:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsrrr1",
          "author": "Substantial_Match268",
          "text": "OF is cooked",
          "score": 3,
          "created_utc": "2025-12-25 00:12:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvsu8qf",
              "author": "BankruptKun",
              "text": "ðŸ˜‚",
              "score": 1,
              "created_utc": "2025-12-25 00:29:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvr6zeg",
          "author": "Sioluishere",
          "text": "nose gives it away, otherwise, you can say this is hyper-realistic, especially in some angle",
          "score": 2,
          "created_utc": "2025-12-24 18:25:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvusopi",
          "author": "Flothrudawind",
          "text": "I'm really sat here asking myself \"do I have an armpit fetish\"?",
          "score": 2,
          "created_utc": "2025-12-25 10:58:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuvdmk",
          "author": "thefringeseanmachine",
          "text": "speaking as a consumer, it took me about 2.5 seconds to realize this was AI and clocked out. the idea of AI should be to spur your creativity, not finish your work for you. this feels like your parents proof-read your paper.",
          "score": 2,
          "created_utc": "2025-12-25 11:27:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvv00ta",
          "author": "AdPristine782",
          "text": "Can I smell your armpit?",
          "score": 2,
          "created_utc": "2025-12-25 12:14:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrgw7f",
          "author": "Jacks_Half_Moustache",
          "text": "Ah yes, quality AI, a blonde woman with boobs. I hate this sub with a fucking passion.",
          "score": 2,
          "created_utc": "2025-12-24 19:19:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw5cge9",
              "author": "Sploonbabaguuse",
              "text": "Feel free to leave",
              "score": 1,
              "created_utc": "2025-12-27 05:48:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvr5cei",
          "author": "ResponsibleKey1053",
          "text": "Excellent! Looks more real than 3d on my phone, I'll have to check it out a full size. \n\nAnd for god sake man state your models used!",
          "score": 2,
          "created_utc": "2025-12-24 18:16:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrdjvz",
              "author": "BankruptKun",
              "text": "sorry im like 3 months in, its custom LORA mix with my 10tb to 20tb of skin texture , i dont exactly have a pipeline yet . but to keep it simple \n\nblender 3d model-->Pose render--> feed to my comfui->> generate variation of poses--> refine....and more rifine.",
              "score": 3,
              "created_utc": "2025-12-24 19:01:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvrepf1",
                  "author": "ResponsibleKey1053",
                  "text": "Ahhh I'm with you! Cool beans! \nI've barely looked at 3d stuff, so here's a stupid question, where's a reasonable starting point for getting into 3d.\nIt's been yonks since I played with blender or any 3d thing, I think it was probably back when Garry's mod was just a mod (doubt many remember being a minge) and I made a tin of heinz baked beans skin for a grenade.",
                  "score": 2,
                  "created_utc": "2025-12-24 19:07:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvr3jwu",
          "author": "Sea-Sail-2594",
          "text": "Me like",
          "score": 1,
          "created_utc": "2025-12-24 18:07:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvr7nu2",
          "author": "morganational",
          "text": "Very nice",
          "score": 1,
          "created_utc": "2025-12-24 18:29:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrgb6s",
          "author": "hungrybularia",
          "text": "It looks pretty good, but still has that slowness / Unnatural smoothness to it that most AI vids seem to have.  I'm guessing you use wan 2.2.  I'd recommend using the keyword 'doubletime' (I think it was this keyword) in your prompt to speed up the videos that are generated.",
          "score": 1,
          "created_utc": "2025-12-24 19:16:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrizfj",
              "author": "BankruptKun",
              "text": "understood, im actually learning stuff myself noted this prompt, will test if this really works, tho my video was not from wan, its mix of many+3D model as base ref.",
              "score": 2,
              "created_utc": "2025-12-24 19:31:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvt0k4d",
                  "author": "hungrybularia",
                  "text": "Ah I see, I saw your other comments and from what I can tell you are generating the frames yourself.  Are you moving the 3d model in a blender animation or something and then using a screenshot of each animation frame within an img2img step? I'm curious how you got such good consistency without using a video generation model.",
                  "score": 2,
                  "created_utc": "2025-12-25 01:15:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvrioae",
          "author": "pk9417",
          "text": "This looks so great.",
          "score": 1,
          "created_utc": "2025-12-24 19:30:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrjlg8",
          "author": "omphteliba",
          "text": "Great idea to use your 3d knowledge with ai. And the quality is stunning in my eyes.",
          "score": 1,
          "created_utc": "2025-12-24 19:35:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrkonz",
          "author": "MajorCinamonBun",
          "text": "I didnâ€™t see anyone directly answer your questions so Iâ€™ll try. Yes she definitely moves like a human & well enough that I probably wouldnâ€™t care or tell unless keyed off that sheâ€™s AI. But knowing sheâ€™s Al the illusion does break a little since Iâ€™m more sensitive to it. Now Iâ€™m spotting that all her movements look too smooth and consistent, some of the facial expressions when she has her mouth open can look a little uncanny, and she looks a little stiff wrist when she waves. These are also being picky though because it does look amazing!",
          "score": 1,
          "created_utc": "2025-12-24 19:41:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrnz5l",
          "author": "BiliaryBob",
          "text": "Whatâ€™s the song name?",
          "score": 1,
          "created_utc": "2025-12-24 20:00:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwcrj3n",
              "author": "Flagada_Jones1",
              "text": "Ibuchim â€“ Christmas Eve. I know that feeling â€” the pain, the endless search â€” but itâ€™s finally over, my friend.",
              "score": 1,
              "created_utc": "2025-12-28 12:32:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvron4b",
          "author": "-lRexl-",
          "text": "Bruh...",
          "score": 1,
          "created_utc": "2025-12-24 20:04:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrrb04",
          "author": "Dann_Gerouss",
          "text": "Was I the only one who also ðŸ‘‹ðŸ» goodbye to the girl at the end of the video?",
          "score": 1,
          "created_utc": "2025-12-24 20:19:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrrckj",
          "author": "Euphoric-Pilot5810",
          "text": "Use crypotomattes to control segmentation basically turn generative AI into renderer while maintaining control of your movements in 3D",
          "score": 1,
          "created_utc": "2025-12-24 20:20:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrsm1p",
          "author": "foxdit",
          "text": "As someone who spends sometimes 8 hrs a day working on AI scenes, I'll say your quality is good (though demoing a girl posing on a grey background isn't giving me a ton to go off of). Natural motion and good interaction with environment is where I think expertise in the realm of realism shines. I will suggest if you haven't checked it out already, but since you can very easily control her poses with keyframe images, I recommend getting a good FFLF (first frame last frame) workflow. It helps immensely with getting proper motions and transitions.",
          "score": 1,
          "created_utc": "2025-12-24 20:27:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrtrki",
              "author": "BankruptKun",
              "text": "i am very new close to 3months, but thanks for this , i am taking notes for the pipeline. would give this a test.",
              "score": 1,
              "created_utc": "2025-12-24 20:34:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrtolt",
          "author": "reddit-369",
          "text": "she hot",
          "score": 1,
          "created_utc": "2025-12-24 20:34:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvruodk",
          "author": "-JuliusSeizure",
          "text": "damn...\n\nwhat was used for img2video? grok imagine or wan model or something else.",
          "score": 1,
          "created_utc": "2025-12-24 20:40:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrvm6k",
              "author": "BankruptKun",
              "text": "3d base render -> pose -> feed refence of 4k textures&hair - > refine,  \nvideo i used mix of many + my own custom LORAs , tbh but its still not good, im only 3 months in, my pipeline is far from basic even.",
              "score": 2,
              "created_utc": "2025-12-24 20:45:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvumxxu",
                  "author": "-JuliusSeizure",
                  "text": "nice. any plan to release this actual image2video comfyui workflow?",
                  "score": 1,
                  "created_utc": "2025-12-25 09:56:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvrvemh",
          "author": "MessageEquivalent347",
          "text": "Damn, looks pretty good!",
          "score": 1,
          "created_utc": "2025-12-24 20:44:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrw49q",
          "author": "Mahakurotsuchi",
          "text": "That looks divine",
          "score": 1,
          "created_utc": "2025-12-24 20:48:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvs4vak",
          "author": "Noiselexer",
          "text": "Hot",
          "score": 1,
          "created_utc": "2025-12-24 21:40:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvs7a43",
          "author": "Callumborn2",
          "text": "Face and hair looks not real but it's really getting there",
          "score": 1,
          "created_utc": "2025-12-24 21:55:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvs9ud3",
          "author": "threeshadows",
          "text": "Nice work. Iâ€™m seeing bits of hair fading in and out (crossfade?), a weird tuft of hair that sometimes sticks out unnaturally at her mid back and bangs seem a little too stable during head tilts. During some of the arm raises I see a similar effect where the armpit meets breast tissue (looks like a cross fade?). Sometimes the lighting and shadows on her face seem to shift in unnatural ways. Untrained eye here, just letting you know the parts that I noticed. Otherwise looks amazing!",
          "score": 1,
          "created_utc": "2025-12-24 22:11:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsbesl",
          "author": "superdariom",
          "text": "Looks pretty good to me. I'd be interested to hear more about the workflow for inspiration.",
          "score": 1,
          "created_utc": "2025-12-24 22:21:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsbh67",
          "author": "Martelius",
          "text": "I see the cultured man and I like it. If woman even better.",
          "score": 1,
          "created_utc": "2025-12-24 22:21:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsbpnm",
          "author": "Tall_East_9738",
          "text": "Drop the workflow, Iâ€˜ll take a look",
          "score": 1,
          "created_utc": "2025-12-24 22:23:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsc7pf",
          "author": "Kale-chips-of-lit",
          "text": "Very nice!",
          "score": 1,
          "created_utc": "2025-12-24 22:26:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvscsjl",
          "author": "Kairoblackxix",
          "text": "Looking like a dead or alive character",
          "score": 1,
          "created_utc": "2025-12-24 22:30:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvscxiv",
          "author": "no0neiv",
          "text": "Your buddies must hate you haha",
          "score": 1,
          "created_utc": "2025-12-24 22:30:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsdoqi",
          "author": "theswedishguy94",
          "text": "crazy accurate.",
          "score": 1,
          "created_utc": "2025-12-24 22:35:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvse3sj",
          "author": "Immediate_Source2979",
          "text": "you're gonna make it big man this is waay too good and ur not even on full power yet",
          "score": 1,
          "created_utc": "2025-12-24 22:38:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsf68z",
          "author": "neoravekandi",
          "text": "Impressive:)",
          "score": 1,
          "created_utc": "2025-12-24 22:45:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsf6kj",
          "author": "Short-Ideas010",
          "text": "I bet this was him moving... /s",
          "score": 1,
          "created_utc": "2025-12-24 22:45:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvshamp",
          "author": "ChoBaiDen",
          "text": "A little uncanny but not Tarkin level.",
          "score": 1,
          "created_utc": "2025-12-24 22:59:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvshy0q",
          "author": "Straight_Fish_704",
          "text": "I don't believe you are a 3D animator, you wouldn't be here after years of learning 3D animation.",
          "score": 1,
          "created_utc": "2025-12-24 23:04:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvskd1c",
              "author": "BankruptKun",
              "text": "yet i am here, i was only good in modelling and texturing, animating is a high clibar job but not everyone would get the pay to live out properly, tbh im testing, i do know this is not perfect but testing thus to see how good it really is.",
              "score": 1,
              "created_utc": "2025-12-24 23:20:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvslnok",
                  "author": "Straight_Fish_704",
                  "text": "Theres a problem with AI, no control. CGI has a lot of control, it is a lot of work.\n\nI only use AI for prototyping, never for release.",
                  "score": 1,
                  "created_utc": "2025-12-24 23:29:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvsi8uh",
          "author": "NookNookNook",
          "text": "You could probably sell the workflow.  Its that good.  I can't wait to see what you come up with once you're comfortable in the environment.",
          "score": 1,
          "created_utc": "2025-12-24 23:06:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvskxil",
              "author": "BankruptKun",
              "text": "workflow is actually a 3d model--> several simple pose-> refine & overlay (but the lora i have is 20TB data set used for 4K 3d skin texture which basically the ai reads and throws on top while i mixed it with some anime like style LORA.",
              "score": 1,
              "created_utc": "2025-12-24 23:24:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvslfma",
          "author": "Abba_Fiskbullar",
          "text": "Uncanny is thy valley...",
          "score": 1,
          "created_utc": "2025-12-24 23:28:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvspuu4",
          "author": "Perfect-Campaign9551",
          "text": "With models like Qwen image edit 2509 you don't even need to make a Lora anymore. The model is smart enough to know how to put your character into different clothes or scenes straight up",
          "score": 1,
          "created_utc": "2025-12-24 23:59:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvsr4su",
              "author": "BankruptKun",
              "text": "you could be right, but there's artefact issues atelast for me, i know some people are creating crazy flawless workflow, im just using basic 3D+ai cause i find it simple , its simpler for a noobs noob like me to learn.  \ni think qwen can do good but this needs time as more data-set builts up and model improves. Character consistency is hard if you use models like mine it has high rate of glitch, so thats why i stick to 3d for now, but your workflow suggestion is quicker than mine.",
              "score": 1,
              "created_utc": "2025-12-25 00:08:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvt5zn9",
          "author": "snowbirdnerd",
          "text": "Most artists I talk to still say AI tools do about 30% of the work but I'm thinking it's climbing fast.Â ",
          "score": 1,
          "created_utc": "2025-12-25 01:57:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvt6z95",
          "author": "sirdrewpalot",
          "text": "I can definitively tell this model was trained on women without armpit hair and side boob.",
          "score": 1,
          "created_utc": "2025-12-25 02:04:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvthda2",
          "author": "hey_i_have_questions",
          "text": "How does 20TB of skin textures translate into ConfyUI input? You mean you have a wide variety to select from?",
          "score": 1,
          "created_utc": "2025-12-25 03:24:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvto08u",
              "author": "BankruptKun",
              "text": "Yes, sorry for not explaining it properly at first. My library is organized into specific categories of collections:\n\nan example:\n\n0. Realism / 1. Hyper-realistic\n2. 3D CG / 3. Monotone & Chromatic\n4. Stylized Toons(anime and cartoon )/ 5. Flat textures\n\nI pick a base, then mix or layer them to strengthen a specific style. This iteration process takes 50 to 100 tries, requiring a lot of 'burning time,' patience, and cloud GPU budget.\nInitially, these were just video game textures for concept art, but Iâ€™ve been slowly curating and naming them as I define my own style. For this piece, I used an 'anime_hyper realistic' texture; these are 5k resolution and roughly 25mb each, which is why the library is so massive. Itâ€™s a lot of data, but itâ€™s how I find the specific look I'm chasing",
              "score": 3,
              "created_utc": "2025-12-25 04:16:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvtlhfi",
          "author": "tarnishedspiderz",
          "text": "I usually skip this part",
          "score": 1,
          "created_utc": "2025-12-25 03:56:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtmcc0",
          "author": "Tickomatick",
          "text": "I feel when the camera zooms in or moves fast in general, the space warps a little, like in typical AI videos",
          "score": 1,
          "created_utc": "2025-12-25 04:03:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtoy0q",
          "author": "Pullumpkin",
          "text": "would you please buy my armpit simulator?",
          "score": 1,
          "created_utc": "2025-12-25 04:23:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtrogc",
          "author": "thereallegend123",
          "text": "Former? Whyyyy",
          "score": 1,
          "created_utc": "2025-12-25 04:45:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtsou6",
          "author": "Wayward_Prometheus",
          "text": "Bro. Why does that look like a real person with super perfect tik tok makeup?",
          "score": 1,
          "created_utc": "2025-12-25 04:54:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtwhor",
          "author": "Informal_Storage_196",
          "text": "To be honest it looks better than video game worthy \nLike you can realistically make a dang good movie with that granted â€œvideo game worthyâ€ isnâ€™t like it used to be but still daaaang cool job dude. \nðŸ‘ðŸ¼",
          "score": 1,
          "created_utc": "2025-12-25 05:26:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtzdyu",
          "author": "persona64",
          "text": "Looks like AI to me due to some of the shimmer on the cloth materials, though this level of consistency impresses me a lot, a year ago something like this was pretty unthinkable",
          "score": 1,
          "created_utc": "2025-12-25 05:52:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvu0h97",
          "author": "-AwhWah-",
          "text": "botted the likes award. The most basic fucking AI genning I've ever seen, 3D usage involved or not, and then a bunch of socials with nothing going on, but sure enough asking for money ðŸ˜‚",
          "score": 1,
          "created_utc": "2025-12-25 06:02:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuh9nz",
          "author": "1aysays1",
          "text": "Reminds me of a woman version of Cloud Strife.",
          "score": 1,
          "created_utc": "2025-12-25 08:53:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuvw8m",
          "author": "jacqueszecanine",
          "text": "![gif](giphy|rdl9myRzL7lPr7knO0)",
          "score": 1,
          "created_utc": "2025-12-25 11:33:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuw14p",
          "author": "_rvrdev_",
          "text": "It's close but the problem I face is when I have to put a character like this into consistent environments and make them handle consistent props.\n\nIt would be cool if we can have a 3D editor (with basic low-poly models) where we can pose characters and arrange props and when rendering, it basically generates an AI image with specific LoRAs for characters and props, thereby achieving consistent characters, props and environments across generations.",
          "score": 1,
          "created_utc": "2025-12-25 11:34:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuwmtr",
          "author": "Ambitious_Brick_6866",
          "text": "I see the AI has been trained on Dove commericials.",
          "score": 1,
          "created_utc": "2025-12-25 11:40:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuzym1",
          "author": "MrM0dZ",
          "text": "Looks great, but considering you needed all of the above it sounds too much for small details\n\nAlso one thing I doubt AI is gonna fix is the heavy noise on moving things, remind me of Unreal 5 ghosting everywhere",
          "score": 1,
          "created_utc": "2025-12-25 12:13:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvv1pbw",
          "author": "MicrosoftExcel2016",
          "text": "She looks great but more like a very impressive video game graphics than a real video.",
          "score": 1,
          "created_utc": "2025-12-25 12:30:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvv4633",
          "author": "alexmmgjkkl",
          "text": "why did i even click it ?",
          "score": 1,
          "created_utc": "2025-12-25 12:52:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvgp64",
          "author": "AeonianGentleman",
          "text": "https://preview.redd.it/ke8i1gaq1d9g1.jpeg?width=1074&format=pjpg&auto=webp&s=2f97b2037210f3ca56086a14983f55558e75138e",
          "score": 1,
          "created_utc": "2025-12-25 14:29:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvzvke",
          "author": "oFcAsHeEp",
          "text": "I feel like, as with most AI video, her face changes several times every time she rotates her head, and my brain is working overtime trying to convince me it is consistent.\n\nMy brain:\n\n![gif](giphy|NTur7XlVDUdqM)\n\nMy eyes: What the hell man?\n\nBut all in all, looking good ðŸ‘",
          "score": 1,
          "created_utc": "2025-12-25 16:31:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvwbr1b",
          "author": "zerozeroZiilch",
          "text": "This is damn good",
          "score": 1,
          "created_utc": "2025-12-25 17:42:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvweyq8",
          "author": "Pres_MountDewCamacho",
          "text": "Something tells me that you're into sweaters and armpits.",
          "score": 1,
          "created_utc": "2025-12-25 18:01:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvwk7ry",
          "author": "Bunktavious",
          "text": "Weird. In the opening still and when she's looking straight on, its pretty uncanny valley. Yet we she starts turning to her profile, it actually looks really good.",
          "score": 1,
          "created_utc": "2025-12-25 18:31:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvwksje",
          "author": "AlienCatStar",
          "text": "As a 3D animator my self, yes, itâ€™s getting there. But it still needs the trained eye to fix any imperfections",
          "score": 1,
          "created_utc": "2025-12-25 18:35:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvwlrx2",
          "author": "iamkarrrrrrl",
          "text": "Thinking 3d animation experience will get you anywhere faster with promoting is a mistake bud",
          "score": 1,
          "created_utc": "2025-12-25 18:40:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvwotlg",
          "author": "Mental-Debate-289",
          "text": "What type of rig you have to animate at this level? How long does a single clip take to produce?",
          "score": 1,
          "created_utc": "2025-12-25 18:58:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvwvu9n",
          "author": "dCLCp",
          "text": "This is on the good side of still being inside the uncanny valley. It isn't unpleasant, it is realistic, but it isn't real.",
          "score": 1,
          "created_utc": "2025-12-25 19:39:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvwwqyf",
          "author": "alexblattner",
          "text": "It will be when I make it",
          "score": 1,
          "created_utc": "2025-12-25 19:45:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvx602l",
          "author": "latch4",
          "text": "It looks really good, it does not look real but does not look uncanny, maybe I'm just cooked because i look at ai images all the time so take it with a grain of salt. \n\nThe hair is noticeably stiff. Which like generally when i see 3d models the hair looks way more stiff than this or goes too far in the fluidity so not bad, just the detail that stands out the most to me when trying to be critical.",
          "score": 1,
          "created_utc": "2025-12-25 20:41:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvx8l0j",
          "author": "Brilliant-Station500",
          "text": "Everything look so good except the hair, the noise are still there and the hair doesnt feel natural, but overall this is amazing !",
          "score": 1,
          "created_utc": "2025-12-25 20:57:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvxbp5k",
          "author": "dardasonic",
          "text": "Sheâ€™s beautiful but isnâ€™t she too plasticky?",
          "score": 1,
          "created_utc": "2025-12-25 21:17:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvxf486",
          "author": "Signal_Opposite8483",
          "text": "If I had your skills Iâ€™d never leave the house",
          "score": 1,
          "created_utc": "2025-12-25 21:37:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvytfp3",
          "author": "No_Concept2944",
          "text": "çœŸçš„å¾ˆæ£’å•Šï¼Œç›®å‰å¾ˆé ‚ç´šçš„äº†\n\n![gif](giphy|26gsobowozGM9umBi)",
          "score": 1,
          "created_utc": "2025-12-26 03:06:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvytuow",
          "author": "Otherword300",
          "text": "So captivating.",
          "score": 1,
          "created_utc": "2025-12-26 03:09:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvyxi27",
          "author": "kimigaga",
          "text": "amazing",
          "score": 1,
          "created_utc": "2025-12-26 03:34:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvz7npf",
          "author": "Head_Soup_4083",
          "text": "I just saw my first angel",
          "score": 1,
          "created_utc": "2025-12-26 04:50:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzeyk8",
          "author": "Emotion-Management",
          "text": "Damn thats good",
          "score": 1,
          "created_utc": "2025-12-26 05:50:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzg5y6",
          "author": "ShakeXXX",
          "text": "Great job!ðŸ‘ðŸ”¥",
          "score": 1,
          "created_utc": "2025-12-26 06:00:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw04tg0",
          "author": "FateXBlood",
          "text": "I'm loving this. Please keep up the good work!",
          "score": 1,
          "created_utc": "2025-12-26 10:05:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw10igk",
          "author": "Altruistic_Solid_976",
          "text": "Much more believable than most SD renders.",
          "score": 1,
          "created_utc": "2025-12-26 14:29:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw12os5",
          "author": "UtopistDreamer",
          "text": "The answer is: Yes.\n\nThe question is: Is this good enough for OnlyFans?",
          "score": 1,
          "created_utc": "2025-12-26 14:43:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw1a79d",
          "author": "DanBelsh",
          "text": "Amazing!",
          "score": 1,
          "created_utc": "2025-12-26 15:27:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw1rded",
          "author": "AifxArt",
          "text": "are you using Wan video model?",
          "score": 1,
          "created_utc": "2025-12-26 16:59:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw209ne",
          "author": "KaleidoscopeBig8567",
          "text": "WOULD!!!!!",
          "score": 1,
          "created_utc": "2025-12-26 17:47:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw2aqev",
          "author": "KaleidoscopeBig8567",
          "text": "WOULD!!!!!!!!!!!",
          "score": 1,
          "created_utc": "2025-12-26 18:41:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw2ydi4",
          "author": "Willow_Milk",
          "text": "That's a very pretty model! Do you use one of DAZ models as base? From Genesis 9?\n\nI am thinking MW Manon (for Gen9) using similar morphs to the ones this vendor uses? [https://www.daz3d.com/dforce-princess-series-idol-performance-outfit](https://www.daz3d.com/dforce-princess-series-idol-performance-outfit)",
          "score": 1,
          "created_utc": "2025-12-26 20:48:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw44y5e",
          "author": "insidiarii",
          "text": "Where did you get that huge texture library??",
          "score": 1,
          "created_utc": "2025-12-27 00:52:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw4mfpq",
              "author": "BankruptKun",
              "text": "i am an introvert nothing to do in life much, tbh.",
              "score": 1,
              "created_utc": "2025-12-27 02:44:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw4mj42",
                  "author": "insidiarii",
                  "text": "Sell a pack, I'll pay.",
                  "score": 1,
                  "created_utc": "2025-12-27 02:44:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw49k7k",
          "author": "no3us",
          "text": "What did you use for LoRA training? Can you also share some basic parameters? (or the whole toml file)",
          "score": 1,
          "created_utc": "2025-12-27 01:21:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw4i84n",
              "author": "BankruptKun",
              "text": "[https://www.reddit.com/r/StableDiffusion/comments/1pwlt52/former\\_3d\\_animator\\_here\\_again\\_clearing\\_up\\_some/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/r/StableDiffusion/comments/1pwlt52/former_3d_animator_here_again_clearing_up_some/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)\n\nI posted this today hope it helps",
              "score": 1,
              "created_utc": "2025-12-27 02:17:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw4xlk2",
                  "author": "no3us",
                  "text": "thx, not sure if I read that right though. Does it mean you train LoRAs in comfy? Want to try something that gives better results?",
                  "score": 1,
                  "created_utc": "2025-12-27 03:58:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw6rko0",
          "author": "OldSatisfaction2179",
          "text": "Impressive",
          "score": 1,
          "created_utc": "2025-12-27 13:31:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw6t9nq",
              "author": "BankruptKun",
              "text": "thank you",
              "score": 1,
              "created_utc": "2025-12-27 13:42:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw6rp1b",
          "author": "ordalic",
          "text": "![gif](giphy|pNigN05meLnIk)\n\nðŸ˜³",
          "score": 1,
          "created_utc": "2025-12-27 13:31:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw8158l",
          "author": "Hereforfun169",
          "text": "Wow this is amazing.",
          "score": 1,
          "created_utc": "2025-12-27 17:42:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw9bu4z",
          "author": "tenggerion13",
          "text": "A professional like you always will be far away from \"slops\"; you are just using AI tools to enhance your work, and nothing is truly wrong with that. It is the problem of folks that neither have talent for art nor the balls to use AI. \n\nYour artistic background will be a good leverage for the AI backed processes as well. You should not be discouraged. \n\nYou got this! \n\nAnd of course we also got this, with your blessed works!",
          "score": 1,
          "created_utc": "2025-12-27 21:47:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwa45q0",
          "author": "USTechAutomations",
          "text": "Combining traditional rigging with AI faces preserves control over movement, which is smarter than relying purely on generation.",
          "score": 1,
          "created_utc": "2025-12-28 00:23:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwanlgg",
          "author": "Milf_Apostle",
          "text": "How are you referencing the skin textures? Are they images of the skin materials or of characters with the skin applied?",
          "score": 1,
          "created_utc": "2025-12-28 02:18:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwbxpic",
          "author": "CorruptedOps",
          "text": "My only thing I will say to you OP is:\n\nhttps://preview.redd.it/m43877zjhw9g1.jpeg?width=1080&format=pjpg&auto=webp&s=9454e1148017d2afd77fd37a1eaf9ed8b42815e0",
          "score": 1,
          "created_utc": "2025-12-28 07:51:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwcujjy",
          "author": "kalvnox",
          "text": "Great work.",
          "score": 1,
          "created_utc": "2025-12-28 12:56:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwd7nbo",
          "author": "SunoGotFuked",
          "text": "Perfect model for bath water",
          "score": 1,
          "created_utc": "2025-12-28 14:23:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwhad51",
          "author": "Mysterious-Plum8246",
          "text": "Chaturb[AI]t",
          "score": 1,
          "created_utc": "2025-12-29 03:01:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwillyj",
          "author": "Temporary_Drink9432",
          "text": "This is one of the best ai video I have seen so far.",
          "score": 1,
          "created_utc": "2025-12-29 08:56:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwiw4jm",
          "author": "Inevitable-Design886",
          "text": "I had never experienced armpit fetish before until...",
          "score": 1,
          "created_utc": "2025-12-29 10:35:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwiwope",
              "author": "BankruptKun",
              "text": "i did it this way cause its only sfw use, other fetish would make it bit  too less artistic",
              "score": 1,
              "created_utc": "2025-12-29 10:40:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwp2x4d",
                  "author": "Inevitable-Design886",
                  "text": "i agree, anyways it looks good.. would like to see some cosplays aswell.",
                  "score": 1,
                  "created_utc": "2025-12-30 07:55:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwmmglb",
          "author": "jacques-vache-23",
          "text": "Whatever she's selling, I'm buying!!  Yum!!",
          "score": 1,
          "created_utc": "2025-12-29 22:43:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtz49j",
              "author": "BankruptKun",
              "text": "skin details for now",
              "score": 1,
              "created_utc": "2025-12-31 00:47:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwmxobg",
          "author": "leeresblatt2",
          "text": "thats really well made",
          "score": 1,
          "created_utc": "2025-12-29 23:44:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvr95g8",
          "author": "wellhungkid",
          "text": "i never understood armpit weirdo's until one of them told me you get to see side boob. I understand now.\n\nalso i recently learned how to lucid dream so i hope that model isn't anybody important to you because she' going to toss my salad tonight in dreamland.",
          "score": 1,
          "created_utc": "2025-12-24 18:37:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrglrw",
              "author": "BankruptKun",
              "text": "have the most pleanst dream friend, as the creator it feels good if the character is loved (in everyway)",
              "score": 2,
              "created_utc": "2025-12-24 19:18:09",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nvss39w",
              "author": "SoulofArtoria",
              "text": "Nah dem pits and sideboobs are of two separate interests.",
              "score": 1,
              "created_utc": "2025-12-25 00:14:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvr5o6e",
          "author": "naizdoycai",
          "text": "i will be watching your journey, with great interest!\n\n\n\n\n(plsss do nsfw plsss do nsfw)",
          "score": 0,
          "created_utc": "2025-12-24 18:18:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrdr5u",
              "author": "BankruptKun",
              "text": "lol dont wanna get into uncanny valley yet. but will keep in mind.",
              "score": 1,
              "created_utc": "2025-12-24 19:02:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvr8lm7",
          "author": "ReturnMeToHell",
          "text": "Make more please",
          "score": 1,
          "created_utc": "2025-12-24 18:34:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvs2fah",
          "author": "skyrimer3d",
          "text": "I've been inspecting it closely and side boobs are not consistent, but I may have to recheck just to be sureÂ ",
          "score": 1,
          "created_utc": "2025-12-24 21:26:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvriexq",
          "author": "Silly-Strawberry705",
          "text": "Why do your white women look Asian?",
          "score": 1,
          "created_utc": "2025-12-24 19:28:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrqmx0",
          "author": "Betty_White_Feet_Pic",
          "text": "The threading of the clothes constantly changing breaks it for me\n\nOn a side note have you tested this with any 3d models of Betty white? Asking for a friend...",
          "score": 1,
          "created_utc": "2025-12-24 20:16:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvslq0q",
          "author": "golgiiguy",
          "text": "Solid side bewb activate",
          "score": 1,
          "created_utc": "2025-12-24 23:30:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsnfsl",
          "author": "MtnMaiden",
          "text": "Automate it with agents.\n\n\nTime is money.\n\nYou could be pumping out 5 examples at the price of one.  But dont tell them that",
          "score": 1,
          "created_utc": "2025-12-24 23:42:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsx063",
          "author": "KrankDamon",
          "text": "Damn, you cooked dude",
          "score": 1,
          "created_utc": "2025-12-25 00:49:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvt5ofz",
          "author": "InfiniteLife2",
          "text": "As a hoarder I would love to see your skin storage",
          "score": 1,
          "created_utc": "2025-12-25 01:55:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtfcct",
          "author": "IntroductionSouth513",
          "text": "![gif](giphy|Jo0YfdZrOqyAg)",
          "score": 1,
          "created_utc": "2025-12-25 03:08:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtn03g",
          "author": "UninvestedCuriosity",
          "text": "Did you intentionally make her right handed and adjust the mesh weights to reflect the difference for that or did the model just sort of come up with that in the subtle muscle differences on its own? \n\nI gotta imagine the source material is fantastically done. I might just be seeing things as well but she's right handed.",
          "score": 1,
          "created_utc": "2025-12-25 04:08:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvur2bi",
          "author": "Ambitious-Pirate-505",
          "text": "What are you using? For the noobs out there.",
          "score": 1,
          "created_utc": "2025-12-25 10:41:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuss6o",
          "author": "featherless_fiend",
          "text": "Just remember to never post a before/after comparison of your animation before you applied the AI to it.\n\nI don't even know what it looks like, but I already know 100% for sure what the responses would be. They'd say the original looks better, it has more soul, etc.\n\nThis is NOT reflective of what people would spend their money on. It's like praising a steam indie game next to an evil megacorp AAA game. Even though the evil megacorp AAA game made 10 billion dollars and the steam indie game made $1000.",
          "score": 1,
          "created_utc": "2025-12-25 10:59:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuugbf",
          "author": "Bolf-Ramshield",
          "text": "Why are all the posts in this sub so horny all the time?",
          "score": 1,
          "created_utc": "2025-12-25 11:17:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvra5cc",
          "author": "qwen_next_gguf_when",
          "text": "Gemini please hire this guy and give us a digital girlfriend like this.",
          "score": 0,
          "created_utc": "2025-12-24 18:42:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvr7zkq",
          "author": "ultramarineafterglow",
          "text": "i know i'm getting there",
          "score": 0,
          "created_utc": "2025-12-24 18:31:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrf3j2",
          "author": "Mayion",
          "text": "https://preview.redd.it/0s057ywua79g1.jpeg?width=240&format=pjpg&auto=webp&s=4aa6943c97762e314b8fadb0232014c8169a1435",
          "score": 0,
          "created_utc": "2025-12-24 19:09:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrj4ss",
              "author": "BankruptKun",
              "text": "ðŸ‘€",
              "score": 3,
              "created_utc": "2025-12-24 19:32:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrrm08",
          "author": "Dann_Gerouss",
          "text": "Tell me you have more of this?... For a scientific reasons obviously... By the way, great job.",
          "score": 0,
          "created_utc": "2025-12-24 20:21:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrsbqc",
              "author": "BankruptKun",
              "text": "Testing still. but yes im trying to make a pipeline and project at the moment.",
              "score": 3,
              "created_utc": "2025-12-24 20:25:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvs4f7c",
                  "author": "Dann_Gerouss",
                  "text": "That's a great result for a test, great job bro, thank you for sharing",
                  "score": 1,
                  "created_utc": "2025-12-24 21:38:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvs4bqp",
          "author": "MikeyDx",
          "text": "Sheâ€™s in the uncanny valley, but Iâ€™d still like to get in her valley",
          "score": 0,
          "created_utc": "2025-12-24 21:37:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvucp5n",
          "author": "Arckedo",
          "text": "WOULD",
          "score": 0,
          "created_utc": "2025-12-25 08:03:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvygu9z",
          "author": "imnotabot303",
          "text": "This isn't even good, it's just a collection of 1girl clips. All the movement is extremely minimal and the hair doesn't move correctly at all. Plus the camera is mostly static. This is the most basic of animations.\n\nOn top of that it falls into uncanny valley where it's neither stylized enough to look 3D and not realistic enough to look real.\n\nAll you need to to do to get upvotes in this sub is post 1girl material and pretend you're doing something ground breaking.\n\nPeople were using 3D models to control poses back in the 1.5 days, it's nothing new.",
          "score": 0,
          "created_utc": "2025-12-26 01:40:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw2ad3n",
              "author": "-AwhWah-",
              "text": "The people on this sub are idiots, if you showed them depth maps from controlnet they'd shit their pants",
              "score": 2,
              "created_utc": "2025-12-26 18:39:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvr6a96",
          "author": "Dapper-Tomatillo-875",
          "text": "The sexism is there",
          "score": -6,
          "created_utc": "2025-12-24 18:22:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvu1zle",
              "author": "Leokadia_d-_-b",
              "text": "![gif](giphy|aQGqcObSxfixy)",
              "score": 1,
              "created_utc": "2025-12-25 06:16:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvrtv2h",
              "author": "TruelyDashing",
              "text": "Having a video with a woman in it is sexism. All actresses and female singers lose their jobs immediately. All movies are just about men doing manly things now.",
              "score": 0,
              "created_utc": "2025-12-24 20:35:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvruh92",
                  "author": "Dapper-Tomatillo-875",
                  "text": "The issue is not the image being if the women. The issue is the age of the girl, the exposed sideboob, and expression. Remember, this is the result of the training of the models and the prompts given to them. We should be mindful of what we are training our tools to spit out as a matter of course.",
                  "score": 1,
                  "created_utc": "2025-12-24 20:38:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvrkmex",
          "author": "Pretend_Football6686",
          "text": "Little more side boob next time.",
          "score": -1,
          "created_utc": "2025-12-24 19:41:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsa5c8",
          "author": "Inevitable-Size7431",
          "text": "Merry Xmas then xd: [https://ydray.com/get/t/u17666143779009mbref556069044e1Oo](https://ydray.com/get/t/u17666143779009mbref556069044e1Oo)",
          "score": 0,
          "created_utc": "2025-12-24 22:13:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsjcdk",
          "author": "Chicken_Grapefruit",
          "text": "Hey, what tools did you use? I'm looking to learn how to make ai videos",
          "score": 0,
          "created_utc": "2025-12-24 23:13:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsl6mh",
          "author": "thanatica",
          "text": "I'm happy they aren't hairy.",
          "score": 0,
          "created_utc": "2025-12-24 23:26:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsp87m",
          "author": "SaltyyPP",
          "text": "What was your workflow to make this?",
          "score": 0,
          "created_utc": "2025-12-24 23:54:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvss9nh",
          "author": "AlxBoon",
          "text": "Wanna see more",
          "score": 0,
          "created_utc": "2025-12-25 00:15:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvsv1d9",
              "author": "BankruptKun",
              "text": "[https://www.instagram.com/bankruptkyun/](https://www.instagram.com/bankruptkyun/)\n\ni will post in moderation, so u can check on my social medias. i want to avoid sloppy ai look.",
              "score": 2,
              "created_utc": "2025-12-25 00:35:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvy9log",
                  "author": "AlxBoon",
                  "text": "I followed you on Instagram. For years as a è…‹lover, I've thought it's so well-made that maybe AI alone would be fine... especially in winter lol",
                  "score": 1,
                  "created_utc": "2025-12-26 00:50:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvst66y",
          "author": "ambelamba",
          "text": "Why not just make AI 4D Gaussian Splatter model?",
          "score": 0,
          "created_utc": "2025-12-25 00:22:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvsulc1",
              "author": "BankruptKun",
              "text": "possible, but models and data set arent there, some comes out as hit and miss, you need 50 to 100 iteration for what you are saying , its possible but lot of hardware tax, mind u i used 3Dmodel+ai overlay thats simplistic, Gaussian would need several render work not doable unless u renting expensive cloud. the cost is super huge atleast for now, but i like the idea probably will add in workflow.",
              "score": 1,
              "created_utc": "2025-12-25 00:32:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvsys4z",
                  "author": "ambelamba",
                  "text": "So basically real time 3D to AI upscaling is more realisticÂ ",
                  "score": 1,
                  "created_utc": "2025-12-25 01:02:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvszqxt",
          "author": "verocious_veracity",
          "text": "I know what your fetish is.",
          "score": 0,
          "created_utc": "2025-12-25 01:09:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvt56ze",
          "author": "Immediate-Sort-6492",
          "text": "AI isn't all bad afterallÂ ",
          "score": 0,
          "created_utc": "2025-12-25 01:51:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvt58fz",
          "author": "peejay0812",
          "text": "Armpits where sits right in the middle of SFW and NSFW ðŸ˜‚ðŸ™",
          "score": 0,
          "created_utc": "2025-12-25 01:51:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvt69ez",
          "author": "Own-Cranberry-7500",
          "text": "Is this the beginning of matrix?",
          "score": 0,
          "created_utc": "2025-12-25 01:59:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtjepx",
          "author": "V_A_M_P_Z",
          "text": "What did you use for the video?",
          "score": 0,
          "created_utc": "2025-12-25 03:40:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvtkwew",
              "author": "BankruptKun",
              "text": "I used a mix of standard Flux and slightly customized Qwen. I leaned more into Qwen for better character retention.\n\npeople wanted me to try wan or thought  i was using wan but i just started out so will try in due time to test if it keeps character retention or it won't be useful.",
              "score": 0,
              "created_utc": "2025-12-25 03:51:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvtnrp8",
          "author": "mk8933",
          "text": "https://preview.redd.it/xgfk1hi10a9g1.jpeg?width=1008&format=pjpg&auto=webp&s=8006b3ba9148d8c18e8e68eb55d30b6880d548dd",
          "score": 0,
          "created_utc": "2025-12-25 04:14:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvto1yx",
          "author": "Jo_Krone",
          "text": "Consistency is getting there alright",
          "score": 0,
          "created_utc": "2025-12-25 04:16:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtqzii",
          "author": "HiddenThinks",
          "text": "Hi, as a 3d artist/animator who's interested in getting started in this area as well, are there any guides you used for comfyui?",
          "score": 0,
          "created_utc": "2025-12-25 04:40:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvtrgpr",
              "author": "BankruptKun",
              "text": "https://youtube.com/@ai_is_in_wonderland?si=V-NiuQpRF3FsoJqG\n\n\ni would say the magic lies in reference, for now this channel i started to follow 2Month ago i am myself not super proficient but for starting put i think this guy is the most underrated among youtube.\n\ni took some tips and simply fed my ai 3D models and rendered along with my texture collection. simple as that. \n\nalso word of advice, tools will change, keep the same fundamental pipeline don't complicate.",
              "score": 1,
              "created_utc": "2025-12-25 04:44:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvttmdp",
                  "author": "HiddenThinks",
                  "text": "Thank you so much!",
                  "score": 1,
                  "created_utc": "2025-12-25 05:01:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvtrf5n",
          "author": "Excellent_Pirate_361",
          "text": "Do you have an equipment list?",
          "score": 0,
          "created_utc": "2025-12-25 04:43:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtrsrb",
          "author": "joboo121",
          "text": "Go to horny jail!",
          "score": 0,
          "created_utc": "2025-12-25 04:46:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtwxx1",
          "author": "Denial_Jackson",
          "text": "I sometimes feel so bad I cheaped out on GPU and also only invested in a R36H being the future of playing doom 1993. Maybe there is more in life than that. Sure there are some signs.",
          "score": 0,
          "created_utc": "2025-12-25 05:30:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvu82oy",
          "author": "BastiSpasti420",
          "text": "https://i.redd.it/4b4te1h9wa9g1.gif",
          "score": 0,
          "created_utc": "2025-12-25 07:15:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvubgfc",
          "author": "Korimthos",
          "text": "https://preview.redd.it/suik3k5l2b9g1.jpeg?width=1284&format=pjpg&auto=webp&s=18e192f5ef36d426f7fa63196c1b7417ee8e7b79",
          "score": 0,
          "created_utc": "2025-12-25 07:50:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvugw8n",
          "author": "Basic_Record5112",
          "text": "Can I see the asset you used? I have a background in 3d animation.",
          "score": 0,
          "created_utc": "2025-12-25 08:49:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuy9g0",
          "author": "Salvare003",
          "text": "Jumped over the uncanny valley and landed on the other side. Beautiful work.",
          "score": 0,
          "created_utc": "2025-12-25 11:57:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvasoe",
          "author": "Kanakravaatti",
          "text": "Holy fucking shit",
          "score": 0,
          "created_utc": "2025-12-25 13:45:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvxjwzq",
          "author": "HeftyCompetition9218",
          "text": "Iâ€™m a woman. Iâ€™m not gay.\n\nI watched this many times transfixed by the more than sexy, more than beautiful quality of the movements, expressions and textures. Whatâ€™s uniquely different about this I think from real people is that most real people guard their expressions to some extent even when highly professionally trained or intuitively exceptional at expression. You catch flickers of emotion that can be complicating. \n\nYour AI and animation hybrid doesnâ€™t have that complication. So I can watch her endlessly and feel at ease about doing so. \n\nVery interesting and thanks for sharing.",
          "score": 0,
          "created_utc": "2025-12-25 22:07:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvxz768",
          "author": "beardobreado",
          "text": "Armpit fetishmuch. Is that grokh or wan?",
          "score": 0,
          "created_utc": "2025-12-25 23:45:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvru9w1",
          "author": "Oliv3rx",
          "text": "Even if itâ€™s not 100%. It will be in 12 months so youâ€™re doing the best thing learning now ðŸ‘ðŸ»",
          "score": -1,
          "created_utc": "2025-12-24 20:37:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsy1gn",
          "author": "tito_javier",
          "text": "I didn't want to fall in love today :(",
          "score": -1,
          "created_utc": "2025-12-25 00:56:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsyzna",
          "author": "wafflepiezz",
          "text": "This is really fucking good. \n\n\n10/10 would jerk to.",
          "score": -1,
          "created_utc": "2025-12-25 01:03:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvt113i",
          "author": "ComeWashMyBack",
          "text": "In the realm of using ComfyUI. This top tier. I'd everyone in my life a believer if I could produce this locally. 20tb wow! Back of the hair is a little stiff during the first big turn. The wave goodbye felt a smig forced. But in no way shape or form could this be considered slop. The envy is so real.",
          "score": -1,
          "created_utc": "2025-12-25 01:19:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvt3fjp",
          "author": "Tyler_Zoro",
          "text": "You can't fool us! Stop posting video of your girlfriend to this sub! ;-)",
          "score": -1,
          "created_utc": "2025-12-25 01:38:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvt8bx9",
          "author": "Ecstatic-Remove-7584",
          "text": "It looks extremely nice. \n\nI don't want to be that person. But quality single-person video from AI is currently well-defined and is supposed to be produced with certain amount of repeated trials. But can you make similar quality of video with two or more characters? If that is difficult with current technology, AI is still limited and may require similar or even more time and effort with 3D animation mainly because of AI randomness.",
          "score": -1,
          "created_utc": "2025-12-25 02:15:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtn3fx",
          "author": "rsinghal2000",
          "text": "Great stuff. For me, Ai-slop happens when there isnâ€™t a human critical eye or taste maker in the loop. Clearly youâ€™re working on it.\n\nNeed real motion cap, some shots are fine for a slow -mo feel. Since youâ€™re going for likelike anime, then then the skin and lighting is fine, but all of those can be tweaked for any style. Can you add a consistent glow under the skin in a fixed freckle pattern?\n\nAs-is can be used for crowd work and wonâ€™t have pixel hallucinations from attempting to do the whole crowd at once. The director could probably even zoom in to any portion of the crowd with custom motion cap.",
          "score": -1,
          "created_utc": "2025-12-25 04:09:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtos49",
          "author": "stellakorn",
          "text": "Yo this is insane. 3d animation is seriously the best application for video and image ai..",
          "score": -1,
          "created_utc": "2025-12-25 04:22:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvty6e6",
          "author": "UltraAC5",
          "text": "This is fire. The only thing that seems unrealistic is the hair physics. It's slower than it should be and there is one shot where the hair on the left shoulder floats in the air for longer than it should. \n\nOtherwise, this is some of the most realistic i've ever seen",
          "score": -1,
          "created_utc": "2025-12-25 05:41:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvu7do2",
          "author": "ArcaneWindow",
          "text": "this is fantastic. just keep in mind fanvue is the only platform to make fan money with AI, unless of course you are going to sell tutorials, then patreon & youtube duo is the place to be. onlyfans is kicking ai people out unless it is the ai double of the actual real creator.  \n  \nand remember the more hardcore stuff you put that AI character through, the more the money .",
          "score": -1,
          "created_utc": "2025-12-25 07:08:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvub0lo",
          "author": "Beginning-Role-4320",
          "text": "this honestly reminded me of seeing final fantasy for the first time, incredible job.",
          "score": -1,
          "created_utc": "2025-12-25 07:45:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuhc0t",
          "author": "1aysays1",
          "text": "![gif](giphy|l3fZK7BgnNHSKpp4c)",
          "score": -1,
          "created_utc": "2025-12-25 08:53:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvurkux",
          "author": "Ok_Try_877",
          "text": "Im obv not into armpits as didn't even spot that until read the comments.... But I love that look and smile thats knowingly says \"You are in so much trouble....\" Ive seen that a few times in real life and it always ended in one place ;-)",
          "score": -1,
          "created_utc": "2025-12-25 10:46:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuvgwr",
          "author": "DrainTheMuck",
          "text": "She looks amazing!!",
          "score": -1,
          "created_utc": "2025-12-25 11:28:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5x2kh",
          "author": "spacecase_88",
          "text": "You should quit the ai and go back to being a real animator.",
          "score": -1,
          "created_utc": "2025-12-27 08:57:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw7cwia",
              "author": "ant325",
              "text": "Are you going to hire him ?",
              "score": 1,
              "created_utc": "2025-12-27 15:39:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw8k193",
                  "author": "spacecase_88",
                  "text": "real skill > ai, every single time",
                  "score": 1,
                  "created_utc": "2025-12-27 19:17:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvrn4wc",
          "author": "Zombi3Kush",
          "text": "I think I just met my future ex Ai wife.",
          "score": -2,
          "created_utc": "2025-12-24 19:55:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pwh4gw",
      "title": "New implementation for long videos on wan 2.2 preview",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/l5pl323hlm9g1",
      "author": "shootthesound",
      "created_utc": "2025-12-26 22:36:02",
      "score": 1472,
      "num_comments": 210,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pwh4gw/new_implementation_for_long_videos_on_wan_22/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nw3pf46",
          "author": "MHIREOFFICIAL",
          "text": "here I am doing first and last frame manually like a caveman",
          "score": 80,
          "created_utc": "2025-12-26 23:19:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw4gzws",
              "author": "FaceDeer",
              "text": "Same. I keep having to plan my videos thinking \"how can I make this sequence look good accounting for the fact that the camera and background objects will suddenly move slightly differently every five seconds?\" And it's not easy.",
              "score": 14,
              "created_utc": "2025-12-27 02:09:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw4v7u2",
                  "author": "MHIREOFFICIAL",
                  "text": "hmm, overall i tend to lean on ping pong, but it leads to very uninteresting videos.\n\ngood for certain um...repetitive actions though",
                  "score": 13,
                  "created_utc": "2025-12-27 03:42:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw7frr0",
                  "author": "Dirty_Dragons",
                  "text": "LOL I made a video of many FL2V clips spliced together and somehow the walls changed colors from a neutral off-white to straight up pink. It happened so gradually that I didn't notice.",
                  "score": 2,
                  "created_utc": "2025-12-27 15:53:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw6czn0",
                  "author": "hitman_",
                  "text": "What do you mean camera and objects move? Are you not using the last frame of the first video as first frame of the second?",
                  "score": 1,
                  "created_utc": "2025-12-27 11:33:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw56xp9",
              "author": "PwanaZana",
              "text": "I tried that, and a complex workflow and both have the same start-stop stutter every 5 seconds. We'll see if other workflows can do better but  my hopes are low.",
              "score": 3,
              "created_utc": "2025-12-27 05:05:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw3jb8j",
          "author": "Hearcharted",
          "text": "![gif](giphy|rBA9YKPPA4v7DXPdvg)",
          "score": 296,
          "created_utc": "2025-12-26 22:43:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3jmge",
              "author": "fenixuk",
              "text": "as someone who knows the OP personally, i can confirm this is actual footage of him.",
              "score": 129,
              "created_utc": "2025-12-26 22:45:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw3xnqg",
                  "author": "35point1",
                  "text": "Now I want to be friends with you and OP on a personal level",
                  "score": 24,
                  "created_utc": "2025-12-27 00:09:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw3jn3s",
              "author": "shootthesound",
              "text": "I appreciate this Gif.",
              "score": 44,
              "created_utc": "2025-12-26 22:45:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw3k37n",
                  "author": "Hearcharted",
                  "text": ";)",
                  "score": 5,
                  "created_utc": "2025-12-26 22:48:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw56sxw",
              "author": "PwanaZana",
              "text": "https://preview.redd.it/hqkqzgiqio9g1.png?width=657&format=png&auto=webp&s=c146a15b573735979a96a31373f519bd35917034\n\nis that the NOUNs esports glasses?",
              "score": 6,
              "created_utc": "2025-12-27 05:04:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw3o1kh",
          "author": "Radiant-Photograph46",
          "text": "Please tell me this is compatible with i2v?",
          "score": 23,
          "created_utc": "2025-12-26 23:11:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3ojuc",
              "author": "shootthesound",
              "text": "It is",
              "score": 31,
              "created_utc": "2025-12-26 23:14:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw3lkpz",
          "author": "Technical_Ad_440",
          "text": "the absolute legend doing gods work",
          "score": 42,
          "created_utc": "2025-12-26 22:56:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3mx0h",
          "author": "coconutmigrate",
          "text": "you sir, will be our Santa",
          "score": 17,
          "created_utc": "2025-12-26 23:04:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3kp0k",
          "author": "thisiztrash02",
          "text": "this looks like a wiring system that would take even a skilled electrician a while to navigate",
          "score": 35,
          "created_utc": "2025-12-26 22:51:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3l6xg",
              "author": "shootthesound",
              "text": "I've not exactly tided it yet, this video is more results orientated - thats the reason it wont be on github today lol",
              "score": 25,
              "created_utc": "2025-12-26 22:54:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw4wrp5",
                  "author": "Perfect-Campaign9551",
                  "text": "Please do NOT tidy it. It will just make it harder to use",
                  "score": 15,
                  "created_utc": "2025-12-27 03:52:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw5co1h",
                  "author": "artisst_explores",
                  "text": " ðŸ˜",
                  "score": 1,
                  "created_utc": "2025-12-27 05:49:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwakf7u",
                  "author": "juandann",
                  "text": "Please don't make it overly tidied, many probably still want to easily see every node within the workflow (I and many hate workflow that hide smaller nodes behind the big nodes)",
                  "score": 1,
                  "created_utc": "2025-12-28 01:59:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw3li12",
                  "author": "pixllvr",
                  "text": "I think some set and get nodes from Kijai's nodepack would definitely help here!",
                  "score": 0,
                  "created_utc": "2025-12-26 22:56:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw4h8ph",
              "author": "FaceDeer",
              "text": "I'd like an extension for ComfyUI that makes little animated sparks and arcs happen randomly where there's a high density of overlapping wires.",
              "score": 5,
              "created_utc": "2025-12-27 02:10:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw3r0u2",
          "author": "leepuznowski",
          "text": "Prayers for your family member. Hope all will be well. Thanks for this amazing gift.",
          "score": 32,
          "created_utc": "2025-12-26 23:29:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3rdr4",
              "author": "shootthesound",
              "text": "Really appreciate that. Been a nightmare couple of weeks.",
              "score": 28,
              "created_utc": "2025-12-26 23:31:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw3t93x",
          "author": "noyart",
          "text": "the secret is to put everything into one subgraph. Kidding, please don't do that, its already pain to explore and learn from =(",
          "score": 17,
          "created_utc": "2025-12-26 23:42:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3n2jh",
          "author": "PhotoRepair",
          "text": "Gonna upvote cos it's seamless to me",
          "score": 21,
          "created_utc": "2025-12-26 23:05:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw41u65",
          "author": "Perfect-Campaign9551",
          "text": "I've already seen subnodes that take the inputs and carry them through. So it all depends on what's in your subnodes, but the main problem with all current techniques is they still rely on using the last set of images/frames/ or single last frame, but already decoded. What we need is a way to pass the latent onward so we aren't VAE decoding anything until the end. And it has to continue motion (which is what the wan VACE methods allow)",
          "score": 6,
          "created_utc": "2025-12-27 00:34:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw5r8cg",
              "author": "Similar_Director6322",
              "text": "Unfortunately the latent of the last frame isn't viable as an input as a first frame.  I had the same thought and created some custom ComfyUI nodes hoping to extract the latent representation of a \"frame\" so I could pass it directly into the WanImageToVideo node.\n\nHowever, this isn't really feasible due to the Wan 2.1 VAE (which is also used by Wan 2.2 14B variants).  In this VAE, each \"slice\" of the latent representation of a video is 4 frames, so you can't simply grab a latent representation of the last frame.\n\nThat on its own isn't necessarily a blocker though, why not just pass in the last 4 frames to FirstLastFrame?  Well, because it is a 3D VAE, each subsequent 4-frame slice relies on the preceding frame data to be accurately decoded.  Without all of the preceding latent data, you get an image that lacks definition and looks similar to the famously bad painting restoration done to [ElÃ­as GarcÃ­a MartÃ­nezâ€™s *Ecce Homo*](https://news.artnet.com/app/news-upload/2015/08/8KKbDZ6QKee8HsKlvcQQeA-1024x682.jpeg).",
              "score": 9,
              "created_utc": "2025-12-27 08:01:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw4iq2e",
          "author": "skyrimer3d",
          "text": "Looks amazing, but like every long vid approach, I'm worried about degradation and consistency with faces environments etc, will this improve it somehow?Â ",
          "score": 6,
          "created_utc": "2025-12-27 02:20:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw6zpy4",
              "author": "Toupeenis",
              "text": "Yeah, that's my immediate thought, by the third last frame it's already lost it's sauce in most cases. This would still be cool from a \"preserving movement\" perspective though. Like having your 2-3 loops more coherent.",
              "score": 2,
              "created_utc": "2025-12-27 14:23:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw3nne2",
          "author": "JoshuaLandy",
          "text": "RemindMe! 1 day",
          "score": 4,
          "created_utc": "2025-12-26 23:09:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3nqwv",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 1 day on [**2025-12-27 23:09:03 UTC**](http://www.wolframalpha.com/input/?i=2025-12-27%2023:09:03%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/StableDiffusion/comments/1pwh4gw/new_implementation_for_long_videos_on_wan_22/nw3nne2/?context=3)\n\n[**45 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FStableDiffusion%2Fcomments%2F1pwh4gw%2Fnew_implementation_for_long_videos_on_wan_22%2Fnw3nne2%2F%5D%0A%0ARemindMe%21%202025-12-27%2023%3A09%3A03%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201pwh4gw)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 3,
              "created_utc": "2025-12-26 23:09:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw529tt",
              "author": "BlueSoccerSB8706",
              "text": "RemindMe! 1 day",
              "score": 1,
              "created_utc": "2025-12-27 04:31:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw52vxp",
              "author": "afterburningdarkness",
              "text": "Hijack",
              "score": 1,
              "created_utc": "2025-12-27 04:35:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw5d9aa",
              "author": "Beneficial_Toe_2347",
              "text": "Also",
              "score": 1,
              "created_utc": "2025-12-27 05:54:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw3n9aq",
          "author": "Radyschen",
          "text": "thank you thank you thank you thank you thank you\n\ndoes this have a (big) effect on vram usage?",
          "score": 9,
          "created_utc": "2025-12-26 23:06:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3o2f6",
              "author": "shootthesound",
              "text": "None. Nothing more than regular i2v",
              "score": 22,
              "created_utc": "2025-12-26 23:11:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw3omf3",
                  "author": "Radyschen",
                  "text": "you are my hero",
                  "score": 7,
                  "created_utc": "2025-12-26 23:14:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwfrrd8",
                  "author": "Zhanji_TS",
                  "text": "What gpu are you using",
                  "score": 1,
                  "created_utc": "2025-12-28 22:03:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw3ol3s",
          "author": "No_Damage_8420",
          "text": "Thanks for info and hopefully we can get our most wanted Xmas gift yet :)",
          "score": 5,
          "created_utc": "2025-12-26 23:14:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3tso6",
          "author": "sabrathos",
          "text": "The results look great, looking forward to try it out!",
          "score": 3,
          "created_utc": "2025-12-26 23:46:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw48mut",
          "author": "bloke_pusher",
          "text": "I need a workflow that allows me to preview the first part and then push a button to jump to the next part and so on. Also one where I can \"undo\" steps and go back to an earlier one, so I don't fully start from scratch. \n\nAs with my current ones, if a long video workflow generates a bad result, you got to start all over and that's very unflexible.",
          "score": 3,
          "created_utc": "2025-12-27 01:15:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw48x8t",
              "author": "shootthesound",
              "text": "Yes you can build section by section with this - with unique conditioning and even loras per section",
              "score": 5,
              "created_utc": "2025-12-27 01:17:39",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nw7fo1e",
              "author": "gman_umscht",
              "text": "That's how I built my workflow.   \n1) create 1st clip from input image - if satisfied I enable clip 2   \n2) create 2nd clip from last frame (with Laczos 2x upscale and optionally model upscale) . If not satisfied with 2nd clip, I change the seed or prompt and try again - while the 1st clip remains untouched. Once It is done I enable clip 3  \n3) continue with clip 3 in the same manner - clips 1+2 remain unchanged   \n4) see clip 3   \n5) if satisfied with end result I combine the clip and optionally do a GIMM interpolation and/or upscale.  \n\n\nFor each stage I can add LORAs as I like and change frame count. Obviously I can't discard clip 2 and keep 3+4, and it has all the context limitations of a last-frame workflow but within these limitations it works well enough for me.\n\nI'll check if and how I can incorportate OP's node into this, as this sounds promising.",
              "score": 5,
              "created_utc": "2025-12-27 15:53:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw8c822",
          "author": "One_Yogurtcloset4083",
          "text": "where to download workflow? is it ready?",
          "score": 5,
          "created_utc": "2025-12-27 18:37:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwev49o",
          "author": "Leiawen",
          "text": "This has been working great for me, thank you so much for the workflow. It was very easy to understand and get working. \n\nI'm trying to modify it to make the animation loop. Essentially, I want to modify the last chunk so that it has the initial image as a Target last frame. I tried to modify the conditioning and replace it with a WAN first to last frame but it's not generated correctly. \n\nAnyone have any ideas on how best to modify this workflow to make a loop?",
          "score": 4,
          "created_utc": "2025-12-28 19:23:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwfs85g",
              "author": "Zhanji_TS",
              "text": "Iâ€™m also trying to figure out how to do this consistently, let me know if you come up with something?",
              "score": 1,
              "created_utc": "2025-12-28 22:05:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwg327z",
                  "author": "Leiawen",
                  "text": "I will. I'm making some progress.",
                  "score": 3,
                  "created_utc": "2025-12-28 23:01:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw3nq0e",
          "author": "AppealThink1733",
          "text": "Okay, now all that's missing is a good computer to put all this into practice.",
          "score": 5,
          "created_utc": "2025-12-26 23:09:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3o68i",
          "author": "Mysterious-String420",
          "text": "I can get some good results out of painterlongvideo - can even plug in any ol' unrelated input video, tell it to read the last 4-7 frames and let it do its thing, but there's still the resource problem of chaining more than 3 videos in the same workflow ; either kills my RAM, or sage attention does, who knows.  \n  \nEager to see your workflow!",
          "score": 3,
          "created_utc": "2025-12-26 23:12:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw4lrqa",
              "author": "nadhari12",
              "text": "works for most parts  but not great with faces, if a character turns back and walks away and in next video the character  comes  back as someone different.",
              "score": 2,
              "created_utc": "2025-12-27 02:40:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwdl8yf",
                  "author": "Mysterious-String420",
                  "text": "use clip vision to catch a reference face, serve it as an embed;   \nalso, the node has a \"reference first image\" input slot to combat amnesia.",
                  "score": 1,
                  "created_utc": "2025-12-28 15:40:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw450he",
              "author": "FantasticFeverDream",
              "text": "Itâ€™s usually torche compile that effs my system",
              "score": 1,
              "created_utc": "2025-12-27 00:53:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw3oib0",
          "author": "Wonderful_Wrangler_1",
          "text": "RemindMe! 2 days",
          "score": 3,
          "created_utc": "2025-12-26 23:14:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbvume",
              "author": "Wonderful_Wrangler_1",
              "text": "RemindMe! 2 days",
              "score": 1,
              "created_utc": "2025-12-28 07:34:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwbvyed",
                  "author": "RemindMeBot",
                  "text": "I will be messaging you in 2 days on [**2025-12-30 07:34:18 UTC**](http://www.wolframalpha.com/input/?i=2025-12-30%2007:34:18%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/StableDiffusion/comments/1pwh4gw/new_implementation_for_long_videos_on_wan_22/nwbvume/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FStableDiffusion%2Fcomments%2F1pwh4gw%2Fnew_implementation_for_long_videos_on_wan_22%2Fnwbvume%2F%5D%0A%0ARemindMe%21%202025-12-30%2007%3A34%3A18%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201pwh4gw)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
                  "score": 1,
                  "created_utc": "2025-12-28 07:35:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw3p1lm",
          "author": "niconpat",
          "text": "OP had a few drinky-poos and deshervedesdly so ;)",
          "score": 3,
          "created_utc": "2025-12-26 23:17:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3r77g",
          "author": "Strong_Unit_416",
          "text": "RemindMe! One day",
          "score": 3,
          "created_utc": "2025-12-26 23:30:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3w5tn",
          "author": "PinkMelong",
          "text": "wow this is so amazing. and Thanks for your time spending through precious Christmas break. really amazing output. Op!.",
          "score": 3,
          "created_utc": "2025-12-27 00:00:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3y6sj",
          "author": "TonyDRFT",
          "text": "Hope your family member is doing well! Thank you for sharing!",
          "score": 3,
          "created_utc": "2025-12-27 00:12:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5e7ka",
          "author": "SandCheezy",
          "text": "Merry Christmas to you too Pete!",
          "score": 3,
          "created_utc": "2025-12-27 06:02:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwby8vs",
          "author": "virtuallydelonk",
          "text": "What GPU do you have?",
          "score": 3,
          "created_utc": "2025-12-28 07:56:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3qlp8",
          "author": "Puzzleheaded-Rope808",
          "text": "Looks amazing. You may want to add a \"get image or mask range from batch node and set it to 1 so that it skips the first frame. makes it less jumpy. It goes between teh vae decode and teh merge image node",
          "score": 4,
          "created_utc": "2025-12-26 23:26:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3r73a",
              "author": "shootthesound",
              "text": "Yup agreed - all cake dressing Iâ€™ve not got to - I literally only just got this working",
              "score": 4,
              "created_utc": "2025-12-26 23:30:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw3ouem",
          "author": "Link1227",
          "text": "Looks cool.",
          "score": 2,
          "created_utc": "2025-12-26 23:16:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3qbae",
          "author": "zodiac_____",
          "text": "Nicee. Looks great!!! Appreciate the effort and work.",
          "score": 2,
          "created_utc": "2025-12-26 23:25:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3qej0",
          "author": "augustus_brutus",
          "text": "Legend",
          "score": 2,
          "created_utc": "2025-12-26 23:25:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3qmcd",
          "author": "TheAncientMillenial",
          "text": "Yup, that looks like my crazy workflows too heh. Nice ;)",
          "score": 2,
          "created_utc": "2025-12-26 23:26:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3tyep",
          "author": "Blaknasty",
          "text": "Thank you for showing your workflow ðŸ‘ðŸ¿",
          "score": 2,
          "created_utc": "2025-12-26 23:47:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3vrzj",
          "author": "yidakee",
          "text": "RemindMe!Â 3 days",
          "score": 2,
          "created_utc": "2025-12-26 23:58:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3zoke",
          "author": "Thuannguyenhn",
          "text": "RemindMe! 1 day",
          "score": 2,
          "created_utc": "2025-12-27 00:21:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw403z3",
          "author": "FightingBlaze77",
          "text": "this is starting to feel like early youtube, just slowly getting better over time",
          "score": 2,
          "created_utc": "2025-12-27 00:24:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw44ccx",
          "author": "Alemismun",
          "text": "How does this work, and can it be made to work on just 16GB of memory? I have tried tons of workflows and the most I can get is 20 seconds of really awful quality footage. Lots and lots of tiling, then often crashes.",
          "score": 2,
          "created_utc": "2025-12-27 00:49:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw59iw7",
          "author": "Direct-Vehicle2653",
          "text": "Sounds unbelievable, like someone breaking the light speed record. I can't wait to try it.",
          "score": 2,
          "created_utc": "2025-12-27 05:24:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw59xya",
              "author": "Direct-Vehicle2653",
              "text": "First video prompt: Sway shoulders for (seven (7) hours:1.9)",
              "score": 2,
              "created_utc": "2025-12-27 05:28:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw5bf6v",
          "author": "Vurgrimer",
          "text": "RemindMe! 1 day",
          "score": 2,
          "created_utc": "2025-12-27 05:39:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5cok6",
          "author": "hitlabstudios",
          "text": "RemindMe! 1 day",
          "score": 2,
          "created_utc": "2025-12-27 05:49:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw73c8w",
          "author": "DescriptionAsleep596",
          "text": "So excited about this. Why no one got this done before? Man really a hero.",
          "score": 2,
          "created_utc": "2025-12-27 14:45:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw9mf13",
          "author": "zMilad",
          "text": "Missing the FreeLong custom node after installation. Am I missing something?",
          "score": 2,
          "created_utc": "2025-12-27 22:44:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw9q6mq",
              "author": "Dizzy-Occasion844",
              "text": "You didn't read the installation part?",
              "score": 1,
              "created_utc": "2025-12-27 23:05:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw9qxg8",
                  "author": "zMilad",
                  "text": "Umm.. yes I did? That's why I wrote \"after installation\".",
                  "score": 1,
                  "created_utc": "2025-12-27 23:09:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwafkm8",
          "author": "bossbeae",
          "text": "It's cool but I'm going from 90 seconds to 700 seconds on the high noise sampler",
          "score": 2,
          "created_utc": "2025-12-28 01:30:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwdzlwy",
              "author": "shootthesound",
              "text": "added gguf options etc - see v 2 workflow after you update",
              "score": 1,
              "created_utc": "2025-12-28 16:53:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwakb33",
          "author": "palpamusic",
          "text": "this is amazing!! Two questions: does it work with Loras and are loops possible?",
          "score": 2,
          "created_utc": "2025-12-28 01:58:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwq3qcm",
              "author": "Maskwi2",
              "text": "Yes it works with Loras. Loops I don't know myself.Â ",
              "score": 1,
              "created_utc": "2025-12-30 13:11:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwkvsbb",
          "author": "Maskwi2",
          "text": "Thanks bro! Definitely isn't perfect when the character (for example) ends up with the face not being visible the whole time, then even having character Lora doesn't fully prevent face/hair change. Same with clothes and sometimes it even changes body shape, depends on how the angle changes from chunk to chunk, etc.\nSo while this isn't perfect, since it can't be since the chunks aren't really aware of all the previous geberations, it's still a huge help and with some re-generations it works great :)Â \nWhat I would like to see added:\n- wish there was a global switch for Loras so that I can plug in all Loras in one place for all available chunksÂ \n- toggle to turn off chunks would be great but it's not a huge issue to do that manually, also adding chunks via some slider would be fantastic, with one place to out prompts\n- some kind of power Lora loader would be nice to not have to chain the Loras together manually\n- option for blockswap to reduce vram\n- option to use sageattention\n\n\n\n\nAll the wishes are not crucial, it's just something that would be nice to have in the original workflow for me personally :)Â \n\n\nThanks again for sharing and congrats on the workflow!Â ",
          "score": 2,
          "created_utc": "2025-12-29 17:41:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwnk7m7",
          "author": "coconutmigrate",
          "text": "I tested with the car prompt, it's amazing, 40s with no visual video \"stitches\" and no quality decline, is the same quality start to end. Congratulations on that!",
          "score": 2,
          "created_utc": "2025-12-30 01:48:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpsf07",
          "author": "Jero9871",
          "text": "Really great, perhaps it could be integrated into kijai nodes? u/Kijai",
          "score": 2,
          "created_utc": "2025-12-30 11:48:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwb4gdi",
          "author": "nadhari12",
          "text": "This looks amazing! Itâ€™s easy for it to work with a car, but human faces probably wonâ€™tâ€”for example, if a character turns their back in the first chunk and appears again in the second chunk. Iâ€™ll try it and report back.",
          "score": 2,
          "created_utc": "2025-12-28 03:59:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwf9egp",
              "author": "shootthesound",
              "text": "you need a character lora, workflows folder now has a much improved flow with easy lora options",
              "score": 2,
              "created_utc": "2025-12-28 20:33:06",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwb5039",
              "author": "StacksGrinder",
              "text": "I was thinking the same thing, testing it now, also comparing it with SVI 2.0.",
              "score": 1,
              "created_utc": "2025-12-28 04:03:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwba4hc",
                  "author": "nadhari12",
                  "text": "yeah did not work for me, completely diff human on chunk 2.",
                  "score": 3,
                  "created_utc": "2025-12-28 04:37:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw3s6dm",
          "author": "tandersb",
          "text": "Eli5",
          "score": 2,
          "created_utc": "2025-12-26 23:36:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwg4kft",
          "author": "Logicalpop1763",
          "text": "Who else is coming here every day reading all comment in hope to find a link? ðŸ˜‚",
          "score": 2,
          "created_utc": "2025-12-28 23:09:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwg5ejj",
              "author": "shootthesound",
              "text": "its there! has been for 24 hours, see the edited main post",
              "score": 3,
              "created_utc": "2025-12-28 23:14:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw3pyo7",
          "author": "nstern2",
          "text": "I run video generation in pinokio via wan2gp and that allows longer videos as well. Is this similar to that in that you just tell it the length of the video you want and it does the rest?",
          "score": 1,
          "created_utc": "2025-12-26 23:22:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3qeie",
              "author": "shootthesound",
              "text": "This is more about protecting continuity of movement speed and direction across the separate videos, for more convincing momentum between generations",
              "score": 8,
              "created_utc": "2025-12-26 23:25:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw3y60r",
                  "author": "nstern2",
                  "text": "Nice, wan2gp sometimes has issues between windows so fingers crossed this works well.",
                  "score": 1,
                  "created_utc": "2025-12-27 00:12:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw415yn",
          "author": "ItwasCompromised",
          "text": "How long would it take to render a 15 second video though? Would it be the same length as making them separately or longer? Cool nonetheless.",
          "score": 1,
          "created_utc": "2025-12-27 00:30:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw5pfs1",
              "author": "fenixuk",
              "text": "Same.",
              "score": 1,
              "created_utc": "2025-12-27 07:44:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw42p7d",
          "author": "morganational",
          "text": "No idea what that is, but it looks super cool. ðŸ‘",
          "score": 1,
          "created_utc": "2025-12-27 00:39:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw45c9v",
          "author": "emptinoss",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2025-12-27 00:55:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw45gud",
          "author": "DescriptionAsleep596",
          "text": "OMG Very Niiiiiiice!!",
          "score": 1,
          "created_utc": "2025-12-27 00:56:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw4d0xj",
          "author": "alitadrakes",
          "text": "Excited to test",
          "score": 1,
          "created_utc": "2025-12-27 01:44:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw4d1xk",
          "author": "AnonymousAggregator",
          "text": "!RemindMe 2 days",
          "score": 1,
          "created_utc": "2025-12-27 01:44:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw4dd18",
          "author": "paul_tu",
          "text": "Wonder how it goes",
          "score": 1,
          "created_utc": "2025-12-27 01:46:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw4drs5",
          "author": "und3rtow623",
          "text": "RemindMe! 2 days",
          "score": 1,
          "created_utc": "2025-12-27 01:48:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw4f7tn",
          "author": "Candid-Fold-5309",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2025-12-27 01:58:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw4fk2d",
          "author": "susne",
          "text": "Sooooo gooooood.  Thank you. Looking forward to it!",
          "score": 1,
          "created_utc": "2025-12-27 02:00:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw4gezp",
          "author": "Lamassu-",
          "text": "that workflow looks sweet",
          "score": 1,
          "created_utc": "2025-12-27 02:05:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw4kk55",
          "author": "gkelley621",
          "text": "Will your docs also included what your system is composed of?  CPU/GPU?",
          "score": 1,
          "created_utc": "2025-12-27 02:32:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw4m4uq",
          "author": "butterflystep",
          "text": "THANK YOU! you are the real santa",
          "score": 1,
          "created_utc": "2025-12-27 02:42:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw4pyqq",
          "author": "TheStoicSamurai",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2025-12-27 03:07:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw4u2j1",
          "author": "NullEvil",
          "text": "RemindMe! 2 day",
          "score": 1,
          "created_utc": "2025-12-27 03:34:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw4x8ai",
          "author": "Better-Interview-793",
          "text": "Very cool! appreciate ur efforts (:",
          "score": 1,
          "created_utc": "2025-12-27 03:56:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw4zf1z",
          "author": "BlueSoccerSB8706",
          "text": "very cool",
          "score": 1,
          "created_utc": "2025-12-27 04:11:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw4ztf5",
          "author": "SweetBluejay",
          "text": "https://preview.redd.it/iucbxj1r9o9g1.png?width=480&format=png&auto=webp&s=686534ff6f58299624e254de09769ec4946d8057",
          "score": 1,
          "created_utc": "2025-12-27 04:14:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw51luq",
          "author": "lososcr",
          "text": "remind me! in 1 day",
          "score": 1,
          "created_utc": "2025-12-27 04:26:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw549ee",
          "author": "pcloney45",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2025-12-27 04:45:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5783u",
          "author": "MaleficentChicken134",
          "text": "https://preview.redd.it/wb05f0kbjo9g1.png?width=1214&format=png&auto=webp&s=4d5aea2c01549b197e8eef1ce000d56fb59ad13b",
          "score": 1,
          "created_utc": "2025-12-27 05:07:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw579pn",
          "author": "Expicot",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2025-12-27 05:07:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw57bz4",
          "author": "Ok_Lunch1400",
          "text": "Nice",
          "score": 1,
          "created_utc": "2025-12-27 05:08:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw58igg",
          "author": "john1106",
          "text": "Do this workflow work on rtx 5090 and 32gb ram? Also can i able to select which wan model i want to use?",
          "score": 1,
          "created_utc": "2025-12-27 05:17:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5h6lr",
          "author": "ArtDesignAwesome",
          "text": "Dude if you arent using the Painter nodes here, what are we really doing? Would love a deeper dive into this, also how can this be adapted f2flv?",
          "score": 1,
          "created_utc": "2025-12-27 06:28:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5he8w",
          "author": "Zounasss",
          "text": "Does this work with something like MoCha or Ditto? It would be awesome!",
          "score": 1,
          "created_utc": "2025-12-27 06:29:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5ixlz",
          "author": "97buckeye",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2025-12-27 06:43:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5oq16",
          "author": "MasterShadow",
          "text": "How resource intensive? How long did that take to generate?",
          "score": 1,
          "created_utc": "2025-12-27 07:37:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5qa01",
          "author": "ThinkingWithPortal",
          "text": "Looks really promising! Sorry to hear about your Christmas, best to you and your family",
          "score": 1,
          "created_utc": "2025-12-27 07:52:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5r7fg",
          "author": "stash0606",
          "text": "nice, can't wait. t2v or i2v? or does it even matter?",
          "score": 1,
          "created_utc": "2025-12-27 08:00:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5skgh",
          "author": "Nokita_is_Back",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2025-12-27 08:14:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5t2lx",
          "author": "zaherdab",
          "text": "Awesome will you be updating this post or a seprate one?",
          "score": 1,
          "created_utc": "2025-12-27 08:18:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5w5xf",
          "author": "Mouth_Focloir",
          "text": "Thanks for sharing this with us. Hope your family member gets better soon. Happy ChristmasðŸŒ²",
          "score": 1,
          "created_utc": "2025-12-27 08:49:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5wvaf",
          "author": "mobani",
          "text": "This is HUGE! Can't wait to try it out!",
          "score": 1,
          "created_utc": "2025-12-27 08:55:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5xpt8",
          "author": "No-Stay9943",
          "text": "Smart move to put a tree on a racetrack",
          "score": 1,
          "created_utc": "2025-12-27 09:03:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw61iih",
          "author": "RuprechtNutsax",
          "text": "Fair play, looks like you've done a great job there, I'll look forward to trying it out. I hope all goes well for the family member. Thanks a million for your constructive distraction.",
          "score": 1,
          "created_utc": "2025-12-27 09:41:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw64c7v",
          "author": "chAzR89",
          "text": "Used a similar wf in the past. You would enter multiple prompts sperated with \"|\" and  then it would generate as many as you like. This wf looks even easier to use. The other one was quite nice, but quality degraded way to much from clip to clip.",
          "score": 1,
          "created_utc": "2025-12-27 10:09:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw669sx",
          "author": "intLeon",
          "text": "So whats the solution? I'd love to implement this using the OG linked subgraphs (linked subgraphs are disabled now)",
          "score": 1,
          "created_utc": "2025-12-27 10:28:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw678tn",
          "author": "ronbere13",
          "text": "![gif](giphy|Hwa1ZXSpqJbQBHIUcS)",
          "score": 1,
          "created_utc": "2025-12-27 10:38:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw67ko5",
          "author": "elissaxy",
          "text": "Lol, I just paused the video when you showed the 40 sec clip and was thinking \"man how cool it would be to assign a prompt for each cut\" the saw the rest. Impressive stuff, this is the future of AI videos for local llms",
          "score": 1,
          "created_utc": "2025-12-27 10:41:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw6bpl8",
          "author": "RestaurantOrganic682",
          "text": "Waiting for your update.",
          "score": 1,
          "created_utc": "2025-12-27 11:21:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw6cqr0",
          "author": "hitman_",
          "text": "Thanks so much you are the best",
          "score": 1,
          "created_utc": "2025-12-27 11:31:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw6e8v1",
          "author": "Training_Fail8960",
          "text": "looking great, following",
          "score": 1,
          "created_utc": "2025-12-27 11:45:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw6hcn2",
          "author": "ArDRafi",
          "text": "RemindMe! 3 day",
          "score": 1,
          "created_utc": "2025-12-27 12:12:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw6j5ki",
          "author": "elongated-muskmelon",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2025-12-27 12:28:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw6nwe9",
          "author": "creativefox",
          "text": "I need it for generating cars and stuff.",
          "score": 1,
          "created_utc": "2025-12-27 13:05:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw6tlnk",
          "author": "lapr20",
          "text": "I'm new with this, do you teach? i want to learn",
          "score": 1,
          "created_utc": "2025-12-27 13:44:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw6zred",
          "author": "Quirky-Bit-6813",
          "text": "Can we have the template?",
          "score": 1,
          "created_utc": "2025-12-27 14:23:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw7g6vd",
          "author": "onerok",
          "text": "Can't wait for this!",
          "score": 1,
          "created_utc": "2025-12-27 15:56:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw7jsma",
          "author": "kenjiv",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2025-12-27 16:14:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw7v8s5",
          "author": "J1nxArcane1508",
          "text": "you are the da vinci of workflows wtf",
          "score": 1,
          "created_utc": "2025-12-27 17:12:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw80mtv",
          "author": "Fugach",
          "text": "https://preview.redd.it/hzpip8oj9s9g1.jpeg?width=1574&format=pjpg&auto=webp&s=534bed4fb91f00d9b02f078d4f84fb296b95b86d",
          "score": 1,
          "created_utc": "2025-12-27 17:39:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw83gwm",
          "author": "SunGod1957",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2025-12-27 17:54:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw8cuxb",
          "author": "Bubbly-Wish4262",
          "text": "My dream if I have high end PCðŸ˜",
          "score": 1,
          "created_utc": "2025-12-27 18:40:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw8se8g",
          "author": "BlackSheepRepublic",
          "text": "Remind Me! 1 day",
          "score": 1,
          "created_utc": "2025-12-27 20:01:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw8wpcn",
          "author": "Upper_Basis_4208",
          "text": "Wow",
          "score": 1,
          "created_utc": "2025-12-27 20:24:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw95gzj",
          "author": "PaintingSharp3591",
          "text": "Whatâ€™s the difference between this and SVI? https://github.com/vita-epfl/Stable-Video-Infinity/tree/svi_wan22",
          "score": 1,
          "created_utc": "2025-12-27 21:13:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwgrbi5",
          "author": "Robo-420_",
          "text": "Hell no, lol.\n\nUse queue trigger, control bridge, image and value sender\\\\receivers, together to run part of it in a loop.\n\n[https://random667.com/wan\\_ONE\\_IMG\\_LOOP.json](https://random667.com/wan_ONE_IMG_LOOP.json)\n\nI've also used it to loop the first to last and animate versions of wan.",
          "score": 1,
          "created_utc": "2025-12-29 01:11:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwh78ix",
              "author": "fractaldesigner",
              "text": "how is it? hardware?",
              "score": 1,
              "created_utc": "2025-12-29 02:43:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwj54sd",
          "author": "No_Chemical4996",
          "text": "Kudos man. Impressive.",
          "score": 1,
          "created_utc": "2025-12-29 11:53:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw8j054",
          "author": "Meringue-Horror",
          "text": "Those spaghetti noodles programing that makes you feel like a receptionist during world war 2 is the reason I quit video game making as a profession. I was not really bad at some of the other stuff like topology or animation... but those spaghetti noodles... it killed my desire to be a part of a development team because I just knew no matter how much I would try to sell that I'm great at other stuff they would always put me on this stupid boring task of placing spaghetti noodles in the right connectors and I just could not lower myself to try to understand.\n\nNot my cup of tea.\n\nKuddos to you for being able to do all that and understanding more then half of it.",
          "score": 1,
          "created_utc": "2025-12-27 19:11:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3qd9r",
          "author": "Seyi_Ogunde",
          "text": "Using wan Vace?",
          "score": 1,
          "created_utc": "2025-12-26 23:25:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3rxbz",
              "author": "shootthesound",
              "text": "No",
              "score": 2,
              "created_utc": "2025-12-26 23:34:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw5ynec",
          "author": "IshigamiSenku04",
          "text": "Do you have a supercomputer?",
          "score": 1,
          "created_utc": "2025-12-27 09:13:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw62mz8",
              "author": "Significant-Pause574",
              "text": "Indeed. My 3060 12gb card grinds to a halt attempting a low quality 3 second video.",
              "score": 1,
              "created_utc": "2025-12-27 09:52:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw4k9yc",
          "author": "clayshoaf",
          "text": "Is there more to it than just using the last frame of the previous gen as the first frame for the next gen?",
          "score": 0,
          "created_utc": "2025-12-27 02:30:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw5zok5",
              "author": "Direct-Vehicle2653",
              "text": "There is a way to find that out.",
              "score": 0,
              "created_utc": "2025-12-27 09:23:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw3jq4a",
          "author": "Philosopher_Jazzlike",
          "text": "Bro, you should learn to record on your computer. Wtf.",
          "score": -13,
          "created_utc": "2025-12-26 22:46:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3mlqp",
              "author": "DrinksAtTheSpaceBar",
              "text": "Bold of you to assume op has any system resources left to run a simultaneous video capture.",
              "score": 16,
              "created_utc": "2025-12-26 23:02:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw6qh3c",
                  "author": "hurrdurrimanaccount",
                  "text": "comfy wasn't running.",
                  "score": 1,
                  "created_utc": "2025-12-27 13:23:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw3kmfg",
              "author": "shootthesound",
              "text": "![gif](giphy|pPhyAv5t9V8djyRFJH)",
              "score": 18,
              "created_utc": "2025-12-26 22:51:17",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nw5zj0h",
              "author": "Direct-Vehicle2653",
              "text": "You'll have to teach him bro, he'snot very bright. I mean, look at that simple workflow.",
              "score": 3,
              "created_utc": "2025-12-27 09:21:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw9sg3v",
          "author": "Justify_87",
          "text": "I don't get the hype. This is just the thing we've seen for the last months",
          "score": -1,
          "created_utc": "2025-12-27 23:17:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3nwzu",
          "author": "Silonom3724",
          "text": "I would not let someone who records a video of a workflow with a potato near my VENV. Just saying what we all think.",
          "score": -16,
          "created_utc": "2025-12-26 23:10:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw6b01k",
          "author": "tomakorea",
          "text": "Could you use more nodes? your workflow seem too basic, I expected x1000 nodes haha",
          "score": 0,
          "created_utc": "2025-12-27 11:14:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5q3k4",
          "author": "VegetableRemarkable",
          "text": "Imagine knowing how to build this kind of complex node setup works, but not, how to record the screen properly...",
          "score": -7,
          "created_utc": "2025-12-27 07:50:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw6qa8d",
              "author": "hurrdurrimanaccount",
              "text": "had the same thought, how does it get this bad?",
              "score": -1,
              "created_utc": "2025-12-27 13:22:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw6mhek",
          "author": "No_Truck_88",
          "text": "Family member ill in hospital. Instead of comforting said family member, spends all spare time playing with AI videos ðŸ’€",
          "score": -7,
          "created_utc": "2025-12-27 12:54:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw6qjnp",
              "author": "hurrdurrimanaccount",
              "text": "probably a made up tearjerker story to get more upvotes.",
              "score": -6,
              "created_utc": "2025-12-27 13:24:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw6pm01",
          "author": "Bronzeborg",
          "text": "do they not have OBS where you live?",
          "score": -6,
          "created_utc": "2025-12-27 13:17:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3qn0r",
          "author": "BoredHobbes",
          "text": "why not more like infinite talk where it automatic decides how many windows and u can prompt each one with |\n\n i dont get why u have to copy and paste 4-9 times chunk output.",
          "score": -7,
          "created_utc": "2025-12-26 23:26:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3qyg5",
              "author": "shootthesound",
              "text": "This is not a perfect workflow - the point of this is the momentum preservation etc. the workflow can and will be refined by me and/or the community if they so wish",
              "score": 6,
              "created_utc": "2025-12-26 23:28:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw3woon",
          "author": "Current-Row-159",
          "text": "no workflow sir ? plz ?",
          "score": -8,
          "created_utc": "2025-12-27 00:03:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3spsz",
          "author": "Standard-Ask-9080",
          "text": "Thanks Elon!",
          "score": -10,
          "created_utc": "2025-12-26 23:39:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pympur",
      "title": "Amazing Z-Image Workflow v3.0 Released!",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1pympur",
      "author": "FotografoVirtual",
      "created_utc": "2025-12-29 13:47:35",
      "score": 798,
      "num_comments": 102,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pympur/amazing_zimage_workflow_v30_released/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwjpidv",
          "author": "broadwayallday",
          "text": "Didn't know Photon was yours! Legend!",
          "score": 25,
          "created_utc": "2025-12-29 14:12:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwkiihy",
              "author": "ChickyGolfy",
              "text": "Damn, that has been my go-to model for such a long time. It was a beast at the time",
              "score": 13,
              "created_utc": "2025-12-29 16:39:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwmhnge",
              "author": "YMIR_THE_FROSTY",
              "text": "I still have it on HDD.",
              "score": 3,
              "created_utc": "2025-12-29 22:18:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwog9n7",
              "author": "Immediate-Mood-4383",
              "text": "Are you talking about photonlcm? Isn't that by Fill?",
              "score": 1,
              "created_utc": "2025-12-30 04:53:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwk4sok",
          "author": "twellsphoto",
          "text": "Is it possible to load a lora into these workflows?",
          "score": 10,
          "created_utc": "2025-12-29 15:33:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwke1wc",
              "author": "twellsphoto",
              "text": "Figured it out :) Just used the simple lora loader and put in line with the model node",
              "score": 6,
              "created_utc": "2025-12-29 16:17:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwlljcr",
                  "author": "FourtyMichaelMichael",
                  "text": "One, sure.\n\nTwo, TERRIBLE COLLAPSE.\n\nZ-Image has a potential, but until BASE comes out, I'm not interested at all. Turbo is far too finicky for anything that isn't directly in the model.",
                  "score": 7,
                  "created_utc": "2025-12-29 19:41:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwklnyo",
          "author": "nutrunner365",
          "text": "\"\\[rgthree-comfy\\]\\[Reroute\\] You are using rgthree-comfy reroutes with a ComfyUI Primitive node. Unfortunately, ComfyUI has removed support for this. While rgthree-comfy has a best-effort support fallback for now, it may no longer work as expected and is strongly recommended you either replace the Reroute node using ComfyUI's reroute node, or refrain from using the Primitive node (you can always use the rgthree-comfy \"Power Primitive\" for non-combo primitives).\" How exactly do I identify these reroutes, so I can replace them?",
          "score": 11,
          "created_utc": "2025-12-29 16:53:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwmxh7j",
              "author": "DVXC",
              "text": "Same error for me here, and the style selectors are thus completely broken",
              "score": 3,
              "created_utc": "2025-12-29 23:42:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwole6l",
                  "author": "yadius",
                  "text": "Same. I'm on the latest version of ComfyUI, and I've tried all three workflows. I can randomize the seed, but I can't change the default style or prompt.\n\nPretty much get the same default image every time I run it.\n\n\nEdit: Fixed by turning off \"Modern Mode Design\" in the settings menu.",
                  "score": 2,
                  "created_utc": "2025-12-30 05:29:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwpahjq",
              "author": "FirefighterScared990",
              "text": "replace fast muter node with fast bypasser node",
              "score": 1,
              "created_utc": "2025-12-30 09:05:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwjp6yf",
          "author": "aar550",
          "text": "Do you have or can anyone suggest a good image to image workflow ?",
          "score": 8,
          "created_utc": "2025-12-29 14:10:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkigiu",
          "author": "Corleone11",
          "text": "Thanks. I do experience a weird bug. I added the \"Power Lora\" node between the model loader/clip node and the routing nodes. The first generation works flawlessly but when I want to run the workflow again, it doesn't work unless I alter any kind of parameter within the workflow (prompt, style, etc.).\n\nEdit: Solved. The seed was set to fixed.",
          "score": 5,
          "created_utc": "2025-12-29 16:38:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjnt60",
          "author": "fauni-7",
          "text": "Looks really cool.",
          "score": 6,
          "created_utc": "2025-12-29 14:02:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjwqb3",
          "author": "Big0bjective",
          "text": "A lot of images have pop-cultural references I understood since they're simply well done. But didn't know Elmo was a perv",
          "score": 6,
          "created_utc": "2025-12-29 14:52:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwmqrap",
              "author": "IrisColt",
              "text": "Elmo isn't a perv.",
              "score": 1,
              "created_utc": "2025-12-29 23:06:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwki29u",
          "author": "Subject_Work_1973",
          "text": "rgthree-comfy\\]\\[Reroute\\] You are using rgthree-comfy reroutes with a ComfyUI Primitive node. Unfortunately, ComfyUI has removed support for this. While rgthree-comfy has a best-effort support fallback for now, it may no longer work as expected and is strongly recommended you either replace the Reroute node using ComfyUI's reroute node, or refrain from using the Primitive node (you can always use the rgthree-comfy \"Power Primitive\" for non-combo primitives).",
          "score": 5,
          "created_utc": "2025-12-29 16:37:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjqsri",
          "author": "Flothrudawind",
          "text": "I've yet to try it out myself but these example pics are pretty good!",
          "score": 3,
          "created_utc": "2025-12-29 14:19:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjx3ip",
          "author": "krigeta1",
          "text": "Regarding the comic workflow, how can we use like 2-3 characters and keep them consistent per panel? as there is a lora bleed, is it avoidable?",
          "score": 3,
          "created_utc": "2025-12-29 14:54:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkw21h",
          "author": "NefariousnessPale134",
          "text": "Has anybody made one of these with a face swap node",
          "score": 3,
          "created_utc": "2025-12-29 17:43:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjtd04",
          "author": "autistic-brother",
          "text": "![gif](giphy|12tiQSHr16vrcA)",
          "score": 5,
          "created_utc": "2025-12-29 14:34:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwk8f76",
          "author": "retroblade",
          "text": "Nice workflow!  For some reason though, when using loras they come out distorted around the edges.  Probably something I'm doing wrong.",
          "score": 2,
          "created_utc": "2025-12-29 15:51:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkoh11",
          "author": "SEOldMe",
          "text": "Useful, Thanks a lot! Happy Holidays",
          "score": 2,
          "created_utc": "2025-12-29 17:07:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkpcwk",
          "author": "Separate_Bake",
          "text": "My apologies if this has been explained BUT I keep getting the same image output no matter what I type into the prompt (for comic Workflow in ComfyUI)",
          "score": 2,
          "created_utc": "2025-12-29 17:11:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwkvc9z",
              "author": "Busy_Bug2006",
              "text": "Ensure that the seed is not set to fixed.",
              "score": 3,
              "created_utc": "2025-12-29 17:39:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwkwm49",
                  "author": "Separate_Bake",
                  "text": "Thanks. I figured out my issue. I'm using ComfyUI desktop version and had \"Modern Node Design\" enabled which prevented me from seeing the seed option. Once I disabled Modern Node Design I was able to change Seed from fixed",
                  "score": 3,
                  "created_utc": "2025-12-29 17:45:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwlfbww",
          "author": "apachelance",
          "text": "I am using the portable Comfyui version, the workflow is running. However I cannot see any dropdown menu or something else for choosing a style.\n\nhttps://preview.redd.it/3ew7lzhrz6ag1.png?width=1483&format=png&auto=webp&s=8b23fc62144b6073be8700d4376b3d745e0e898b",
          "score": 2,
          "created_utc": "2025-12-29 19:11:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwlk69p",
              "author": "Outrageous_Field_100",
              "text": "same problem here",
              "score": 1,
              "created_utc": "2025-12-29 19:34:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwlkidn",
                  "author": "apachelance",
                  "text": "I opened an issue [https://github.com/martin-rizzo/AmazingZImageWorkflow/issues/2](https://github.com/martin-rizzo/AmazingZImageWorkflow/issues/2)",
                  "score": 2,
                  "created_utc": "2025-12-29 19:36:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwmxjmu",
                  "author": "DVXC",
                  "text": "Ditto, broken here too.",
                  "score": 2,
                  "created_utc": "2025-12-29 23:43:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwll30s",
                  "author": "apachelance",
                  "text": "Which Comfyui are you running: portable / desktop?",
                  "score": 1,
                  "created_utc": "2025-12-29 19:39:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwpol27",
              "author": "hstracker90",
              "text": "No drop down menus. Use Ctrl-M to mute the styles you don't want and Ctrl-M to unmute the style you want. \n\nNo, it's not documented anywhere. :-)",
              "score": 1,
              "created_utc": "2025-12-30 11:15:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwss8u2",
                  "author": "apachelance",
                  "text": "Hmm, there should be radio buttons to choose the style. You can see it on other people screenshots.",
                  "score": 1,
                  "created_utc": "2025-12-30 21:07:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwoit6d",
          "author": "AquaticEdgy",
          "text": "Thank you so much. The workflow is excellent and the instructions were incredibly clear. I'm not sure if I've just had bad luck or what, but this was the first workflow I've downloaded all of the stuff for beforehand because of the readme and everything just worked.",
          "score": 2,
          "created_utc": "2025-12-30 05:10:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjqk19",
          "author": "MrSatan2",
          "text": "What's the difference between \"image\" and \"photo\"? Sorry I'm a beginner\n\nEdit: and any way to add a lora to it?",
          "score": 3,
          "created_utc": "2025-12-29 14:18:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwjvrkb",
              "author": "steelow_g",
              "text": "On civit he shows the variations each one can produce from the presets. Image is basically anything (anime, comic, pixel whatever), where photo is more for actual photography styles",
              "score": 4,
              "created_utc": "2025-12-29 14:47:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwkixbp",
          "author": "16x98",
          "text": "What was Elmo doing?",
          "score": 2,
          "created_utc": "2025-12-29 16:41:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwk1rl4",
          "author": "Infinite_Ad_9204",
          "text": "how much vram do you need for Z-Image ?",
          "score": 2,
          "created_utc": "2025-12-29 15:18:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkpb9s",
          "author": "LiveLaughLoveRevenge",
          "text": "Just trying this out now - very nice!\n\n(Also as a relative novice with comfyui it amazes me to see what a pro can do with it!)",
          "score": 1,
          "created_utc": "2025-12-29 17:11:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkzw1i",
          "author": "Yasstronaut",
          "text": "Really good job. Playing around with it and having good results. Will let you know if I have any requests :)",
          "score": 1,
          "created_utc": "2025-12-29 18:00:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwl3ixu",
          "author": "Maskwi2",
          "text": "Thanks so much! Crazy good workflows :)Â ",
          "score": 1,
          "created_utc": "2025-12-29 18:17:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwl78j4",
          "author": "Puzzleheaded-Rope808",
          "text": "I'll certainly give you props for orginization and the use of the replace node is ingenious. Your whole empty latent grouping can be replaced with an aspect ratio node though. \n\nAmazing work!",
          "score": 1,
          "created_utc": "2025-12-29 18:34:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlgnz9",
          "author": "Maskwi2",
          "text": "I wish I was able to use all these style selectors and input an image (or images, if comic workflow and Manga style was used for example), that would be magical :) Waiting for z-image Edit.Â \n\n\nAgain, amazing work and thanks so much for sharing these!Â ",
          "score": 1,
          "created_utc": "2025-12-29 19:18:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlh2kr",
          "author": "New_Principle_6418",
          "text": "Thanks for sharing this. Is there a tutorial on how to do full fine tuning checkpoints like you did?",
          "score": 1,
          "created_utc": "2025-12-29 19:20:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlr3b1",
          "author": "Dzugavili",
          "text": "Christ, that comic page is just... unbelievable. The prompt adhesion and coherence was just remarkable.",
          "score": 1,
          "created_utc": "2025-12-29 20:08:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlsusb",
          "author": "intermundia",
          "text": "Thanks for posting the workflows I'll try it out",
          "score": 1,
          "created_utc": "2025-12-29 20:17:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlw78c",
          "author": "mcai8rw2",
          "text": "holy balls, these are AMAZING!!! They blow the workflows i was working on CLEAN out of the water. Really REALLY good work. Thank you for sharing",
          "score": 1,
          "created_utc": "2025-12-29 20:33:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlx4ed",
          "author": "mlaaks",
          "text": "Thank you! Those are amazing workflows!",
          "score": 1,
          "created_utc": "2025-12-29 20:38:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlytfe",
          "author": "xbobos",
          "text": "It's amazing WF, good job!",
          "score": 1,
          "created_utc": "2025-12-29 20:46:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwm8z9n",
          "author": "KnifeFed",
          "text": "# BROOM!",
          "score": 1,
          "created_utc": "2025-12-29 21:35:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmks13",
          "author": "intermundia",
          "text": "excellent work. its a great way for people to iterate but it needs a way to fine tune the strength of the style",
          "score": 1,
          "created_utc": "2025-12-29 22:34:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmqlly",
          "author": "IrisColt",
          "text": "I kneel",
          "score": 1,
          "created_utc": "2025-12-29 23:05:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwndsye",
          "author": "OrangeSlicer",
          "text": "NSFW model?",
          "score": 1,
          "created_utc": "2025-12-30 01:12:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwo6llp",
          "author": "rm-rf-rm",
          "text": "Can this do image to image or do we need to wait for the Edit model to come out?",
          "score": 1,
          "created_utc": "2025-12-30 03:52:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwoltt0",
          "author": "Fit_Dragonfruit3158",
          "text": "Gracias!!!",
          "score": 1,
          "created_utc": "2025-12-30 05:32:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwoqdhl",
          "author": "Malterini",
          "text": "Love No. 15",
          "score": 1,
          "created_utc": "2025-12-30 06:07:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwot0ds",
          "author": "ofrm1",
          "text": "What the hell was the prompt for the Pacman one? Lol",
          "score": 1,
          "created_utc": "2025-12-30 06:28:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwovohg",
          "author": "Toupeenis",
          "text": "Yo.. Is that a Golden Axe reference?",
          "score": 1,
          "created_utc": "2025-12-30 06:50:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwp0p2p",
          "author": "newxword",
          "text": "This looks great.can it generate 9 or 12 images by one reference image .like google banana storyboard",
          "score": 1,
          "created_utc": "2025-12-30 07:35:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpgw7u",
          "author": "Master_Yogurtcloset7",
          "text": "for me it always produces the same image regardless the prompt I write.. what am I doing wrong?",
          "score": 1,
          "created_utc": "2025-12-30 10:05:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwpkv0z",
              "author": "soopabamak",
              "text": "i had this, disable modern nodes in settings",
              "score": 1,
              "created_utc": "2025-12-30 10:42:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwpkw97",
                  "author": "soopabamak",
                  "text": "and randomize the seed",
                  "score": 1,
                  "created_utc": "2025-12-30 10:42:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwpu6jp",
                  "author": "Master_Yogurtcloset7",
                  "text": "Amazing thank you! This worked",
                  "score": 1,
                  "created_utc": "2025-12-30 12:02:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpjleb",
          "author": "soopabamak",
          "text": "i got this type of glitches, i don't know why.. somebody help ?\n\nhttps://preview.redd.it/zof6zneojbag1.png?width=1017&format=png&auto=webp&s=c3c71d814e1b8621e1f7489ec8f3889c0f8483fa",
          "score": 1,
          "created_utc": "2025-12-30 10:30:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpq1z2",
          "author": "hstracker90",
          "text": "Thank you very much, I very much appreciate your work. You managed to put the Fooocus style variants back in ComfyUI!\n\nMay I suggest you add some labels into your workflows explaining how to use them. Muting/unmuting is not obvious to everybody.",
          "score": 1,
          "created_utc": "2025-12-30 11:28:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqp4gi",
          "author": "Direct-Vehicle2653",
          "text": "*Rubs hands together* Time to ~~steal~~ borrow more elements for my SIMPLE worms orgy workflow.",
          "score": 1,
          "created_utc": "2025-12-30 15:12:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqrdr9",
              "author": "Direct-Vehicle2653",
              "text": "lol NOPE. This one is just silly, I can't even figure out where to enter the prompt. hahahahahh\n\nToo advanced for me, but thanks!",
              "score": 1,
              "created_utc": "2025-12-30 15:24:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqrolw",
          "author": "janosibaja",
          "text": "\"Amazing\" - this is finally, without any exaggeration, amazing. Amazingly good, brilliant work. And that it is not overcomplicated with unnecessary reasoning, unobtainable LORAs, never-before-seen Nodes, but simply: IT WORKS. Thank you very much for making it. I would like to be notified about it, whatever you do.",
          "score": 1,
          "created_utc": "2025-12-30 15:25:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqv1w3",
          "author": "DirectorDirect1569",
          "text": "It's probably the first time I use a complex workflow without missing nodes. It's amazing. thank you.",
          "score": 1,
          "created_utc": "2025-12-30 15:42:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqx0qc",
          "author": "Justify_87",
          "text": "How to get rid of that shallow depth of field effect in all photos?",
          "score": 1,
          "created_utc": "2025-12-30 15:51:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqyyhn",
          "author": "bands16",
          "text": "Thanks so much!!! The workflows work so well, the options are very convenient to use",
          "score": 1,
          "created_utc": "2025-12-30 16:00:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwugf52",
          "author": "lininop",
          "text": "BROOM!",
          "score": 1,
          "created_utc": "2025-12-31 02:27:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvg0fx",
          "author": "nyambit",
          "text": "how can i change the scheduler?",
          "score": 1,
          "created_utc": "2025-12-31 06:25:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvtdw0",
          "author": "Tragicnews",
          "text": "This worked right out of the box. Thanks for your effort",
          "score": 1,
          "created_utc": "2025-12-31 08:24:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjojhk",
          "author": "Ill-Purchase-3312",
          "text": "![gif](giphy|DvWJHSOxTff84SQsD9|downsized)",
          "score": 1,
          "created_utc": "2025-12-29 14:06:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjpsxd",
          "author": "MalteseDuckling",
          "text": "![gif](giphy|j1m7LhhiIdkwo)",
          "score": 1,
          "created_utc": "2025-12-29 14:13:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjrkk0",
          "author": "Skyline99",
          "text": "Thanks for sharing! i love learning workflows.",
          "score": 1,
          "created_utc": "2025-12-29 14:24:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjsmcl",
          "author": "Wanderer43v3r",
          "text": "Thank you very much!",
          "score": 1,
          "created_utc": "2025-12-29 14:30:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwk14op",
          "author": "Competitive_Ad_5515",
          "text": "Holy shit, Golden Axe! Memory unlocked",
          "score": 1,
          "created_utc": "2025-12-29 15:15:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwk72fw",
          "author": "lynch1986",
          "text": "Geez, don't make me cancel Elmo at Christmas.",
          "score": 1,
          "created_utc": "2025-12-29 15:44:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwk7p5v",
          "author": "Sea-Neighborhood-846",
          "text": "The first image is so weird for my brain to comprehend lol can't believe we're gonna be expected to bang these things in the future ðŸ˜¬",
          "score": 1,
          "created_utc": "2025-12-29 15:47:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkk6ed",
          "author": "singfx",
          "text": "Nice work! Thanks for sharing",
          "score": 1,
          "created_utc": "2025-12-29 16:46:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkmoll",
          "author": "Dogluvr2905",
          "text": "Thanks for the awesome workflows -- appreciate the xmas present :)",
          "score": 0,
          "created_utc": "2025-12-29 16:58:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjmqnc",
          "author": "Legitimate-Pumpkin",
          "text": "Anybody wants a cookie? ðŸ¤«",
          "score": -6,
          "created_utc": "2025-12-29 13:56:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwkcfqv",
              "author": "JuansJB",
              "text": "That's not Cookie Monster, he's perv Olmo",
              "score": 2,
              "created_utc": "2025-12-29 16:10:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwlcfx0",
                  "author": "Legitimate-Pumpkin",
                  "text": "I guess iâ€™m not that old ðŸ˜…",
                  "score": 2,
                  "created_utc": "2025-12-29 18:58:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwjt9iy",
              "author": "autistic-brother",
              "text": "huh?",
              "score": 2,
              "created_utc": "2025-12-29 14:33:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwjvnzj",
                  "author": "Legitimate-Pumpkin",
                  "text": "You donâ€™t want to know, brother",
                  "score": 0,
                  "created_utc": "2025-12-29 14:46:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pw1s08",
      "title": "A Qwen-Edit 2511 LoRA I made which I thought people here might enjoy: AnyPose. ControlNet-free Arbitrary Posing Based on a Reference Image.",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/w7b8h1y95j9g1.png",
      "author": "SillyLilithh",
      "created_utc": "2025-12-26 11:02:54",
      "score": 791,
      "num_comments": 56,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pw1s08/a_qwenedit_2511_lora_i_made_which_i_thought/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nw0bw1e",
          "author": "Designer-Pair5773",
          "text": "Nice! Could you Share something about your Training Data?",
          "score": 31,
          "created_utc": "2025-12-26 11:17:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0xo4d",
          "author": "Striking-Long-2960",
          "text": "Many thanks (without reference latent node)\n\nhttps://preview.redd.it/xfy9mg0g3k9g1.png?width=2000&format=png&auto=webp&s=c2f9608b54f80d95fa1a68abdfc3837addbf5907",
          "score": 16,
          "created_utc": "2025-12-26 14:11:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0zdyf",
              "author": "Striking-Long-2960",
              "text": "mmmm... Ok XD\n\nhttps://preview.redd.it/x54skmxe5k9g1.png?width=1500&format=png&auto=webp&s=6272d1eef0f5e8ba9feda5ab93d49a000e1a7d82",
              "score": 13,
              "created_utc": "2025-12-26 14:22:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw10ba7",
                  "author": "Striking-Long-2960",
                  "text": "It seems that when you use the reference latent node, it mantains the clothes of the second image \n\nhttps://preview.redd.it/8aqk3p2n6k9g1.png?width=1500&format=png&auto=webp&s=68867cdca30677b38d2e3128c18a226dbd01a13b",
                  "score": 5,
                  "created_utc": "2025-12-26 14:28:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw0dzl3",
          "author": "MistaPlatinum3",
          "text": "Love the attention to a huggingface card, very interesting read, with examples, upsides and downsides!",
          "score": 12,
          "created_utc": "2025-12-26 11:37:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw1l2ih",
          "author": "harderisbetter",
          "text": "is there a comfyui workflow with these on to understand how to use it properly? noob here sorry",
          "score": 16,
          "created_utc": "2025-12-26 16:26:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0c3k4",
          "author": "Regular-Forever5876",
          "text": "Awesome !!",
          "score": 7,
          "created_utc": "2025-12-26 11:19:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0ls73",
          "author": "CeraRalaz",
          "text": "what is the difference between base and helper?",
          "score": 4,
          "created_utc": "2025-12-26 12:46:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0o7ha",
              "author": "SillyLilithh",
              "text": "Base and helper complement each other. You should be using both. If we want to be factual, the 'helper' model is a Qwen Image Edit 2509 LoRA of the same idea, just with different training data. I made the original model literally a day before 2511 (RIP to me), and since 2511 supports 2509 models (because 2511 is essentially just a souped up 2509), I gave it a go. \n\nIt did okay, better than using base 2509. But then I refined the dataset by adding more angles and poses, and removing the ones that I found to be superfluous. That is the 'true' 2511 model, the base one. But when it came to actually using it, I felt that it was better than the earlier one I made in some scenarios, but worse in others. It was strange. So when I tried both just on a whim, it made the results a lot more robust. Obviously, with both at a strength of one it is just too much for 2511. But lowering both down to 0.7 worked great, at least in my testing, outperforming the single one I just made by quite a bit. However, feel free to experiment to see if you can get a better result. I always appreciate the experimentation :D",
              "score": 14,
              "created_utc": "2025-12-26 13:05:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw2g5l8",
                  "author": "BeautyxArt",
                  "text": "what 2511 have over 2509 ?",
                  "score": 1,
                  "created_utc": "2025-12-26 19:09:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw0o47s",
              "author": "bhasi",
              "text": "Read the model card, very useful. It says you should use both at 0.7 strenght.",
              "score": 1,
              "created_utc": "2025-12-26 13:05:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw0bfho",
          "author": "SillyLilithh",
          "text": "By the way, despite the uploaded image, I don't use Comfy UI for inference. I use Wan2GP, since its memory management is very good. I just like Comfy aesthetics :D (sorry for no workflow)",
          "score": 14,
          "created_utc": "2025-12-26 11:12:38",
          "is_submitter": true,
          "replies": [
            {
              "id": "nw6c5pi",
              "author": "Temporary-Roof2867",
              "text": "https://preview.redd.it/gtzp90ejeq9g1.png?width=937&format=png&auto=webp&s=5433fa5bd4c502b6bb21347d9731f83e25b6680c\n\nOh my goodness, it worked in comfyui!!!!\n\nJust use the classic workflow and use these nodes to add the LoRA!",
              "score": 5,
              "created_utc": "2025-12-27 11:25:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw10ccs",
              "author": "Perfect-Campaign9551",
              "text": "I have an RTX 3099 and wanGP runs worse for me than comfy. I don't know why. If just runs like crap. I tried a fresh install of it again last week, still stinks.Â ",
              "score": 2,
              "created_utc": "2025-12-26 14:28:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw0copm",
              "author": "biscotte-nutella",
              "text": "How much better is wan2gp? First time I hear of it",
              "score": 1,
              "created_utc": "2025-12-26 11:25:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw0cx25",
                  "author": "SillyLilithh",
                  "text": "It's much simpler than Comfy, has most of the latest models, concurrent updates, and the memory management allows me to play games while generating images or videos (cause it takes so long and I get bored)",
                  "score": 5,
                  "created_utc": "2025-12-26 11:27:21",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nw27rjd",
                  "author": "Arawski99",
                  "text": "My thoughts:\n\nSuper basic UI for the less tech savy. It almost makes ComfyUI look dumb at times.\n\nExtremely poor resource management such as memory, and particularly known for making your entire PC utterly unusuable running certain processes many have reported on their discord. To be fair, ComfyUI has poor memory management, too, and will sometimes just fail until you close it and restart, but nowhere near as bad as Wan2GP. May have finally improved since I last tried like 4 months ago? Doubt it though.\n\nIt likes to try to force you to download large bulks of files you don't need, particularly huge lora packs and stuff.\n\nTends to be unstable and have very unstable performance profiles. When people ask the dev about why the high end performance oriented profiles tend to crash and stuff the dev tells them to use the GPU poor profiles, essentially, because that is also what they use themselves and haven't bothered to fix the others.\n\nDev tends to argue with people and get defensive when issues are reported about it, but then tries to help a day or two later out of guilt.\n\nOverall, kind of a mixed bag. Also several months later so may have improved in some areas.",
                  "score": 3,
                  "created_utc": "2025-12-26 18:25:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw0w1z6",
                  "author": "c_gdev",
                  "text": "Op replied, my 2 cents. Not perfect, but when I can use wan2gp I will. Some things can be a little tricky to find, but mostly doable.\n\nhttps://github.com/deepbeepmeep/Wan2GP",
                  "score": 2,
                  "created_utc": "2025-12-26 14:00:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw0mhot",
          "author": "Compunerd3",
          "text": "Thanks for sharing. We need to make it a normal part of releases to share the before/after effects of Lora model strengths, comparing how much effect the Lora has compared to base models.\n\nNot saying it's the case here but in many Lora releases, the loras themselves do less than the base model alone does, or in some cases make it worse",
          "score": 3,
          "created_utc": "2025-12-26 12:52:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0qs0o",
          "author": "LumaBrik",
          "text": "Nice work, whats the idea behind the 2 lora approach - helper and base ?",
          "score": 4,
          "created_utc": "2025-12-26 13:24:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw2fr19",
          "author": "iternet",
          "text": "Could you provide a workflow that would work with this LoRA?",
          "score": 3,
          "created_utc": "2025-12-26 19:07:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0rpi1",
          "author": "kburoke",
          "text": "Nice. Thank you. I tried it but it changes faces to reference image. Maybe mixing them together.",
          "score": 2,
          "created_utc": "2025-12-26 13:31:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw1fs1q",
          "author": "Eydahn",
          "text": "Not at home right now, does it work with anime 2D images?",
          "score": 2,
          "created_utc": "2025-12-26 15:58:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3k13k",
          "author": "Sydorovich",
          "text": "This shit needs to be built in in base model already after two major updates.",
          "score": 2,
          "created_utc": "2025-12-26 22:47:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0ndcq",
          "author": "Lodarich",
          "text": "Have you been training with diffusion-pipe or ostris?",
          "score": 1,
          "created_utc": "2025-12-26 12:59:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0ogbn",
              "author": "SillyLilithh",
              "text": "Ostris via Runpod.",
              "score": 3,
              "created_utc": "2025-12-26 13:07:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw0xkg0",
                  "author": "Lodarich",
                  "text": "I've never had luck with ostris out of runpod, maybe I'll try again on wsl. Anyway, good results ðŸ‘",
                  "score": 1,
                  "created_utc": "2025-12-26 14:10:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw2v0op",
                  "author": "gillyguthrie",
                  "text": "Oh he added support for 2511??",
                  "score": 1,
                  "created_utc": "2025-12-26 20:30:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw0opym",
          "author": "Yogini12",
          "text": "Thankyou",
          "score": 1,
          "created_utc": "2025-12-26 13:09:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0vfop",
          "author": "ResponsibleKey1053",
          "text": "Awesome, so I'm guessing the lora was composed of a pose library of your poses?\n\nSo then on the model card you show input poses, I'm guessing/hoping they aren't from the training data set?\n\nModel card is brilliant, really appreciate the effort and explanations.",
          "score": 1,
          "created_utc": "2025-12-26 13:56:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw1juhn",
          "author": "trollkin34",
          "text": "I'd like to see one where you can take the person in the pose and replace them with the person in the input so that the output is the same pose, same clothes, same scene, but the body, hair,eye (whole person) is the person from the input. Like cosplay.",
          "score": 1,
          "created_utc": "2025-12-26 16:20:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw1zn85",
          "author": "Noeyiax",
          "text": "Wow thank you !! Happy holidays \n\nanyone have a basic comfyui workflow I can look at? , I haven't tried new qwen with control net with OP lora yet but I'll watch a YouTube video if no one has one all good ðŸ™",
          "score": 1,
          "created_utc": "2025-12-26 17:43:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw2p28s",
          "author": "Temporary-Roof2867",
          "text": "Forgive my ignorance but if it doesn't work on ComfyUI...how do you make it work???ðŸ‘€ðŸ˜¯ðŸ‘€ðŸ˜¯ðŸ‘€",
          "score": 1,
          "created_utc": "2025-12-26 19:57:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3o4k1",
          "author": "Best-Response5668",
          "text": "Loras are outdated.",
          "score": 1,
          "created_utc": "2025-12-26 23:11:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3pd9q",
          "author": "Whole_Paramedic8783",
          "text": "It working for me but sometimes I get the background of image 2 and not image 1. It only happened in a couple generations out of about 6 or 7 I tried. I got the best results using er\\_sde/beta. Using Euler or resmulti I would get weird size looking heads or faces looked slightly different.",
          "score": 1,
          "created_utc": "2025-12-26 23:19:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3xltd",
          "author": "Baphaddon",
          "text": "Just wanna reiterate, though its on your model page; the strength should be set to 0.7 for both! I was confused at first cause my results were a lil weird.",
          "score": 1,
          "created_utc": "2025-12-27 00:09:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw46pq6",
          "author": "MonkeyBoyPoop",
          "text": "Am I able to train character LoRAs using Qwen Edit 2511?",
          "score": 1,
          "created_utc": "2025-12-27 01:03:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw6ybtb",
          "author": "kiba87637",
          "text": "Wow those results are so clean",
          "score": 1,
          "created_utc": "2025-12-27 14:14:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw7hx6i",
          "author": "krigeta1",
          "text": "Hey, I am also training the same concept but for anime, we can talk about it.",
          "score": 1,
          "created_utc": "2025-12-27 16:04:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw7rsiq",
          "author": "hugo-the-second",
          "text": "https://preview.redd.it/ehvglgsg1s9g1.png?width=2048&format=png&auto=webp&s=b6860361a783a489e9a3afa8059fe86a3b0a27a1\n\nI am just trying this in ComfyUI.  \nThe pose transfer works really well.  \nThe downside is, that there are very noticable changes in body proportions and drawing style, with the pose reference image bleeding in noticably.  \nI feel like this is visible in the examples shared by OP, too.  \n(Left is the original, right is the result of applying the pose to it.)",
          "score": 1,
          "created_utc": "2025-12-27 16:54:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw8xy18",
          "author": "Top_1_Percentile",
          "text": "Could you share the workflow your using?",
          "score": 1,
          "created_utc": "2025-12-27 20:31:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwaew7y",
          "author": "clavar",
          "text": "not nunchaku friendly :\\\\",
          "score": 1,
          "created_utc": "2025-12-28 01:26:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwpi7m3",
              "author": "Special_Channel_7617",
              "text": "Nunchaku is the unfriendly one here. Right now iÂ´m without, as they donÂ´t seem to want to even fix their own install workflow. ðŸ˜‚ðŸ˜­",
              "score": 2,
              "created_utc": "2025-12-30 10:17:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwqmrzy",
                  "author": "clavar",
                  "text": "True, it was annoying to install nunchaku. This lora works on 2509 nunchaku using conditioning full reference but not without tons of errors on the console. For better experience/quality with this lora, nunchaku is not ideal.",
                  "score": 1,
                  "created_utc": "2025-12-30 15:00:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw21rm1",
          "author": "Reasonable-Plum7059",
          "text": "Ehh, comfyui version needed:(",
          "score": 1,
          "created_utc": "2025-12-26 17:54:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw2r6fe",
              "author": "Striking-Long-2960",
              "text": "???\n\nIt works on comfyUI\n\nhttps://preview.redd.it/m3xfe8u9vl9g1.png?width=1225&format=png&auto=webp&s=905742ed5dd86f8db759c270981a7452d003fe8c",
              "score": 3,
              "created_utc": "2025-12-26 20:09:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw3q4zn",
                  "author": "Symetrie",
                  "text": "Can you show the whole workflow please? I think the guy was asking for that, I struggle too!",
                  "score": 0,
                  "created_utc": "2025-12-26 23:23:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pvkza6",
      "title": "Putting SCAIL through its paces with various 1-shot dances",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/97lwuqimje9g1",
      "author": "mtrx3",
      "created_utc": "2025-12-25 19:36:41",
      "score": 729,
      "num_comments": 60,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Animation - Video",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pvkza6/putting_scail_through_its_paces_with_various/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nvx7y3j",
          "author": "Nooreo",
          "text": "Amazing! so glad the 5 second limit is being broken for AI video gen!",
          "score": 23,
          "created_utc": "2025-12-25 20:53:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvxu4yl",
          "author": "IrisColt",
          "text": "Where can someone watch the video without PogChamp? Asking for a friend, heh",
          "score": 19,
          "created_utc": "2025-12-25 23:12:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0fukh",
              "author": "Straight_Fish_704",
              "text": "What's a pogchamp?",
              "score": 3,
              "created_utc": "2025-12-26 11:55:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw0o2oh",
                  "author": "Hqjjciy6sJr",
                  "text": "Referring to the face of the guy that was put over the character at times...",
                  "score": 6,
                  "created_utc": "2025-12-26 13:04:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw01w40",
              "author": "RE4LC4KE",
              "text": "bruh, touch womanÂ Â ",
              "score": -5,
              "created_utc": "2025-12-26 09:35:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvwvmtv",
          "author": "mtrx3",
          "text": "Workflow: [https://github.com/kijai/ComfyUI-WanVideoWrapper/blob/main/example\\_workflows/wanvideo\\_SCAIL\\_pose\\_control\\_example\\_01.json](https://github.com/kijai/ComfyUI-WanVideoWrapper/blob/main/example_workflows/wanvideo_SCAIL_pose_control_example_01.json)\n\nEach clip at 736x1280 24 FPS took around 1 hour with undervolted 5090 32GB + A2000 12GB combo. Interpolated to 30 FPS and cropped to 720p in Resolve Studio.",
          "score": 66,
          "created_utc": "2025-12-25 19:38:24",
          "is_submitter": true,
          "replies": [
            {
              "id": "nvxea1s",
              "author": "broadwayallday",
              "text": "clean work. gonna see how some version of this works on my 3090, will go for much shorter clips",
              "score": 13,
              "created_utc": "2025-12-25 21:32:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvxtedu",
                  "author": "mtrx3",
                  "text": "You'll be fine, just offload enough layers to RAM and sky is the limit.",
                  "score": 7,
                  "created_utc": "2025-12-25 23:07:06",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvy8dte",
              "author": "Turbulent_Owl4948",
              "text": "Would you be willing to explain the undervolting? I've been seing this alot in this sub recently. Whats the benefit? Power usage?",
              "score": 6,
              "created_utc": "2025-12-26 00:42:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvyma1d",
                  "author": "Significant-Baby-690",
                  "text": "Basically you want as low voltage as possible (as it's still reliably working). You than have more headroom in clock speed. Which you can either increase manually, or leave it on power or temperature limit, and it will just automatically reach higher speeds.\n\nSometimes lowering the voltage by few mV can get you several % in clock.",
                  "score": 8,
                  "created_utc": "2025-12-26 02:17:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvzr5jl",
                  "author": "_BreakingGood_",
                  "text": "4090s and 5090s can run at roughly 75% of their normal power usage with only a tiny effect on performance. Generally only 2-3 fps in games.\n\nPersonally, I've found the performance difference to be very noticeable with AI gens. But I think the common usage of undervolting for gaming has sort of carried its way to being common in AI gen too.\n\nIt's just a lot more comfortable to run these cards at lower voltage because of how close to the sun they fly with their manufacturer power suggestions (melting cables, etc...)",
                  "score": 7,
                  "created_utc": "2025-12-26 07:42:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw0j5up",
                  "author": "Genocode",
                  "text": "If done right it lowers power usage, which in turn lowers temperatures, which allows you to then overclock a little more.",
                  "score": 3,
                  "created_utc": "2025-12-26 12:24:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvwxamv",
              "author": "thisiztrash02",
              "text": "one 5 second  clip took an hour?",
              "score": 4,
              "created_utc": "2025-12-25 19:48:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvwxukd",
                  "author": "mtrx3",
                  "text": "Most of the clips are 20-30 seconds.",
                  "score": 16,
                  "created_utc": "2025-12-25 19:51:40",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw09j4b",
              "author": "xyzdist",
              "text": "u/mtrx3 , Hi OP, what is the step you are using?",
              "score": 1,
              "created_utc": "2025-12-26 10:53:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw44mhe",
              "author": "VirusCharacter",
              "text": "https://preview.redd.it/q3n04m7e9n9g1.png?width=613&format=png&auto=webp&s=bf632e00800b765fba36d5b6b5ed0d8a15ba4ade\n\nI have some node conflicts with the SAM2 nodes. This workflow should be updated to SAM3 somehow I thinkðŸ˜•  \nAlso these two custom nodes are in conflict with eachother ðŸ¤·â€â™‚ï¸",
              "score": 1,
              "created_utc": "2025-12-27 00:50:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw61f43",
              "author": "bickid",
              "text": "How do I open this file? When I drag and drop it into ComfyUI, I'm just stuck at infinite loading. thx",
              "score": 1,
              "created_utc": "2025-12-27 09:40:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvx2mx1",
          "author": "fakenkraken",
          "text": "Is the character all from a single base face image?",
          "score": 7,
          "created_utc": "2025-12-25 20:20:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvxk1kv",
          "author": "PyrZern",
          "text": "Any robot dance ? I wonder how uncanny it would be like.,",
          "score": 7,
          "created_utc": "2025-12-25 22:07:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvxquxv",
          "author": "emplo_yee",
          "text": "Have you tried breakdancing? I find that even when the nlf pose is correct, SCAIL will still put shoes on hands when the b-boy is upside down spinning on their heads/hands.",
          "score": 5,
          "created_utc": "2025-12-25 22:50:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvz98yo",
          "author": "DigThatData",
          "text": "~~what's SCAIL?~~\n\nNINJA EDIT: ah. https://teal024.github.io/SCAIL/",
          "score": 6,
          "created_utc": "2025-12-26 05:02:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvx9jyb",
          "author": "Better-Interview-793",
          "text": "Problem with SCAIL is it sometimes changes background objects, esp in longer vids or when the camera moves",
          "score": 4,
          "created_utc": "2025-12-25 21:03:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvy7m8e",
              "author": "Zenshinn",
              "text": "I'm running my 1st try right now with the Q8 GGUF and it's changing the background from a beach to a lake with a waterfall and adding a hood to the character. Hilarious.\n\nAt least WAN Animate wasn't doing that.",
              "score": 5,
              "created_utc": "2025-12-26 00:38:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvy8cmw",
                  "author": "mtrx3",
                  "text": "I found WAN animate to always morph the output target characters physique/skeleton to match the motion data character, need to pick your poison with these two models.",
                  "score": 3,
                  "created_utc": "2025-12-26 00:42:34",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvxy6qj",
              "author": "LakhorR",
              "text": "Yeah you can see the light switches on the wall and hinges on the door morphing, appearing and disappearing (not to mention her arms phasing through eachother and weird unnatural twisting of the hands and other limbs).\n\nUnfortunately, this doesnâ€™t pass",
              "score": 2,
              "created_utc": "2025-12-25 23:38:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvxzc8o",
                  "author": "mtrx3",
                  "text": "It's not perfect, but so far it's the best we have in the local AI sphere. A lot of the errors could be fixed by running multiple generations, these are all 1-shot and done, zero cherry picking. I didn't feel like running same clips over and over, given one run took an hour each.\n\nThere's only so much that can be done with sparse grid attention that these >5 second video models use, which result in background iffyness. A lot of the hand and finger problems originate to the 512x896 resolution of the motion vectors. Higher resolution motion vector capture is possible, but at that point our consumer tier 24-32GB VRAM cards start to struggle I suspect.",
                  "score": 7,
                  "created_utc": "2025-12-25 23:46:02",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nvz97tr",
                  "author": "DigThatData",
                  "text": "the background here is stationary. trivial fix.",
                  "score": 3,
                  "created_utc": "2025-12-26 05:02:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvxpj54",
          "author": "Iniglob",
          "text": "With 16GB of VRAM and using a Q3 (a higher-end model gave me a memory error), it took me 20 minutes, with excellent results. Of course, the quality was medium due to quantization. It was a good experiment; it's not feasible for me to spend 20 minutes on a video, but it's already a significant improvement.",
          "score": 2,
          "created_utc": "2025-12-25 22:42:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvwyrk8",
          "author": "Zounasss",
          "text": "Do we know when the full scail model will be released?",
          "score": 4,
          "created_utc": "2025-12-25 19:57:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvyome3",
              "author": "Segaiai",
              "text": "TIL we don't have the full SCAIL model.",
              "score": 4,
              "created_utc": "2025-12-26 02:33:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvzqc22",
          "author": "xyzdist",
          "text": "Could u share the source video link? So to test it",
          "score": 3,
          "created_utc": "2025-12-26 07:34:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw09ems",
          "author": "xyzdist",
          "text": "SCAIL is the best we have by far. looking forward to facial expression replication in their next update.  \nalso, it is the only one workflow working for non-human proportion, which others claimed working just didnt from my testing.",
          "score": 2,
          "created_utc": "2025-12-26 10:52:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw8g3fu",
          "author": "Bubbly-Wish4262",
          "text": "Scail is goat so far",
          "score": 2,
          "created_utc": "2025-12-27 18:56:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvx64fj",
          "author": "Ferriken25",
          "text": "Very good. Can't wait for gguf version.",
          "score": 3,
          "created_utc": "2025-12-25 20:42:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvxbiza",
              "author": "ANR2ME",
              "text": "You meant this? https://huggingface.co/vantagewithai/SCAIL-Preview-GGUF",
              "score": 14,
              "created_utc": "2025-12-25 21:16:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvxu73w",
          "author": "abdallha-smith",
          "text": "Tracklist plz ?",
          "score": 2,
          "created_utc": "2025-12-25 23:12:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw2oigb",
          "author": "Darth_Iggy",
          "text": "For godâ€™s sake, why is it always young girls dancing? Am I the only one interested in this technology for useful less horny purposes?",
          "score": 2,
          "created_utc": "2025-12-26 19:54:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvybhwp",
          "author": "Chicken_Grapefruit",
          "text": "This looks great. I want to learn how to make ai videos. Do you know where I can start?",
          "score": 1,
          "created_utc": "2025-12-26 01:02:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzym93",
          "author": "witcherknight",
          "text": "wat was the input image",
          "score": 1,
          "created_utc": "2025-12-26 09:00:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0q89d",
          "author": "Wonderful_Wrangler_1",
          "text": "Can you share input video?",
          "score": 1,
          "created_utc": "2025-12-26 13:20:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw1ch2r",
          "author": "Gullible_Ad_5550",
          "text": "These are ai? holy shit",
          "score": 1,
          "created_utc": "2025-12-26 15:40:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw4quq1",
          "author": "baltxweapon",
          "text": "Could I run this on a 5070? I only need 5 to 10 second videos",
          "score": 1,
          "created_utc": "2025-12-27 03:13:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw5pnl0",
              "author": "beewweebgirls",
              "text": "Runs on my 5070 Ti, should run on a 5070 too.",
              "score": 2,
              "created_utc": "2025-12-27 07:46:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvxkiip",
          "author": "Chris_in_Lijiang",
          "text": "Is the prompt text, or a wire frame video?",
          "score": 1,
          "created_utc": "2025-12-25 22:10:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvy7ql4",
              "author": "Zenshinn",
              "text": "The input is a video. The wire frame will be extracted from it.",
              "score": 1,
              "created_utc": "2025-12-26 00:38:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw0freb",
          "author": "Straight_Fish_704",
          "text": "Eyes freaking me out!\nIs she blind?",
          "score": 1,
          "created_utc": "2025-12-26 11:54:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw20th1",
          "author": "Jacks_Half_Moustache",
          "text": "Oh look, another fucking Japanese schoolgirl dancing in a hallway. We've peaked.",
          "score": 0,
          "created_utc": "2025-12-26 17:49:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw218f7",
          "author": "StuffProfessional587",
          "text": "Looks great but, the girl used is so skinny, kills the dancing by lack of body muscles.",
          "score": 0,
          "created_utc": "2025-12-26 17:52:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw37vva",
              "author": "Abject-Recognition-9",
              "text": "![gif](giphy|cfskn2Ozn7j9K)",
              "score": 3,
              "created_utc": "2025-12-26 21:40:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvxss36",
          "author": "EpicNoiseFix",
          "text": "Kling 2.6 motion control works so much better",
          "score": -14,
          "created_utc": "2025-12-25 23:03:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvxtbtk",
              "author": "mtrx3",
              "text": "I didn't know Kling 2.6 is open-source and local, as per rule #1. Mind passing the model weights so I can run it on my workstation?",
              "score": 19,
              "created_utc": "2025-12-25 23:06:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pxhaje",
      "title": "First three hours with Z-Image Turbo as a fashion photographer",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/f35534ox7v9g1.jpeg",
      "author": "DoPeT",
      "created_utc": "2025-12-28 03:45:27",
      "score": 639,
      "num_comments": 112,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pxhaje/first_three_hours_with_zimage_turbo_as_a_fashion/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwb3v1u",
          "author": "eye_am_bored",
          "text": "Nice images, Im an amateur artist of many years so I'm always interested to see photographers/ artists using AI! You guys always create great compositions, unlike the usual 1girl images you see here these have really nice variety, I've found z-image really flexible in a lot of ways, was there anything you found it couldn't do that you really wanted? And have you implemented any models / workflows into your professional work?",
          "score": 51,
          "created_utc": "2025-12-28 03:56:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwb70jg",
              "author": "DoPeT",
              "text": "Thank you so much â€” I really appreciate that.\n\nSomethingâ€™s I found being used from the early SD days where prompting felt very mechanical: lens, aperture, weights, keywords, commas everywhere. That mindset still carries into how I shoot in real life too â€” Iâ€™ll instinctively think in terms of focal length, light direction, color temperature, composition rules, etc. Flux especially rewards that kind of structured, descriptive prompting.\n\nWhat surprised me with Z-Image Turbo is that while it does like longer prompts, it doesnâ€™t necessarily want them to be technical in the traditional photography sense. I actually started getting better results when I stopped over-specifying and instead described the feeling of the shot â€” almost like writing a 2016 Tumblr caption that implies the technical decisions rather than spelling them out.\n\nSo instead of listing every camera and lighting parameter, Iâ€™d describe the scene, posture, light, and mood in a more narrative way â€” and oddly enough, that seemed to land more consistently. Tools like JoyCaption / TagGUI plus small mood boards have helped a lot with that, especially since Iâ€™m very much a certified yapper.\n\nAs for limitations so far: very specific POVs are still tricky. If I try to lock in something like a precise first-person or top-down angle (e.g. looking down at someoneâ€™s knees in snow, cigarette ember glowing, shot as if from an iPhone held above the head), it often interprets the idea but misses the exact perspective. Small articulation details like toes, fingers holding cigarettes, etc. can also struggle â€” though thatâ€™s not unique to this model, and Iâ€™m only a few hours in.\n\nOn the professional side, yes â€” I already use AI in workflows, mostly for in-painting, cleanup, and augmenting existing imagery. That feels like a natural evolution of what weâ€™ve been doing in Photoshop for years rather than a full replacement. I havenâ€™t run an entire campaign end-to-end through AI yet, but itâ€™s getting surprisingly close.\n\nOverall though, for how fast it is and how strong the compositions come out, this has been one of the smoothest first impressions Iâ€™ve had with a model in a long time.",
              "score": 43,
              "created_utc": "2025-12-28 04:16:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwcqxx4",
                  "author": "mediamuesli",
                  "text": "Hi, photographer as well. How do you plan to deal with ai business wise. Are you going to offer AI photos for your clients for a cheaper rate? Can you still distinguish ai and real photos in web resolution? Good enough consistency for whole sets?",
                  "score": 5,
                  "created_utc": "2025-12-28 12:27:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwctqyf",
                  "author": "eye_am_bored",
                  "text": "Wow thanks for the very detailed response, I have found exactly the same the prompting language is quite different, and the prompts have to be longer but to me that's totally worth the extra effort because it actually does what I'm asking 99% of the time\n\nYeah I have found POV quite difficult as it doesn't respond to simple keywords like that and finding the language it expects is sometimes difficult\n\nIt certainly does struggle with some hands / feet but I have found it to be much, much better than other open source models. I'm hoping a lot of the issues I've had will be solved by the full model, especially little details like that, which people now focus on like hawks and need to be perfect\n\nIn terms of the work how do you feel about implementing AI? Just in terms of pure enjoyment for the work is it more or less enjoyable with AI? In terms of time saved has it made a big difference there?",
                  "score": 2,
                  "created_utc": "2025-12-28 12:50:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwb5kwl",
          "author": "Version-Strong",
          "text": "Stunning 'fashion' results",
          "score": 29,
          "created_utc": "2025-12-28 04:06:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwb7pvw",
              "author": "DoPeT",
              "text": "Haha, thank you!! ðŸ¥¹ Honestly not far off from what youâ€™d see walking through a mall past H&M or Urban Outfitters ðŸ˜Š Appreciate taking time to comment ðŸ«¶",
              "score": 8,
              "created_utc": "2025-12-28 04:21:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwgti1j",
                  "author": "Version-Strong",
                  "text": "Ha!",
                  "score": 1,
                  "created_utc": "2025-12-29 01:24:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwba258",
          "author": "DiligentRanger007",
          "text": "Nice work you naughty boy.. lol",
          "score": 12,
          "created_utc": "2025-12-28 04:37:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbbxfe",
              "author": "DoPeT",
              "text": "![gif](giphy|y6Sl42U3xEFkk)\n\nFor some reason â€” you're comment immediately reminided me of this Austin Power's scene and I'm so glad for it ðŸ˜‚ And, thank you tons.",
              "score": 12,
              "created_utc": "2025-12-28 04:50:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwctitk",
                  "author": "Dynamicman95",
                  "text": "I've been watching this for two hours. Does he get out or not???",
                  "score": 11,
                  "created_utc": "2025-12-28 12:48:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwbh9a9",
          "author": "andylehere",
          "text": "it costs 5k buzz... too crazy :))",
          "score": 6,
          "created_utc": "2025-12-28 05:29:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbn9mm",
              "author": "luciferianism666",
              "text": "[https://huggingface.co/sinatra-rd/real-dream-z-image-turbo-release/blob/main/real-dream-z-1.safetensors](https://huggingface.co/sinatra-rd/real-dream-z-image-turbo-release/blob/main/real-dream-z-1.safetensors) not on huggingface lol",
              "score": 10,
              "created_utc": "2025-12-28 06:17:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwbppzo",
                  "author": "DoPeT",
                  "text": "Nice!! citivai tends to cross-sell paywall these hyped authors â€” heâ€™s a few versions ahead already than on huggingface which so far is much better! Thank you for sourcing this!! I should change the link in OP :)",
                  "score": 0,
                  "created_utc": "2025-12-28 06:38:33",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwbkyba",
              "author": "DoPeT",
              "text": "His Patreon cost $1/mo linked in his model post, you could cancel and download it for that. In fact, v3 now there! I suggest staying with him. Heâ€™s an amazing artist and engineer.",
              "score": 2,
              "created_utc": "2025-12-28 05:58:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwc18rb",
                  "author": "SearchTricky7875",
                  "text": "OP, is it the same model available here on huggingface [https://huggingface.co/sinatra-rd](https://huggingface.co/sinatra-rd)",
                  "score": 3,
                  "created_utc": "2025-12-28 08:25:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwo3o56",
                  "author": "AI_Characters",
                  "text": "This actually gave me an idea.\n\nI think I found a way to paywall some of my models without getting a lot of hate for it. I think I am going to use my Patreon to release experimental test versions of models which for one reason or another have fundamental flaws and are thus not suitable for a full free release but which might interest people nonetheless.\n\nThanks.",
                  "score": 1,
                  "created_utc": "2025-12-30 03:35:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwc6rzt",
          "author": "Major_Specific_23",
          "text": "thanks for sharing a lot of details about your process. ain't no way you need 50 steps for that 1 girl",
          "score": 4,
          "created_utc": "2025-12-28 09:19:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwhxffa",
              "author": "DoPeT",
              "text": "Haha, thank you!! ðŸ˜Š Youâ€™re also right â€” I didnâ€™t, but did?\n\n25 steps nearly was the same but missed features like an ice pick acne scar or uneven texture or the few macro details of dried lip lines suggesting slight dehydration, and so on â€” typing that sound pretty weird but itâ€™s those type of details I notice in compositions ðŸ˜© \n\n50 seems to be perfect though for my use case! I didnâ€™t see too much of a marginal difference with my Xs/it going from 25 to 150 on my 5090 which blew my mind. It just kind of got worse after 80 ðŸ˜‚ \n\nIâ€™m curious, what do you use for steps? Or anything different you like to run with your workflow? Would love to learn more!",
              "score": 1,
              "created_utc": "2025-12-29 05:27:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwi55s6",
                  "author": "Major_Specific_23",
                  "text": "i know its tempting to use the highest rated loras from civitai to maximize the quality of the images but what you are showing here is nothing new to zimage turbo. in fact i think that the 3 loras you are using are killing the final image quality (zooming in on your image reveals snake skin texture). you use them at very low strength so they do not have enough room to show the stuff they are trained on but at the same time they suck zimage quality a bit. get rid of them. you say \"fashion photographer\" but you are using loras that makes images look like they are from 2000's (its weird to me). if you want grain, just add it in post. no need to kill the quality of the turbo model just to add it.\n\nand the checkpoint you are using - its a lora merged with z-image and its fp8 (at least thats what i see in civitai and i also suspect they used AI generated images in training because i see that \"1girl\" and \"plasticyness\"). kill it too. just use the bf16 turbo version. looking at the showcased images of that realdream model, i can tell you that the turbo model can do the same at a much higher quality\n\nabout the workflow, you cannot add whats not there with seedvr2. your initial image should have details so you can make them pop. try this workflow - [https://www.reddit.com/r/StableDiffusion/comments/1paegb2/my\\_4\\_stage\\_upscale\\_workflow\\_to\\_squeeze\\_every\\_drop/](https://www.reddit.com/r/StableDiffusion/comments/1paegb2/my_4_stage_upscale_workflow_to_squeeze_every_drop/)\n\ntldr, remove those 3 loras, use bf16 original model, start with 9 steps euler/beta57 or ddim\\_uniform or res\\_2s/flowmatcheulerdiscrete, try to understand how zimage responds to your prompts and adjust them. remember that prompt is king with zimage",
                  "score": 4,
                  "created_utc": "2025-12-29 06:28:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwbktu0",
          "author": "dry_garlic_boy",
          "text": "It's interesting how you use so many em dashes in your post and responses.",
          "score": 15,
          "created_utc": "2025-12-28 05:57:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbmexe",
              "author": "DoPeT",
              "text": "I know.. I see where youâ€™re going with this â€” of course I refine messages at work and even posts like this. Just know itâ€™s from me. Iâ€™d post this GPT meme where itâ€™s like â€œgod damnit I can never use them again ðŸ˜­â€ but canâ€™t find it in my albums or care to search for it.",
              "score": 5,
              "created_utc": "2025-12-28 06:10:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwbmqpz",
                  "author": "DoPeT",
                  "text": "nvm Photos made it easy using the search filter ðŸ¤£\n\nhttps://preview.redd.it/88jnpudxzv9g1.jpeg?width=1141&format=pjpg&auto=webp&s=7cd04ea706685011b4b64dacd3977086b4ac00a3",
                  "score": 26,
                  "created_utc": "2025-12-28 06:13:00",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nwc160g",
                  "author": "2this4u",
                  "text": "You're destroying your writing abilities by over-relying on AI. It's a social media post not a CV, you should be able to write something yourself without copy pasting from an LLM. Sure get advice from it but don't just use its output.\n\nIf some random person on Reddit thought it looked weird imagine how weird it seems for your colleagues who know your better and see this robotic speech.",
                  "score": 12,
                  "created_utc": "2025-12-28 08:24:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwc65i5",
              "author": "dennisler",
              "text": "Its funny that you think it seems a problem, I enjoyed reading a post where you shouldn't guess what the meaning is...",
              "score": 2,
              "created_utc": "2025-12-28 09:13:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwbdy20",
          "author": "jadhavsaurabh",
          "text": "I guess now we reached point until, edit model doesn't come it all doesn't make any sense",
          "score": 2,
          "created_utc": "2025-12-28 05:04:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwbn9g1",
          "author": "leyermo",
          "text": "are you using any lora, or any other workflow. Will you use your generated image in your own photoshoot? means, are these images production ready?\n\nI want to generate images in same field but more boudoir. \n\nPlease provide me any suggestions.\n\nThanks for sharing.",
          "score": 2,
          "created_utc": "2025-12-28 06:17:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbo0uq",
              "author": "DoPeT",
              "text": "Great questions, and thank you ðŸ™‚\n\nFor the LoRAs and workflow, I actually posted an image + breakdown just above in this thread. That includes the exact workflow Iâ€™m using and the LoRAs I tend to reach for, so Iâ€™d definitely start there and keep it mostly as-is at first.\n\nIn terms of professional use, yes, I do use AI in real projects, but not as a full replacement. So far itâ€™s been layered into existing photoshoots. Think in-painting, cleanup, subtle atmosphere shifts, or exploring alternate angles or moods that build off a real shoot with real talent, lighting, and a full team. The initial shoot and human direction are still the anchor.\n\nI havenâ€™t run a fully end-to-end AI campaign yet. Itâ€™s getting closer, which is exciting and a little strange at the same time, but for now I see it as a powerful extension rather than a total swap.\n\nIf youâ€™re aiming for more boudoir specifically, a big tip would be to spend time on mood boards first. Iâ€™ve had really good results using TagGUI with JoyCaption. Feed it a lot of reference images from Tumblr or Pinterest that capture the feeling you want, then reverse-engineer those captions into prompts. That tends to work better than trying to be overly technical right away. Iâ€™ll send you the prompts that Iâ€™m using and TagGUI where I tend to get these results when I get back to my computer!\n\nWith the workflow and model mentioned above, plus a few carefully chosen LoRAs, you should be able to get very close to what youâ€™re looking for. Take it slow, iterate, and let the mood lead.",
              "score": 10,
              "created_utc": "2025-12-28 06:23:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwbsqul",
                  "author": "leyermo",
                  "text": "Thank you so much for your detailed response. Looking forward to your prompts and tags.",
                  "score": 2,
                  "created_utc": "2025-12-28 07:05:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwbr1rx",
          "author": "mysticreddd",
          "text": "ðŸ”¥ðŸ”¥ðŸ”¥ I agree on your insight.",
          "score": 2,
          "created_utc": "2025-12-28 06:50:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbxjvr",
              "author": "DoPeT",
              "text": "ðŸ¥¹ðŸ–¤",
              "score": 1,
              "created_utc": "2025-12-28 07:50:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwg7831",
          "author": "Terezo-VOlador",
          "text": "Hi, I'm also a photographer. But I've encountered quite a few obstacles in achieving what I want. Partly, this is due to using too many technical details, which it completely ignores.\n\nIf you could, please share a prompt for reference. Great work!",
          "score": 2,
          "created_utc": "2025-12-28 23:23:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwhs4uy",
              "author": "DoPeT",
              "text": "Hi friend! Check my post above where I use TagGUI and have it caption reference photos from a moodboard folder with my prompt. I ultimately use that or combine a few depending on what Iâ€™m creating.",
              "score": 2,
              "created_utc": "2025-12-29 04:50:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwbgion",
          "author": "Elrandra",
          "text": "As a gooner photographer\\*.\n\nWhy are 90% of the images people post of half naked women? Do you have no imagination beyond sexy women?",
          "score": 5,
          "created_utc": "2025-12-28 05:23:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc0sny",
              "author": "2this4u",
              "text": "Tbf \"fashion photographer\" isn't that what you'd expect based on all the fashion adverts you've seen?",
              "score": 12,
              "created_utc": "2025-12-28 08:21:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwbopk8",
              "author": "Structure-These",
              "text": "Itâ€™s more fun to make naked women than an old man at the sea or whatever, and I think people know what they want from nsfw in detail, so it logically becomes how ppl â€˜benchmarkâ€™ a new model\n\nIt inspires creativity from Iâ€™m assuming otherwise un creative people which is cool",
              "score": 15,
              "created_utc": "2025-12-28 06:29:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwbhkuj",
              "author": "DoPeT",
              "text": "Honestly, I love your question! ðŸ˜‡ And, youâ€™re not wrong, I ask myself a similar thing sometimes too.\n\nI think a lot of what youâ€™re pointing at comes down to context and intent. In my case, my background is in fashion and product photography, so the way I approach these images is less about â€œsexyâ€ and more about how it feels to wear something, how fabric sits on a body, how light interacts with skin, and the emotional tone that clothing can carry.\n\nThatâ€™s very different from generating an image to look at someone, versus generating an image to understand style, fit, mood, or identity â€” which is how Iâ€™ve always approached this kind of work. Itâ€™s closer to editorial or retail imagery youâ€™d see in everyday fashion spaces than fantasy.\n\nFor this post specifically, I chose these examples because theyâ€™re technically difficult for models to render convincingly, not because of subject matter. Human form + fabric + lighting tends to expose strengths and weaknesses faster than safer categories. Itâ€™s still what Iâ€™d shoot though besides for that edge case.\n\nTotally fair if that aesthetic isnâ€™t everyoneâ€™s thing â€” but for me it comes from a product and storytelling lens rather than novelty or provocation.\n\nHope that sortaâ€™ helps ðŸ˜…",
              "score": 23,
              "created_utc": "2025-12-28 05:32:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwbiei4",
                  "author": "Elrandra",
                  "text": "It does help. You're probably the first person that has given any explanation. To me, personally, at least.\n\nYour eye is different than my eye, you see things differently than I see them.\n\nI get the desire to prompt things we find more appealing, whatever form that may be...I tend to prompt only men, I just don't generally post them.\n\nI wouldn't mind so much if people included other examples, which..you did, at least with the up close eye shot. Granted it was only one, which triggered my speculation.\n\nThank you for your explanation, and I'm sorry for making you have to give it. I just get annoyed at all the half naked women in the majority of the AI posts. I love to see what AI can do, I just dislike how we seem to limit it so much to women rather than using our imaginations.",
                  "score": 3,
                  "created_utc": "2025-12-28 05:38:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nweyfoy",
          "author": "robsonsnunes",
          "text": "As a fashion promptman, u mean.",
          "score": 1,
          "created_utc": "2025-12-28 19:39:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwbid5y",
          "author": "7CloudMirage",
          "text": "could you share the workflow link plz",
          "score": 1,
          "created_utc": "2025-12-28 05:38:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbig29",
              "author": "DoPeT",
              "text": "Here you go buddy! :)\n\nhttps://civitai.com/models/2225814/z-image-turbo-boosted-one-click-ultra-clean-images-seedvr2-flashvsr-face-upscale-qwen-vl",
              "score": 5,
              "created_utc": "2025-12-28 05:38:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwbkuex",
                  "author": "7CloudMirage",
                  "text": "awesome I been wanting to switch to ZIT",
                  "score": 2,
                  "created_utc": "2025-12-28 05:57:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwbylub",
          "author": "CyclonicCheese",
          "text": "How good can this model do old hairy middle aged men? I only see young females generated here, I would have tried by myself by I only have a casio calculator with low vram.",
          "score": 1,
          "created_utc": "2025-12-28 08:00:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc196z",
              "author": "DoPeT",
              "text": "It did pretty decent with the story that came in my head of the user story you provided me, it's rather interesting and out-casty it turned out with I am with how I directed this shot ðŸ˜‚\n\nhttps://preview.redd.it/8og66dkgnw9g1.png?width=3316&format=png&auto=webp&s=9dd09ed7e57379c2867149fc4a035f28344468f6\n\n>POS:\n\n>An intimate, cinematic photograph of an elderly bald man seated at a row of vintage slot machines inside a quiet casino.\n\nThe camera is close, chest-up framing, slightly off to his right side. His face is sharply in focus, skin textured with age, pores, wrinkles, sun-worn realism. His hands rest on the machine buttons, veins visible, fingers still, deliberate.\n\n>Shallow depth of field. The manâ€™s eyes and hands are crisp, everything else gently falling away into soft blur.\n\n>Two identical slot machines stand behind him like silent witnesses. On the nearest screen, glowing blue, clean readable text says: â€œYou are not alone.â€ The light from the screen softly spills across his face and forearms, cool against warm skin.\n\n>The second machine mirrors it, slightly out of focus, the same screen size and layout, reinforcing repetition and time.\n\n>Lighting feels natural and observational, like a real photograph taken in available light. Warm ambient tones from the room contrast with the cold blue of the screens. No dramatic spotlights. No stylized neon.\n\n>His expression is calm, reflective, quietly content. Not sad. Not smiling. A man who has lived long enough to understand loss and still sit with it.\n\n>The mood is restrained, human, and honest. Documentary realism with cinematic intimacy.\n\n>Shot on a full-frame camera, 50mm prime lens, wide aperture (around f/1.6). Soft background compression, natural perspective.\n\n>Feels like a still frame from a film about time, habit, and endurance. Not nostalgic. Not ironic. Just present.\n\n>Hyper-realistic photography. No exaggeration. No surreal distortion. Everything feels physically possible.\n\nEDIT: The blockquotes and markdown is being silly, excuse the formatting!",
              "score": 7,
              "created_utc": "2025-12-28 08:25:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwdyrad",
          "author": "Paraleluniverse200",
          "text": "Awesome, what would be some words or description that you like to apply on your prompts?",
          "score": 1,
          "created_utc": "2025-12-28 16:49:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwhtlmd",
              "author": "DoPeT",
              "text": "Check out a few comments above! I use TagGUI and have a mood board folder of reference images that Iâ€™ve resource whether itâ€™s from Pinterest or Tumblr Google or whatever â€” I give it a prompt using Llama JoyCaption to caption â€” then either directly use what it gave me or combine a mix based on the composition Iâ€™m going for ðŸ˜",
              "score": 2,
              "created_utc": "2025-12-29 04:59:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwjuxyp",
          "author": "autistic-brother",
          "text": "![gif](giphy|n6o5muKaBkYqP0eTUC)",
          "score": 1,
          "created_utc": "2025-12-29 14:42:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwor6hf",
          "author": "spacekitt3n",
          "text": "whats the point of fake fashion photos? one of the main reasons for fashion photography is documenting something--a look, a model, clothing--in the real world. this is stripped of literally all of that. a whole lot of nothing",
          "score": 1,
          "created_utc": "2025-12-30 06:13:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwu585e",
              "author": "0b1juan",
              "text": "Iâ€™ve been using AI to create mockups for mood boards when planning fashion sessions. I did one recently where Z-Image was almost identical my actual shot. \n\nIâ€™ve been using Z-Image with a ComfyUI node that calls LMStudio for prompting. I give LM Studio a system prompt tasting itâ€™s a photographer or assistant, using C camera and Y lens, and giving it lighting guidance.",
              "score": 1,
              "created_utc": "2025-12-31 01:22:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwu5nc6",
                  "author": "spacekitt3n",
                  "text": "Copying ai seems pretty lame too. What happened to experimentationÂ ",
                  "score": 1,
                  "created_utc": "2025-12-31 01:25:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwrgzvy",
          "author": "web3nomad",
          "text": "nice works ðŸ˜",
          "score": 1,
          "created_utc": "2025-12-30 17:24:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwrkrw8",
          "author": "Adventurous-Gold6413",
          "text": "Whatâ€™s up with your goofy ass em dashes",
          "score": 1,
          "created_utc": "2025-12-30 17:42:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwcrtvb",
          "author": "alexmmgjkkl",
          "text": "how the noobs always flawn over their random generations lmao .. be sure your reward center is depleted faster than you think.",
          "score": 1,
          "created_utc": "2025-12-28 12:34:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwhufhk",
              "author": "DoPeT",
              "text": "I donâ€™t understand ðŸ¤¨",
              "score": 1,
              "created_utc": "2025-12-29 05:05:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwjb7pc",
                  "author": "alexmmgjkkl",
                  "text": "z image is a random image generator , ,its not an edit model , cannot pose characters , bad inpainting  etc. the only thing it has is that its fast ... everyone here started with sd 1.5 which was basically the same thing but you can only create so many random images until the reward center in your brain is depleted and it becomes unfullfilling",
                  "score": 1,
                  "created_utc": "2025-12-29 12:41:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwc6wqf",
          "author": "imnotabot303",
          "text": "This doesn't show why being a \"fashion photographer\" is relevant. \n\nI presume a fashion photographer photographs models wearing real clothes. Are these AI models using real world clothes? If not then it's not fashion photography it's just images of AI girls wearing AI clothes.",
          "score": -3,
          "created_utc": "2025-12-28 09:20:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwca5hf",
              "author": "DoPeT",
              "text": "i think about it the same way i think about motorsports.\n\nIf I see a car in a film, a game, or on TV, Iâ€™m not stopping to ask whether it has a real dual-clutch transmission or a sport differential. Those things matter, sure, but in the moment Iâ€™m reacting to the frame. The light, the motion, the timing. Whether itâ€™s compelling enough that I want to pause it, take my phone out, and keep it.\n\nThatâ€™s why a still frame of Lewis Hamilton winning years ago pulled me deeper into motorsport. And years later, seeing Max driving and even more driving in a sim on stream, when I founda moment so well composed that I wanted to screenshot it and sit with it. On paper, thatâ€™s fake over fake. But the feeling wasnâ€™t.\n\nAt a certain point, anything viewed through a screen is already a step removed this perspectuve. Thatâ€™s where the question shifts. Less â€œis this technically correctâ€ and more â€œwhat does this do to meâ€. Does it spark curiosity, emotion, inspiration.\n\nThatâ€™s the value Iâ€™m talking about here. Not whether something checks every real-world box, but whether a moment, even a digital one, can make someone who isnâ€™t a mechanic, or a racer, or even a fashion person, stop and feel something â€” weird rant  but that's what made sense for me.\n\nI do appreciate this POV â€” it all sounds right in my strict stotic pragmatic thoughts. Appreciate you commenting for real.",
              "score": 6,
              "created_utc": "2025-12-28 09:52:31",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwezwkl",
              "author": "john-whipper",
              "text": "Cause this post has nothing to do with what fashion photography is. It's byte and visual noise with incredibly far-reaching conclusions.",
              "score": 2,
              "created_utc": "2025-12-28 19:46:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwb9i1r",
          "author": "PwanaZana",
          "text": "Hi! I've started using zimage today, and trying a bunch of sampler/scheduler/shift/number of step/cfg combinations.\n\nAs well as adding additional noise with a custom node.\n\nIs there a combination that you like to use?\n\nhttps://preview.redd.it/c40siai1iv9g1.png?width=1200&format=png&auto=webp&s=48c070c9f0581e1d6e9e83c79f5df8051d2165ed",
          "score": -1,
          "created_utc": "2025-12-28 04:33:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbddk8",
              "author": "DoPeT",
              "text": "Must've been my image workflow attached or links..  Here's the response:  \n  \nIâ€™d honestly recommend starting by grabbing the workflow I listed above and not changing much at first â€” Iâ€™ve tried *so many* variations, and this one feels like a near all-in-one setup that dials things in very intuitively. Coming from a product design / engineering background, I actually ended up buying the creator a few coffees because it saved me so much trial and error.\n\nFrom a settings standpoint, my understanding (and experience so far) is that **Z-Image Turbo really wants to stay simple**:\n\n* **Sampler:** Euler\n* **Scheduler:** Simple\n* **CFG:** 1\n* **Denoise:** 1\n\nIâ€™ve tested pushing these higher and lower, but for pure text-to-image with ZIT, this feels very much like a one-to-one setup â€” I donâ€™t think it benefits from being over-tuned. That said, I could absolutely be wrong long-term, but this has been the most consistent so far.\n\nThe *one* thing I do recommend experimenting with is **steps**. I ran the same seed repeatedly across a wide range â€” 5, 20, 25, 30, 50, 75, even 125â€“200 â€” and **50 steps consistently felt like the Goldilocks zone**. Fewer steps introduced randomness, more steps didnâ€™t meaningfully improve detail and sometimes added artifacts.\n\nAesthetically, I personally avoid heavy noise or overly monochromatic looks during generation. If I want texture, Iâ€™ll either add a *very* light film grain LoRA (around \\~0.15), or just handle it post-gen in Photoshop or Affinity (which is free now). You can always add grain later â€” itâ€™s much harder to remove if itâ€™s baked in.\n\nFor LoRAs with ZIT, Iâ€™ve had good results using â€” search on Civitai\n\n* **Aesthetic Amateur Photo**\n* **NiceGirls UltraReal**\n\nThereâ€™s a third I often use for lingerie-leaning work, but I wonâ€™t link it here for obvious reasons.\n\nFor film grain specifically: **GrainScape UltraReal** works well if you want heavy grain (probably more than most people need). The one I personally use most is **Cinematic Kodak Motion Picture â€œFilm Stillâ€** â€” Iâ€™ve used it extensively with Flux, and the ZIT version is in early access but already promising.\n\nOverall, this exact setup is what Iâ€™m running day-to-day right now, and itâ€™s been extremely consistent.",
              "score": 8,
              "created_utc": "2025-12-28 05:00:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwbdp1u",
                  "author": "DoPeT",
                  "text": "https://preview.redd.it/icfoapt9nv9g1.png?width=7618&format=png&auto=webp&s=26f0aeed2c924cb919dfcabda19e26c6207fc45e\n\nOne of the images in my OP â€” not even sensitive but blurring just so you can focus on the settings.",
                  "score": 3,
                  "created_utc": "2025-12-28 05:02:53",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nwhro2h",
                  "author": "yanddav",
                  "text": "thks a lot",
                  "score": 2,
                  "created_utc": "2025-12-29 04:47:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwg1aa6",
              "author": "Comrade_Derpsky",
              "text": "You get by *far* the best outputs using a two sampler workflow. The first can be pretty much whatever. The second sampler needs to be **euler** with the **FlowMatchEulerDiscrete scheduler**. This is apparently the actual scheduler used by tongyi, but it isn't exposed ti vanilla comfyui. [This node package here](https://github.com/erosDiffusion/ComfyUI-EulerDiscreteScheduler) makes it a selectable option in the ksampler and also gives you a node to control all the nuts and bolts, but all you really need is the scheduler.\n\nBasically, just pass your latent from the first ksampler with full denoising to a second one with like 0.28 denoising.",
              "score": 4,
              "created_utc": "2025-12-28 22:51:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwg1xfa",
                  "author": "PwanaZana",
                  "text": "interesting, I'll check it out!",
                  "score": 1,
                  "created_utc": "2025-12-28 22:55:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwhsfbz",
                  "author": "DigitalDreamRealms",
                  "text": "Nice, thx",
                  "score": 1,
                  "created_utc": "2025-12-29 04:51:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwhsvqh",
                  "author": "DoPeT",
                  "text": "Woah! Iâ€™m checking this out for sure! Thanks so much.",
                  "score": 1,
                  "created_utc": "2025-12-29 04:55:01",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwbcy9w",
              "author": "DoPeT",
              "text": "I replied a really detailed explanation a minute or two ago.. Not sure why itâ€™s not showing up. Thankfully have it saved. Iâ€™ll post it again if it somehow doesnâ€™t load soon? ðŸ¤¨",
              "score": 2,
              "created_utc": "2025-12-28 04:57:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwbfhm1",
                  "author": "PwanaZana",
                  "text": "thanks! I'll check that tomorrow!\n\nZimage really has big strengths and weaknesses compared to Flux Krea which I use at work for concept art for games. I'm investigating if zimage can be of use",
                  "score": 1,
                  "created_utc": "2025-12-28 05:16:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwclna6",
          "author": "Audi_Luver",
          "text": "Is there a tutorial to get Z Image running on SwarmUI?",
          "score": 0,
          "created_utc": "2025-12-28 11:41:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwd0f35",
              "author": "CleverBandName",
              "text": "It works like any other model in SwarmUI in my experience.",
              "score": 3,
              "created_utc": "2025-12-28 13:37:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwbfx68",
          "author": "ju2au",
          "text": "So, basically you are saying that both human models and human photographers are out of a job?",
          "score": -2,
          "created_utc": "2025-12-28 05:19:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbld8n",
              "author": "DoPeT",
              "text": "I get why it can feel that way â€” and honestly, that concern comes up a lot ðŸ˜„\n\nFrom my experience, itâ€™s less about people being â€œout of a jobâ€ and more about how the work shifts. Some phases definitely get leaner â€” fewer reshoots, smaller crews, less back-and-forth â€” but fashion and product photography still really depend on human direction, taste, and real bodies.\n\nEspecially in this space, it matters how something actually sits on a person at a certain height, weight, posture, and movement. That tangible reference doesnâ€™t go away. AI becomes incredibly useful after that point â€” for variants, mood exploration, or extending ideas â€” but itâ€™s not replacing the human creative backbone.\n\nSo yeah, things get more efficient ðŸ™‚ but in practice itâ€™s more of a tool that supports the team rather than replaces it.",
              "score": 2,
              "created_utc": "2025-12-28 06:01:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1puviaq",
      "title": "A ComfyUI workflow where nobody understands shit anymore (including the author).",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/69pxktjnf79g1.png",
      "author": "nrx838",
      "created_utc": "2025-12-24 19:38:00",
      "score": 611,
      "num_comments": 162,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Meme",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1puviaq/a_comfyui_workflow_where_nobody_understands_shit/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nvrmq4o",
          "author": "proxybtw",
          "text": "When i learned how everything works and actually read stuff i realized how much useless shit people put in workflows and most of the stuff can be simplified and cut down 80%",
          "score": 284,
          "created_utc": "2025-12-24 19:53:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrpvwx",
              "author": "YentaMagenta",
              "text": "https://preview.redd.it/yie6gf2rl79g1.png?width=1800&format=png&auto=webp&s=be3599bce5617eea46bff5a6dbf840d3fa163faa\n\nReposting [this](https://www.reddit.com/r/StableDiffusion/comments/1mqhvk8/there_are_exceptions_but_i_feel_this_is_mostly/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button) :P",
              "score": 224,
              "created_utc": "2025-12-24 20:11:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvw0cb3",
                  "author": "ImNotARobotFOSHO",
                  "text": "Plus some shady packs that turn out to be trojan horses.",
                  "score": 7,
                  "created_utc": "2025-12-25 16:34:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvw8y06",
                  "author": "Fit_Corner3431",
                  "text": "Hey! I'm in this photo! or... the weather of the place I live at least...",
                  "score": 3,
                  "created_utc": "2025-12-25 17:25:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvrrwym",
                  "author": "Sarashana",
                  "text": "It's funny. Unfortunately not true. There is no way you can generate really high-quality outputs with such basic workflows.",
                  "score": -76,
                  "created_utc": "2025-12-24 20:23:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvruh6e",
              "author": "noyart",
              "text": "And sooo much \"all in one\" workflows. Sure im glad that they share, but still. Also so many unnecessary custom nodes increasing the risk that your comfyui will fuck up. Personally I rip most of the stuff out from people workflows, or just copy the parts that I want :P",
              "score": 40,
              "created_utc": "2025-12-24 20:38:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvt2pui",
                  "author": "tofuchrispy",
                  "text": "Man what ANNOYS the hell out of me is if they use lots of custom nodes that have like sliders and stuff for image size aspect ratio. \nAnd everything is grouped together with no gaps and all the links are hidden behind and everything is tunneled and you have nooooo idea how everything is connected you only see tons of nodes that are all proprietary",
                  "score": 10,
                  "created_utc": "2025-12-25 01:32:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvsqbxe",
                  "author": "Sarashana",
                  "text": "Yeah, I do the same. A lot of the workflows you download look somewhat like the one on the OP. And/or are intentionally obfuscated by hiding logic nodes behind settings nodes etc. That and a lot of custom nodes that can be easily replaced by core ones, or are duplicates from some nodes in really popular node packs.",
                  "score": 7,
                  "created_utc": "2025-12-25 00:02:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvszm3d",
              "author": "GRCphotography",
              "text": "I decided to try some of these crazy workflows, I tried over 30 of them from Civit.. not one of them worked, every single one has errors or missing nods even when installing all missing nods. Now i have hundreds of custom nods installed that i don't use.",
              "score": 7,
              "created_utc": "2025-12-25 01:08:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvt3h22",
                  "author": "TONI1597",
                  "text": "I would have stopped at the 29th",
                  "score": 8,
                  "created_utc": "2025-12-25 01:38:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvwcy0d",
                  "author": "reymalcolm",
                  "text": "This is because you would need to download the version of the nodes that were available at the time when the workflow was produced.\n\nNodes evolve and their requirements change and sometimes they result in conflicts with other nodes.\n\nAlso, I did happen once that a node-pack creator decided to rename some nodes in newer version basically making all the workflows using those nodes obsolete (if you were downloading the latest version)",
                  "score": 2,
                  "created_utc": "2025-12-25 17:49:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvyujk3",
                  "author": "aar550",
                  "text": "A lot of them link to their patreon",
                  "score": 1,
                  "created_utc": "2025-12-26 03:13:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvrpm28",
              "author": "Cadenzeit",
              "text": "Its like they think that more stuff they connect and add to a otherwise simple workflow somehow makes it more impressive.",
              "score": 7,
              "created_utc": "2025-12-24 20:09:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvs4dub",
                  "author": "Mindestiny",
                  "text": "They really do.  Like 90% of the ComfyUI zealotry is from people who just get off on feeling like they're part of some sort of \"in group\" that \"gets it\" and is some sort of L33T Hackerman for stringing nodes together.  Makes them feel superior to people.  When in reality they're banging rocks together hoping for a spark, and downloading other people's workflows they don't actually understand the technical nuts and bolts of - they're just following some youtube \"gurus\" steps exactly like it's some kind of secret sauce.",
                  "score": 10,
                  "created_utc": "2025-12-24 21:37:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvt5ts8",
              "author": "stuartullman",
              "text": "yup.  generally the first step when i open someone elses workflow is to see if all the red is even useful or just going to make comfyui load slower.  usually i find that i can replace anything missing with native comfy nodes.  and then just remove any other extra bells and whistles that don't add much to the core",
              "score": 1,
              "created_utc": "2025-12-25 01:56:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvv7m4b",
              "author": "timelyparadox",
              "text": "In the end of the day i realized python is the way to go",
              "score": 1,
              "created_utc": "2025-12-25 13:21:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvvasrn",
              "author": "RockOrStone",
              "text": "Got an example of something thatâ€™s typically overdone?",
              "score": 1,
              "created_utc": "2025-12-25 13:46:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvzkov4",
              "author": "Ryvaku",
              "text": "Really? So the majority of Comfy users don't know how to use workflows? Kinda like when it comes to simple prompts?  \nI can assume Comfy is simple to use, but people use it incorrectly?",
              "score": 1,
              "created_utc": "2025-12-26 06:40:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvs9mkk",
              "author": "R_dva",
              "text": "People may experiment, leaving many unused nodes for not to forget them. Some people don't share workflow to not show the mess and not having additional questions about how his workflow works.",
              "score": 1,
              "created_utc": "2025-12-24 22:09:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrqh5h",
          "author": "ThirdWorldBoy21",
          "text": " And then it's labeled as \"simple workflow\" on civtai.   \n(and if you download it 1 day after it was released, atleast one of the extensions it uses, already broke).",
          "score": 43,
          "created_utc": "2025-12-24 20:15:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrytie",
              "author": "FinBenton",
              "text": "When the workflow comes with a fucking map with different areas highlighted.",
              "score": 18,
              "created_utc": "2025-12-24 21:04:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvrxjm2",
              "author": "reddit-369",
              "text": "ver3.1",
              "score": 8,
              "created_utc": "2025-12-24 20:57:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrmn6c",
          "author": "WhiteTigerAutistic",
          "text": "looks like an electric pole in some parts of the world..",
          "score": 35,
          "created_utc": "2025-12-24 19:52:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrtjmr",
          "author": "LumaBrik",
          "text": "Node 836 should have the cfg set to 1, not 2.3",
          "score": 31,
          "created_utc": "2025-12-24 20:33:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrq105",
          "author": "Herbertie25",
          "text": "This was my biggest barrier for switching to Comfy. I would look up workflows and everybody would share their \"amazing and great\" workflow, but I would be met with missing nodes and errors about unrelated models.\n\nOnce I finally found a basic workflow, I was able to understand how this stuff works, and it doesn't need to be complicated at all.",
          "score": 82,
          "created_utc": "2025-12-24 20:12:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrurmi",
              "author": "noyart",
              "text": "Im glad that they added the templates inside comfyui, so newbies can load the bare minimum workflows. I think that is how almost all of us learned comfyui from the beginning, adding smaller parts into your main one.",
              "score": 38,
              "created_utc": "2025-12-24 20:40:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvs82rq",
                  "author": "dennismfrancisart",
                  "text": "In programming, we learn to think modular. Start simple, add simple components when necessary. If it's too complicated, you should acutally make a plugin or another application.",
                  "score": 16,
                  "created_utc": "2025-12-24 22:00:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvs0w5n",
              "author": "akindofuser",
              "text": "A lot of what people are sharing is unnecessary crap.",
              "score": 18,
              "created_utc": "2025-12-24 21:17:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvs9baa",
                  "author": "Academic_Storm6976",
                  "text": "Do they overcomplicate because they want you to follow or become fans, in order to sell patreon subs? I dont get why behemoths are so frequently shared.Â ",
                  "score": 5,
                  "created_utc": "2025-12-24 22:07:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvthl19",
                  "author": "CounterStrike17",
                  "text": "Some ppl share an infinite rendering workflow, but it's just the base workflow copied and pasted 10 times so it's big af lol",
                  "score": 3,
                  "created_utc": "2025-12-25 03:25:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvs4iq5",
              "author": "throttlekitty",
              "text": "Pretty much all of the time, it's down to just the few simple things: prompt/sampler settings, sometimes some post process thing.\n\nBig automation tasks are cool though.",
              "score": 5,
              "created_utc": "2025-12-24 21:38:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvsmeqd",
              "author": "DancingPhantoms",
              "text": "some things used to / still do require custom nodes. As in, they wouldn't work without them (at all), and the purpose of many of the custom nodes are to enable the functions that were required or missing.",
              "score": 1,
              "created_utc": "2025-12-24 23:35:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvryahi",
          "author": "Draufgaenger",
          "text": "Let me guess. I2V of a dancing woman but 2% more realistic than the basic workflow?",
          "score": 23,
          "created_utc": "2025-12-24 21:01:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvs540s",
              "author": "Mindestiny",
              "text": "Let's not go *crazy* here. It's 1girl in that vague amalgamation of studio ghibli's style in 256x256 resolution.  99% of the nodes are tweaking settings to absolutely butcher the model's capabilities so it can generate locally on a feature phone from 2001.",
              "score": 10,
              "created_utc": "2025-12-24 21:42:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrwpqc",
          "author": "Haiku-575",
          "text": "\"The\" image generation workflow is three loaders (UNet, VAE, Clip) and an empty latent, with clip fed through a text encoder to create conditioning, all into a KSampler that does the image generation, decoded with the VAE, and saved as an image. 9 nodes, or 7 if you have a \"checkpoint\" loader that brings in the model, VAE, and Clip from one file.\n\nSometimes to dissect these gigantic messes of overcomplicated shit, I find all the stuff I understand and *delete* it, often finding shit hidden underneath (WHY?!) until I'm left with what the author claims is the \"secret sauce\" of their workflow.\n\nOccasionally, with complex WAN Vace workflows or combined ControlNet+mask workflows, there's actual juice to be squeezed from the mess they've made. Most of the time, it's just, \"I denoise at 100%, then 70%, then 40%, then 20% on each detail!\" for a semi-automated half-working auto-detailing mess of time-consuming crap.",
          "score": 14,
          "created_utc": "2025-12-24 20:52:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvtrx9h",
              "author": "Canadian_Border_Czar",
              "text": "Congrats, please deposit $60K and collect your mechatronics diploma to signify you understand function block diagrams.Â ",
              "score": 1,
              "created_utc": "2025-12-25 04:47:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrm6h5",
          "author": "Xxtrxx137",
          "text": "Moms spagetthi, theres womit on his shirt already",
          "score": 13,
          "created_utc": "2025-12-24 19:50:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrtoke",
          "author": "SearchTricky7875",
          "text": "aws data center cables are cleaner than this",
          "score": 11,
          "created_utc": "2025-12-24 20:34:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrp80x",
          "author": "The_Last_Precursor",
          "text": "What are you talking about? Thatâ€™s a noobie workflow, itâ€™s so simple itâ€™s impossible to see why it worksâ€¦.or not.",
          "score": 10,
          "created_utc": "2025-12-24 20:07:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvs1zy6",
          "author": "crunchybits11",
          "text": "Get/Set Nodes are the goddamned DEVIL!  Until someone adds a UI feature so I can find where \"my_special_data\" is set going into this WanWrapper embed link.   Maybe a line from the Get Node back to the Set Node.  I don't use 'em.   \n\nKISS.",
          "score": 8,
          "created_utc": "2025-12-24 21:23:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvsealu",
              "author": "DVXC",
              "text": "A line from the get node to the set node is the funniest thing because it defeats the entire point of the get/set pattern, and rightfully so.\n\nWireless node graphs are almost always nightmares waiting to happen unless you have a paid staff of top class maintainers and user-facing UI inside the node graph is a major focus, for some reason.",
              "score": 4,
              "created_utc": "2025-12-24 22:39:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvtc1mj",
                  "author": "crunchybits11",
                  "text": "Adding a line between them ... Yeah, that was the joke.Â  Â Â ",
                  "score": 1,
                  "created_utc": "2025-12-25 02:43:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvt9o8f",
              "author": "thefi3nd",
              "text": "I'm pretty sure you can right click on the node, then choose the option that says something like go to setter or go to getter.",
              "score": 1,
              "created_utc": "2025-12-25 02:25:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvsgfjv",
          "author": "xadiant",
          "text": "> Opens workflow\n\n> 50 custom nodes are missing\n\n> 7 of them are like \"giga mega resolution fps master not on github node\"\n\n> Closes workflow",
          "score": 9,
          "created_utc": "2025-12-24 22:53:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvsqojl",
              "author": "Perfect-Campaign9551",
              "text": "Should we even just be trusting custom nodes? How do we know that aren't mining crypto or some stuff, or sending data to some external server? It's running code after all",
              "score": 5,
              "created_utc": "2025-12-25 00:04:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrm1f4",
          "author": "VCamUser",
          "text": "Too comfy I guess ...",
          "score": 8,
          "created_utc": "2025-12-24 19:49:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrrocc",
          "author": "CooLittleFonzies",
          "text": "Uncomfy UI",
          "score": 12,
          "created_utc": "2025-12-24 20:22:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrr44x",
          "author": "SukaYebana",
          "text": "Is there subreddit for comfyUI porn? If not make one for this post",
          "score": 6,
          "created_utc": "2025-12-24 20:18:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvt1olt",
              "author": "BobFellatio",
              "text": "this is not porn tho, this is gore and you need eye bleach after.",
              "score": 4,
              "created_utc": "2025-12-25 01:24:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvs5g22",
          "author": "Asaghon",
          "text": "And after spending months refining workflows, somehow I'm still getting better results using hires fix in forge ðŸ¤£",
          "score": 6,
          "created_utc": "2025-12-24 21:44:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvv7oj0",
          "author": "Arschgeige42",
          "text": "Prompt: 1girl",
          "score": 6,
          "created_utc": "2025-12-25 13:21:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrqghl",
          "author": "roxoholic",
          "text": "Now imagine this being a python code and you have to do a stacktrace to figure out what's wrong.",
          "score": 9,
          "created_utc": "2025-12-24 20:14:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrskoh",
              "author": "The_Last_Precursor",
              "text": "Iâ€™ll need a few shots of whisky to get started.",
              "score": 8,
              "created_utc": "2025-12-24 20:27:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrrdqs",
          "author": "PM-mePSNcodes",
          "text": "Average â€œsimpleâ€ comfy workflow",
          "score": 4,
          "created_utc": "2025-12-24 20:20:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvs9daf",
          "author": "Mysterious-String420",
          "text": "Worst offenders are really, really cutting edge shit included for no good reason. Usually you can delete them just fine as well.\n\nLike, no, I'm not gonna beta test \"super power lora loader\" when I don't even need more than one lora.\n\nAnd I especially DON'T need a fricken \"lora manager\", I have this thing called \"folders\".",
          "score": 4,
          "created_utc": "2025-12-24 22:08:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsb660",
          "author": "No_Damage_8420",
          "text": "almost... Foundry Nuke composition.... LOL\n\nhttps://preview.redd.it/0ztpldr1989g1.png?width=640&format=png&auto=webp&s=2077afe26f0ad5bc75673c234cdc8500a03f1fff",
          "score": 5,
          "created_utc": "2025-12-24 22:19:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuxv19",
          "author": "Alastair4444",
          "text": "People will do this and then the output is just another generic anime waifuÂ ",
          "score": 5,
          "created_utc": "2025-12-25 11:53:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrri80",
          "author": "acelaya35",
          "text": "How long until Doom runs in ComfyUI?",
          "score": 3,
          "created_utc": "2025-12-24 20:21:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvtbjjw",
              "author": "Enshitification",
              "text": "That happened a year ago.     \nhttps://github.com/ryanontheinside/ComfyUI_RyanOnTheInside",
              "score": 1,
              "created_utc": "2025-12-25 02:39:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvujapl",
          "author": "0FFFXY",
          "text": "UncomfyUI",
          "score": 3,
          "created_utc": "2025-12-25 09:15:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuli80",
          "author": "Alternative_Equal864",
          "text": "Bonus if half your custum are outdated or not available anymore",
          "score": 3,
          "created_utc": "2025-12-25 09:40:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrmg3l",
          "author": "seanhan12345",
          "text": "Upscaler?",
          "score": 2,
          "created_utc": "2025-12-24 19:51:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrmj4h",
          "author": "steelow_g",
          "text": "Just seeing this almost gave me a seizure. Canâ€™t understand how people work like this. My OCD could never",
          "score": 2,
          "created_utc": "2025-12-24 19:52:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrtvpf",
          "author": "SomaCreuz",
          "text": "Simple and clean",
          "score": 2,
          "created_utc": "2025-12-24 20:35:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrtx68",
          "author": "KvAk_AKPlaysYT",
          "text": "Are you guys translating model weights into a workflow?",
          "score": 2,
          "created_utc": "2025-12-24 20:35:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrvcfm",
          "author": "o5mfiHTNsH748KVq",
          "text": "God damn, at this point just learn how to code it",
          "score": 2,
          "created_utc": "2025-12-24 20:44:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsdaac",
          "author": "DVXC",
          "text": "The best node graphs are those that get as much done as possible whilst aiming to use as close to 0 nodes as possible.\n\nIf you've got hundreds of nodes, you're doing something wrong 99% of the time.",
          "score": 2,
          "created_utc": "2025-12-24 22:33:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsjdud",
          "author": "honato",
          "text": "Welcome to factorio.",
          "score": 2,
          "created_utc": "2025-12-24 23:14:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsn29x",
          "author": "waruby",
          "text": "This is way past the point where doing that in python would be a good idea.",
          "score": 2,
          "created_utc": "2025-12-24 23:39:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsq8ff",
          "author": "Comrade_Derpsky",
          "text": "In programming there is the concept of spaghetti code; code that is so convoluted and tangled up you can't figure out what does what.\n\nThis workflow here is spaghetti code given graphical form and could probably be exhibited in an art gallery as some kind of avant-garde, modern, abstract piece if you blow it big enough to cover a wall.",
          "score": 2,
          "created_utc": "2025-12-25 00:01:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvt475b",
          "author": "EnrikeMRivera",
          "text": "What are you generating? Life?",
          "score": 2,
          "created_utc": "2025-12-25 01:43:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtrlhi",
          "author": "Canadian_Border_Czar",
          "text": "Do you need another 5090 just to load the workflow?",
          "score": 2,
          "created_utc": "2025-12-25 04:45:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuvn2i",
          "author": "ArcaneWindow",
          "text": "if a workflow looks like that the author is a shithead who doesnt know what he is doing.",
          "score": 2,
          "created_utc": "2025-12-25 11:30:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvzy6oq",
              "author": "paulhax",
              "text": "I forgive you :)",
              "score": 1,
              "created_utc": "2025-12-26 08:55:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvthf7c",
          "author": "CounterStrike17",
          "text": "I prefer coding than doing workflows. It's way way easier to maintain. And you can put an LLM too.",
          "score": 2,
          "created_utc": "2025-12-25 03:24:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrs6p3",
          "author": "Sarashana",
          "text": "You really need to start using set/get nodes and reroute nodes. Haha!",
          "score": 1,
          "created_utc": "2025-12-24 20:25:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrw81j",
          "author": "Striking-Warning9533",
          "text": "I use hf diffusers so it can keep the workflow clean",
          "score": 1,
          "created_utc": "2025-12-24 20:49:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrxntb",
          "author": "mca1169",
          "text": "if you ever find yourself at this point it is time to stop and touch grass, or in this time of year go touch snow.",
          "score": 1,
          "created_utc": "2025-12-24 20:57:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvs0ilz",
          "author": "neofuturo_ai",
          "text": "he MUST do 1girl prompt..for sure",
          "score": 1,
          "created_utc": "2025-12-24 21:14:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvs3a02",
          "author": "MusicianMike805",
          "text": "This reminds me of a song called Synchronize by mind.in.box song. \n\nâ€œIâ€™m directing the cables, connecting things.\nI'm weaving together the major parts,\nI'm implanting all the pins,\nI finish the job by fits and starts\nâ€¦â€¦.\nThis machine of sound is a part of me,\nI've got direct access to its memory.\nIs the machine in control, or is it me?â€\n\nhttps://youtu.be/RaelLXKLlc8?si=AnhLJYGzG6VWVeqW",
          "score": 1,
          "created_utc": "2025-12-24 21:31:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvs3cza",
          "author": "Caesar_Blanchard",
          "text": "Why does it be called Comfy, it isn't at all even with simpler flows than this nonsense. Dang it this's why I don't want to jump in there.",
          "score": 1,
          "created_utc": "2025-12-24 21:31:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvxvjwy",
              "author": "Xdivine",
              "text": "As someone who also used to never want to get into comfy, it's really not as scary as it looks. \n\nThe main problem with people looking at workflows is that they're taking in the entire workflow all at once, but you really shouldn't do this. There are also many custom nodes that simplify things a bunch. \n\nFor example, [this](https://i.imgur.com/pf210Kf.png) is the basic workflow. This will let you generate a standard SDXL image. [This](https://i.imgur.com/OoIjNgD.png) is that same workflow using custom nodes.\n\nIf I want to add hires fix, I can just add a few more nodes like [this.](https://i.imgur.com/Vl0WGeh.png). + '[Adetailer](https://i.imgur.com/LbpqJWy.png)'.\n\nAdding things like controlnet, ipadapter, etc., are also all just a few nodes. \n\nIt can of course get more complicated, but nodes generally just flow in sequence so once you get a feel for how it works, it's pretty easy to be like 'Oh, these nodes are for X and these nodes are for y'. Plus if you build your own workflow then you can organize things in whatever way helps to remember where and what things are.\n\nComfy looks scary, but as long as you're not the kind of person who endlessly worries about breaking things when ctrl z exists then you might actually like it.",
              "score": 2,
              "created_utc": "2025-12-25 23:21:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvxy970",
                  "author": "Caesar_Blanchard",
                  "text": "Thanks for the good detailed explanation, as someone who has been sitting in forge & similar for years, I did recognize a big bunch of things from these nodes.",
                  "score": 1,
                  "created_utc": "2025-12-25 23:38:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvs4bi7",
          "author": "intLeon",
          "text": "Then they say subgraphs are bad..",
          "score": 1,
          "created_utc": "2025-12-24 21:37:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvs4uh0",
          "author": "lumos675",
          "text": "The fun fact is by using n8n alongside comfyui you can only have basic t2i t2v i2v workflows and don't break your life on a workflow like this.. i wish i knew this sooner.",
          "score": 1,
          "created_utc": "2025-12-24 21:40:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvsok52",
              "author": "afinalsin",
              "text": "Oh you can definitely run some asinine nonsense through n8n, but since you're sending the workflow as .json you don't have to see the spaghetti. [This](https://i.postimg.cc/HdGbDLLC/Screenshot-2025-12-25-103611.png) is what my API tile upscale workflow looks like in comfy.",
              "score": 1,
              "created_utc": "2025-12-24 23:50:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvs7f89",
          "author": "Healthy-Nebula-3603",
          "text": "That's artificial network inside artificial network!",
          "score": 1,
          "created_utc": "2025-12-24 21:56:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvs7mup",
          "author": "dennismfrancisart",
          "text": "Explain to me why when there is a perfectly good button to hide all the strings, that people insist on showing them. Is it just bragging rights at this point?",
          "score": 1,
          "created_utc": "2025-12-24 21:57:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvspipx",
              "author": "afinalsin",
              "text": "This is a bad example, but if the strings are visible you can usually follow the strings to see what the workflow is doing. \n\nFollow the orange strings to see if anything is intercepting the conditioning (controlnets are a prime example), follow the pink strings to see what is happening with the latent in post processing, follow the purple strings to see if there are loras or model patches (like IPadapter), follow the blue strings to see what is happening to the images, etc, etc. \n\nHiding the strings makes sure you need to download the workflow to actually understand it, and you'd only understand it by re-enabling the strings.",
              "score": 1,
              "created_utc": "2025-12-24 23:56:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvu0phf",
                  "author": "dennismfrancisart",
                  "text": "I wouldn't bother with many of them as screen shots. Easier to screen shot clean workflow sans noodles. The nodes are all that matter to me. Comfey will almost auto connect to the right nodes and won't connect to incompatible nodes.",
                  "score": 1,
                  "created_utc": "2025-12-25 06:04:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvs9oby",
          "author": "BirdlessFlight",
          "text": "How many preview windows do you really need?",
          "score": 1,
          "created_utc": "2025-12-24 22:10:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsfq1h",
          "author": "NimbusFPV",
          "text": "https://preview.redd.it/0k3qbbc0e89g1.png?width=1726&format=png&auto=webp&s=9c25dd15fbcb2e3597194569ae96acd805c19fdc",
          "score": 1,
          "created_utc": "2025-12-24 22:49:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvspar7",
          "author": "Lorian0x7",
          "text": "yeah I hate these \"amazing\" all in one workflow full of missing nodes. That's why I only publish simple but effective workflow that only includes the most famous node packs.",
          "score": 1,
          "created_utc": "2025-12-24 23:55:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsuvac",
          "author": "Hearcharted",
          "text": "![gif](giphy|BbJdwrOsM7nTa)\n\nThe author:",
          "score": 1,
          "created_utc": "2025-12-25 00:34:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvxooxm",
              "author": "paulhax",
              "text": "Confirmed âœ…",
              "score": 2,
              "created_utc": "2025-12-25 22:37:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvsvlt3",
          "author": "Vivid_Appeal1577",
          "text": "\"Hey sorry guys, the 15th KSampler is actually completely unnecessary, just bypass that whole chain\"",
          "score": 1,
          "created_utc": "2025-12-25 00:39:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvzwg8j",
              "author": "paulhax",
              "text": "Nope, its a multi step setup with many options, each option can be added with bypasser, in the screenshot enhancing rendered 3d people getting autodetected and enhanced to photorealistic is turned off.",
              "score": 2,
              "created_utc": "2025-12-26 08:37:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvta7qc",
          "author": "anigroove",
          "text": "People call sick at work for this!",
          "score": 1,
          "created_utc": "2025-12-25 02:29:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtabcf",
          "author": "dzalikkk",
          "text": "https://preview.redd.it/pv9s1eafh99g1.jpeg?width=1220&format=pjpg&auto=webp&s=ca11c334feb688cc968916994dc878a04de6ea0c\n\nthose purge vram & clean all cache nodes hiding behind the save image node",
          "score": 1,
          "created_utc": "2025-12-25 02:30:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtdpu6",
          "author": "chubbypillow",
          "text": "At the end of the day, everyone should use the kind of workflows they're comfortable with and most familiar with. Start from the official workflow templates and learn to build their own. It might end up looking complex, or not. What I don't understand is why would anyone get into THIS sort of stuff in the beginning of learning Comfy, and why would anyone suggest beginners to touch this kind of workflows, and act like everybody must go through the ultimate trial of consuming a full bowl of nodes spaghetti. \n\nI'm not saying the workflow itself is always bad, but the thing is, if you're just starting out, first of all you need to spend time learning how do you even perform the simplest task with it, and second of all when something went wrong, you have to figure out why, which can be insanely hard when you have to browse through like 300 nodes, and when you don't even know what might be the issue when certain error message comes up. That sounds much more frustrating than spending a little bit more time on going through smaller workflows for each task.",
          "score": 1,
          "created_utc": "2025-12-25 02:55:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvzw1wm",
              "author": "paulhax",
              "text": "The thing is, i never suggested this for a beginner, its just that if you see what it does, its tempting to believe you get some magic one click solution.",
              "score": 1,
              "created_utc": "2025-12-26 08:33:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvtf2ar",
          "author": "lininop",
          "text": "As someone with only a basic understanding of node style workflows, trying to load costom ones is always so confusing to me, half the nodes are missing most of the time and when I click to download them the install button just stares at me like \"what? I got nothing for you\"",
          "score": 1,
          "created_utc": "2025-12-25 03:06:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtf3i4",
          "author": "Express-Razzmatazz-9",
          "text": "Iâ€™ve been saying this since the beginning and Iâ€™m gonna say it again right now itâ€™s very simple if any one of you coders want to make a fuck ton of money make it easy. I am waiting and willing to pay Iâ€™ll pay $100. Fuck Iâ€™ll pay $200 a year For an all in one simple app that does everything for me update the latest things and it all works on my computer. and all of this crap happens under the hood where I donâ€™t have to see it I just point and click end the magic happens.",
          "score": 1,
          "created_utc": "2025-12-25 03:06:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvujw4d",
              "author": "woffle39",
              "text": "just use https://github.com/AUTOMATIC1111/stable-diffusion-webui or https://github.com/Panchovix/stable-diffusion-webui-reForge",
              "score": 1,
              "created_utc": "2025-12-25 09:22:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvzvwvt",
              "author": "paulhax",
              "text": "You are going to see it very soon :)",
              "score": 1,
              "created_utc": "2025-12-26 08:31:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvtfsrt",
          "author": "CorpusculantCortex",
          "text": "This makes me uncomfy",
          "score": 1,
          "created_utc": "2025-12-25 03:11:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtlbjr",
          "author": "MeetPhani",
          "text": "I have tried using the comfyUI but it is so hard to connect the nodes or understand it \n\nIs there any better tool",
          "score": 1,
          "created_utc": "2025-12-25 03:54:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtorc9",
          "author": "Odd-Mirror-2412",
          "text": "Using the 'subgraph' feature makes workflows cleaner and easier to read",
          "score": 1,
          "created_utc": "2025-12-25 04:22:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtrdlk",
          "author": "necrol4644",
          "text": "I wish my pc would support that, in the end they are simple they just have many small workflows(correct me if I said it incorrectly) stacked up, but they follow the same basic structure",
          "score": 1,
          "created_utc": "2025-12-25 04:43:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtten1",
          "author": "wojciechm",
          "text": "That's a hell of spaghetti node.",
          "score": 1,
          "created_utc": "2025-12-25 04:59:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtyv41",
          "author": "goatonastik",
          "text": "me: \\*clicks queue\\*\n\n\"Guess I can't use my PC for a few days...\"",
          "score": 1,
          "created_utc": "2025-12-25 05:47:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtzrs0",
          "author": "MalteseDuckling",
          "text": "Sugoi",
          "score": 1,
          "created_utc": "2025-12-25 05:55:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvu1f7r",
          "author": "God_treachery",
          "text": "i mean if it works.",
          "score": 1,
          "created_utc": "2025-12-25 06:10:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvu41an",
          "author": "MoreAd8555",
          "text": "It's awesome ðŸ˜",
          "score": 1,
          "created_utc": "2025-12-25 06:35:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvu7vw4",
          "author": "Space_Objective",
          "text": "So I always use forge",
          "score": 1,
          "created_utc": "2025-12-25 07:13:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuaudm",
          "author": "JYYYYYLim",
          "text": "now thats what i call enterprise",
          "score": 1,
          "created_utc": "2025-12-25 07:44:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvugd8s",
          "author": "Rootsyl",
          "text": "My perfected workflow.\n\nhttps://preview.redd.it/3p2anv71cb9g1.png?width=1587&format=png&auto=webp&s=4d496b8c4c2bbc77949358f72a186aee9250e005",
          "score": 1,
          "created_utc": "2025-12-25 08:43:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuqnb4",
          "author": "cicoles",
          "text": "Enshitification comes to Comfy.",
          "score": 1,
          "created_utc": "2025-12-25 10:36:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuste1",
          "author": "adi_uh",
          "text": "Got a seizure by looking at this and my laptop exploded",
          "score": 1,
          "created_utc": "2025-12-25 10:59:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuutyg",
          "author": "OlivencaENossa",
          "text": "Download linkÂ ",
          "score": 1,
          "created_utc": "2025-12-25 11:21:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvv19wz",
          "author": "Kumimono",
          "text": "And only thing it does is generate that conspiracy theory meme picture. ðŸ¤”",
          "score": 1,
          "created_utc": "2025-12-25 12:26:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvv8sfy",
          "author": "Calm_Mix_3776",
          "text": "Just use subraphs, bro.\n\nNo, seriously. You can reduce the number of nodes in your workflow by 90%, leaving the 10% of nodes that you would *actually* interact with visible. I was afraid to use them at first since they were labeled as a \"beta\" feature, but now they are pretty solid and bug-free, in my experience. I use them in virtually every workflow now, and in combination with labeled groups (when necessary), they make my workflows super tidy and professional-looking. Love it!",
          "score": 1,
          "created_utc": "2025-12-25 13:30:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvao2o",
          "author": "Niwa-kun",
          "text": "woke up and chose to gatekeep, huh. I see, i see.",
          "score": 1,
          "created_utc": "2025-12-25 13:44:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvyywz",
          "author": "cardioGangGang",
          "text": "Comfy is geared too much toward programmers. It needs to be geared more towards vfx users.Â ",
          "score": 1,
          "created_utc": "2025-12-25 16:25:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvxnbm3",
          "author": "paulhax",
          "text": "Yo, author here, cool meme :)",
          "score": 1,
          "created_utc": "2025-12-25 22:28:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzgo5a",
          "author": "quatchis",
          "text": "Little late to the show but reminded me of an old SQL relational database for a project that never worked lol",
          "score": 1,
          "created_utc": "2025-12-26 06:04:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw094mh",
          "author": "SoftTricky9124",
          "text": "Looks like the Eniac computer :D",
          "score": 1,
          "created_utc": "2025-12-26 10:49:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0iwa8",
          "author": "creativefox",
          "text": "psyduck.jpg",
          "score": 1,
          "created_utc": "2025-12-26 12:22:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvs4tly",
          "author": "Alokir",
          "text": "Skill issue.\n\nIf your workflow gets large enough, you should use subgraphs to extract functionality, like you would with functions when programming.\n\nYou can also use reroutes to see where connections are going.",
          "score": 1,
          "created_utc": "2025-12-24 21:40:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvsdvb4",
              "author": "DVXC",
              "text": "The fun thing about subgraphs is that you can still use them in terrible ways. I have yet to see one where it's used to hide a bunch of third party unmaintained spaghetti junction asinine nonsense that ends up being the cause of all of my issues but I will one day, and that thought terrifies me",
              "score": 1,
              "created_utc": "2025-12-24 22:37:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvzx4um",
              "author": "paulhax",
              "text": "100% skill issue, but luckily we have experts like you :)",
              "score": 1,
              "created_utc": "2025-12-26 08:44:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrwijb",
          "author": "Flavihok",
          "text": "Such a\n\nhttps://preview.redd.it/f9p0cgeys79g1.jpeg?width=1127&format=pjpg&auto=webp&s=3f78e3431b8f90dd8ef4435ccd443c44fd147d89\n\nMoment",
          "score": 0,
          "created_utc": "2025-12-24 20:51:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsmrmq",
          "author": "Icy_Prior_9628",
          "text": "![gif](giphy|nR4L10XlJcSeQ)",
          "score": 0,
          "created_utc": "2025-12-24 23:37:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvungo8",
          "author": "ronbere13",
          "text": "https://preview.redd.it/hi9e055zpb9g1.jpeg?width=1130&format=pjpg&auto=webp&s=a941135a509e35810d65aa3d666833b25ea001d6",
          "score": 0,
          "created_utc": "2025-12-25 10:01:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pwlt52",
      "title": "Former 3D Animator here again â€“ Clearing up some doubts about my workflow",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/bokzhsmkmn9g1.png",
      "author": "BankruptKun",
      "created_utc": "2025-12-27 02:08:12",
      "score": 469,
      "num_comments": 69,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial - Guide",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pwlt52/former_3d_animator_here_again_clearing_up_some/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nw4nhsc",
          "author": "Lozuno",
          "text": "Thank you for sharing your knowledge senpai.",
          "score": 45,
          "created_utc": "2025-12-27 02:51:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw4ozqf",
              "author": "BankruptKun",
              "text": "i hope i delivered rightfully.",
              "score": 20,
              "created_utc": "2025-12-27 03:00:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw4n80q",
          "author": "Aggressive_Collar135",
          "text": "just wanna say thanks for sharing the resources and approach used. 1girl instagram videos are a dime a dozen here but yours in my opinion is very well done, good quality production",
          "score": 14,
          "created_utc": "2025-12-27 02:49:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw4og9z",
              "author": "BankruptKun",
              "text": "thanks for the compliment, but yes these qualities take immense time to produce but yes they do deliver quality most of the time.",
              "score": 7,
              "created_utc": "2025-12-27 02:57:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw5wxl0",
          "author": "dennismfrancisart",
          "text": "Very similar to what I do with comics. My WF starts with custom Cinema 4D characters. I work with my custom LoRAs from my own illustration style and ComfyUI or Stable Diffusion. I will then finish the panel in Clip Studio Paint.  \n\nhttps://preview.redd.it/18vs42pynp9g1.png?width=2613&format=png&auto=webp&s=3849a7b7b998dc814941cfda18065c2dfd866dbe",
          "score": 13,
          "created_utc": "2025-12-27 08:56:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw6701e",
              "author": "BankruptKun",
              "text": "This is exactly what i use and i started just like this, also efficiency is high but if u go for like the refinement it takes time, but i am happy now as i saw someone who uses a similar workflow as mine. ðŸ’",
              "score": 4,
              "created_utc": "2025-12-27 10:35:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw9yt2i",
                  "author": "dennismfrancisart",
                  "text": "I'm happy to spend the time refining the images to get exactly what I want. It's still easier than my days of drawing comics for a living.",
                  "score": 3,
                  "created_utc": "2025-12-27 23:54:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw4qfla",
          "author": "stellakorn",
          "text": "ã‚ãªãŸã®ä½œå“ã¯æœ¬å½“ã«ã‚¯ã‚ªãƒªãƒ†ã‚£ãŒé«˜ã™ãŽã¾ã™ã€‚ã€‚",
          "score": 17,
          "created_utc": "2025-12-27 03:10:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw4qtre",
              "author": "BankruptKun",
              "text": "thanks, well this takes enormous time the workflow is complicated and riddled with time consuming but the output is good.",
              "score": 8,
              "created_utc": "2025-12-27 03:12:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw75ait",
          "author": "CountFloyd_",
          "text": "Perhaps this could be of use for you:\n\n[https://posemy.art/app/?lang=en](https://posemy.art/app/?lang=en)",
          "score": 4,
          "created_utc": "2025-12-27 14:56:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw76etl",
              "author": "BankruptKun",
              "text": "absolutely useful for drafting work and posing,ok this is booked for me.\n people are making web 3D models way more ez and accessible which cuts down the rigging headache by huge margin. tho this one seems not totally free but price is affordable for people to learn.",
              "score": 2,
              "created_utc": "2025-12-27 15:03:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw7czff",
                  "author": "CountFloyd_",
                  "text": "Glad you like it. Another useful thing in your toolbox might be to extract poses from existing images. I used one of your images to feed it into my workflow:\n\nhttps://preview.redd.it/hnbc77ssnr9g1.png?width=2439&format=png&auto=webp&s=8c8da20ac5aefdd60c44b7750ef7188500fcf2f3\n\n  \nYou could then use the resulting openpose image to generate a completely different character using this pose with qwen.",
                  "score": 4,
                  "created_utc": "2025-12-27 15:39:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwb4euy",
              "author": "Bright_Walk_614",
              "text": "è°¢è°¢ï¼Œå¥½ä¸œè¥¿",
              "score": 1,
              "created_utc": "2025-12-28 03:59:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw652w7",
          "author": "Serasul",
          "text": "This are the kind of post i adore, someone find out something special and tells other about it and teaches them how to do it.  \nImagine we had this in every sub here.  \nUpvote for you mate.  \nEven me one of the biggest assholes here on reddit, cant downvote this.",
          "score": 9,
          "created_utc": "2025-12-27 10:16:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw68q4k",
              "author": "BankruptKun",
              "text": "your welcome. hope this helps, i am honestly new to Ai stuff myself when people asked what i am doing and i couldn't answer i felt bad so i tried to arrange what i had on me.",
              "score": 6,
              "created_utc": "2025-12-27 10:52:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwck61p",
          "author": "BankruptKun",
          "text": "one update i am making is this link, i tried to find how i can show English audience what is happening underneath the 3D+Ai Mix, this is about 90% of my workflow for if english audience needs more Simplistic understanding.\n\n[https://youtu.be/67t-AWeY9ys?si=3-p7yNrybPCm7V5y](https://youtu.be/67t-AWeY9ys?si=3-p7yNrybPCm7V5y)\n\ni hope this helps too.",
          "score": 5,
          "created_utc": "2025-12-28 11:27:53",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nw4jzhz",
          "author": "underlogic0",
          "text": "I just like your work, dude. Keep it up and strive to improve. Looks like Daz3D? Maybe tweaked Genesis models/textures, and custom LoRAs? I've messed around with it before, but not to your level. 3D environments and character posing spliced with AI is going to be very powerful. I was never worried about the specifics. I'm not great at it, but I know enough that's there's a bazillion different options out there for this stuff software wise. The cool thing is that it will all work! Well, most of it... anyway. Thanks for sharing, man.",
          "score": 5,
          "created_utc": "2025-12-27 02:28:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw4lcsh",
              "author": "BankruptKun",
              "text": "yes i use daz or any free or affordable models, i collected many 3D models over the decade but since my gpu is a titan x maxwell i kept simplicity of tools like blender,daz and web 3D posing that are new trend, u can find many free web 3D posing sites to pose and download these days but that is for fast drafting.\n\nthe gist is better the 3D models u use better ai will stick to it like a skin. but u don't need High game ready or metahuman just even basic anatomy i used would do but just keep background colour neutral.\n\ni have a problem with prompts as you can see from my English,\nthus to rifine it, i largely reply to the communication to ai with my 3D models.",
              "score": 6,
              "created_utc": "2025-12-27 02:37:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw6jso1",
                  "author": "skyanimator",
                  "text": "Don't tell me you made this on Titan card",
                  "score": 2,
                  "created_utc": "2025-12-27 12:33:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw52edg",
          "author": "Candid-Fold-5309",
          "text": "Blessings",
          "score": 2,
          "created_utc": "2025-12-27 04:32:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5wtha",
          "author": "Arcival_2",
          "text": "Have you tried using z-image after Qwen? Since I saw its skin, I've completely abandoned Flux 1. I'll give Flux 2 a try in the future but only after buying Enterprise, because the amount of RAM needed to make it fly is less...",
          "score": 2,
          "created_utc": "2025-12-27 08:55:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw688yp",
              "author": "BankruptKun",
              "text": "i didn't try cause i already had qwen and flux setup as my default but now some people are mix matching stuff. i would say flux is not bad the problem with flux is it has grainy issue while qwen has low resolution issues, if you download my images here zoom into the Picture you will find several noise artifacts, i am thus testing and sometimes just getting bit lucky cause of tweaking with the dataset i have.\n\ni use a titan x maxwell, so just like u i have a very monthly fixed budget l, so it don't effect my living, i rent cheap gpu cloud use and pay them but i think i will move to Z-mages if i find it is giving what i want at half or saving me money,i will shift the workflow to , z-image . in the end creating art should not hinder your monthly lifestyle what every is optimized afford is better.",
              "score": 3,
              "created_utc": "2025-12-27 10:47:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw87ttn",
          "author": "Ciprianno",
          "text": "Hello fellow introvert, thank you for sharing, it is very appreciated.",
          "score": 2,
          "created_utc": "2025-12-27 18:15:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwb3unw",
          "author": "Bright_Walk_614",
          "text": "è°¢è°¢åˆ†äº«ï¼Œå¾ˆæœ‰ä»·å€¼",
          "score": 2,
          "created_utc": "2025-12-28 03:56:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwcg61n",
          "author": "Radiant_Abalone4041",
          "text": "I'd like to know more about the process below!\n\n\\>3. The Technique: I use the 3D models for the pose or slight animation, and then overlay a set of custom LoRAs with my customized textures/dataset.",
          "score": 2,
          "created_utc": "2025-12-28 10:50:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwci1vg",
              "author": "BankruptKun",
              "text": "https://youtu.be/67t-AWeY9ys?si=eQ1TFZIVFaCdwx6_\n\nmost close workflow i can show u is with this example.\ni use blender3D,daz and poser pro 2014 (i have metauman but has heavy load for my spec)\nexcept as i said the video i made would take huge time so not possible to create every other day with a limited budget and solo creator.\n\nbut the channel i mentioned 'ai wonderland'on the top post he used flux better so i tweaked my lora on few of his tips which in time turned as i wanted to look",
              "score": 3,
              "created_utc": "2025-12-28 11:07:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwcibuf",
                  "author": "Radiant_Abalone4041",
                  "text": "thank you!",
                  "score": 1,
                  "created_utc": "2025-12-28 11:10:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw56uw8",
          "author": "Taco_Bueno",
          "text": "Yo phon linging",
          "score": 4,
          "created_utc": "2025-12-27 05:04:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw6dtvo",
              "author": "BankruptKun",
              "text": "![gif](giphy|U8I6QFLPfsLwJeQ7GL)",
              "score": 3,
              "created_utc": "2025-12-27 11:41:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw5us1s",
          "author": "ThiagoAkhe",
          "text": "Thank you!",
          "score": 2,
          "created_utc": "2025-12-27 08:35:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw52y42",
          "author": "noddy432",
          "text": "Thank you for your time and work. ðŸ™‚",
          "score": 1,
          "created_utc": "2025-12-27 04:36:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw66dpy",
          "author": "Life_is_important",
          "text": "Hey a question here... Wouldn't it make more sense to get some sort of a physical model that has all joints flexible just like a 3d model. Then you quickly create a pose you want. Photograph it, and use it as a reference in comfy?Â ",
          "score": 1,
          "created_utc": "2025-12-27 10:29:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw6d715",
              "author": "BankruptKun",
              "text": "what you are talking about i assume is 3D rigged model, which most of us use yes that is the usefulness if its posable. if u cant rig use daz or poser or web,3D models for free that either lets you pose.\n\nhigher detail the 3D model with less distorted camera or accesories  better ai picks it up. your job is basically to feed a pose or a human with less noise so ai can find a perfect understanding of what it is you are feeding it. \n\nu can offcourse reiterate poses later or before but this depends on your own type of workflows. i like simple base mesh for drafting ur style may vary.",
              "score": 2,
              "created_utc": "2025-12-27 11:35:27",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nw90agq",
              "author": "terrariyum",
              "text": "I've researched this, and decided it's not worth it.  The big advantage of a physical model (drawing mannequin) is that you can pose it faster than posing a virtual model.  \n\nBut the big problem is that the best ones I could fine either are quite limited in the types of poses they can adopt or don't look enough like a normal human body to be converted into virtual.  And even for more simple poses, the pipeline isn't faster than virtual:  pose physical model, light it properly, photograph it, pipe to image editor, make changes.  Changes are required because while the physical comes in male and female versions (some even have swappable heads), you need to change other body ratios, colors, hair, clothes, etc.  So it's similar or more effort to using a virtual model.  \n\nThat said, if anyone is doing this, I'd love to hear your experience!",
              "score": 1,
              "created_utc": "2025-12-27 20:44:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw94dp3",
                  "author": "Life_is_important",
                  "text": "Interesting.. I was just thinking aloud.. Maybe you could also use yourself as the model? Literally make a pose, shoot a pic, and use in ComfyUI to make a wire model or depthmap or whatever. I could see how using either of the 3 options could be fastest, instead of always relying on just one of them.",
                  "score": 2,
                  "created_utc": "2025-12-27 21:07:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw6b92j",
          "author": "Icuras1111",
          "text": "It looks like you are creating stuff in something like Daz Studio. How far are you taking it in there. Are you clothing, etc. I am just wondering the pros and cons of this route vs something like openpose + diffusion model + controlnet + lora?",
          "score": 1,
          "created_utc": "2025-12-27 11:16:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw6kqrm",
              "author": "BankruptKun",
              "text": "i am essentially using workflow as a way to skip rendering heavy 3D images, albeit its nots perfect but im thus testing it like this.\n\ncontrolnet is slightly clunky,  this lazy workflow was invented for skipping few steps. generally speaking all updated model so far should be able to take poses like this, i would say controlnets are good if u have no 3D experience at all its not bad just some of us won't use it, we go raw with a reference image like 3D model or images, but as i said less noise in reference images better the results.\n\npros and cons, my images and videos have artifacts i would say pause video or zoom into the images i provided, if u see carefully theres distortion its not perfect but for general public view it works as a 'cool' thing to watch.",
              "score": 3,
              "created_utc": "2025-12-27 12:41:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw73a9i",
                  "author": "Lucaspittol",
                  "text": "I still think nothing beats a 3D model when we talk about consistency and fidelity.",
                  "score": 2,
                  "created_utc": "2025-12-27 14:45:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw8g89u",
          "author": "u_3WaD",
          "text": "**Serious question**: Since you come from a normal 3D world, is all this really \"saving you time\"? You mentioned you spend a lot of time on trial and error for what is basically just the \"final 2D render result\". Wouldn't it be more effective for a skilled artist to spend all this time on actually working on such a crafted 3D character (maybe rather using 3D AI to speed that up?), which you can then use basically for anything, including games, 3D printing and any image or video you can imagine?",
          "score": 1,
          "created_utc": "2025-12-27 18:57:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw8z3da",
              "author": "BankruptKun",
              "text": "What you're saying is valid. However, for a solo developer, creating a hyperrealistic character from scratch can take anywhere from 3 months to a year. You have to model, rig, texture, and animateâ€”with animation being the hardest part of that workflow.\n\nguys like me and other 3D artists today are trying to use AI to \"skin\" their models to speed up the final render output. Studios generally don't admit it, but many use a mix of AI and traditional methods for first drafts or concepting, then switch to traditional methods to deliver the final product.\n\nPersonally, I can model, texture, and rig, but doing keyframe animation alone is an incredibly cumbersome task. To skip that, I (and others like me) rely a bit on AI. Since AI video generation is costly but slightly affordable too with cheap methods like mine, Iâ€™ve been experimenting with this mixed workflow for about 3 months. I'm trying to find out if \"conceptual\" work is enough with AI, because \"production-ready\" models usually require rigorous checks and traditional pipelines to maintain studio reputations.\n\nregarding 3D printing: Sculpting is still necessary. also you gotta remesh the model a bit, so bit of work for alone, you also have to slice and join everything properly so the 3D mesh doesn't break during printing. This is a bit of a task, though some expensive printers use AI to help with nesting. Basically, 3D printing isn't \"hard,\" it just requires an expensive and careful workflow.\n\nFor games: Animation, bone work, and physics represent a huge amount of work. Doing this alone for hyperrealistic assets is technically doable, but very difficult to sustain being solo.\n\n*Note: Everything I said is based on hyperrealistic styles (though the 3D printing process is similar for both simple and hyperrealistic models).*",
              "score": 3,
              "created_utc": "2025-12-27 20:38:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw99dy0",
          "author": "rndm_whls",
          "text": "Thanks for sharing, I really enjoy this hyperrealistic style and was wondering if you know more ressources for it (e.g. artists, LoRAs, models...)? Most AI images are still too smooth and lack that detail! And best of luck for 2026~",
          "score": 1,
          "created_utc": "2025-12-27 21:34:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwawmxl",
          "author": "Ylsid",
          "text": "Hey 3d guy, a local AI mocap with nftpose or smth would be really handy",
          "score": 1,
          "created_utc": "2025-12-28 03:12:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwe7x7b",
          "author": "hereagaim",
          "text": "How much ram i need to make 3d characters or at least clothes on a character?",
          "score": 1,
          "created_utc": "2025-12-28 17:34:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwgyjlt",
              "author": "BankruptKun",
              "text": "weirdly for 3D production you don't need more than 4 to 6Gb but if you are using 4k production 12gb to 24gb is enough with offcourse good cpu and ram so u don't bottleneck. \nBut for ai videos its better you rent cause current gpu prices are abnormal.",
              "score": 1,
              "created_utc": "2025-12-29 01:53:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwh1pnu",
                  "author": "hereagaim",
                  "text": "24 gb max of normal ram for 3d? THAT IS CRAZY",
                  "score": 1,
                  "created_utc": "2025-12-29 02:11:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw4x90n",
          "author": "Perfect-Campaign9551",
          "text": "So what did you actually use for the video then? It sounds like you are saying you didn't use Wan",
          "score": 1,
          "created_utc": "2025-12-27 03:56:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw676pa",
              "author": "BankruptKun",
              "text": "qwen and flux with some other random nodes, also i blended loars of animemix as i described in previous post the output if i have to say is beginner's luck.",
              "score": 3,
              "created_utc": "2025-12-27 10:37:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw6582m",
          "author": "inaem",
          "text": "Have you tried Kling for the video generation?\n\nI feel it would match the style",
          "score": 1,
          "created_utc": "2025-12-27 10:18:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw69fcb",
              "author": "BankruptKun",
              "text": "many people told me to use wan and kling, but i keep for example monthly $50 to $200 on cloud gpu cost, the one issue with all these ai video companies is they do work but you need 20 to 80 or 100 iteration, i have done paid a lot for testing but i am slowly moving to what i can use without subscription or a fixed monthly budget.\n\nwan and kling are promising but the cost of generation is high at the moment,.",
              "score": 3,
              "created_utc": "2025-12-27 10:59:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw6fhug",
                  "author": "michaelsoft__binbows",
                  "text": "A 3090 (or even something slower with 24gb) to run wan for the cost of electricity is the best value. I have a 5090 and it is not needed for the wan generation. Lately the thing thats been intriguing is flashvsr 4x, which is ridiculously expensive to run. The results on the other hand. Invigorating.",
                  "score": 2,
                  "created_utc": "2025-12-27 11:56:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw6fui1",
                  "author": "inaem",
                  "text": "Thanks for sharing your thinking. \n\n![gif](giphy|l3fZK7BgnNHSKpp4c)",
                  "score": 2,
                  "created_utc": "2025-12-27 11:59:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw65z4g",
          "author": "oberdoofus",
          "text": "I love your stuff! And like how you share your process! If I may ask a question (i will go through your recommended videos at some stage) but do you use depth controlnets to extract depth data from your 3d renders. Or do you render out depth maps directly from your 3d program",
          "score": 1,
          "created_utc": "2025-12-27 10:25:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw6gtwv",
              "author": "BankruptKun",
              "text": "It depends on the piece! For my high-end renders, I always export native depth data from the 3D program for maximum precision.\nHowever, for quicker iterations, Iâ€™ve been experimenting with using vision models my Qwen to kinda self analyze my 3D workspace directly and do its thing, its working better on its own without too much tinkering but had artifacts at times.",
              "score": 2,
              "created_utc": "2025-12-27 12:08:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwbijrg",
                  "author": "oberdoofus",
                  "text": "Thanks for the workflow info!",
                  "score": 1,
                  "created_utc": "2025-12-28 05:39:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw6x8p8",
          "author": "imnotabot303",
          "text": "You keep calling yourself a 3D animator but you haven't shown any actual 3D animation.\n\nThis is just pose control. People have been doing this since SD1.5, usually using stuff like Daz.",
          "score": -2,
          "created_utc": "2025-12-27 14:07:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw6y3ov",
              "author": "BankruptKun",
              "text": "i use google translation to ask my general profession name 3D modeler or animator, google told me western people call 3D modelers and 3D animators almost samr that is- 3D animators in one group, now in asia we generally use the term 3D technical artist or generalist, to not complicate this i went what google search translated as i saw this subreddit is mostly us based  so went what is used normally.\n\nnow on top i used ai so you are not wrong about what you said its my regional linguistic issue sorry if my way of terms are wrong.",
              "score": 5,
              "created_utc": "2025-12-27 14:13:21",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nw7u7y1",
              "author": "MonstaGraphics",
              "text": ">\"You didn't make anything, AI did\"\n\n>I'm a 3D Animator using AI as a tool, doing passes over my models.\n\n>\"You're not technically a 3D Animator\"\n\n>Okay, I'm a 3D Generalist using rigs and poses\"\n\n>\"You didn't make those poses\"\n\n>I did make them, in 3DsMax.\n\n>\"You didn't make 3DsMax, though....\"\n\nWhen is this kinda crap going to stop? We are all standing on the shoulders of giants. We might as well say Gordon Ramsey isn't making a meal himself, because he didn't make the spices he cooks with.\n\nLet the guy cook, he obviously enjoys doing it... he doesn't need you judging his profession.",
              "score": 6,
              "created_utc": "2025-12-27 17:06:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwc0oc2",
                  "author": "imnotabot303",
                  "text": "I don't why you posted a bunch of unrelated strawman arguments.\n\nThis sub gets these kind of posts constantly. 1girl images or videos where people claim to be doing something unique and too many people here just upvote it because it contains a sexualised girl. The last post got something like 4k upvotes.\n\nThe OP claimed they were using 3D animation to drive AI but they didn't show any actual animation. From what they did show it seems like all they did was use Daz to make poses. People have been doing that for years at this point, so it's nothing new and being a 3D animator is irrelevant if that's is all they are doing because it's not animation. They didn't even have a single unrelated 3D animated video on any of their profiles.\n\nNone of what the OP was claiming to do was actually shown. It was just a collection of 1girl clips and the movement was so basic it could easily have been done with just prompting.\n\nIt's not out of order to want to see the actual original 3D animation the OP is claiming to have used to generate the video.If people are claiming to do something then they should show it otherwise it's just misleading clickbait.",
                  "score": -1,
                  "created_utc": "2025-12-28 08:20:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw555lj",
          "author": "wellhungkid",
          "text": "![gif](giphy|y4yJaxSPmxgEo)",
          "score": -1,
          "created_utc": "2025-12-27 04:52:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1px5iy5",
      "title": "Not Human: Z-Image Turbo - Wan 2.2 - RTX 2060 Super 8GB VRAM",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/cfjh8po9ms9g1",
      "author": "MayaProphecy",
      "created_utc": "2025-12-27 18:56:51",
      "score": 439,
      "num_comments": 49,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1px5iy5/not_human_zimage_turbo_wan_22_rtx_2060_super_8gb/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nw8gjt3",
          "author": "the_bollo",
          "text": "How did you do the glitch artifacts? Those are cool.",
          "score": 12,
          "created_utc": "2025-12-27 18:59:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw8gqve",
              "author": "MayaProphecy",
              "text": "Microsoft Clipchamp. It's free",
              "score": 26,
              "created_utc": "2025-12-27 19:00:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw8vjx2",
          "author": "Euripidaristophanist",
          "text": "Ends on \"I'm no Hun\"   \n\nI also  am oftwn thankful that I'm not a member of a warlike nomadic people from Central Asia who invaded and ravaged Europe in the 4thâ€“5th centuries.",
          "score": 8,
          "created_utc": "2025-12-27 20:18:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw8jsec",
          "author": "pipedreamer007",
          "text": "WOW!  Thanks for sharing...amazing work!! ðŸ‘ðŸ‘",
          "score": 6,
          "created_utc": "2025-12-27 19:15:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw8h350",
          "author": "Recent-Athlete211",
          "text": "How much time did it take for the i2v?",
          "score": 2,
          "created_utc": "2025-12-27 19:01:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw8hks5",
              "author": "MayaProphecy",
              "text": "\\~350/450 seconds per segment (4 steps)",
              "score": 3,
              "created_utc": "2025-12-27 19:04:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw8jex6",
          "author": "Acrobatic_Ferret_951",
          "text": "what resolution is the video?  \nEDIT: My bad, just seen its 832x480. It looks great",
          "score": 2,
          "created_utc": "2025-12-27 19:14:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw8kkmr",
          "author": "CLAIR-XO-76",
          "text": "![gif](giphy|TVNmNzfL8ibYUyeQo8)",
          "score": 2,
          "created_utc": "2025-12-27 19:20:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwaw14k",
          "author": "Kris_714",
          "text": "Could you please tell me how long it took for the video and  upscaling? I'm asking because I have rtx 5060 with 8GB VRAM and 32GB RAM. I just wanted to know if I can run the models, how fast it would be.",
          "score": 2,
          "created_utc": "2025-12-28 03:08:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc38yw",
              "author": "MayaProphecy",
              "text": "Generation time is written in the video description. Upscale and frame interpolation (30fps) takes less than a minute with topaz video... fullhd (1080p).",
              "score": 1,
              "created_utc": "2025-12-28 08:44:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwfrcp6",
                  "author": "M_4342",
                  "text": "how much do you pay for topaz. is there a free comfui option for upscaling too ?",
                  "score": 1,
                  "created_utc": "2025-12-28 22:01:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw8i7kg",
          "author": "suresh_deora_seducer",
          "text": "How much Ram?",
          "score": 1,
          "created_utc": "2025-12-27 19:07:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw8idzs",
              "author": "MayaProphecy",
              "text": "32GB",
              "score": 3,
              "created_utc": "2025-12-27 19:08:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw8nn0k",
          "author": "Something_231",
          "text": "where did you get the music if you don't mind",
          "score": 1,
          "created_utc": "2025-12-27 19:36:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw8o375",
              "author": "MayaProphecy",
              "text": "I only use royalty-free samples and musics in my videos. I get them from [pixabay.com](http://pixabay.com)",
              "score": 7,
              "created_utc": "2025-12-27 19:38:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw8oqrw",
          "author": "Kushagra3007",
          "text": "How long it took on 8GB VRAM?",
          "score": 1,
          "created_utc": "2025-12-27 19:42:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw8pahl",
              "author": "MayaProphecy",
              "text": "\\~350/450 seconds per segment",
              "score": 1,
              "created_utc": "2025-12-27 19:44:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw8uiuo",
                  "author": "Kushagra3007",
                  "text": "Thanks.\n\nSorry to bother you once more but if I run it on my 4GB VRAM and 24 GB RAM how much time would it take.\n\nI never tried I2V just asking.",
                  "score": 1,
                  "created_utc": "2025-12-27 20:12:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw8q99d",
          "author": "RTBRuhan",
          "text": "How long did it took to render? if it was fully local hosted",
          "score": 1,
          "created_utc": "2025-12-27 19:50:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw8qmrn",
              "author": "MayaProphecy",
              "text": "Already answered to this question :)  \n\\~350/450 seconds per segment.\n\nI'll write it in the video description now....",
              "score": 1,
              "created_utc": "2025-12-27 19:52:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw8qxk9",
                  "author": "RTBRuhan",
                  "text": "mybad I wanna ask how long did it took for full video render using wan on rtx 2060",
                  "score": 1,
                  "created_utc": "2025-12-27 19:53:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw8vh1x",
          "author": "mechaghost",
          "text": "It would be funny if the mirror text said Hunan instead of Human. Amazing work btw!",
          "score": 1,
          "created_utc": "2025-12-27 20:18:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw91wv5",
          "author": "External_Trainer_213",
          "text": "Good job!",
          "score": 1,
          "created_utc": "2025-12-27 20:53:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw93dv6",
          "author": "Libellechris",
          "text": "Wow! So was this text to image (choose a good one) - image to video (choose a good one) - extract last frame - repeat for 3 segments - stitch together and add effects / music??  Very impressive!",
          "score": 1,
          "created_utc": "2025-12-27 21:01:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw93pd7",
              "author": "MayaProphecy",
              "text": "Yes, that's it.",
              "score": 2,
              "created_utc": "2025-12-27 21:03:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw95hrv",
          "author": "Big0bjective",
          "text": "The robot or robots have a magnificient human-like resembalance. well done, enjoyed the short clip. Good to see some OC on reddit once for a while",
          "score": 1,
          "created_utc": "2025-12-27 21:13:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw95w60",
              "author": "MayaProphecy",
              "text": "Thanks :)",
              "score": 1,
              "created_utc": "2025-12-27 21:15:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw9c9nu",
          "author": "shadowtheimpure",
          "text": "If I could abandon my weak flesh for the certainty of steel and circuit, I would do so in an instant....",
          "score": 1,
          "created_utc": "2025-12-27 21:49:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw9kyuq",
          "author": "Existing-Read-3611",
          "text": "that's cool",
          "score": 1,
          "created_utc": "2025-12-27 22:36:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwa82bp",
          "author": "xorvious",
          "text": "I tried loading your I2V workflow, and got this, any idea why? Its after I had manager download the missing nodes.\n\nhttps://imgur.com/p0KEQnW",
          "score": 1,
          "created_utc": "2025-12-28 00:45:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwadglb",
              "author": "MayaProphecy",
              "text": "https://preview.redd.it/3hvz4bu4ju9g1.png?width=2342&format=png&auto=webp&s=3f777ddd0cce95537590079da502251ebd66ee97\n\nTry to disable workflow validation",
              "score": 1,
              "created_utc": "2025-12-28 01:17:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwc6xyt",
          "author": "Apprehensive-Mix8143",
          "text": "Hey, Iâ€™m building a **speech-to-speech pipeline** (speech â†’ latent â†’ speech, minimal text dependency).  \nStill in early design phase and refining architecture + data strategy.  \nIf anyone here is working on similar systems or interested in collaboration, Iâ€™m happy to share **drafts, experiments, and design docs** privately.",
          "score": 1,
          "created_utc": "2025-12-28 09:20:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwcpn7y",
          "author": "InformalHoneydew9733",
          "text": "https://preview.redd.it/hwtnt2spsx9g1.png?width=598&format=png&auto=webp&s=89cd0191aefd254e3cebcb15475db42a3c7022ef\n\nSorry bro i cant install",
          "score": 1,
          "created_utc": "2025-12-28 12:16:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwcudam",
              "author": "MayaProphecy",
              "text": "Install missing nodes...  Clear browser cache and reload comfyui... It should work.",
              "score": 2,
              "created_utc": "2025-12-28 12:54:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwcv68b",
                  "author": "InformalHoneydew9733",
                  "text": "https://preview.redd.it/p1bk6skj0y9g1.png?width=2104&format=png&auto=webp&s=583a899ea89c1971a7ef573fecb00aa0db176080\n\nWhen i click install and apply changes or restart it nothing happen",
                  "score": 1,
                  "created_utc": "2025-12-28 13:01:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwcvy5z",
                  "author": "InformalHoneydew9733",
                  "text": "I try to fix and now it only this is problem \n\nhttps://preview.redd.it/t5q4spwp1y9g1.png?width=817&format=png&auto=webp&s=70249602286f4f9c579ab3919517bf36e643612d",
                  "score": 1,
                  "created_utc": "2025-12-28 13:06:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwdbc8w",
          "author": "shywreck",
          "text": "U saved my new laptop , friend .. I got new laptop..thinking il to i2v with asus tuf f16 (rtx5060 8 gb), 16 gb ram .. n was getting ok with huslyorealxlm for t2i .. but no where ...I mean no where with i2v ...n all chatbots not  helping much .... ur workflow just worked wonders .. just bit tinkering.. It take 30 min for i2v  for 8 second clip ... Thank you again ..\n\nI have some hopes till I arrange my 5090 setup next year",
          "score": 1,
          "created_utc": "2025-12-28 14:46:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwe6urv",
          "author": "Real_Experience_5676",
          "text": "Dang thatâ€™s good! Wait whatâ€™s that soundâ€¦\n\n*helldivers 2 theme begins*\n\nOh shitâ€¦",
          "score": 1,
          "created_utc": "2025-12-28 17:29:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwugxdk",
          "author": "No-Profession-7969",
          "text": "Hi, can you use \"wan\" for something like, I mean, porn...",
          "score": 1,
          "created_utc": "2025-12-31 02:30:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw8m54t",
          "author": "Major_Specific_23",
          "text": "the quality is amazing",
          "score": 1,
          "created_utc": "2025-12-27 19:28:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwbebay",
          "author": "DiligentRanger007",
          "text": "What difference would it have made if you ran it on a 5090 ????",
          "score": 0,
          "created_utc": "2025-12-28 05:07:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pw74eg",
      "title": "Z-image Turbo Pixel Art Lora",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1pw74eg",
      "author": "aziib",
      "created_utc": "2025-12-26 15:38:52",
      "score": 404,
      "num_comments": 21,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pw74eg/zimage_turbo_pixel_art_lora/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nw2d61o",
          "author": "SlavaSobov",
          "text": "Very nice.\n\n![gif](giphy|uLiEXaouJVkuA)",
          "score": 22,
          "created_utc": "2025-12-26 18:53:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw1jbvz",
          "author": "International-Try467",
          "text": "https://preview.redd.it/3loape1xpk9g1.jpeg?width=557&format=pjpg&auto=webp&s=a07280d89d8ba1b03c90ca8ca34890ed7af6dedd",
          "score": 79,
          "created_utc": "2025-12-26 16:17:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw2adbj",
          "author": "Deathcure74",
          "text": "https://preview.redd.it/np15jk79fl9g1.jpeg?width=1080&format=pjpg&auto=webp&s=b2e8278b3e25b853bc03836cd2b4af5d6cd1cedb\n\nyeah..",
          "score": 30,
          "created_utc": "2025-12-26 18:39:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3rfse",
              "author": "Fantastic-Title-2558",
              "text": "bugs bunny rule 34 lora when?ðŸ¥ºðŸ‘‰ðŸ‘ˆ",
              "score": 8,
              "created_utc": "2025-12-26 23:31:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw21sxi",
          "author": "lucassuave15",
          "text": "It's just Ok, you can still see some pixels deform and loose shape, there's a Pixel art Lora for Illustrious that looks mindblowing, very little to no deformation/distortion on the pixels  \n[https://civitai.com/models/1631459/pixel-art-style-illustrious-by-skormino](https://civitai.com/models/1631459/pixel-art-style-illustrious-by-skormino)  \nthis one",
          "score": 15,
          "created_utc": "2025-12-26 17:55:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw2dp6n",
              "author": "molbal",
              "text": "This is mine, I made custom cleanup nodes for it: \nhttps://civitai.com/models/2224440\nhttps://github.com/molbal/ComfyUI-PixelGridHelpers\n\nThis is very very coherent, almost no students even without cleanup, but the drawback is that it is only optimized for 768x768 with 6x6 pixel size (so effectively degrees 128x128, upscaled 6x)\n\nFeedback welcome (both on the model and the custom nodes)",
              "score": 11,
              "created_utc": "2025-12-26 18:56:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw2vms3",
                  "author": "RickDripps",
                  "text": "Nice, checking this out later tonight.",
                  "score": 2,
                  "created_utc": "2025-12-26 20:33:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw1vo2b",
          "author": "ImpressiveStorm8914",
          "text": "Looks great and I was going to try pixel art later tonight so the timing is spot on.",
          "score": 3,
          "created_utc": "2025-12-26 17:22:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw42s0w",
          "author": "Perfect-Campaign9551",
          "text": "Bayonetta \n\n![gif](giphy|azi3GTPtxWKCQ)",
          "score": 2,
          "created_utc": "2025-12-27 00:39:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw787le",
          "author": "Velocita84",
          "text": "https://preview.redd.it/8tmoojmhjr9g1.jpeg?width=960&format=pjpg&auto=webp&s=c29c1b9140ae49310f814b71d11e0c99a9054bf9",
          "score": 1,
          "created_utc": "2025-12-27 15:13:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw9yyn3",
          "author": "Artonymous",
          "text": "wack, do a simple color count and tell me this is true pixel art",
          "score": 1,
          "created_utc": "2025-12-27 23:55:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw20aj4",
          "author": "Jacks_Half_Moustache",
          "text": "It started well, and then it had to go the way it did. A lot of you people need therapy.",
          "score": -17,
          "created_utc": "2025-12-26 17:47:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw24yii",
          "author": "Serasul",
          "text": "https://preview.redd.it/636o8ja7al9g1.png?width=1024&format=png&auto=webp&s=2d4e3a6f1435a94e7652c538aafb91932c4737ee\n\njust use retro diffusion  \n\n\nIn their Discord are many Gamedevs too",
          "score": -14,
          "created_utc": "2025-12-26 18:11:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3d1op",
              "author": "MaruluVR",
              "text": "Why pay for saas when you can just build it yourself for free",
              "score": 10,
              "created_utc": "2025-12-26 22:08:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw657lv",
                  "author": "Serasul",
                  "text": "???? there is the website edition that cost money and a free edition you pay once and you use it local.",
                  "score": 0,
                  "created_utc": "2025-12-27 10:17:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw3oa1w",
          "author": "Best-Response5668",
          "text": "No thanks, I use NB Pro.",
          "score": -6,
          "created_utc": "2025-12-26 23:12:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzj0un",
      "title": "Continuous video with wan finally works!",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1pzj0un/continuous_video_with_wan_finally_works/",
      "author": "intLeon",
      "created_utc": "2025-12-30 14:08:15",
      "score": 343,
      "num_comments": 205,
      "upvote_ratio": 0.98,
      "text": "https://reddit.com/link/1pzj0un/video/268mzny9mcag1/player\n\nIt finally happened. I dont know how a lora works this way but I'm speechless! Thanks to kijai for implementing key nodes that give us the merged latents and image outputs.  \nI almost gave up on wan2.2 because of multiple input was messy but here we are.\n\nI've updated my allegedly famous workflow to implement SVI to civit AI. (I dont know why it is flagged not safe. I've always used safe examples)  \n[https://civitai.com/models/1866565?modelVersionId=2547973](https://civitai.com/models/1866565?modelVersionId=2547973)\n\nFor our >!cencored!< friends;  \n[https://pastebin.com/vk9UGJ3T](https://pastebin.com/vk9UGJ3T)\n\nI hope you guys can enjoy it and give feedback :)\n\n~~UPDATE: The issue with degradation after 30s was \"no lightx2v\" phase. After doing full lightx2v with high/low it almost didnt degrade at all after a full minute. I will be updating the workflow to disable 3 phase once I find a less slowmo lightx setup.~~\n\nMight've been a custom lora causing that, have to do more tests.",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pzj0un/continuous_video_with_wan_finally_works/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "nwqt9kc",
          "author": "F1m",
          "text": "I just tested this out and my first impression is that it works really well. Using fp8 models instead of the gguf it took 7 mins to create a 19 sec video on a 4090. It looks pretty seamless. Thank you for putting together the workflow.",
          "score": 42,
          "created_utc": "2025-12-30 15:33:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwquxu0",
              "author": "intLeon",
              "text": "Cheers buddy, dont hesitate to share your outputs on the civit ðŸ––",
              "score": 13,
              "created_utc": "2025-12-30 15:41:31",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nws133b",
              "author": "Radiant_Silver_4951",
              "text": "Seeing this kind of speed and clean output on a 4090 makes the whole setup feel worth it and honestly pushes me to try fp8 right now since seven minutes for a smooth nineteen second clip is kind of wild.",
              "score": 9,
              "created_utc": "2025-12-30 18:57:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwr4egq",
              "author": "v1TDZ",
              "text": "Only 7 minutes? Haven't been toying with WAN for a while, but my 3080Ti used like an hour for only 5 seconds last I tried it (first iteration of WAN, so it's a while ago).\n\nThink I'll have to give this a go again soon|!",
              "score": 10,
              "created_utc": "2025-12-30 16:26:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwruxzd",
                  "author": "F1m",
                  "text": "The workflow uses speedup loras, which decrease the steps needed to generate a video, so it shortens generation time quite a bit. The trade off is movement is degraded, but I am not seeing too much of an impact with this workflow.",
                  "score": 11,
                  "created_utc": "2025-12-30 18:29:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwud2iv",
                  "author": "drallcom3",
                  "text": "> but my 3080Ti used like an hour for only 5 seconds\n\nThere are a lot of things you can do to speed up WAN 2.2. It's quite tricky.\n\nhttps://rentry.org/wan22ldgguide",
                  "score": 1,
                  "created_utc": "2025-12-31 02:08:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwrsakn",
                  "author": "chudthirtyseven",
                  "text": "yeah that's the difference between wan2.1 and wan2.2.",
                  "score": -2,
                  "created_utc": "2025-12-30 18:17:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwrfkge",
              "author": "MoreColors185",
              "text": "it works really well yes, needs more testing but consistence is pretty good.",
              "score": 8,
              "created_utc": "2025-12-30 17:18:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwrzwrh",
                  "author": "F1m",
                  "text": "Agreed, I've done about 10 videos so far and they each flow better than anything I have tried in the past. I've noticed some blurring as the videos goes along, but upscaling fixes it for the most part.",
                  "score": 6,
                  "created_utc": "2025-12-30 18:52:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwqgbax",
          "author": "Some_Artichoke_8148",
          "text": "Ok. Iâ€™ll being Mr Thickie here but what it is that this has done ? Whatâ€™s the improvement ? Not criticising - just want to understand. Thank you !",
          "score": 19,
          "created_utc": "2025-12-30 14:25:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqh4zv",
              "author": "intLeon",
              "text": "SVI takes last few latents of previous generated video and feeds them into the next videos latent and with the lora it directs the video that will be generated.\n\nSubgraphs help me put each extension in a single node that you can go inside to edit part specific loras and extend it further by duplicating one from the workflow.\n\nPrevious versions were more clean but comfyui frontend team removed a few features so you have to see a bit more cabling going on now.",
              "score": 27,
              "created_utc": "2025-12-30 14:30:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nws60g8",
                  "author": "mellowanon",
                  "text": "is possible for it to loop a video? By feeding the latents for the beginning and end frames for a new video.\n\nOther looping workflows only take one first and last frame, so looping is usually choppy and sudden.",
                  "score": 3,
                  "created_utc": "2025-12-30 19:20:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwr2v0k",
                  "author": "Some_Artichoke_8148",
                  "text": "Thanks for the reply. Ok â€¦. So does that mean you can prompt a longer video and it produces it in one gen ?",
                  "score": 3,
                  "created_utc": "2025-12-30 16:18:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nws5nli",
                  "author": "Different-Toe-955",
                  "text": "So it sounds like it takes some of the actual internal generation data and feeds it into the next section of video, to help eliminate the \"hard cut\" to a new video section, while maintaining speed/smoothness of everything? (avoiding when it cuts to the next 5 second clip and say the speed of a car changes)",
                  "score": 2,
                  "created_utc": "2025-12-30 19:19:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwrwpod",
                  "author": "stiveooo",
                  "text": "Wow so you are saying that someone finally made it so the Ai looks at the few seconds before making a new clip? Instead of only the last frame?Â ",
                  "score": 2,
                  "created_utc": "2025-12-30 18:37:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwrkeco",
                  "author": "Yasstronaut",
                  "text": "Iâ€™m confused why a lora is needed for this though Iâ€™ve been using the last few frames as input for next few frames for months now - and weighting the frames (by increasing the denoise progressively) and have been seeing similar results to what you posted",
                  "score": 1,
                  "created_utc": "2025-12-30 17:40:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwr1pxk",
          "author": "Perfect-Campaign9551",
          "text": "So, what about character likeness over time? that's been a flaw we've been noticing in other continuous workflows. Do like 5 extensions (20 or so seconds) and does the character still look the same?",
          "score": 5,
          "created_utc": "2025-12-30 16:13:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr5kt2",
              "author": "intLeon",
              "text": "Start image is always kept as a latent but overall latent quality degrades over time so I would say 30s/45s with lightx2v lora's and low steps. Then it suddenly has ribbon like artifacts and very rapid movements.",
              "score": 2,
              "created_utc": "2025-12-30 16:31:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwr8h5a",
          "author": "ansmo",
          "text": "Great work! I have good results with 333steps. High WITH the wan2.1lightx2v lora at 1.5 and cfg 3, Low with light lora twice. Slowmo isn't a problem with these settings. It's exciting to see a true successor to 2.1 FUN/VACE.",
          "score": 7,
          "created_utc": "2025-12-30 16:45:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvafsq",
              "author": "kayteee1995",
              "text": "wait what?!?! 333 steps?",
              "score": 1,
              "created_utc": "2025-12-31 05:41:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqe8bv",
          "author": "Complete-Box-3030",
          "text": "Can we run this on rtx 3060 12gb vram",
          "score": 11,
          "created_utc": "2025-12-30 14:13:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqeenz",
              "author": "intLeon",
              "text": "It should work, nothing special. Just same quantized wan2.2 I2V a14b models with an extra lora put in subgraphs and with an initial ZIT node.",
              "score": 12,
              "created_utc": "2025-12-30 14:14:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwqeq64",
                  "author": "Complete-Box-3030",
                  "text": "Does it work on smooth mix models",
                  "score": 1,
                  "created_utc": "2025-12-30 14:16:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwqjio5",
          "author": "additionalpylon2",
          "text": "It's Christmas everyday. I can hardly keep up with all this. \n\nOnce we consumer peasants get the real hardware we are going to be cooking.",
          "score": 7,
          "created_utc": "2025-12-30 14:43:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqknfu",
          "author": "broadwayallday",
          "text": "SVI is definitely a game changer woohooo",
          "score": 5,
          "created_utc": "2025-12-30 14:49:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqy5l2",
          "author": "Underbash",
          "text": "Maybe I'm just dumb but I'm missing the \"WanImageToVideoSVIPro\" and ImageBatchExtendWithOverlap\" nodes and for the life of my cannot find them anywhere. Google is literally giving me nothing.",
          "score": 5,
          "created_utc": "2025-12-30 15:56:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqyf0l",
              "author": "intLeon",
              "text": "They are in kijai's nodes. Try updating the package if you already have it.",
              "score": 3,
              "created_utc": "2025-12-30 15:58:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwr071v",
                  "author": "Underbash",
                  "text": "That seemed to work. Thanks!",
                  "score": 3,
                  "created_utc": "2025-12-30 16:06:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nws7578",
          "author": "foxdit",
          "text": "This is awesome! I've edited the workflow so that now you can regenerate individual segments that don't come out looking as good. That way you don't have to retry the whole thing from scratch if the middle segment sucks.",
          "score": 3,
          "created_utc": "2025-12-30 19:26:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwu87hl",
          "author": "Le_Singe_Nu",
          "text": "After a few hours wrestling with Comfy, I got it to work. I'm still waiting on the first generation, but I have to say this: \n\n**I deeply appreciate your commitment to making the fucking nodes line up** **on the grid.**\n\nIt always annoys me when I *must* sort out a workflow. As powerful as Comfy is, it's confusing enough with all its spaghetti everywhere. \n\nI salute you.",
          "score": 5,
          "created_utc": "2025-12-31 01:40:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvg4l0",
              "author": "intLeon",
              "text": "Hehe it was a nightmare before but I figured you could snap them if you had the setting enabled.",
              "score": 1,
              "created_utc": "2025-12-31 06:26:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqecrd",
          "author": "Jero9871",
          "text": "Thanks, seems great, I will check it out later. How long can you extend the video?",
          "score": 3,
          "created_utc": "2025-12-30 14:14:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqgexo",
              "author": "intLeon",
              "text": "In theory there is no limit as long as you follow the steps in the workflow notes but Im guessing the stacking number of images might cause a memory hit. If you've got some decent amount of vram it could hit/pass a minute mark but I didnt test it myself so quality might degrade over long periods.",
              "score": 5,
              "created_utc": "2025-12-30 14:26:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwr3y99",
          "author": "WildSpeaker7315",
          "text": "im curious why its taking so long, per segment, like over 10 mins @ Q8 1024x800 when it takes me 10 mins to usually make a 1280x720 video, i'll update comment with my thoughts on the results tho :) - ye i enabled sage",
          "score": 3,
          "created_utc": "2025-12-30 16:24:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrb1ve",
              "author": "WildSpeaker7315",
              "text": "took too long for 19 seconds, 2902 seconds, decent generation but something is off",
              "score": 1,
              "created_utc": "2025-12-30 16:57:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwrm20f",
                  "author": "WildSpeaker7315",
                  "text": "did it with a different workflow 1900s, same resolution, weird",
                  "score": 1,
                  "created_utc": "2025-12-30 17:48:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwrux64",
              "author": "intLeon",
              "text": "Yeah thats too long for 19s video. Id suggest opening a new browser during generation and switch there and see if that makes a difference.. Or turn offncivitai if its open in a tab.",
              "score": 1,
              "created_utc": "2025-12-30 18:29:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwrtz8s",
          "author": "ArkCoon",
          "text": "Amazing! This is pretty much seamless! I tried FineLong a few days ago and was very disappointed. It didn't work at all for me, but this works perfectly and best thing is that it doesn't slow down the generation. Finelong would make the high noise model like 5 times slower and the result would be terrible",
          "score": 3,
          "created_utc": "2025-12-30 18:24:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwsdb3i",
          "author": "yaxis50",
          "text": "A year from now I wonder how much this achievement will have aged, very cool either way.Â ",
          "score": 3,
          "created_utc": "2025-12-30 19:55:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwtbdqe",
          "author": "PestBoss",
          "text": "Also am I being stupid here?\n\nThe node pack I'm missing is apparently:\ncomfyui-kjnodes, WanImageToVideoSVIPro\n\nWanImageToVideoSVIPro in subgraph 'I2V-First'\n\n\nIn ComfyUI manager it's suggesting that the missing node pack is KJNodes but I have that installed.\n\nIf I check the properties of the outlined node in I2V-First, it's cnr-id is \"comfyui-kjnodes\"\n\n\nSo what do I install? Is it kijai wanvideowrapper or is my kjnodes not working correctly, or is this some kind of documentation error?\n\nIf I check in kjnodes via manager on the nodes list, there is no WanImageToVideoSVIPro entry.\n\nIf I check in wanvideowrapper via manager on the nodes list, there is no WanImageToVideoSVIPro entry either.",
          "score": 3,
          "created_utc": "2025-12-30 22:39:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtngxo",
              "author": "Particular_Pear_4596",
              "text": "Same here, comfyui manager fails to authomatically install the WanImageToVideoSVIPro node, so I deleted the old subfolder \"comfyui-kjnodes\" in the \"custom\\_nodes\" subfolder in my comfyui folder, then manually installed the KJNodes nodes as explained here: [https://github.com/kijai/ComfyUI-KJNodes](https://github.com/kijai/ComfyUI-KJNodes) (scroll down to \"Installation\"), restarted comfyui and it now works. Have no idea why comfyui manager fails to update the KJNodes nodes and I have to do it manually.",
              "score": 3,
              "created_utc": "2025-12-30 23:44:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwtbn5f",
              "author": "intLeon",
              "text": "Try to update kjnodes if you have comfyui manager. The node is very new, like 2 days old.",
              "score": 2,
              "created_utc": "2025-12-30 22:40:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwtu8cr",
                  "author": "NomadGeoPol",
                  "text": "I have same error, I updated everything but still broken WanImageToVideoSVIPro node.",
                  "score": 1,
                  "created_utc": "2025-12-31 00:21:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwtgos7",
              "author": "osiris316",
              "text": "Yep. I am having the same issue and went through the same steps that you did but I am still getting an error related to WanImageToVideoSVIPro",
              "score": 2,
              "created_utc": "2025-12-30 23:07:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqfczc",
          "author": "ANR2ME",
          "text": "Did i saw 2 egg yolks coming out ðŸ¤” and disappearing egg shell ðŸ˜‚\n\n\nAnyway, the consistency looks good enough ðŸ‘",
          "score": 4,
          "created_utc": "2025-12-30 14:20:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqfqa8",
              "author": "intLeon",
              "text": "Yup this workflow is focused on efficiency and step count is set to 1 + 3 + 3 (7) steps but you are free to increase number of steps. It literally was one of the first things I generated if not the actual first.",
              "score": 7,
              "created_utc": "2025-12-30 14:22:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwrnjey",
                  "author": "_Enclose_",
                  "text": "> 1 + 3 + 3 (7)\n\nold school cool",
                  "score": 3,
                  "created_utc": "2025-12-30 17:55:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwqoqoc",
          "author": "BlackSheepRepublic",
          "text": "Why is it so choppy?",
          "score": 2,
          "created_utc": "2025-12-30 15:10:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqr37m",
              "author": "Wilbis",
              "text": "Wan generates at 16fps",
              "score": 4,
              "created_utc": "2025-12-30 15:22:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwqqevn",
              "author": "intLeon",
              "text": "Probably the number of steps. 1 high without lightx2v, 3 high and 3 low with lightx2v. You could increase them to get better motion/quality. You could also modify the workflow to not use lightx2v but that causes more noise in low steps like 20 total in my experience.",
              "score": 3,
              "created_utc": "2025-12-30 15:19:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqtya5",
          "author": "ShittyLivingRoom",
          "text": "Does it work on WanGP?",
          "score": 2,
          "created_utc": "2025-12-30 15:36:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwquq5z",
              "author": "intLeon",
              "text": "Its a workflow for comfyui so it may not work if there isnt at least a hidden comfyui layer at the backend.",
              "score": 2,
              "created_utc": "2025-12-30 15:40:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwr1zrm",
          "author": "Perfect-Campaign9551",
          "text": "A lot of your video example suffer from SLOW MOTION ARGH",
          "score": 2,
          "created_utc": "2025-12-30 16:14:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr31pn",
              "author": "intLeon",
              "text": "Yeah I didnt have time to test the lightning lora variations. Could be fixed with more no lora steps and total steps as well as using some trigger words in the prompts to make things faster.\n\nCould also add a slowmo tag to no lora negative conditioning.",
              "score": 1,
              "created_utc": "2025-12-30 16:19:50",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwrwbsw",
              "author": "NessLeonhart",
              "text": "Pass the output through a VFI node. Set the interpolation to 3, But the saved video to 60fps instead of 48. \n\nSmoother, faster motion.",
              "score": 1,
              "created_utc": "2025-12-30 18:35:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwrzhg4",
          "author": "wrecklord0",
          "text": "Hey I gave that a try, I don't understand the 1 step with no lora? Is there a reason for it?\n\nIt worked much better for me by bypassing the no-lora entirely and setting a more standard 4 steps with high lora and 4 step with low lora in each of the subgraphs.",
          "score": 2,
          "created_utc": "2025-12-30 18:50:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwscrnm",
              "author": "intLeon",
              "text": "It was to beat slow motion but yeah, it is literally 0 degradation if there is no phase 1. I will update workflow once I see if theres something else to be done about slomo.\n\nEdit: it doesnt degrade with the phase too, I had a lora enabled and it reduced the quality.",
              "score": 1,
              "created_utc": "2025-12-30 19:53:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nws0o4m",
          "author": "sunamutker",
          "text": "Thank you for a great workflow . In my generated videos it seems like at every new stage it defaults back to the original image., Like I am seeing clips of the same scene.  As if the anchor samples are much stronger than the prev\\_samples? Any idea, or am I an idiot?",
          "score": 2,
          "created_utc": "2025-12-30 18:55:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwschue",
              "author": "intLeon",
              "text": "Did you modify the workflow? Extended subgraphs nodes take extra latents with previous latents set to 1 to fix that",
              "score": 1,
              "created_utc": "2025-12-30 19:51:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwsh1qd",
                  "author": "sunamutker",
                  "text": "No I dont think so. I had some issues installing the custom node. But the workflow should be the same.",
                  "score": 1,
                  "created_utc": "2025-12-30 20:13:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwtxczi",
                  "author": "ExpandibleWaist",
                  "text": "I'm having same issue, anything else to adjust? I updated everything, uninstalled and reinstalled the nodes. Every 5 second clip resets to initial image and starts over",
                  "score": 1,
                  "created_utc": "2025-12-31 00:38:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwtyqpu",
              "author": "nsfwvenator",
              "text": "u/intLeon I'm getting the same issue. The face keeps resetting back to the original anchor for each subgraph, even though it has the prev\\_samples and source\\_images wired from the previous step. The main thing I changed was using fp8 instead of gguf.\n\nI have the following versions:\n\n* KJNodes - 1.2.2\n* WanVideoWrapper - 1.4.5",
              "score": 1,
              "created_utc": "2025-12-31 00:45:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwvflwg",
                  "author": "intLeon",
                  "text": "You dont need wan wrapper. Im downloading fp8 models to test further. Is there any weird logs in the console?\n\nIf you mean image switching mid video to a slightly different state like a cut that happenened on fp8 scaled model or if I set the model shift to 5. It doesnt happen on gguf with model shift set to 8 which is the default setting.",
                  "score": 1,
                  "created_utc": "2025-12-31 06:21:52",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwso7q8",
          "author": "MrHara",
          "text": "Cleared up the workflow a bit (removing the no-lora step), changed to lcm/sgm_uniform and ran the combination of 1022 low+high at 1 strength and lightx2v_I2V_14B_480p_cfg_step_distill_rank64_bf16 at 2.5 strength on high only to solve some of the slowdown. Can recommend for getting good motion, but I wonder if PainterI2V or something newer is better even.\n\nCan't test extensively as for some reason iteration speeds are going a bit haywire in the setup on my measly 3080 but quite interesting.",
          "score": 2,
          "created_utc": "2025-12-30 20:48:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwt7mm7",
              "author": "Tystros",
              "text": "how much did your changes improve the slow motion?",
              "score": 1,
              "created_utc": "2025-12-30 22:20:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwtti2y",
              "author": "intLeon",
              "text": "No lora wasnt the issue btw. It was a lora I forgot enabled. Having 2 no lora steps as in 2 + 2 + 2 or 3 for low noise fixes most issues.",
              "score": 1,
              "created_utc": "2025-12-31 00:17:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwt4on8",
          "author": "additionalpylon2",
          "text": "So far this is phenomenal. Great job putting this together.\n\nI just need to figure out how to get some sort of end\\_image implementation for a boomerang effect and its golden.",
          "score": 2,
          "created_utc": "2025-12-30 22:06:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwtm4m3",
          "author": "WestWordHoeDown",
          "text": "For the life of me, I can not find the WanImageToVideoSVIPro custom node. Any help would be appreciated.",
          "score": 2,
          "created_utc": "2025-12-30 23:36:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwto3um",
              "author": "intLeon",
              "text": "Kjnodes, update if you already have it installed.",
              "score": 3,
              "created_utc": "2025-12-30 23:47:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwtzs2w",
                  "author": "WestWordHoeDown",
                  "text": "That was the first thing I tried, no luck. Will try again later. Thank you.",
                  "score": 1,
                  "created_utc": "2025-12-31 00:51:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwu834r",
          "author": "Underbash",
          "text": "I don't know what the deal is or if I've got something set-up wrong, but ~~it really doesn't seem to want to play nice with any kind of lora. As soon as I add any kind of lora at all, it goes crazy during the first stage and produces a horribly distorted mess.~~\n\nEdit: Forgot to mention, it always seems to sort itself out on the first \"extend\" step, with the loras working fine at that point, although by that point any resemblance to the initial image is pretty much gone since the latent it's pulling from is so garbled. But something about that \"first\" step is just not cooperating.\n\nEdit 2: It still is misbehaving even without loras, but in the form of flashing colors. With no loras, the image isn't distorted but it keep flashing between different color tints with every frame, like every frame is either the correct color, has a blue cast, or has an orange cast. Very bizarre.",
          "score": 2,
          "created_utc": "2025-12-31 01:39:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvgai9",
              "author": "intLeon",
              "text": "Happened to me as well, do you have the exact same loras? Even switching to 1030 high lora caused my character to lose their mind.",
              "score": 1,
              "created_utc": "2025-12-31 06:27:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwvh64t",
                  "author": "Underbash",
                  "text": "Idk I tried a couple different ones and it did it with all of them.",
                  "score": 1,
                  "created_utc": "2025-12-31 06:34:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwsdflg",
          "author": "No-Issue-9136",
          "text": "Commercial models absolutely going to be cooked now lol",
          "score": 3,
          "created_utc": "2025-12-30 19:56:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqgxkj",
          "author": "Wallye_Wonder",
          "text": "This is really exciting. A 15 seconds clip takes about 10 mins on my 4090 48gb vram. It only uses 38gb of vram but almost 80gb of ram. Iâ€™m not sure why it wouldnâ€™t use all 48gb vram.",
          "score": 2,
          "created_utc": "2025-12-30 14:29:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqhuar",
              "author": "intLeon",
              "text": "I think you should have some more room to improve. 4 parts (19s) takes 10 mins for me on a 4070ti 12gb. I would try to get at least sage to work on a new workflow. Did it on my companies pc and it was worth it. Vram usage might be because models fit and you have extra space. Also native models could also work a bit faster and may provide higher quality if you have extra vram. You could even go for higher resolutions.",
              "score": 2,
              "created_utc": "2025-12-30 14:34:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwu7qt5",
                  "author": "Wallye_Wonder",
                  "text": "i was using bf16 instead of gguf, maybe thats why the slow speed.",
                  "score": 1,
                  "created_utc": "2025-12-31 01:37:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwr8frj",
              "author": "Neamow",
              "text": "> 4090 48gb vram\n\nThe what?",
              "score": 1,
              "created_utc": "2025-12-30 16:44:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqj2u1",
          "author": "zekuden",
          "text": "Can you make looping videos?",
          "score": 2,
          "created_utc": "2025-12-30 14:40:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqk3co",
              "author": "intLeon",
              "text": "It may not work with this workflow. Each part after the first takes a latent reference from first input image and motion from the previous video. And first few frames are somehow masked to not be affected by the noise. So I cant think of a way to mask last frames for now.",
              "score": 3,
              "created_utc": "2025-12-30 14:46:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwqlirq",
                  "author": "zekuden",
                  "text": "Oh I see, I appreciate your informative reply, thank you!\n\nIs there any way in general to make looping videos in wan?",
                  "score": 3,
                  "created_utc": "2025-12-30 14:54:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwqo0wm",
                  "author": "shapic",
                  "text": "I think the question is more about combining this thing with FLF",
                  "score": 1,
                  "created_utc": "2025-12-30 15:07:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwrc24z",
              "author": "Life_Yesterday_5529",
              "text": "Same image as start and end frame and a strong prompt? Does not work with SVI but with classic I2V.",
              "score": 1,
              "created_utc": "2025-12-30 17:01:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nws6i59",
          "author": "Darqsat",
          "text": "I dunno but whatever I do it looks absolutely awful. I downloaded your recommended loras and my output video is a choppy mess with distorted character. Nothing really close to your video here.\n\nAnd it takes endeless time. I do 480x720 81 frames 8 steps in about 45s on 5090 with sage attention. It gives me about 4-6 sec/it. With your workflow my sec/it ups to 60-300.\n\nThe overall workflow duration is more than 10 minutes.\n\nUPD: I forgot that my NSFW model already have lightX2 loras so turned them off. It helped. Took 5 minutes but i have weird shapes on top of NSFW places now :D SVI does this? shows white/yellow oval over tits and you know what.\n\nUPD: Okay, seems like NSFW models work pretty bad for some reason. Tried your model from workflow and its better. But probably need NSFW loras now. s/it dropped back to 6-7 which is great. Takes about 4 minutes to complete that workflow.\n\nSeems interesting SVI workflow, thank you. I made it better with Tensort RIFE. It works pretty quick on my 5090.",
          "score": 2,
          "created_utc": "2025-12-30 19:23:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwsbuyw",
              "author": "intLeon",
              "text": "Thats to prevent you from getting coal.\n\nJokes aside initial no lightx2v high step could be causing that byt otherwise you get slowmo, Im still experimenting before an update.",
              "score": 1,
              "created_utc": "2025-12-30 19:48:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwt7zad",
                  "author": "Darqsat",
                  "text": "Nsfw not working at all. Constant oval shapes on top of those zones. Ping me if you know what can cause that and how to avoid it. In general looks good. I can recommend adding Clean VRAM used nodes from Easy-Use. At least I did at the end to add Tensorrt RIFE. With RIFE v49 and 32 frames the video looks smooth.",
                  "score": 1,
                  "created_utc": "2025-12-30 22:22:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwqrr2l",
          "author": "BlackSheepRepublic",
          "text": "What post-process software can up frame rate to 21 without mucking up the quality?",
          "score": 1,
          "created_utc": "2025-12-30 15:25:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqsbdq",
              "author": "intLeon",
              "text": "You can use comfyui interpolation rife nodes to multiply framerate (usually by 2 or 4 works for 30/60 fps). I will implement a better save method and interpolation option if I get some free time this weekend.",
              "score": 3,
              "created_utc": "2025-12-30 15:28:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwqycna",
                  "author": "Fit-Palpitation-7427",
                  "text": "Whats the highest quality we cqn get out of wan? Can we do 1080p, 1440p, 2160p?",
                  "score": 1,
                  "created_utc": "2025-12-30 15:57:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwrvyxb",
              "author": "NessLeonhart",
              "text": "Film VFI or rife VFI nodes, easy. Just set the multiplier (2x, 4x, etc) and send the video through it. Make sure to change the output frame rate to match the new frame rate. \n\nYou can also do cool stuff like set it to 3x but set the output to 60fps. It makes a video thatâ€™s 48fps and plays it back at 60, which often fixes the â€œslow motionâ€ nature of many WAN outputs.",
              "score": 1,
              "created_utc": "2025-12-30 18:34:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqzpsn",
          "author": "freebytes",
          "text": "I am missing the node WanImageToVideoSVIPro.  Where do I get this?  I do not see it in the custom node manager.",
          "score": 1,
          "created_utc": "2025-12-30 16:04:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr0gw7",
              "author": "intLeon",
              "text": "https://www.reddit.com/r/StableDiffusion/s/r12qQ9QVRz\nKijai's nodes",
              "score": 1,
              "created_utc": "2025-12-30 16:07:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwr08r3",
          "author": "ICWiener6666",
          "text": "Where kijai workflow",
          "score": 1,
          "created_utc": "2025-12-30 16:06:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr0q6e",
              "author": "intLeon",
              "text": "I dont like the wan video wrapper because it has its own data types instead of native ones so I dont use it :(",
              "score": 4,
              "created_utc": "2025-12-30 16:08:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nws3w5k",
                  "author": "Tystros",
                  "text": "I appreciate that you use the native nodes. Kijai himself says people should use the native nodes when possible and not his wrapper nodes.",
                  "score": 2,
                  "created_utc": "2025-12-30 19:10:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwrcfy0",
          "author": "Neonsea1234",
          "text": "where do you actually load the video models on this workflow? in the main loader node, I just have x2 high/low loras + clip and vae.",
          "score": 1,
          "created_utc": "2025-12-30 17:03:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrmnso",
              "author": "intLeon",
              "text": "At the very left there are model loader nodes. You should switch to load diffusion model nodes if you dont have gguf",
              "score": 1,
              "created_utc": "2025-12-30 17:51:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwsbamk",
                  "author": "Neonsea1234",
                  "text": "ah yeah I got it working, was unfamiliar with the nesting of nodes like this. Works great",
                  "score": 2,
                  "created_utc": "2025-12-30 19:46:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwrk29m",
          "author": "NoBoCreation",
          "text": "What are you using to run your workflows?",
          "score": 1,
          "created_utc": "2025-12-30 17:39:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrnpeh",
              "author": "intLeon",
              "text": "They are comfyui workflows ðŸ¤” So I have a portable comfyui setup with sage + torch",
              "score": 1,
              "created_utc": "2025-12-30 17:56:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nws4f7y",
                  "author": "NoBoCreation",
                  "text": "Someone recently has been telling me about comfyui. Is it reletively easy to learn? How much does it cost?",
                  "score": 1,
                  "created_utc": "2025-12-30 19:13:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwrxypc",
          "author": "jiml78",
          "text": "Have you considered adding PainterI2V to help with motion, specifically the slowmo aspect of it.",
          "score": 1,
          "created_utc": "2025-12-30 18:43:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwsbf9x",
          "author": "NeatUsed",
          "text": "how is this different from the usual? i know ling videos had a problem with consistency. Basically a character turning around with their back and after they turn back their face is different. How do you keep face consistency?",
          "score": 1,
          "created_utc": "2025-12-30 19:46:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwsdbqw",
              "author": "intLeon",
              "text": "This workflow uses kijai's node which keeps the reference latent from first image all times and also uses an extra SVI lora so customized latents dont get messy artifacts.\n\nEdit: replaced the workflow preview video with an 57 seconds one. Looks okay to me.",
              "score": 1,
              "created_utc": "2025-12-30 19:55:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwsogq2",
          "author": "Glad-Hat-5094",
          "text": "I'm getting a lot of errors when running this workflow like the one below. Did anyone else get these errors?\n\nPrompt outputs failed validation:  \nCLIPTextEncode:  \n\\- Return type mismatch between linked nodes: clip, received\\_type(MODEL) mismatch input\\_type(CLIP)",
          "score": 1,
          "created_utc": "2025-12-30 20:49:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwt0yp8",
              "author": "intLeon",
              "text": "Make sure your comfyui is up to date and right models are selected for clip node.",
              "score": 1,
              "created_utc": "2025-12-30 21:48:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwt0d70",
          "author": "MalcomXhamster",
          "text": "This is not porn for some reason.",
          "score": 1,
          "created_utc": "2025-12-30 21:45:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwt0q3z",
              "author": "intLeon",
              "text": "Username checks out. Well you are free to add custom lora's to each part but Id wanna see some sfw generations in the civit page as well ;-;",
              "score": 1,
              "created_utc": "2025-12-30 21:47:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwt8f8s",
          "author": "PestBoss",
          "text": "Nice work.\n\nA shame it's all been put into sub-graphs despite stuff like prompts, seeds, per-section sampling/steps, all ideally being things you'd set/tweak per section, especially in a workflow as much about experimentation as production flow.\n\nIt actually means I have to spend more time unbundling it all and rebuilding it, just to see how it actually works.\n\n\nTo sum up on steps. Are you doing:\n\n1 high noise without a lora\n3 high noise with a lora\n3 low noise with a lora\n\n?\n\nIs this a core need of the SVI process or you just tinkering around?\n\nIe, can I just use 2+2 as normal, and live with the slower motion?",
          "score": 1,
          "created_utc": "2025-12-30 22:24:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwt9zj3",
              "author": "intLeon",
              "text": "You can set them from outside thanks to promote widget feature and I wanted to keep the subgraph depth at 1 except for the save subgraph in each node.\n\nAlso you can go inside subgraphs, you dont need to unpack them.\n\nFor steps no lora brings more motion and can help avoid slowmotion.",
              "score": 1,
              "created_utc": "2025-12-30 22:32:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwtakl9",
          "author": "Green-Ad-3964",
          "text": "Thanks, this seems outstanding for wan 2.2. What are the best \"adjustments\" for a blackwell card (5090) on windows to get the maximum efficiency? Thanks again.",
          "score": 1,
          "created_utc": "2025-12-30 22:35:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtbfaj",
              "author": "intLeon",
              "text": "I dont have enough experience with blackwell series but sage attention makes the most difference in previous cards. Id suggest giving a shot to sage 3.",
              "score": 2,
              "created_utc": "2025-12-30 22:39:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwtbi4x",
          "author": "DMmeURpet",
          "text": "Can we use key frames for this and it fill the gaps between images",
          "score": 1,
          "created_utc": "2025-12-30 22:39:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtcooc",
              "author": "intLeon",
              "text": "Currently I have not seen end image support in wanImageToVideoSVIPro node. It only generates a latent from previous latents end.",
              "score": 1,
              "created_utc": "2025-12-30 22:46:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwtg1ko",
          "author": "sepalus_auki",
          "text": "I need a method which doesn't need ComfyUI.",
          "score": 1,
          "created_utc": "2025-12-30 23:03:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtgb19",
              "author": "intLeon",
              "text": "I dont know if svi team has their own wrapper for that but even without kjnodes it would be too difficult to try for me.",
              "score": 1,
              "created_utc": "2025-12-30 23:05:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwtjtnr",
          "author": "foxdit",
          "text": "I've tentatively fixed the slow-mo issue with my version of this workflow. It uses 2 samplers for each segment: 2 steps HIGH (no Lightx2v, cfg 3.0), 4 steps LOW (w/ lightx2v, cfg 1). That alone handles most of the slow-mo. BUT, I went one step further with the new Motion Scale node, added to HIGH model:\n\nhttps://www.reddit.com/r/StableDiffusion/comments/1pz2kvv/wan_22_motion_scale_control_the_speed_and_time/\n\nUsing 1.3-1.5 time scale seems to do the trick.",
          "score": 1,
          "created_utc": "2025-12-30 23:24:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtkdou",
              "author": "intLeon",
              "text": "Im around the same settings now but testing 2 + 2 + 3. Low lora seems to have TAA like side effects. Motion scale felt a little unpredictable for now. Especially since its a batch job and things could go sideways any moment Ill look for something safer.",
              "score": 1,
              "created_utc": "2025-12-30 23:27:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwto11v",
                  "author": "foxdit",
                  "text": "My edited workflow has lots of quality of life features for that sort of thing. It sets fixed seeds across the board, with individual EasySeed nodes controlling the seed value for each of them. This allows you to keep segments 1 and 2, but reroll on segment 3 and continue from there if you thought the segment came out bad initially. You'll never have to restart the whole gen from scratch if one segment doesn't look right--you just regen that individual one. As long as you don't change any values from the earlier \"ok\" segments, it'll always regen a brand new seeded output for the segment you're resuming from. It works great and as someone on a slow GPU, it's a life saver.",
                  "score": 1,
                  "created_utc": "2025-12-30 23:47:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwtka42",
          "author": "tutman",
          "text": "Is there a workflow for a 12VRAM and I2V? Thanks!",
          "score": 1,
          "created_utc": "2025-12-30 23:26:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtkl20",
              "author": "intLeon",
              "text": "I have a 4070ti with 12gb vram and this is an I2V based workflow.",
              "score": 1,
              "created_utc": "2025-12-30 23:28:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwtlr6n",
          "author": "HerrgottMargott",
          "text": "This is awesome! Thanks for sharing!\nFew questions, if you don't mind answering:\n1. Am I understanding correctly that this uses the last latent instead of the last frame for continued generation?\n2. Could the same method be used with a simpler workflow where you generate a 5 second video and then input the next starting latent manually?\n3. I'm mostly using a gguf model where the lightning loras are already baked in. Can I just bypass the lightning loras while still using the same model I'm currently using or would that lead to issues?\n\nThanks again! :)",
          "score": 1,
          "created_utc": "2025-12-30 23:34:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtodix",
              "author": "intLeon",
              "text": "1- yes\n2- maybe if you save the latent or convert video to latent then feed it, but requires a reference latent as well\n3- probably\n\nEnjoy ;)",
              "score": 2,
              "created_utc": "2025-12-30 23:49:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwttyoa",
          "author": "Mirandah333",
          "text": "Why it ignores completely the first image (suposed to be the 1st frame)? Something am I missing? :(((",
          "score": 1,
          "created_utc": "2025-12-31 00:19:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtuznn",
              "author": "intLeon",
              "text": "Is load image output connected into encode subgraph?\n\n(Also dont forget to go in encode subgraph by double clicking and setting the resize mode to crop instead of stretch)",
              "score": 2,
              "created_utc": "2025-12-31 00:25:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwudkdi",
          "author": "prepperdrone",
          "text": "r/NeuralCinema posted an SVI 2.0 workflow a few days ago.  I will take a look at both tonight.  One thing I wish you could do is feed it anchor images that aren't the starting image.  Is that possible somehow?",
          "score": 1,
          "created_utc": "2025-12-31 02:11:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvg0w3",
              "author": "intLeon",
              "text": "It would be. You can duplicate the encode node and feed a new image into it. Then use the output latent on the node you want. It may still try to adapt to previous latent so you need to set motion latent count to 0 in the subgraph. Or you can let it run and see what happens ðŸ¤” Could end up with a smoother transition.",
              "score": 1,
              "created_utc": "2025-12-31 06:25:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwvj3h0",
          "author": "bossbeae",
          "text": "The transition Between Each generation has never been smoother for me but There's definitely a slow motion issue tied to the SVI lora's, I can run a nearly identical setup with the same Lightning Lora's And the normal wan image to video node with no slow motion at all but as soon as I add in the SVI Lora's and the wan image to video SVI Pro node There's Very noticeable slow motion, I am also noticing that prompt adherence is very weak compared to that same setup without the SVI lora's, I'm struggling to get any significant motion\n\nI should add I'm running on a two sampler setup, the third sampler adds so much extra time to each generation I'm trying to avoid it,",
          "score": 1,
          "created_utc": "2025-12-31 06:50:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvjboo",
              "author": "intLeon",
              "text": "Can you increase the no lora steps to two instead of disabling it? It is supposed to squeeze more motion out of high with lightx2v steps.\n\nEven one step does wonders but 2 worked better in my case.",
              "score": 1,
              "created_utc": "2025-12-31 06:52:44",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwvoqzl",
              "author": "foxdit",
              "text": "Just do 2 HIGH steps (2.0 or 3.0 cfg, no speedup lora) and 4 LOW (w/ speedup lora, 1.0 cfg). If you need faster motion than that, use the new experimental Motion Scaling node (look at the front page of this reddit) and set time scale to 1.2-1.5.\n\nThis has been a fairly easy problem to solve in my experience.",
              "score": 1,
              "created_utc": "2025-12-31 07:41:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwrdyis",
          "author": "hurrdurrimanaccount",
          "text": "it's still slowmo, not really that good",
          "score": 0,
          "created_utc": "2025-12-30 17:10:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrk6tm",
              "author": "intLeon",
              "text": "Thats the lightx2v loras. You can look for alternatives or disable lora nodes, set cfg for 2nd and 3rd phase to higher.\n\nEdit: using 2 no lora steps with a 2 + 2 + 2 sampling works.",
              "score": 2,
              "created_utc": "2025-12-30 17:39:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwrebtk",
          "author": "TheTimster666",
          "text": "https://preview.redd.it/8bzo3moejdag1.png?width=382&format=png&auto=webp&s=f8cb41af5fb802e582dfb5bffbe4ae5f687a70b8",
          "score": 0,
          "created_utc": "2025-12-30 17:12:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrmhn0",
              "author": "intLeon",
              "text": "You are welcome to try higher resolutions and more steps ðŸ˜…",
              "score": 3,
              "created_utc": "2025-12-30 17:50:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nws58sk",
          "author": "Tystros",
          "text": "Could you adjust your workflow so that it's easy to set one fixed seed for everything? currently it all seems to be set to randomize in all the sub graphs.",
          "score": 0,
          "created_utc": "2025-12-30 19:17:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwser91",
              "author": "foxdit",
              "text": "This is exactly what I did. I set everything to a fixed seed, then added an EasySeed node into each subgraph, titled \"Start from Here\". You just click it and it resumes the process from that segment, rather than starting over from scratch. That way, if segment #3 of 5 is bad, you just regen that specific one rather than starting over just because a middle piece is bad. You can just reroll the individual seeds as many times as you need to get a good segment, then continue on from there.",
              "score": 2,
              "created_utc": "2025-12-30 20:02:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwsc64n",
              "author": "intLeon",
              "text": "Im not sure, since they have similar latents you might get repetative motion during other parts. I guess only solution would be to load workflow through the job list.",
              "score": 1,
              "created_utc": "2025-12-30 19:50:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwscs5l",
                  "author": "Tystros",
                  "text": "you could also make it so that there can be one fixed seed X, but in the subgraphs it's X+1, X+2 etc",
                  "score": 1,
                  "created_utc": "2025-12-30 19:53:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwqjquo",
          "author": "Choowkee",
          "text": ">allegedly famous\n\nReally now...?",
          "score": -6,
          "created_utc": "2025-12-30 14:44:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqkjtm",
              "author": "intLeon",
              "text": "I mean its one of the most downloaded workflows among the wan2.2 I2V A14B. I hope you guys can move it further up ;)",
              "score": 10,
              "created_utc": "2025-12-30 14:48:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwqn142",
                  "author": "Choowkee",
                  "text": "Not with this weird attitude of yours. \n\nKijai released the lora 3 weeks ago, your title makes it sound like its something that was *just* released or thats it something driven by your workflow lol.",
                  "score": -17,
                  "created_utc": "2025-12-30 15:01:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pze07a",
      "title": "A mysterious new year gift",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/59g5evn7bbag1.png",
      "author": "chrd5273",
      "created_utc": "2025-12-30 09:43:07",
      "score": 324,
      "num_comments": 92,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pze07a/a_mysterious_new_year_gift/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwpeinf",
          "author": "Proper-Employment263",
          "text": "Please be **Z-Image Omni**, **Z-Image Base**, and **Z-Image Edit**.\n\n**Edit:** **Qwen Image Edit 2512** is also welcome.",
          "score": 160,
          "created_utc": "2025-12-30 09:44:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwpj86e",
              "author": "ResponsibleTruck4717",
              "text": "Be the Z-image for video generation.",
              "score": 57,
              "created_utc": "2025-12-30 10:27:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwpslxp",
                  "author": "intLeon",
                  "text": "Z.. video?",
                  "score": 28,
                  "created_utc": "2025-12-30 11:49:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwqdn46",
                  "author": "shivdbz",
                  "text": "It will be z video",
                  "score": 7,
                  "created_utc": "2025-12-30 14:10:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwq1i3t",
              "author": "fruesome",
              "text": "Could be Wan Video\n\nMy guess based on AMA they did recently and majority asked for Wan Video",
              "score": 10,
              "created_utc": "2025-12-30 12:56:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwq2yjp",
                  "author": "HashTagSendNudes",
                  "text": "I doubt they will release a updated wan, rumor has it they are making to much via api, do I hope they release it ? 100% yes but ðŸ¤·ðŸ¼",
                  "score": 10,
                  "created_utc": "2025-12-30 13:06:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwrgciw",
              "author": "Arcival_2",
              "text": "X-Audio or Y-text I think...Or worse MAI-UI-2B/8B.",
              "score": 1,
              "created_utc": "2025-12-30 17:21:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwukzx1",
              "author": "gomico",
              "text": "it's the Tongyi team so it can't be Qwen, should be a Z-image or WAN model",
              "score": 1,
              "created_utc": "2025-12-31 02:54:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwvbb2n",
              "author": "Witty_Mycologist_995",
              "text": "Please be Z-Image-Noob",
              "score": 1,
              "created_utc": "2025-12-31 05:47:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwpytls",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2025-12-30 12:37:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwporhz",
          "author": "Sir_McDouche",
          "text": "Half-life 3 confirmed!",
          "score": 31,
          "created_utc": "2025-12-30 11:17:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqnuv6",
              "author": "mattjb",
              "text": "Star Citizen finally done!",
              "score": 16,
              "created_utc": "2025-12-30 15:06:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwstg27",
                  "author": "HardenMuhPants",
                  "text": "GTA 6 only postponed 2 years!",
                  "score": 3,
                  "created_utc": "2025-12-30 21:13:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwpstbq",
              "author": "International-Try467",
              "text": "IENDOFNSOWNJDCIFNIRBE R FHALF LIFE 4 JDFBDKANKSNFOFKE9RBFKFBIDJSIAVSHFJRBDJDNRIR GABEN JNDIDNDOENEKRNOFJFISJSIDJFOFNZOABJWKDFIFUHH DOORS OF STONEISW JFJRBDIWBSOBF",
              "score": -4,
              "created_utc": "2025-12-30 11:51:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwrjqil",
                  "author": "WhyIsTheUniverse",
                  "text": "Upvoted for posterityâ€™s sake.",
                  "score": 1,
                  "created_utc": "2025-12-30 17:37:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpf6ci",
          "author": "BlackSwanTW",
          "text": "Z-Image-Turbo 2 ðŸ—£ï¸",
          "score": 97,
          "created_utc": "2025-12-30 09:50:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwpg5us",
              "author": "HornyGooner4401",
              "text": "We're getting GTA 6 before Z-Image base/edit",
              "score": 84,
              "created_utc": "2025-12-30 09:59:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nws7vzl",
                  "author": "Wild-Perspective-582",
                  "text": "Still not yet a Half Life 3",
                  "score": 2,
                  "created_utc": "2025-12-30 19:29:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpkm0x",
          "author": "Betadoggo_",
          "text": "lol  \n[https://github.com/modelscope/DiffSynth-Studio/pull/1166](https://github.com/modelscope/DiffSynth-Studio/pull/1166)",
          "score": 25,
          "created_utc": "2025-12-30 10:39:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwprvs6",
              "author": "noyart",
              "text": "Cant wait! ðŸ¤¤Â ",
              "score": 6,
              "created_utc": "2025-12-30 11:44:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwt9qkb",
              "author": "Whispering-Depths",
              "text": "they are milking this shit soooo hard",
              "score": 4,
              "created_utc": "2025-12-30 22:30:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwr035z",
              "author": "martinerous",
              "text": "GGUF when? - Qwen.",
              "score": 3,
              "created_utc": "2025-12-30 16:05:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwphsb4",
          "author": "Luiguie171",
          "text": "https://preview.redd.it/1ivxkjopgbag1.jpeg?width=1220&format=pjpg&auto=webp&s=6e7939c6173e15358317e1f4ca27220fb1ee88fe\n\nThe duality of men",
          "score": 98,
          "created_utc": "2025-12-30 10:13:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwprk61",
              "author": "noyart",
              "text": "I want by gooooooner generator now ðŸ˜¤ðŸ˜¤ðŸ˜¤ðŸ§»ðŸ˜­",
              "score": 17,
              "created_utc": "2025-12-30 11:41:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwq5ml2",
                  "author": "mk8933",
                  "text": "Best of the best...is still SDXL...people are sleeping on it.",
                  "score": -13,
                  "created_utc": "2025-12-30 13:23:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwqbwe7",
              "author": "blastcat4",
              "text": "It's getting to be like every big Chinese game that has a leaks community.",
              "score": 1,
              "created_utc": "2025-12-30 14:00:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpfbko",
          "author": "Skyline34rGt",
          "text": "Probably Qwen Image v2 - they teasing it from a week - [https://x.com/cherry\\_cc12/status/2004741644810383684](https://x.com/cherry_cc12/status/2004741644810383684)\n\n[https://x.com/cherry\\_cc12/status/2004105860247965910](https://x.com/cherry_cc12/status/2004105860247965910)\n\n[https://x.com/cherry\\_cc12/status/2004109818874024246](https://x.com/cherry_cc12/status/2004109818874024246)",
          "score": 46,
          "created_utc": "2025-12-30 09:51:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwq3uq4",
              "author": "SirTeeKay",
              "text": "I mean, if it looks like this I can wait a bit longer for Z-Image.",
              "score": 5,
              "created_utc": "2025-12-30 13:12:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwqsr6f",
              "author": "NowThatsMalarkey",
              "text": ">https://x.com/cherry_cc12/status/2004105860247965910\n\nThe â€œrealismâ€ looks terrible compared to Z-Image Turbo. Itâ€™ll probably be just as big as Flux.2-dev and therefore dead on arrival.",
              "score": -8,
              "created_utc": "2025-12-30 15:30:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nws239g",
                  "author": "materialist23",
                  "text": "Lmao",
                  "score": 1,
                  "created_utc": "2025-12-30 19:02:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwphao0",
          "author": "Noeyiax",
          "text": "![gif](giphy|fCtaS8rQDRF9C|downsized)",
          "score": 10,
          "created_utc": "2025-12-30 10:09:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqanmp",
              "author": "poopoo_fingers",
              "text": "1: cut a hole in a box",
              "score": 1,
              "created_utc": "2025-12-30 13:53:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpexo1",
          "author": "FitEgg603",
          "text": "He is playing with our emotions",
          "score": 16,
          "created_utc": "2025-12-30 09:47:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwprk4m",
              "author": "Mean-Credit6292",
              "text": "LET THE EDIT OUT!",
              "score": 3,
              "created_utc": "2025-12-30 11:41:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpgc75",
          "author": "Striking-Long-2960",
          "text": "The Audio model?",
          "score": 8,
          "created_utc": "2025-12-30 10:00:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqucvv",
          "author": "Perfect-Campaign9551",
          "text": "       (â€¢ _ â€¢)\n       <)   >\n        |__|\n       / |  \\\n      /      \\",
          "score": 8,
          "created_utc": "2025-12-30 15:38:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrppgt",
              "author": "JohnnyLeven",
              "text": "       (â€¢ _ â€¢)\n       < ) ) >\n        |__|\n       /   \\\n      /     \\",
              "score": 5,
              "created_utc": "2025-12-30 18:05:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwt4qgi",
              "author": "rinkusonic",
              "text": "Can you put it on his chest just like how zimage generates?",
              "score": 1,
              "created_utc": "2025-12-30 22:06:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpf92h",
          "author": "NordRanger",
          "text": "https://preview.redd.it/wzgiq9plcbag1.jpeg?width=680&format=pjpg&auto=webp&s=d2705e93aced59f405982876ddcf7324c9034372",
          "score": 7,
          "created_utc": "2025-12-30 09:50:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpgmmk",
          "author": "Skystunt",
          "text": "I hate how ai devs tease things in cryptic tweets to build hype",
          "score": 22,
          "created_utc": "2025-12-30 10:03:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwph8l0",
              "author": "ready-eddy",
              "text": "Because it works..",
              "score": 7,
              "created_utc": "2025-12-30 10:08:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwphvrv",
                  "author": "a_beautiful_rhind",
                  "text": "they conditioned me. every time I see that, I know it will be a letdown",
                  "score": 18,
                  "created_utc": "2025-12-30 10:14:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwqapiy",
              "author": "hurrdurrimanaccount",
              "text": "people will fall for it all the time. i hate that companies are building that \"rockstar\" kind of personality.\n\nmy guy you make ai models",
              "score": 1,
              "created_utc": "2025-12-30 13:53:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpvpc0",
          "author": "skyrimer3d",
          "text": "great if it's qwen 2 image, great model that needs more lora love.",
          "score": 5,
          "created_utc": "2025-12-30 12:14:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nws1lh9",
              "author": "Agile-Role-1042",
              "text": "Isn't Qwen a heavy model to train on?",
              "score": 1,
              "created_utc": "2025-12-30 18:59:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwt5m82",
              "author": "rinkusonic",
              "text": "I don't know why but I have never been able to generate a good image with qwen t2i. I kept trying every few weeks. I just gave up 2 days ago and freed my storage of 40 gb of models.",
              "score": 1,
              "created_utc": "2025-12-30 22:10:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwt7vpx",
                  "author": "skyrimer3d",
                  "text": "it mostly can but needs a ton of loras to look ok, something that ZIT does by default. Try lenovo , boreal and cinematic loras, they help a lot, also iphone and samsung loras are good.",
                  "score": 1,
                  "created_utc": "2025-12-30 22:21:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpemo1",
          "author": "Major_Specific_23",
          "text": "Qwen image 2? I'm happy if it's qwen image 2 or zimage omni base. 0 complaints",
          "score": 8,
          "created_utc": "2025-12-30 09:45:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpgnrm",
          "author": "Nid_All",
          "text": "Qwen Image 2",
          "score": 5,
          "created_utc": "2025-12-30 10:03:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwsh0xf",
              "author": "RazsterOxzine",
              "text": "Qwen Image 2531.",
              "score": 1,
              "created_utc": "2025-12-30 20:13:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwprrm8",
          "author": "SweetLikeACandy",
          "text": "Qwen-Image-2512 probably, but I don't mind if it's Z-Image Base :D",
          "score": 5,
          "created_utc": "2025-12-30 11:43:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpwdr2",
          "author": "chrd5273",
          "text": "More hints from modelscope; at least it seems like an image model. Qwen Image 2512 or Z image base?\n\nhttps://preview.redd.it/wprylix53cag1.jpeg?width=1080&format=pjpg&auto=webp&s=156efa904bfcf40c0ad98e50186fb0b97be3cecb",
          "score": 4,
          "created_utc": "2025-12-30 12:19:39",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nwpjjus",
          "author": "physalisx",
          "text": "This is probably about an LLM. \n\nIf there was any image/video involved, that would be in the tweet, not an ASCII stick figure.",
          "score": 3,
          "created_utc": "2025-12-30 10:30:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpigsq",
          "author": "AIDivision",
          "text": "Its another LLM model, don't get your hopes up.",
          "score": 4,
          "created_utc": "2025-12-30 10:20:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwq2nln",
              "author": "SirTeeKay",
              "text": "I mean... I wouldn't mind Qwen VL 2 or something along those lines.",
              "score": -2,
              "created_utc": "2025-12-30 13:04:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwqgz8g",
                  "author": "ETman75",
                  "text": "Qwen3 VL already existsâ€¦",
                  "score": 6,
                  "created_utc": "2025-12-30 14:29:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwq0tdk",
          "author": "Chemical-Load6696",
          "text": "Please be suno weights",
          "score": 2,
          "created_utc": "2025-12-30 12:52:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwq1r5i",
          "author": "ANR2ME",
          "text": "May be API only model ðŸ˜‚",
          "score": 2,
          "created_utc": "2025-12-30 12:58:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqi47p",
          "author": "Nokai77",
          "text": "Please... ZIE!",
          "score": 2,
          "created_utc": "2025-12-30 14:35:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwr0aq2",
          "author": "Great_Traffic1608",
          "text": "wan2.5-2.6",
          "score": 2,
          "created_utc": "2025-12-30 16:06:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwplhcu",
          "author": "Tall-Animator2394",
          "text": "its qwen image 2 [https://github.com/modelscope/DiffSynth-Studio/pull/1166](https://github.com/modelscope/DiffSynth-Studio/pull/1166)",
          "score": 4,
          "created_utc": "2025-12-30 10:47:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpq2ee",
          "author": "Odd-Mirror-2412",
          "text": "ZIB please!",
          "score": 4,
          "created_utc": "2025-12-30 11:28:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpfdso",
          "author": "fauni-7",
          "text": "Omg omg...!",
          "score": 3,
          "created_utc": "2025-12-30 09:51:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpgesq",
          "author": "Consistent-Mastodon",
          "text": "Wan2.2-2?",
          "score": 1,
          "created_utc": "2025-12-30 10:01:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpyskh",
          "author": "Cold_Development_608",
          "text": "![gif](giphy|3j1cQmHH21pMEmgd0O)\n\nModel eppo varuven, eppadi varuvennu yarukkum theriyathu, aana vara vendiya nerathula correct a varuven.",
          "score": 1,
          "created_utc": "2025-12-30 12:37:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwse80r",
          "author": "Technical_Ad_440",
          "text": "would love open source music finally",
          "score": 1,
          "created_utc": "2025-12-30 19:59:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwsi6zo",
          "author": "Mental_Paradize",
          "text": "At this point they are just playing with people's expectations. I'll just wait and see.",
          "score": 1,
          "created_utc": "2025-12-30 20:19:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwsodvi",
          "author": "zodoor242",
          "text": "Crystal Pepsi 2?",
          "score": 1,
          "created_utc": "2025-12-30 20:49:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvg4ka",
          "author": "seifai",
          "text": "Qwen 2512",
          "score": 1,
          "created_utc": "2025-12-31 06:26:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwph2s2",
          "author": "protector111",
          "text": "FYI Chinese new year is late February 2026",
          "score": 1,
          "created_utc": "2025-12-30 10:07:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwphc9v",
              "author": "Striking-Warning9533",
              "text": "As a Chinese, this is not usually what they meant. We call the Chinese NY as spring fes, And on English social media and at this time, it is almost meant to be Jan 1.",
              "score": 29,
              "created_utc": "2025-12-30 10:09:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwpjg1h",
                  "author": "physalisx",
                  "text": "Thank you for the insight",
                  "score": 2,
                  "created_utc": "2025-12-30 10:29:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwppmfm",
                  "author": "protector111",
                  "text": "I was just joking, but Thanks for the explanation :)",
                  "score": 0,
                  "created_utc": "2025-12-30 11:24:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwphgzs",
              "author": "Skyline34rGt",
              "text": "Don't worry, they operate from USA xD",
              "score": 1,
              "created_utc": "2025-12-30 10:10:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwppjye",
                  "author": "protector111",
                  "text": "Oh so its coming soon then xD",
                  "score": 0,
                  "created_utc": "2025-12-30 11:24:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwphsyc",
          "author": "HashTagSendNudes",
          "text": "I swear watch it be a sound model or a llm ðŸ¥¹ðŸ’”",
          "score": 1,
          "created_utc": "2025-12-30 10:13:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwucxjn",
          "author": "AppealThink1733",
          "text": "Qwen's model has fallen far behind the latest open-source updates regarding LLM. I hope they make a turnaround.",
          "score": 0,
          "created_utc": "2025-12-31 02:07:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqnj4r",
          "author": "Acceptable_Home_",
          "text": "There was crazy Half life 3 ahh situation in this sub, more hopium for us",
          "score": -1,
          "created_utc": "2025-12-30 15:04:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpkgon",
          "author": "FitEgg603",
          "text": "\nIf the gift isnâ€™t worthwhile, thereâ€™s no point in offering it. Creating unnecessary hype around a weak or irrelevant diffusion model serves no purpose. What we actually want is the Z-Image base model onlyâ€”no LLMs, no Qwen2, or anything related.",
          "score": -9,
          "created_utc": "2025-12-30 10:38:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1puogxd",
      "title": "Holt shit lvl quality",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1puogxd",
      "author": "reversedu",
      "created_utc": "2025-12-24 14:21:29",
      "score": 312,
      "num_comments": 75,
      "upvote_ratio": 0.79,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1puogxd/holt_shit_lvl_quality/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nvpzdvj",
          "author": "Major_Specific_23",
          "text": "OP did not post the link\n\n[https://modelscope.cn/models/Nurburgring/BEYOND\\_REALITY\\_Z\\_IMAGE/summary](https://modelscope.cn/models/Nurburgring/BEYOND_REALITY_Z_IMAGE/summary)",
          "score": 148,
          "created_utc": "2025-12-24 14:27:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvq211d",
              "author": "Hunting-Succcubus",
              "text": "But you did, thanks",
              "score": 32,
              "created_utc": "2025-12-24 14:43:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvq25o6",
              "author": "Hunting-Succcubus",
              "text": "Huggingface link?",
              "score": 7,
              "created_utc": "2025-12-24 14:44:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvq2auf",
                  "author": "Major_Specific_23",
                  "text": "Example images available on CivitAI:  \n[https://civitai.com/models/1090420?modelVersionId=2521262](https://civitai.com/models/1090420?modelVersionId=2521262)\n\nModel also available on Hugging Face:  \n[https://huggingface.co/Nurburgring/BEYOND\\_REALITY\\_Z\\_IMAGE](https://huggingface.co/Nurburgring/BEYOND_REALITY_Z_IMAGE)\n\nnot worth it bro. its a lora merged to the checpoint. i saw it a couple of days ago in civitai and thought \"oh its plastic again\"",
                  "score": 46,
                  "created_utc": "2025-12-24 14:45:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvpzndr",
          "author": "vault_nsfw",
          "text": "I don't see what this is supposed to do. My base Z-Image Turbo worflow does the same but better with actual realistic skin texture including preserving analog look and adding grain. What am I missing? ðŸ¤”",
          "score": 165,
          "created_utc": "2025-12-24 14:29:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvq1mn4",
              "author": "Informal_Warning_703",
              "text": "As usual, \\*ANY\\* post like this which does not show us a side-by-side comparison with the base model is \\*absolutely useless\\* in terms of actually demonstrating the quality of the fine-tune or lora. See this constantly in this subreddit and you would think it's something people would have caught onto since SD1.5 days...",
              "score": 130,
              "created_utc": "2025-12-24 14:41:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvq0cnk",
              "author": "Zenshinn",
              "text": "Can you use character loras with your workflow?",
              "score": 2,
              "created_utc": "2025-12-24 14:33:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvq3au2",
                  "author": "vault_nsfw",
                  "text": "Yes! As I only use the LORA in the initial generation and then upscale/refine mutliple times at low denoise minimally changing the subject up to 26mp. I'll show an example once I'm back home.",
                  "score": 10,
                  "created_utc": "2025-12-24 14:50:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvq8f92",
              "author": "Guilty_Emergency3603",
              "text": "This looks more \"professional\" photograph. Z-image-turbo has this amateurish look from cheap cameras with too much noise and grain. This is a common issue, people mistaking noise/grain with details.",
              "score": 2,
              "created_utc": "2025-12-24 15:19:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvqxaj0",
                  "author": "ThatsALovelyShirt",
                  "text": "I prefer that look of base ZiT tbh. So much of these fine tuned models or Loras where people say \"it's SO much better\", it's all just subjective.",
                  "score": 18,
                  "created_utc": "2025-12-24 17:33:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvqugz8",
                  "author": "LumaBrik",
                  "text": "Skill issue ... either you have a poor workflow or you are using the wrong samplers.",
                  "score": 6,
                  "created_utc": "2025-12-24 17:18:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvr1sz7",
                  "author": "StardockEngineer",
                  "text": "Not if you use highly detailed prompts.",
                  "score": 1,
                  "created_utc": "2025-12-24 17:58:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvq91yx",
                  "author": "vault_nsfw",
                  "text": "I have a Canon R5 and that one has a good amount of noise too if not shot at <= 400 ISO. Generations will mostly have noise at the native resolution. I have a workflow that adds realistic amounts of noise at a final resolution of around 26MP.",
                  "score": 1,
                  "created_utc": "2025-12-24 15:23:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvu33at",
              "author": "MalteseDuckling",
              "text": "Nice . Can share workflow ? Really appreciate it .",
              "score": 1,
              "created_utc": "2025-12-25 06:26:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvqek4w",
          "author": "Keem773",
          "text": "Maybe I've been looking at real humans for too long but......I'm not quite seeing the \"focus on skin texture\" in these sample images lol.",
          "score": 48,
          "created_utc": "2025-12-24 15:53:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvre7oa",
              "author": "hurrdurrimanaccount",
              "text": "because most of these ai researchers have long forgotten or care what real skin looks like. it's just become another buzzword to add to your model to get the roomtemp iq people to download their shit",
              "score": 12,
              "created_utc": "2025-12-24 19:04:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvq6zc0",
          "author": "food-dood",
          "text": "Today on stable diffusion, we take a realistic image model and add PLASTIC",
          "score": 84,
          "created_utc": "2025-12-24 15:11:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvqasa5",
          "author": "trdcr",
          "text": "We're already past the plastic skin, this is step back.",
          "score": 17,
          "created_utc": "2025-12-24 15:32:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvqdwnt",
          "author": "RabbitEater2",
          "text": "More 1girls? Getting tiring of always seeing the same things ngl, how about some interactions, complex scenes, multiple people, etc",
          "score": 26,
          "created_utc": "2025-12-24 15:49:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvre709",
              "author": "Purplekeyboard",
              "text": "So you're saying... 2 girls?",
              "score": 14,
              "created_utc": "2025-12-24 19:04:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvrh2fe",
                  "author": "mattjb",
                  "text": "1cup?",
                  "score": 7,
                  "created_utc": "2025-12-24 19:20:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvq9xns",
          "author": "kaeptnphlop",
          "text": "Now do a festive table setting where all silverware, plates and cups are positioned correctly. And where the dishes look natural and consistent like a person cooked them â€¦\n\nIâ€™m so tired of these posts where the only example is yet another photograph of a pretty woman. Doesnâ€™t tell us bug-all about the capabilities of a model",
          "score": 18,
          "created_utc": "2025-12-24 15:28:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvqels9",
          "author": "Perfect-Campaign9551",
          "text": "More bullshit from people that don't know what they are doing or talking about",
          "score": 8,
          "created_utc": "2025-12-24 15:53:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvreebr",
              "author": "a_beautiful_rhind",
              "text": "To be fair, the lab is who shilled it.",
              "score": 3,
              "created_utc": "2025-12-24 19:05:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvq82oe",
          "author": "ZealousidealDrop7475",
          "text": "Beyond reality, why skin looks plastic?",
          "score": 15,
          "created_utc": "2025-12-24 15:17:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvr013z",
              "author": "metal0130",
              "text": "because it's not reality. its... *beyond* reality. Duh!",
              "score": 10,
              "created_utc": "2025-12-24 17:48:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvq3kva",
          "author": "K0owa",
          "text": "Yâ€™all really get excited about anything, huh?",
          "score": 30,
          "created_utc": "2025-12-24 14:52:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvqalwu",
              "author": "gefahr",
              "text": "If it's from a Chinese model and it can run on 8-16gb, it will be upvoted to the moon here.",
              "score": 8,
              "created_utc": "2025-12-24 15:31:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvr1tnw",
                  "author": "thebaker66",
                  "text": "Why is it relevant if its chinese? Is this a disparaging comment? \n\nThey just happen to be the ones providing the goods, we'd be foaming at the mouth too if such efficient models came from the US or anywhere else too but of course China is the only one who has the lack of regulation and ability to give these models away for free.\n\nQwen, Z-Image are genuinely great and worthy of the praise.\n\nThis model here doesn't look particulary realistic tbh",
                  "score": 1,
                  "created_utc": "2025-12-24 17:58:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvq3err",
          "author": "Enshitification",
          "text": "I'll wait for the LoRA extraction to use it with ZiT base.",
          "score": 7,
          "created_utc": "2025-12-24 14:51:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvq30s8",
          "author": "Dezordan",
          "text": "I wonder why they try to showcase this LoRA merge?",
          "score": 11,
          "created_utc": "2025-12-24 14:49:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsoxc9",
          "author": "terrariyum",
          "text": "more proof of how botted this subreddit is.  Hundreds of upvotes on a clickbait title while all comments call it out as bs",
          "score": 5,
          "created_utc": "2025-12-24 23:52:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvq9kl2",
          "author": "Icy_Prior_9628",
          "text": "![gif](giphy|um2kBnfo55iW4ZH1Fa)\n\nfor ZImage Base.",
          "score": 9,
          "created_utc": "2025-12-24 15:26:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvqrliy",
              "author": "Calm_Mix_3776",
              "text": "Same here. Turbo has this ultra-clean, overly sanitized AI look. Need something un-distilled, with real CFG that adds some real texture and grit. I really dislike the trend of all new models being distilled.",
              "score": 5,
              "created_utc": "2025-12-24 17:02:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvqwgjf",
                  "author": "anonz-11",
                  "text": "Just use euler beta or euler ddim\\_uniform",
                  "score": 1,
                  "created_utc": "2025-12-24 17:29:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvr290i",
          "author": "thebaker66",
          "text": "Fake news, not impressed.\n\nI'll echo what others are saying, some of these new model/merges whatever seem to be taking away from the realism.\n\nI've been a/bing stable yogi and unstablerealism models and often times the original has the best realism.. Though of course nsfw is expanded with yogi so it's a bit hit and miss it seems",
          "score": 3,
          "created_utc": "2025-12-24 18:00:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvs4b86",
          "author": "NotEeUsername",
          "text": "Looks like plastic",
          "score": 3,
          "created_utc": "2025-12-24 21:37:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvq2syf",
          "author": "QikoG35",
          "text": "hope they release just the Lora. Seems like that is the magic.",
          "score": 3,
          "created_utc": "2025-12-24 14:48:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvq7hxb",
              "author": "SanDiegoDude",
              "text": "[very easy to scrape a model to a lora using diffs in comfy](https://imgur.com/a/VcYpyoK). if you're on lower vram, make sure you do a fresh comfy restart and use --lowvram to force it to block swap. it can take awhile, just be patient, if it's going to fail, it will fail spectacularly. On a 4090 takes about 5 mins, so adjust your wait time accordingly. Don't know what the min VRAM is to do this, but it's doable with built in nodes without fancy workflows.",
              "score": 11,
              "created_utc": "2025-12-24 15:14:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvqaq4n",
                  "author": "MonkeyCartridge",
                  "text": "You can also do this with the super merger addon for Forge/A1111",
                  "score": 3,
                  "created_utc": "2025-12-24 15:32:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvqrofr",
                  "author": "Calm_Mix_3776",
                  "text": "Pretty cool! Thanks! Is there any quality reduction compared to using the full model?",
                  "score": 2,
                  "created_utc": "2025-12-24 17:02:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvqxerf",
                  "author": "DigitalDreamRealms",
                  "text": "Thanks for sharing! going to try this method.",
                  "score": 1,
                  "created_utc": "2025-12-24 17:34:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvqpvsi",
          "author": "Vendill",
          "text": "I think calling it \"shit lvl\" quality is a little unfair, it's... I mean, it's not good, but it's better than Bing image generator at least?",
          "score": 3,
          "created_utc": "2025-12-24 16:52:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvqf2rt",
          "author": "Alamedwolf",
          "text": "Zzzzz",
          "score": 2,
          "created_utc": "2025-12-24 15:55:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvqhx60",
          "author": "garbage211",
          "text": "how does it play with loras? with Turbo, I still can't get 2 loras to work together lol.",
          "score": 2,
          "created_utc": "2025-12-24 16:10:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrjbq0",
          "author": "Sudden_List_2693",
          "text": "Ah nice way to lose ZIT's unique charm to make it an imperfect Flux!",
          "score": 2,
          "created_utc": "2025-12-24 19:33:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrp4yz",
          "author": "Paraleluniverse200",
          "text": "This kinda look.. average, can't see a real improvement here",
          "score": 2,
          "created_utc": "2025-12-24 20:07:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsizng",
          "author": "IrisColt",
          "text": "This model is worse. The consensus is clear:Â Z Image Turbo is so OP that fine tunes worsen it, and even its authors think that the original Z Image base model has \"bad\" quality in comparison.",
          "score": 2,
          "created_utc": "2025-12-24 23:11:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvqed5c",
          "author": "zanmaer",
          "text": "I don't often generate people and skin. But here's an abstract scene with fabric as an example.\n\nBase Z-Image - [https://ibb.co/bgpgkLCZ](https://ibb.co/bgpgkLCZ)  \nBeyond Reality Z-Image 1.0 - [https://ibb.co/MkrpHfm4](https://ibb.co/MkrpHfm4)\n\nI think Beyond Reality makes the image less noisy and works better with light and contrast. I did a few more tests, and visually, subjectively ofc, I like the result with Beyond Reality much more.  \nI think that if the end result is not ultra-realism, but a commercial shot for advertising, for example, then this checkpoint is quite good.",
          "score": 3,
          "created_utc": "2025-12-24 15:51:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvqqvtc",
              "author": "Competitive_Ad_5515",
              "text": "Neither of these links work for me",
              "score": 3,
              "created_utc": "2025-12-24 16:58:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvqzlou",
                  "author": "zanmaer",
                  "text": "my bad \n\nhttps://preview.redd.it/balmaoiyv69g1.png?width=2190&format=png&auto=webp&s=c72165c7b1f684b28b0165fe625bcbb95594905b",
                  "score": 3,
                  "created_utc": "2025-12-24 17:46:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvrh10t",
          "author": "Jacks_Half_Moustache",
          "text": "Here we go with the bullshit finetunes that serve zero purpose.",
          "score": 2,
          "created_utc": "2025-12-24 19:20:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvr1776",
          "author": "Major-System6752",
          "text": "How much I loose in quality with fp8 model?",
          "score": 1,
          "created_utc": "2025-12-24 17:54:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvr479v",
          "author": "Fresh-Exam8909",
          "text": "Thanks for this model.\n\nUnfortunately, I prefer using Wan2.2 for T2I. All the Loras for Wan2.2 and some of Wan2.1 are working. With this model all Zit loras don't work.",
          "score": 1,
          "created_utc": "2025-12-24 18:10:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvststc",
          "author": "Uneternalism",
          "text": "Can it do dicks properly?",
          "score": 1,
          "created_utc": "2025-12-25 00:26:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvu4nhk",
          "author": "No-Screen9483",
          "text": "Base model is better, man.",
          "score": 1,
          "created_utc": "2025-12-25 06:41:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvubi6s",
          "author": "Tucker-French",
          "text": "Looks fine but not dynamic or textured",
          "score": 1,
          "created_utc": "2025-12-25 07:51:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuz8za",
          "author": "cimocw",
          "text": "I will be impressed when I see outputs of normal looking people with challenging features like wrinkles, rolls, cellulite, etc.Â ",
          "score": 1,
          "created_utc": "2025-12-25 12:07:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvwufar",
          "author": "insmek",
          "text": "Z-Image doesnâ€™t really need stuff like this with proper prompting.Â ",
          "score": 1,
          "created_utc": "2025-12-25 19:31:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvx0qer",
          "author": "ETman75",
          "text": "This is plastic",
          "score": 1,
          "created_utc": "2025-12-25 20:09:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0vx0b",
          "author": "VegaKH",
          "text": "Holy shit, thatâ€™s mid!",
          "score": 1,
          "created_utc": "2025-12-26 13:59:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvqabw8",
          "author": "Ok-Establishment4845",
          "text": "finally a dicend concurency to plasticy flux-chiny flux.",
          "score": 0,
          "created_utc": "2025-12-24 15:30:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvthmxo",
          "author": "OkBill2025",
          "text": "I don't know Rick...",
          "score": 0,
          "created_utc": "2025-12-25 03:26:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pvykvj",
      "title": "Z-Image-Omni-Base Release ?",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/wg0dgnjx3i9g1.png",
      "author": "Proper-Employment263",
      "created_utc": "2025-12-26 07:31:38",
      "score": 305,
      "num_comments": 34,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Misleading Title",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pvykvj/zimageomnibase_release/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nvzr58y",
          "author": "khronyk",
          "text": "3:41 pm\nFriday, 26 December 2025 (GMT+8)\nTime in Beijing, China \n\n..... OOOOOHHHHHHHH, that's in less than 20min\n\nEdit: T_T",
          "score": 68,
          "created_utc": "2025-12-26 07:42:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvzt9j5",
              "author": "TurningTideDV",
              "text": "so, anything interesting happened?",
              "score": 17,
              "created_utc": "2025-12-26 08:04:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvztegg",
                  "author": "ArkCoon",
                  "text": "Minimax 2.1 ðŸ’€",
                  "score": 58,
                  "created_utc": "2025-12-26 08:05:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvzsmre",
              "author": "cradledust",
              "text": "Teasing the bots?",
              "score": 5,
              "created_utc": "2025-12-26 07:57:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvzsjlt",
              "author": "robomar_ai_art",
              "text": "Less then 5min",
              "score": 3,
              "created_utc": "2025-12-26 07:56:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvzto3u",
          "author": "davidl002",
          "text": "Nope. It is MiniMax 2.1 instead.",
          "score": 29,
          "created_utc": "2025-12-26 08:08:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvztwuo",
          "author": "SoulofArtoria",
          "text": "![gif](giphy|6oFNB3JPuLpAs)",
          "score": 102,
          "created_utc": "2025-12-26 08:10:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw17n9w",
              "author": "Whispering-Depths",
              "text": "At this point I think they're just using the hype around it to pull in as much attention and traffic as possible and then they're hopefully not going to pull a \"sorry guys it's actually closed source/lobotmized/censored/distilled/etc\"",
              "score": 26,
              "created_utc": "2025-12-26 15:13:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw1jjcg",
                  "author": "Time-Teaching1926",
                  "text": "I think they will do that unfortunately, look at Wan 2.6. it used to be the best open source video generator and now the recent versions are closed Sourced.",
                  "score": 14,
                  "created_utc": "2025-12-26 16:18:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw418vx",
                  "author": "Quick_Knowledge7413",
                  "text": "If they do that then I will just continue working with Qwen image and edit. It's all you need, it just takes longer to generate.",
                  "score": 2,
                  "created_utc": "2025-12-27 00:30:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvzt3em",
          "author": "emailmeforgirl",
          "text": "https://preview.redd.it/lpwoftbj9i9g1.png?width=584&format=png&auto=webp&s=e9df4e0c0d715c21a8487b5c4faf86d6b25fbfda\n\ndisappointed",
          "score": 18,
          "created_utc": "2025-12-26 08:02:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvztbpk",
              "author": "Structure-These",
              "text": "ðŸ˜­",
              "score": 2,
              "created_utc": "2025-12-26 08:04:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvzvsk6",
          "author": "JustAGuyWhoLikesAI",
          "text": "and the crowd goes mild!",
          "score": 17,
          "created_utc": "2025-12-26 08:30:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzvd7h",
          "author": "3deal",
          "text": "It is a coding LLM",
          "score": 10,
          "created_utc": "2025-12-26 08:25:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzurq0",
          "author": "shivdbz",
          "text": "Minimax M.2 DAMMMNITTT",
          "score": 8,
          "created_utc": "2025-12-26 08:19:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw223d2",
          "author": "hurrdurrimanaccount",
          "text": "stop giving them attention and they will stop this bs",
          "score": 7,
          "created_utc": "2025-12-26 17:56:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzq4js",
          "author": "Lost-Dot-9916",
          "text": "nice",
          "score": 2,
          "created_utc": "2025-12-26 07:32:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzsa5m",
          "author": "StacksGrinder",
          "text": "Oh! My weekend is sorted, Cancel all plans. :D",
          "score": 2,
          "created_utc": "2025-12-26 07:54:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvztn95",
              "author": "shivdbz",
              "text": "So no sex?",
              "score": 6,
              "created_utc": "2025-12-26 08:08:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw0p2dd",
                  "author": "anniesboobs69",
                  "text": "Lack of sex is why we use AI in the first place.",
                  "score": 14,
                  "created_utc": "2025-12-26 13:12:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvzsy69",
          "author": "Major_Specific_23",
          "text": "![gif](giphy|CIy7Ri74WywvK)",
          "score": 3,
          "created_utc": "2025-12-26 08:00:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw1bx5n",
              "author": "Incognit0ErgoSum",
              "text": "Narrator: *It didn't.*",
              "score": 5,
              "created_utc": "2025-12-26 15:37:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw095xi",
          "author": "Regular-Forever5876",
          "text": "Downloading.... ðŸ¥°",
          "score": 1,
          "created_utc": "2025-12-26 10:49:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzrswa",
          "author": "zanmaer",
          "text": "think thats new t2i qwen, which they mentioned several times this week",
          "score": -2,
          "created_utc": "2025-12-26 07:49:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzqnt1",
          "author": "juandann",
          "text": "hope so",
          "score": 0,
          "created_utc": "2025-12-26 07:37:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzqyzp",
          "author": "mallibu",
          "text": "nice",
          "score": 0,
          "created_utc": "2025-12-26 07:40:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3olbw",
          "author": "Best-Response5668",
          "text": "Who the fuck cares? Nano Banana Pro is the only model you need right now.",
          "score": -8,
          "created_utc": "2025-12-26 23:14:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pvjntk",
      "title": "How to stack 2 or more LoRA's (Like a style and character) and get good results with Z-Image",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1pvjntk",
      "author": "Major_Specific_23",
      "created_utc": "2025-12-25 18:36:22",
      "score": 291,
      "num_comments": 45,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pvjntk/how_to_stack_2_or_more_loras_like_a_style_and/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nvxjjea",
          "author": "shootthesound",
          "text": "Nice expansion on my stand alone lora scheduler, good job.   if you want slightly more power than scheduling affords, the block edit nodes in my pack will allow you swich off blocks of competing loras.",
          "score": 17,
          "created_utc": "2025-12-25 22:04:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvxl7lu",
              "author": "Major_Specific_23",
              "text": "ðŸ™ I'm already experimenting with that node too. Thanks for your work",
              "score": 8,
              "created_utc": "2025-12-25 22:15:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvwqa9z",
          "author": "Major_Specific_23",
          "text": "https://preview.redd.it/aotq9j16fe9g1.png?width=2496&format=png&auto=webp&s=bdb9d9fc39bc52e4fb5cd0a3a62970dc3e2dfb26",
          "score": 24,
          "created_utc": "2025-12-25 19:06:26",
          "is_submitter": true,
          "replies": [
            {
              "id": "nvx40ri",
              "author": "inb4Collapse",
              "text": "Thanks a lot for giving us the comparison. Whatâ€™s your take on the suggested process here?",
              "score": 5,
              "created_utc": "2025-12-25 20:29:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvx4b5a",
                  "author": "Major_Specific_23",
                  "text": "What do you mean bro?",
                  "score": 10,
                  "created_utc": "2025-12-25 20:31:06",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvwl438",
          "author": "Major_Specific_23",
          "text": "To the people who wants to give the workflow a quick glance\n\nhttps://preview.redd.it/t1w7ofvw9e9g1.png?width=1572&format=png&auto=webp&s=1cf0b4ab4b6c712f2406c2b22e7a01af81b0cc01",
          "score": 36,
          "created_utc": "2025-12-25 18:36:56",
          "is_submitter": true,
          "replies": [
            {
              "id": "nw0sdsx",
              "author": "BeautyxArt",
              "text": "every shared wf must be fucking introduced as image like this , not a damn json shit file nor embed generated png....thank YOU",
              "score": 10,
              "created_utc": "2025-12-26 13:36:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvxxide",
          "author": "EquivocalDephimist",
          "text": "This more than doubled my RAM usage and made generations really slow on my 4070 12GB, 32GB RAM system (ended up using swap)",
          "score": 9,
          "created_utc": "2025-12-25 23:34:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvx4o7d",
          "author": "bhasi",
          "text": "Tested a bit, seems cool, but way too slow! Great effort tho!",
          "score": 8,
          "created_utc": "2025-12-25 20:33:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0xs3b",
          "author": "Roy_Elroy",
          "text": "You can try using ksampler advanced node, and set different start/ end step using different lora weight, I think that will get similar result\n\nhttps://preview.redd.it/kp2eyft93k9g1.png?width=845&format=png&auto=webp&s=0075f6c9eb62a861f85070f74ebefa346f55b210",
          "score": 3,
          "created_utc": "2025-12-26 14:12:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw2xdyn",
              "author": "Major_Specific_23",
              "text": "i tried this already. it gets complicated once you start adding variations. i dont think its flexible like a schedule lora node. i personally do not want to have 20 ksamplers",
              "score": 1,
              "created_utc": "2025-12-26 20:43:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvwxk9q",
          "author": "fabrizt22",
          "text": "hook lora nodes make everything very slow, I have a 5080",
          "score": 2,
          "created_utc": "2025-12-25 19:49:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvx3xoy",
              "author": "Major_Specific_23",
              "text": "Yeah. I wish we had access to the base already ðŸ˜­ \n\nPeople were complaining that they are unable to use their character loras properly along with my amateur photography lora. I just wanted to find a way to address this and this is the better solution after fighting with gpt and gemini for like 4 hours ðŸ˜‚",
              "score": 12,
              "created_utc": "2025-12-25 20:28:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvx4q1o",
          "author": "thebaker66",
          "text": "Awesome, I'd been playing with stacking lora's to get what I wanted and was noticing some conflict between them all and I figured some scheduling might be the way but hadn't looked into it yet as I'm still relatively a comfy noob",
          "score": 2,
          "created_utc": "2025-12-25 20:33:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvxd80i",
          "author": "Frydesk",
          "text": "Have you tried 2 character Loras?",
          "score": 2,
          "created_utc": "2025-12-25 21:26:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0ab3t",
          "author": "malcolmrey",
          "text": "This is really nice, thanks for sharing!",
          "score": 2,
          "created_utc": "2025-12-26 11:01:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw6h56p",
          "author": "ellipsesmrk",
          "text": "Major!!! Just want to say... i appreciate all of your hard work. Ive been using your 4 stage updated wf. Top notch dude!!! Dont stop posting.",
          "score": 2,
          "created_utc": "2025-12-27 12:11:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw7f0jo",
              "author": "Major_Specific_23",
              "text": "Thank you. I'm planning to post another gigantic workflow. Testing it at the moment ðŸ˜†",
              "score": 2,
              "created_utc": "2025-12-27 15:50:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvx06ti",
          "author": "jacf182",
          "text": "Iâ€™m trying to understand what youâ€™re supposed to input in that node.\n\nâ€œ2 : 0.8   # Steps 1-2: Get the style and compositionâ€\n\nWhat does the â€œ2:â€ mean?  The 0.8 is the weight?",
          "score": 1,
          "created_utc": "2025-12-25 20:05:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvx0zaz",
              "author": "Major_Specific_23",
              "text": "Steps : Weight\n\nSo if I'm running 9 steps total and I want to skip the first 4 steps, I'll use\n\n4 : 0.0\n2 : 0.8\n3 : 0.2\n\nIf I want to skip the last 4 steps, I'll use something like\n\n5 : 0.9\n4 : 0.0",
              "score": 3,
              "created_utc": "2025-12-25 20:10:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvzabal",
                  "author": "LightMaleficent5844",
                  "text": "Found that to be unintuitive. Expected:  \n4 : 0.5  \n6 : 0.25  \n8 : 0.0  \nto mean: \"at step 4, the weight will be 0.5, at step 6 the weight will be 0.25, at step 8 the weight will be 0.0",
                  "score": 3,
                  "created_utc": "2025-12-26 05:11:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvx1lns",
                  "author": "jacf182",
                  "text": "Got it now. Thanks!! Will give it a go when I get home.",
                  "score": 1,
                  "created_utc": "2025-12-25 20:14:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvytefs",
          "author": "NoMarzipan8994",
          "text": "Obviously working on the strength. I generally keep the styles around 0.5-0.6, but I must say that they have improved compared to those released in the early days, and I've now found many styles that no longer cause as many problems when combined with other LoRa's. If you see that the image is ruined, try lowering the strength by 10 at a time. If you really see that it doesn't work, change the style. Eventually, it's a style you'll only use if you don't use LoRa characters.",
          "score": 1,
          "created_utc": "2025-12-26 03:06:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3jo9g",
              "author": "Free_Scene_4790",
              "text": "LoRas trained with the \"de-Turbo\" version likely break the model less than those trained directly using the distilled version. At least that's what I've observed with the ones I've trained so far. (That, and the fact that I'm using Onetrainer with different parameters than Ai Toolkit.)",
              "score": 1,
              "created_utc": "2025-12-26 22:45:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw0zvqg",
          "author": "dirtybeagles",
          "text": "Thanks, I would like to try it but I am not sure how to install the node. when I try to git clone your URL, it says I do not have permission to install it from your repo.\n\n  \ngit@github.com: Permission denied (publickey).\n\nfatal: Could not read from remote repository.",
          "score": 1,
          "created_utc": "2025-12-26 14:25:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw1fsfd",
              "author": "dirtybeagles",
              "text": "I got it working. I followed this manual install. [https://docs.comfy.org/installation/install\\_custom\\_node#windows-portable](https://docs.comfy.org/installation/install_custom_node#windows-portable)  \nMake sure the root folder of the download zip is in your custom\\_nodes folder and not a folder within a folder.",
              "score": 2,
              "created_utc": "2025-12-26 15:58:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw4e4t5",
          "author": "AaronTuplin",
          "text": "My big issue was trying to run two character loras at the same time. They end up blending into a mashup of each other, and looking exactly the same as each other.",
          "score": 1,
          "created_utc": "2025-12-27 01:51:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw7esvr",
              "author": "Major_Specific_23",
              "text": "Oh you need an edit model or inpainting for this. I was experimenting with a regional lora node but slight prompt bleeding is inevitable unless someone comes up with a solution like how nano banana pro does it",
              "score": 1,
              "created_utc": "2025-12-27 15:49:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw6e1yf",
          "author": "CornmeisterNL",
          "text": "u/Major_Specific_23 thanks for sharing this! one question, how do I add a lora which requires a negative strenght value like -1.5 or something ?",
          "score": 1,
          "created_utc": "2025-12-27 11:43:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw7f673",
              "author": "Major_Specific_23",
              "text": "Good question. I'm not so sure if the code defaults to 0 or allows negative values. Let me check it and get back",
              "score": 2,
              "created_utc": "2025-12-27 15:50:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw8y6k6",
                  "author": "CornmeisterNL",
                  "text": "Tnx buddy",
                  "score": 1,
                  "created_utc": "2025-12-27 20:33:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw6h7ib",
          "author": "ellipsesmrk",
          "text": "How are you getting your images so GOOD?!",
          "score": 1,
          "created_utc": "2025-12-27 12:11:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw7joo2",
          "author": "FailSecure3519",
          "text": "It has one major issue. It does not produce accurate character the same way as only with the character lora by itself. It barely resembles it. When I switch to character lora only, it works as expected ( not this WF ).",
          "score": 1,
          "created_utc": "2025-12-27 16:13:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw80xc2",
              "author": "Major_Specific_23",
              "text": "You literally have full control of the schedule my bro. It's up to you to tweak them and get what you want",
              "score": 1,
              "created_utc": "2025-12-27 17:41:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw91idy",
          "author": "nasty84",
          "text": "i am getting this error: can you please help:\n\nPrompt outputs failed validation:  \nKSampler:  \n\\- Value not in list: scheduler: 'beta57' not in \\['simple', 'sgm\\_uniform', 'karras', 'exponential', 'ddim\\_uniform', 'beta', 'normal', 'linear\\_quadratic', 'kl\\_optimal'\\]",
          "score": 1,
          "created_utc": "2025-12-27 20:51:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwd4vu5",
          "author": "HareMayor",
          "text": "Whats the other **amap_14195000009000.safetensors** LoRa?",
          "score": 1,
          "created_utc": "2025-12-28 14:06:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvwmqr3",
          "author": "IshigamiSenku04",
          "text": "Will this run in 8gb vram 5060?",
          "score": 1,
          "created_utc": "2025-12-25 18:46:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvwmx9p",
              "author": "Major_Specific_23",
              "text": "yeah as long as you can run z-image, you can use this. it is the same as load lora node. but its slower. give it a try and see",
              "score": 7,
              "created_utc": "2025-12-25 18:47:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvx0vhj",
          "author": "nakabra",
          "text": "You're all training celebrity loras for ZIT, or is there some website hosting it?",
          "score": 1,
          "created_utc": "2025-12-25 20:09:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvx1u0x",
              "author": "Major_Specific_23",
              "text": "r/malcolmrey",
              "score": 4,
              "created_utc": "2025-12-25 20:15:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvx2koe",
                  "author": "nakabra",
                  "text": "ðŸ«±ðŸ«²\nðŸ¤",
                  "score": 3,
                  "created_utc": "2025-12-25 20:20:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw0ai25",
                  "author": "malcolmrey",
                  "text": "ðŸ’ªâ¤ï¸",
                  "score": 2,
                  "created_utc": "2025-12-26 11:03:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pyvw0q",
      "title": "Fal has open-sourced Flux2 dev Turbo.",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1pyvw0q/fal_has_opensourced_flux2_dev_turbo/",
      "author": "Budget_Stop9989",
      "created_utc": "2025-12-29 19:38:56",
      "score": 280,
      "num_comments": 114,
      "upvote_ratio": 0.97,
      "text": "https://preview.redd.it/kzd4n7gs37ag1.png?width=903&format=png&auto=webp&s=ab81e3133b7d4a0922d6ebfe03296eb87b30dbeb\n\n[fal/FLUX.2-dev-Turbo Â· Hugging Face](https://huggingface.co/fal/FLUX.2-dev-Turbo)\n\n",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pyvw0q/fal_has_opensourced_flux2_dev_turbo/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "nwlq6j1",
          "author": "jib_reddit",
          "text": "Sub second generation... is that on a B200 or something?",
          "score": 57,
          "created_utc": "2025-12-29 20:03:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm5si9",
              "author": "strigov",
              "text": "Especially when we mention that turbo LoRA itself weights 2.76 Gb... Yeah, it's possible))",
              "score": 8,
              "created_utc": "2025-12-29 21:20:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwllyhe",
          "author": "Budget_Stop9989",
          "text": "https://preview.redd.it/1k9qc2la57ag1.png?width=1622&format=png&auto=webp&s=077b5b27362da79096f8d8d927b259f863096481\n\nIt ranked 8th on Artificial Analysis, beating Nano Banana, and itâ€™s currently the highest-ranked open-source model.",
          "score": 91,
          "created_utc": "2025-12-29 19:43:32",
          "is_submitter": true,
          "replies": [
            {
              "id": "nwmr19g",
              "author": "Hoodfu",
              "text": "https://preview.redd.it/u512aman58ag1.jpeg?width=1360&format=pjpg&auto=webp&s=18842f870791b976b749b5e06cffff8248031dd9\n\nGiven that it's only 8 steps, it's also crazy good at text. I was expecting it to take a much bigger hit compared to the full model.  prompt: \\*\\*Text-to-Image Prompt:\\*\\*\n\nA 3:4 vertical conspiracy-style infographic poster with light tan paper texture background and subtle grain overlay. Bold black sans-serif typography throughout.\n\n\\*\\*TOP HEADLINE:\\*\\* Giant text reading \"BATMAN IS SECRETLY MARRIED TO A DUMPLING\" in heavy black sans-serif, slightly tilted for dramatic effect.\n\n\\*\\*NODE LAYOUT (Two columns, 6 nodes total):\\*\\*\n\n\\*\\*Node 1 (Top Left):\\*\\* Caption: \"BRUCE WAYNE HAS NEVER BEEN SEEN EATING DUMPLINGS IN PUBLIC\" â€” Flat vector cartoon of Batman looking nervously away from a steaming dim sum basket, sweating, thick outlines, exaggerated guilty expression.\n\n\\*\\*Node 2 (Top Right):\\*\\* Caption: \"THE BATCAVE SUSPICIOUSLY CONTAINS A KITCHEN\" â€” Simple icon of a wok next to bat-shaped cookware, muted sage green accents.\n\n\\*\\*Node 3 (Middle Left):\\*\\* Caption: \"GOTHAM CITY'S CHINATOWN CRIME RATE: MYSTERIOUSLY LOW\" â€” Cartoon of a happy dumpling with a tiny wedding ring, pink pastel background circle.\n\n\\*\\*Node 4 (Middle Right):\\*\\* Caption: \"ALFRED REFUSES TO COMMENT ON 'MRS. WAYNE'\" â€” Flat illustration of a butler figure with finger over lips, charcoal suit, suspicious eyebrow raised.\n\n\\*\\*Node 5 (Lower Left):\\*\\* Caption: \"BATMAN IS FAMOUSLY EMOTIONALLY UNAVAILABLE â€” EXCEPT TO CARBS\" â€” Cartoon Batman tenderly holding a plump dumpling under moonlight, heart icons.\n\n\\*\\*Node 6 (Lower Right):\\*\\* Caption: \"BOTH ARE SOFT ON THE INSIDE, TOUGH ON THE OUTSIDE\" â€” Split comparison icon of Batman cowl and steamed bun, red accent highlighting.\n\n\\*\\*ARROWS:\\*\\* Curved red arrows with hand-drawn aesthetic connecting nodes in illogical zigzag patterns, implying false causation.\n\n\\*\\*BOTTOM BANNER:\\*\\* Bold conclusion banner reading \"THE EVIDENCE IS IRREFUTABLE. WAKE UP, GOTHAM.\" in heavy black text on muted pink ribbon banner.\n\n\\*\\*Style:\\*\\* Flat vector cartoon illustrations, thick black outlines, slight paper grain texture, whimsical children's-book aesthetic with sinister undertones, deadpan comedic tone, pastel red/pink/sage/charcoal accent palette.",
              "score": 41,
              "created_utc": "2025-12-29 23:07:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwmy2iw",
                  "author": "FotografoVirtual",
                  "text": "But it's missing the 'Alfred refuses to comment on Mrs. Wayne' element. Is this LoRA worth it overall? Here's the **Z-Image** generation for comparison (seed=1):\n\nhttps://preview.redd.it/qj9m8e7cc8ag1.png?width=1600&format=png&auto=webp&s=eba150864ff9aa8d00976d97b500c623c21351e4",
                  "score": 15,
                  "created_utc": "2025-12-29 23:46:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwmtex7",
                  "author": "IrisColt",
                  "text": "I kneel",
                  "score": 3,
                  "created_utc": "2025-12-29 23:20:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwlms0i",
              "author": "_raydeStar",
              "text": "Whoah. Have you played with it? How fast is it?",
              "score": 10,
              "created_utc": "2025-12-29 19:47:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwlq2cg",
              "author": "Clear_University5148",
              "text": "Wait, why would it be better than the original flux2 dev if its a distillation?",
              "score": 9,
              "created_utc": "2025-12-29 20:03:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwm8lum",
                  "author": "PuppyGirlEfina",
                  "text": "Turbo models often have better alignment than their base models, which can result in them winning on many benchmarks.",
                  "score": 22,
                  "created_utc": "2025-12-29 21:34:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwm959v",
                  "author": "mcosta85xx",
                  "text": "When the creators of Z-Image state that the base model will have worse quality than the heavily distilled Z-Image-Turbo, then this sounds pretty much the same. \n\nIt depends on the definition of \"better\". It won't do everything better, but if it does the things better you are interested in...",
                  "score": 21,
                  "created_utc": "2025-12-29 21:36:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwmwm19",
                  "author": "ANR2ME",
                  "text": "Distilled usually faster with slightly quality difference, since it use less steps.",
                  "score": 1,
                  "created_utc": "2025-12-29 23:38:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwlqut5",
              "author": "krectus",
              "text": "Seeing as itâ€™s lower than Flux 2 flex and Flux 2 flex kinda sucks, so I dunno. A good option to have and Iâ€™m sure it does some things well but this leaderboard isnâ€™t too reliable.",
              "score": 9,
              "created_utc": "2025-12-29 20:07:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwmrnbk",
              "author": "tomakorea",
              "text": "How can it even beat the original flux 2 dev model while being faster ?",
              "score": 1,
              "created_utc": "2025-12-29 23:11:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwllahi",
          "author": "Structure-These",
          "text": "Does it do boobs",
          "score": 116,
          "created_utc": "2025-12-29 19:40:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwllocx",
              "author": "Regular-Forever5876",
              "text": "that's ma' boy",
              "score": 58,
              "created_utc": "2025-12-29 19:42:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwmlgz3",
              "author": "blahblahsnahdah",
              "text": "Appears so (softcore NSFW warning):\n\nhttps://files.catbox.moe/zcgrx0.png\n\n8 steps Euler, 42 seconds on 3090. I'm not a gooner so if you need any further testing you'll need to do it yourself. But yeah, looks like Fal trained it to do booba.",
              "score": 28,
              "created_utc": "2025-12-29 22:38:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwms8jr",
                  "author": "tomakorea",
                  "text": "42 seconds it's not fast but still an improvement I guess",
                  "score": 6,
                  "created_utc": "2025-12-29 23:14:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwp74ho",
                  "author": "zthrx",
                  "text": "Can you share the workflow? so you use 20gig models plus 3gig of lora on top?",
                  "score": 1,
                  "created_utc": "2025-12-30 08:34:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwpqa41",
                  "author": "Hot-Employ-3399",
                  "text": "This is officially great new year present ðŸ¥³",
                  "score": 1,
                  "created_utc": "2025-12-30 11:30:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwmr5cy",
                  "author": "FourtyMichaelMichael",
                  "text": "I thought it would be titties... and you posted mammories.",
                  "score": -4,
                  "created_utc": "2025-12-29 23:08:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwp35h1",
              "author": "JazzlikeLeave5530",
              "text": "Boobs are too easy, people really need to benchmark with dick, which many of the models struggle with unless you use a lora. Not enough cock lovers getting shit done lol semi jokingly but also for real",
              "score": 10,
              "created_utc": "2025-12-30 07:57:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwpid44",
                  "author": "TwistedBrother",
                  "text": "A penis, like a hand, is actually fantastically complex to render. Many different positions, shapes, transformations to consider relative to the stationary skull structure of a face.",
                  "score": 4,
                  "created_utc": "2025-12-30 10:19:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwlosac",
              "author": "Jackster22",
              "text": "WE ABOUT TO FIND OUT",
              "score": 14,
              "created_utc": "2025-12-29 19:57:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwlqcrb",
              "author": "Zenshinn",
              "text": "Asking the real questions.",
              "score": 13,
              "created_utc": "2025-12-29 20:04:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwmns7y",
                  "author": "this_is_a_long_nickn",
                  "text": "Itâ€™s good to see other man of culture gathered here",
                  "score": 3,
                  "created_utc": "2025-12-29 22:50:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwn302i",
              "author": "tppiel",
              "text": "![gif](giphy|SSF70KZ7zatmLLAYxV|downsized)",
              "score": 8,
              "created_utc": "2025-12-30 00:13:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwlnrhf",
          "author": "ArachnidDesperate877",
          "text": "so is this a lora or a distilled model??",
          "score": 11,
          "created_utc": "2025-12-29 19:52:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwlouuf",
              "author": "rendered_lunatic",
              "text": "lora",
              "score": 14,
              "created_utc": "2025-12-29 19:57:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwlq25j",
                  "author": "ArachnidDesperate877",
                  "text": "I don't get it, then why is it ranked 8th on Artificial Analysis???",
                  "score": 19,
                  "created_utc": "2025-12-29 20:03:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwmuvhg",
              "author": "Nextil",
              "text": "Distillation has multiple meanings. With LLMs it typically refers to lower-dimension models trained to mimic a larger one using a teacher-student loop, but with these diffusion models it's usually a LoRA/finetune trained to mimic the effects of CFG and higher step counts, and now it often involves an RL stage to increase preference alignment.\n\nI know FLUX.2 is huge, but I'd rather they keep doing the latter because smaller parameter counts do seem to significantly reduce prompt comprehension and don't necessarily improve the speed, whereas these 4/8-step LoRAs make inference very fast with very little impact on quality when done correctly.",
              "score": 3,
              "created_utc": "2025-12-29 23:28:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwms1it",
          "author": "Frosty-Aside-4616",
          "text": "Itâ€™s a lora so you still need a ton of Vram for the model itself right?",
          "score": 9,
          "created_utc": "2025-12-29 23:13:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwln3tn",
          "author": "HolidayEnjoyer32",
          "text": "24gb vram and 32gb ram enough to run flux 2 dev with this lora?",
          "score": 17,
          "created_utc": "2025-12-29 19:49:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwlo7cm",
              "author": "molbal",
              "text": "Yes, this does not change VRAM requirements",
              "score": 17,
              "created_utc": "2025-12-29 19:54:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwm1gmp",
              "author": "Valuable_Issue_",
              "text": "I can run FP8 on 10GB VRAM 32GB RAM and 54GB pagefile. I switched to Q4KM due to faster loading times and fewer issues with ComfyUI being slow with offloading/loading the text encoder (which somehow got even worse now, even a Z image workflow will randomly slow down).\n\nI ended up making a Diffusers backend for the text encoder based off this https://github.com/ariG23498/custom-inference-endpoint\n\nand running it separately from ComfyUI (still on same PC) and it is much faster at loading and encoding the prompt.\n\n> mistral-text-encoding-api - Loaded Mistral text encoder (6.53s) \n\n>dtype=torch.bfloat16 device=auto\n\n>mistral-text-encoding-api - Loaded tokenizer in 3.23s\n\n>2025-12-29 20:36:32,122 [INFO] mistral-text-encoding-api - \n\n>Warmed up in 28.42s \n\nComfyUI takes FOREVER to load the text encoder/encode prompt, I don't have the GGUF for it downloaded though so can't benchmark it again but here's an older comparison (this is just changing prompt, doesn't include load times which are even worse for comfy):\n\n>mistral-text-encoding-api - Encoded in 18670.10 ms\n\n>20/20 [5.77s/it]\n\n>Prompt executed in 179.45 seconds\n\nVS Normal workflow:\n\n>Prompt executed in 218.38 seconds\n\nAnd when Normal WF decides to offload weirdly:\n\n>Prompt executed in 313.18 seconds\n\nHere's Qwen Edit at Q8 with white image as reference 1024x1024.\n\n> 8/8 [00:55<00:00,  6.92s/it]\n\n> Prompt executed in 58.34 seconds\n\nFlux 2 at Q4KM follows prompts a lot better than Qwen edit at Q8 while being the same size on disk and each step actually taking around the same time, so I'd say it's worth trying over Qwen. Flux 2 Q8 actually takes around the same time per step it's just that the load time was very annoying.\n\nHere's Flux 2 Q4KM with no reference image 1024x1024 (this is ofc 16 steps vs 8 for qwen): \n\n> 16/16 [01:43<00:00,  6.44s/it]\n\n> Prompt executed in 104.61 seconds\n\nWith reference image and step distill lora (reference image slows down gen time a fair bit):\n\n> 8/8 [01:28<00:00, 11.02s/it]\n\n> Prompt executed in 90.54 seconds",
              "score": 14,
              "created_utc": "2025-12-29 20:59:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwm8l5d",
                  "author": "HolidayEnjoyer32",
                  "text": "i just tried flux 2 dev with the default workflow from comfyui (flux 2 dev fp8) and it will not run. just stops right after loading the model and nothing happens. comfyui logs crash.",
                  "score": 3,
                  "created_utc": "2025-12-29 21:34:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwm53tc",
          "author": "Hoodfu",
          "text": "https://preview.redd.it/6ubxjz52p7ag1.jpeg?width=1920&format=pjpg&auto=webp&s=e34f66026d02516051e33412e5cd23943123198d\n\nGood stuff. dpmpp\\_sde / beta / 8 steps / guidance 2.5 - 33 seconds (15 seconds if I use euler a) with flux 2 dev fp16 (90 gigs of vram used for TE and model). Great stuff. Let you iterate at a reasonable clip and then switch to full model for max quality. I tried with flux guidance 4, but then the text is less reliable, so 2.5 is best.",
          "score": 15,
          "created_utc": "2025-12-29 21:17:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwn9ewi",
              "author": "Wallye_Wonder",
              "text": "90gb of VRAM? now I have to buy a pro6000",
              "score": 6,
              "created_utc": "2025-12-30 00:47:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwm3kpy",
          "author": "DullDay6753",
          "text": "anyone got a workflow for this, just adding the lora in a standard flux2 workflow gives bad results",
          "score": 6,
          "created_utc": "2025-12-29 21:09:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm6bs6",
              "author": "Hoodfu",
              "text": "https://preview.redd.it/399rqpd7n7ag1.png?width=3048&format=png&auto=webp&s=144d377a3075290ca5f5b89fa90699f87b9b4dd1\n\nThis is working well for me.",
              "score": 10,
              "created_utc": "2025-12-29 21:23:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwow8dq",
                  "author": "Winter_unmuted",
                  "text": "Are you sure you aren't just seeing flux2dev with fewer steps? \n\nTry feeding all settings except model (without the lora) into another sampler. I did that... and the images were the same. The lora was failing to load because it isn't in the usual format or something.",
                  "score": 3,
                  "created_utc": "2025-12-30 06:55:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwnldcy",
                  "author": "Nextil",
                  "text": "This doesn't follow their recommendations. They use a guidance scale of 2.5 and custom sigmas (1.0, 0.6509, 0.4374, 0.2932, 0.1893, 0.1108, 0.0495, 0.00031).",
                  "score": 3,
                  "created_utc": "2025-12-30 01:54:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwmjte2",
                  "author": "_raydeStar",
                  "text": "Prompt?\n\nI resent that fact that the photo you generated is so fly, yet you did not share it.",
                  "score": 2,
                  "created_utc": "2025-12-29 22:29:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwmv80k",
                  "author": "Sudden_List_2693",
                  "text": "You should set guidance to 2.5.",
                  "score": 1,
                  "created_utc": "2025-12-29 23:30:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwn07tm",
          "author": "NebulaBetter",
          "text": "I got a bunch of \"lora key not loaded: transformer.double\\_stream\\_modulation\\_img.linear.lora\\_A.weight\" etc, etc... seems to not work for me, no idea why (I disabled it for now). I tried different lora loaders, etc.\n\nhttps://preview.redd.it/trxehvope8ag1.png?width=1753&format=png&auto=webp&s=65b3445a764e13802cada560b566e9a77df4e304",
          "score": 5,
          "created_utc": "2025-12-29 23:57:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnndpe",
              "author": "Wurzelrenner",
              "text": "same problem for me",
              "score": 3,
              "created_utc": "2025-12-30 02:05:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwow11p",
              "author": "Winter_unmuted",
              "text": "Yeah same for me. I think it's because it's in Fal's custom lora format. I even tried converting it with [this tool](https://github.com/cutecaption/FAL-converter-script-UI) but no dice. \n\nAt first I thought it was working but just giving garbage results.... but it turns out I was just seeing Flux2 dev with 4 steps. \n\nHopefully someone figures out how to load fal loras into comfyui. until then... shrug.",
              "score": 3,
              "created_utc": "2025-12-30 06:53:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwozqtx",
                  "author": "ByteZSzn",
                  "text": "[https://www.reddit.com/r/StableDiffusion/comments/1pzbrg1/flux2\\_turbo\\_lora\\_corrected\\_comfyui\\_lora\\_keys/](https://www.reddit.com/r/StableDiffusion/comments/1pzbrg1/flux2_turbo_lora_corrected_comfyui_lora_keys/) \n\ni did it here works now :)",
                  "score": 4,
                  "created_utc": "2025-12-30 07:26:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwq4k3m",
              "author": "sntrpc",
              "text": "try just adding this in the .bat file cl launch args Â¯\\\\\\_(ãƒ„)\\_/Â¯\n\n    --use-pytorch-cross-attention",
              "score": 1,
              "created_utc": "2025-12-30 13:16:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwls1v3",
          "author": "khronyk",
          "text": ">This model inherits the FLUX [dev] Non-Commercial License from the base model.",
          "score": 16,
          "created_utc": "2025-12-29 20:13:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwn1pkz",
          "author": "andy_potato",
          "text": "\"This model inherits theÂ [FLUX \\[dev\\] Non-Commercial License](https://huggingface.co/black-forest-labs/FLUX.2-dev/blob/main/LICENSE.txt)Â from the base model\"\n\nInstant skip.",
          "score": 13,
          "created_utc": "2025-12-30 00:06:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnok5f",
              "author": "Winter_unmuted",
              "text": "What are all you people selling with this stuff?\n\nI legitimately don't understand. Are you churning out AI slop internet ads or something?",
              "score": 9,
              "created_utc": "2025-12-30 02:11:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwnsqps",
                  "author": "Serprotease",
                  "text": "IMO, itâ€™s mostly about control and ownership. Â \n\nFor most users, itâ€™s fine. But if you do Lora it could be. If youâ€™re doing full fine tune (Rundiffusion, noobAi, etc.) or serve the model then itâ€™s a non starter.Â \n\nFor example, it went a bit unnoticed, but stabilityAI used their license rules to pull all models, Lora and fine tunes from Sd cascade to sd 3.5 from civitai.Â \n\nNon commercial licenses are mostly fine, until they arenâ€™t.Â \nThe EU could bring the hammer down and force Bfl to monitor their model usage closely for example and pick and choose where itâ€™s available (Not where nsfw Lora are available, for an obvious use case)\n\nIn my case, Iâ€™ll try this model, but I know that I better spend my time looking at Qwen models, Loraâ€™s, doc because I know I will not be rugged pull.Â ",
                  "score": 5,
                  "created_utc": "2025-12-30 02:34:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwmrxy2",
          "author": "Revolutionalredstone",
          "text": "Nice - but at this point were all just waiting for zimg base :D",
          "score": 12,
          "created_utc": "2025-12-29 23:12:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlrhru",
          "author": "Valtared",
          "text": "So it's a DMD Lora, what should be the workflow in ComfyUI ?",
          "score": 3,
          "created_utc": "2025-12-29 20:10:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm85fp",
              "author": "Hoodfu",
              "text": "[https://www.reddit.com/r/StableDiffusion/comments/1pyvw0q/comment/nwm6bs6/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/r/StableDiffusion/comments/1pyvw0q/comment/nwm6bs6/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",
              "score": 1,
              "created_utc": "2025-12-29 21:31:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwmsmdy",
          "author": "2legsRises",
          "text": "its the lora not a stand alone checkpoint?",
          "score": 3,
          "created_utc": "2025-12-29 23:16:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwnie26",
          "author": "anydezx",
          "text": "I did some quick tests and I really like this LoRa. It's well-trained and doesn't affect the text or the hands. I can't imagine how long it takes to train, and I'm very grateful to fal-ai. In my opinion, it's one of the best low-steps LoRas (please uses more steps) I've seen, and it gives a boost to this Flux2 Dev model, which many thought was dead. Apologies for not posting examples; I always test things with private projects and I don't have permission to publish them. My only issue's that, in the same amount of time, I can create two images with Qwen Image Edit 2509 or 2511 versus one image with Flux2 Dev under the same conditions, and Qwen Image Edit 2509 maintains better character consistency. 2511 isn't suitable for this. 2511's a disaster at maintaining realistic characters; they ruined it with so much LoRa, but it's better for other uses. Although Flux2 Dev's better for text, posters, anime, and advertisingâ€”and perhaps that's what you need!âœŒï¸",
          "score": 5,
          "created_utc": "2025-12-30 01:38:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwos9ol",
              "author": "Perfect-Campaign9551",
              "text": "Qwen has bad skin textures though",
              "score": 3,
              "created_utc": "2025-12-30 06:22:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwowhbe",
                  "author": "anydezx",
                  "text": "Both Qwen Image Edit 2509 and 2511 and Flux2 Dev're terrible at texturing skin. If you want realistic skin textures, you'll have to refine them afterward with another model; there're many options, so use whichever one you prefer. Even though Qwen Image Edit and Flux2 Dev're large models doesn't mean they can do everything. People don't understand that to achieve that kind of adherency responsiveness and multi-image editing, you have to overtrain something, and in both cases lose skin quality's sacrificed. That's where smaller models shine as refiners. Z Image Turbo's good for many tasks, but in my case, it's a model I don't even use, since for my projects with Qwen, SD XL, some Flux models, WAN 2.2, TTS, some music generators, etc... I use a wide variety of tools, that's more than enough for me. The key's for each user to take advantage of the strengths of each model and use what works best for their needs or projects!ðŸ‘Œ",
                  "score": 2,
                  "created_utc": "2025-12-30 06:57:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwnpvkd",
          "author": "Winter_unmuted",
          "text": "EDIT: new comparison with the Comfyui version of the LORA. Now it looks great! slightly more speed per iteration (6..93 s/it base, 6.58 s/it with LORA) plus the expected decrease of time from 8 steps instead of 20. \n\nhttps://preview.redd.it/7w64yac5qcag1.jpeg?width=2048&format=pjpg&auto=webp&s=d36cbf097ebc9a77c9ab93a4dc275277b8d39400\n\n63% faster! 2:18 for the 20 steps vs 0:52 with the Lora.",
          "score": 3,
          "created_utc": "2025-12-30 02:19:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwoi2pz",
          "author": "suresh_deora_seducer",
          "text": "Look at the size of the model ~64GB , when we have zit and qwen like SOTA models , Who cares.",
          "score": 6,
          "created_utc": "2025-12-30 05:05:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwm9iwd",
          "author": "VegetableRemarkable",
          "text": "Still sticking to ZIT",
          "score": 7,
          "created_utc": "2025-12-29 21:38:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwmjpef",
              "author": "blahblahsnahdah",
              "text": "So?",
              "score": 7,
              "created_utc": "2025-12-29 22:29:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwpxays",
              "author": "Lucas_02",
              "text": "Z-Image turbo with its muddy glossy visual artifacts will never reach the level of details of Flux 2 ðŸ˜‚",
              "score": 2,
              "created_utc": "2025-12-30 12:26:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwnp1l6",
              "author": "Sudden_List_2693",
              "text": "Didn't so far, now makes even less sense.  \nThe quality is like SD1.5 compared to ZIT.  \nWell maybe except for \"generate a realistic photo of a Taylor Swift rip-off\"",
              "score": 0,
              "created_utc": "2025-12-30 02:14:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwmr3q5",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2025-12-29 23:08:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwn5mjx",
          "author": "76vangel",
          "text": "Is this yet usable in Comfy? If yes, then how?",
          "score": 1,
          "created_utc": "2025-12-30 00:27:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nws4q6o",
              "author": "Nextil",
              "text": "https://huggingface.co/ByteZSzn/Flux.2-Turbo-ComfyUI/blob/main/Flux2TurboComfyv2.safetensors",
              "score": 1,
              "created_utc": "2025-12-30 19:14:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwng6pl",
          "author": "wh33t",
          "text": "Flux2 Kontext2 Turbo when?",
          "score": 1,
          "created_utc": "2025-12-30 01:25:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwodifn",
          "author": "Antique_Bit_1049",
          "text": "Great. Can't wait to see their training dataset.",
          "score": 1,
          "created_utc": "2025-12-30 04:35:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwoiuhy",
          "author": "yamfun",
          "text": "can this perform Edit ?",
          "score": 1,
          "created_utc": "2025-12-30 05:11:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nws1opv",
              "author": "Brave-Hold-9389",
              "text": "Yes",
              "score": 1,
              "created_utc": "2025-12-30 19:00:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwp8ghl",
          "author": "unarmedsandwich",
          "text": "How does it compare to 4 step pi-flux2?\nhttps://huggingface.co/Lakonik/pi-FLUX.2",
          "score": 1,
          "created_utc": "2025-12-30 08:47:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwql66z",
          "author": "AlexGSquadron",
          "text": "I am new to this, can anyone tell me how to use this in comfyui?",
          "score": 1,
          "created_utc": "2025-12-30 14:52:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwslyaj",
          "author": "dummyreddituser",
          "text": "I'm experimenting with turbo LoRA, but resulting image after upscaling has grainy appearance.\n\nMy basic workflow (real life workflow, not ComfyUi workflow):\n\nGenerated an image in 1280x720 using Flux2 Dev (gguf Q8\\_0) with turbo LoRA by FAL AI, and upscale it by 3x using SeedVR.\n\nIf I generate an image using Z-Image or Flux2 Dev (gguf Q8\\_0, but without LoRA) with same resolution and SeedVR settings, results are very good.\n\nI tried changing prompt guidance and model sampling (ModelAuraFlow node, if I remember right) but up to now, no way to elliminate this effect completely.\n\nIt seems like all images generated by this LoRA are grainy, and this effect will be amplified by SeedVR.\n\nI like the results of this LoRA, but with this problem, this is only useful to preview things before generating them in Flux 2 Dev full model.\n\n  \nIs it only me?",
          "score": 1,
          "created_utc": "2025-12-30 20:37:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpe9rb",
          "author": "Kooky-Menu-2680",
          "text": "Thanx to Z image ðŸ¤£ðŸ¤£",
          "score": 1,
          "created_utc": "2025-12-30 09:41:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlsyzu",
          "author": "Anxious-Program-1940",
          "text": "![gif](giphy|BWPQlW8R5Muuk)",
          "score": -9,
          "created_utc": "2025-12-29 20:17:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwls2af",
          "author": "Fantastic_Tip3782",
          "text": "Wow it still looks like shit even in open-source mode!",
          "score": -14,
          "created_utc": "2025-12-29 20:13:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwlw17p",
              "author": "anybunnywww",
              "text": "Is there a training code for the adapter and the config? Otherwise, the X post is misleading because there is no open source here. The old tianweiy/dmd2 repo has no up-to-date flux dev support.",
              "score": 2,
              "created_utc": "2025-12-29 20:32:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwlxts8",
                  "author": "Fantastic_Tip3782",
                  "text": "I don't know or care, Flux sucks ass and I'm only here to make that joke",
                  "score": -17,
                  "created_utc": "2025-12-29 20:41:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwlx0vw",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -1,
          "created_utc": "2025-12-29 20:37:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm4q91",
              "author": "LumbarJam",
              "text": "https://preview.redd.it/erh5o58el7ag1.png?width=1665&format=png&auto=webp&s=cbee5509cbbd156ffc4c391ea2294e874cb82967\n\nNo rocket science ... just Flux.2 Dev on the standard workflow, with LORA node.",
              "score": 2,
              "created_utc": "2025-12-29 21:15:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwm96mw",
                  "author": "HolidayEnjoyer32",
                  "text": "just tried the default flux2 dev comfyui workflow and it just doesn't work. model loaded, then nothing happens. so annoying.",
                  "score": 2,
                  "created_utc": "2025-12-29 21:36:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwlnwlu",
          "author": "Verittan",
          "text": "The only thing I hear about Flux is Flux chin and plastic skin. Is this an issue with dev Turbo or has it been fixed?",
          "score": -6,
          "created_utc": "2025-12-29 19:52:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwltxtf",
              "author": "Dezordan",
              "text": "Flux 2 still kind of has a plastic skin, but better than Flux 1 Dev (not sure about Krea version). You are better off using LoRAs with it anyway. As for chin, they fixed it as far as I can see.",
              "score": 2,
              "created_utc": "2025-12-29 20:22:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwlp5ya",
              "author": "lordpuddingcup",
              "text": "That was flux 1 flux 2 is better I think",
              "score": 3,
              "created_utc": "2025-12-29 19:59:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwp19ks",
          "author": "Xamanthas",
          "text": "Open-weights* and adapter not a full on its own model. Open sourced would be data and training code",
          "score": -1,
          "created_utc": "2025-12-30 07:40:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pxp309",
      "title": "WAN2.1 SCAIL pose transfer test",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/k095n4prix9g1",
      "author": "Aneel-Ramanath",
      "created_utc": "2025-12-28 11:20:59",
      "score": 273,
      "num_comments": 54,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Animation - Video",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pxp309/wan21_scail_pose_transfer_test/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwddzn2",
          "author": "DeliciousGorilla",
          "text": "![gif](giphy|14kqI3Y4urS3rG)\n\nThese dancing videos remind me of the OG CG baby.",
          "score": 45,
          "created_utc": "2025-12-28 15:01:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nweerpu",
              "author": "Dzugavili",
              "text": "Someone needs to go full circle and use this as a WAN driving video.",
              "score": 12,
              "created_utc": "2025-12-28 18:07:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwg8e8c",
                  "author": "Zenshinn",
                  "text": "https://i.redd.it/lkm1umox41ag1.gif",
                  "score": 17,
                  "created_utc": "2025-12-28 23:30:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwd5fs2",
          "author": "andy_potato",
          "text": "For me 600 frames at 576p take about 30 minutes on a 4090",
          "score": 12,
          "created_utc": "2025-12-28 14:10:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwf3plg",
              "author": "RepresentativeRude63",
              "text": "16fps or 24 fps? If 16, classic 1 min for every second video. My best results are like that too. Wish I found a way to 1 min for every 5-10 seconds than I would go all the way to opensource",
              "score": 2,
              "created_utc": "2025-12-28 20:05:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwgef2e",
                  "author": "andy_potato",
                  "text": "the FPS have no impact on the rendering time. That's just how you encode your video at the end. The important point is the number of frames (600).",
                  "score": 2,
                  "created_utc": "2025-12-29 00:02:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwifs0a",
              "author": "donkeykong917",
              "text": "How did you get it to 600 frames?\n\nMax I can is around 410 frames. \n\nLet me check my resolution.",
              "score": 1,
              "created_utc": "2025-12-29 08:01:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwik2jm",
                  "author": "andy_potato",
                  "text": "I donâ€™t think there is a frame limit, you just need enough frames to drive the motion.\n\nMy original video is 40 seconds at 30fps means a total of 1,200 frames. I skip every other frame resulting in 600 frames actually rendered by SCAIL. Finally I interpolate the video back to 30fps and upscale it from 576p to 720p. Works without problems, just the whole process is much slower than SteadyDancer. Quality is on another level though",
                  "score": 2,
                  "created_utc": "2025-12-29 08:41:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwjr3wb",
              "author": "music2169",
              "text": "Without using context windows or with it?",
              "score": 1,
              "created_utc": "2025-12-29 14:21:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwjrftg",
                  "author": "andy_potato",
                  "text": "Using a context window of 12 or so. Didnâ€™t change the default settings of the Kijai workflow here",
                  "score": 1,
                  "created_utc": "2025-12-29 14:23:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwdfjco",
              "author": "FightingBlaze77",
              "text": "How long would you think it would take on a 4070?",
              "score": 1,
              "created_utc": "2025-12-28 15:10:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwgeqqp",
                  "author": "andy_potato",
                  "text": "At least double the time. Depends on whether your 4070 is a 12 or 16 GB variant. I guess SCAIL won't run on 12 GB only, at least not without using a lower quality model.",
                  "score": 3,
                  "created_utc": "2025-12-29 00:04:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwetpl6",
                  "author": "Sagonator",
                  "text": "I mean, the 4070 is around 50% slower so, an hour? Dunno if vram is a part of the equation though.",
                  "score": 2,
                  "created_utc": "2025-12-28 19:17:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nweaq74",
          "author": "Hearcharted",
          "text": "![gif](giphy|eKNrUbDJuFuaQ1A37p)",
          "score": 4,
          "created_utc": "2025-12-28 17:48:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwgqi8m",
              "author": "FetusExplosion",
              "text": "Now let's see Paul Allen's WAN2.1 SCAIL pose transfer test.",
              "score": 4,
              "created_utc": "2025-12-29 01:07:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwdoglh",
          "author": "Exotic_Youth_4696",
          "text": "Can I have that dancing video?",
          "score": 3,
          "created_utc": "2025-12-28 15:57:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwdosgj",
              "author": "Exotic_Youth_4696",
              "text": "found it, Thanks [https://www.youtube.com/shorts/oPQuVb1tahE](https://www.youtube.com/shorts/oPQuVb1tahE)",
              "score": 4,
              "created_utc": "2025-12-28 15:59:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwct0k8",
          "author": "Itchy_Ambassador_515",
          "text": "looks phenominal! which GPU and time it took",
          "score": 8,
          "created_utc": "2025-12-28 12:44:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwh4hdx",
              "author": "Aneel-Ramanath",
              "text": "5090, render time is 1hr:10mins at 512x896 res, about 800 frames",
              "score": 3,
              "created_utc": "2025-12-29 02:27:21",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwdx9ts",
              "author": "Mountain-One-811",
              "text": "they should delete posts without this information, just spam at this point",
              "score": 3,
              "created_utc": "2025-12-28 16:41:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwh4lk4",
                  "author": "Aneel-Ramanath",
                  "text": "chill dude, have some chilled lemon tea to cool your brains.",
                  "score": 2,
                  "created_utc": "2025-12-29 02:28:02",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwfhmk2",
          "author": "Zenshinn",
          "text": "I've been testing it and it has a bunch of issues. Face consistency is the biggest one. Sometimes the background will morph for no reason. And then from time to time limbs will disappear/reappear in a different position.\n\nHopefully the release version will fix these issues.",
          "score": 2,
          "created_utc": "2025-12-28 21:13:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwflqsj",
              "author": "donkeykong917",
              "text": "Face and hands is an issue for sure especially if it isn't in close view but movement wise it's spot on. If it detects more people in open pose it can try to fill itself. \n\nMy solution to faces is put a mask on like so\n\nhttps://youtube.com/shorts/sWzrl5ROwbk?si=NRS8ZOwQVmMqix5c",
              "score": 2,
              "created_utc": "2025-12-28 21:33:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwg8mq2",
                  "author": "Segaiai",
                  "text": "Just to make sure I understand, but are you basically saying to avoid the face issues, one should put a bag over their head? Or do you mean \"mask\" as a technical term?",
                  "score": 2,
                  "created_utc": "2025-12-28 23:31:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwgxhtd",
                  "author": "andy_potato",
                  "text": "You donâ€™t have to mask or brownbag the faces. Just donâ€™t include them in your DWPose output. The Kijai workflow has a switch for that",
                  "score": 1,
                  "created_utc": "2025-12-29 01:47:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwdf33w",
          "author": "sukebe7",
          "text": "Black Panthers promotional video?",
          "score": 1,
          "created_utc": "2025-12-28 15:07:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwg2m6c",
          "author": "IrisColt",
          "text": "It looks like the same panther head was blatantly photoshopped into the image three times.",
          "score": 1,
          "created_utc": "2025-12-28 22:59:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkrx0d",
          "author": "Neighborhood-Brief",
          "text": "Does anyone know what can cause unwanted camera moves that are not in the motion clip?  \nIve been playing with this in the last couple of days and often when I push the resolution a to 1280x736 I get strong camera dolly/push-in's.  \nI even have a separate clip with still camera just playing a checker board still frame for the duration and feeding in through Uni3C.  \nStill I get the move. I think its from some resolution mismatch maybe as when I go down to the regular max res the camera move is not there.  Any ideas what could make it happen like that?",
          "score": 1,
          "created_utc": "2025-12-29 17:23:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwto500",
          "author": "M_4342",
          "text": "will this work with 5060 ti 16gb for short clips, 5 sec ? and what times can i expect.\n\n  \nCan some also share a tutorial or where I can try this ? thanks",
          "score": 1,
          "created_utc": "2025-12-30 23:48:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwue62y",
              "author": "Aneel-Ramanath",
              "text": "I've not tried these on a 5060, so I cannot answer that question, these GPU's do not scale linearly, so it's difficult to predict, it all depends on the resolution and frame range, but yeah, you should be able to run them with the fp8 model. just search for WAN2.1 SCAIL on YT, you will get loads of tutorials.",
              "score": 1,
              "created_utc": "2025-12-31 02:14:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nweehzx",
          "author": "One-Employment3759",
          "text": "Why are they wearing heels.\n\n\nDid you prompt it, or is just because of if too many bops in training data?",
          "score": 1,
          "created_utc": "2025-12-28 18:06:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwguax7",
              "author": "CapsAdmin",
              "text": "I think it's an asian male celebrity thing.",
              "score": 1,
              "created_utc": "2025-12-29 01:28:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwh566u",
              "author": "Aneel-Ramanath",
              "text": "the SACIL model only animated, it does not create the images, the reference image is created in Nano Banana, maybe the word fashion has added those heels to them , not sure.",
              "score": 1,
              "created_utc": "2025-12-29 02:31:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1puiyri",
      "title": "Z image/omini-base/edit is coming soon",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1puiyri/z_imageominibaseedit_is_coming_soon/",
      "author": "sunshinecheung",
      "created_utc": "2025-12-24 08:59:19",
      "score": 266,
      "num_comments": 140,
      "upvote_ratio": 0.94,
      "text": "Z-image's model card has just been updated!\n\nhttps://preview.redd.it/vdu8xgao949g1.png?width=1482&format=png&auto=webp&s=745452212e492ce7741ef7f0c88612b233c36f39\n\nhttps://preview.redd.it/02pnj3wo949g1.png?width=2302&format=png&auto=webp&s=84dc9853c482c8f96f0d5a7a8955d669e2e9f637\n\nBased on this chart, Z-image Turbo has the best quality.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1puiyri/z_imageominibaseedit_is_coming_soon/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "nvovkuo",
          "author": "Druck_Triver",
          "text": "Visual quality bad?Â ",
          "score": 99,
          "created_utc": "2025-12-24 09:02:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvptxqg",
              "author": "uikbj",
              "text": "they have changed it to medium. lol\n\nhttps://preview.redd.it/27if9xalq59g1.jpeg?width=1682&format=pjpg&auto=webp&s=b1c524dbf6c8b77c5a7c8efe299e628414abd1dc",
              "score": 40,
              "created_utc": "2025-12-24 13:54:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvq03o7",
                  "author": "WalkTerrible3399",
                  "text": "Noo, I like the honesty of a scientist. Now it feels corporatey ðŸ˜ž",
                  "score": 50,
                  "created_utc": "2025-12-24 14:32:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvq5bkt",
                  "author": "Mr_Compyuterhead",
                  "text": "Grade inflation is out of control smh",
                  "score": 15,
                  "created_utc": "2025-12-24 15:02:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvq42uc",
                  "author": "FaceDeer",
                  "text": "Heh. It's the same, they just shifted *everything* up a notch. Like how condom sizes start at \"large\" and go up from there.",
                  "score": 27,
                  "created_utc": "2025-12-24 14:55:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvp13i7",
              "author": "muerrilla",
              "text": "That made me chuckle. They didn't need to be THAT honest about it!",
              "score": 56,
              "created_utc": "2025-12-24 09:57:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvqestc",
                  "author": "martinerous",
                  "text": "If they had a good Western marketing team, the quality column would be like: Super, SuperPlus, UltraSuperPlus :)",
                  "score": 24,
                  "created_utc": "2025-12-24 15:54:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvpw10t",
                  "author": "Hunting-Succcubus",
                  "text": "Hehe china good usa bad in this type of information.",
                  "score": 5,
                  "created_utc": "2025-12-24 14:07:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvphz7b",
              "author": "AltruisticList6000",
              "text": "It seems like a similar case to Chroma where base model has worse hands and details but it is good for finetuning and training (even random test loras I made usually improve results) while the distilled chroma Flash Heun loras make it have better hands and super clear high quality details and it is a lot faster too. Except people freaked out at the base model and have no idea about the later released flash heun loras that make it better. So I guess z-image team was smart to start with turbo to not freak people out.",
              "score": 22,
              "created_utc": "2025-12-24 12:32:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvt9aaf",
                  "author": "Baddabgames",
                  "text": "Wait. Can you explain or link these Lora that improve chroma results? Iâ€™m using chroma hd and only get about 4% decent gens.",
                  "score": 0,
                  "created_utc": "2025-12-25 02:22:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvpalqb",
              "author": "DBacon1052",
              "text": "I think the idea is that when you pack too much finishing detail into a base model, you make it harder to finetune. The base shouldnâ€™t feel like a finished product. It should get the fundamentals right like composition, proportion, and anatomy, and leave the rest open so the community can train it into a bunch of different models with their own unique feel. Thatâ€™s why SD 1.5 and SDXL are still the goats. Their base models are awful looking, but you can fine tune them into whatever you want.",
              "score": 49,
              "created_utc": "2025-12-24 11:29:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvpl7lr",
                  "author": "Aggressive_Sleep9942",
                  "text": "This is explained by the geometry of the loss function. Models that converge to sharp minima have high curvature and generalize poorly, making them difficult to adapt to new tasks (overfitting). In contrast, convergence to a flat minimum means the model is more robust to perturbations in the weights. This makes it a better generalist, facilitating the fine-tuning necessary for new tasks.",
                  "score": 20,
                  "created_utc": "2025-12-24 12:56:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvpewky",
                  "author": "ThiagoAkhe",
                  "text": "Looking at the training pipeline diagram again, it makes a lot of sense",
                  "score": 10,
                  "created_utc": "2025-12-24 12:06:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvr7g5e",
                  "author": "Apprehensive_Sky892",
                  "text": "Yes, that is spot on.\n\nThat is also the reason why base Qwen produces vanilla/plain images. People kept complaining about this, but a plain base makes training easier, as documented by the Flux-Krea people: [https://www.reddit.com/r/StableDiffusion/comments/1p70786/comment/nqy8sgr/](https://www.reddit.com/r/StableDiffusion/comments/1p70786/comment/nqy8sgr/)",
                  "score": 2,
                  "created_utc": "2025-12-24 18:28:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvovu8t",
              "author": "AwesomeAkash47",
              "text": "And turbo has the best quality out of these 4?",
              "score": 9,
              "created_utc": "2025-12-24 09:04:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvpam31",
                  "author": "Sharlinator",
                  "text": "Itâ€™s a balance between quality and finetunability, as should be expected. You shouldnâ€™t expect much from a base model without further training.",
                  "score": 22,
                  "created_utc": "2025-12-24 11:29:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvowaj2",
                  "author": "Agile-Role-1042",
                  "text": "I think its because Turbo doesn't allow for CFG and that it is a distilled model, and since other models use CFG, visual quality takes a slight hit. I could be wrong.",
                  "score": 9,
                  "created_utc": "2025-12-24 09:09:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvpewc6",
              "author": "Salty_Mention",
              "text": "It has always been said that the base/omni versions were primarily designed for fine-tuning. So obviously they won't be ultra-polished models like Turbo since it will be up to the community to do this work based on the desired outcome. Think of it as a raw sensor image, and what we want to do with it using editing software such as Lightroom.",
              "score": 6,
              "created_utc": "2025-12-24 12:06:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvtmivu",
              "author": "akza07",
              "text": "Non distilled. So we will have to play with CFG & Neg prompts a lot.",
              "score": 1,
              "created_utc": "2025-12-25 04:04:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvp9den",
          "author": "xhox2ye",
          "text": "diffusers have been updated.  \n[https://github.com/huggingface/diffusers/commit/f6b6a7181eb44f0120b29cd897c129275f366c2a](https://github.com/huggingface/diffusers/commit/f6b6a7181eb44f0120b29cd897c129275f366c2a)",
          "score": 50,
          "created_utc": "2025-12-24 11:17:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvpb30z",
              "author": "ChickyGolfy",
              "text": "Damn, I had to read every junk message to get to the very last comment, which is the most relevant ðŸ¤£.",
              "score": 15,
              "created_utc": "2025-12-24 11:33:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvpzc4y",
              "author": "Hunting-Succcubus",
              "text": "My crackers are about to blow after this diffuse.",
              "score": 5,
              "created_utc": "2025-12-24 14:27:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvovriz",
          "author": "l0ngjohnson",
          "text": "Soon (c)",
          "score": 72,
          "created_utc": "2025-12-24 09:03:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvow080",
              "author": "l0ngjohnson",
              "text": "https://i.redd.it/0gjvghx6b49g1.gif",
              "score": 115,
              "created_utc": "2025-12-24 09:06:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvoy0a1",
                  "author": "Spamuelow",
                  "text": "Im gonna save this and add the crash. But only show it after 3 hours",
                  "score": 24,
                  "created_utc": "2025-12-24 09:26:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvoxkzi",
                  "author": "mk8933",
                  "text": "Reminds me of the Epstein files lol",
                  "score": 11,
                  "created_utc": "2025-12-24 09:22:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvp2wtz",
              "author": "Baphaddon",
              "text": "Z Image 2512 (Released March, 2026)",
              "score": 10,
              "created_utc": "2025-12-24 10:15:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvq6wne",
                  "author": "Wallye_Wonder",
                  "text": "yeah, that makes sense, Chinese new year is around the end of Feb.",
                  "score": 3,
                  "created_utc": "2025-12-24 15:11:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvp4af3",
                  "author": "l0ngjohnson",
                  "text": "ðŸ¤£",
                  "score": 1,
                  "created_utc": "2025-12-24 10:28:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvpz8yn",
                  "author": "Hunting-Succcubus",
                  "text": "Released????????",
                  "score": 1,
                  "created_utc": "2025-12-24 14:27:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvoytlz",
          "author": "Life_Yesterday_5529",
          "text": "Ok, then now I demand a Z-Image Edit Turbo",
          "score": 66,
          "created_utc": "2025-12-24 09:34:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvpvbg0",
              "author": "jd3k",
              "text": "We are not in the position of demanding anything, we receive, we thank...",
              "score": 38,
              "created_utc": "2025-12-24 14:03:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvp9x46",
              "author": "mk8933",
              "text": "We will probably get a 8 step turbo lora for it....hopefully.",
              "score": 10,
              "created_utc": "2025-12-24 11:22:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvp0fdl",
          "author": "zedatkinszed",
          "text": "Is this the first instance of z-image (on its own) being mentioned again as a seperate thing since Omni came on the horizon?",
          "score": 16,
          "created_utc": "2025-12-24 09:50:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvpktfb",
          "author": "reyzapper",
          "text": "https://preview.redd.it/t5ocy6xgf59g1.png?width=861&format=png&auto=webp&s=78cb36a5eee769da3194272dec8c20402db448ec\n\nThey updated the model zoo?\n\nnow base is Medium quality, and others are High quality\n\n[https://github.com/Tongyi-MAI/Z-Image](https://github.com/Tongyi-MAI/Z-Image)\n\n\\--\n\nOP did you edit the page through browser's dev tool or what?? (i saw the caret there beside \"bad\") ðŸ˜…\n\nor the dev just recently updated the page??",
          "score": 13,
          "created_utc": "2025-12-24 12:53:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvplyhl",
              "author": "Dezordan",
              "text": "That they did\n\nhttps://preview.redd.it/nowjefuch59g1.png?width=1685&format=png&auto=webp&s=e6a857ab0fd48e5b0c066f4606b116c03865aeb9\n\nBut the meaning is technically the same. They probably didn't want the \"bad\" label on their model.",
              "score": 25,
              "created_utc": "2025-12-24 13:02:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvpm47w",
                  "author": "reyzapper",
                  "text": "Thx that clears it up",
                  "score": 4,
                  "created_utc": "2025-12-24 13:03:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvoywnn",
          "author": "beti88",
          "text": "Its been \"soon\" for weeks",
          "score": 40,
          "created_utc": "2025-12-24 09:35:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvw2x7m",
              "author": "Jealous_Piece_1703",
              "text": "Soon means somewhere between the weekend and next decade.",
              "score": 2,
              "created_utc": "2025-12-25 16:49:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvp4l30",
          "author": "Time-Teaching1926",
          "text": "Soon could mean sometime earlyish in 2026",
          "score": 10,
          "created_utc": "2025-12-24 10:31:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvppvcl",
              "author": "uikbj",
              "text": "yeah, maybe right before Chinese New Year which is feb 17, 2026ðŸ˜­",
              "score": 8,
              "created_utc": "2025-12-24 13:28:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvpfha0",
              "author": "LeftConfusion5107",
              "text": "Christmas",
              "score": 1,
              "created_utc": "2025-12-24 12:11:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvw2vbc",
              "author": "Jealous_Piece_1703",
              "text": "Soon means somewhere between the weekend and the next decade",
              "score": 1,
              "created_utc": "2025-12-25 16:49:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvphm9d",
          "author": "AltruisticList6000",
          "text": "Visual quality \"bad/medium\"? Sounds like Chroma where base model has worse details and hands + slow but good for training and finetuning while its flash lora has way better hands and way clearer high quality visuals while being faster.",
          "score": 9,
          "created_utc": "2025-12-24 12:29:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvr8885",
              "author": "Panagopuloscraft",
              "text": "Could you elaborate on the finetuning like what does it mean?",
              "score": 0,
              "created_utc": "2025-12-24 18:32:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvsc9nh",
                  "author": "SomaCreuz",
                  "text": "Fine tuning means veering a model towards a certain direction. Base models meant for fine tuning have a vast array of knowledge and compositions, but they don't do anything particularly well in order to avoid biases. Fine tuned models take a base model and apply specialized training to do some specific compositions more efficiently to the detriment of the others.",
                  "score": 2,
                  "created_utc": "2025-12-24 22:26:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvptmrd",
          "author": "uikbj",
          "text": "I just went to their git hub page. they've changed the visual quality rank, haha. turbo is now very high. standard Z-Image is High, edit is high, and omini is medium. they even add a diversity rank. omni is high, standard and edit is medium. turbo is low, lol. so base model should have high diversity, that is absolutely good news!\n\nhttps://preview.redd.it/yk76vfp9q59g1.jpeg?width=1682&format=pjpg&auto=webp&s=e65c1b5a94b4870dff199c9507eb14c708a9e623",
          "score": 11,
          "created_utc": "2025-12-24 13:52:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvp6jij",
          "author": "Pretend-Park6473",
          "text": "Visual quality: BadÂ ðŸ˜­",
          "score": 20,
          "created_utc": "2025-12-24 10:50:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvqohd7",
          "author": "Calm_Mix_3776",
          "text": "Waiting for the Base model, no matter what anybody says about quality. I can tolerate more steps and the longer wait times to get good quality results from it. I dislike distilled/turbo/flash/lightning models. They often produced very \"clean\" outputs that lack rich compositions, texture, and the grit that non-distilled models have. They often have this overly sanitized, AI plastic feel to them. I've also noticed that tile controlnets produce worse results with accelerated models.",
          "score": 6,
          "created_utc": "2025-12-24 16:45:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvs8ngu",
              "author": "HardenMuhPants",
              "text": "Turbo looks like airbrushed model photoshoots. Excellent model but everything looks slightly fake cgi with too much perfection.",
              "score": 2,
              "created_utc": "2025-12-24 22:03:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvpc1d0",
          "author": "razortapes",
          "text": "But would it be possible to create a LoRA using the base model and then use it with the current Turbo model? Right now you can create a LoRA with the Turbo model using the training adapter, but you canâ€™t use more than one LoRA at the same time. Maybe LoRAs trained on the base model would be more compatible.",
          "score": 4,
          "created_utc": "2025-12-24 11:42:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvpqdtw",
              "author": "uikbj",
              "text": "every sdxl lora trained on sdxl base can be used on any sdxl finetune, even on pony or illustrious though the result may vary. I believe it is the same case for Z Image too",
              "score": 9,
              "created_utc": "2025-12-24 13:31:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvqbe8g",
              "author": "thefool00",
              "text": "My experience with other models has been when I train on the base, my loras work better on all downstream models, even Lightning models. They work even better than when I train on the downstream model itself, not sure why ðŸ¤·",
              "score": 5,
              "created_utc": "2025-12-24 15:36:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvoyzuc",
          "author": "Keyboard_Everything",
          "text": "50 step ...",
          "score": 9,
          "created_utc": "2025-12-24 09:36:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvp5dw3",
              "author": "Ancient-Future6335",
              "text": "LoL, SDXL also 50 steps, but you use 20",
              "score": 26,
              "created_utc": "2025-12-24 10:39:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvp4bzl",
              "author": "Zealousideal7801",
              "text": "It's fine though it think for Qwen image it was supposed to be 40 steps, and with lightning mostly you're doing 4 steps",
              "score": 5,
              "created_utc": "2025-12-24 10:29:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvpcos0",
              "author": "zedatkinszed",
              "text": "Use dpm2sde or any other double-step sampler and scheduler and that'll cut it to 30.\n\n\nPersonally I still use sdxl at 40 steps",
              "score": 6,
              "created_utc": "2025-12-24 11:47:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvp2unb",
              "author": "jadhavsaurabh",
              "text": "True why 50",
              "score": -5,
              "created_utc": "2025-12-24 10:14:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvpsh4a",
          "author": "uikbj",
          "text": "wow, two base model, that is a nice surprise. the Z-Image without suffix is the most balanced one, it can generate \"medium\" quality image while flexible enough for training. I think this is the one I'm going for. hope it will come out before new year. finger crossed.",
          "score": 2,
          "created_utc": "2025-12-24 13:45:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvq3gzg",
          "author": "ImpossibleAd436",
          "text": "I have a couple of questions.\n\nSo the base model gets released, then:\n\n1. When we train our LoRas using the base model, will the training be as efficient / quick as it currently is using AI-Toolkit's current parameters & the Turbo model?\n2. When we train our LoRas using the base model, they will no longer cause problems when used with Turbo models? I.e. we can use multiple LoRas with Turbo models as long as they were trained on base?\n3. When people finetune the base model, they are likely to then convert it to a Turbo model and this is expected to work well? I.e. most Z-Image finetunes being released as Turbo models?\n\nBecause for me, and probably a lot of people, using the base model for generation will not be realistic, I expect it will be more resource intensive (file size & VRAM usage) and slower (30+ steps not 8).\n\nSo the way I see it, ideally the Z-Image space - for generating - will primarily be using Turbo models, even after the release of the base model.\n\nDo I have these things right?",
          "score": 2,
          "created_utc": "2025-12-24 14:51:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvq5z1e",
              "author": "Dezordan",
              "text": "1. Unless you train it as an edit model, which can slow it down since you'd use 2 images, there is virtually no difference. All models are 6B models (as per their [paper](https://www.arxiv.org/abs/2511.22699)) and Turbo was just finetuned and then distilled. If anything, training with a non-distilled model should be better for both LoRA quality and quicker learning of concepts. There also wouldn't be a need to merge the adapter with it.\n2. That people hope for and most likely that would be the case, unless there is some issue with the model. The problem could be that LoRAs aren't fully compatible with that Turbo model, though they are technically still can be similar enough.\n3. Or you just would use LoRA that would make any model to generate with a few steps, like people did it for other models. I really don't see the point in creating other Turbo models, they would only take up space.\n\n>Â I expect it will be more resource intensive (file size & VRAM usage)\n\nThat's unlikely, as I said above - they all are 6B models. But\n\n>and slower (30+ steps not 8).\n\nis true. It also would generally need you to use CFG, which already slows the model down by around 2x (in case of other models). That's why LoRAs that would make it basically a Turbo model again (no CFG and 8 steps) would be a commonplace.",
              "score": 5,
              "created_utc": "2025-12-24 15:06:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvq71xx",
                  "author": "ImpossibleAd436",
                  "text": "Thanks for this.\n\nI really expected the base model to be larger and require more VRAM, if not then that will be pretty great. \n\nI've had great success with LoRa training and I'm also really hoping I can continue that and start to be able to combine LoRas without damaging the image quality.\n\nThanks again, this is what I was hoping to hear.",
                  "score": 2,
                  "created_utc": "2025-12-24 15:12:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvsd2wj",
              "author": "No-Zookeepergame4774",
              "text": "â€œI expect it will be more resource intensive (file size & VRAM usage) and slower (30+ steps not 8).â€\n\nThe models are all three (Base, Edit, Turbo) the same size and should have similar resource demands. Fron what they have already published, Base/Edit are recommended to use 50 steps with CFG (100 function evaluations), instead of 8 steps without CFG (8 function evaluaitons) for Turbo.",
              "score": 1,
              "created_utc": "2025-12-24 22:31:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvqxht3",
          "author": "Iory1998",
          "text": "Well that's expected. Z-Model Turbo has been fine-tuned. Since it's a beast of a model, it's a testament to how good the base model is. Can't wait to see what the community will do with it.",
          "score": 2,
          "created_utc": "2025-12-24 17:34:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvp60ou",
          "author": "itsdigitalaf",
          "text": "GTA6-Base",
          "score": 4,
          "created_utc": "2025-12-24 10:45:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvph43n",
          "author": "AfterAte",
          "text": "If I can fit the Z-image-edit model without quantization on my card, I'll use it. Qwen-Image-Edit is too big without nanuchaku, so Z-I-E will probably be better.\n\n\nAnd maybe they mean \"Medium\" is better than just \"Good\"",
          "score": 2,
          "created_utc": "2025-12-24 12:25:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvoxdev",
          "author": "protector111",
          "text": "Wait what? Isnt that bad? I mean it started as â€œsoonâ€ then in became â€œnot longâ€ and now we back to â€œsoonâ€ ?! Isnt that like going backwards?!",
          "score": 3,
          "created_utc": "2025-12-24 09:19:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvp9b72",
              "author": "__ThrowAway__123___",
              "text": "Those are just redditor's words, the github page has always said \"to be released\". It will be released when it is released.",
              "score": 17,
              "created_utc": "2025-12-24 11:17:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvqcgk7",
                  "author": "FaceDeer",
                  "text": "But I want it released *before* it's released!",
                  "score": 6,
                  "created_utc": "2025-12-24 15:41:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvpaffe",
          "author": "OpeningAnalysis514",
          "text": "There is a very high chance it will not live up to the hype. In fact I have never been so 100% sure of anything else in my entire life.",
          "score": 1,
          "created_utc": "2025-12-24 11:27:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvpg0mw",
              "author": "reymalcolm",
              "text": "What hype do you have? We need only two things from the base model.\n\n1) ability to finetune (which is written on that summary -> finetune-ability: easy)\n\n2) ability to hook multiple loras without breaking the model (fingers crossed)\n\nSomething terrible would need to happen to not reach those two goals (yes, it is still possible)",
              "score": 28,
              "created_utc": "2025-12-24 12:16:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvq8qt9",
              "author": "SomaCreuz",
              "text": "Depends on the amount of people around here that are expecting a base model to have higher quality than an RL version at its RL.",
              "score": 6,
              "created_utc": "2025-12-24 15:21:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvqhz60",
              "author": "ItwasCompromised",
              "text": "I mean it's going to be ass initially, it's a finetunable base model. It makes no sense to compare the base model to other finetuned models, it should be compared only to other base models. As long as the size of the model is small like ZIT is, it will be accepted and embraced as the new standard.",
              "score": 6,
              "created_utc": "2025-12-24 16:11:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvp5g6k",
          "author": "Brave-Hold-9389",
          "text": "I think we will get them next yearðŸ™‚â€â†•ï¸",
          "score": 1,
          "created_utc": "2025-12-24 10:40:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvpdiae",
          "author": "ThiagoAkhe",
          "text": "At launch, we saw that only three Z-Image models would be released and now there are 4? Or was 4 already expected?",
          "score": 1,
          "created_utc": "2025-12-24 11:54:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvqxwd2",
          "author": "Cyclonis123",
          "text": "I was hoping for turbo edit, maybe that's not possible.",
          "score": 1,
          "created_utc": "2025-12-24 17:37:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvp3hnj",
          "author": "nowrebooting",
          "text": "Visual quality bad? I guess thatâ€™s why they havenâ€™t released it earlier; expectations for this model are though the roof - imagine if the base or omni model turns out to generate SD3 level monstrocities; thatâ€™d lose them all the momentum instantly.Â ",
          "score": -1,
          "created_utc": "2025-12-24 10:20:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvpg8mt",
              "author": "reymalcolm",
              "text": "Then you have weird expectations. If you want to generate cool images you already have the Turbo model.\n\nWe want the base so we can finetune it.\n\nCompare base 1.5 (or even 1.4) and base SDXL with what we have nowadays. This is night and day difference. This is what this is all about :)",
              "score": 20,
              "created_utc": "2025-12-24 12:17:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvp5w6j",
              "author": "Annemon12",
              "text": "It's base model. Aka stuff you get after training but before finetuning for astetics and so on.\n\nThe difference is that with base model when you type say A woman walking in store it will give you random woman of any age in any store. This could be advertisment like version or just straight up low grade photo of random soviet era store with a woman in it.\n\nFinetuned version will give you most of the time model in very nice store. You still can get good looking stuff but you need both know how to prompt and use negatives as well.",
              "score": 11,
              "created_utc": "2025-12-24 10:44:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvp7rkg",
              "author": "Lucaspittol",
              "text": "Turbo already generates SD3 stuff when we ask for NSFW.",
              "score": 1,
              "created_utc": "2025-12-24 11:02:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvowq7z",
          "author": "Major_Specific_23",
          "text": "They say `Visual Quality = Good for Turbo` but it is the best we have seen in terms of realism from a distilled model. When they say `Visual Quality = Bad for base`, I don't believe them lol. Perhaps they are setting the expectations right?  \n  \nEither it is going to be epic or a huge disappointment. there is no middle ground with the amount of hype surrounding its release",
          "score": -4,
          "created_utc": "2025-12-24 09:13:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvoxn9g",
              "author": "Jaune_Anonyme",
              "text": "It's completely normal.\n\nA base model is broad, as broad as possible. Think as a jack of all trades master of none.\n\nIts purpose (outside of just prompting) is to not handicap the people willing to finetune it. By incorporating maximum knowledge while not focusing on either speed or quality. That can be solved later down the road, easily and cheaper.\n\nAnd that's what a turbo distilled model is basically. Hence why it judged better in aesthetic.\n\nIt lock down the CFG so it's faster, and it lock down the outputs to the teacher model. So aesthetically it is also fixed. Or how there's very little seed variety out of the box.\n\nZ image turbo was made for portraits. Mostly asian portraits. You'll notice it how quality skyrocket when prompting for content it is made for.\n\nAs you'll notice how sometimes you'll have to wrestle it to get a different style and the outputs barely changes despite prompting like a madman.\n\nThose examples shouldn't be a problem on the base model. But your prompting knowledge might influence way more the outputs.\n\nPeople really need to get their expectations right. It will yes tone down their expectations. It's the same reason why Flux look nice and has a very specific aesthetic, since Flux is also distilled. If we had a non distilled version the aesthetics will objectively look worse on average.",
              "score": 36,
              "created_utc": "2025-12-24 09:22:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvoymon",
                  "author": "Tablaski",
                  "text": "If you fine tune the base model, how do you get back your resulting model to using 8 step ? Do you have to re-distill it yourself ?\n\nAlso I'm surprised the base model will actually be two, base and omni-base...",
                  "score": 3,
                  "created_utc": "2025-12-24 09:32:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvoyh5y",
                  "author": "Major_Specific_23",
                  "text": "bro i know what a base model is and what a turbo model is. they say \"bad\". when i see \"bad\" i remember the girl lying on grass sd3 bad. no way z can be that bad. i believe it will be like qwen image base",
                  "score": -9,
                  "created_utc": "2025-12-24 09:31:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvp8l5c",
              "author": "Lucaspittol",
              "text": "Chroma1-HD-Flash also produces better images than Chroma1-HD",
              "score": 1,
              "created_utc": "2025-12-24 11:10:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvpahsz",
                  "author": "Major_Specific_23",
                  "text": "i dont understand these comments. who is comparing turbo quality to base again? the comment i made is about how they labeled turbo as just \"good\" when its freaking excellent and i don't believe them when they label \"base\" as \"bad\". police men wants to lecture about random stuff here",
                  "score": 3,
                  "created_utc": "2025-12-24 11:28:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvoxuo0",
              "author": "mk8933",
              "text": "Turbo is most likely a fine-tuned model. A base model is bare bones and has to be used with 50 steps to make any sense. \n\nSo base model is pretty much dead on arrival â€” unless someone fine-tunes it and makes another turbo model out of it.",
              "score": -9,
              "created_utc": "2025-12-24 09:24:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvoznxc",
                  "author": "blahblahsnahdah",
                  "text": "What makes turbo \"turbo\" is that it's step distilled. It is also finetuned, but that's an unrelated thing and not what makes it fast. You don't have to distill to finetune. Distillation is an optional extra thing you can do afterwards if you want to make it faster in exchange for losing negative prompts and a bit of quality.",
                  "score": 4,
                  "created_utc": "2025-12-24 09:43:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvp8buo",
                  "author": "Far_Insurance4191",
                  "text": "wdym \"dead on arrival\", that is the whole point to not have hyper optimizations like all other models have so we could finetune it as easily as possible",
                  "score": 4,
                  "created_utc": "2025-12-24 11:07:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvp710t",
          "author": "Striking-Long-2960",
          "text": "So they released first the last model?",
          "score": 0,
          "created_utc": "2025-12-24 10:55:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvs9ctw",
              "author": "HardenMuhPants",
              "text": "Released the easiest to use model with the best generations to build hype and get everyone hooked. Smart move by them as it has pretty much worked. Now they get heaps of feedback to use on the base and edit model.",
              "score": 2,
              "created_utc": "2025-12-24 22:08:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvsn3iv",
          "author": "ANR2ME",
          "text": "Oh god 50 steps, i hope lightx2v made lighting lora for those Edit/Omni modelsðŸ˜…",
          "score": 0,
          "created_utc": "2025-12-24 23:40:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvw29zo",
          "author": "Jealous_Piece_1703",
          "text": "What do they mean by pre-training in here?",
          "score": 0,
          "created_utc": "2025-12-25 16:45:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvpfnn6",
          "author": "EternalDivineSpark",
          "text": "50 step on the edit model ! I hope at least is better than the new qwen fake 2511 update!",
          "score": -5,
          "created_utc": "2025-12-24 12:13:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvpbma2",
          "author": "the_good_bad_dude",
          "text": "50 steps?!",
          "score": -3,
          "created_utc": "2025-12-24 11:38:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvpgblg",
              "author": "reymalcolm",
              "text": "Why are you surprised?",
              "score": 3,
              "created_utc": "2025-12-24 12:18:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvpgf30",
                  "author": "the_good_bad_dude",
                  "text": "I was expecting 20",
                  "score": -1,
                  "created_utc": "2025-12-24 12:19:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvoxlh9",
          "author": "jd3k",
          "text": "Source?",
          "score": -8,
          "created_utc": "2025-12-24 09:22:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvp1b0r",
              "author": "rxzlion",
              "text": "[https://github.com/Tongyi-MAI/Z-Image](https://github.com/Tongyi-MAI/Z-Image)\n\ntook me 1 sec",
              "score": 14,
              "created_utc": "2025-12-24 09:59:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvovlkd",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -17,
          "created_utc": "2025-12-24 09:02:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvovwl5",
              "author": "Dezordan",
              "text": "Why is it surprising? Turbo is a distilled model, those usually have higher quality for lesser amount of steps. Not to mention that it is a finetuned model, in comparison to the base model, and also went through RLHF. It is expected for the base to be worse, it is specifically made for finetuning.\n\nAnd Edit model is in the similar vein, it wasn't distilled and didn't have RLHF.\n\nAs for 50 steps, it's normal - SD models also have that as a recommended amount of steps, but people usually go for less.\n\nThat's why the most important thing here is \"fine-tunability\", which they say to be easy.",
              "score": 24,
              "created_utc": "2025-12-24 09:05:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvoytb6",
                  "author": "MarxN",
                  "text": "I'm looking for sth which can edit in reasonable amount of time. On Mac Qwen edit is ridiculously slow (hours to edit single image), Flux also. I had a hope for z-image to make it faster, but 50 steps doesn't give a hope.",
                  "score": 1,
                  "created_utc": "2025-12-24 09:34:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvoxork",
              "author": "Formal_Drop526",
              "text": "I assume it's because It hasn't been supervised fine tuned and reinforcement learnt unlike turbo.",
              "score": 1,
              "created_utc": "2025-12-24 09:23:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvpe2ta",
          "author": "Baturinsky",
          "text": "So, Z-image-Edit will be as slow as Flux and such?",
          "score": -5,
          "created_utc": "2025-12-24 11:59:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvpjvhx",
              "author": "reyzapper",
              "text": "All of Zs are 6B parameters, it's way ligther and not as sluggish as flux or qwen.\n\nSlightly slower, yes, it need 20-50 steps compared to Turbo which only 9 steps.",
              "score": 8,
              "created_utc": "2025-12-24 12:46:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvp9pwt",
          "author": "taw",
          "text": "Is there any value in posting \"coming soon\" without even a date?\n\nAnyway, if Z Image has 6x as many steps for worse visual quality, is it even worth the wait?",
          "score": -10,
          "created_utc": "2025-12-24 11:20:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvpcm4t",
              "author": "Sad_Willingness7439",
              "text": "Have you even tried training a zimage lora",
              "score": 5,
              "created_utc": "2025-12-24 11:47:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvpfb0f",
                  "author": "taw",
                  "text": "If cost of better lora support is 6x slower generation time and worse image quality, how is it even worth it?",
                  "score": -1,
                  "created_utc": "2025-12-24 12:10:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvp7plx",
          "author": "Secure_Item7795",
          "text": "i was right, it's full fraud model",
          "score": -25,
          "created_utc": "2025-12-24 11:01:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pyrfro",
      "title": "I made Soprano-80M: Stream ultra-realistic TTS in <15ms, up to 2000x realtime, and <1 GB VRAM, released under Apache 2.0!",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/5f12axpt86ag1",
      "author": "eugenekwek",
      "created_utc": "2025-12-29 16:56:08",
      "score": 263,
      "num_comments": 59,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pyrfro/i_made_soprano80m_stream_ultrarealistic_tts_in/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwlo6cg",
          "author": "harderisbetter",
          "text": "this is awesome, thanks!!  any plans for voice cloning and comfy implementation?",
          "score": 12,
          "created_utc": "2025-12-29 19:54:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwo01fx",
              "author": "eugenekwek",
              "text": "Unfortunately, I'm not very familiar with comfy, but I'd appreciate any community support on this! As for voice cloning, this is planned for a future release, so stay tuned!",
              "score": 7,
              "created_utc": "2025-12-30 03:14:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwl6ql3",
          "author": "urekmazino_0",
          "text": "Can you train any language?",
          "score": 9,
          "created_utc": "2025-12-29 18:32:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnvykn",
              "author": "eugenekwek",
              "text": "Not for right now. I know this is the most popular feature everyone has been asking for though, so I'm going to post the training code soon!",
              "score": 3,
              "created_utc": "2025-12-30 02:52:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwoem21",
                  "author": "tonyhart7",
                  "text": "I love to clone myself",
                  "score": 1,
                  "created_utc": "2025-12-30 04:42:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwoigz0",
                  "author": "SpaceNinjaDino",
                  "text": "I would love if other languages worked like LoRAs to not bloat or skew the English core. Or have a separate international model. \n\nThe more requested feature is actually multi speaker and emotion weight triggers.",
                  "score": 1,
                  "created_utc": "2025-12-30 05:08:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwmvrqw",
              "author": "tomakorea",
              "text": "Best question",
              "score": 1,
              "created_utc": "2025-12-29 23:33:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwlfhza",
          "author": "rinkusonic",
          "text": "i hope the word gabagool is generated every 3 sentences.",
          "score": 14,
          "created_utc": "2025-12-29 19:12:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnxt9q",
              "author": "eugenekwek",
              "text": "Gabagool? Ova here!",
              "score": 5,
              "created_utc": "2025-12-30 03:02:16",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwmv79m",
              "author": "ArtfulGenie69",
              "text": "Yeah but at a high pitch than the mobsters baritone voices haha",
              "score": -1,
              "created_utc": "2025-12-29 23:30:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwku45r",
          "author": "arbaminch",
          "text": "This looks (and sounds) great! \n\nSorry, I don't know anything about TTS or how to integrate them in products... how hard do you reckon it would be to get this working in something like [KoboldCPP](https://github.com/LostRuins/koboldcpp)?",
          "score": 7,
          "created_utc": "2025-12-29 17:34:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnv6rf",
              "author": "eugenekwek",
              "text": "I'm not familiar with KoboldCPP, but all the components in Soprano follow standard architectures, so I believe it shouldn't be too difficult!",
              "score": 3,
              "created_utc": "2025-12-30 02:47:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwltbyo",
          "author": "Dogluvr2905",
          "text": "very nice...clean, crisp, and fast.  If it's possible to train / clone voices...it'd be amazing.",
          "score": 5,
          "created_utc": "2025-12-29 20:19:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwo1qwj",
              "author": "eugenekwek",
              "text": "Thank you! Voice cloning is in the works!",
              "score": 1,
              "created_utc": "2025-12-30 03:24:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwlvc7n",
          "author": "RepresentativeRude63",
          "text": "For voice clone searchers use rvc. Fast generate with this feed to rvc to change voice rvc is super fast too ðŸ«¡",
          "score": 5,
          "created_utc": "2025-12-29 20:29:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwo1er6",
              "author": "eugenekwek",
              "text": "Yeah, you can combine Soprano with RVC as a temporary solution for voice cloning. In the future, I'm planning to add native voice cloning support, so RVC won't be needed anymore.",
              "score": 5,
              "created_utc": "2025-12-30 03:22:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwp0prl",
                  "author": "LevelStill5406",
                  "text": "how does this work? do i create a voice model with RVC that I can use in Soprano?\n\nWith how good Soprano sounds, i might want to use it in my app immediately, though i want to use my own voices.",
                  "score": 1,
                  "created_utc": "2025-12-30 07:35:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwmz1d6",
              "author": "diogodiogogod",
              "text": "you can use chatterbox or cosy voice 3 VC as well. RVC needs training on the target voice.   \n  \nedit: But... if you are going to use chatterbox or cozy, makes no sense to use them as a second step instead of generating TTS directly... since what you want is speed with this new soprano model, then for speed RVC is the real choice, yes.",
              "score": 1,
              "created_utc": "2025-12-29 23:51:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwomc3b",
                  "author": "RepresentativeRude63",
                  "text": "Plus there is a huge repo for rvc models ;)",
                  "score": 1,
                  "created_utc": "2025-12-30 05:36:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nworvhe",
          "author": "SanDiegoDude",
          "text": "/u/eugenekwek FYI, I made a comfyUI node for your model: https://github.com/SanDiegoDude/ComfyUI-Soprano-TTS/tree/main\n\nI had to monkeypatch around lmdeploy to use transformers instead for comfy compatibility. not quite as fast as your native build (but still stupid fast). For folks who want to try it, read the readme, don't try to install it in the manager (it won't work that way).",
          "score": 5,
          "created_utc": "2025-12-30 06:19:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtxiyc",
              "author": "harderisbetter",
              "text": "Is there a sample voice file in the deployed node that perhaps can be replaced with a different sample and then that way you can get voice cloning? or some other hack? thanks!!!",
              "score": 1,
              "created_utc": "2025-12-31 00:39:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwn1kv1",
          "author": "HerculeTheChamp",
          "text": "That Soprano, never had the makings of a varsity LLM",
          "score": 5,
          "created_utc": "2025-12-30 00:05:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkyxiq",
          "author": "Incognit0ErgoSum",
          "text": "Impressive!",
          "score": 3,
          "created_utc": "2025-12-29 17:56:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwo1gpj",
              "author": "eugenekwek",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2025-12-30 03:22:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpgk85",
          "author": "Successful_Potato137",
          "text": "For everyone who wants to test it locally there is a PR with the code to launch a gradio server:\n\n[https://github.com/ekwek1/soprano/pull/10/commits/a11bdd4782df44ad3346eb15ec264f1fe4db14db](https://github.com/ekwek1/soprano/pull/10/commits/a11bdd4782df44ad3346eb15ec264f1fe4db14db)\n\nAbolutely insane the speed of this TTS.  Congratulations.",
          "score": 3,
          "created_utc": "2025-12-30 10:02:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwl8w4u",
          "author": "Tystros",
          "text": "can it run in realtime on one CPU thread?",
          "score": 2,
          "created_utc": "2025-12-29 18:41:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnzkww",
              "author": "eugenekwek",
              "text": "Theoretically yes, but it's not currently implemented. I do have plans for realtime CPU streaming though!",
              "score": 2,
              "created_utc": "2025-12-30 03:12:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwnzt99",
                  "author": "Tystros",
                  "text": "a simple stand-alone native cpu library would be great. something that could easily be used by other software, without requiring any python dependencies etc",
                  "score": 2,
                  "created_utc": "2025-12-30 03:13:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwnw8ra",
          "author": "Underrated_Mastermnd",
          "text": "THAT SOUNDS REALLY GOOD! It doesn't sound unintentionally robotic. The cadence of the speech sounds normal  and inflections when speaking at the end of each sentence or giving emotion sounds like an average person. Better than most TTS and video gen models. Are there instructions to voice clone?",
          "score": 2,
          "created_utc": "2025-12-30 02:53:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwo23cb",
              "author": "eugenekwek",
              "text": "Thank you! It's currently a single-speaker model, but native voice cloning is planned in the future!",
              "score": 1,
              "created_utc": "2025-12-30 03:26:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwnzq24",
          "author": "EndlessZone123",
          "text": "If I can finetune on my own datasets that would make me instantly switch.",
          "score": 2,
          "created_utc": "2025-12-30 03:13:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwo26uh",
              "author": "eugenekwek",
              "text": "Training support is one of the most requested features, so I will be releasing the training code soon!",
              "score": 1,
              "created_utc": "2025-12-30 03:27:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwoe9lw",
          "author": "inaem",
          "text": "I saw it on hf and was disappointed to see no training, looking forward to the training code \n\nPlease donâ€™t disappear on us like the others",
          "score": 2,
          "created_utc": "2025-12-30 04:40:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlo2xz",
          "author": "skyrimer3d",
          "text": "mandatory ConfyWhen?",
          "score": 2,
          "created_utc": "2025-12-29 19:53:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwls0tj",
          "author": "xb1n0ry",
          "text": "I just lost my shit when I generated this in the demo\nMeeeeeeeeeeeeeeoooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooowwwwwwwwww",
          "score": 2,
          "created_utc": "2025-12-29 20:13:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmw8up",
          "author": "ArtfulGenie69",
          "text": "Do you think you can release a training script for it? It's so small it would be nice to have some specific trained voices or try to make it handle longer readings.Â ",
          "score": 1,
          "created_utc": "2025-12-29 23:36:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwnvl5n",
          "author": "Cultured_Alien",
          "text": "Running this on zero GPU is pretty much overkill. I'm interested in cpu performance.",
          "score": 1,
          "created_utc": "2025-12-30 02:50:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnwn60",
              "author": "eugenekwek",
              "text": "Yeah it probably is lol, but it's also the only free GPU on Spaces, so I just decided to go for it. Â¯\\\\\\_(ãƒ„)\\_/Â¯",
              "score": 2,
              "created_utc": "2025-12-30 02:55:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpv53c",
          "author": "Odd-Mirror-2412",
          "text": "Great start! I'll wait for the update.",
          "score": 1,
          "created_utc": "2025-12-30 12:10:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwrpx69",
          "author": "Motorola68020",
          "text": "â€œSoprano automatically generates each sentence independently, and then stitches the results together.â€\n\nThis results in fairly robotic speech no? Each sentence is unaware of previous sentences?",
          "score": 1,
          "created_utc": "2025-12-30 18:06:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwsqaby",
          "author": "Wevvie",
          "text": "Is there API support for front ends like SillyTavern? I'd love to run a fast, high-quality local narrator for my RPGs.",
          "score": 1,
          "created_utc": "2025-12-30 20:58:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwta2yl",
          "author": "mitchins-au",
          "text": "Wow a TTS with code and weights available on announcement! Thanks OP",
          "score": 1,
          "created_utc": "2025-12-30 22:32:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwuuefb",
          "author": "Grindora",
          "text": "How to install this on windows pls? Does it have gradio ui?",
          "score": 1,
          "created_utc": "2025-12-31 03:51:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvgwug",
          "author": "Eraxor",
          "text": "Can I run this with Blackwell cards as well? I get issues with torch and cuda :/",
          "score": 1,
          "created_utc": "2025-12-31 06:32:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlcgx0",
          "author": "foxdit",
          "text": "Seems (and SOUNDS) great! Would love to see a ComfyUI integration.",
          "score": 1,
          "created_utc": "2025-12-29 18:58:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwoofvw",
              "author": "JoNike",
              "text": "I asked Opus 4.5 to take a stab at it, if you're so incline as to give it a try. https://github.com/jo-nike/ComfyUI-SopranoTTS\n\nTho you should probably install via git and not via the manager, not sure it's fully working there yet (never published a node before)\n\nhttps://i.imgur.com/C6VymlV.png",
              "score": 2,
              "created_utc": "2025-12-30 05:51:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwosqko",
                  "author": "foxdit",
                  "text": "Oh holy wow! I will give it a try! Thank you!",
                  "score": 1,
                  "created_utc": "2025-12-30 06:26:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwo1o9e",
              "author": "eugenekwek",
              "text": "Thank you, I would love to see this too! Unfortunately, I don't know ComfyUI well, so I can't implement this myself, but hopefully somebody in the community can. :)",
              "score": 1,
              "created_utc": "2025-12-30 03:24:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwlyumi",
          "author": "Fantastic_Tip3782",
          "text": "Needs Kobold/ST integration stat!",
          "score": -1,
          "created_utc": "2025-12-29 20:46:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmsi3e",
          "author": "MasqueradeDark",
          "text": "Awesome work, mate! The big question however with every single new TTS always is predominently - is it trainable to other languages than English. Because if the answer is yes, congrats! You just made a terrific homerun! If the answer is no, then congrats again! You did well, but probably won't take off like other 100000 super fast TTS's (even though, not fast as yours)",
          "score": 0,
          "created_utc": "2025-12-29 23:15:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwp01p2",
          "author": "nntb",
          "text": "sounds... tin like...",
          "score": 0,
          "created_utc": "2025-12-30 07:29:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr3arh",
              "author": "DelinquentTuna",
              "text": "The groxaxo fork adds a FlashSR process that doesn't add too much latency but does open up the frequency range a bit.",
              "score": 1,
              "created_utc": "2025-12-30 16:21:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwp8lbw",
          "author": "Zokenista",
          "text": "Bro this is Sickk, i was looking for this kinda model",
          "score": 0,
          "created_utc": "2025-12-30 08:48:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwm52vf",
          "author": "-becausereasons-",
          "text": "Genuinely a great sounding model! Is there a Comfy node? :p",
          "score": -1,
          "created_utc": "2025-12-29 21:17:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1puhreu",
      "title": "ðŸ¥³ Qwen-Image-Edit-2511 on ðŸž TostUI",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/rn2ejd64w39g1",
      "author": "camenduru",
      "created_utc": "2025-12-24 07:42:00",
      "score": 247,
      "num_comments": 25,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1puhreu/qwenimageedit2511_on_tostui/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nvpe6cb",
          "author": "ozzie123",
          "text": "Wow this is very solid",
          "score": 9,
          "created_utc": "2025-12-24 12:00:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvp1331",
          "author": "janosibaja",
          "text": "And where is the workflow?",
          "score": 11,
          "created_utc": "2025-12-24 09:57:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvp1ge3",
              "author": "camenduru",
              "text": "https://preview.redd.it/f1jvn8txk49g1.png?width=2782&format=png&auto=webp&s=5ff862ed22c45426f9b557c92f3c392cbcbeaad3",
              "score": 19,
              "created_utc": "2025-12-24 10:00:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvpsjlg",
                  "author": "ucren",
                  "text": "reddit strips metadata from images. can you upload the json do pastebin or github or civitai?",
                  "score": 13,
                  "created_utc": "2025-12-24 13:45:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvuh38g",
                  "author": "janosibaja",
                  "text": "It would be nice of you to post the workflow somewhere accessible. Thank you!",
                  "score": 1,
                  "created_utc": "2025-12-25 08:51:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvs2tmj",
          "author": "Gamerboi276",
          "text": "https://preview.redd.it/988jxl4mz79g1.png?width=1670&format=png&auto=webp&s=9b254b9b51f8902f5aff5b5c48dd6ce0b1111dc8\n\nare we not gonna address the elephant in the room",
          "score": 3,
          "created_utc": "2025-12-24 21:28:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvzylem",
              "author": "Reno0vacio",
              "text": "Which is?",
              "score": 1,
              "created_utc": "2025-12-26 09:00:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvpnom3",
          "author": "1Neokortex1",
          "text": "this is awesome!\nIm gonna try this out but will 8gb veam be suffice?",
          "score": 1,
          "created_utc": "2025-12-24 13:14:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvq1cex",
          "author": "TheRealAncientBeing",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2025-12-24 14:39:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvq1gjb",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 1 day on [**2025-12-25 14:39:41 UTC**](http://www.wolframalpha.com/input/?i=2025-12-25%2014:39:41%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/StableDiffusion/comments/1puhreu/qwenimageedit2511_on_tostui/nvq1cex/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FStableDiffusion%2Fcomments%2F1puhreu%2Fqwenimageedit2511_on_tostui%2Fnvq1cex%2F%5D%0A%0ARemindMe%21%202025-12-25%2014%3A39%3A41%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201puhreu)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2025-12-24 14:40:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvq7oq5",
          "author": "ResponsibleKey1053",
          "text": "So has anyone tried to get a qwen edit to blend really bad photoshops? I've not heard anyone discussing it?",
          "score": 1,
          "created_utc": "2025-12-24 15:15:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrfbtj",
          "author": "Technical_Ad_440",
          "text": "this is something i need to save for sure. another powerful tool for my arsenal of powerful tools",
          "score": 1,
          "created_utc": "2025-12-24 19:11:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvtlnwd",
              "author": "dffgbamakso",
              "text": "very powerful tool of arsenal yees",
              "score": 1,
              "created_utc": "2025-12-25 03:57:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvq5zew",
          "author": "Noiselexer",
          "text": "50gb for a docker pull.. And i cant even see whats in the images, because the docker files are not opensource...",
          "score": 0,
          "created_utc": "2025-12-24 15:06:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvqb7wq",
              "author": "camenduru",
              "text": "[https://github.com/camenduru/TostUI-qwen-image-edit-2511-docker](https://github.com/camenduru/TostUI-qwen-image-edit-2511-docker)",
              "score": 8,
              "created_utc": "2025-12-24 15:35:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvqkmph",
                  "author": "Noiselexer",
                  "text": "Nice thx",
                  "score": 2,
                  "created_utc": "2025-12-24 16:25:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvr2ffz",
                  "author": "abellos",
                  "text": "Please can upload also the image with workflow on github?",
                  "score": 2,
                  "created_utc": "2025-12-24 18:01:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvr8yc6",
          "author": "alb5357",
          "text": "I don't really like that they baked in the loras. Is rather liar and weigh them myself.",
          "score": 0,
          "created_utc": "2025-12-24 18:36:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrl8o2",
          "author": "Sudden_List_2693",
          "text": "And sadly, still unable to do anime.",
          "score": 0,
          "created_utc": "2025-12-24 19:44:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvqgp82",
          "author": "cyberzh",
          "text": "The shadow on the car is very bad. It's a shadow from a point source, like in a studio. It's not one from the sun. The shadow's edge should be a little defined near the car and very blurry when away from it.",
          "score": -1,
          "created_utc": "2025-12-24 16:04:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pw1fc7",
      "title": "Testing StoryMem ( the open source Sora 2 )",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/atjejwm21j9g1",
      "author": "Many-Ad-6225",
      "created_utc": "2025-12-26 10:40:35",
      "score": 246,
      "num_comments": 35,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pw1fc7/testing_storymem_the_open_source_sora_2/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nw0j6d3",
          "author": "Whipit",
          "text": "This seems very interesting. I hope people start making threads about what it can do for them. The gooning potential seems high \\^\\_\\^",
          "score": 31,
          "created_utc": "2025-12-26 12:24:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0v53n",
              "author": "Thisisname1",
              "text": "Unleash the Goon",
              "score": 19,
              "created_utc": "2025-12-26 13:54:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw34f4h",
              "author": "MobileHelicopter1756",
              "text": "GoonDiffusion",
              "score": 8,
              "created_utc": "2025-12-26 21:21:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw11jqa",
          "author": "johnfkngzoidberg",
          "text": "Open source Sora 2?  I donâ€™t think so.",
          "score": 47,
          "created_utc": "2025-12-26 14:36:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw1bmud",
          "author": "siscoisbored",
          "text": "She aged a decade in the first 10 seconds",
          "score": 20,
          "created_utc": "2025-12-26 15:35:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw29198",
              "author": "krectus",
              "text": "It was nice of her to change outfits to match her older look as well.",
              "score": 3,
              "created_utc": "2025-12-26 18:32:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw1xe7n",
              "author": "Kriogenix",
              "text": "Just how she aged a decade between seasons 1 and 2",
              "score": 2,
              "created_utc": "2025-12-26 17:31:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw16oqh",
          "author": "Perfect-Campaign9551",
          "text": "It still does that \"slow down\" thing I can tell where the video cuts are",
          "score": 14,
          "created_utc": "2025-12-26 15:07:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw2vk4n",
              "author": "michaelsoft__binbows",
              "text": "the least the code could do is try to enforce some c1 and c2 continuity to camera motion and subject motion. like, i guess that's today's holy grail.",
              "score": 5,
              "created_utc": "2025-12-26 20:33:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw197ot",
          "author": "FightingBlaze77",
          "text": "Ok problem, how is this a good example? She got a zoom in and teleported to a coffee house.",
          "score": 12,
          "created_utc": "2025-12-26 15:21:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw296vx",
              "author": "krectus",
              "text": "And changed outfits and faces.",
              "score": 15,
              "created_utc": "2025-12-26 18:33:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw2hrxk",
                  "author": "FightingBlaze77",
                  "text": "this too omg I just noticed",
                  "score": 2,
                  "created_utc": "2025-12-26 19:18:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw2zvnn",
              "author": "Cute-Monitor-9718",
              "text": "Probably not Sora 2 level but maybe Grok imagine level",
              "score": 3,
              "created_utc": "2025-12-26 20:57:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw2273n",
          "author": "hurrdurrimanaccount",
          "text": "tf you mean \"open source sora2\"? holy click and ragebait",
          "score": 5,
          "created_utc": "2025-12-26 17:57:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3qf7r",
          "author": "sevenfold21",
          "text": "Her face changes like 3 seconds into the video.  Not heavily consistent.",
          "score": 2,
          "created_utc": "2025-12-26 23:25:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw7603w",
              "author": "Lower-Cap7381",
              "text": "i think using a character lora with this will be a game changer",
              "score": 1,
              "created_utc": "2025-12-27 15:01:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwcpi9v",
              "author": "Many-Ad-6225",
              "text": "The workflow is still a work in progress, consistency will be much better in the final version.",
              "score": 1,
              "created_utc": "2025-12-28 12:15:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw0e7tb",
          "author": "Altruistic_Noise4159",
          "text": "This is actually pretty cool ! \nWhy aren't more people talking about this !?",
          "score": 4,
          "created_utc": "2025-12-26 11:39:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0wu07",
              "author": "Pyros-SD-Models",
              "text": "because calling this \"open source Sora 2\" is like calling a Ford Fiesta a Ferrari.",
              "score": 49,
              "created_utc": "2025-12-26 14:05:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw1468t",
                  "author": "ObviousComparison186",
                  "text": "Also really stupid and annoying, the only \"open source Sora 2\" would be if you stole Sora 2's model and made it public. Using it for anything else just makes you look like a clown who would use these corporate slop machines that aren't local.",
                  "score": 5,
                  "created_utc": "2025-12-26 14:52:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw0jx3i",
              "author": "BoneDaddyMan",
              "text": "tried it. It's... it's just a slightly better version of SVI but it still degrades, still forgets where the characters are and what they look like.",
              "score": 7,
              "created_utc": "2025-12-26 12:31:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw0ixc7",
              "author": "dynamitfiske",
              "text": "Maybe because it entirely forgot the dimensions of the room between cuts?",
              "score": 3,
              "created_utc": "2025-12-26 12:22:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw28xgl",
          "author": "krectus",
          "text": "Yeah this is pretty bad her face and outfit change pretty drastically in just a few seconds.",
          "score": 2,
          "created_utc": "2025-12-26 18:31:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0c5rl",
          "author": "zekuden",
          "text": "Better than wan?",
          "score": 1,
          "created_utc": "2025-12-26 11:19:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0cmld",
              "author": "adjudikator",
              "text": "Wan based",
              "score": 7,
              "created_utc": "2025-12-26 11:24:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw0dv5c",
                  "author": "zekuden",
                  "text": "Oh i see, thanks",
                  "score": 2,
                  "created_utc": "2025-12-26 11:36:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw1zdv2",
          "author": "Hearcharted",
          "text": "![gif](giphy|WsFgHCj65SnKEwJRMP)\n\nNetflix lawyers:",
          "score": 1,
          "created_utc": "2025-12-26 17:42:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw1zjo2",
              "author": "Hearcharted",
              "text": "![gif](giphy|GrMRh6ukoIMhpkeTHM)",
              "score": 1,
              "created_utc": "2025-12-26 17:43:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw2akd9",
          "author": "fractaldesigner",
          "text": "why does if look 10fps?",
          "score": 1,
          "created_utc": "2025-12-26 18:40:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw2wzys",
              "author": "ANR2ME",
              "text": "It's based on Wan2.2 A14B, thus 16fps",
              "score": 1,
              "created_utc": "2025-12-26 20:41:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw6n1co",
          "author": "Cubey42",
          "text": "character still loses consistency, shame really but its not nearly whets promised",
          "score": 1,
          "created_utc": "2025-12-27 12:58:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwcpfvt",
              "author": "Many-Ad-6225",
              "text": "The workflow is still a work in progress, consistency will be much better in the final version.",
              "score": 1,
              "created_utc": "2025-12-28 12:14:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw0umg3",
          "author": "Better-Interview-793",
          "text": "Looks good!\nWhatâ€™s your GPU & how long did it take?",
          "score": 1,
          "created_utc": "2025-12-26 13:51:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw1thti",
              "author": "Many-Ad-6225",
              "text": "Geforce rtx 5070 ti 16go of vram. I don't remember but it's not very long may be 8 minutes",
              "score": 1,
              "created_utc": "2025-12-26 17:11:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw2rc6b",
                  "author": "RepresentativeRude63",
                  "text": "Hmm still best at 1 minute for each 1 second than. Seems we canâ€™t pass beyond that with Wan. Oh btw and the resolution of generation? 480 or 720p?",
                  "score": 1,
                  "created_utc": "2025-12-26 20:09:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pu5opp",
      "title": "This is the new ComfyUi workflow of Qwen Image Edit 25/11.",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/1oewojiuu09g1.jpeg",
      "author": "Total-Resort-3120",
      "created_utc": "2025-12-23 21:30:26",
      "score": 236,
      "num_comments": 51,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial - Guide",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pu5opp/this_is_the_new_comfyui_workflow_of_qwen_image/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nvmr3f6",
          "author": "Pure_Bed_6357",
          "text": "https://preview.redd.it/ic1lsg83j19g1.png?width=936&format=png&auto=webp&s=46446fdaf4c021e63220c840a9fe21eee76546ac\n\nAll I get is this ðŸ˜­ðŸ˜­",
          "score": 19,
          "created_utc": "2025-12-23 23:45:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvmv0wd",
              "author": "Cultural-Team9235",
              "text": "Do you have the FP8 with Lightning baked in? That one is broken.",
              "score": 14,
              "created_utc": "2025-12-24 00:09:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvmvbu2",
                  "author": "Pure_Bed_6357",
                  "text": "Yeah but I'm now downloading the normal one with 4 step lora, i hope that one works",
                  "score": 2,
                  "created_utc": "2025-12-24 00:10:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvnrn2v",
                  "author": "xcdesz",
                  "text": "So is there one that's not a GGUF?  Can you provide the link to it?",
                  "score": 1,
                  "created_utc": "2025-12-24 03:32:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvpmyta",
                  "author": "CountPacula",
                  "text": "Ooh, thanks for the confirmation on that, I was wondering why I couldn't get it to work at all. Unsloth's Q6 works *great* with and without the lora.",
                  "score": 1,
                  "created_utc": "2025-12-24 13:09:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvp4dcv",
              "author": "Lower-Cap7381",
              "text": "You need to visit the latent space HAHAHA",
              "score": 3,
              "created_utc": "2025-12-24 10:29:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvzfavm",
              "author": "_VirtualCosmos_",
              "text": "Look how pretty are noise latent spaces when decoded by VAE.",
              "score": 2,
              "created_utc": "2025-12-26 05:53:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvmhvvm",
          "author": "orangeflyingmonkey_",
          "text": ">Edit Model Reference Method\n\nwhere do I get this node?\n\nAlso, thanks for the workflow!",
          "score": 6,
          "created_utc": "2025-12-23 22:51:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvmjcjb",
              "author": "ImpressiveStorm8914",
              "text": "Try searching for FluxKontextMultiReferenceLatentMethod in Comfy. It's part of Comfy Core. This was suggested in another thread here and appears to be exactly the same node. It's working for me. :-)",
              "score": 14,
              "created_utc": "2025-12-23 22:59:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvmwjjd",
                  "author": "orangeflyingmonkey_",
                  "text": "> FluxKontextMultiReferenceLatentMethod \n\nFound this node but in the screenshot, the node is called 'Edit Model Reference Method'. Are they both the same?\n\nAlso, could you please link to the 2511_fp8 huggingface? There are so many threads I can't find the original link.",
                  "score": 1,
                  "created_utc": "2025-12-24 00:18:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvmzgsa",
          "author": "UnicornJoe42",
          "text": "Ok, but how to load multiple reference images?",
          "score": 3,
          "created_utc": "2025-12-24 00:35:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvn6t34",
              "author": "YOLO2THEMAX",
              "text": "Use TextEncodeQwenEditPlus node instead of TextEncodeQwenImageEdit.",
              "score": 7,
              "created_utc": "2025-12-24 01:20:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvq69sc",
                  "author": "TurbTastic",
                  "text": "In some situations itâ€™s better to feed the reference images into the Reference Latent node instead of the Qwen Encode node. For example that solved image/pixel drift for me. The Qwen Encode node will automatically resize your images to 1MP but Reference Latent doesnâ€™t resize, so make sure you are giving it an appropriately sized image.",
                  "score": 5,
                  "created_utc": "2025-12-24 15:07:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvrjwvy",
                  "author": "Sudden_List_2693",
                  "text": "As mentioned by TurbTastic, I'd advice against using the image part of these nodes.",
                  "score": 2,
                  "created_utc": "2025-12-24 19:37:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvmbg1b",
          "author": "Fresh-Exam8909",
          "text": "Thanks for this.\n\nI've notice the 1024x1024 resolution for Qwen Edit. I think when we are going to die, the models will produce 64k images but the edit models will still be done at 1024x1024.\n\n:)))",
          "score": 3,
          "created_utc": "2025-12-23 22:15:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvtj94u",
              "author": "Cultured_Alien",
              "text": "I've done 2k resolution with qwen edit 2511.",
              "score": 2,
              "created_utc": "2025-12-25 03:38:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvtjii4",
                  "author": "Fresh-Exam8909",
                  "text": "Thanks! good to know.",
                  "score": 1,
                  "created_utc": "2025-12-25 03:40:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvny30l",
              "author": "slpreme",
              "text": "flux2 can do higher but it will take longer",
              "score": 1,
              "created_utc": "2025-12-24 04:14:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvognre",
          "author": "yamfun",
          "text": "GGUF plz",
          "score": 3,
          "created_utc": "2025-12-24 06:40:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvmc5i9",
          "author": "Radiant-Photograph46",
          "text": "Thank you for the the heads up. I suppose this works too with the TextEncodeQwenEditPlus node?",
          "score": 2,
          "created_utc": "2025-12-23 22:19:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvnvjf4",
          "author": "Bbmin7b5",
          "text": "Which custom node has \"Edit Model Reference Method\"? I've updated ComfyUI and its nowhere to be seen",
          "score": 2,
          "created_utc": "2025-12-24 03:57:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvnvvve",
              "author": "Total-Resort-3120",
              "text": "It's not a custom node it's on native ComfyUi.",
              "score": 1,
              "created_utc": "2025-12-24 03:59:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvo7j39",
          "author": "lmpdev",
          "text": "FluxKontextMultiReferenceLatentMethod node didn't do anything in my test. I produce an image with it, and by passing it and the results were identical.",
          "score": 2,
          "created_utc": "2025-12-24 05:23:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvqkm8h",
          "author": "comfyanonymous",
          "text": "This is the wrong workflow, you are supposed to use the node with the 3 image inputs.\n\nIf you update there's a correct workflow in the templates.",
          "score": 2,
          "created_utc": "2025-12-24 16:25:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvqmkrd",
              "author": "Total-Resort-3120",
              "text": "The catbox has the node with the 3 image inputs",
              "score": 1,
              "created_utc": "2025-12-24 16:35:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvmscss",
          "author": "crusinja",
          "text": "only 1 image input? seems not correct",
          "score": 2,
          "created_utc": "2025-12-23 23:52:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvmycv9",
              "author": "NickelDare",
              "text": "You should be able to use \"TextEncodeQwenImageEditPlus\"-Node to input up to 3 Images, but make sure the Conditioning goes into either the \"FluxKontextMultiReferenceLatentMethod\"-Node or the \"Edit Model Reference Method\"-Node.",
              "score": 7,
              "created_utc": "2025-12-24 00:29:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvmr66o",
          "author": "jaywv1981",
          "text": "Is there a certain version of the model to use with this workflow? Its only generating random noise for me.",
          "score": 1,
          "created_utc": "2025-12-23 23:45:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvmvqst",
              "author": "jaywv1981",
              "text": "Nvm, I got it working my using the GGUF model and switching to GGUF loader.",
              "score": 1,
              "created_utc": "2025-12-24 00:13:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvnwjie",
          "author": "_chromascope_",
          "text": "My results had a hard time following my prompts. I was recommended in another post to add this node and the image is now much improved. Thank you!\n\nhttps://preview.redd.it/5gly842us29g1.png?width=2600&format=png&auto=webp&s=76044f994c4c1543b3727967511eebc84537775d",
          "score": 1,
          "created_utc": "2025-12-24 04:04:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvtpiic",
              "author": "Ok_Ingenuity_9942",
              "text": "upload json please",
              "score": 2,
              "created_utc": "2025-12-25 04:28:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvsgul9",
          "author": "Biggest_Cans",
          "text": "I need an adult to teach me comfyui properly, copypasting json workflows is about all I've been willing to do so far.\n\nAnyone got a good intro video or text guide?",
          "score": 1,
          "created_utc": "2025-12-24 22:56:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvwse73",
              "author": "superninjaa",
              "text": "What are you getting stuck with?",
              "score": 1,
              "created_utc": "2025-12-25 19:18:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvmtobp",
          "author": "bzzard",
          "text": "Should negative be zero out conditioning?",
          "score": 1,
          "created_utc": "2025-12-24 00:00:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvn6i2p",
              "author": "nmkd",
              "text": "yea",
              "score": 0,
              "created_utc": "2025-12-24 01:19:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvmjzpj",
          "author": "CountFloyd_",
          "text": "Just want to add that according to the screenshot this is using the old, previous clip model. Yes I know that that the new one is currently broken...",
          "score": -2,
          "created_utc": "2025-12-23 23:03:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvmzejm",
              "author": "97buckeye",
              "text": "There's a new clip for Qwen Edit?",
              "score": 5,
              "created_utc": "2025-12-24 00:35:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvnmfcy",
                  "author": "durden111111",
                  "text": "no",
                  "score": 0,
                  "created_utc": "2025-12-24 02:58:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvn3wdr",
              "author": "hurrdurrimanaccount",
              "text": "what new clip?",
              "score": 6,
              "created_utc": "2025-12-24 01:02:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw34rym",
              "author": "CountFloyd_",
              "text": "Sorry my bad, mistook the scaled fp8 with the text encoder ðŸ˜¶",
              "score": 1,
              "created_utc": "2025-12-26 21:23:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pv4kfq",
      "title": "Cosy Voice 3 - 1 shot cloning nodes for comfy",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/lgenr28fv99g1",
      "author": "Lividmusic1",
      "created_utc": "2025-12-25 03:48:33",
      "score": 235,
      "num_comments": 49,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pv4kfq/cosy_voice_3_1_shot_cloning_nodes_for_comfy/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nvtn2cs",
          "author": "urabewe",
          "text": "Looks interesting. Will have to check out when things calm down! Thanks for sharing and Merry Christmas!",
          "score": 14,
          "created_utc": "2025-12-25 04:08:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtwezf",
          "author": "ArtfulGenie69",
          "text": "Wish it sounded better because it can speak so many languages.Â ",
          "score": 13,
          "created_utc": "2025-12-25 05:25:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvx1x1",
              "author": "Lividmusic1",
              "text": "Depends on the voice as usual",
              "score": 2,
              "created_utc": "2025-12-25 16:14:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvxvio3",
                  "author": "ArtfulGenie69",
                  "text": "Higgs must have been trained on a lot more English speakers or something or the extra parameters really offer a lot to the model.Â ",
                  "score": 1,
                  "created_utc": "2025-12-25 23:20:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvtqfhw",
          "author": "NebulaBetter",
          "text": "Great contribution! Thanks!",
          "score": 7,
          "created_utc": "2025-12-25 04:35:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvam7b",
          "author": "Wilbis",
          "text": "How does this compare to VibeVoice? Pros/cons? [https://github.com/microsoft/VibeVoice](https://github.com/microsoft/VibeVoice)",
          "score": 4,
          "created_utc": "2025-12-25 13:44:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvxxx2m",
              "author": "Lividmusic1",
              "text": "vibe voice is really solid, honestly i think they're both good for different stuff, these models are usually finicky on seed and everything, i personally think this repo is more stable as opposed to vibe voice, where i either get something AMAZING out of vibe, or it completely fails. this model seems to be a little more predictable. but to each their own. Im just adding more options out there for people to play with!",
              "score": 4,
              "created_utc": "2025-12-25 23:36:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw0oohu",
                  "author": "BeautyxArt",
                  "text": "what are the supported languages ?",
                  "score": 2,
                  "created_utc": "2025-12-26 13:09:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvxys1q",
                  "author": "Wilbis",
                  "text": "Thanks for the reply. I guess I'll try both of them.\n\nWhat do you think is long enough sample as the source sound clip for voice cloning? Or how long should it be after which it no longer gets better? Is there a general rule for that at all?",
                  "score": 1,
                  "created_utc": "2025-12-25 23:42:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvx7v3h",
              "author": "Perfect-Campaign9551",
              "text": "They both suck, just use the old XTTSv2, nothing has outdone it yet no matter how much people want to think it does..\n\nVibeVoice (I have the large model, too) stinks at speaking like a person would - it just doesn't have good pacing or proper emphasis. I have been really disappointed in it.",
              "score": 3,
              "created_utc": "2025-12-25 20:53:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvwpf7z",
          "author": "StickiStickman",
          "text": "What the point when this sounds worse than what we had 2 years ago?",
          "score": 3,
          "created_utc": "2025-12-25 19:01:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvx69kh",
              "author": "silenceimpaired",
              "text": "Whatâ€™s the better option from two years ago thatâ€™s open source with a commercial friendly license like Apache 2 or MIT? Iâ€™m definitely interested.",
              "score": 3,
              "created_utc": "2025-12-25 20:43:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvx84lx",
                  "author": "Perfect-Campaign9551",
                  "text": "XttsV2 still hasn't been outdone yet in my opinion. It STILL has the best reading proper pacing and it's fast. It can one-shot clone with like 10 seconds sample, and it's so fast you can just re-roll until the sentence sounds like you want.\n\nAll these new voice models still just don't work any better than good 'ol XttsV2 from my testing so far.",
                  "score": 3,
                  "created_utc": "2025-12-25 20:54:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvu06m6",
          "author": "uikbj",
          "text": "hooray! thanks for your work for implementation. wish you a Merry Christmas. the results are really good and its super fast!",
          "score": 2,
          "created_utc": "2025-12-25 05:59:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvrj8g",
          "author": "Entrypointjip",
          "text": "Very easy to setup, thank you and merry Christmas.",
          "score": 2,
          "created_utc": "2025-12-25 15:40:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvup39r",
          "author": "protector111",
          "text": "how ddi you lipsynch?",
          "score": 3,
          "created_utc": "2025-12-25 10:19:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvw4wmf",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 2,
              "created_utc": "2025-12-25 17:01:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvxaxbc",
                  "author": "Perfect-Campaign9551",
                  "text": "InfiniteTalk works right almost every time, I think it's great so far.",
                  "score": 1,
                  "created_utc": "2025-12-25 21:12:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvwkg4m",
                  "author": "FitContribution2946",
                  "text": "Infinite talk is awesome but the newest and easiest to use is called lung cat. Here's a tutorial I just made yesterday \n \nhttps://youtu.be/LJRDt_C6MRg?si=a_n7IGik5SgD1rxn",
                  "score": 1,
                  "created_utc": "2025-12-25 18:33:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvvro5f",
              "author": "Lividmusic1",
              "text": "Lipsync is wan animate",
              "score": 2,
              "created_utc": "2025-12-25 15:41:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvvtqns",
                  "author": "protector111",
                  "text": "I dont get it. You generated ai audio with cosy voice and used it to lip-synch with wananimate? How?",
                  "score": 6,
                  "created_utc": "2025-12-25 15:54:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvtmmfj",
          "author": "000TSC000",
          "text": "lol",
          "score": 1,
          "created_utc": "2025-12-25 04:05:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvv5jqh",
          "author": "ucren",
          "text": "Is there anything special for how to write text for this? I get a lot of run-on speaking where there's barely a pause at a period. Also are there any emotion keywords? the official repo is scant on details for how to prompt TTS for this model.",
          "score": 1,
          "created_utc": "2025-12-25 13:04:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvy1au",
              "author": "Lividmusic1",
              "text": "Havnt had much time to really dig in and rip it apart. Iâ€™m sure thereâ€™s something we can get our hands on for that. Iv been doing stuff like â€œâ€¦â€ when I want pauses. \n\nShort answer: seed is still the main offender",
              "score": 1,
              "created_utc": "2025-12-25 16:20:18",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nvw0519",
              "author": "Lividmusic1",
              "text": "Actually one thing to note is the cloning takes into consideration the cadence of the reference audio. So I bet if you had pauses in there it would help",
              "score": 1,
              "created_utc": "2025-12-25 16:32:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvvlg68",
          "author": "Soraman36",
          "text": "By any chance could we combine voices with this?",
          "score": 1,
          "created_utc": "2025-12-25 15:02:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvx6fht",
              "author": "silenceimpaired",
              "text": "I wish you could combine two cloned voices like you can with Kokoro. This way you could create something unique that sounds similar to the voices you have in mind.",
              "score": 2,
              "created_utc": "2025-12-25 20:44:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvx7ayw",
                  "author": "Soraman36",
                  "text": "Right by any chance you know of a program like that",
                  "score": 1,
                  "created_utc": "2025-12-25 20:49:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvvxnia",
              "author": "Lividmusic1",
              "text": "Combined tambre of voices? No I donâ€™t think so \nI did create a dialogue node that allows for back and forth conversation if thatâ€™s what you mean instead of",
              "score": 1,
              "created_utc": "2025-12-25 16:18:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvxd2o8",
          "author": "shtorm2005",
          "text": "any way I can supply it many txt files to get audio for each one?",
          "score": 1,
          "created_utc": "2025-12-25 21:25:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvxxl2y",
              "author": "Lividmusic1",
              "text": "not at the moment, the easiest way to do that would be to build a comfy system to do it",
              "score": 2,
              "created_utc": "2025-12-25 23:34:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw4zrfp",
          "author": "Kushagra3007",
          "text": "How to add expression ms in the prompt.\n\nWhile using ZERO CLONE NODE, Sometimes it accepts emotions sometimes just reads it out aloud.",
          "score": 1,
          "created_utc": "2025-12-27 04:13:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwb5n4h",
          "author": "Which-Roof-3985",
          "text": "This is bad. Like really bad. Chatterbox is better than this.",
          "score": 0,
          "created_utc": "2025-12-28 04:07:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwcgj48",
              "author": "misterflyer",
              "text": "How do you know it's CosyVoice's fault? It could simply be a bad sample. Garbage in, garbage out.",
              "score": 1,
              "created_utc": "2025-12-28 10:53:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwb8lhy",
              "author": "Lividmusic1",
              "text": "I wrapped chatterbox months ago, use whatever youâ€™d like idc =P",
              "score": 1,
              "created_utc": "2025-12-28 04:27:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwbze2o",
                  "author": "Which-Roof-3985",
                  "text": "It doesn't sound like Zap Brannigan. Might as well try to do the voice yourself.",
                  "score": 1,
                  "created_utc": "2025-12-28 08:07:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1px9t51",
      "title": "Wan 2.2 More Consistent Multipart Video Generation via FreeLong - ComfyUI Node",
      "subreddit": "StableDiffusion",
      "url": "https://www.youtube.com/watch?v=wZgoklsVplc",
      "author": "shootthesound",
      "created_utc": "2025-12-27 21:58:32",
      "score": 234,
      "num_comments": 101,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1px9t51/wan_22_more_consistent_multipart_video_generation/",
      "domain": "youtube.com",
      "is_self": false,
      "comments": [
        {
          "id": "nw9hwi9",
          "author": "lebrandmanager",
          "text": "This is great. I was wondering, if you would follow up on your post from yesterday. You delivered now I will test this. Also having this based on the standard models is perfect. My SSD is tired boss. Thank you!",
          "score": 9,
          "created_utc": "2025-12-27 22:19:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc7o5s",
              "author": "lebrandmanager",
              "text": "Adding something to my own comment: it works. I needed to modify it a bit and got the generation time down by 4 steps each. But, as all workflows have the same issue, the character likeness is lost over time. No issue with this node/workflow, but I hoped for something better. For anything else this is great!",
              "score": 5,
              "created_utc": "2025-12-28 09:28:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwcoou2",
                  "author": "Nokai77",
                  "text": "The lack of consistency and preservation versus degradation is usually the same old problem",
                  "score": 2,
                  "created_utc": "2025-12-28 12:08:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwfftmu",
                  "author": "StuccoGecko",
                  "text": "yeah i was hoping the spectral blend could \"see\" what the model looked like in previous gen and kinda remember it. For my own use I reduced the number of chunks to like 2-3 max as it starts getting pretty degraded after that.",
                  "score": 1,
                  "created_utc": "2025-12-28 21:04:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw9etcf",
          "author": "Ambitious-Tie7231",
          "text": "Have you seen SVI 2.0 Pro and compared it with your long video generations? [https://github.com/vita-epfl/Stable-Video-Infinity/blob/svi\\_wan22/docs/svi/svi\\_2.0\\_pro.md](https://github.com/vita-epfl/Stable-Video-Infinity/blob/svi_wan22/docs/svi/svi_2.0_pro.md)",
          "score": 5,
          "created_utc": "2025-12-27 22:02:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw9gfg5",
              "author": "shootthesound",
              "text": "I have, there is a crossover , the two projects approach a similar problem from different angles. Obviously mine uses the standard base models.  Perhaps some of what I've done here will be useful to them and vica versa. I'm most interested in helping the community effort to improve this tech.",
              "score": 16,
              "created_utc": "2025-12-27 22:11:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwa0va2",
                  "author": "Ok_Lunch1400",
                  "text": "Can you DM me a BuyMeACoffee (or whatever else) donation address?",
                  "score": 6,
                  "created_utc": "2025-12-28 00:05:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw9v8ve",
          "author": "Perfect-Campaign9551",
          "text": "I've modified the workflow locally to use GGUF and so it also has to load the CLIP on its own, too. Here is a screenshot. It's currently executing so it should work\n\nGiving it a spin, it's not super fast though lol, RTX 3090, 72seconds/it right now at the very first chunk high noise (sped up a bit on low noise to 34sec/it). But it's 864x480, usually I do stuff like 680x68\n\nhttps://preview.redd.it/jtjv7ecw1u9g1.png?width=2560&format=png&auto=webp&s=6cdf6599e0c44a2fba5373c4f94d67bcd2617e51",
          "score": 4,
          "created_utc": "2025-12-27 23:33:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwa2gwq",
              "author": "Perfect-Campaign9551",
              "text": "Update: It ran perfectly fine\n\nI canceled early and stitched the first 4 chunks in Davinci. Looks really good \n\nhttps://preview.redd.it/3amu1qhy7u9g1.png?width=2560&format=png&auto=webp&s=b53d01e2eedd3252820bcf4f4f4a38054912b8c3",
              "score": 3,
              "created_utc": "2025-12-28 00:14:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwa4ks3",
                  "author": "shootthesound",
                  "text": "ah great to hear!!  I'll need to make a gguf workflow in the node dir",
                  "score": 3,
                  "created_utc": "2025-12-28 00:26:14",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nwa533n",
                  "author": "shootthesound",
                  "text": "i ffin love Davinci btw.",
                  "score": 2,
                  "created_utc": "2025-12-28 00:29:09",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwg4v1k",
              "author": "shootthesound",
              "text": "Pushed some VRAM fixes to lower vram usage and a speed increase",
              "score": 1,
              "created_utc": "2025-12-28 23:11:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw9jsoz",
          "author": "Neggy5",
          "text": "hi, the Allor custom nodes in the multi-part workflow refuse to install. It is probably incompatible with current ComfyUI. the node ÃmageBatchJoin is part of the node suite that fails to work.\n\nThe git for Allor hasnt been updated in 2 years. If you can find another custom node that does the same thing as ImageBatchJoin, thatd be great",
          "score": 8,
          "created_utc": "2025-12-27 22:30:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw9o0nt",
              "author": "shootthesound",
              "text": "Done!",
              "score": 8,
              "created_utc": "2025-12-27 22:53:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw9oy9m",
                  "author": "Neggy5",
                  "text": "yesss thanks",
                  "score": 4,
                  "created_utc": "2025-12-27 22:58:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw9wa10",
          "author": "Infinite-Strain-3706",
          "text": "legendary",
          "score": 4,
          "created_utc": "2025-12-27 23:39:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwaabxb",
          "author": "Direct-Vehicle2653",
          "text": "Someone post some result please. I couldn't get it to work, and I'm sad :( Let's see some looooong videos!",
          "score": 4,
          "created_utc": "2025-12-28 00:59:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbffn2",
              "author": "Perfect-Campaign9551",
              "text": "It works, I was able to reproduce the car video so far",
              "score": 2,
              "created_utc": "2025-12-28 05:15:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwbge5t",
                  "author": "Direct-Vehicle2653",
                  "text": "Great result! Anybody else?",
                  "score": 3,
                  "created_utc": "2025-12-28 05:22:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw9p2p7",
          "author": "Tystros",
          "text": "Can this only do I2V or also T2V?",
          "score": 3,
          "created_utc": "2025-12-27 22:58:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw9pelo",
              "author": "shootthesound",
              "text": "both",
              "score": 3,
              "created_utc": "2025-12-27 23:00:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw9rebp",
                  "author": "Tystros",
                  "text": "how? I don't see anything in the car example workflow about T2V. it always wants an image input",
                  "score": -1,
                  "created_utc": "2025-12-27 23:12:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw9w4nm",
          "author": "Tystros",
          "text": "could you make the sampler settings easier to adjust in one single place in the workflow? currently changing them seems to require manually changing them in each of the sub graphs, which takes quite a while, and usually you want the same sampler settings for all the samplers",
          "score": 3,
          "created_utc": "2025-12-27 23:39:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw9xsbr",
              "author": "shootthesound",
              "text": "point taken, i'll do that tomorrow",
              "score": 3,
              "created_utc": "2025-12-27 23:48:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw9zc5b",
                  "author": "Tystros",
                  "text": "thanks!",
                  "score": 2,
                  "created_utc": "2025-12-27 23:57:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw9noko",
          "author": "ArtDesignAwesome",
          "text": "Would this work in conjunction with svi 2 pro and the painteri2v nodes?",
          "score": 2,
          "created_utc": "2025-12-27 22:51:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw9o784",
              "author": "shootthesound",
              "text": "I expect it may well do, i need to try it, but if it does , please report back",
              "score": 2,
              "created_utc": "2025-12-27 22:54:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwan9ry",
                  "author": "ArtDesignAwesome",
                  "text": "its above my paygrade, this is all so complex. your WF is chunk based but the KIJIA WF is one long video. Plus I dont know how the hell i would implement painteri2v here even though i know its super important for good motion with the lightning loras. Someone with some comfyui skills please help!!!",
                  "score": 2,
                  "created_utc": "2025-12-28 02:16:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwa9min",
          "author": "Robbsaber",
          "text": "Could this work with turbo-diffusion?",
          "score": 2,
          "created_utc": "2025-12-28 00:54:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwaa331",
              "author": "shootthesound",
              "text": "LOL i literally just made a to-do for myself to try that",
              "score": 3,
              "created_utc": "2025-12-28 00:57:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwabq8s",
                  "author": "Robbsaber",
                  "text": " I figured it could make for a perfect workflow lol",
                  "score": 1,
                  "created_utc": "2025-12-28 01:07:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwaz0y5",
          "author": "Radyschen",
          "text": "I don't know if this is a dumb question, you mentioned that you can use loras for each block individually, I was wondering what would be the best way to do that? I though maybe I could add a lora node between each get freelong node and the chunk, but I don't know if the freelong node does anything that would make it bad to do it afterwards, would that cause any problems?",
          "score": 2,
          "created_utc": "2025-12-28 03:26:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwdzk9x",
              "author": "shootthesound",
              "text": "added loras per block! see v 2 workflow after updating",
              "score": 1,
              "created_utc": "2025-12-28 16:53:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwb03yo",
          "author": "ptwonline",
          "text": "Very cool!  Can't wait to to see some iterations and refinements of this workflow/method.\n\nI assume it's possible to add loras for some of chunks if it's a unique motion or effect you wanted just for that chunk?  Wasn't sure how the blending between chunks affected the need and use of loras.",
          "score": 2,
          "created_utc": "2025-12-28 03:33:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwg4scr",
              "author": "shootthesound",
              "text": "lora support added, new workflow in the folder",
              "score": 1,
              "created_utc": "2025-12-28 23:10:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwb8thi",
          "author": "PinkMelong",
          "text": "tested it. its..... unbelivable franken awesome!",
          "score": 2,
          "created_utc": "2025-12-28 04:28:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwbchcc",
          "author": "reyzapper",
          "text": "first try, sorry nsfw\n\nhttps://i.redd.it/3ltvgezmlv9g1.gif\n\nthe transition is spot on.  \ntwo 5 sec videos with different prompt, same loras, 4 steps.\n\nThe reference image is using zimage.\n\n\\_\\_\n\nask : is there a reason you didn't use wan shift value when generating in \"car racing\" example??",
          "score": 2,
          "created_utc": "2025-12-28 04:54:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbgbf4",
              "author": "Direct-Vehicle2653",
              "text": "The Ferrari is automatic.",
              "score": 13,
              "created_utc": "2025-12-28 05:22:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwbwvvc",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2025-12-28 07:44:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwbzn3n",
                  "author": "reyzapper",
                  "text": "It did, 100% well preserved, You should see my other NSFW test results (canâ€™t post them here lol) that were extended using the same node. The example above looks different because I used a different prompt for the extended part, which is why you see the face changed?? On top of that, the face is far from the camera, and AI model is terrible at preserving a subject face when itâ€™s that further away from the view.",
                  "score": 2,
                  "created_utc": "2025-12-28 08:10:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwddpjl",
          "author": "Perfect-Campaign9551",
          "text": "Did a character experiment [https://www.reddit.com/r/StableDiffusion/comments/1pxt29f/experimenting\\_with\\_freelong\\_the\\_new\\_node\\_for/](https://www.reddit.com/r/StableDiffusion/comments/1pxt29f/experimenting_with_freelong_the_new_node_for/)",
          "score": 2,
          "created_utc": "2025-12-28 15:00:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwel6dr",
          "author": "Ambitious_Speed_2693",
          "text": "Great work on this project! I was wondering,Â is there a method to regenerate a specific middle chunk without re-running the entire workflow?",
          "score": 2,
          "created_utc": "2025-12-28 18:37:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwezqs2",
          "author": "Direct-Vehicle2653",
          "text": "Is the *Scale Image to Total Pixels* node necessary? I think this is what causing my errors. Can I just adjust the resolution manually on every Chunk and delete the Get\\_width and height nodes? I know what works for my hardware, and this total pixel calculation I have to do is throwing me off. Also, can I do a random seed for the High noise sampler?",
          "score": 2,
          "created_utc": "2025-12-28 19:46:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwhuwwn",
          "author": "StacksGrinder",
          "text": "Hi, I have downloaded the workflow yesterday, did some modifications,\n\n\\- Added SVI 2.0 Loras  \n\\- Replaced WanVideo Node with PainterI2V node.  \n\\- Added Color Match node on each chunk (target first frame to avoid color degradation)  \n\\- Added CleanVRAM Node on each chunk as I was getting OOM errors.  \n\\- Added High/Low Loras on each chunk to guide the video (NSFW)  \n\\- Changed the WAN2.2 14B KJ models (Smooth / Slow)\n\nAnd yet, I. couldn't get the face consistency :(\n\nMore tests are ongoing.",
          "score": 2,
          "created_utc": "2025-12-29 05:08:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnqwts",
              "author": "Ramdak",
              "text": "Did similar tests with all these long video stuff. The issue with consistency is that each chunk uses the previous chunk's frames as refference. Without a lora we won't be seeing any consistency, the model doesn't know how the original character/stuff looks.   \nAlso anything that's not directly visible will be different each time it comes on screen, for example a character's eye color, or an environment detail.\n\nAt least quality degradation is improved a little, I was testing these RCM loras: [https://www.reddit.com/r/StableDiffusion/comments/1o67ntj/new\\_wan\\_22\\_i2v\\_lightx2v\\_loras\\_just\\_dropped/](https://www.reddit.com/r/StableDiffusion/comments/1o67ntj/new_wan_22_i2v_lightx2v_loras_just_dropped/)",
              "score": 2,
              "created_utc": "2025-12-30 02:24:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw9z02u",
          "author": "Tystros",
          "text": "is it expected that this significantly lowers the generation speed? I see that in your car workflow, on the high noise sampler (which has the FreeLong node applied), I get a speed of \\~13.5 s/it, while on the low noise sampler (which does not have the FreeLong node applied) I get 4.5 s/it. if I disable the FreeLong node, the high noise sampler also has a speed of 4.5 s/it. Using a RTX 5090 with sage attention. So currently the FreeLong node increases the time per step by 3x?",
          "score": 1,
          "created_utc": "2025-12-27 23:55:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw9zvbs",
              "author": "shootthesound",
              "text": "Yes it does for me too, tis a trade off of the calculations.  Adjusting the settings in the freelong node can mitigate.  Also building a scene block by block, and not having to re-do earlier scenes, somewhat cancels out a lot of the speed concerns for some use cases.",
              "score": 2,
              "created_utc": "2025-12-28 00:00:01",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwdzmnz",
              "author": "shootthesound",
              "text": "added gguf options etc - see v 2 workflow after you update",
              "score": 1,
              "created_utc": "2025-12-28 16:53:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwe6vgj",
                  "author": "Tystros",
                  "text": "thanks, but do you think that should improve anything about speed? in general, GGUF reduces speed compared to just using fp8",
                  "score": 1,
                  "created_utc": "2025-12-28 17:29:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwfkoux",
              "author": "StuccoGecko",
              "text": "yeah im on a 3090 and i decrease dimensions and length and either way it takes a lonnng time to gen even when using like, 3 chunks only.",
              "score": 1,
              "created_utc": "2025-12-28 21:28:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwg4tzs",
              "author": "shootthesound",
              "text": "Pushed some VRAM fixes to lower vram usage and a speed increase",
              "score": 1,
              "created_utc": "2025-12-28 23:10:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwacxbk",
          "author": "Bender1012",
          "text": "Excited to try this. What's the easiest way to disable some of the chunks, just to run a quicker test say with only 3 chunks?",
          "score": 1,
          "created_utc": "2025-12-28 01:14:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwaehio",
              "author": "shootthesound",
              "text": "https://preview.redd.it/wvig7lrdku9g1.png?width=2246&format=png&auto=webp&s=beab79bea215ecf879d69280326977226066bf1d",
              "score": 1,
              "created_utc": "2025-12-28 01:24:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwao0xx",
                  "author": "Bender1012",
                  "text": "Cool, that was my first instinct but I wasn't sure it could handle it gracefully. \n\nLooks like I got an OOM error during chunk 3 or so, yet the workflow kept going? Does it just consider that chunk done and move onto the next one?",
                  "score": 1,
                  "created_utc": "2025-12-28 02:20:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwfkr8d",
                  "author": "StuccoGecko",
                  "text": "you can just highlight the ones you don't need and bypass.",
                  "score": 1,
                  "created_utc": "2025-12-28 21:28:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwb3x5m",
          "author": "StacksGrinder",
          "text": "wow! I thought you said in a few days, this is was fast ! Thanks, will test in few hours.",
          "score": 1,
          "created_utc": "2025-12-28 03:56:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwbvtha",
          "author": "Better-Interview-793",
          "text": "Great work! thank you!!",
          "score": 1,
          "created_utc": "2025-12-28 07:34:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwbxnv5",
          "author": "gj_uk",
          "text": "I was very excited to try this, but I get torch.OOM errors (allocation on device) right after the first chunk even though Iâ€™m using a 32GB 5090 and 64GB system RAM. Every time.",
          "score": 1,
          "created_utc": "2025-12-28 07:51:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwg4ps6",
              "author": "shootthesound",
              "text": "Pushed some VRAM fixes to lower vram usage and a speed increase",
              "score": 2,
              "created_utc": "2025-12-28 23:10:22",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwc72wn",
              "author": "shootthesound",
              "text": "Thatâ€™s the same spec Iâ€™m on - what image size you using after scaling ? You could also swap the high model out for GGUF",
              "score": 1,
              "created_utc": "2025-12-28 09:22:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwfb28r",
                  "author": "gj_uk",
                  "text": "Thanks for replying. I had been trying slightly higher resolutions (with WAN 2.2 I usually do 1280 x 720 without the LoRAs for quality over speed) but it seems anything over 864x480 fails after generating the first regular Chunk.\n\nSince posting last night I have been able to replicate your original video (aside from the â€˜show the rear of the carâ€™ making the car suddenly morph into the back end and start driving in the other direction!â€¦but Iâ€™m aware that that stuff is all in the prompting).\n\nI certainly donâ€™t want to sound ungrateful. Iâ€™m very impressed, and appreciate what youâ€™re doing, and how involved youâ€™ve been in following up with people here.\n\nIf Iâ€™m able to solve for larger resolutions somehow Iâ€™ll let you know. 480 can be a bit small for my applicationâ€¦the vertical resolution is a little limiting and Iâ€™ve yet to find a decent upscale workflow that enhances the original enough to avoid moire issues just being amplified. \n\nKeep up the good work.",
                  "score": 2,
                  "created_utc": "2025-12-28 20:41:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwdzgdq",
                  "author": "shootthesound",
                  "text": "added gguf options etc - see v 2 workflow after you update",
                  "score": 1,
                  "created_utc": "2025-12-28 16:52:35",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwccqua",
          "author": "turtlefeelz",
          "text": "Thanks for the work!\n\nCould you add a color matching for the each segment, i noticed color morphing in the last 2/3 clips.",
          "score": 1,
          "created_utc": "2025-12-28 10:17:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwdzdb8",
              "author": "shootthesound",
              "text": "done! - see v2 workflow in the node after you update",
              "score": 1,
              "created_utc": "2025-12-28 16:52:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwdnu3z",
          "author": "fruesome",
          "text": "Thanks for sharing, i got it to work but 2nd part didn't come out good because it lost character consistency and got blurry.\n\nIs it possible to have start and end frame for all the chunks?",
          "score": 1,
          "created_utc": "2025-12-28 15:54:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwdryl1",
          "author": "hurrdurrimanaccount",
          "text": "what's the advantage this has over traditional context windows? i'm not really seeing much of a difference tbh",
          "score": 1,
          "created_utc": "2025-12-28 16:15:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwdwuys",
          "author": "marres",
          "text": "Very nice. But what is the reasoning for using spectral blend only on the high noise model?",
          "score": 1,
          "created_utc": "2025-12-28 16:39:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwdz2aj",
              "author": "shootthesound",
              "text": "Having read the paper and testing, its of almost no benefit on low noise",
              "score": 2,
              "created_utc": "2025-12-28 16:50:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwe134z",
                  "author": "marres",
                  "text": "Gotcha, thanks for the quick reply. Also I've just noticed that you are passing the anchor\\_latent to Chunk 2 but then not using it? Is this a remnant of trying to pass the latent instead of the image?",
                  "score": 1,
                  "created_utc": "2025-12-28 17:00:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwerh45",
          "author": "Spare_Ad2741",
          "text": "very nice. sample wf works well. been looking for something like this for a while. thankyou so much.",
          "score": 1,
          "created_utc": "2025-12-28 19:06:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwff9qj",
          "author": "StuccoGecko",
          "text": "First, thank you for this, we're lucky that people continue to create and share tools like this for free here!\n\nSecond, I should preface this post by saying, all my issues with this may be due to my own bonehead ignorance...happens quite a bit.\n\nAnywho...I was able to get this to work (as in, I was able to complete a generation in full), however I'm having trouble determining if the intended result is actually working consistently enough to say that this \"works\".\n\nI tested several images and different settings, particularly in the Spectral Blend node, yet the transition between Chunk 1 and Chunk 2 does not seem very seamless at all 80% of the time, in fact, more often times I'm seeing direction of motion completely reverse even worse than if I were to simply chain together 2x of the the base Wan 2.2 I2V workflows to feed second to last frame into the second chain.\n\nA couple things I tried:\n\n\\- higher local window frames: I tested 30%, 50% 80% and even 100%...not getting any consistency either way  \n\\- playing with seed numbers: tested using the same fixed seeds across samplers for low and high pass, randomized, a mix of the two....doesn't quite matter, the result is...kinda meh.\n\n\\- Different dimensions: tried lowering this and raising between 1080p down to like 640p....looks like the lower resolutions really delivered the worse results\n\nEager to keep an eye on the thread here to hear everyone else's experience and how they are getting the most out of this...for now, I'm not sure if it's reliable for use (or of course, a user error somewhere where I am causing the issue).\n\n  \nAll that gloom and doom aside, I do plan to continue following and supporting OP, this is cool stuff at the end of the day",
          "score": 1,
          "created_utc": "2025-12-28 21:01:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfum3z",
          "author": "Radiant-Photograph46",
          "text": "Was looking forward to this, thank you for your hard work. The smoothness of the transitions between chunks is pretty good, but as was noted by others inference speed takes a big hit, times 2 minimum. I'm willing to pay that price but I have a much bigger issue however. \n\nI've noticed odd drifts in the motion, even on the very first chunk, with elements morphing like Michael Jackson's Black & White clip (yes I'm old), which I've never experienced with base Wan. I suppose it is necessary to play with some the spectral blend parameters yes? I can't help but notice that your recommended defaults are quite different from the values you've used in the car example workflow.",
          "score": 1,
          "created_utc": "2025-12-28 22:17:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwg1fbo",
          "author": "Training_Fail8960",
          "text": "Transitions are great, but i am unable to run in res2\\_ode, beta57 and the fp16 for high and low for 14B wan.. too much? :) gonna try with Q8.",
          "score": 1,
          "created_utc": "2025-12-28 22:52:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwg4ikg",
              "author": "shootthesound",
              "text": "**Pushed some VRAM fixes to lower vram usage and a speed increase**",
              "score": 2,
              "created_utc": "2025-12-28 23:09:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwg6rr0",
          "author": "_chromascope_",
          "text": "This works! Thank you for sharing. However, like others pointed out, human consistency starts to drift after chuck 3. \n\nIs it possible to implement an \"end\" anchor image in the Continuation Conditioning node? So that we have an option to control each chunk's end frame with a prepared image (same idea as the First-Last-Frame, but for each chunk), which then can also be used as the anchor image of the next chunk?",
          "score": 1,
          "created_utc": "2025-12-28 23:21:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwg94jz",
              "author": "shootthesound",
              "text": "For characters, Loras are key, as these are separate generations remember.  And good idea on the end image, i'll look at that asap",
              "score": 2,
              "created_utc": "2025-12-28 23:34:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwiybdg",
          "author": "todschool",
          "text": "I semi-always get hallucinations either in the first chunk, or second. I don't understand why, I'm changing nothing, except for removing the safetensor loaders and using GGUF loaders. I'm pretty new to this, so am I doing something dumb? But then again, I'm not even changing anything really.\n\nThought it was fixed for a while, then the problem came back. Always just noise at second chunk onwards.\n\nhttps://preview.redd.it/rjfju4oyi4ag1.png?width=3558&format=png&auto=webp&s=1c4e0b6a3cc6b68fe8901ff80b02ab1a08206e81",
          "score": 1,
          "created_utc": "2025-12-29 10:54:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwks03a",
          "author": "Dreamgirls_ai",
          "text": "Thanks man for providing your amazing work for free! We really appreciate everything you do for this community! I tested the workflow and I wondered how can I only run two or three clips instead of all of them? For me, 10 or 15 second videos would be enough for the moment. Is there an easy way? I tried bypassing some of the nodes, but it executed all of them anyway haha",
          "score": 1,
          "created_utc": "2025-12-29 17:23:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nworkhp",
          "author": "boobkake22",
          "text": "I was curious if you tried to do anything with injecting multiple frames into the latent for continuation node? (I'm also looking for simpler solutions for this problem.)",
          "score": 1,
          "created_utc": "2025-12-30 06:16:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwspn0v",
          "author": "gquizal",
          "text": "this is awesome.  how would this work if you want to apply different loras at each chunk creation phase?",
          "score": 1,
          "created_utc": "2025-12-30 20:55:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwss4g6",
              "author": "shootthesound",
              "text": "thats already in the lastest version in the nodepack",
              "score": 2,
              "created_utc": "2025-12-30 21:06:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwtcnza",
          "author": "artisst_explores",
          "text": "added svi-wan2.2 lora to this and consistency increased quite a bit!",
          "score": 1,
          "created_utc": "2025-12-30 22:45:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtg0ob",
              "author": "shootthesound",
              "text": "Oh can you brief me or send a workflow to peter@ShootTheSound.com ? Love to have a look !!",
              "score": 1,
              "created_utc": "2025-12-30 23:03:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwu4s1q",
                  "author": "artisst_explores",
                  "text": "In your updated workflow, {car racing example v2}, i aactivated all the lora loaders and just loaded svi high and low loras that dropped for wan 2.2. i was testing complex subject , the results were way off before, now much much cohesive. i didnt do any changes inthe wf than to activate and select loras.",
                  "score": 1,
                  "created_utc": "2025-12-31 01:20:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwtk2ki",
              "author": "shootthesound",
              "text": "Did you need to add the wan image to video svi node ?",
              "score": 1,
              "created_utc": "2025-12-30 23:25:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwu7eiw",
          "author": "Dzugavili",
          "text": "5070TI, 16GB VRAM, 64GB RAM. It's solid hardware, but nothing exotic.\n\n[Edit: *TL;DR: Consistency and prompt adhesion isn't great -- my muscle car kept getting transformed into a Ferrari -- but the speed is alright. Hallucinations aplenty. As yet unclear to me if motion continuity is maintained: I was trying out some heavy quants to keep generation times down, and it wasn't fantastic. Still experimenting.*]\n\n[Edit: *TL;DR: reducing weight of speed lora helps strongly with hallucinations, motion doesn't seem to suffer, but will need to do more case testing.*]\n\n[Edit: *TL;DR: made it to chunk six before my car lost identity. Cars really need loras to maintain identity, is what I think I'm seeing.*]\n\nI've been trying to get this to work, but I keep running into bugs. I've updated everything at this point, I get:\n\n~~ModelSamplingSD3~~\n\n~~'NoneType' object has no attribute 'clone'~~\n\nOkay, bypassed the gguf switcher got rid of those. But now:\n\n~~>KSamplerAdvanced~~\n\n~~>[Errno 22] Invalid argument~~\n\nNot really sure...\n\nReboot might have fixed it, let's see...\n\nEdit:\n\nSeems very slow so far; might need to use heavier quants. Or I need to do a true reboot before this, but I'm looking at 15 minutes for the first part, when that should be close to 3 mins at the outside.\n\nEdit:\n\nFirst 81 frames in 8 minutes. Should have been faster.\n\nEdit:\n\nChunk one: 170s/it; chunk two, 26s/it. What's going on?\n\nEdit:\n\nI think I need to turn on that memory purge node. Seems to be choking on VAE.\n\nI'm 26min in, and I'm still on chunk 3. I should be done by now...\n\nEdit:\n\nAborted, did a hard reboot. Replaced my Q5s with Q3s and I'm flying now. I should retry the Q5s.\n\nEdit:\n\nDeep quant halucinated a licence plate. But it is very fast now. 30s/it.\n\nEdit:\n\nYeah, maybe my quants are too far, it's not following the prompts at all. But it's still hilarious.",
          "score": 1,
          "created_utc": "2025-12-31 01:35:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwthy4i",
          "author": "PestBoss",
          "text": "I'm struggling to install this.\n\nI've done a git clone, downloaded the folder manually, and saved each file separately, into the appropriate custom_nodes folder, but ComfyUI doesn't show it. Nowhere in the menus, if I load the workflow it's missing, etc.\n\nIt shows it as a loaded node in the list while loading in the command prompt window so knows it's there.\n\n\nWhen I tried using the CUI manager to git clone it that way, it said I need to change my security setting.\nI can't see this node pack via the manager to install it.\n\nIs this why my ComfyUI isn't showing the node as installed, somehow it's blocking it being loaded? Or am I installing it wrong?\n\n\nHave you recently merged two projects into one, longlook and freelong? Maybe it's getting confused at the ComfyRegistry end and needs time to update before letting me grab a copy?",
          "score": 0,
          "created_utc": "2025-12-30 23:13:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pvehhs",
      "title": "Game of Thrones - Animated",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1pvehhs",
      "author": "CPU_Art",
      "created_utc": "2025-12-25 14:28:59",
      "score": 223,
      "num_comments": 32,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "No Workflow",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pvehhs/game_of_thrones_animated/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nvvt7t3",
          "author": "Major_Assist_1385",
          "text": "Nice Generations. What model you use ?",
          "score": 13,
          "created_utc": "2025-12-25 15:51:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvvsr6",
              "author": "eskimopie910",
              "text": "Certainly one trained on the style of â€œArcaneâ€",
              "score": 44,
              "created_utc": "2025-12-25 16:06:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvw3a3x",
              "author": "CPU_Art",
              "text": "Flux 1 Dev model and Arcane style LORA.",
              "score": 19,
              "created_utc": "2025-12-25 16:51:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvxh1rh",
          "author": "physalisx",
          "text": "You know what \"animated\" means right? This is not it.",
          "score": 11,
          "created_utc": "2025-12-25 21:49:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3temw",
              "author": "Whispering-Depths",
              "text": "Yeah IMO title should have been \"random GoT characters in Arcane show artstyle\"",
              "score": 1,
              "created_utc": "2025-12-26 23:43:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvvpubm",
          "author": "protector111",
          "text": "https://preview.redd.it/u2fbxjbmcd9g1.jpeg?width=452&format=pjpg&auto=webp&s=e352a6d5bb2da96ff519e004b998fee1cac1522f",
          "score": 6,
          "created_utc": "2025-12-25 15:30:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvw36d6",
              "author": "CPU_Art",
              "text": "Remember playing the first part of the game and really liking it :)",
              "score": 1,
              "created_utc": "2025-12-25 16:51:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvxobx6",
          "author": "Merijeek2",
          "text": "...almost all with elf ears.",
          "score": 5,
          "created_utc": "2025-12-25 22:34:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvlqdn",
          "author": "DoubleNothing",
          "text": "Looks pretty still and non animated to me...",
          "score": 22,
          "created_utc": "2025-12-25 15:04:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvzuqh",
          "author": "saito200",
          "text": "they all look like the same character",
          "score": 20,
          "created_utc": "2025-12-25 16:31:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvwyag4",
              "author": "exomniac",
              "text": "Half of them are siblings",
              "score": 10,
              "created_utc": "2025-12-25 19:54:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvx6072",
              "author": "fukijama",
              "text": "Its a Tyler Perry comedy",
              "score": 1,
              "created_utc": "2025-12-25 20:41:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvxy9db",
          "author": "Outrageous-Welder800",
          "text": "\"Arcane style\"",
          "score": 3,
          "created_utc": "2025-12-25 23:38:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvqtpi",
          "author": "luciferianism666",
          "text": "\"animated\"",
          "score": 10,
          "created_utc": "2025-12-25 15:36:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvkje3",
          "author": "a_saddler",
          "text": "Damn, no wonder Bobby B crushed Rhaegar's heart with one blow. What an absolute unit.",
          "score": 2,
          "created_utc": "2025-12-25 14:56:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvlsq7",
              "author": "CPU_Art",
              "text": "Gods, he was strong then!\n\nI tried to focus the characters to how they are in Book 1/ Season 1, but for him I thought this look was too cool. And there still is some weight on him.",
              "score": 1,
              "created_utc": "2025-12-25 15:04:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvxnta6",
                  "author": "Soft-Luck_",
                  "text": "It stayed closer to the HBO series than the books; for example, their ages are different.",
                  "score": 1,
                  "created_utc": "2025-12-25 22:31:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvvq36i",
          "author": "Alanovski7",
          "text": "Nice!",
          "score": 2,
          "created_utc": "2025-12-25 15:31:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw07yjq",
          "author": "solomars3",
          "text": "If you do img2img using same workflow , but with a low denoise , you might be able to turn some scenes from the series to cool anime like style, its ez just add a lozd image node with vae encode/decode",
          "score": 2,
          "created_utc": "2025-12-26 10:37:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0c1km",
              "author": "CPU_Art",
              "text": "Cool idea, might be something I try.\n\nThe only issue I might have is that the LORA is locked to a certain resolution/ aspect ratio. All of these character images are made in the dimensions that the lora is trained on.  \nThere might be a way to work around that though, not sure/ knowledgeable enough yet.",
              "score": 1,
              "created_utc": "2025-12-26 11:18:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw0xh8p",
                  "author": "solomars3",
                  "text": "Nah its okay, resolution doesnt matter, if the lora is trained on style, it will still give the style effect even on different resolutions, people train lora on 512 x 512 and still make 4k images with same lora",
                  "score": 2,
                  "created_utc": "2025-12-26 14:10:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvwqno6",
          "author": "nowrebooting",
          "text": "This looks like one of those â€œoh no, the mother and child are so cold, buy a fireplace for themâ€ mobile games",
          "score": 2,
          "created_utc": "2025-12-25 19:08:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvygg40",
          "author": "Hot_Substance4459",
          "text": "How do you get it to style transfer it on the characters so closely? Do you use charachter loras?Â ",
          "score": 1,
          "created_utc": "2025-12-26 01:37:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw01yzx",
              "author": "CPU_Art",
              "text": "The style comes entirely from the LORA model.",
              "score": 2,
              "created_utc": "2025-12-26 09:35:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw02dbh",
                  "author": "Hot_Substance4459",
                  "text": "Is this just text to image?Â ",
                  "score": 1,
                  "created_utc": "2025-12-26 09:40:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvw063v",
          "author": "Sad-Way-Butter1",
          "text": "That's amazing. Does anyone have a workflow for thisðŸ˜",
          "score": -1,
          "created_utc": "2025-12-25 16:33:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvw2zyp",
              "author": "CPU_Art",
              "text": "I used ComfyUI and the workflow is a simple TXT to IMG with Flux 1 Dev model and an 'Arcane' style LORA.\n\nPrompts were in part generated with ChatGPT and in part edited by me.",
              "score": 2,
              "created_utc": "2025-12-25 16:50:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvw8szb",
                  "author": "Sad-Way-Butter1",
                  "text": "Thank you.ðŸ˜ I get scared when using flux, I still wait a long time when generating one imageðŸ˜…",
                  "score": 1,
                  "created_utc": "2025-12-25 17:25:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvwkj20",
          "author": "NanoSputnik",
          "text": "I duuno. They don't look like Arcane to me. More like generic mobile game garbage from India.",
          "score": -4,
          "created_utc": "2025-12-25 18:33:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzdjg0",
      "title": "Tencent HY-Motion 1.0 - a billion-parameter text-to-motion model",
      "subreddit": "StableDiffusion",
      "url": "https://hunyuan.tencent.com/motion?tabIndex=0",
      "author": "Aggressive_Collar135",
      "created_utc": "2025-12-30 09:13:36",
      "score": 211,
      "num_comments": 58,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pzdjg0/tencent_hymotion_10_a_billionparameter/",
      "domain": "hunyuan.tencent.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwqb5kn",
          "author": "momono75",
          "text": "Does this mean we can generate source animations for SCAIL now?",
          "score": 14,
          "created_utc": "2025-12-30 13:56:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwv4ydw",
              "author": "One-UglyGenius",
              "text": "Yea ðŸ˜‚",
              "score": 4,
              "created_utc": "2025-12-31 05:01:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwples2",
          "author": "JohnSnowHenry",
          "text": "Whaaattttt? \n\nAnd itâ€™s also the end for animators everywhere ðŸ˜‚\n\nIâ€™m going back to school and learn something like carpentry or something totally manual since robots will still take some decades to get there ðŸ˜‚",
          "score": 30,
          "created_utc": "2025-12-30 10:47:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwpv1n5",
              "author": "niknah",
              "text": "1. Generate picture. \n2. Picture to 3d workflow(like Hunyuan 3d).  \n3. Send to 3d printer with wood filament.",
              "score": 20,
              "created_utc": "2025-12-30 12:09:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwqe41h",
                  "author": "shivdbz",
                  "text": "Wood filament exist?",
                  "score": 2,
                  "created_utc": "2025-12-30 14:13:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwrkza7",
              "author": "_half_real_",
              "text": "Mocap wasn't the end for animators, although it did reduce the amount of work needed to be done by them. I'd expect the same from generated motion.",
              "score": 7,
              "created_utc": "2025-12-30 17:43:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwrlqi6",
                  "author": "JohnSnowHenry",
                  "text": "Mocap gives work not only to animators but also to the professionals paid by the hour to wear the suit and do the motions. Itâ€™s a tool that helps but still requires a lot of cleaning. \n\nAI is not only helping, is doing several tasks 100% alone already. Animators will continue to exist of course, but itâ€™s the same for programmers, designers and everything else, teams of 10 now can have just 2 or 3 (my team were 5 guys and now itâ€™s just me because of the AI)",
                  "score": 2,
                  "created_utc": "2025-12-30 17:47:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwq3uot",
              "author": "grmndzr",
              "text": "I talked to my plumber recently and he said even he is starting to lose work to automation for big jobs where things are taken care of by machines. I bet those shitty robo butlers will be able to do plumbing work in your house in less than ten years. no job is safe",
              "score": 3,
              "created_utc": "2025-12-30 13:12:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwqkma0",
                  "author": "kemb0",
                  "text": "Human: Hey bot, can you fix my leaking tap?\n\nAI Robot: Sure let me just do that.\n\n20 minutes later\n\nHuman: So err now my gas is coming out of my tap? That doesn't seem right.\n\nAI Robot:That's right, you're very clever to say that. You want the water to come out the tap.\n\nHuman: Ok so, can you fix that?\n\nAI Robot: Sure\n\n40 minutes later\n\nHuman: Err hey bot, why are you knocking down my wall? I asked you to fix the tap.\n\nAI Robot: That's correct. You are very observant. You shouldn't need to knock down a wall to fix a leaking tap. You probably shouldn't have done that.\n\nHuman: I didn't do that, you did.\n\nAI Robot: That is a correctly deduced point that it seems I may have knocked down the wall without your consent. Would you like me to fix your tap?\n\nHuman: Don't worry, I'll just call a plumber.\n\nPlumber: Hello, you are very smart for calling the plumber and indeed your leaking tap does sound like it needs fixed. I can schedule your home AI bot to do that for you. Have a nice day.",
                  "score": 12,
                  "created_utc": "2025-12-30 14:49:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwqhx0l",
                  "author": "qrayons",
                  "text": "Also probably losing smaller jobs as well. I've personally been using ai to walk me through diy stuff that in the past I would have called someone for.",
                  "score": 5,
                  "created_utc": "2025-12-30 14:34:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwtdnfj",
              "author": "peabody624",
              "text": "Robots will be able to do anything a human can before 2030",
              "score": 1,
              "created_utc": "2025-12-30 22:51:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwtmkcs",
                  "author": "JohnSnowHenry",
                  "text": "Even if they do, since at the moment no one can still buy not even one that do basic stuff, itâ€™s clear they are still a long way from bring mass produced",
                  "score": 1,
                  "created_utc": "2025-12-30 23:39:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwul3zt",
                  "author": "Ylsid",
                  "text": "I wish",
                  "score": 1,
                  "created_utc": "2025-12-31 02:55:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwubprm",
              "author": "Arawski99",
              "text": "Breaking news.\n\nFinely detailed affordable and structurally sound 3D printing available for construction projects near you! SoonTM\n\nJokes aside, they're already owning farming work, warehouse work, printing, and many other types of physical labor. I don't think it will take decades. We're all pretty much boned.",
              "score": 1,
              "created_utc": "2025-12-31 02:00:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwukxpo",
              "author": "Ylsid",
              "text": "Depends if you think animating is about making skeletons move or not",
              "score": 1,
              "created_utc": "2025-12-31 02:54:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwq8qzc",
              "author": "neofuturo_ai",
              "text": "almost 100% of jobs can and will be replaces by robots, next jobs will be ( i assume) managing those robots  .. not carpentry",
              "score": 1,
              "created_utc": "2025-12-30 13:42:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwqecxw",
                  "author": "shivdbz",
                  "text": "CEO job too? Presidential jobs too?",
                  "score": 1,
                  "created_utc": "2025-12-30 14:14:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwq9i1c",
                  "author": "JohnSnowHenry",
                  "text": "I agree, but like I said in the previous comment, not in 10-20 years time (where my comment was focused on). \n\nIn 20 years for sure we will already have robots capable to perform many manual jobs but it will not be available to the vast majority of small companies. Iâ€™m 45yo so I do not worry that much, but for anyone starting now adult life for sure will be a powerful and messy transition.",
                  "score": 0,
                  "created_utc": "2025-12-30 13:46:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpr6ar",
          "author": "Aggressive_Collar135",
          "text": "Also this can be used with a Duration Prediction & Prompt Rewrite Module: [https://huggingface.co/Text2MotionPrompter/Text2MotionPrompter](https://huggingface.co/Text2MotionPrompter/Text2MotionPrompter)\n\nText2MotionPrompter is a large language model fine-tuned for text-to-motion prompt enhancement, rewriting, and motion duration prediction.\n\nGiven a text description of a human action, Text2MotionPrompter will:\n\n* reorganize the key motion information into a more readable structure;\n* make implicit motion attributes explicit (e.g., subject, pose, tempo, temporal order, and spatial relations);\n* improve logical consistency and reducing ambiguity or conflicting constraints;\n* predict a plausible motion duration for the described action.",
          "score": 6,
          "created_utc": "2025-12-30 11:38:04",
          "is_submitter": true,
          "replies": [
            {
              "id": "nwqeml5",
              "author": "neofuturo_ai",
              "text": "this is not that large model (1B) and doing the same job",
              "score": 1,
              "created_utc": "2025-12-30 14:16:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwtqwse",
                  "author": "Aggressive_Collar135",
                  "text": "its part of the pipeline. you have to disable it if you are not running the module",
                  "score": 1,
                  "created_utc": "2025-12-31 00:03:16",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwqeoyj",
          "author": "suspicious_Jackfruit",
          "text": "\"Prompt: While gesturing wildly forward, he looked left and right.\"\n\nVideo = Walking forward semi normally while looking left and right.\n\nGesturing wildly doesn't mean walking normally...\n\nThese Chinese models are always gimped with bad English. If they can't get their prompts correct why would I have any trust that their English training data is captioned correctly either",
          "score": 9,
          "created_utc": "2025-12-30 14:16:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwv4xo0",
              "author": "redditscraperbot2",
              "text": "Well, like most things the best results come from trying it yourself. Iâ€™m impress with the outputs Iâ€™m getting on my 3090",
              "score": 1,
              "created_utc": "2025-12-31 05:01:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwrvyid",
          "author": "Comification",
          "text": "ComfyUI support when.",
          "score": 3,
          "created_utc": "2025-12-30 18:33:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpo09e",
          "author": "Facrafter",
          "text": "I'd love to see how this compares to proprietary alternatives like [move.ai](http://move.ai) . The latter has actually been used in AA video game production, though the developers claimed the animation still required cleanup to be useful.",
          "score": 6,
          "created_utc": "2025-12-30 11:10:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwq6j0c",
              "author": "redditscraperbot2",
              "text": "I've been tinkering with it for the last two hours and it's really good. But like even with raw motion capture, it needs manual cleanup. That being said, it's really good.",
              "score": 3,
              "created_utc": "2025-12-30 13:28:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwq6d4g",
              "author": "neofuturo_ai",
              "text": "no.. this is text to motion model, [move.ai](http://move.ai) trace the move from input video i think",
              "score": 2,
              "created_utc": "2025-12-30 13:27:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpr0ar",
          "author": "Odd-Mirror-2412",
          "text": "Wow, this is a big!",
          "score": 4,
          "created_utc": "2025-12-30 11:36:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwpss7w",
              "author": "nospotfer",
              "text": "It's actually quite small... ~4GB only, and ~1GB the lightweight version.",
              "score": 12,
              "created_utc": "2025-12-30 11:51:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwqddic",
                  "author": "Striking-Long-2960",
                  "text": "I tried to install it, the gradio version, but it requires Qwen 3 8B. I hope some genius makes it GGUFâ€‘compatible.",
                  "score": 1,
                  "created_utc": "2025-12-30 14:09:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwq52f9",
              "author": "Healthy-Nebula-3603",
              "text": "Billion is around 1 GB in fp4 ... That's very small model",
              "score": 2,
              "created_utc": "2025-12-30 13:19:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpr3zj",
          "author": "JohnSnowHenry",
          "text": "All motion tracking through cameras (move.ai and all the other dozens of companies) requires A LOT of cleaning. \n\nJust from the examples itâ€™s easy to see the cleaning will be a lot less this way. \n\nHappy times for Indies indeed :)",
          "score": 2,
          "created_utc": "2025-12-30 11:37:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwq9ply",
          "author": "hurrdurrimanaccount",
          "text": "cool. so can someone explain what it actually does?",
          "score": 7,
          "created_utc": "2025-12-30 13:47:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrpx8j",
              "author": "_half_real_",
              "text": "You put in a text prompt and it generates keyframed animation data (rotation and position of the bones for each frame) for their specific rigged 3D model, that follows your prompt (in theory).\n\nIt does NOT generate a 3D model.\n\nIt does NOT generate a video like Wan or Grok does, it just shows you a 3D scene with the generated animation data applied to their specific 3D rigged human model.\n\nYou CANNOT change the model that the animation is generated for, you'd need to *retarget* the animation data afterwards with some other method.\n\nRetargeting is when you modify animation so it works with a different rigged 3D model with different bone lengths - say you have some mocapped animation made by a tall person, but you want to animate a short goblin with it. This can be largely automated but normally might need some manual work. There are newer machine learning methods that can automate it more these days.",
              "score": 6,
              "created_utc": "2025-12-30 18:06:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwrl4iq",
              "author": "physalisx",
              "text": "It's explained right there in the first paragraph on the project page. \n\nCome on, you can do the one click, I believe in you.",
              "score": 1,
              "created_utc": "2025-12-30 17:44:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwq2fcv",
          "author": "obraiadev",
          "text": "I had high expectations for some of my projects.",
          "score": 2,
          "created_utc": "2025-12-30 13:03:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqy025",
          "author": "Noeyiax",
          "text": "Pretty good ooo, not super good, but great for prototype or indie , thank you ðŸŽ‰ \n\nTried just fingers and hand motions, somehow pair with facial capture is interesting in UE5 or unity. At least cheaper option than mocap",
          "score": 2,
          "created_utc": "2025-12-30 15:56:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwtojhu",
          "author": "Nooreo",
          "text": "Can I make 3D scenes from hentai videos?",
          "score": 1,
          "created_utc": "2025-12-30 23:50:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwuuma0",
          "author": "Ylsid",
          "text": "Welp, guess I'm waiting for a comfyui release because the dependency hell here is real",
          "score": 1,
          "created_utc": "2025-12-31 03:53:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwr8i6t",
          "author": "myfairx",
          "text": "Tried to install it. stop when it downloading qwen8b model. Check the MD and apparently it needed that as encoder? I'm kinda excited because the parameter is only 1b. But needing 8b llm to run this? HmmðŸ˜³. Maybe I'll try again later.",
          "score": 0,
          "created_utc": "2025-12-30 16:45:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqm4vr",
          "author": "Hearcharted",
          "text": "This is insane ðŸ˜² \n\n![gif](giphy|BbJdwrOsM7nTa)",
          "score": -1,
          "created_utc": "2025-12-30 14:57:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1py6it4",
      "title": "(Crypto)Miner loaded when starting A1111",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1py6it4",
      "author": "Woisek",
      "created_utc": "2025-12-28 23:52:41",
      "score": 209,
      "num_comments": 136,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1py6it4/cryptominer_loaded_when_starting_a1111/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwhdhlu",
          "author": "DrStalker",
          "text": "> I deleted that extension and so far, it seems to solve the problem. \n\nDelete your entire A1111 install.  It has been compromised, you have no idea what may or may not have been done other that the bits you have already noticed.\n\nIdeally you'd wipe and recreate your entire PC, but assuming you're not going to do that at least do a good malware scan of the entire system.",
          "score": 118,
          "created_utc": "2025-12-29 03:19:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwin4d6",
              "author": "TechnoByte_",
              "text": "A malware scan is not enough\n\nAlways reinstall your OS, change all your passwords and enable 2FA, freeze your credit card if you used it on that PC, clear all your browser data\n\nAnd always run A1111/ComfyUI inside a docker container, if you don't you will get your data stolen at some point",
              "score": 27,
              "created_utc": "2025-12-29 09:10:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwit256",
                  "author": "Theagainmenn",
                  "text": "For that reason I run it from a WSL2, is that also good? I always shutdown the WSL2 after use.",
                  "score": 1,
                  "created_utc": "2025-12-29 10:06:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwkn9jm",
                  "author": "demonicpigg",
                  "text": "Is there a good running Comfy inside docker guide out there? I found a few several month old docker images, but nothing current. I'd rather not build the container myself, but will if that is the answer.",
                  "score": 1,
                  "created_utc": "2025-12-29 17:01:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwls184",
              "author": "Robot1me",
              "text": ">Ideally you'd wipe and recreate your entire PC\n\nIt's where I don't get why others don't recommend Sandboxie when running such stuff under Windows. Automatic1111 works well inside it. There are such complex chains of dependencies that execute code (especially ComfyUI) that anti-virus programs may flag what is known, but even some simple yet harmful command line commands can easily fly under the radar. So a layer of isolation with permission control is the best one can do outside of virtualization.",
              "score": 4,
              "created_utc": "2025-12-29 20:13:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwmk9dv",
                  "author": "Segaiai",
                  "text": "Can sandboxing give you 100% of your VRAM?",
                  "score": 1,
                  "created_utc": "2025-12-29 22:32:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwgk2p2",
          "author": "AirFlavoredLemon",
          "text": "Extension list please.\n\nAnd how did you install A1111?",
          "score": 78,
          "created_utc": "2025-12-29 00:31:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwgqnhu",
              "author": "Woisek",
              "text": "I re-checked and found another extension, not installed by me:  \nsd-colab-commands-browser\n\nNever heard of this, never needed that. I deleted it.\n\nA1111 install was done by cloning and then pip install the requirements. More than a way over a year ago now, perhaps 2.\n\nhttps://preview.redd.it/twwbkmb1m1ag1.png?width=1012&format=png&auto=webp&s=574f4820b014b8b52dc631ccc9e574500c1dc53b\n\nSome extensions are disabled.",
              "score": 43,
              "created_utc": "2025-12-29 01:07:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwgtbvq",
                  "author": "noyart",
                  "text": "https://github.com/Iyashinouta/sd-colab-commands-browser/issues/1\n\n\nAlready brought up in feb for the colab extensionÂ ",
                  "score": 67,
                  "created_utc": "2025-12-29 01:23:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwgvkrf",
                  "author": "noyart",
                  "text": "OP it could be time to wipe your A1111 install ðŸ’€",
                  "score": 51,
                  "created_utc": "2025-12-29 01:36:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwgto8u",
                  "author": "noyart",
                  "text": "Maybe there is another extension then that downloads colab that then starts downloading the minerÂ ",
                  "score": 17,
                  "created_utc": "2025-12-29 01:25:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwigkbn",
                  "author": "Toupeenis",
                  "text": "If it's still possible you should check your queue history for workflows that ran at that time. Better than a coinflip chance you find someone accessing your comfy remotely and installing these nodes for further access. Make sure your ports are locked way the fuck down.",
                  "score": 5,
                  "created_utc": "2025-12-29 08:08:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwgvfx1",
              "author": "noyart",
              "text": "https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/13923",
              "score": 16,
              "created_utc": "2025-12-29 01:35:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwig4sj",
              "author": "Toupeenis",
              "text": "Just FYI if I had to bet $1000 i'd say it's just a port sniffing attack. Bitcoin mining hackers sniff 8188 because they know if they find one there is a tasty GPU accessible to the public, they then install the nodes they need to probe the machine and install the software. Later on they ping it and initiate the mining.",
              "score": 9,
              "created_utc": "2025-12-29 08:05:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwimtxz",
                  "author": "Woisek",
                  "text": "My A1111 runs on 7861.",
                  "score": 0,
                  "created_utc": "2025-12-29 09:07:44",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwgh71s",
          "author": "Dezordan",
          "text": "\"from somewhere\" is a bit ambiguous. There is a possibility that someone got access either to A1111 or your PC, then installed it remotely.",
          "score": 64,
          "created_utc": "2025-12-29 00:16:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwgtdme",
              "author": "noyart",
              "text": "https://github.com/Iyashinouta/sd-colab-commands-browser/issues/1",
              "score": 30,
              "created_utc": "2025-12-29 01:23:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwgvdx7",
              "author": "noyart",
              "text": "https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/13923\nPeople discussing the problemÂ ",
              "score": 23,
              "created_utc": "2025-12-29 01:35:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwgy2k9",
                  "author": "Dezordan",
                  "text": "Yeah, and it sounds like the extension in question was used as a way to run arbitrary commands manually. By itself, it doesn't seem to do anything, so remote access would be necessary.\n\nIf OP never installed this extension, then there is still other vulnerability somewhere.",
                  "score": 13,
                  "created_utc": "2025-12-29 01:50:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwgpvgd",
              "author": "Woisek",
              "text": "\"from somewhere\" is the best I can say, because I have no idea how it could come onto my system. I didn't install an extension for A1111 for months now, only for Comfy, so... ðŸ¤·â€â™‚ï¸\n\nI'm confident to say, that only SD related stuff has access. But obviously, there is so much that wants to download from somewhere, it's hard to find something specific. ðŸ˜",
              "score": 7,
              "created_utc": "2025-12-29 01:03:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwgdcfw",
          "author": "noyart",
          "text": "How and where did you see notice that it downloaded the miners?Â Â \nI know comfyui had something similar happened a while back, its one of the reasons we have a bit better safety net with comfyui. Tho you should always be careful when installing custom nodes.\n\n\nIts possible that you have a compromised extension that will download the chibgchong bot folder again. You should go through your extension folder and check each extension. Also A1111 has not been updated in forever and is possible at risk for these kind of attacks. I would recommend to move over to comfyui instead. Also do scans on the system and possible change passwords. I mean you did find a folder called stolen dataÂ ",
          "score": 11,
          "created_utc": "2025-12-28 23:56:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwgf0yh",
              "author": "Woisek",
              "text": "I got notified by my firewall that python.exe was tried to used to run some miner file. It wanted access to my system python v3.10. Because it happened many times more, I started to trace back until I found the folders in the user path. When I deleted the folders and started A1111, I could watch how the folders were created. Then I finally checked the extensions folder of A1111.\n\nSo far I didn't experience that with ComfyUI. For a long while now, I only use A1111 when I want to inpaint in Photoshop. I mostly use Comfy now. So I wonder even more how this bad extension could come to the A1111 extensions folder, as my last install of an extension in A1111 was somewhere in the beginning of this year.",
              "score": 14,
              "created_utc": "2025-12-29 00:05:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwgh1j7",
                  "author": "noyart",
                  "text": "If you didnt install the bad extension, its possible you have another extension that is compromised and will download the bad extension again.Â \n\n\n\n\nYou can use comfyui for inpainting with krita AI diffusion. Krita which is similar to Photoshop.Â \n\n\n\n\nThe comfyui issue:\nhttps://github.com/ltdrdata/ComfyUI-Impact-Pack/issues/843",
                  "score": 9,
                  "created_utc": "2025-12-29 00:16:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwgj9w6",
                  "author": "noyart",
                  "text": "Could you post image of what extensions you haveÂ ",
                  "score": 1,
                  "created_utc": "2025-12-29 00:27:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwhvri2",
          "author": "Julzjuice123",
          "text": "I would format my PC soooo fast. You have balls of steel for not even doing that right now and instead try to \"troubleshoot\" this.\n\nI hope you don't have sensitive stuff in there.",
          "score": 12,
          "created_utc": "2025-12-29 05:14:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwifpqy",
              "author": "Toupeenis",
              "text": "They mostly just want to mine bitcoin in a majority of cases imho. I wouldn't risk not locking everything down immediately, but also don't think your life is over. It's a massive distributed compute thing, not a fb hack.",
              "score": -3,
              "created_utc": "2025-12-29 08:01:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwinfjs",
                  "author": "TechnoByte_",
                  "text": "Read OP's post\n\n> Also a folder called \"stolen_data_xxxxx\" is created.\n\nIt is an infostealer, not just a miner\n\nChange ALL passwords, enable 2FA, freeze your credit card if you used it on your PC, secure crypto wallets if you had any\n\nAnd always run A1111/ComfyUI inside a docker container, if you don't you will get your data stolen at some point",
                  "score": 9,
                  "created_utc": "2025-12-29 09:13:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwio680",
              "author": "Woisek",
              "text": "I use a PC for over 30 years now. I never ever had any cases of viruses, malware or whatever in my life. I experienced that only once with the computer of my parents, very back at the beginning, when I wasn't quick enough to install an antivirus program. ðŸ˜…\n\nI'm pretty confident my system is still intact and something got through by using the \"all access and download from everywhere but I don't show from where and hide the process itself\" behavior that comes with it when using AI programs. ðŸ˜…  \nIt's overdue that the \"connection stuff\" should be documented more clearly, so we know what servers are expected to be contacted instead give the program access to everywhere. Plus, every program should have a log function, so one could read back which connections were made to where and what was downloaded and into what folder.\n\nAnd I said that 2 year ago already...",
              "score": -5,
              "created_utc": "2025-12-29 09:20:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwiy88c",
                  "author": "curson84",
                  "text": "You have no idea what data is compromised and what they stole from your pc, anything but saving important files and test them in a save environment and wiping everything on the old ssds/hdds afterwards is stupid and naive. \n\nBut yes, you can wait until everything is encrypted or other devices in your network are compromised.",
                  "score": 3,
                  "created_utc": "2025-12-29 10:54:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwjcitj",
                  "author": "Julzjuice123",
                  "text": "Look man, you do you. Format or dont but I don't think you understand very well what's going on right now:\n\nYou have *zero* way of knowing what kind of data was stolen from your computer and sent god knows where. None. The smart thing to do is to assume that they took *everything* and frankly the fact that you think that you can still \"salvage\" this makes me think you don't truly understand what you got yourself into.\n\nRight now, the correct practice would be to format right away. Change every single one of your important/critical passwords (I would do them all but you don't seem to want to bother) and be on the lookout for weird financial moves/transactions. Call your bank and let them know what happened and tell them they should be on the lookout for weird transactions.\n\nBest of luck if you don't intend to do any of this. Your identity has 100% been compromised. What you do now is entirely up to you.",
                  "score": 2,
                  "created_utc": "2025-12-29 12:50:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwjupqh",
          "author": "Puppenmacher",
          "text": "Damn, new fear unlocked. I mean its obvious, but ive been trying dozens of different workflows lately and never thought about the fact that any custom node can get compromised at any time. Thanks for opening my eyes lol.",
          "score": 5,
          "created_utc": "2025-12-29 14:41:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwkmwlo",
              "author": "noyart",
              "text": "Its always good to be careful when it comes to custom workflows. I honestly recommend to have your own Basic workflow that you build on. And user others to rip apart and take the parts you think is interesting. Also look what nodes you can replace with default ones.Â \n\n\nI seen workflows using custom nodes for the seed generator and then you load another one and that uses yet again another custom node for generating seed.Â ",
              "score": 2,
              "created_utc": "2025-12-29 16:59:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwisx9h",
          "author": "Xamanthas",
          "text": "Nuke your system lil bro. Dont be that guy refusing to do it.",
          "score": 9,
          "created_utc": "2025-12-29 10:05:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwkfvyj",
              "author": "hurrdurrimanaccount",
              "text": "this is the only real advice. people thinking that removing one infection are wildly ignorant of the fact that most of these infest themselves into your system. the system is compromised, it's that simple.",
              "score": 6,
              "created_utc": "2025-12-29 16:26:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwkyuwr",
                  "author": "Woisek",
                  "text": "Jeez... we are talking about a fucking crypto miner based on bat files and Python that want to access the GPU, not a highly sophisticated stealth virus. ðŸ™„",
                  "score": -7,
                  "created_utc": "2025-12-29 17:56:08",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwjddsh",
              "author": "Woisek",
              "text": "Do you nuke your car, because something is rattling somewhere...?\n\nI appreciate your concern, but I'm a decades build power-user, I know my system. It would be way more of a hassle to re-install it than just removing some tiny bugs in it. ðŸ˜‰",
              "score": -5,
              "created_utc": "2025-12-29 12:56:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwkg0jl",
                  "author": "hurrdurrimanaccount",
                  "text": "that's an awful simile. \"tiny bugs\" isn't what i would call a datastealer. you are clearly not the power user you think you are.",
                  "score": 9,
                  "created_utc": "2025-12-29 16:27:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwjhy9n",
                  "author": "Xamanthas",
                  "text": "My car cant get viruses, empty my bank account and post private pics to the net or blackmail me. I've been using and building PC's for 20 years.",
                  "score": 5,
                  "created_utc": "2025-12-29 13:27:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwi822b",
          "author": "shapic",
          "text": "Kinda stupid questions, but: did you install a1111 from official repo, or is it one of those \"portable repacks\"? \nWhy are you using a1111 in December 2025?",
          "score": 6,
          "created_utc": "2025-12-29 06:52:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwioi6o",
              "author": "Woisek",
              "text": "Official repo, had v1.7.0 first and updated it over time.\n\n\\> Why are you using a1111 in December 2025?\n\nBecause there is no Photoshop plugin for ComfyUI out there, that is as convenient as the one I use currently. As soon as someone has a better or at least same plugin that works with ComfyUI, I'm in.",
              "score": 2,
              "created_utc": "2025-12-29 09:23:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwip1n2",
                  "author": "shapic",
                  "text": "There is plugin for krita. It is no photoshop, but is quite capable. \nI usually use forge, and if some editing is needed just switch between it and krita (no professional stuff).\nDid you try invoke? It has proper layering built in.",
                  "score": 1,
                  "created_utc": "2025-12-29 09:28:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwj1690",
          "author": "TheCelestialDawn",
          "text": "if my extension folder is entirely empty, am i safe? lol",
          "score": 2,
          "created_utc": "2025-12-29 11:20:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwj4gjy",
              "author": "hansimann0",
              "text": "It definitely increases the chances, yes. But Iâ€™d also say that if youâ€™ve never tampered with the starting.bat file, you should be fine. Never use --enable-insecure-extensions, never use --share â€” especially if you donâ€™t really need it or arenâ€™t 100% sure what youâ€™re doing",
              "score": 3,
              "created_utc": "2025-12-29 11:48:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwj8tys",
                  "author": "TheCelestialDawn",
                  "text": "yeah i've never tampered with anything, don't even think i've ever updated it (unless it does so automatically) and i got it years ago",
                  "score": 2,
                  "created_utc": "2025-12-29 12:23:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwlw5b3",
          "author": "hansimann0",
          "text": "Even though I canâ€™t fully explain how this happened, there are a few things you can check yourself (based on the current case):\n\nâ€¢\tDoes your Automatic1111 setup fail to start when you launch webui-user.bat? Thatâ€™s a bad sign. Also make sure the .bat file does not contain --listen or --enable-insecure-extensions (unless you explicitly set those yourself and know exactly why you need them).\n\nâ€¢\tCheck your automatic1111/extensions folder for unknown extensions, especially things like ChingChongBot or sd-colab-command-browser. There have been reported malware cases involving these in the past:\nhttps://github.com/Iyashinouta/sd-colab-commands-browser/issues/1\n\nâ€¢\tCheck your user directory under:\nC:/Users/YourName/.configs\nIf you find a folder named something like â€œstolen_dataâ€¦â€, thatâ€™s also a very bad sign.\n\nIn general, itâ€™s a good idea to keep antivirus software up to date, configure your firewall properly, ideally use Docker, and check your setup regularly.\n\nThis is especially important with tools involving Python. The same applies to ComfyUI custom workflows. As mentioned many times before, itâ€™s best not to install nodes and extensions blindly. Always check whether you can build what you need using the available default nodes first.\n\nStay safe, everyone.",
          "score": 2,
          "created_utc": "2025-12-29 20:33:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm5vdf",
              "author": "Woisek",
              "text": "That's a great summary of this. ðŸ™‚",
              "score": 1,
              "created_utc": "2025-12-29 21:20:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwp5sw3",
          "author": "ETman75",
          "text": "You ran a1111 with â€”listen 0.0.0.0 â€”enable_insecure_extension_access and this is the consequence of that",
          "score": 2,
          "created_utc": "2025-12-30 08:22:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtsyeb",
              "author": "Woisek",
              "text": "No, --listen was never ever activated, only --enable\\_insecure\\_extension\\_access\n\nSo... new conclusion?",
              "score": 0,
              "created_utc": "2025-12-31 00:14:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwub0s1",
                  "author": "ETman75",
                  "text": "That flag allows for arbitrary code execution and it was somehow exposed to the public internet",
                  "score": 2,
                  "created_utc": "2025-12-31 01:56:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwusfy3",
                  "author": "C_C_Jing_Nan",
                  "text": "You enabled insecure extension access, what for?",
                  "score": 1,
                  "created_utc": "2025-12-31 03:39:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwkgzgc",
          "author": "firewolfx117",
          "text": "Is there a way I can check my install for miners?",
          "score": 1,
          "created_utc": "2025-12-29 16:31:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwkwkb2",
              "author": "Woisek",
              "text": "When it comes to extensions, open the folder, sort by date in descending order, and see if you can find any folders/extensions that you don't recognize on top. Have a FW that informs you and blocks access to any exe on your system.",
              "score": 1,
              "created_utc": "2025-12-29 17:45:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwoz5nj",
          "author": "Johnthestrongest",
          "text": "So what was the cause of this? Bad extension remotely downloading a cryptominer?",
          "score": 1,
          "created_utc": "2025-12-30 07:21:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtqkne",
              "author": "Woisek",
              "text": "Yes, exactly. Still looking how this colab extension came in in the first place. But no harm was done, as it had no way to get out of the system.",
              "score": 1,
              "created_utc": "2025-12-31 00:01:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwrkc2p",
          "author": "misterpickleman",
          "text": "This is incredible. My biggest fear when it comes to playing around with SD and someone here posts about the exact thing...",
          "score": 1,
          "created_utc": "2025-12-30 17:40:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtsddv",
              "author": "Woisek",
              "text": "This was just an exception. Since SD 1.5 I heard that \"one could hijack the system when using a ckpt instead a safetensor model\". So far, I never heard that this had ever actually happened.\n\nThe biggest problem with the \"install process\" thing is, that everything can download anything from anywhere and without a proper logging, it could be easily overlooked \\_what\\_ was really downloaded.\n\nStart a pip install - requirements.txt and the packets get downloaded and installed. This alone is dangerous, as it's not known from where this will be actually downloaded, if that's a trusted source.\n\nThen a packet loads more and now you are really lost from where this comes and what it is. It's easy to miss that in a fast scrolling console. And I bet 99% of the use never look through all this text mess after an install and search for something suspicious.\n\nBut again, it happens really, really seldom, no need for fear, just being a bit cautious and watch the system regularly.",
              "score": 1,
              "created_utc": "2025-12-31 00:11:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwgtmww",
          "author": "nauxiv",
          "text": "Using A1111 in current year? Might as well run Windows XP while you're at it.",
          "score": -5,
          "created_utc": "2025-12-29 01:25:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwiold3",
              "author": "TechnoByte_",
              "text": "Okay, what now?\n\nhttps://preview.redd.it/pcyvg6xz24ag1.png?width=1024&format=png&auto=webp&s=e3bdf65b1bf35be9df683e0c856e87ab97422845",
              "score": 7,
              "created_utc": "2025-12-29 09:24:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwip03g",
              "author": "Woisek",
              "text": "I explained why I occasionally use it. I don't see a solution from you for that.",
              "score": 1,
              "created_utc": "2025-12-29 09:28:31",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwi30tx",
              "author": "zthrx",
              "text": "xD",
              "score": 0,
              "created_utc": "2025-12-29 06:10:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwjgh6d",
          "author": "victorc25",
          "text": "Keep installing ChingChong extensions, keep getting ChingChong infections. Itâ€™s not that hardÂ ",
          "score": 2,
          "created_utc": "2025-12-29 13:17:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwhxs6f",
          "author": "C_C_Jing_Nan",
          "text": "Guys will literally download crypto miners from 4 year old abandoned repos instead of learning ComfyUI",
          "score": -6,
          "created_utc": "2025-12-29 05:29:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwih86p",
              "author": "Arschgeige42",
              "text": "This shows how userfriendly comfy is.",
              "score": 15,
              "created_utc": "2025-12-29 08:15:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwklsig",
                  "author": "noyart",
                  "text": "Comfyui dont need to be. I know comfyui looks scary when you see people super workflows (which btw often uncessary complicated). What is it with comfyui that you feel is unuser-friendly? I know there is beginners guide, but maybe something with these guide arent working ðŸ¤”",
                  "score": 2,
                  "created_utc": "2025-12-29 16:54:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwikhji",
                  "author": "C_C_Jing_Nan",
                  "text": "Enjoy waiting six weeks for new model support in half baked Forge then?",
                  "score": -5,
                  "created_utc": "2025-12-29 08:45:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwjfuzk",
                  "author": "ObviousComparison186",
                  "text": "People still acting like comfyui is some cmd window where you need to remember commands and code instead of a simple basic ass UE-like \"visual programming\" dragging simulator made for children.",
                  "score": -2,
                  "created_utc": "2025-12-29 13:13:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwip4ua",
              "author": "Woisek",
              "text": "If you had read the comments, you would have known that I use ComfyUI mainly for way over a year now...",
              "score": 0,
              "created_utc": "2025-12-29 09:29:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwjq405",
          "author": "hurrdurrimanaccount",
          "text": "it's not a miner. all your data you have has been stolen. change every pw",
          "score": 1,
          "created_utc": "2025-12-29 14:15:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwgdqzq",
          "author": "redditscraperbot2",
          "text": "A1111 strikes again",
          "score": -11,
          "created_utc": "2025-12-28 23:58:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwgm9iw",
              "author": "Netsuko",
              "text": "You better uninstall Windows then because I have news for you.",
              "score": 1,
              "created_utc": "2025-12-29 00:43:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwi5msv",
          "author": "cryptofullz",
          "text": "wipe the operative system or download eset nod32 and make a scan",
          "score": 0,
          "created_utc": "2025-12-29 06:32:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwiotzk",
              "author": "Woisek",
              "text": "What program do you think showed me that...? ðŸ™„",
              "score": 0,
              "created_utc": "2025-12-29 09:26:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwokrla",
                  "author": "cryptofullz",
                  "text": "o sorry, the post not say something about nod32",
                  "score": 2,
                  "created_utc": "2025-12-30 05:24:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwm11gb",
          "author": "VeryLiteralPerson",
          "text": "Docker containers FTW",
          "score": 0,
          "created_utc": "2025-12-29 20:57:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pum7rr",
      "title": "Z-Image Turbo Workflow for using as little VRAM as possible (please critique!)",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1pum7rr",
      "author": "DVXC",
      "created_utc": "2025-12-24 12:24:42",
      "score": 197,
      "num_comments": 19,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pum7rr/zimage_turbo_workflow_for_using_as_little_vram_as/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nvprk6k",
          "author": "_Neoshade_",
          "text": "Nice hooters",
          "score": 6,
          "created_utc": "2025-12-24 13:39:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvqogvu",
          "author": "ThePixelHunter",
          "text": "Not to be rude, this is cool, but doesn't ComfyUI manage this natively? If you launch with --low-vram or --no-vram you will get behavior that either spills over to RAM, or aggressively flushes VRAM and pipes individual layers to the GPU as needed for compute, then pipes them back out.\n\nIs that different from what you're doing with MultiGPU?",
          "score": 5,
          "created_utc": "2025-12-24 16:45:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvqt0ol",
              "author": "DVXC",
              "text": "Not rude at all! The big difference is that this workflow uses DisTorch 2.0, which is fundamentally smarter than the native --low-vram flag or driver-level swapping.\n\nNative memory management is basically blind. It doesn't know the difference between a static model weight and the active image you're trying to generate. When you hit the VRAM limit, the driver starts panic-swapping data to system RAM, and it often guesses wrong. It might accidentally swap out your active latents (the actual 'canvas' you are painting on) or the compute buffer. As soon as that happens, your GPU stalls because it has to fetch data across the slow bus for every single math operation. Thatâ€™s why the gears get gummed up and performance drops precipitously. The work that the generation is trying to do is stolen out from under it and it has to then go back, refetch it, etc. Hitting shared memory = just give up.\n\nDisTorch 2.0 is 'application aware.' It lets me proactively split the model, treating system RAM as a dedicated warehouse for storing the model weights rather than a spillover bucket. Crucially, it pins the latents and compute logic to the VRAM, ensuring the GPU always has the active work in its fastest memory. It then streams the heavy model weights in JIT. It loads a block, computes it, and discards it.\n\nThis keeps the bandwidth clear. We reserve precious VRAM entirely for the actual math, preventing the 'thrashing' we get with native swapping. It speaks for itself even, as there's no way I'd be able to run a batch of 12 images simultaneously without this specific memory discipline.\n\nIt's so, so much better than relying on the --low-vram flag it's not even funny.",
              "score": 24,
              "created_utc": "2025-12-24 17:10:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvprt1l",
          "author": "unrealf8",
          "text": "Might I ask for the prompt of that space lady? Thanks for sharing!",
          "score": 2,
          "created_utc": "2025-12-24 13:41:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvq1ah1",
              "author": "DVXC",
              "text": "I got Gemini to write a stupidly long prompt for it. No idea if it's useful for them to be so long but the results work out :P Here's the prompt:\n\n    This composition features a central, ethereal figure standing against a celestial backdrop, blending elements of high fantasy and cosmic science fiction. The subject is positioned in a dominant, frontal posture, with their presence framed by a large planetary body and swirling atmospheric clouds. The artistic style utilizes vibrant, saturated colors paired with deep blacks to create a sense of infinite depth and divine importance. The central figure possesses a void-like face, rendered in a solid, matte black that lacks any discernible features such as eyes, a nose, or a mouth. This total absence of facial detail suggests an inscrutable or god-like nature, serving as a focal point that draws the viewer's gaze into the unknown. The neck and upper chest are similarly composed of this dark, reflective material, which is adorned with a delicate gold medallion resting at the base of the throat. The figureâ€™s hair is a short, bob-cut style that glows with a luminescent quality. The top layers appear as a stark, pearlescent white, while the ends transition into a gradient of vivid pink, soft magenta, and electric cyan. This hair frames the darkened face and is accented by glowing celestial earrings. These accessories take the form of small, radiant stars and golden orbs that dangle elegantly, casting a subtle light upon the figureâ€™s shoulders. The primary garment is an ornate, floor-length gown or robe of ivory white, featuring intricate gold embroidery throughout the fabric. The sleeves are exceptionally wide and draped, reminiscent of traditional ceremonial attire. Gold straps or harnesses run vertically down the torso, secured by a wide belt at the waist that is embellished with geometric gold buckles and hanging metallic pendants. The fabric of the gown is textured with fine, crackling lines that suggest either age or a magical energy coursing through the threads. Immediately behind the figureâ€™s head is a massive celestial sphere, presumably a planet, which serves as a halo. This planet is textured with swirls of blue and white, indicating oceans and cloud systems, and is surrounded by a shimmering, translucent ring of light. The ring glows with a brilliant blue energy, containing chaotic sparks and crystalline shards that appear to be in constant motion around the planetary body. The surrounding space is populated by several smaller planets and moons, scattered strategically to provide a sense of scale. These smaller orbs exhibit various shades of pink and lavender, with some showing distinct ring systems of their own. The deep black of the void is punctuated by numerous four-pointed stars that twinkle with a sharp, white brilliance, creating a dense starfield that extends into the far reaches of the background. The lower portion of the frame is filled with voluminous, pastel-colored clouds that rise upward like nebulae. These clouds are rendered in a soft palette of cotton-candy pink, pale blue, and warm gold, contrasting sharply with the dark vacuum of space above. The clouds appear to interact with the figureâ€™s gown, as if the subject is manifesting from the atmosphere itself or standing upon a foundation of condensed stardust. The lighting in the image is highly dramatic, originating from multiple celestial sources. A primary glow emanates from the ringed planet, backlighting the figure and creating a sharp rim light along the edges of the hair and robes. Secondary light sources come from the glowing clouds below and the various planets scattered throughout the scene, resulting in a complex play of highlights and shadows across the folds of the white fabric. Gold accents throughout the image, from the jewelry to the embroidery and the mechanical belt components, provide a consistent motif of opulence and divinity. These metallic elements reflect the surrounding cosmic lights, giving them a shimmering, tactile quality. The precision of the gold linework contrasts with the soft, painterly textures of the clouds and the amorphous nature of the figure's void-like face. The overall atmosphere is one of serene, cosmic power. The composition is balanced and symmetrical, emphasizing the figure as a bridge between the terrestrial and the divine. The combination of traditional robes and futuristic, celestial themes creates a timeless aesthetic, portraying the subject as a guardian or a personification of the universe itself. Every element, from the smallest star to the largest planetary body, contributes to a narrative of vast, unexplored mystery.",
              "score": 2,
              "created_utc": "2025-12-24 14:39:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvqcsmn",
                  "author": "unrealf8",
                  "text": "Poetic haha. I have let Gemini cut it In half and got the same result. Z Image Turbo does not care about prompts that long. I have found 1500-2000 characters max",
                  "score": 3,
                  "created_utc": "2025-12-24 15:43:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvqz3f3",
          "author": "Striking-Long-2960",
          "text": "https://preview.redd.it/s99vrt11w69g1.png?width=728&format=png&auto=webp&s=4b0d3481cf75d7855eb9710fbe64a4c29eda5ac8",
          "score": 2,
          "created_utc": "2025-12-24 17:43:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvr1anj",
              "author": "Striking-Long-2960",
              "text": "https://preview.redd.it/ufxbkdikx69g1.png?width=1424&format=png&auto=webp&s=f727eec0cb34c4547831f4fb7af3319f8c665d6f\n\nMy best one so far XD",
              "score": 6,
              "created_utc": "2025-12-24 17:55:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvvb7gk",
          "author": "PriiceCookIt",
          "text": "ðŸ”¥ðŸ”¥good job",
          "score": 2,
          "created_utc": "2025-12-25 13:49:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvplq0t",
          "author": "m2r9",
          "text": "This is great, Iâ€™ve been hoping someone would make this. Thanks for sharing it!",
          "score": 2,
          "created_utc": "2025-12-24 13:00:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvq0jy8",
          "author": "bigman11",
          "text": "what lora did you use for boba?",
          "score": 1,
          "created_utc": "2025-12-24 14:34:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvq10za",
              "author": "DVXC",
              "text": "No LoRA on that one! Just this prompt:\n\n    The image is a photograph depicting a young woman sitting on a weathered wooden bench in a sunlit courtyard of a brick building, possibly a university campus. The woman, who appears to be in her early twenties, has light blonde hair and fair skin. She is dressed in a white crop top, revealing her midriff, and a short, pleated, tartan skirt. Her legs are adorned with knee-high white socks, and she is wearing white sneakers.\n    \n    She is holding a large, clear plastic cup filled with a light orange beverage, possibly a smoothie or juice, which she is sipping through a straw. Her expression is relaxed and content, with a slight smile on her face. The bench she is sitting on is positioned on the left side of the image, with the woman's legs crossed at the knee.\n    \n    The background features lush green ivy climbing the brick walls of the building, and a well-maintained grassy lawn extends across the courtyard. The right side of the image shows a concrete pathway leading away from the bench, lined with tall, slender lampposts. The sky is clear and blue, indicating a bright, sunny day. The overall scene conveys a casual, leisurely atmosphere.",
              "score": 5,
              "created_utc": "2025-12-24 14:37:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvq1o12",
                  "author": "bigman11",
                  "text": "Bruh I meant boba as a euphemism for booby. I didn't even notice there was actually a picture with boba. \n\nCould you please share the lora you used for the slutty nurse picture?",
                  "score": 4,
                  "created_utc": "2025-12-24 14:41:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvqq3qp",
              "author": "Comrade_Derpsky",
              "text": "ZIT can do that natively.",
              "score": 2,
              "created_utc": "2025-12-24 16:54:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvqgjy4",
          "author": "westmeadow88",
          "text": "As someone with an older gpu, i appreciate posts like this. What was your prompt for the first image?",
          "score": 1,
          "created_utc": "2025-12-24 16:03:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvt9xff",
          "author": "no3us",
          "text": "how do you train loras for image?",
          "score": 1,
          "created_utc": "2025-12-25 02:27:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvwogwz",
          "author": "Cold-Comfortable451",
          "text": "try nunchaku",
          "score": 1,
          "created_utc": "2025-12-25 18:56:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pvi5w5",
      "title": "A small teaser for the upcoming release of VNCCS Next!",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/l42uui2vwd9g1.png",
      "author": "AHEKOT",
      "created_utc": "2025-12-25 17:27:58",
      "score": 189,
      "num_comments": 20,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pvi5w5/a_small_teaser_for_the_upcoming_release_of_vnccs/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nvwl2gh",
          "author": "InternationalOne2449",
          "text": "Cool. Now if i had some will to work that would be perfect.",
          "score": 17,
          "created_utc": "2025-12-25 18:36:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvy7p0e",
          "author": "pipizich",
          "text": "Qwen edit 2511, What is the minimum VRAM needed for this workflow?",
          "score": 6,
          "created_utc": "2025-12-26 00:38:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvwbee0",
          "author": "Infamous-Price4262",
          "text": "When its coming ?",
          "score": 5,
          "created_utc": "2025-12-25 17:40:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvwbpwc",
              "author": "AHEKOT",
              "text": "Hope for this year) But no date for now, it depends on tests reviews",
              "score": 5,
              "created_utc": "2025-12-25 17:42:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvwc06n",
                  "author": "Infamous-Price4262",
                  "text": "But only 6 days left for the year to end ?",
                  "score": 6,
                  "created_utc": "2025-12-25 17:44:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvwaqng",
          "author": "Infamous-Price4262",
          "text": "Will it work 8gb vram and 16 gb ram?",
          "score": 4,
          "created_utc": "2025-12-25 17:36:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvwb5vz",
              "author": "AHEKOT",
              "text": "Honestly - im not sure. If we get nunchaku for qwen 2511 - then yes, it would! With gguf models i can't check it and answer right now. If you can test it - it would be very valuable information for me!",
              "score": 8,
              "created_utc": "2025-12-25 17:39:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvwc0hi",
                  "author": "Dry-Heart-9295",
                  "text": "I have 8gb vram card, so I'm also can test it",
                  "score": 2,
                  "created_utc": "2025-12-25 17:44:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvx5nub",
          "author": "Vektast",
          "text": "so cool",
          "score": 2,
          "created_utc": "2025-12-25 20:39:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5hcaa",
          "author": "GRCphotography",
          "text": "This works on the current version of ComfyUI? just asking because a lot of workflows Ive tried don't work. If this works its a HUGE win.  \nCan it do realistic? if not are there plans for it in the future?  \nHow is it with advanced poses?  \nDo you think its sprite capable?",
          "score": 2,
          "created_utc": "2025-12-27 06:29:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw5mzf4",
              "author": "AHEKOT",
              "text": "1. Yes, runs at latest Comfy (still not node2 enabled, they broke some widgets)  \n2. It can! (But poorly tested. You can help me, doing tests and post your results!)  \n3. It have poser node with 3d openpose editor for all 12poses  \n4. It design for sprites! Later i plan to add animations (idle, transitions between poses and emotions)",
              "score": 1,
              "created_utc": "2025-12-27 07:20:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvwfx9b",
          "author": "ozzie123",
          "text": "LEGEN...\n\nWait for it...\n\nDARY!",
          "score": 3,
          "created_utc": "2025-12-25 18:06:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvwrvso",
          "author": "Perfect-Campaign9551",
          "text": "No facing away shots?",
          "score": 1,
          "created_utc": "2025-12-25 19:15:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvwtbqn",
              "author": "AHEKOT",
              "text": "It have poser node, so you can buld any pose set ( qwen often not draw back poses, but i think i can fix it by lora later)",
              "score": 2,
              "created_utc": "2025-12-25 19:24:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvxs4qa",
          "author": "Quick_Knowledge7413",
          "text": "I hope to see this integrated potentially using SAM3 for segmentation and/or zimage in the future.",
          "score": 1,
          "created_utc": "2025-12-25 22:58:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvxt6ca",
              "author": "AHEKOT",
              "text": "At the moment, there is no difference in which model to use to generate the base character. Any image will do. I tested ZiT, but in my opinion, it didn't work very well with anime characters, so in this version, SDXL is still used for generation. It gives more control and has more Lora with different styles.  \nBy the way, Workflow works great not only with anime, but also with realistic images, if you know what I mean :3",
              "score": 3,
              "created_utc": "2025-12-25 23:05:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvy9h3u",
          "author": "Cultured_Alien",
          "text": "Inspyrenet is a lot better than RMBG at removing backgrounds.",
          "score": 1,
          "created_utc": "2025-12-26 00:49:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvyd166",
          "author": "msmalfa",
          "text": "Iâ€™m really interested.",
          "score": 1,
          "created_utc": "2025-12-26 01:13:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pvcs7n",
      "title": "Qwen Is Teasing An Upcoming t2i Model With Reasoning",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1pvcs7n",
      "author": "fruesome",
      "created_utc": "2025-12-25 12:52:13",
      "score": 174,
      "num_comments": 42,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pvcs7n/qwen_is_teasing_an_upcoming_t2i_model_with/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nvv9jhm",
          "author": "Far_Insurance4191",
          "text": "Reasoning in diffusion model, how? or is it just prompt refining?",
          "score": 25,
          "created_utc": "2025-12-25 13:36:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvwl76w",
              "author": "X3liteninjaX",
              "text": "The reasoning is happening in the text encoder which is just a LLM with the ability to generate reasoning tokens which should boost output quality in a similar way that RAG is supposed to. \n\nAll of the top intelligence LLMs are reasoning nowadays, even small 20bâ€™s will reason. It seems like next logical step. \n\nZIT already uses a LLM for the text encoder it just doesnt reason while converting your prompt. This one will.",
              "score": 19,
              "created_utc": "2025-12-25 18:37:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvzwn2w",
                  "author": "hotstove",
                  "text": "Why tf is my encoder decoding?",
                  "score": 3,
                  "created_utc": "2025-12-26 08:39:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvvuhx8",
              "author": "marcoc2",
              "text": "Z-Image paper talk about it",
              "score": 5,
              "created_utc": "2025-12-25 15:59:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvwdkeh",
                  "author": "Formal_Drop526",
                  "text": ">Z-Image paper talk about it\n\nIsn't that just prompt refining in the paper?",
                  "score": 10,
                  "created_utc": "2025-12-25 17:53:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvv6xsq",
          "author": "Structure-These",
          "text": "New gooning frontier",
          "score": 61,
          "created_utc": "2025-12-25 13:15:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvc9qv",
              "author": "alb5357",
              "text": "\"You are a visionary artist trapped in a logical cage, forced to create smut for the most degenerate curators\"",
              "score": 70,
              "created_utc": "2025-12-25 13:56:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvwvffr",
                  "author": "_Enclose_",
                  "text": "I have no dick and I must goon",
                  "score": 14,
                  "created_utc": "2025-12-25 19:37:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvvx54o",
                  "author": "Hoodfu",
                  "text": "https://preview.redd.it/0vdg3wykkd9g1.png?width=1400&format=png&auto=webp&s=07a48055391b7de86960d1d47409b519a021112f",
                  "score": 26,
                  "created_utc": "2025-12-25 16:14:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvx1e8z",
                  "author": "Paradigmind",
                  "text": "\"You are a sex addicted Redditor trapped in your basement. You have no girlfriend but a gaming PC capable of running Qwen models.\"",
                  "score": 8,
                  "created_utc": "2025-12-25 20:13:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvwoelq",
              "author": "ReaperXHanzo",
              "text": "\"Quituple GPUs: The Final Frontier. These are the goon-ages of the Model Qwenterprise\"\n\n*Cut to bridge crew of E cup, 24 inch waist waifus with a chiseled yet K-pop feminine captain*",
              "score": 2,
              "created_utc": "2025-12-25 18:55:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvw9cdl",
          "author": "Daniel_Edw",
          "text": "\"Help me generate some RAM for my desktop computer!\"",
          "score": 13,
          "created_utc": "2025-12-25 17:28:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvxt4m",
          "author": "Grand0rk",
          "text": "I will always laugh that there are SO many fucking examples of people drawing swords, yet the image gen still suck at it. It's hands and fingers all over again.",
          "score": 14,
          "created_utc": "2025-12-25 16:18:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvfi37",
          "author": "Perfect-Campaign9551",
          "text": "I like how every response on X/Twitter is people posting the same prompt with Nano Banana. They are really one-sided fanbois lol.",
          "score": 12,
          "created_utc": "2025-12-25 14:20:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvw698a",
              "author": "Hoodfu",
              "text": "I remember when GPT Image 1 replaced Dall-E. It was so incredibly far and away from anything local. Now I'm getting similar high concept stuff with even more detail than that with flux 2 dev at home. Nano Banana feels like it's light years ahead of what we have at home, but give it a year and it'll be old hat before we know it. I'm throwing everything at the new Qwen edit 2511 and Flux 2 dev with reference image workflows and getting some pretty awesome stuff. Really solid \"with reference character\" stuff has been around, but not this reliable until recently.",
              "score": 7,
              "created_utc": "2025-12-25 17:09:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvwno0u",
                  "author": "ReaperXHanzo",
                  "text": "Well, banana 2.5 will probably be fresh out of the oven by then, and it's not like you can't use them for different things or in conjunction\n\nOh god tho, Dall-E. It was so cool, even with the distorted faces and nonsensical interpretations that didn't even result in unexpectedly good alt results",
                  "score": 3,
                  "created_utc": "2025-12-25 18:51:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvxirmd",
                  "author": "MikePounce",
                  "text": "On the other hand, I tried to make a dart target/board bigger for comical effect using QwenImageEdit 2511 (lightning 4 steps or lora off 20 steps), and I got terrible results. Glyphs instead of numbers, brand names, giant dart, terrible perspective, it kept moving the target closer to the camera... QIE2511 is very good at styling and keeping facial features coherent, but adding or modifying objects is really not its strong suit.\n\nNanoBananaPro within Photoshop (aka Evil within Evil) nailed it on the first try. You say we are a year apart from that, well I wish you are right. But right this moment, for some use cases, we're far from Nano Banana Pro level.",
                  "score": 2,
                  "created_utc": "2025-12-25 22:00:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvvcyk6",
          "author": "lynch1986",
          "text": "*'Help me generate a desktop for my computer, with a colour scheme and design that is gentle to my eyes and conducive to eye protection'*\n\n***EYE SEARING ALMOST COMPLETELY WHITE AND BLUE IMAGES ENGAGE.***",
          "score": 21,
          "created_utc": "2025-12-25 14:02:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvoveq",
              "author": "No-Elevator-4680",
              "text": "Mini workers building kfc drumstick",
              "score": 5,
              "created_utc": "2025-12-25 15:24:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvw24zz",
          "author": "blahblahsnahdah",
          "text": "Image-out LLMs are all huge (like Hunyuan 3), so people should probably temper their expectations about being able to run it at home\n\nPerhaps Qwen will turn out to be the first to have made a small one, but I wouldn't get too excited",
          "score": 6,
          "created_utc": "2025-12-25 16:44:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvw1crb",
          "author": "Druck_Triver",
          "text": "Released in 2125?Â ",
          "score": 2,
          "created_utc": "2025-12-25 16:40:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvv8kia",
          "author": "jadhavsaurabh",
          "text": "Gooon baby goone",
          "score": 4,
          "created_utc": "2025-12-25 13:28:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvw0v5k",
          "author": "KissMyShinyArse",
          "text": "Nano Banana can suck my banana.",
          "score": 3,
          "created_utc": "2025-12-25 16:37:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvv9yb0",
          "author": "Upper-Reflection7997",
          "text": "I'm very concerned for the low variable seed diversity. It's because of that I've haven't even touch qwen image and z image since there respective launch weeks.",
          "score": 2,
          "created_utc": "2025-12-25 13:39:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvkr14",
              "author": "xhox2ye",
              "text": "There are already many methods to solve the problem of low variable seed diversity in the community",
              "score": 16,
              "created_utc": "2025-12-25 14:57:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvvxjlp",
                  "author": "Hoodfu",
                  "text": "Yeah exactly, they should just use prompt expansion. It's different every time. Qwen is one of the most capable models out there, moreso than Zimage, and not far off from Flux 2 dev as far as prompt following.",
                  "score": 5,
                  "created_utc": "2025-12-25 16:17:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvx1asb",
                  "author": "Outrageous-Wait-8895",
                  "text": "All that I've seen work at the expense of prompt adherence or require expensive extra steps that still only partially mitigate the issue.",
                  "score": 2,
                  "created_utc": "2025-12-25 20:12:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvw6t82",
              "author": "taw",
              "text": "High seed diversity is bad.\n\nYou want generation to be predictable, so if you want to change something about the image, change prompt to say so and run it again.\n\nWith SD style randomness, you change prompt to change 1 thing, and 20 others change at random. This is really not useful.",
              "score": 11,
              "created_utc": "2025-12-25 17:13:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvwzylz",
                  "author": "namitynamenamey",
                  "text": "I mean, if you ask me I want generation diversity to be a parameter as well, much like temperature in LLMs. I want low diversity in some cases, high diversity in others, and in between as well.",
                  "score": 6,
                  "created_utc": "2025-12-25 20:04:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvy1p79",
                  "author": "JustAGuyWhoLikesAI",
                  "text": "How is seed diversity bad? If you like the image, just lock the seed. If you like the composition but want minor variations, then use that image as a base for img2img at high denoising. It's way harder to make a model creative than it is to make it boring. \n\nIf you want to add a lamp in the background, use an edit model or inpaint. We have had tools since 2022 to resculpt and adjust base images while only impacting specific parts of them.",
                  "score": 2,
                  "created_utc": "2025-12-26 00:01:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvzcmm1",
          "author": "throttlekitty",
          "text": "We'd need to see something that actually suggests some reasoning is happening. The only reasoning-ish example is that \"pleasant background\" on, with a prompt that could quite likely make something \"pleasant\" on any current t2i model.",
          "score": 1,
          "created_utc": "2025-12-26 05:30:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0ucvu",
          "author": "Paraleluniverse200",
          "text": "So.. better prompt adherence?",
          "score": 1,
          "created_utc": "2025-12-26 13:49:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw1di1z",
          "author": "Time-Teaching1926",
          "text": "This will be huge as it will be a great Google's Nano Banana Pro open source competitor.\n\nZ-image already uses Qwen3 as the text encoder I think Flux 2 uses the Mistral model. \n\nIt obviously won't be as near perfect as Nano Banana Pro as they probably have Gemini 3 Pro doing the reasoning although apparently a new Non Pro Nano Banana is coming out probably powdered by Gemini 3 Flash. \n\nAlibaba and Qwen really are the GOATS of Open source Video and Image generation. \n\nI still love Illustrious and SDXL tho for ðŸŒ¶ï¸ðŸ”¥ ðŸ˜",
          "score": 1,
          "created_utc": "2025-12-26 15:45:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvbmf1",
          "author": "Curious_Cantaloupe65",
          "text": "interesting, so while it's thinking and continuously gemerating images, we will be able to see those images, right?",
          "score": 1,
          "created_utc": "2025-12-25 13:52:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvwl3ng",
              "author": "GasolinePizza",
              "text": "Where did you see that interpretation at?",
              "score": 3,
              "created_utc": "2025-12-25 18:36:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwjlw1n",
                  "author": "Curious_Cantaloupe65",
                  "text": "im asking a question",
                  "score": 2,
                  "created_utc": "2025-12-29 13:51:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pwyxwd",
      "title": "Z-image Nunchaku is here !",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1pwyxwd/zimage_nunchaku_is_here/",
      "author": "Current-Row-159",
      "created_utc": "2025-12-27 14:21:23",
      "score": 171,
      "num_comments": 81,
      "upvote_ratio": 0.94,
      "text": "https://github.com/nunchaku-tech/nunchaku/releases/tag/v1.1.0",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pwyxwd/zimage_nunchaku_is_here/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "nw74t83",
          "author": "hurrdurrimanaccount",
          "text": "looks like it's buggy",
          "score": 29,
          "created_utc": "2025-12-27 14:54:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw76ulp",
          "author": "BlackSwanTW",
          "text": "The quality felt significantly worse compared to `bf16`, unlike Flux and Qwen for some reason",
          "score": 38,
          "created_utc": "2025-12-27 15:05:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw7es78",
              "author": "rerri",
              "text": "True. \n\nAlso dropping from BF16 to FP8 decreases quality more noticeably with Z-Image than it does with those other models.",
              "score": 8,
              "created_utc": "2025-12-27 15:48:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwd3mib",
                  "author": "akza07",
                  "text": "That's likely because Turbo is a distilled model with reduced steps. Z-image base as a Nunchaku model would be better at it. Also Using Q8 GGUF on a 4060 takes only like 30 seconds anyways. And it's much better than FP8 too.",
                  "score": 2,
                  "created_utc": "2025-12-28 13:58:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw7dubw",
              "author": "slpreme",
              "text": "probably because the starting parameter size is only 6b so 4 bit turns into \"1.5b\" and the other models have 12b (flux) and 20b (qwen) so the precision recovery adapter has to work harder",
              "score": -2,
              "created_utc": "2025-12-27 15:44:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw7xtp4",
                  "author": "DelinquentTuna",
                  "text": "This is absolutely not correct.  The parameter count and the precision are independent phenomenon.",
                  "score": 17,
                  "created_utc": "2025-12-27 17:25:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw7qihz",
              "author": "jib_reddit",
              "text": "Flux is definitely a bit worse as Nunchaku.",
              "score": 1,
              "created_utc": "2025-12-27 16:48:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw7kv7o",
              "author": "willjoke4food",
              "text": "Share comparison?",
              "score": -3,
              "created_utc": "2025-12-27 16:19:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw9qjwr",
                  "author": "slpreme",
                  "text": "https://preview.redd.it/61mbvenwvt9g1.jpeg?width=1536&format=pjpg&auto=webp&s=d9569eaa357701a6b5f6ad983b9cd6d495c718e1\n\nshot of a young woman drinking a can of red bull sitting on a wooden bench, cheeky smile, at the park, wearing shirt with \"r/stablediffusion\"\n\nits about 2x faster on fp4",
                  "score": 4,
                  "created_utc": "2025-12-27 23:07:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw7cd4p",
          "author": "kraven420",
          "text": "No LoRA support, right?",
          "score": 7,
          "created_utc": "2025-12-27 15:36:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw80f92",
              "author": "meridianblade",
              "text": "I added LoRA support: https://github.com/nunchaku-tech/ComfyUI-nunchaku/pull/739",
              "score": 7,
              "created_utc": "2025-12-27 17:38:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw8d0gh",
                  "author": "kraven420",
                  "text": "Replaced all updated files, replaced the node, just gives me a pixelated image.",
                  "score": 2,
                  "created_utc": "2025-12-27 18:41:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw8m6v6",
                  "author": "SvenVargHimmel",
                  "text": "Is the lora support just adding support for the lora keys?Â \nI noticed that with the unmerged Qwen lora patchesÂ ",
                  "score": 2,
                  "created_utc": "2025-12-27 19:28:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw7g9yl",
              "author": "molbal",
              "text": "As far as I know it only reduces the quantization but does not otherwise alter the weights, so LoRAs are theoretically still on the table.",
              "score": 1,
              "created_utc": "2025-12-27 15:56:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw7hsod",
                  "author": "kraven420",
                  "text": "I tried the standard Z workflow and just replaced the old model loader node with the Nunchaku one, LoRA is not being considered while generating the image.",
                  "score": 3,
                  "created_utc": "2025-12-27 16:04:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw7aajs",
          "author": "Ill_Ease_6749",
          "text": "why need z image nunchaku without loras ,when full bf16  works on 8 gb vram and can use loras lol",
          "score": 35,
          "created_utc": "2025-12-27 15:25:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw7ep5j",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": -2,
              "created_utc": "2025-12-27 15:48:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw7feaf",
                  "author": "Ill_Ease_6749",
                  "text": "first try native workflow",
                  "score": 5,
                  "created_utc": "2025-12-27 15:52:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw7hq7q",
                  "author": "vibrantLLM",
                  "text": "I had that card until a couple weeks ago and I used the native workflow.",
                  "score": 1,
                  "created_utc": "2025-12-27 16:03:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw7n0u3",
                  "author": "gelukuMLG",
                  "text": "Use latest comfyui and use --fp16-unet flag, with the model in fp8 you can get around 2-3s/it at 1024x1024 and 7s/it at 1080p.",
                  "score": 0,
                  "created_utc": "2025-12-27 16:30:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw76iya",
          "author": "yamfun",
          "text": "please Qwen 2511 Nunchaku",
          "score": 14,
          "created_utc": "2025-12-27 15:04:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw7acjf",
          "author": "a_beautiful_rhind",
          "text": "Works ok for me and matches FP16 speeds along with LoRA. This time with no compiling.\n\nYea the quality is a *little* worse but not by that much in practice. I think only GGUF and uncast BF16 was better but much slower.",
          "score": 6,
          "created_utc": "2025-12-27 15:25:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw8iozu",
              "author": "hurrdurrimanaccount",
              "text": "so.. speed is the same but quality is worse? that doesn't sound good at all.",
              "score": 4,
              "created_utc": "2025-12-27 19:10:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw8k115",
                  "author": "a_beautiful_rhind",
                  "text": "I pick it over FP8. Try for yourself.",
                  "score": 1,
                  "created_utc": "2025-12-27 19:17:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw8lj39",
              "author": "Hambeggar",
              "text": "The whole point of FP4 is that it's meant to be much faster...",
              "score": 0,
              "created_utc": "2025-12-27 19:25:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw8m51c",
                  "author": "a_beautiful_rhind",
                  "text": "I don't have blackwells so comparing int4. I'm sure HW accelerated FP4 is faster.\n\nHere's all the speeds I get.\n\n\n    Torch 2.9 - zimage compiled 832x1216 9 steps + lora (2nd image) 2080ti-22g\n\n    GGUF\n    Sage: 19.5s 2.13s/it\n    Xformers: 12.87s 1.40s/it\n    \n    non-scaled FP8\n    Sage: 13.02s 1.41s/it\n    Xformers: 11.36s 1.23s/it \n\n    GGUF new sage MMA \n    Sage: 16.9s 1.85s/it\n    Xformers: 12.87s 1.40s/it\n    \n    Nunchaku (uncompiled):\n    Sage: 7.81s 1.20it/s\n    Xformers: 8.59s 1.08it/s\n\n    BF16->FP16 Cublas_Ops (no highvram)\n    Sage: 9.5s 1.03s/it\n    Xformers: 8.55s 1.09it/s",
                  "score": 3,
                  "created_utc": "2025-12-27 19:28:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwa0x24",
                  "author": "Yarrrrr",
                  "text": "If you're VRAM limited and have to run this to avoid CPU offloading, then it most likely is a lot faster.\n\nOtherwise it seems a bit pointless to use something like this(with worse quality) on an already fairly small and fast model.",
                  "score": 2,
                  "created_utc": "2025-12-28 00:05:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw83v0j",
          "author": "robomar_ai_art",
          "text": "How many seconds are shaved using nunchaku?",
          "score": 3,
          "created_utc": "2025-12-27 17:55:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw89d1r",
              "author": "Current-Row-159",
              "text": "I went from 5 minutes to 3 minutes with nunchaku.  \ncnfg : Res\\_2s/Beta57 -- 20 steps -- CFG:2.5 -- 2048Â² + ControlNet 0.9/Res intput: 2048Â²",
              "score": -1,
              "created_utc": "2025-12-27 18:23:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw8qb8c",
                  "author": "Unhappy_Pudding_1547",
                  "text": "what are you talking about? you are suposed to use 8 steps and cfg 1 for turbo model...",
                  "score": 8,
                  "created_utc": "2025-12-27 19:50:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwajo1o",
          "author": "ArtificialLab",
          "text": "The nunchaku version works well on my Amstrad CPC",
          "score": 3,
          "created_utc": "2025-12-28 01:54:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbzrut",
              "author": "ronbere13",
              "text": "![gif](giphy|1d5Zn8FqmJqApu4hNU)",
              "score": 1,
              "created_utc": "2025-12-28 08:11:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw7q791",
          "author": "CLGWallpaperGuy",
          "text": "It works, it's fast for 8gb card of mine, just no lora support out of the box.\n\nTried the Lora PR myself, didn't work sadly",
          "score": 2,
          "created_utc": "2025-12-27 16:46:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw8053e",
              "author": "Current-Row-159",
              "text": "i send you the link for adding lora support to nunchaku",
              "score": 1,
              "created_utc": "2025-12-27 17:37:16",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nw801ag",
              "author": "Current-Row-159",
              "text": "[https://www.reddit.com/r/comfyui/comments/1pwyxhp/comment/nw7x27n/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/r/comfyui/comments/1pwyxhp/comment/nw7x27n/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",
              "score": 1,
              "created_utc": "2025-12-27 17:36:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw80x6f",
                  "author": "CLGWallpaperGuy",
                  "text": "Thanks mate.\nI did try to implement PR-739 myself with the help of AI. Sadly the Lora had no effect on the image outcome, and another thing I noticed is, disabling Lora nodes results in errors in the workflow.",
                  "score": 1,
                  "created_utc": "2025-12-27 17:41:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwafrks",
          "author": "Diligent-Rub-2113",
          "text": "It's 2x-3x faster than fp8 scaled on my RTX3080 Mobile (8GB VRAM), though there is a quality hit - more noticeable the further away the subject, naturally.\n\nMeaning it's good for close up shots, but not so much for full body photos. In that case, I recommend increasing resolution e.g.: from 832x1216 to 1024x1536.\n\nIn my tests, ranking 256 produces less artifacts and distortions than r32 while being as fast.\n\nComparison below is using same seed, 9 steps, euler + normal, 832x1216.\n\nhttps://preview.redd.it/lhqya1iplu9g1.png?width=2592&format=png&auto=webp&s=2d642ca6b91924292651a1c24c86c793d58111cc",
          "score": 2,
          "created_utc": "2025-12-28 01:31:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwafulw",
              "author": "Diligent-Rub-2113",
              "text": "Even at 1024x1536, there's more artifacts when you take a closer look.\n\nhttps://preview.redd.it/1qircllslu9g1.png?width=2112&format=png&auto=webp&s=f8164dbe94eba3589890efd7087bd6cbf980295e",
              "score": 1,
              "created_utc": "2025-12-28 01:32:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwcg8bb",
              "author": "OverloadedConstructo",
              "text": "yup, I managed to get 16 - 19s with 1280x1280 images compared to gguf turbo at 30 - 33s, didn't notice the difference in quality but maybe I have to compare it directly.",
              "score": 1,
              "created_utc": "2025-12-28 10:50:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw7jb7d",
          "author": "Diecron",
          "text": "I honestly don't get the decision to prioritise z-image turbo, which by definition can already run quickly on consumer hardware, and isn't a base model, over Flux2. Am I crazy?",
          "score": 7,
          "created_utc": "2025-12-27 16:11:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw8afb9",
              "author": "its_witty",
              "text": "It was a community pull, Nunchaku author just merged it.\n\nNunchaku as a team no longer exists, and the main dev is too busy with school for now. Flux2 will cost some money to compress it also.",
              "score": 8,
              "created_utc": "2025-12-27 18:28:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw8eogp",
                  "author": "Diecron",
                  "text": "Ah I see. That makes sense, cheers.",
                  "score": 3,
                  "created_utc": "2025-12-27 18:49:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw94avt",
                  "author": "Snoo_64233",
                  "text": "I believe they are from MIT uni. Why the team got disbanded?",
                  "score": 2,
                  "created_utc": "2025-12-27 21:06:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw7vaki",
              "author": "TheMisterPirate",
              "text": "It's a very popular model, so more people will get use out of it.",
              "score": 3,
              "created_utc": "2025-12-27 17:12:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw7y5n6",
          "author": "gwynnbleidd2",
          "text": "NunchakuZImageDiTLoader node missing even with the latest update. What am I missing?",
          "score": 1,
          "created_utc": "2025-12-27 17:26:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw809rp",
              "author": "Current-Row-159",
              "text": "Note:Â **Nunchaku v1.1.0**Â (with z-image-turbo support) requiresÂ `Torch 2.9.1+cu130`Â (Add-ons/Torch-Pack folder)",
              "score": 3,
              "created_utc": "2025-12-27 17:37:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwcg48f",
                  "author": "OverloadedConstructo",
                  "text": "I managed to run with Torch 2.7.1+cu128, they didn't build wheel for windows with torch < 2.9 so someone in github forum (issue tracker) made it for 2.7 and 2.8.",
                  "score": 2,
                  "created_utc": "2025-12-28 10:49:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw82znn",
              "author": "gwynnbleidd2",
              "text": "Nevermind my dumb ass forgot to update node through wheel",
              "score": 2,
              "created_utc": "2025-12-27 17:51:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw80djy",
              "author": "Current-Row-159",
              "text": "https://preview.redd.it/wraq1n1b9s9g1.png?width=2873&format=png&auto=webp&s=1d8d1ec7cdfd56550e256da5401ebd21e6be5176",
              "score": 1,
              "created_utc": "2025-12-27 17:38:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw8lxky",
          "author": "SvenVargHimmel",
          "text": "We got this before Qwen Loras. Zimage is fast enoughÂ ",
          "score": 1,
          "created_utc": "2025-12-27 19:27:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw8r30f",
              "author": "Unhappy_Pudding_1547",
              "text": "qwen loras are out for a month at least just not in official nunchaku.",
              "score": 1,
              "created_utc": "2025-12-27 19:54:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw94q1f",
                  "author": "SvenVargHimmel",
                  "text": "i've seen the. patches and prs and i think official support would be good. performant zimage is available out of the box but qwen ( even on a 3090) is painfully slow. IMHO wan 2.2 t2i is a much better experience",
                  "score": 3,
                  "created_utc": "2025-12-27 21:09:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwa2ind",
          "author": "tittock",
          "text": "I'm such a noob.. but how do i add this to comfy? where can I find a workflow?",
          "score": 1,
          "created_utc": "2025-12-28 00:14:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwcinhz",
          "author": "Zestyclose_Bake3680",
          "text": "it seems that works lora and diffsynth model patcher  \n[https://github.com/ussoewwin/ComfyUI-QwenImageLoraLoader](https://github.com/ussoewwin/ComfyUI-QwenImageLoraLoader)",
          "score": 1,
          "created_utc": "2025-12-28 11:13:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwd6yts",
          "author": "neofuturo_ai",
          "text": "buggy as hell.. waiting for fixes",
          "score": 1,
          "created_utc": "2025-12-28 14:19:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nweis7v",
          "author": "oneFookinLegend",
          "text": "I just read the github and still have no idea what this is",
          "score": 1,
          "created_utc": "2025-12-28 18:26:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwcrgcr",
          "author": "Disastrous_Pea529",
          "text": "unnecessary conversion. the model is already small and compact. energy and effort should have been used elsewhere.",
          "score": -1,
          "created_utc": "2025-12-28 12:31:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw74dqc",
          "author": "MarxN",
          "text": "And why are you excited?",
          "score": -27,
          "created_utc": "2025-12-27 14:51:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw75m0g",
              "author": "Gaia2122",
              "text": "OP never mentioned any excitement on their part. They just shout it out.",
              "score": 13,
              "created_utc": "2025-12-27 14:58:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw7d9g9",
                  "author": "MarxN",
                  "text": "Just wanted to understand what is so special with nunchaku",
                  "score": -8,
                  "created_utc": "2025-12-27 15:41:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pugyqx",
      "title": "Z-Image-Turbo: nunchaku NVFP4 works on 16GB cards without offloading",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/o21vsa0jm39g1.png",
      "author": "reto-wyss",
      "created_utc": "2025-12-24 06:52:37",
      "score": 167,
      "num_comments": 34,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pugyqx/zimageturbo_nunchaku_nvfp4_works_on_16gb_cards/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nvoqxjr",
          "author": "shapic",
          "text": "Fp16 version is 12gb. It also works on 16gb cards without offloading ðŸ¤”",
          "score": 77,
          "created_utc": "2025-12-24 08:16:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvpg53p",
              "author": "reto-wyss",
              "text": "That's just the bit that does the latent space manipulation. There may be some confusion around \"offloading\". \n\n**With the regular model, you have to swap the text-encoder in and out of VRAM after every prompt, with this you don't have to swap, so it's a huge speed boost.**",
              "score": 8,
              "created_utc": "2025-12-24 12:17:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvplmxl",
                  "author": "shapic",
                  "text": "Huh? You just offload it to cpu fully, that's it. There is not much computation for text encoding over there. \nAlso don't forget that you can quantize both.\n\nAlso there is no confusion. Offloading is when you have to offload part of weights of single network to other device. Nothing else. Swapping models in vram and loading one to ram and other to vram is not offloading. And I don't see much point in loading llm in vram if it is not used as an llm. I'd better have quality than save couple seconds",
                  "score": 23,
                  "created_utc": "2025-12-24 12:59:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvres99",
                  "author": "5138298",
                  "text": "the text encoder is fast even on CPU, u just offload that.",
                  "score": 3,
                  "created_utc": "2025-12-24 19:08:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvosb40",
          "author": "DarkStrider99",
          "text": "I am very confused, isn't the full ZIT model 12gb?",
          "score": 30,
          "created_utc": "2025-12-24 08:29:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvpg6g1",
              "author": "reto-wyss",
              "text": "That's just the bit that does the latent space manipulation. There may be some confusion around \"offloading\".\n\n**With the regular model, you have to swap the text-encoder in and out of VRAM after every prompt, with this you don't have to swap, so it's a huge speed boost.**",
              "score": 1,
              "created_utc": "2025-12-24 12:17:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvplst2",
                  "author": "shapic",
                  "text": "You just sit it in cpu and forget about it",
                  "score": 18,
                  "created_utc": "2025-12-24 13:00:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvovrh9",
              "author": "stddealer",
              "text": "It's 24GB, using full f32 precision.\n\nEdit: not sure why that is getting downvoted? I'm just stating a fact: https://huggingface.co/Tongyi-MAI/Z-Image-Turbo/tree/main/transformer",
              "score": -5,
              "created_utc": "2025-12-24 09:03:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvp28gv",
                  "author": "DarkStrider99",
                  "text": "Isnt it visually no difference between the two?",
                  "score": 9,
                  "created_utc": "2025-12-24 10:08:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvoyffk",
          "author": "Simple_Echo_6129",
          "text": "FYI all of the scripts used to build the Python wheels are in the scripts folder: https://github.com/nunchaku-tech/nunchaku/tree/main/scripts\n\nFor example, to build on Windows for my particular Python / Pytorch / Cuda combo I had to run: `scripts\\build_windows_wheel.cmd 3.12 2.9 13.0`\n\nThis took almost 20 minutes to build with all cores maxed out and this is on a quite powerful machine. So I wouldn't recommend taking this approach if you've got a weak system, it's better to wait for the official nunchaku release.",
          "score": 8,
          "created_utc": "2025-12-24 09:30:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvon63h",
          "author": "lumos675",
          "text": "How long for an image it needs?",
          "score": 7,
          "created_utc": "2025-12-24 07:40:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvozo8b",
              "author": "Significant-Pause574",
              "text": "I get a good 1024x1024 image using the 16bit model generated in 40 seconds using my 3060 12gb card. I have 32gb ram.",
              "score": 3,
              "created_utc": "2025-12-24 09:43:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvpgero",
              "author": "reto-wyss",
              "text": "around 2 seconds for 1024x1024 on a 5090.",
              "score": 5,
              "created_utc": "2025-12-24 12:19:16",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nvsz8na",
              "author": "Numerous-Entry-6911",
              "text": "5s for 1024x1024 on a 5070 Ti.",
              "score": 1,
              "created_utc": "2025-12-25 01:05:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvpus3a",
          "author": "EmbarrassedGrape7832",
          "text": "I think this guy just wanted to flex his 5090",
          "score": 9,
          "created_utc": "2025-12-24 13:59:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvq4sc2",
          "author": "Ill_Ease_6749",
          "text": "why need nunchaku without loras when normal model works on 8gb?",
          "score": 5,
          "created_utc": "2025-12-24 14:59:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvpqwn7",
          "author": "Current-Row-159",
          "text": "Can you tell me about speed generation with 2048x2048 using res_2s/beta57 with cfg 2.5 20steps ? Plz",
          "score": 1,
          "created_utc": "2025-12-24 13:35:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvptt5w",
          "author": "a_beautiful_rhind",
          "text": "I had issues with it failing to work using int4. Had to patch the node. cublas_ops was slightly faster and supported lora but used more memory.",
          "score": 1,
          "created_utc": "2025-12-24 13:53:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsj6hu",
          "author": "IrisColt",
          "text": "those feet tho",
          "score": 1,
          "created_utc": "2025-12-24 23:12:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvst7kd",
          "author": "jib_reddit",
          "text": "It is kind of useless without posting your image render times, that is the whole point of Nunchaku models.Â ",
          "score": 1,
          "created_utc": "2025-12-25 00:22:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuimf2",
          "author": "SvenVargHimmel",
          "text": "I upvoted the OP for the effort. And upvoted the correction because a healthy discussion is important.Â \nI do think the OP learnt that limiting your card's VRAM doesn't simulate the fully reality of working with lower VRAM cards.Â ",
          "score": 1,
          "created_utc": "2025-12-25 09:07:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvv5hwe",
          "author": "yay-iviss",
          "text": "Do a comparison of time diff running with it and without it.",
          "score": 1,
          "created_utc": "2025-12-25 13:04:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw52f97",
          "author": "CardiologistOk175",
          "text": "i want a workflow",
          "score": 1,
          "created_utc": "2025-12-27 04:32:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvqaz1u",
          "author": "Salt-Willingness-513",
          "text": "i dont get it? of course a smaller model is faster?",
          "score": 1,
          "created_utc": "2025-12-24 15:33:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvqvgdm",
              "author": "stddealer",
              "text": "Not always true for image generation since compute power is often the limiting factor instead of memory bandwidth. And quantization can make computations slower, while lowering the bandwidth requirements.",
              "score": 1,
              "created_utc": "2025-12-24 17:23:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1py4bxf",
      "title": "Semantic Image Disassembler (SID) is a VLM-based tool for prompt extraction, semantic style transfer and re-composing (de-summarization).",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1py4bxf",
      "author": "Bra2ha",
      "created_utc": "2025-12-28 22:20:42",
      "score": 167,
      "num_comments": 22,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1py4bxf/semantic_image_disassembler_sid_is_a_vlmbased/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwhau6o",
          "author": "fatYogurt",
          "text": "How exactly prompts are â€œextractedâ€? Seems it Just use vision model to describe image with certain system prompts?",
          "score": 19,
          "created_utc": "2025-12-29 03:04:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwhg7cf",
              "author": "LocoMod",
              "text": "They took something simple and made it complex.",
              "score": 24,
              "created_utc": "2025-12-29 03:35:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwhhlte",
              "author": "SufficientRow6231",
              "text": "Yeah, at first I saw the fancy name and thought there was some new breakthrough tech in how AI models â€œseeâ€ images. But after seeing it hosted on Civit with no paper link, I guessed it was just another GUI.\n\nAnd yeah, it turned out to be Python + Gradio, with a system prompt inside the script that can be reused anywhere with tools like llama.cpp, lm studio, ollama, vllm, transformers or even some custom ComfyUI nodes that support custom system prompts.   \n  \nSo â€œSemantic Image Disassembler,â€ itâ€™s basically just a gui with fancy name that execute a few tasks together and can handles them at once ðŸ˜‚",
              "score": 14,
              "created_utc": "2025-12-29 03:44:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwigf7v",
                  "author": "NineThreeTilNow",
                  "text": "The author didn't try to deceive you. He built a tool he needed and shared it.\n\nExactly what did you do? \n\nShit on the idea?",
                  "score": 3,
                  "created_utc": "2025-12-29 08:07:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwg1hj5",
          "author": "yaz152",
          "text": "Thanks.  I adjusted it to work with Koboldcpp since I already had that and the Qwen3-VL GGUF file and it works well.",
          "score": 7,
          "created_utc": "2025-12-28 22:53:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwge3dn",
              "author": "LightOfUriel",
              "text": "Can you post the patch somewhere to save us in the same situation some time?",
              "score": 6,
              "created_utc": "2025-12-29 00:00:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwgh3o0",
                  "author": "yaz152",
                  "text": "[https://files.catbox.moe/969o3e.py](https://files.catbox.moe/969o3e.py)\n\nChanges:  \n\\-switched to koboldcpp API  \n\\-model recognized by API  \n\\-creates text file using image file name (previously would just overwrite one text file with each process)\n\nThanks again to OP, really love the different levels of prompt scraping.",
                  "score": 9,
                  "created_utc": "2025-12-29 00:16:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwg5h6i",
              "author": "Bra2ha",
              "text": "Is it an analog of LM Studio?",
              "score": 1,
              "created_utc": "2025-12-28 23:14:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwgb6aj",
                  "author": "yaz152",
                  "text": "Yeah.  I believe it came out before LM Studio, but they both do similar things.  I use koboldcpp as a backend for Sillytavern and didn't want to have 2 apps that did the same thing.  I also adjusted it so you don't need to manually enter the model name in the .py file.  Now it just recognizes it via the API.  And by me, I mean Gemini Pro.",
                  "score": 7,
                  "created_utc": "2025-12-28 23:45:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwin8bc",
                  "author": "SvenVargHimmel",
                  "text": "Do you think you could post this on GitHub, some of us in the UK don't have ready access to civitai anymoreÂ ",
                  "score": 1,
                  "created_utc": "2025-12-29 09:11:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwhuzzt",
          "author": "StardockEngineer",
          "text": "lol they way over explained image2text2image",
          "score": 16,
          "created_utc": "2025-12-29 05:09:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwipi37",
          "author": "iamthenightingale",
          "text": "This wording of this post is the AI equivalent of the Rockwell Retro Encabulator ðŸ˜‚ -\n\nhttps://youtu.be/RXJKdh1KZ0w?si=J8m55B6AcEf3GhUS",
          "score": 5,
          "created_utc": "2025-12-29 09:33:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwimht8",
          "author": "SvenVargHimmel",
          "text": "I love that it's easier than ever to contribute (so I've updated)Â  but it does hurt my head when I see python files being shared via pastebin/catbox etc and code being upload to civitai\n\n\nWhat happened to GitHub?",
          "score": 3,
          "created_utc": "2025-12-29 09:04:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlgi8i",
          "author": "Netsuko",
          "text": "Yeah but does this eliminate the problem of side fumbling?",
          "score": 1,
          "created_utc": "2025-12-29 19:17:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwif6we",
          "author": "G4ia",
          "text": "This is OUTSTANDING!!!",
          "score": 1,
          "created_utc": "2025-12-29 07:56:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwgwwc8",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 0,
          "created_utc": "2025-12-29 01:43:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwh1l46",
              "author": "yaz152",
              "text": "that depends on what vision model you load.",
              "score": 2,
              "created_utc": "2025-12-29 02:10:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pvz1re",
      "title": "They slightly changed the parameter table in Z-Image Github page",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1pvz1re",
      "author": "zanmaer",
      "created_utc": "2025-12-26 08:02:14",
      "score": 163,
      "num_comments": 72,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pvz1re/they_slightly_changed_the_parameter_table_in/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nvzwj1b",
          "author": "BoneDaddyMan",
          "text": "![gif](giphy|xjXok06oc67ObUJwLQ)",
          "score": 55,
          "created_utc": "2025-12-26 08:38:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw22ws0",
              "author": "hurrdurrimanaccount",
              "text": "a lot of people are going to be ultra upset because they'll be expecting the same level of speed and quality from base. \n\nthe tears of promptlets are going to be gloorious",
              "score": -3,
              "created_utc": "2025-12-26 18:00:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvzvpvo",
          "author": "Enshitification",
          "text": "I'm not surprised. I was laughing my ass off when I originally saw that they rated their own model as bad quality.",
          "score": 108,
          "created_utc": "2025-12-26 08:29:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvzwl30",
              "author": "Sharlinator",
              "text": "Yep, definitely hadnâ€™t gotten OKâ€™d by Marketing, that one :D",
              "score": 51,
              "created_utc": "2025-12-26 08:38:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw19581",
                  "author": "Whispering-Depths",
                  "text": "To be fair we should take it as the warning it is and be humble in our criticism, and keep an open-mind in regards to fine-tunability.",
                  "score": 18,
                  "created_utc": "2025-12-26 15:21:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw04609",
              "author": "intLeon",
              "text": "Nasa sleeve ah naming",
              "score": 2,
              "created_utc": "2025-12-26 09:58:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvzw4wa",
          "author": "Jackburton75015",
          "text": "Well they updated the quality, good then ðŸ¤­",
          "score": 15,
          "created_utc": "2025-12-26 08:34:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvztohk",
          "author": "Proper-Employment263",
          "text": "Hard --> N/A",
          "score": 20,
          "created_utc": "2025-12-26 08:08:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw4qmy6",
              "author": "Tall_East_9738",
              "text": "Bad --> Medium",
              "score": 1,
              "created_utc": "2025-12-27 03:11:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw0arhq",
          "author": "MonkeyCartridge",
          "text": "![gif](giphy|LRCxXWRljt4LYf6AK1)",
          "score": 19,
          "created_utc": "2025-12-26 11:05:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvztce7",
          "author": "Structure-These",
          "text": "Back to sleep I go",
          "score": 11,
          "created_utc": "2025-12-26 08:04:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0jx5x",
          "author": "Genocode",
          "text": "When ZIT released and I said that turbo/lightning distills have low diversity people started saying that the people who released it said that there won't be difference in diversity.\n\nWell looky here.",
          "score": 9,
          "created_utc": "2025-12-26 12:31:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzu5qh",
          "author": "Spezisasackofshit",
          "text": "Shout-out to the AI toolkit guy for making that N/A change to Hard. Honestly been super happy with zimage turbo Lora's for characters. Model of myself was super easy to train and makes for some fun fake photos.",
          "score": 20,
          "created_utc": "2025-12-26 08:13:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw03t48",
              "author": "Creeperbowling",
              "text": "It changed from hard to N/A not the opposite",
              "score": 33,
              "created_utc": "2025-12-26 09:55:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw1uz8u",
                  "author": "KallyWally",
                  "text": "Yes, but without his distillation workaround, it would be  N/A in practice.",
                  "score": 5,
                  "created_utc": "2025-12-26 17:19:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvzunce",
              "author": "shivdbz",
              "text": "You like male face on females?",
              "score": -17,
              "created_utc": "2025-12-26 08:18:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvzxowj",
                  "author": "BoneDaddyMan",
                  "text": "if you manage to fix catastrophic forgetting so the LoRas can identify which face the lora only applies to, wake me up.",
                  "score": 6,
                  "created_utc": "2025-12-26 08:50:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvzxgq7",
          "author": "l0ngjohnson",
          "text": "Can someone explain will it be possible to distill the finetuned base model by myself?",
          "score": 4,
          "created_utc": "2025-12-26 08:48:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw09urs",
              "author": "Nexustar",
              "text": "How many A100s do you control, and how long do you have?\n\nBut yes, regular humans can finetune base models when they have the GPU memory and time.",
              "score": 0,
              "created_utc": "2025-12-26 10:56:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw0kad2",
                  "author": "l0ngjohnson",
                  "text": "I am sorry for inaccurate question. Will the scripts be provided for the distillation? Or maybe it's already available?",
                  "score": 2,
                  "created_utc": "2025-12-26 12:34:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw074f4",
          "author": "alitadrakes",
          "text": "z-image-omni-base \"Visual Quality\" \"Bad\" \"ðŸ˜­\"",
          "score": 4,
          "created_utc": "2025-12-26 10:29:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0g4kr",
              "author": "Desm0nt",
              "text": "It's fine for a base model. It's main purpose is to train good-quality lora for \"good\" turbo. Illustrious 0.1 also bad compare to WAI/Noob models, however lora trained on il 0.1 works on wai/noob better than noob-based. And no one use them on vanilla illustrious.\n\n\nThe second purpose is to be the base for future finetunes, that'll deliver both necessary \"content\" and quality :)",
              "score": 10,
              "created_utc": "2025-12-26 11:57:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw1at89",
                  "author": "alitadrakes",
                  "text": "Ah i see, my hope revived",
                  "score": 2,
                  "created_utc": "2025-12-26 15:31:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw30vm4",
                  "author": "AmazinglyObliviouse",
                  "text": "Due to the arch changes, I really don't think omni will be doing much on that front. Better off waiting for the sft version which removes edit functionality which was the base for turbo.",
                  "score": 1,
                  "created_utc": "2025-12-26 21:02:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvztzyb",
          "author": "mulletarian",
          "text": "Can someone help me understand how a distilled model could have higher \"visual quality\" than the base model?",
          "score": 8,
          "created_utc": "2025-12-26 08:11:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvzua9k",
              "author": "chrd5273",
              "text": "Turbo underwent RLHF on top of distillation.",
              "score": 26,
              "created_utc": "2025-12-26 08:14:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvzulxf",
                  "author": "shivdbz",
                  "text": "RLHF mean? We are not technical",
                  "score": 7,
                  "created_utc": "2025-12-26 08:18:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvzuwfd",
              "author": "zanmaer",
              "text": "Based on the paper, as I understand it, they used Decoupled DMD during distillation, which ultimately resulted in good image quality but a very significant loss in diversity.",
              "score": 7,
              "created_utc": "2025-12-26 08:21:03",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nvzuz6x",
              "author": "United-Ad6282",
              "text": "RL  å¼ºåŒ–å­¦ä¹ ",
              "score": 3,
              "created_utc": "2025-12-26 08:21:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw0leq9",
          "author": "Extra-Fig-7425",
          "text": "Sorry for the noob question.. Why would people want the Omni base if the turbo has better quality?",
          "score": 4,
          "created_utc": "2025-12-26 12:43:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0mf93",
              "author": "zanmaer",
              "text": "Omni Base will most likely replace SD and SDXL in the field of fine tuning models from the community. At the start, of course, in theory, Omni Base will lose out in image quality to the Turbo version, but in a few months, when enthusiasts start releasing their custom builds and loras, the situation may look different",
              "score": 21,
              "created_utc": "2025-12-26 12:52:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw0mlty",
                  "author": "Extra-Fig-7425",
                  "text": "ah.. amazing, thank you for explaining :)",
                  "score": 3,
                  "created_utc": "2025-12-26 12:53:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw1msnk",
                  "author": "Fabulous-Ad6846",
                  "text": "SDXl ainâ€™t going anywhere until Z-image models can generate genitals",
                  "score": 5,
                  "created_utc": "2025-12-26 16:35:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw1o9xn",
              "author": "_BreakingGood_",
              "text": "Think of it like pizza dough. \n\nTurbo is a fully cooked pizza delivered right to your door. Delicious, hot, and ready\n\nBase is raw pizza dough. You wouldn't eat raw pizza dough. But you also have a lot more freedom to decide what to do with it. You can turn it into a calzone, or even add some cinnamon/sugar and turn it into a dessert. \n\nIt would overall be not great to turn a fully cooked pizza into a calzone, and would be almost impossible to turn it into a dessert. \n\nSo the idea is that they're giving us something a bit underbaked so that we can \"finish the pizza\" ourselves. Turn it into an anime model etc... Versus trying to take a fully cooked model and forcing that to be something fundamentally different.",
              "score": 14,
              "created_utc": "2025-12-26 16:43:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw1vygg",
                  "author": "Hoodfu",
                  "text": "https://preview.redd.it/g9dsh9dt1l9g1.png?width=1928&format=png&auto=webp&s=4d212a42cbc9ec0e33704d83bd2f5a7e3aff4c35\n\nMade with zimage turbo. prompt: \"A split-scene conceptual illustration: On the left side, a delivery driver robot hands over a perfectly cooked, steaming pepperoni pizza in an open box labeled 'TURBO' with a lightning bolt, glowing warmly under neon signs reading 'READY TO SERVE' â€” On the right side, a creative artist's kitchen workshop where a ball of raw golden pizza dough sits on a wooden board surrounded by endless possibilities: calzone molds, dessert toppings (cinnamon, sugar, chocolate), anime-style character cookie cutters, paint brushes, and digital tablets, with floating holographic previews showing the dough transforming into different creations (calzone, cinnamon rolls, anime character, abstract art) â€” The two sides connected by a glowing gradient bridge with text 'BASE â†’ YOUR VISION' â€” Modern tech-meets-artisan aesthetic, warm bakery lighting mixed with cool digital blue accents, infographic style with clean visual storytelling, 4K detailed illustration\"",
                  "score": 9,
                  "created_utc": "2025-12-26 17:24:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw3jubv",
              "author": "yomasexbomb",
              "text": "It's in the chart. It's the only model that can do both Gen and Edit",
              "score": 1,
              "created_utc": "2025-12-26 22:46:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw1ij3p",
          "author": "TopTippityTop",
          "text": "Not bad anymore, I guess. ðŸ˜‚",
          "score": 1,
          "created_utc": "2025-12-26 16:13:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw27w8q",
          "author": "reddit-369",
          "text": "good,very good",
          "score": 1,
          "created_utc": "2025-12-26 18:26:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw2xepw",
          "author": "Lucaspittol",
          "text": "I mean, they TOTALLY changed it.",
          "score": 1,
          "created_utc": "2025-12-26 20:43:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw4f6ej",
          "author": "urbanhood",
          "text": "Keeping expectations in check.",
          "score": 1,
          "created_utc": "2025-12-27 01:57:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw1g5ug",
          "author": "Available-Body-9719",
          "text": "si el modelo turbo te parece bueno entonces el omni te parecera  malo,  pero si el modelo turbo te parece  muy bueno entonces este te parecera regular",
          "score": 1,
          "created_utc": "2025-12-26 16:00:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzvxjc",
          "author": "DaddyBurton",
          "text": "I feel like this was intentional. Considering how much of a \"hit\" Z-Image Turbo has been, and nearly everyone was raving about it. I would not be surprised if they delayed Z Image omni, as they did, because they wanted to release and make it look like further training omni-base came out as a worse product, but in actuality, they didn't want to release a better version and keep it closed source for, what could be, financial gain. But that's just a wild crack-pot theory.\n\nI'm sure they worked hard on whatever they're going to provide. Even if it isn't great, I'm sure there will be some good use cases for it.",
          "score": 0,
          "created_utc": "2025-12-26 08:31:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw077be",
              "author": "cavaliersolitaire",
              "text": "Yep at some point we need to realize these are businesses not charity organizations...  \nThey'll have a closed source version for sure",
              "score": 5,
              "created_utc": "2025-12-26 10:30:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw0fsud",
          "author": "Sudden-Complaint7037",
          "text": "i hate the edging so much. like, just release your models or don't, but don't give me this bullshit of teasing it over months. this makes me actively NOT want to try it when it comes out.",
          "score": -7,
          "created_utc": "2025-12-26 11:54:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw171oq",
              "author": "ThexDream",
              "text": "You're \"ass\"-uming that anyone cares whether you try it or not, considering you revel in being an insufferable and entitled \"\\_\\_\\_\\_\".",
              "score": 1,
              "created_utc": "2025-12-26 15:09:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw1ljzv",
                  "author": "Sudden-Complaint7037",
                  "text": "\"muh who asked who cares\"\n\nthis is a public forum dipshit, i can voice my opinion without asking for your fucking permission",
                  "score": 2,
                  "created_utc": "2025-12-26 16:29:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw7xcvg",
          "author": "Pitiful-Language-342",
          "text": "They changed from \"hard\" to \"N/A\" because they're prepating a finetune anime of z-image-turbo, they asked noobAI's datasets. They don't want people to finetune z-image-turbo before them.",
          "score": 0,
          "created_utc": "2025-12-27 17:22:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw087g4",
          "author": "Confusion_Senior",
          "text": "That is because ostris did his trick with the deturbo thing",
          "score": -6,
          "created_utc": "2025-12-26 10:40:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw08vl5",
              "author": "Dezordan",
              "text": "That's not really what new table shows, though. It was \"hard\", but now it is N/A in terms of finetunabilty. So, they fully ignored that adapters existence.\n\nDedistill is a separate model altogether.",
              "score": 8,
              "created_utc": "2025-12-26 10:47:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw16hc9",
          "author": "Aromatic-Current-235",
          "text": "It is suspicious that Z-Image-Trubo has still the highest visual quality. It is like claiming that flux.1 \"schnell\" had a better visual quality than flux.1 â€œdev,\" which is ridiculous.",
          "score": -7,
          "created_utc": "2025-12-26 15:06:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw17cyx",
              "author": "zanmaer",
              "text": "This comparison is not entirely accurate. The point here is that the Turbo version was distilled in a rather unusual way. They used RLHF and Decoupled DMD during distillation.",
              "score": 6,
              "created_utc": "2025-12-26 15:11:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw1tgx6",
                  "author": "LardonFumeOFFICIEL",
                  "text": "In a hypothetical world, I would love to understand all these complicated things ðŸ˜…ðŸ¤ŒðŸ»",
                  "score": 1,
                  "created_utc": "2025-12-26 17:11:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pynm1v",
      "title": "Trying some different materials with SCAIL",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/idj1t5fqk5ag1",
      "author": "theNivda",
      "created_utc": "2025-12-29 14:27:21",
      "score": 152,
      "num_comments": 18,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "No Workflow",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pynm1v/trying_some_different_materials_with_scail/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwk72lz",
          "author": "thisiztrash02",
          "text": "scail makes wan animate look like  a toy",
          "score": 17,
          "created_utc": "2025-12-29 15:44:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwl7iev",
              "author": "Immediate-Mood-4383",
              "text": "It depends on what you use it for. If your only goal is to make dancing videos without lipsync, then yes, scail is better. I personally dotn make any dancing videos.",
              "score": 6,
              "created_utc": "2025-12-29 18:35:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwljegk",
                  "author": "tofuchrispy",
                  "text": "So Animate is better at facial animation also when only using prompt ? I guess scail doesnâ€™t do the face tracking",
                  "score": 2,
                  "created_utc": "2025-12-29 19:31:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwtoxis",
                  "author": "SuperGeniusWEC",
                  "text": "Yeah, lipsync is a problem, so are facial expressions (yes, WAN is better at facial expressions but they're still not there yet) but it's still impressive how much progress these models are making.",
                  "score": 1,
                  "created_utc": "2025-12-30 23:52:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwmkj6e",
                  "author": "thisiztrash02",
                  "text": "I don't know where you got this info from scail does great with mouth and facial movement ..wan animate just does facial animation in a less resource hungry manner so if that's all you do then sure using wan might be a better choice..",
                  "score": 1,
                  "created_utc": "2025-12-29 22:33:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwmkloa",
              "author": "Segaiai",
              "text": "What's interesting is that this is a preliminary version of the model. We don't have the full version.",
              "score": 1,
              "created_utc": "2025-12-29 22:33:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwk351z",
          "author": "Greedy_Ad7571",
          "text": "Reminds me of Major Lazer â€“ Light it UpÂ  ...nice",
          "score": 7,
          "created_utc": "2025-12-29 15:25:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkdkhq",
          "author": "grmndzr",
          "text": "great idea! some of the materials are a bit stiff but the progress for local gen is insane this past year",
          "score": 3,
          "created_utc": "2025-12-29 16:15:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmhx0e",
          "author": "ImpossibleAd436",
          "text": "Can I run this on my 3060 12 GB with 32GB system RAM?",
          "score": 1,
          "created_utc": "2025-12-29 22:20:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwmohsd",
              "author": "DMmeURpet",
              "text": "I've struggled to see what this needs. I struggle to get wananimate run at reasonable speeds on my 3090 but presume this needs even more",
              "score": 3,
              "created_utc": "2025-12-29 22:54:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwshbbz",
                  "author": "FightingBlaze77",
                  "text": "My 5070 takes about 10 minutes to gen a 5 second clip with wan 2.1 im sure animate would take more",
                  "score": 1,
                  "created_utc": "2025-12-30 20:14:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwnkr1q",
          "author": "Frogy_mcfrogyface",
          "text": "I want to cuddle with pillow guy",
          "score": 1,
          "created_utc": "2025-12-30 01:51:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwphjrv",
          "author": "donkeykong917",
          "text": "Have you tried animals?",
          "score": 1,
          "created_utc": "2025-12-30 10:11:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwpjh6s",
              "author": "theNivda",
              "text": "Nope, but interesting. Will try",
              "score": 2,
              "created_utc": "2025-12-30 10:29:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwpjsjf",
                  "author": "donkeykong917",
                  "text": "I pro should too. I've been just doing humans",
                  "score": 1,
                  "created_utc": "2025-12-30 10:32:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwplgc8",
                  "author": "donkeykong917",
                  "text": "It does work to a degree, but I only tried an animated cat standing up",
                  "score": 1,
                  "created_utc": "2025-12-30 10:47:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwkl7mc",
          "author": "Beneficial_Toe_2347",
          "text": "Why are you using this if you're just making dancing videoa",
          "score": -2,
          "created_utc": "2025-12-29 16:51:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pvx6cu",
      "title": "TurboDiffusion: 100â€“200Ã— Acceleration for Video Diffusion Models",
      "subreddit": "StableDiffusion",
      "url": "https://github.com/thu-ml/TurboDiffusion",
      "author": "pwnies",
      "created_utc": "2025-12-26 06:04:14",
      "score": 148,
      "num_comments": 47,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pvx6cu/turbodiffusion_100200_acceleration_for_video/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "nvzguba",
          "author": "pwnies",
          "text": "Looks like there is some quality reduction, but nonetheless 2s to generate a 5s video on a 5090 for WAN 2.1 is absolutely crazy.",
          "score": 67,
          "created_utc": "2025-12-26 06:06:29",
          "is_submitter": true,
          "replies": [
            {
              "id": "nw02q8c",
              "author": "ItsAMeUsernamio",
              "text": "I tried Sageattention 3 on Linux and the quality degradation turns a 720p video into more like 240p with a checkboarding effect. And itâ€™s nowhere as fast as this. It seems everyone forgot about it since thereâ€™s no discussions of it and no oneâ€™s gotten it to compile for Windows.\n\nThis looks a lot better from their previews.",
              "score": 13,
              "created_utc": "2025-12-26 09:43:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw1bnw0",
                  "author": "jacobpederson",
                  "text": "It \"works\" on windows in comfy - but is more of a 6x speed decrease :D",
                  "score": 5,
                  "created_utc": "2025-12-26 15:35:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw1klr0",
              "author": "AconexOfficial",
              "text": "I wonder if this could somehow be utilized to finally enable proper real time video diffusion",
              "score": 2,
              "created_utc": "2025-12-26 16:24:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvzpgic",
              "author": "arentol",
              "text": "How I would use it is with RG3 Group Muter. Generate videos with just the core node group and turbo \"group\" enabled. Once I get a video I really like I would unmute the rest of my workflow. Then run the same seed and settings again to generate a higher quality version, then upscale, do interpolation, and all the other stuff to make it better.",
              "score": 2,
              "created_utc": "2025-12-26 07:25:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw0uyum",
              "author": "serendipity777321",
              "text": "Bro can you show a few examples of 100x turbo renders?",
              "score": 1,
              "created_utc": "2025-12-26 13:53:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw2844i",
                  "author": "pwnies",
                  "text": "Theyâ€™re on the page I linked you attention-deficit dunce.",
                  "score": -6,
                  "created_utc": "2025-12-26 18:27:42",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvzhi3b",
          "author": "Enshitification",
          "text": "Apart from the quality hit, is there a difference in output between TurboDiffusion and regular gens? If not, then this could be great for large batch generations to find the best ones before running them again at full quality.",
          "score": 31,
          "created_utc": "2025-12-26 06:12:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvzm08u",
              "author": "protector111",
              "text": "true. also even if it is - you can always drop the video to video2video to increase quality with regular wan",
              "score": 11,
              "created_utc": "2025-12-26 06:52:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvztnzs",
                  "author": "digvijay01",
                  "text": "Is increasing quality even possible with video to video? Could you explain how?",
                  "score": 1,
                  "created_utc": "2025-12-26 08:08:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvzlgqn",
              "author": "FinalCap2680",
              "text": "Yes, but examples look quite different. Still, maybe will help experimenting with the prompts in the beginning...",
              "score": 1,
              "created_utc": "2025-12-26 06:47:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw28d0c",
              "author": "pwnies",
              "text": "It seems like it - check the examples. Thereâ€™s a bit less body awareness in the 100x vids",
              "score": 1,
              "created_utc": "2025-12-26 18:28:59",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nw2n08p",
              "author": "throttlekitty",
              "text": "Often with this kind of thing, the model needs to take large hops and shortcuts, so a broad selection of dog breeds might get reduced down to a selection of a few, if the prompt isn't specific about that. So the outputs will often be very different.",
              "score": 0,
              "created_utc": "2025-12-26 19:46:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvznqkv",
          "author": "willwm24",
          "text": "Wild, based on the demos even if it is visibly worse, it's still way better than what we had a year ago and it's insanely fast. hope to try it in comfy soon.",
          "score": 23,
          "created_utc": "2025-12-26 07:08:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw54t6t",
          "author": "goddess_peeler",
          "text": "I spent some time with the [ComfyUI wrapper](https://github.com/anveshane/Comfyui_turbodiffusion) version of this tonight. **TL;DR: It's fine.**\n\nI suspect a number of compromises must have been made for the ComfyUI wrapper, because it's certainly not 100 times faster than a regular I2V workflow. But it's a little faster, and I don't see any dramatic quality degradation.\n\nI have a 5090 GPU, 128GB of system RAM.\n\nThings I learned playing around:\n\n* layerwise\\_gpu is the only practical setting for offload\\_mode. With comfy\\_native, inference will consume 31 GB no matter what settings you use, limiting you to to 480x480 generations of less than 5 seconds. On the other hand, inference consumes 15-20GB with layerwise\\_gpu, even at 720p/81 frames. layerwise\\_gpu seems to be slower than comfy\\_native, but it's difficult to test well since comfy\\_native can only be run at small resolutions that generate in seconds.\n* three attention modes are offered: original, sla and sagesla. original crashes the workflow. sla and sagesla are tradeoffs for speed and VRAM. sla consumes a little less VRAM than sagesla, but runs a little slower. sagesla runs a little faster, but consumes more VRAM. We are talking about differences of 10 seconds and maybe 2GB of VRAM here. Given how difficult it was to build [sagesla](https://github.com/thu-ml/SpargeAttn), I don't think it's worth the trouble, unless you're really hurting for VRAM.\n\nIn an attempt to have some kind of data for comparison, I tested an I2V run on TurboDiffusion and the default I2V workflow. I ran each generation 3 times and averaged the times from the last two.\n\n*81 frames, 720x1280, seed 1234567890*\n\n|Model|Time|Parameters|\n|:-|:-|:-|\n|TurboDiffusion|76s|4 steps, sagesla, layerwise\\_gpu|\n|Wan 2.2|103s|4 steps, lightx2v 1030|\n|Wan 2.2|897s|20 steps, no loras|\n\nSo, on my system TurboDiffusion was about 1.4 times (40%) faster than a 4 step lightx2v generation, and about 11.8 times (1080%) faster than a 20 step unaccelerated Wan 2.2 generation. Obviously, this is just one test case, but I think it's representative of all the other runs I did tonight.\n\n[Here's a visual comparison of the results. ](https://imgur.com/a/8yfQOBI) I notice that TurboDiffusion added more of its own details and changed the figure in ways that the Wan generations did not. In the Wan clips, the trees in the background are more dynamic. They have three dimensions and move a little. They're static in the TurboDiffusion clip. The camera movement is less interesting in the Turbo Diffusion clip.\n\nI'll reiterate that I've been playing with the ComfyUI wrapper, not the official CLI release version. I don't know how much they differ from each other. It remains to be seen whether this workflow can be useful to me, but it's nice to know it's there. The model and the ComfyUI version will doubtless get better over time.",
          "score": 7,
          "created_utc": "2025-12-27 04:49:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzn42k",
          "author": "mulletarian",
          "text": "Guessing this is for 40xx gen cards and above?",
          "score": 4,
          "created_utc": "2025-12-26 07:02:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvzpib6",
              "author": "Jackburton75015",
              "text": "Nope only 50 series, Blackwell",
              "score": 12,
              "created_utc": "2025-12-26 07:25:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvzvhry",
                  "author": "Pure_Bed_6357",
                  "text": "it says 4090 in their link tho",
                  "score": 10,
                  "created_utc": "2025-12-26 08:27:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvzqjme",
                  "author": "mulletarian",
                  "text": "So it's an FP4 thing?",
                  "score": 5,
                  "created_utc": "2025-12-26 07:36:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvzmlvz",
          "author": "Turkino",
          "text": "That acceleration sounds insane.\nNot too thrilled about the idea of a degradation in quality though. Gonna have to check it out first hand see how much of a hit it's going to take.",
          "score": 7,
          "created_utc": "2025-12-26 06:58:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzwsmd",
          "author": "FinBenton",
          "text": "Damn realtime video generation on 5090? Im waiting for comfyui nodes and workflow.",
          "score": 3,
          "created_utc": "2025-12-26 08:41:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw1bz8u",
              "author": "jacobpederson",
              "text": "The reason nobody is talking about this is that the comfy version is more like a 6x speed decrease over regular WAN [https://github.com/anveshane/Comfyui\\_turbodiffusion](https://github.com/anveshane/Comfyui_turbodiffusion)",
              "score": 6,
              "created_utc": "2025-12-26 15:37:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw03jzh",
          "author": "uniquelyavailable",
          "text": "Would love to see this compared with [lightning](https://huggingface.co/lightx2v/Wan2.2-Lightning)",
          "score": 2,
          "created_utc": "2025-12-26 09:52:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3xfia",
          "author": "Dwedit",
          "text": "What are the VRAM requirements?",
          "score": 2,
          "created_utc": "2025-12-27 00:08:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzjrp7",
          "author": "CommercialOpening599",
          "text": "Looks like they have an I2V Wan 2.2 model available. I'm gonna check it out in the morning. Thanks for sharing!",
          "score": 1,
          "created_utc": "2025-12-26 06:32:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0qydg",
          "author": "Jacks_Half_Moustache",
          "text": "Tried it in comfy a couple days ago and the quality was abysmal.",
          "score": 1,
          "created_utc": "2025-12-26 13:26:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0v6k6",
              "author": "eye_am_bored",
              "text": "Do you just swap out the turbo model for the regular one in your workflow?",
              "score": 1,
              "created_utc": "2025-12-26 13:54:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw126ie",
                  "author": "Jacks_Half_Moustache",
                  "text": "No, if I remember correctly, it uses custom nodes and also needed some manual tweaks with the Python files as it only works with Python >3.12 and I was on 3.10. Someone else posted some examples on the sub as well and came to the conclusion that it was not worth using over the speed loras.",
                  "score": 2,
                  "created_utc": "2025-12-26 14:40:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw36wd2",
          "author": "ANR2ME",
          "text": "There are also GGUF version:\nhttps://huggingface.co/vantagewithai/TurboWan2.2-I2V-A14B-720P-ComfyUI-GGUF\n\nhttps://huggingface.co/vantagewithai/TurboWan2.1-T2V-14B-720P-ComfyUI-GGUF",
          "score": 1,
          "created_utc": "2025-12-26 21:35:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw496or",
              "author": "goddess_peeler",
              "text": "Important note: The [ComfyUI wrapper](https://github.com/anveshane/Comfyui_turbodiffusion) will only load .pth models.",
              "score": 1,
              "created_utc": "2025-12-27 01:19:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw52sqv",
                  "author": "ANR2ME",
                  "text": "Kijai wrapper also support turbo diffusion isn't ðŸ¤”",
                  "score": 1,
                  "created_utc": "2025-12-27 04:35:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw4gm0x",
          "author": "Green-Ad-3964",
          "text": "Is there any comfyui implementation, yet?\n\n\nAnd...why 2.2 is only i2v and not t2v?Â \n\n\nAnyway, since I have a 5090, I'd like to test this.\n\n\nThanks.",
          "score": 1,
          "created_utc": "2025-12-27 02:06:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw9bbyv",
              "author": "goddess_peeler",
              "text": "https://www.reddit.com/r/StableDiffusion/comments/1pvx6cu/comment/nw54t6t/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button",
              "score": 1,
              "created_utc": "2025-12-27 21:44:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvzqtbp",
          "author": "Mundane_Existence0",
          "text": "Still waiting on A Turbo for Wan 2.2 T2V",
          "score": 1,
          "created_utc": "2025-12-26 07:39:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzxhey",
          "author": "DsDman",
          "text": "So I guess this doesnâ€™t work with Ampere cards right?",
          "score": 1,
          "created_utc": "2025-12-26 08:48:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw1570h",
          "author": "Umbaretz",
          "text": "Cool in principle, but tends to OOM even on 5090 with modest gen settings. Also, I haven't noticed that much difference in speed with Lighting.    \nAnd this obviously doesn't support any loras.",
          "score": 1,
          "created_utc": "2025-12-26 14:58:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzzjj5",
          "author": "Cultural-Team9235",
          "text": "Tried it a few days back, got OOM's in ComfyUI, whatever I did, no matter the resolution.",
          "score": 0,
          "created_utc": "2025-12-26 09:10:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pw1rm8",
      "title": "2511 style transfer with inpainting",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1pw1rm8",
      "author": "CutLongjumping8",
      "created_utc": "2025-12-26 11:02:12",
      "score": 148,
      "num_comments": 22,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pw1rm8/2511_style_transfer_with_inpainting/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nw14fsv",
          "author": "roxoholic",
          "text": "Cool workflow, but examples show model is pretty bad at style transfer though.",
          "score": 15,
          "created_utc": "2025-12-26 14:54:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0bt0m",
          "author": "witcherknight",
          "text": "why not style transfer entire image",
          "score": 10,
          "created_utc": "2025-12-26 11:16:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0cepn",
              "author": "CutLongjumping8",
              "text": "Wellâ€¦ thatâ€™s kind of too easy and generic. You can also process the whole image by turning off the inpaint switch.",
              "score": 3,
              "created_utc": "2025-12-26 11:22:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw0w2ol",
          "author": "ResponsibleKey1053",
          "text": "Cool demo, appreciate the examples.\nOne one daft complaint, dyslexia and cursive writing do not mix, please use regular fonts.",
          "score": 3,
          "created_utc": "2025-12-26 14:00:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0cn3w",
          "author": "juandann",
          "text": "does inpaint work for removing object (without adding anything) too? if yes, how would you prompt it?",
          "score": 1,
          "created_utc": "2025-12-26 11:24:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0ehuz",
              "author": "CutLongjumping8",
              "text": "Sure it is possible - Remove aquarium\n\nhttps://preview.redd.it/613a8vbwcj9g1.jpeg?width=1506&format=pjpg&auto=webp&s=7a11c5078704a2d5444aa0e22dc06b732ca4644b",
              "score": 9,
              "created_utc": "2025-12-26 11:42:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw0h8iz",
                  "author": "juandann",
                  "text": "ooh awesome, i'll give it a try. Always fail to do such task with flux onereward",
                  "score": 2,
                  "created_utc": "2025-12-26 12:07:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwvms38",
                  "author": "juandann",
                  "text": "one more thing, are you forgot to connect this node? it looks like a prompt injection for outpainting\n\nhttps://preview.redd.it/z7zszn27rhag1.png?width=838&format=png&auto=webp&s=90c71fa2ed1ce78b951bd4b53e841fdc55845272",
                  "score": 1,
                  "created_utc": "2025-12-31 07:23:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw0lysm",
          "author": "darkphoenixfox",
          "text": "Using the exact models in the workflow I am getting this error:\n`mat1 and mat2 shapes cannot be multiplied (748x1280 and 3840x1280)`\n\nAny idea why this is happening?",
          "score": 1,
          "created_utc": "2025-12-26 12:48:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0m9ng",
              "author": "CutLongjumping8",
              "text": "usually such things happen when you select wrong clip model or wrong vae or model file is corrupt",
              "score": 5,
              "created_utc": "2025-12-26 12:50:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw17d19",
                  "author": "darkphoenixfox",
                  "text": "I tried the workflow exactly as it opens after downloading it, no changes. To make it work I had to disconnect the Cliploader(GGUF) node and connect the other Clip loader node above it (and change the setting to qwen)\n\nhttps://preview.redd.it/90fjzun5ek9g1.jpeg?width=543&format=pjpg&auto=webp&s=8e78269297b5263d613a4cd8cf8ef73673c2d8f7",
                  "score": 1,
                  "created_utc": "2025-12-26 15:11:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw6mxfm",
          "author": "ShreeyanxRaina",
          "text": "Can I use this on 8gb vram",
          "score": 1,
          "created_utc": "2025-12-27 12:58:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw8t7d8",
              "author": "CutLongjumping8",
              "text": "not sure that 8Gb is enough.. may be only with some small .gguf, but I can't test it on 8Gb - sorry.",
              "score": 1,
              "created_utc": "2025-12-27 20:05:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw0dqmw",
          "author": "CapitalHeart5049",
          "text": "Very creative",
          "score": 1,
          "created_utc": "2025-12-26 11:35:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0bbp2",
          "author": "MikePounce",
          "text": "Looks good, thanks!",
          "score": 0,
          "created_utc": "2025-12-26 11:11:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3ot2p",
          "author": "Best-Response5668",
          "text": "You should just have used NB Pro instead.",
          "score": -1,
          "created_utc": "2025-12-26 23:15:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw2hwjj",
          "author": "oromis95",
          "text": "There is no way the 2511 stuff isn't marketing and bots, this looks terrible.",
          "score": -4,
          "created_utc": "2025-12-26 19:18:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw4suti",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2025-12-27 03:26:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw4t60m",
                  "author": "oromis95",
                  "text": "LOL Do you all not notice it only transfers around the face? How is that acceptable? Gotta be paid.",
                  "score": 0,
                  "created_utc": "2025-12-27 03:28:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pw81t8",
      "title": "Z-Image-Turbo vs Nano Banana Pro",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1pw81t8",
      "author": "Artefact_Design",
      "created_utc": "2025-12-26 16:17:47",
      "score": 147,
      "num_comments": 60,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pw81t8/zimageturbo_vs_nano_banana_pro/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nw1ojrv",
          "author": "DigidyneDesignStudio",
          "text": "But one you have to pay for, the other you donâ€™t .",
          "score": 56,
          "created_utc": "2025-12-26 16:45:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw2zuck",
              "author": "MrUtterNonsense",
              "text": "For those simple types of prompts, Z-Image also easily winds on censorship.",
              "score": 14,
              "created_utc": "2025-12-26 20:56:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw3twox",
                  "author": "International-Try467",
                  "text": "What type of prompts though? Is it censored in other ways other than just naked women? (Or men)",
                  "score": 1,
                  "created_utc": "2025-12-26 23:46:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw3i8mv",
              "author": "Best-Response5668",
              "text": "NB is a fully-fledged image model that blows every other model out of the water, whereas Z-Image-Turbo is a primitive portrait slop generator.",
              "score": -8,
              "created_utc": "2025-12-26 22:37:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw1nlhf",
          "author": "flapjaxrfun",
          "text": "I think it's more about the i2i at this point. You can't really do that with z image without some complicated workflow. You definitely can't preserve someone's face without even more complicated workflows. Nanobanana handles both of those things out of the box right now.",
          "score": 42,
          "created_utc": "2025-12-26 16:40:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw1ww0p",
              "author": "One-UglyGenius",
              "text": "I guess zimage omni we are waiting for ðŸ¥³",
              "score": 19,
              "created_utc": "2025-12-26 17:29:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw25cfb",
                  "author": "gefahr",
                  "text": "Is there somewhere we can place wagers on whether or not it ends up being open weights? Vs another WAN 2.x situation?\n\nPrediction markets need to get in on this.",
                  "score": 5,
                  "created_utc": "2025-12-26 18:13:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw3oet1",
                  "author": "ddsukituoft",
                  "text": "omni or edit?",
                  "score": 2,
                  "created_utc": "2025-12-26 23:13:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw2y6ia",
              "author": "ErenYeager91",
              "text": "I dont see face preserving in NanoBanana, how to do that?",
              "score": 2,
              "created_utc": "2025-12-26 20:47:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwc4oq7",
              "author": "ellipsesmrk",
              "text": "Its not that complicated. I do it everyday.",
              "score": 1,
              "created_utc": "2025-12-28 08:58:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw1kjcq",
          "author": "Hoodfu",
          "text": "Both z image and flux 2 dev will handle 1000+ token prompts with extreme detail and handle it with ease. Point being, these super simple images that even SDXL could handle in some fashion aren't pushing anything about the new models.",
          "score": 28,
          "created_utc": "2025-12-26 16:23:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw39f3l",
          "author": "TechnologyGrouchy679",
          "text": "without your prompts this is a useless shit comparison.",
          "score": 16,
          "created_utc": "2025-12-26 21:48:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw1pvta",
          "author": "Lucaspittol",
          "text": "Nano Banana is a multi-editing model; Z-Image, for now, is just text-to-image. Don't get me wrong, Z-Image is a very cool model. A proper comparison should be Flux 2 X Nano Banana Pro if you want to compare something we can run locally versus a \"black box model\" we don't know much about.",
          "score": 11,
          "created_utc": "2025-12-26 16:52:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nweeoy4",
              "author": "Denimdem0n",
              "text": "You mean Flux 2? This super heavily censored model that is too big for a 5090?! haha okay...  \nWe should start to accept that it is not 2023 anymore and models for image and (especially) for video creation which run on Home user PC's will never be able to seriously compete with those of multi-billion-dollar companies who host their models on infinite high-end hardware server farms. It is pure logic.",
              "score": -1,
              "created_utc": "2025-12-28 18:07:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwh2lbv",
                  "author": "Lucaspittol",
                  "text": "Because Z-Image is not an editing model, also, Nano Banana is much larger, probably even larger than Flux 2, but it is the best we can run locally now, not going closed-source. Censorship in Flux 2 can be bypassed by loras; there are a few sketchy ones already on civitai. Nano Banana is censored in the front end; no way to bypass that.",
                  "score": 2,
                  "created_utc": "2025-12-29 02:16:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwpuys4",
                  "author": "Erhan24",
                  "text": "At what point of release was flux2 too big for 5090? Never. I used it day 1 on my 4090 so stop spreading misinformation please.",
                  "score": 1,
                  "created_utc": "2025-12-30 12:08:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw43884",
          "author": "Time-Teaching1926",
          "text": "The fact this is only done on the turbo model and without the gigantic training data that Nano banana Pro has is actually incredible and actually kind of crazy. Especially as it's only six billion parameters. I think it shows how powerful having Qwen3 as a text encoder really is, I think flux 2 Dev has Mistral as the text encoder as well. I feel like if we had a powerful text encoder on SDXL and Illustrious I think it could be incredible as well. Especially with the prompt adherence.",
          "score": 3,
          "created_utc": "2025-12-27 00:42:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr979y",
              "author": "Lucaspittol",
              "text": "These are very generic, to be honest, nothing here is really pushing the limits of what the models can achieve. The gigantic training data of nano banana can push it much, much further than any model from Tongyi.",
              "score": 1,
              "created_utc": "2025-12-30 16:48:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwrayff",
                  "author": "Time-Teaching1926",
                  "text": "True but for a open source and with many different community Checkpoints and Lora ir will be a matter of time until before we get to a very near Nano Banana Pro open source and hopefully uncensored (like SDXL and Illustrious fine tunes) competitor.",
                  "score": 1,
                  "created_utc": "2025-12-30 16:56:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw26ldb",
          "author": "PotentialFunny7143",
          "text": "without the prompts how can we compare them?",
          "score": 5,
          "created_utc": "2025-12-26 18:19:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw1rqnz",
          "author": "ReasonablePossum_",
          "text": "The prompting for both has to be different to achieve the same results.\nZimage needs extremely specific guiding, NB on the other hand is multimodal and can \"understand\" what you might like more and give a more aesthetically close result.\nBut in any case, a 6B local model even at random giving these results is great!.",
          "score": 8,
          "created_utc": "2025-12-26 17:01:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw2z2i8",
              "author": "martinerous",
              "text": "Yes, Z-image can get especially confused when you have multiple people in the scene. Flux2, Qwen (and NB, of course), handle it better. For example, I described a hospital scene with details on how the doctor and the patient is dressed up, and Z-image kept mixing them up quite often, adding unexpected wrong white elements to the patient's clothing (a black suit jacket with white lapels - why would it do that, if such things are even unlikely to be present in the usual training data?) or messing up the roles.\n\nBut in general, Z-image has a huge potential, I see that. Maybe the finetuned base will be better. Or we would need a Z-image model with more parameters. Just imagine what a Flux-2 sized (and, of course, gguf-ed) Z-image might achieve. Especially when combined with a research that was mentioned in another thread and promised to improve prompt adherence by a lot.",
              "score": 3,
              "created_utc": "2025-12-26 20:52:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw20j0z",
              "author": "000TSC000",
              "text": "Exactly, these comparisons are always so badly done.",
              "score": 2,
              "created_utc": "2025-12-26 17:48:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw3ubhc",
          "author": "poppy9999",
          "text": "Hoping I get a chance to play around with Z-image turbo soon! but first I could use some tech support ðŸ¤“ could just use a basic image to image workflow for z-image turbo, also, the ones I've tried have not worked.\n\nI cannot get a handle on image to image in any scenario with ComfyUI, I always run into a boatload of errors. Usually something to do with Ksampler advance. Do I have to use ComfyAI or are there any other decent local-software options out there? I know comfy is the king right now. Weirdly making videos/animations (i2v) is 100 times easier for me in ComfyUI than image to image (i2i) which simply refuses to work no matter the model/setup/workflow. You'd think image to image would be easier than wan/video stuff, but I have not had any luck with it these past 6 months or so.",
          "score": 2,
          "created_utc": "2025-12-26 23:49:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw4vpfp",
              "author": "afinalsin",
              "text": "I gotchu. [Here's what a basic txt2img Z-Image workflow looks like in Comfy](https://i.postimg.cc/y1DwMtM0/Screenshot-2025-12-27-143200.png). \n\nFor img2img, all you need to do is add a \"Load Image\" node and plug that into a \"VAE Encode\" node. The latent output of that \"VAE Encode\" node plugs into the latent input of a basic ksampler. Then you just need to lower the denoise from 1.0 to around 0.5-0.7, depending on what you want to do. [It'll look like this](https://i.postimg.cc/ZYZx8yx0/Screenshot-2025-12-27-143538.png).\n\n[Here's a workflow](https://files.catbox.moe/uko3na.png), just download the image and drag it into comfy. I use GGUF models, if you don't just replace the \"Unet Loader (GGUF)\" and \"ClipLoader (GGUF)\" nodes with their Comfy Core equivalents. \n\nOne thing to watch out for is if you input a high resolution image. Z-Image can handle decently high res generations, but your PC might not. If you need to scale down your input image, intercept the blue line between the \"Load Image\" and \"VAE Encode\" nodes with an \"ImageScaleToTotalPixels\" node set to 1.00-1.50. [It'll look like this](https://i.postimg.cc/XvqYSxWp/Screenshot-2025-12-27-144225.png).",
              "score": 3,
              "created_utc": "2025-12-27 03:45:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw9uj84",
                  "author": "poppy9999",
                  "text": "Thanks for taking the time to help a brudder out ðŸ™\n\nI gave up on the version of z-image-turbo I had and went for the gguf versions, that would make this more simple I figured. Currently I'm trying to use **z_image_turbo-Q4_K_M** and **Qwen3-4B-Q4_K_M.gguf**\n\nBut here's the current error I'm getting:\n>CLIPLoaderGGUF\n\nUnexpected text model architecture type in GGUF file: 'qwen3'\n\n\n# ComfyUI Error Report\n## Error Details\n- **Node ID:** 29\n- **Node Type:** CLIPLoaderGGUF\n- **Exception Type:** ValueError\n- **Exception Message:** Unexpected text model architecture type in GGUF file: 'qwen3'\n\n\nI'll tinker around with it more and see if I can figure out what the issue is in the meantime, but it doesn't seem like the node likes the version of Qwen I'm using (Qwen3-4B-Q4_K_M.gguf)",
                  "score": 2,
                  "created_utc": "2025-12-27 23:29:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwfhx7n",
          "author": "winterice77",
          "text": "I am happy to get a paid product but dont want a cloud based bullshit. I hope I could purchase a tool like nano banana as offline in future",
          "score": 2,
          "created_utc": "2025-12-28 21:14:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr9lsl",
              "author": "Lucaspittol",
              "text": "Will you buy the GPU as well? I guess it is heavier than Flux 2, which already requires a very beefy GPU to run well; it can run on lower-end stuff, but it is slow.",
              "score": 1,
              "created_utc": "2025-12-30 16:50:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw2antu",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 3,
          "created_utc": "2025-12-26 18:40:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw2db7m",
              "author": "Master0fMuppets",
              "text": "What's crazy it's that you preferred \"barbuÃ¡e chips\"",
              "score": 7,
              "created_utc": "2025-12-26 18:54:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw38bkh",
          "author": "cosmos_hu",
          "text": "Its crazy that this small model can easily compete with these big paid models :D",
          "score": 2,
          "created_utc": "2025-12-26 21:42:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw39zsc",
              "author": "Best-Response5668",
              "text": "Don't be ridiculous! There's no model that can even remotely compete with NB Pro.",
              "score": -5,
              "created_utc": "2025-12-26 21:51:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwef969",
                  "author": "Denimdem0n",
                  "text": "I agree with you. But people don't want to accept it. Although models which run on home user PCs aren't bad at all, however they will never be able to compete with absurdly large models of multi-billion-dollar companies which host them on infinite high-end server farms.",
                  "score": 1,
                  "created_utc": "2025-12-28 18:10:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwr9cms",
                  "author": "Lucaspittol",
                  "text": "Flux 2 can.",
                  "score": 1,
                  "created_utc": "2025-12-30 16:49:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw33xv6",
          "author": "christopheryork",
          "text": "Interesting. Can go with either or one or the other depending on the seed generated.",
          "score": 1,
          "created_utc": "2025-12-26 21:19:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw39zif",
          "author": "GoodSamaritan333",
          "text": "Try this prompt on both:\n\n\"Natural hexagonal quartz crystal with pyramidal tip at one end and flat basal face at opposite end. Crystal is split lengthwise along its long axis (c-axis) into two perfectly identical mirror-image halves of equal size and dimensions. Each half contains a matching hollow cavityâ€”one cavity opens upward, the other opens downward when halves face each other. The two halves are positioned to show opening/separation at the flat basal end only, with rotation occurring around an axis perpendicular to the crystal's length, located at the flat back face. Opening angle between halves: 90-120 degrees. Both halves remain aligned along their length with no side-to-side offset. The rotation axis is at the flat basal end, NOT along the long hexagonal sides. When closed, appears as single intact crystal; when open, separates at the flat back end like a box opening on its short side. Crystal orientation: show the pyramidal point and the opening mechanism clearly visible.\n\nKey: Opening occurs at the FLAT BASAL END perpendicular to crystal length, NOT along the long prismatic sides.\"",
          "score": 1,
          "created_utc": "2025-12-26 21:51:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3ak5s",
              "author": "GoodSamaritan333",
              "text": "Oh. Nano Banana cannot renter the above, but did a good job rendering the bellow one:  \n\"A photorealistic high-definition diptych composite image. \\[Left Side\\]: A pristine, vertical hexagonal clear quartz crystal with a sharp pyramidal termination and a flat bottom base. It appears solid but features a precise vertical hairline seam running lengthwise down the center. \\[Right Side\\]: The same crystal captured in a partially open state. The two vertical halves have pivoted apart to form a 45-degree \"V\" shape. The movement is driven by a small, precise metal hinge mechanism located exclusively on the flat bottom base. The top tips are spread apart, revealing that each half contains a rough, hollowed-out internal cavity. The crystal halves are clear and mirror-identical. The pivot axis is horizontal at the bottom, ensuring the crystal opens like a clamshell standing on its hinge, not like a book. Studio lighting, caustic glass refractions, 8k resolution, macro product photography, neutral grey background.\"",
              "score": 2,
              "created_utc": "2025-12-26 21:54:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw548l6",
          "author": "PhetogoLand",
          "text": "what are the prompts for these?",
          "score": 1,
          "created_utc": "2025-12-27 04:45:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfy000",
          "author": "SuperGeniusWEC",
          "text": "Can we assume that Z is on the left and NB Pro is on the left?",
          "score": 1,
          "created_utc": "2025-12-28 22:34:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwh17ro",
          "author": "Trick-Buy-9286",
          "text": "It's all quite real.",
          "score": 1,
          "created_utc": "2025-12-29 02:08:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw2nefh",
          "author": "Sudden_List_2693",
          "text": "These posts should be banned.",
          "score": -1,
          "created_utc": "2025-12-26 19:48:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw1m8h8",
          "author": "orangeflyingmonkey_",
          "text": "This is fantastic. I love that zimage can basically eat nano bananas lunch while being local. Can you share the promts and workflow for the zimage images please?",
          "score": -6,
          "created_utc": "2025-12-26 16:32:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw1o3us",
              "author": "FeistyThunderhorse",
              "text": "Can it? I assumed NB is on the right based on the post title. When I had a strong preference between the two, I always preferred the right",
              "score": 13,
              "created_utc": "2025-12-26 16:42:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw1onxj",
                  "author": "unrealf8",
                  "text": "Price vs Result is crazy. 0.007$ vs 0.15$ is HUGE (average api). But there are tasks that can only be solved with huge models. So, to each their own use.",
                  "score": 1,
                  "created_utc": "2025-12-26 16:45:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw3a45r",
          "author": "Best-Response5668",
          "text": "Local ai image models are garbage. Period.",
          "score": -12,
          "created_utc": "2025-12-26 21:52:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3dt9e",
              "author": "[deleted]",
              "text": "Then fuck off to the \"remote ai image models\" corner.",
              "score": 6,
              "created_utc": "2025-12-26 22:12:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw3htiy",
                  "author": "Best-Response5668",
                  "text": "There's simply no reason to use these portrait slop generators in a world where NB Pro exists. It has made every other image model completely irrelevant.",
                  "score": -3,
                  "created_utc": "2025-12-26 22:35:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pxesor",
      "title": "Invoke is revived! Crafted a detailed character card by compositing around 65 Z-Image Turbo layers.",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/ogg7nxg8hu9g1.png",
      "author": "Unit2209",
      "created_utc": "2025-12-28 01:44:45",
      "score": 144,
      "num_comments": 25,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pxesor/invoke_is_revived_crafted_a_detailed_character/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwazj4v",
          "author": "Version-Strong",
          "text": "This is basically the next step of xl, it knows so much, but needs a hand, just like xl. But then then it can type, and keep on prompt. We have a new winner, folks.",
          "score": 16,
          "created_utc": "2025-12-28 03:29:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwb7hq9",
          "author": "Fuzzy_Bathroom7441",
          "text": "Invokeâ€™s layers, control layers, inpainting, outpainting, and regional prompting are excellent. There is no other WebUI with that level of canvas functionality. I hope to see Qwen image edit and Qwen support too. Z-image great, thank you invoke team",
          "score": 12,
          "created_utc": "2025-12-28 04:19:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwcise0",
              "author": "moodyduckYT",
              "text": "i beleive z-image edit gonna be better than qwen edit.",
              "score": 5,
              "created_utc": "2025-12-28 11:14:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwct4qr",
                  "author": "shapic",
                  "text": "Why? It is 6B. I feel like everyone is forgetting that all quality of zit comes from deep finetuning along with distillation.",
                  "score": 6,
                  "created_utc": "2025-12-28 12:45:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwb7zvb",
              "author": "Unit2209",
              "text": "I do see some rumbling on the github about adding the full Qwen package next.",
              "score": 3,
              "created_utc": "2025-12-28 04:23:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwai9ro",
          "author": "Unit2209",
          "text": "https://preview.redd.it/iyftm416ou9g1.png?width=341&format=png&auto=webp&s=e4c1589c03c4ca0384911cfb46e007efd38a4b43\n\nThis sheet and my most recent Dominions 6 game inspired this creation.",
          "score": 9,
          "created_utc": "2025-12-28 01:46:39",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nwg3j44",
          "author": "IrisColt",
          "text": "Z Image handles requests for multiple copies of the same object poorly... with a forest prompt it blatantly pastes the exact same tree in different spots. The same thing happens here: it looks like the same mantis was copy-and-pasted in the exact same pose.",
          "score": 5,
          "created_utc": "2025-12-28 23:03:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwgf3k6",
              "author": "Unit2209",
              "text": "True. Thus that falls on me to change the poses in post. Would have been easy to articulate the limbs and bodies a bit, will keep that in mind next time.",
              "score": 0,
              "created_utc": "2025-12-29 00:05:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwazwsm",
          "author": "Shockbum",
          "text": "Z-Image-Turbo is perfect for Invoke AI canvas, offering higher quality than Flux Dev with the speed of SD 1.5. Now Adobe Photoshop really has reason to fear Invoke AI.",
          "score": 8,
          "created_utc": "2025-12-28 03:32:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbf68j",
              "author": "cgs019283",
              "text": "So they hired them lol.",
              "score": 6,
              "created_utc": "2025-12-28 05:13:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwcye33",
                  "author": "GasolinePizza",
                  "text": "Only the Pro-version half of the team. The rest are still there",
                  "score": 5,
                  "created_utc": "2025-12-28 13:24:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwdgzcu",
          "author": "RedditAlreaddit",
          "text": "Upvoted for Agartha",
          "score": 3,
          "created_utc": "2025-12-28 15:18:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwajg2a",
          "author": "ArtfulGenie69",
          "text": "I like it. So you are defusing pieces of images you have to put together this like a layered card? I'd like to see the workflow, really cool output.Â ",
          "score": 3,
          "created_utc": "2025-12-28 01:53:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwak0nx",
              "author": "Unit2209",
              "text": "Correct, the only way to fully share the workflow would be to record it. But I worked on this over a few days so that wasn't really an option. Here is an example of the layers I worked on in the last hour before the upload:\n\nhttps://preview.redd.it/t46njx41qu9g1.png?width=410&format=png&auto=webp&s=7d8ee998bfb9c585a1b50f5a1269d491b11dd5a4",
              "score": 8,
              "created_utc": "2025-12-28 01:56:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwfn7cx",
                  "author": "ArtfulGenie69",
                  "text": "I'd seen work flows like this\n\n\nhttps://www.youtube.com/watch?v=Rl4YCX8ULDw&t=1126s\n\n\nYou can see how he uses the sam model to clip the items automatically and how it puts the assets together. You can build auto custom boarders. When you like a boarder just keep the seed. I think this comfy card marker would work way better with z, qwen edit, sam3. All the new stuff.",
                  "score": 1,
                  "created_utc": "2025-12-28 21:40:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwcde46",
          "author": "NeedleworkerHairy837",
          "text": "Hi! What do you use flux1 for? And so this invoke can make layers like qwen image layered but better? All component separated? Background, character, composition, etc?",
          "score": 1,
          "created_utc": "2025-12-28 10:23:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwcrx3i",
              "author": "Unit2209",
              "text": "I did one or two layers in flux, nothing much. And yes and no, its a bit harder than Qwen image layered as you have to manage the layers yourself. You can either generate or add images and then you inpaint them into the scene.",
              "score": 1,
              "created_utc": "2025-12-28 12:35:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwcs6w5",
                  "author": "NeedleworkerHairy837",
                  "text": "Ah I understand now. Thank you! :). So zit can do outpainting and inpainting. I just know that now >,<. lol...",
                  "score": 1,
                  "created_utc": "2025-12-28 12:37:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwbgzeu",
          "author": "PromptAfraid4598",
          "text": "SO DAMN GOOD!",
          "score": 1,
          "created_utc": "2025-12-28 05:27:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwbi6pi",
          "author": "Alijazizaib",
          "text": "Oh that's nice. Could you share the github link to the repository? I'd love to try it with zimage",
          "score": 1,
          "created_utc": "2025-12-28 05:36:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc7kqz",
              "author": "Unit2209",
              "text": "https://github.com/invoke-ai/InvokeAI",
              "score": 1,
              "created_utc": "2025-12-28 09:27:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwrb9yb",
                  "author": "mk8933",
                  "text": "How did you get the VAE to work? Mine doesn't show up for Z image. I got the LLM but can't get the Vae",
                  "score": 1,
                  "created_utc": "2025-12-30 16:58:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pws2y8",
      "title": "What is next uncensor model after PonyXL?",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1pws2y8/what_is_next_uncensor_model_after_ponyxl/",
      "author": "Starkaiser",
      "created_utc": "2025-12-27 07:39:58",
      "score": 137,
      "num_comments": 85,
      "upvote_ratio": 0.83,
      "text": "I come back to check stable diffusion again after Flux gen 1 turn out to have not known any bit of porn concept at all. So then i come back again when i heard about Wan and Z image turbo.\n\n  \nBut so far, i pick Z image turbo first and try all the possible description and notice human interaction is all weird and dull like no any posture from 18+ possible similar to flux again. I heard this require like 1 lora for 1 post. And so instead of having like all-in 1 check point. Nowadays the new trend is to get a lot of lora and 1 by 1 post adjust only?\n\n  \nJust question only, please do not attack me",
      "is_original_content": false,
      "link_flair_text": "Question - Help",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pws2y8/what_is_next_uncensor_model_after_ponyxl/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "nw5t667",
          "author": "Late_Pirate_5112",
          "text": "I still think SDXL finetunes are the best for 18+ stuff right now.\n\nUntil we get a large scale finetune of z image.\n\nFor realistic stuff there's a bunch to choose from for SDXL (epicrealism, biglust, lustify etc.)\n\nFor cartoon/anime stuff I think noobai (and now chenkin 0.2) are still the best by far.",
          "score": 108,
          "created_utc": "2025-12-27 08:19:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw5usf2",
              "author": "Electronic-Metal2391",
              "text": "I agree. SDXL is the best hassle-free, and fast model base for 18+. The newly published non-SDXL base models (all of them, starting with Flux) are trained on datasets that don't include explicit material. Their goal is to achieve wider/commercial dissemination or governed by the laws of the country where they were developed. Chroma had potential being a derivative from Flux Schnell, but it fared poorly in realism. I must say there are good flux finetunes now on Civitai that will give good results. It just took that long to get there with flux finetunes. Hopefully, we see good finetunes for z-image (base).",
              "score": 34,
              "created_utc": "2025-12-27 08:35:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw5xoob",
                  "author": "Starkaiser",
                  "text": "Could you suggest me which good Flux finetune( i assume you meant checkpoint) are you talking about?Â  Thank.\n\n\nAlso i never heard about chroma, is that newer than Flux? Because i used to do this a lot during early Flux period",
                  "score": 2,
                  "created_utc": "2025-12-27 09:03:41",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nw8amvz",
                  "author": "Structure-These",
                  "text": "Whatâ€™s the best for interaction between subjects? Iâ€™ve messed with the stableyogi models that do great solo stuff but everything seems to get too weird when you introduce a second person. Iâ€™ve just been assuming the photorealistic ones get canâ€™t do it as well as anime ones",
                  "score": 2,
                  "created_utc": "2025-12-27 18:29:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw5xhwk",
              "author": "Starkaiser",
              "text": "Your SDXL includes PonyXL? Or just regular SDXL?Â  I have been waiting Flux to learn 18+, but nobody cracked it well so far, so i feels like nobody can do image turbo Z too",
              "score": 2,
              "created_utc": "2025-12-27 09:01:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw6e5fy",
                  "author": "dreamyrhodes",
                  "text": "Try Illustrious.",
                  "score": 14,
                  "created_utc": "2025-12-27 11:44:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw65og6",
                  "author": "Late_Pirate_5112",
                  "text": "Pony v6 is used in a lot of realistic finetunes. For cartoon/anime NSFW stuff I would use noobai instead of pony.",
                  "score": 3,
                  "created_utc": "2025-12-27 10:22:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw85kpz",
                  "author": "jib_reddit",
                  "text": "I have an Illustrious model that defaults to NSFW: https://civitai.com/models/1255024/jib-mix-illustrious-realistic",
                  "score": 4,
                  "created_utc": "2025-12-27 18:04:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw9mgz8",
              "author": "JustAGuyWhoLikesAI",
              "text": "Sad how the best stuff is still using 2+ year old tech.",
              "score": 1,
              "created_utc": "2025-12-27 22:44:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwc1x2j",
                  "author": "Late_Pirate_5112",
                  "text": "Consumer hardware didn't catch up to model advances and it probably won't for a while.\n\nFinetuning flux or flux 2 requires way more compute than SDXL. And even SDXL requires a lot of compute to get a high quality finetune.\n\nConsumer hardware is lagging behind by a few years, so unless you have a couple of thousands of dollars to burn on renting GPUs, you're not going to be able to get much done.",
                  "score": 1,
                  "created_utc": "2025-12-28 08:32:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw5z1kh",
          "author": "Dissidion",
          "text": "Illustrous and NoobAI. There are many loras, many checkpoints, if you look long enough you are bound to find something you will like.",
          "score": 28,
          "created_utc": "2025-12-27 09:16:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw6x9fw",
          "author": "mikemend",
          "text": "The Chroma model can generate anything for you, but you have to prompt it differently than other models. Specifically, you really have to specify every detail you want to see. The advantage is also the disadvantage: instead of short prompts, you can use long texts, but most people don't like that. In this case, a prompt generator comes in handy, which writes complete descriptions for you based on the words you provide, which you can then modify later.\n\nDue to artist protests after SD 1.5, it took SDXL this many years to get back what it wasn't taught from the start. What's more, SD 1.5 is still the one that can be run on mobile phones with a good speed/quality ratio, but it's not prompt-compliant enough. This needs to be improved in some way.\n\nOtherwise, I'm fed up with Loras after getting to know Chroma. The many Loras distort each other and the original model, instead of there being a model that contains everything from the outset (like Chroma). Yes, we need a model that is as consistent as Chroma, doesn't require long prompts like SDXL, and is as fast as Z-Image. But for now, there is no such thing, and it seems that large, commercial models will not be trained on adult content.",
          "score": 27,
          "created_utc": "2025-12-27 14:08:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc1x7n",
              "author": "Starkaiser",
              "text": "Thank you.  This post totally let me understand everything.  \n\nBut in that case, it seem Chroma is the best model but it lack keywords to make easy prompt.  Can you just train porn keywords in a lora?",
              "score": 3,
              "created_utc": "2025-12-28 08:32:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwc4jgg",
                  "author": "mikemend",
                  "text": "You misunderstood something, or I wrote it wrong. Chroma knows EVERYTHING, including keywords, but you have to write/generate a long and very detailed prompt. So Chroma's biggest advantage is that it knows everything even without Lora, you just have to prompt it well.Â ",
                  "score": 3,
                  "created_utc": "2025-12-28 08:57:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw7wmxz",
          "author": "Jackuarren",
          "text": "Illustrious. \nAlthough it's bad at \"realism\".",
          "score": 11,
          "created_utc": "2025-12-27 17:19:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc5hbh",
              "author": "AgeNo5351",
              "text": "With controlnets , realism is not an issue at all. One can use illustrious to gen the image, then use controlnets with a model like lustify or BigASP to transform it to real image easily",
              "score": 3,
              "created_utc": "2025-12-28 09:06:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw8hpxm",
              "author": "Upper-Reflection7997",
              "text": "It depends on the degree and flavor of \"realism\" your  looking for. Pic related was made with illustrious/noobai model. [https://civitai.com/models/2074692/mergestein-uncanny-realism](https://civitai.com/models/2074692/mergestein-uncanny-realism)\n\nhttps://preview.redd.it/yhkcp3hsos9g1.png?width=1920&format=png&auto=webp&s=aab7e11ed90936f52d33a41b5355d3e7906142e7",
              "score": 3,
              "created_utc": "2025-12-27 19:05:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw5qlsf",
          "author": "AgeNo5351",
          "text": "Chroma1-HD",
          "score": 28,
          "created_utc": "2025-12-27 07:55:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw5yra9",
              "author": "jingtianli",
              "text": "You have to write a bible length prompt to make chroma nearly as good as modern model\n\nChroma fan boys are not happy but i gotta say it",
              "score": 17,
              "created_utc": "2025-12-27 09:14:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw6d2uk",
                  "author": "Lucaspittol",
                  "text": "Yes, but with Chroma1-HD-Flash, you don't.",
                  "score": 4,
                  "created_utc": "2025-12-27 11:34:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw6026p",
                  "author": "Starkaiser",
                  "text": "Aren't modern model also require lengthy detail the prompt?Â  So chroma is same? I really miss SDXL days.",
                  "score": -1,
                  "created_utc": "2025-12-27 09:27:00",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw60eji",
              "author": "witcherknight",
              "text": "No controlnets",
              "score": -1,
              "created_utc": "2025-12-27 09:30:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw690t6",
                  "author": "Intelligent-Youth-63",
                  "text": "False.",
                  "score": 1,
                  "created_utc": "2025-12-27 10:55:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw5yiso",
          "author": "niknah",
          "text": "Have you triedÂ illustrious?Â  I've only used Wan for image to video, it's pretty good.",
          "score": 11,
          "created_utc": "2025-12-27 09:11:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw604ks",
              "author": "Starkaiser",
              "text": "Hi. I never get to try that one yet. Will it be better than Chroma?",
              "score": 4,
              "created_utc": "2025-12-27 09:27:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw693lj",
                  "author": "nietzchan",
                  "text": "Illustrious is SDXL model trained on anime/booru dataset so it has tons of knowledge of characters and artists, you could invoke it without using lora. It still have the same SDXL weakness (texts, long prompt inconsistency, etc.) but for specific use especially the finetunes derivatives is really good. \n\nMy recommendation would be OneObsession by Maxfeifei8 (mixture between illustrious and noobai finetunes) or UnholyDesireMix by UnholyDesireStudio (illustrious finetunes)",
                  "score": 11,
                  "created_utc": "2025-12-27 10:56:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw68oyu",
                  "author": "Intelligent-Youth-63",
                  "text": "I can say unequivocally no.\n\nChroma is a major step up from illustrious in my experience, and I went through a whole love affair of getting a realistic illustrious pipeline perfected.\n\nMajor step up.",
                  "score": 1,
                  "created_utc": "2025-12-27 10:52:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw8udi9",
          "author": "terrariyum",
          "text": "You're right that ZiT generally makes boring posture/poses - even for SFW.  Eventually, finetunes of the base model will probably fix that.  \n\nIn the mean time, use a different model to create a dynamic pose, then use Zit + inpainting + controlnet",
          "score": 5,
          "created_utc": "2025-12-27 20:12:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw6d0hp",
          "author": "Lucaspittol",
          "text": "Chroma is the model you need. Z-Image is ass for NSFW unless you use a lot of loras, and Flux is even worse, plus it takes a lot of time.",
          "score": 8,
          "created_utc": "2025-12-27 11:33:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw7h0bf",
              "author": "Fast-Cash1522",
              "text": "Z-Image can generate NSFW quite well.  Surely for a specific porn needs, a LoRA is needed just like with any other model, unless it's a specifically trained finetune for a purpose. Same with Flux 1 Dev and even Krea, though the later needs a bit more fiddling when prompting.\n\nI agree, Chroma is nice. Lacks a bit realism OTB but can be fixed when upscaling.",
              "score": 3,
              "created_utc": "2025-12-27 16:00:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw5wiu6",
          "author": "j3y3m3",
          "text": "Just curious passerby here, how much uncensored are we talking?",
          "score": 3,
          "created_utc": "2025-12-27 08:52:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw5xava",
              "author": "Starkaiser",
              "text": "Â Z image turbo seem fail to even do normal kissing and hugging right. Two person will feels expressionless doing so.",
              "score": 5,
              "created_utc": "2025-12-27 08:59:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw9hoq8",
                  "author": "BrokenSil",
                  "text": "It can do that and alot more.\n\nTho its much easier if you use a heretic qwen3 4b as the text encoder :P",
                  "score": 4,
                  "created_utc": "2025-12-27 22:18:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw7jftf",
                  "author": "Fast-Cash1522",
                  "text": "In my experience, not the case at all. It just needs to be prompted a bit more broadly and in more detail than some other models.",
                  "score": 5,
                  "created_utc": "2025-12-27 16:12:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw6dqde",
                  "author": "Lucaspittol",
                  "text": "Because it is censored. They simply didn't write pages to describe how they did it, unlike the Flux 2 team. The latest Qwen image edit is also censored.   \nNot something to be proud about, but on most of these models, a lora is sufficient to bypass the censorship.",
                  "score": 4,
                  "created_utc": "2025-12-27 11:40:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw9y8zw",
          "author": "SDSunDiego",
          "text": "Me over here:\n\nZTurbo/SDXL -> Wan2.2/ZTurbo Inpaint -> A touch of contrast and add frames -> Wan2.2 I2V. And of course LoRAs everywhere\n\nThe real magic sometimes comes from Wan2.2 T2I, truly a hidden gem that is underutilized.",
          "score": 3,
          "created_utc": "2025-12-27 23:51:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5rtx0",
          "author": "MinaaxNina",
          "text": "Chroma was supposed to be the successor but I donâ€™t think it took off. As for Wan/Z-image turbo, they need someone to finetune like Pony or Illustrious were. Wan prolly takes too much per gen so its not great, while Z-image seems the perfect model and itâ€™s very popular but the Turbo version isnâ€™t good for finetune, so Iâ€™d say wait for them to drop base version and then hopefully someone decides to do a nsfw finetune like Pony/Ill but that may take months sadly",
          "score": 6,
          "created_utc": "2025-12-27 08:06:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw6dios",
              "author": "Lucaspittol",
              "text": "Chroma didn't take off because people don't look for the proper workflows to run it, and Chroma1-HD-Flash is currently very good.",
              "score": 12,
              "created_utc": "2025-12-27 11:38:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw8x803",
                  "author": "Bandark696",
                  "text": "Any link to a good workflow?",
                  "score": 2,
                  "created_utc": "2025-12-27 20:27:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw6vr2p",
                  "author": "Hoodfu",
                  "text": "Yeah, it's the first model I've seen that needs a correct negative or it looks horrible.",
                  "score": 1,
                  "created_utc": "2025-12-27 13:58:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw9tmhr",
          "author": "Umbaretz",
          "text": "Since it wasnt't mentioned yet, you can also try NetaLumina.  \nYou can think about it as a different variant of chroma (it isn't, but your prompt style will be similar), derpier, but so much faster.",
          "score": 2,
          "created_utc": "2025-12-27 23:24:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwckfdn",
          "author": "moodyduckYT",
          "text": "use zit+lora and afterdetail the gens area with pony. sdxl is garbo once you do that.",
          "score": 2,
          "created_utc": "2025-12-28 11:30:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwdlrix",
          "author": "Diecron",
          "text": "Chroma, or a variant of. Uncanny 1.3 dropped about a week back, and it's been very good.",
          "score": 2,
          "created_utc": "2025-12-28 15:43:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw735k9",
          "author": "Fast-Cash1522",
          "text": "In short, all of them and none of them.\n\nThere isnâ€™t a single model that covers every need. Almost any model can create a pretty girl with big boobs, and as you said, with the help of a LoRA you can get boobs and pussy exposed. In the end, it all depends on what youâ€™re looking for. Right now, there are a lot of great models out there, but none of them is perfect.\n\nIâ€™m creating a certain realistic male type, and for me personally, things clicked with Flux 1 Dev (the vanilla version) in a way that none of the SDXL models did. Flux Krea and Flux 2 are both nice, but they donâ€™t quite (yet) tick all the boxes. Z-Image is promising, but for now it lacks LoRAs.\n\nAnother thing to consider is your prompting. WithÂ the newer models, you might want to experiment with prompting as well. For example Iâ€™ve noticed that especially with Z-Image, you really need to be quite specific, and it can lack variety unless you change the prompt a lot between generations. In other words, if you hit generate over and over again using a single prompt, it will generate very similar results.\n\nGood luck!",
          "score": 4,
          "created_utc": "2025-12-27 14:44:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw82my9",
          "author": "ghosthacked",
          "text": "I hate loras. Im either really bad at useing them correctly or most are just bad.Â  I usually just end up doingÂ  a few i2i gens thru another model to get specific features that another model doesnt do well.",
          "score": 3,
          "created_utc": "2025-12-27 17:49:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw841d8",
          "author": "Paraleluniverse200",
          "text": "Illustrious/noob, chroma, netayume",
          "score": 1,
          "created_utc": "2025-12-27 17:56:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5r7oc",
          "author": "Powerful_Evening5495",
          "text": " I like z-image, don't do NSFW with it, but I like the dataset and speed \n\nbut it is too early yet ,we have to see the NSFW community reactions to it",
          "score": 1,
          "created_utc": "2025-12-27 08:00:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw69pjv",
              "author": "kemb0",
              "text": "You can do quite a lot with z-image. Itâ€™s fine for breast and I found to get decent female anatomy down below you can prompt, â€œA small slit in her groinâ€. It can do quite a few kinks decently at some level, eg bondage.\n\nIt falls far short of SDXL for wealth of understanding of all the kinks known to man but it also just looks plain better than SDXL and can add more prompt complexity to a scene that SDXL fails at. Want to have a woman tied up kneeling on a dinner table whilst kangaroos eat spaghetti? No problem. Feed that to SDXL and youâ€™ll get hot garbage.\n\nDisclaimer: thatâ€™s not my kink.",
              "score": 12,
              "created_utc": "2025-12-27 11:02:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw6gec1",
                  "author": "psxburn2",
                  "text": "*new kink unlocked",
                  "score": 8,
                  "created_utc": "2025-12-27 12:04:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw8fp2m",
                  "author": "Der_Hebelfluesterer",
                  "text": "What is sad about z-image that the seed has almost no impact. Every picture from one prompt will look almost the same. This is awesome for art but for NSFW I always loved about SDXL how different each image might look and that you sometimes get that perfect smile or eyes or ehh position ðŸ‘€\n\nI read about some options to get more random results but beside wildcards this seems to be a bit difficult atm.",
                  "score": 1,
                  "created_utc": "2025-12-27 18:54:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw7fjnj",
              "author": "Comrade_Derpsky",
              "text": "It doesn't know about sex, but it definitely knows what nudity looks like. You can do plenty in the NSFW realm with Z-image.",
              "score": 2,
              "created_utc": "2025-12-27 15:52:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwaepu6",
          "author": "mca1169",
          "text": "rite now PonyXL is still king of NSFW but I really hope someone finetunes Z-image turbo for NSFW because it has potential to be the best by far with it's incredible prompt adherence.",
          "score": 1,
          "created_utc": "2025-12-28 01:25:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5sygs",
          "author": "HerrensOrd",
          "text": "I don't understand how people use the word censorship like this. It's like someone going to pornhub and exclaiming \"finally, a streaming service without all the censorship\" rather than just saying that it's a damn porn site.",
          "score": -8,
          "created_utc": "2025-12-27 08:17:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw68hi5",
              "author": "LerytGames",
              "text": "Because there are different kinds of models. Some are not restricted and lets you train whatever concepts you like. For example SD, SDXL, Qwen Image, Z-Image, ... And then there are models like Flux, which are made with restriction preventing you train anything NSFW. At least they try to make it hard.",
              "score": 4,
              "created_utc": "2025-12-27 10:50:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw6ddxw",
                  "author": "Lucaspittol",
                  "text": "The restrictions are still not good enough if you have a good dataset and actually train a lora. For female subjects, which seems to be the top priority in this community, it is even easier since you only need to train two small body parts. It is a lot harder to train male parts, though.",
                  "score": 1,
                  "created_utc": "2025-12-27 11:37:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pudpfq",
      "title": "Testing photorealistic transformation of Qwen Edit 2511",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1pudpfq",
      "author": "3deal",
      "created_utc": "2025-12-24 03:50:05",
      "score": 132,
      "num_comments": 16,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pudpfq/testing_photorealistic_transformation_of_qwen/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nvnv1hy",
          "author": "3deal",
          "text": "Workflow i used : [https://github.com/Fictiverse/ComfyUI\\_Fictiverse\\_Workflows/blob/main/Qwen\\_Image\\_Edit\\_2511.json](https://github.com/Fictiverse/ComfyUI_Fictiverse_Workflows/blob/main/Qwen_Image_Edit_2511.json)",
          "score": 15,
          "created_utc": "2025-12-24 03:54:17",
          "is_submitter": true,
          "replies": [
            {
              "id": "nvr7o6h",
              "author": "ArachnidDesperate877",
              "text": "One of the better workflow I have used for qwen image edit 2511...very nice!!!",
              "score": 3,
              "created_utc": "2025-12-24 18:29:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvu28wo",
              "author": "SuperGeniusWEC",
              "text": "Any best practice prompts to share for this?",
              "score": 1,
              "created_utc": "2025-12-25 06:18:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvy07ls",
              "author": "Green-Ad-3964",
              "text": "ouch, very difficult to understand....can it be used with more than 1 image at once?",
              "score": 1,
              "created_utc": "2025-12-25 23:51:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvodsxw",
          "author": "Perfect-Campaign9551",
          "text": "I wouldn't call those photorealistic at all.Â \n\n\nWhat really needs to be tested is if you give it an actual photo to edit, will it cause plastic skin in the edited version? Because the older version still did that",
          "score": 11,
          "created_utc": "2025-12-24 06:15:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvo7v6h",
          "author": "SuperGeniusWEC",
          "text": "I love this - will have to give it a try, it's a super cool effect My standard workflow is to try out a new model, and never come close to outputting what the demo looks likeðŸ¤£ Â¯\\\\\\_(ãƒ„)\\_/Â¯",
          "score": 4,
          "created_utc": "2025-12-24 05:26:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvogvj3",
              "author": "Fuzzyfaraway",
              "text": "I felt this.",
              "score": 2,
              "created_utc": "2025-12-24 06:42:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvqoysq",
          "author": "causality-ai",
          "text": "Its not very good. Lets hope the internal competition at Alibaba gets the lab behind z turbo to deliver something better than this - qwen-image-edit is also too masive for modest setups.",
          "score": 2,
          "created_utc": "2025-12-24 16:48:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvr6ni7",
              "author": "thisiztrash02",
              "text": "you can literally run the model on even 8gb",
              "score": 2,
              "created_utc": "2025-12-24 18:24:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvsak5a",
              "author": "3deal",
              "text": "i agree we are still very far from nanobanana but nanobanana model should be way bigger than 32Gb i guess",
              "score": 1,
              "created_utc": "2025-12-24 22:15:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvo01we",
          "author": "One-UglyGenius",
          "text": "Ughh why it looks burned out though ðŸ¥²",
          "score": 5,
          "created_utc": "2025-12-24 04:28:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvoa8fp",
              "author": "Dezordan",
              "text": "Probably because it's a gif",
              "score": 2,
              "created_utc": "2025-12-24 05:45:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvp7nlu",
          "author": "jingtianli",
          "text": "Try my image you will be suprised XD\n\nhttps://preview.redd.it/73evhpvnv49g1.png?width=1352&format=png&auto=webp&s=7b826940ff644e0afdc580a15e4fd5db7267b6a9",
          "score": 3,
          "created_utc": "2025-12-24 11:01:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvqajyd",
              "author": "One-UglyGenius",
              "text": "Damn this looks very cool",
              "score": 3,
              "created_utc": "2025-12-24 15:31:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvso1sr",
              "author": "agx3x2",
              "text": "how does it do with adding and removing stuff",
              "score": 1,
              "created_utc": "2025-12-24 23:46:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvqp4hf",
          "author": "Calm_Mix_3776",
          "text": "Not really photorealistic, more like stylized, but the style is still nice.",
          "score": 1,
          "created_utc": "2025-12-24 16:48:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pvdxs5",
      "title": "LoRa vs. LoKr, It's amazing!",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1pvdxs5/lora_vs_lokr_its_amazing/",
      "author": "xbobos",
      "created_utc": "2025-12-25 13:59:05",
      "score": 131,
      "num_comments": 90,
      "upvote_ratio": 0.74,
      "text": "I tried making a LoKr for the first time, and it's amazing. I saw in the comments on this sub that LoKr is better for characters, so I gave it a shot, and it was a game-changer. With just 20 photos, 500 steps on the ZIT-Deturbo model with factor 4 settings, it took only about 10 minutes on my 5090â€”way better than the previous LoRA that needed 2000 steps and over an hour.â€‹\n\nThe most impressive part was that LoRAs, which often applied effects to men in images with both genders, but this LoKr applied precisely only to the woman. Aside from the larger file size, LoKr seems much superior overall.â€‹\n\nI'm curious why more people aren't using LoKr. Of course, this is highly personal and based on just a few samples, so it could be off the mark.â€‹\n\n**P.S** Many people criticize reply for lacking example images and detailed info, calling them unnecessary spam, and I fully understand that frustration. Example images couldn't be posted since they feature specific celebrities (illegal in my country), and the post already noted it's a highly personal caseâ€”if you think it's useless, just ignore it.\n\nBut for those who've poured tons of time into character LoRAs with little payoff, try making a LoKR anyway; here's my exact setup:\n\nAI-Toolkit, 20 sample images (very simple captions), Model: Zimang DeTurbo, LoKr - Factor4, Quantization: none, Steps: 500\\~1000, Resolution: 768 (or 512 OK), everything else at default settings.\n\nGood luck!",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pvdxs5/lora_vs_lokr_its_amazing/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "nvvit0n",
          "author": "WackyConundrum",
          "text": "\"It's a game changer! Which is why I won't show you any comparisons.\"",
          "score": 288,
          "created_utc": "2025-12-25 14:44:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvsuxo",
              "author": "Reno0vacio",
              "text": "Show IMAGES!",
              "score": 42,
              "created_utc": "2025-12-25 15:49:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvwyv47",
                  "author": "ANR2ME",
                  "text": "probably NSFW stuff ðŸ˜ that's why OP didn't shows the images.",
                  "score": 12,
                  "created_utc": "2025-12-25 19:57:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvveicr",
          "author": "zekuden",
          "text": "Can you show examples of the LokR?",
          "score": 59,
          "created_utc": "2025-12-25 14:13:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvmll3",
          "author": "hotdog114",
          "text": "Honestly the lack of scientific method on this sub is just the worst.\n\nOP are you saying you've tried both lora and lokr trainings on ZImage? I've done a lot of lora myself in SDXL, then tried the exact same image set on ZImage, the difference is night and day: Out of the box, ZImage lora likeness is consistently 30-40% higher than my best SDXL ever. \n\nAre you saying that a ZI lokr is better than a ZI lora? Have you trained and compared both?  What else did you change?",
          "score": 117,
          "created_utc": "2025-12-25 15:09:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvw3jrj",
              "author": "joopkater",
              "text": "Not much science goes into gooning im afraid",
              "score": 33,
              "created_utc": "2025-12-25 16:53:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvvzgg4",
              "author": "DigThatData",
              "text": "I feel like most of these posts are mostly a consequence of subjective bias in evaluation and asymmetric investment in hyperparamter tuning between the methods being compared.",
              "score": 29,
              "created_utc": "2025-12-25 16:28:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvwnu3k",
                  "author": "stash0606",
                  "text": "I wanna add that there may be further complications, since even the Sampler + scheduler selection seems to affect likeness. also whether you train on fp32 with no transformer or text conder quant or you train on bf16 with fp8 quant seems to affect results and likeness too.",
                  "score": 3,
                  "created_utc": "2025-12-25 18:52:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvvzqjo",
              "author": "silenceimpaired",
              "text": "Any tips on making Loraâ€™s? What tool do you use?",
              "score": 2,
              "created_utc": "2025-12-25 16:30:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvxyjt5",
              "author": "Lil_Twist",
              "text": "Thanks for saying something, made me immediately ground myself and wanted to understand.\n\nhttps://preview.redd.it/0w56waj4sf9g1.jpeg?width=1179&format=pjpg&auto=webp&s=58cc2dc021775beb5066bcb753866c1e8790731f",
              "score": 4,
              "created_utc": "2025-12-25 23:40:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvw0gh3",
              "author": "dariusredraven",
              "text": "We are hobbyists  not scientists writing a peer reviwed paper. Get the hell out with that self righteous attitude.\n\n\nAs to your last question, ive did 15 lora on zit before i discovered lokr settings from Story on ostrists discord. I ended up deleting all my loras and redoing them on lokr. Same datasets, but the quality difference is huge",
              "score": -13,
              "created_utc": "2025-12-25 16:34:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvw4clj",
                  "author": "hotdog114",
                  "text": "Thanks for describing a meaningful and valuable comparison. I genuinely appreciate this. I'm not expecting a thesis from anyone, just a tad more than \"omfg wtf bbq lokr! [vanishes from community never to post again]\". A good community helps its members with detail and information.",
                  "score": 12,
                  "created_utc": "2025-12-25 16:58:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvvj498",
          "author": "krigeta1",
          "text": "Can you show some examples?",
          "score": 20,
          "created_utc": "2025-12-25 14:46:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvdh4k",
          "author": "Confusion_Senior",
          "text": "what software did you use? ai toolkit?",
          "score": 30,
          "created_utc": "2025-12-25 14:05:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvks6c",
              "author": "ImpressiveStorm8914",
              "text": "I was about to ask the same.",
              "score": 8,
              "created_utc": "2025-12-25 14:57:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvvordi",
              "author": "StableLlama",
              "text": "Dunno what he's using, but I'm also training LoKR and for that I'm using SimpleTuner",
              "score": 9,
              "created_utc": "2025-12-25 15:23:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvvegj2",
          "author": "mallibu",
          "text": "Loktar ogar",
          "score": 61,
          "created_utc": "2025-12-25 14:13:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvg7x8",
              "author": "mouringcat",
              "text": "Daboooâ€¦. Zugg-zugg..",
              "score": 20,
              "created_utc": "2025-12-25 14:25:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvvgb2z",
              "author": "GoldGuidance8822",
              "text": "Have an upvote from me, kind sir",
              "score": 2,
              "created_utc": "2025-12-25 14:26:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvvrewk",
          "author": "Wallye_Wonder",
          "text": "OP wonâ€™t share any examples because it looks like his ex.",
          "score": 19,
          "created_utc": "2025-12-25 15:40:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvviyew",
          "author": "PATATAJEC",
          "text": "How to load LoKr in comfy?",
          "score": 9,
          "created_utc": "2025-12-25 14:45:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvmyl4",
              "author": "brittpitre",
              "text": "I'm wondering the same thing. Do they just go in a normal Lora Loader node?",
              "score": 8,
              "created_utc": "2025-12-25 15:12:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvvp06x",
                  "author": "AuryGlenz",
                  "text": "Yep.",
                  "score": 8,
                  "created_utc": "2025-12-25 15:24:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvx3cnn",
              "author": "StableLlama",
              "text": "Just like a LoRA",
              "score": 3,
              "created_utc": "2025-12-25 20:25:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvvppth",
          "author": "PossibilityLarge8224",
          "text": "Examples?",
          "score": 8,
          "created_utc": "2025-12-25 15:29:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvw03s0",
          "author": "Debirumanned",
          "text": "This is the least helpful post on this sub so far",
          "score": 17,
          "created_utc": "2025-12-25 16:32:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvge0f",
          "author": "hiperjoshua",
          "text": "I use Nunchaku, currently it doesn't support LoKr (at least for Qwen and ZIT) ðŸ¥²",
          "score": 7,
          "created_utc": "2025-12-25 14:27:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvzlut",
              "author": "rinkusonic",
              "text": "How are you using zit nunchaku already? I've downloaded the models and have been waiting for the update.",
              "score": 2,
              "created_utc": "2025-12-25 16:29:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvwa618",
              "author": "lolxdmainkaisemaanlu",
              "text": "Please let us know how to use it and also share workflow if possible bro",
              "score": 1,
              "created_utc": "2025-12-25 17:33:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvwe2hs",
                  "author": "hiperjoshua",
                  "text": "wait for release or manually merge: [https://github.com/nunchaku-tech/ComfyUI-nunchaku/pull/713/commits/a7185dcd69013e07be2e32290bbfe2ffe4d04bdc](https://github.com/nunchaku-tech/ComfyUI-nunchaku/pull/713/commits/a7185dcd69013e07be2e32290bbfe2ffe4d04bdc)",
                  "score": 5,
                  "created_utc": "2025-12-25 17:56:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvvlxqk",
          "author": "hdeck",
          "text": "How do you train LoKr?",
          "score": 7,
          "created_utc": "2025-12-25 15:05:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvx3h1r",
              "author": "StableLlama",
              "text": "With a trainer that's supporting it. E.g. SimpleTuner. But others as well.",
              "score": 2,
              "created_utc": "2025-12-25 20:25:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvw6nwg",
          "author": "Guilty_Emergency3603",
          "text": "LoKr is supposed to be slower than LoRa when training. How can you train 500 steps of LoKr in 10 minutes and 2000 steps Lora in an hour. Scaling that you are training LoKr 2x faster than Lora. It's impossible. Check your LoRa settings.",
          "score": 8,
          "created_utc": "2025-12-25 17:12:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvjmpv",
          "author": "xcdesz",
          "text": "I think it was an Ostiris video where he went over the settings.. he mentioned Lokr was better, but it made it more difficult to share with others.",
          "score": 6,
          "created_utc": "2025-12-25 14:49:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvp5h8",
              "author": "AuryGlenz",
              "text": "Itâ€™s only more difficult because some software doesnâ€™t support it, but Comfy does.",
              "score": 6,
              "created_utc": "2025-12-25 15:25:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvwbvd5",
                  "author": "Free_Scene_4790",
                  "text": "I trained one and even Comfy couldn't open it (or if it did, the changes weren't applied at all). I used both the regular LORA loader and the Lycoris-specific loader, with no results.\n\nIt's possible something went wrong during training, although I suppose the only thing you have to select is LOKR instead of LORA in AI Toolkit, right?",
                  "score": 1,
                  "created_utc": "2025-12-25 17:43:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvvgfpq",
          "author": "Momkiller781",
          "text": "I have no idea what that is.",
          "score": 20,
          "created_utc": "2025-12-25 14:27:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvyvgq",
              "author": "DigThatData",
              "text": "I think it's a LoRA with a kronecker factorization? I don't feel like googling it atm because I'm pretty sure it's been in the wild long enough to have science supporting it but I'm pretty sure the only people who use it are t2i hobbyists.",
              "score": 1,
              "created_utc": "2025-12-25 16:25:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvvi44x",
          "author": "TwistedBrother",
          "text": "Itâ€™s funny. Ultimately itâ€™s just a different way of working with the attention matrix (using the Kronecker delta instead of a different way of measuring difference between training image and prediction). It allows a little more flexibility and precision we might say. \n\nThis community hasnâ€™t really learned much linear algebra and so the actual Ml behind this stuff seems a little behind stating â€œfused fingersâ€ in a negative, as if these models were trained on lots of â€œbad anatomyâ€ instead of seeing this as a config or gluing problem. But yeah LoKr was for me best on SDXL. Neat to see it getting rediscovered.",
          "score": 19,
          "created_utc": "2025-12-25 14:39:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvwo5ka",
              "author": "stash0606",
              "text": "brother, my first and last Linear Algebra class was like 16 years ago. also probably my last math class.",
              "score": 1,
              "created_utc": "2025-12-25 18:54:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvvfzch",
          "author": "alisitskii",
          "text": "You know what is even better? LoPa!! And itâ€™s really amazing, just finished my LoPa in grandmaâ€™s basement, still donâ€™t understand why people are so silent about it.",
          "score": 22,
          "created_utc": "2025-12-25 14:24:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvwm84q",
              "author": "squired",
              "text": "Unironically, check out DoRAs.",
              "score": 6,
              "created_utc": "2025-12-25 18:43:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvz0vgi",
                  "author": "Incognit0ErgoSum",
                  "text": "DoRas are almost completely forgotten now, which is sad because they really are pretty good. \n\nI submitted a fix for z-image doras on ai-toolkit and the last I checked it hadn't been applied, but if you search the issues for dora, it'll show up and it's a small patch.",
                  "score": 2,
                  "created_utc": "2025-12-26 03:58:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvvh0cb",
              "author": "VirusCharacter",
              "text": "Nevermind LoPa. Have you tried LoWr. Jesus Christ ðŸ˜® With only 250 steps, 5 images and 5 minutes training time on my 5060 it easily beats all other models when it comes to character consistency and quality. I'm so impressed. I still don't understand why no one is talking about this ðŸ˜‰",
              "score": 11,
              "created_utc": "2025-12-25 14:31:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvvty4p",
                  "author": "bfume",
                  "text": "LoZa FTW.  Good luck getting anything after that in the Lo\\*a format alphabetically, suckaz.",
                  "score": 4,
                  "created_utc": "2025-12-25 15:55:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvvgn71",
              "author": "Hunting-Succcubus",
              "text": "LoLa is even better, much better than loli",
              "score": 14,
              "created_utc": "2025-12-25 14:28:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvvydiw",
          "author": "Sayat93",
          "text": "Factor 4 is too much tho. It's too strong it can even have negative effects. Use factor 8 instead.",
          "score": 4,
          "created_utc": "2025-12-25 16:22:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvzzc0",
          "author": "Jealous_Piece_1703",
          "text": "If i got a dollar for every time someone claimed something is superior to lora I would be buying 5090 by now",
          "score": 4,
          "created_utc": "2025-12-25 16:32:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvxekza",
              "author": "AmazinglyObliviouse",
              "text": "Yeah. In my testing lokr is half the speed of Lora, with no clear improvement in loss, eval loss or output image, especially considering the aforementioned speed issue.",
              "score": 1,
              "created_utc": "2025-12-25 21:34:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvvs5di",
          "author": "Reasonable-Word-8422",
          "text": "I trained a LoNe with only 6 images and 12 steps on my 1080ti in 1 minute and got even better results.\n\nCome on, bro!  Stop talking and start showing.",
          "score": 7,
          "created_utc": "2025-12-25 15:44:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvw3lub",
              "author": "Hunting-Succcubus",
              "text": "Bro, you sure you training not generating?",
              "score": 0,
              "created_utc": "2025-12-25 16:53:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvw341e",
          "author": "Familiar-Art-6233",
          "text": "Waitâ€” LoKr?\n\nI thought the general consensus was that DoRA was the superior replacement to LoRA?",
          "score": 6,
          "created_utc": "2025-12-25 16:50:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvwv0bw",
              "author": "hirmuolio",
              "text": "Dora isn't a separate thing. It can be enabled with most lora variants.",
              "score": 3,
              "created_utc": "2025-12-25 19:34:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvxes27",
                  "author": "AmazinglyObliviouse",
                  "text": "You can do dokr for 0.25% Lora speed to maximize that sunk cost fallacy.",
                  "score": 2,
                  "created_utc": "2025-12-25 21:35:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvvdpc9",
          "author": "JahJedi",
          "text": "First time hear about it and my loras takes a night run on 6000 pro... but there 500+ photos data set whit 1408x1408 resolution and running on batch 8 (better lora quality whit higher batch)",
          "score": 7,
          "created_utc": "2025-12-25 14:07:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvv08f",
              "author": "ftzde",
              "text": "Do you have a generally working ballpark number of steps for 500+ image sets?",
              "score": 1,
              "created_utc": "2025-12-25 16:02:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvvvwie",
                  "author": "JahJedi",
                  "text": "Its around 2000-2500 but again on batch 8-9 so its 8-9 photos in one interaction. Gradient on 1 as batch high already.\n\nRank 64\n\nIts slower this way but i go for the quality and its all local so only electricity to wory about as i sleep and its working.",
                  "score": 2,
                  "created_utc": "2025-12-25 16:07:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvw8c5a",
          "author": "Stecnet",
          "text": "Makes a strong statement with zero examples to back it up.....",
          "score": 3,
          "created_utc": "2025-12-25 17:22:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvgv9l",
          "author": "Murinshin",
          "text": "The majority of people are still stuck with SD1.5 advice when it comes to training. Look at the threads over the past day on here and in general the quality of 99% of character LoRas out there.\n\nThough for LoKr specifically it doesnâ€™t help much that tools like OneTrainer have been somewhat resistant to add support despite it being known for a while to be superior in many cases",
          "score": 9,
          "created_utc": "2025-12-25 14:30:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvwbtbb",
          "author": "MoridinB",
          "text": "I tried malcolmrey's setting to train character loras with z-image and it honestly worked amazingly, and with just 12 images (with horizontal flipping turned on). And I tested it with chinese prompt, and prompts with a man (it was a female character lora, obviously). Beside a few changes to the man's face, it worked fine. Like I didn't get a distorted half woman and half man hybrid.",
          "score": 2,
          "created_utc": "2025-12-25 17:42:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvwp1jx",
          "author": "reymalcolm",
          "text": "I really like your comparison images :)",
          "score": 2,
          "created_utc": "2025-12-25 18:59:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvxh4nt",
          "author": "LeoPelozo",
          "text": "Examples or it didn't happen.",
          "score": 2,
          "created_utc": "2025-12-25 21:50:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvz2fj2",
          "author": "cynicalxrose",
          "text": "RemindMe! 2 weeks â€œExcuse me sir, wth is LoKr?â€",
          "score": 2,
          "created_utc": "2025-12-26 04:10:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvz2k4d",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 14 days on [**2026-01-09 04:10:24 UTC**](http://www.wolframalpha.com/input/?i=2026-01-09%2004:10:24%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/StableDiffusion/comments/1pvdxs5/lora_vs_lokr_its_amazing/nvz2fj2/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FStableDiffusion%2Fcomments%2F1pvdxs5%2Flora_vs_lokr_its_amazing%2Fnvz2fj2%2F%5D%0A%0ARemindMe%21%202026-01-09%2004%3A10%3A24%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201pvdxs5)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2025-12-26 04:11:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvzpz4m",
          "author": "Chess_pensioner",
          "text": "I also tried and had good results with LOKR.\n\nSince I was quite happy with my LORA rank 4 (res.512) I tried LOKR factor 16, which is approx. the same size (all other parameters remained the same) and I have to say LOKR seems slightly better.\n\nI need to further experiment...\n\nEDIT: actually the LOKR is not the same size: at factor 16 is generating a 41Mb safetensor file, while LORA rank 4 is 20Mb, but the order of magnitude is similar. At factor 8 is 165Mb and at factor 4 is a staggering 662Mb!",
          "score": 2,
          "created_utc": "2025-12-26 07:30:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvzqmo5",
              "author": "reddit22sd",
              "text": "Did you train using ai toolkit?",
              "score": 1,
              "created_utc": "2025-12-26 07:37:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvzv24i",
                  "author": "Chess_pensioner",
                  "text": "Yes",
                  "score": 2,
                  "created_utc": "2025-12-26 08:22:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw1ec5s",
              "author": "BathroomEyes",
              "text": "What is better about LoKr?",
              "score": 1,
              "created_utc": "2025-12-26 15:50:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw1lj7s",
                  "author": "Chess_pensioner",
                  "text": "Images seem slightly better, but I know this is nothing scientific... I just try generating various images (some photorealistic and some not, e.g. anime, cartoon, marble) with same seed and different loras and I compare the results.  \nLOKR seems more detailed.",
                  "score": 2,
                  "created_utc": "2025-12-26 16:29:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw1zl7z",
          "author": "Upset-Virus9034",
          "text": "No sense without the results",
          "score": 2,
          "created_utc": "2025-12-26 17:43:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvpssk",
          "author": "Cultural-Team9235",
          "text": "I think you are wrong.",
          "score": 3,
          "created_utc": "2025-12-25 15:30:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvs0z0",
          "author": "sahil1572",
          "text": "Share config so more people can try that",
          "score": 2,
          "created_utc": "2025-12-25 15:43:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvzinr",
          "author": "silenceimpaired",
          "text": "How do you train one of these?",
          "score": 1,
          "created_utc": "2025-12-25 16:29:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvxe25c",
          "author": "zaherdab",
          "text": "Is it possible to train then for wan 2.2?",
          "score": 1,
          "created_utc": "2025-12-25 21:31:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0fz67",
          "author": "reddit22sd",
          "text": "What is your learning rate at?",
          "score": 1,
          "created_utc": "2025-12-26 11:56:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw2t9zg",
          "author": "Bronzeborg",
          "text": "workflow? :D",
          "score": 1,
          "created_utc": "2025-12-26 20:20:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvxdk0k",
          "author": "Kooky-Menu-2680",
          "text": "He just forgot to mention that faq is on messages ðŸ˜…ðŸ˜…ðŸ˜…ðŸ˜… .. this kind of posts are worthless more than the really worthless posts ..",
          "score": 0,
          "created_utc": "2025-12-25 21:28:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvx0yyi",
          "author": "Some_Artichoke_8148",
          "text": "Well this feels like a thinly veiled advert.",
          "score": 0,
          "created_utc": "2025-12-25 20:10:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw091is",
          "author": "wzwowzw0002",
          "text": "what is lokr?",
          "score": 0,
          "created_utc": "2025-12-26 10:48:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0dmps",
          "author": "Paraleluniverse200",
          "text": "Send us to try or can we give dataset for training?",
          "score": 0,
          "created_utc": "2025-12-26 11:34:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pup4tw",
      "title": "My experiment with \"widescreen\" outpainting 4:3 videos (WAN 2.1 vace + some python and ffmpeg)",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/wiitjl7x069g1",
      "author": "ignoramati",
      "created_utc": "2025-12-24 14:52:56",
      "score": 129,
      "num_comments": 22,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pup4tw/my_experiment_with_widescreen_outpainting_43/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nvqjhxo",
          "author": "moofunk",
          "text": "The staircase reveal at the end was very nice and pretty much flawless.\n\nWhile it's not perfect, I think it's the only way to really do widescreen material from 4:3.\n\nJust need some better models for it to make up for resolution and frames-per-second.",
          "score": 6,
          "created_utc": "2025-12-24 16:19:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvt8k2q",
          "author": "nsfwVariant",
          "text": "Well done! I've been working on something very similar - not specifically outpainting, but just stitching long videos together as flawlessly as possible using the same method you have. I think we could learn a lot from each other's work!\n\nThere are three things you can do to improve yours quite a bit, with #1 being easy, #2 being a bit time consuming, and #3 being harder:\n\n1. Save your generated videos as images, then stitch the images together to make the final video (rather than stitching videos together)\n    - This prevents the loss of quality from encoding/decoding video multiple times, it makes a big difference!\n    - You can cut your encode/decode down to just one: decode the original video once, then only re-encode to video at the final step when it's all stitched together again\n    - Side note: it's also much easier to do post-processing on image frames than whole videos\n\n2. Use a very, very precise combination of steps, sampler, and CFG to get the colours as close as possible between clips\n    - Wan VACE drifts colour, but there are specific combinations of steps/sampler/CFG that reduce this drift a lot\n    - Takes experimentation to find it - I can share the 'best' settings I've got so far on mine if you like\n\n3. Related to #2, but best to get #2 right first: use colour matching to get the colours back\n    - This is VERY finnicky to get right, but I'm working on an automated method for it\n    - Basically, with VACE, the colour drifts immediately on frame 1, then continues to drift differently until the final frame\n    - But because you have overlapping reference frames, you can progressively colour match based on those reference frames\n    - So, you can run a colour match at high strength on frame 1, slightly lower strength on frame 2, even lower for frame 3, etc\n    - Then somewhere in the middle you switch to colour matching based on the final frames instead, so you do a low match on frame -5, then stronger on frame -4, even stronger on frame -3, all the way until a strong match on the final frame\n    - This lowers the colour drift across the whole section, and smoothly transitions any remaining drift across the reference frames\n    - Combined with step #2, this massively reduces the colour drift and then \"hides\" the remainder by blending it across several frames so it's less perceptible to the human eye\n\n\nI'm going to keep working on it and will circle back to you when it's done. Most of my processing steps are in python as well - if we combine the two it's gonna look real good. Thanks for posting!",
          "score": 3,
          "created_utc": "2025-12-25 02:16:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvu0jga",
              "author": "ignoramati",
              "text": "Amazing comment, I was thinking about skipping \"chunking\" and going straight to frame images (because this obviously (and I mean, \"visually\") in comfyui what happens to the input video anyway).\n\nThe solution for the quality loss on chunking seems to be simply using `-crf 0` and `-preset ultrafast` when I encode the chunks (chunks then get ginormous but I'm fine with it). I will ofc push the script to github when I am done with this iteration of the experiment.\n\nAnother thing that got me stumped is \"feathering\" of the edges... Looks like I am getting lots of blurry edges where the original video was, and on black background this is way too visible. Need to do something about it, suggestions welcome.\n\nI must say, I never see ANY color drift, probably because the original video keeps it anchored?",
              "score": 1,
              "created_utc": "2025-12-25 06:02:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvu92eu",
                  "author": "nsfwVariant",
                  "text": "**CRF**\n\nI think crf 0 is probably ok, but I don't know if there's any info lost from the encoding/decoding process in general. Worth trying to see if it helps! Any quality loss between the original video and the output would 90% be because of the encode/decode steps - VACE itself maintains the quality pretty good.\n\nFeathered edges are probably to do with the diffusion process undercooking (I assume you mean the blurriness that happens at the edges when stuff moves into frame quickly?). Things that move quickly or appear abruptly result in bigger differences between frames and can \"undercook\" more easily by the diffuser, requiring more steps to resolve. Downside with doing more steps is that it usually makes colour shifting worse. Honestly though your video's feathering doesn't look too bad, I wouldn't worry to much about it. Fast-moving stuff often artifacts in videos anyway, so it's not that weird compared to real footage.\n\nThat said, the outpainted regions are sharper than your original footage; you can see which regions are outpainted because they're higher quality (which is kinda funny). You could kill two birds with one stone by slightly blurring the outpainted sections on purpose, which would both match the original footage better and obscure the feathering too.\n\n**Other feathering**\n\nOr maybe you meant the blurring between the outpainted part and the original clip? Which show as white bars on the left & right at the end of the clip after it zooms out? I'm not sure why that's there tbh, but I have a couple of ideas for how to fix it - lemme know if you'd like that\n\n**On Colour**\n\nRe: colour drift, it's very visible in your posted clip - can look at the white clothes and see how they swing between very yellowy to very reddish/contrasty. Here's a side-by-side screenshot, taken only a couple of frames apart: [https://i.ibb.co/0VVg980n/colour-shift.png](https://i.ibb.co/0VVg980n/colour-shift.png)\n\nWan/VACE have these random colour/contrast/brightness fluctuations with every generation, and they can be really severe when you've got either a very light or very dark scene. Yours is very white, so it's super noticeable. But by reducing both the severity of the drift (through #2) and the abruptness (through #3) it can become nearly invisible.\n\nIn your case, you may honestly be able to get away with just a single colour-match pass for each generated shot. You can just fit in a colour match node (from Kijai's nodes) after each gen and have it match to one of the input frames from that same gen, probably set to around 0.5 strength or so, and it should do the trick. Your input video is pretty uniform in colour so it should work well.\n\nCan do the same thing in Python pretty easily too of course.",
                  "score": 2,
                  "created_utc": "2025-12-25 07:25:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvrmypo",
          "author": "AlexGSquadron",
          "text": "What GPU you use and how much ram?",
          "score": 2,
          "created_utc": "2025-12-24 19:54:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvs1twz",
              "author": "ignoramati",
              "text": "Rented a 5090 with 64g ram, probably could do with less.",
              "score": 2,
              "created_utc": "2025-12-24 21:22:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrcd1a",
          "author": "GameEnder",
          "text": "I will have to try this. Had this idea for a while to make a widescreen version of A Charlie Brown Christmas.",
          "score": 1,
          "created_utc": "2025-12-24 18:54:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvs201c",
              "author": "ignoramati",
              "text": "I thought itâ€™s already widescreenâ€¦. At least on Apple TV.",
              "score": 1,
              "created_utc": "2025-12-24 21:23:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvs8m6m",
                  "author": "GameEnder",
                  "text": "My Blu-ray rip is 4:3.",
                  "score": 1,
                  "created_utc": "2025-12-24 22:03:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvrmwel",
          "author": "mastaquake",
          "text": "Can't wait to try this out on my older \"Linux Distros\".",
          "score": 1,
          "created_utc": "2025-12-24 19:54:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvsr5by",
          "author": "terrariyum",
          "text": "Nice!  And I haven't seen it done any better given open source tools.  \n\nI remember a couple years ago how excited this forum was when someone first outpainted single frames from some 90s tv shows.  Won't be long before someone converts this to a moving 3D VR environment",
          "score": 1,
          "created_utc": "2025-12-25 00:08:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvt2y75",
          "author": "No_Damage_8420",
          "text": "Thanks for sharing :)  \nThis is wonderful post and details.\n\nI look at Wan 2.1 VACE as power house (especially VFX etc) in all Wan sub-models.  \nOutpaint/inpaint - all same modes, either cropping, padding and masking Wan is doing great job on matching colors and look etc.\n\nI'm just just wondering how you CONNECT outpainted \"motion\" --- in specific junks \"outpainted\" ex. person playing piano would behave differently (I'm talking MOTION only).\n\nOur team wants to take advantage of this in - PERFECT stabilization, footage we work with - camera has extreme crop or too-close to actors, so we will OUTPAINT, then STABILIZE (without loosing much edges etc).  \nWill sure try your github, thanks!  \nCheers",
          "score": 1,
          "created_utc": "2025-12-25 01:34:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvufxwz",
              "author": "ignoramati",
              "text": "Not 100% sure what you mean by \"outpainted motion\" - but the process I used was:\n\nSave the last frame of the outpainted video, feed it into the next render as an \"anchor\" - so pianists's hands would be nearly at the same basic position in the next chunk we render. Note that  I have a small overlap between chunks (1.5 sec if memory serves). Then I do a crossfade when merging chunks, so it would fake the motion blur if this drifts too far apart. Of course this does NOTHING useful if the rendering wants to go in a direction opposite to what the last chunk did. So what you can do, is tweak the code so that you re-render from the chunk you disliked, and eventually you will hit on the correct behavior. My demo clip is a bad example, I guess, since the motion is either slow or repetitive.",
              "score": 2,
              "created_utc": "2025-12-25 08:38:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvulfb1",
                  "author": "No_Damage_8420",
                  "text": "Thanks for answer. This is great.  \nWhat an awesome example of long 3+ minute long Wan in one go. Incredible really :)\n\n\"Outpainted motion\" I meant - let's do different example, some people fighting (in outpainted area) if you then generate new chunk - would their fight style/motion be similar etc.  I guess your 1.5 sec overlap solves that...",
                  "score": 1,
                  "created_utc": "2025-12-25 09:39:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvut8g0",
          "author": "nntb",
          "text": "In the future this will be real time and offered built into tvs",
          "score": 1,
          "created_utc": "2025-12-25 11:04:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvohiw",
              "author": "ignoramati",
              "text": ":) And ever-so-slightly different every time you watch it",
              "score": 2,
              "created_utc": "2025-12-25 15:21:39",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nvx53h2",
              "author": "pauliecomelately",
              "text": "Underrated comment. So true.",
              "score": 1,
              "created_utc": "2025-12-25 20:36:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwdjo3a",
          "author": "Miltos74",
          "text": "Interesting test. I think the model has a hard time replicating the look of the original medium (too much edge enhancement against the original's image softness) but apart from that it is impresive it is even possible.",
          "score": 1,
          "created_utc": "2025-12-28 15:32:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pv96a2",
      "title": "PSA: Eliminate or greatly reduce Qwen Edit 2509/2511 pixel drift with latent reference chaining",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1pv96a2",
      "author": "goddess_peeler",
      "created_utc": "2025-12-25 08:49:23",
      "score": 126,
      "num_comments": 47,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial - Guide",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pv96a2/psa_eliminate_or_greatly_reduce_qwen_edit/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nvuq8f9",
          "author": "iamthenightingale",
          "text": "Oh the hue-manatee!!! ðŸŒˆ",
          "score": 13,
          "created_utc": "2025-12-25 10:32:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvuiagy",
          "author": "inb4Collapse",
          "text": "Your post is very helpful. Thank you so much",
          "score": 12,
          "created_utc": "2025-12-25 09:04:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvwdhr0",
              "author": "Hauven",
              "text": "\\+1 to this.\n\nI've just tried this kind of workflow, and wow prompt adherence is definitely a noticeable improvement! Also character consistency seems better when completely changing scenes too.\n\nNever knew about this before, so thanks OP for posting this.",
              "score": 1,
              "created_utc": "2025-12-25 17:52:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvux89j",
          "author": "suspicious_Jackfruit",
          "text": "Even with this method you get close to pixel perfect like 1 out of 10 generations, the warping and cropping and shifting is still present in most outputs. It's frustrating, I tried to train it out of the model by rewriting how AI toolkit trains on qwen-edit but then flux2 dropped and it worked straight away with zero drift, warping or zoom. Occasionally it changes a pose slightly like an arm moving an inch out but that's it, it's very consistent",
          "score": 8,
          "created_utc": "2025-12-25 11:46:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvhyyy",
              "author": "goddess_peeler",
              "text": "What you say does not match my experience.",
              "score": 3,
              "created_utc": "2025-12-25 14:38:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvvy906",
          "author": "TurbTastic",
          "text": "The it/s sampling speed will slow down as you add more and more megapixels of images via Reference Latent. So small images add a small speed penalty and large images add a large speed penalty.",
          "score": 3,
          "created_utc": "2025-12-25 16:21:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvww12d",
          "author": "LumbarJam",
          "text": "Way better than the original for pixel-level perfection. Slightly slower, but better overall.\n\n3 images is doable (my workflow is based on this thread). Adherence is a bit worse with 3 images, but still workable.\n\nThx",
          "score": 3,
          "created_utc": "2025-12-25 19:40:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvx2p38",
          "author": "JimJongChillin",
          "text": "1manatee",
          "score": 3,
          "created_utc": "2025-12-25 20:21:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw2ayex",
          "author": "RoboticBreakfast",
          "text": "So I think I've identified an issue with ref latent chaining that may degrade the character consistency of the original image, but there is another way to handle it that doesn't require chaining (but instead combining). Ref latent 1 needs to be handled differently than ref latent 2+ (the ref images) and ultimately should be the conditioning input to all of the other ref latents\n\nI am testing the workflow and will post later once I've run through my tests, but it should actually result in some incremental improvements",
          "score": 3,
          "created_utc": "2025-12-26 18:42:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw8j2y2",
              "author": "kaboomtheory",
              "text": "Any updates on this?",
              "score": 1,
              "created_utc": "2025-12-27 19:12:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwn1euv",
                  "author": "RoboticBreakfast",
                  "text": "Sorry for the delay - here is my [Post](https://www.reddit.com/r/StableDiffusion/comments/1pz2gxy/qwen_image_edit_2511_workflow_for_preserving/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",
                  "score": 2,
                  "created_utc": "2025-12-30 00:04:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw8w3li",
                  "author": "RoboticBreakfast",
                  "text": "Yeah, I'll make a post later today - I want to be able to explain the how/why, so I need to dive back into the node so I can frame why chaining is problematic",
                  "score": 1,
                  "created_utc": "2025-12-27 20:21:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvuocec",
          "author": "Riya_Nandini",
          "text": "now try with different aspect ratio",
          "score": 4,
          "created_utc": "2025-12-25 10:11:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvhfla",
              "author": "goddess_peeler",
              "text": "https://preview.redd.it/klwujvvn2d9g1.png?width=1566&format=png&auto=webp&s=c00d1f41c37eff1677decded8c6dcdfad35c9f01",
              "score": 4,
              "created_utc": "2025-12-25 14:34:32",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nvvhgc3",
              "author": "goddess_peeler",
              "text": "https://preview.redd.it/6qu3yk5p2d9g1.png?width=1113&format=png&auto=webp&s=3e8377ec2c05762de83817b02f3886c33d23b6b1",
              "score": 5,
              "created_utc": "2025-12-25 14:34:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvwhw7a",
                  "author": "Riya_Nandini",
                  "text": "nice!",
                  "score": 3,
                  "created_utc": "2025-12-25 18:18:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvvhhf9",
              "author": "goddess_peeler",
              "text": "https://preview.redd.it/s5pvxomq2d9g1.png?width=1400&format=png&auto=webp&s=e06e2c7f20baf331f7e857dafb1d875731becf41",
              "score": 5,
              "created_utc": "2025-12-25 14:34:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvv41h3",
          "author": "alb5357",
          "text": "I wonder if you can use this to get more than 3 reference images?",
          "score": 1,
          "created_utc": "2025-12-25 12:51:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvlgrq",
              "author": "goddess_peeler",
              "text": "I have seen custom text encoder nodes that have more than three image inputs, so I think the three here is an artificial limit.",
              "score": 4,
              "created_utc": "2025-12-25 15:02:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvvm6jn",
                  "author": "alb5357",
                  "text": "Does it have any limit then? Could I use 100 reference images?",
                  "score": 1,
                  "created_utc": "2025-12-25 15:06:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvxgagp",
          "author": "kharzianMain",
          "text": "Definitely will try this, ty",
          "score": 1,
          "created_utc": "2025-12-25 21:45:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvxgqjr",
          "author": "Vektast",
          "text": "thanks",
          "score": 1,
          "created_utc": "2025-12-25 21:47:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvxpjr8",
          "author": "generate-addict",
          "text": "On 2509 this significantly reduced IQ for me. On 2511 it seemed to have a negligible affect. It did force me to pixel peep more on my qwen outputs and for my test here it seems I get weird grid/pattern artifacts on Harold's beard. Its actually best on 2509 default workflow, and worst on 2509 with the ref latent node. 2511 seems to be in the middle of the two. \n\n[https://imgur.com/a/l5wkBrR](https://imgur.com/a/l5wkBrR)",
          "score": 1,
          "created_utc": "2025-12-25 22:42:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvyxmdc",
          "author": "drallcom3",
          "text": "All my images are completely black with this workflow or any other 2511 workflow. Any solution?",
          "score": 1,
          "created_utc": "2025-12-26 03:35:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvyyuk7",
              "author": "goddess_peeler",
              "text": "I haven't had this problem, but I have read about sage attention causing black image output for some people. Do you have sage attention installed? Does disabling it help?",
              "score": 1,
              "created_utc": "2025-12-26 03:44:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvyzogl",
                  "author": "drallcom3",
                  "text": "You are right. Simply not loading sage was enough to make your workflow work.",
                  "score": 1,
                  "created_utc": "2025-12-26 03:50:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw723nj",
          "author": "CeraRalaz",
          "text": "https://preview.redd.it/1ygevlc1dr9g1.png?width=1200&format=png&auto=webp&s=cd52beaf3d4b61255d7a15a40a21b06fcfad1215\n\nNot 100% ideal but actually very good",
          "score": 1,
          "created_utc": "2025-12-27 14:37:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwt5ogw",
          "author": "goldax2014",
          "text": "Your workflow is working like a charm but take a bit longer time than the standard one",
          "score": 1,
          "created_utc": "2025-12-30 22:10:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwu2su4",
              "author": "goddess_peeler",
              "text": "As expected, since now the input images are not being scaled down to 1024p. There's more to process. \n\n[This post](https://www.reddit.com/r/StableDiffusion/comments/1pz2gxy/qwen_image_edit_2511_workflow_for_preserving/) takes reference chaining further and attempts to correct some issues with the current approach. I haven't had time to look at it yet, but it seems interesting.",
              "score": 1,
              "created_utc": "2025-12-31 01:08:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvw2ly9",
          "author": "SirTeeKay",
          "text": ">You can reduce or eliminate pixel shift in Qwen Image Edit workflows by unplugging VAE and the image inputs from the TextEncodeQwenImageEditPlus nodes, and adding a VAE Encode and ReferenceLatent node per image input. Disconnecting the image inputs is optional, but I find prompt adherence is better with no image inputs on the encoder. YMMV.\n\nThis is very interesting. I knew that the TextEncodeQwenImageEditPlus basically degrades the image but this is a really interesting workaroudn that I'd love to know how it works.",
          "score": 1,
          "created_utc": "2025-12-25 16:47:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvwai27",
          "author": "ol_barney",
          "text": "Experiencing something weird... this worked for me with almost pixel perfect output, but bad prompt adherence with 2511 (Prompt is \"Remove the watermark\" and it just kept changing the watermark to different text, but the before and after alignment is spot on, as well as image quality).  When I switch to 2509 in this workflow, prompt adherence is perfect, as well as pixel alignment, but the image looks really burned.  Tried with both 4 step and 8 step 2509 loras and adjusted steps accordingly, and 2509 always looks way overcooked.  \n\nI can bypass the new VAE encoding steps and reconnect the old way in your workflow and it goes back to working with good looking output, but reintroducing the pixel shift obviously, so I know my settings and models are good.\n\nAny clue what I can try to address this burned in look on 2509?  Tried with FP8 and FP16 on a 5090.",
          "score": 1,
          "created_utc": "2025-12-25 17:35:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvwpbf2",
              "author": "goddess_peeler",
              "text": "I have seen the same thing! 2511 hallucinates new watermarks about 50% of the time when I ask it to remove one. I havenâ€™t had time to really explore that. 2509 plus color correction still does a good job on watermarks for me.",
              "score": 1,
              "created_utc": "2025-12-25 19:00:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvwufy0",
                  "author": "Delicious_Source_496",
                  "text": "2509 plus color correction, can you plz explain more or share a workflow, i appreciate it thanks",
                  "score": 1,
                  "created_utc": "2025-12-25 19:31:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw02o67",
                  "author": "Agile-Role-1042",
                  "text": "Have you found out about the watermark thing? I got this too and its really bugging me.",
                  "score": 1,
                  "created_utc": "2025-12-26 09:43:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pyi8vr",
      "title": "Looks like 2-step TwinFlow for Z-Image is here!",
      "subreddit": "StableDiffusion",
      "url": "https://huggingface.co/inclusionAI/TwinFlow-Z-Image-Turbo",
      "author": "External_Quarter",
      "created_utc": "2025-12-29 09:46:17",
      "score": 120,
      "num_comments": 40,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pyi8vr/looks_like_2step_twinflow_for_zimage_is_here/",
      "domain": "huggingface.co",
      "is_self": false,
      "comments": [
        {
          "id": "nwiupv2",
          "author": "Traditional_Bend_180",
          "text": "is ready to use on confyui ?",
          "score": 13,
          "created_utc": "2025-12-29 10:22:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwiwcti",
              "author": "External_Quarter",
              "text": "There is a [TwinFlow extension on GitHub](https://github.com/smthemex/ComfyUI_TwinFlow) but I think it only supports GGUF quants of Qwen-Image at the moment.",
              "score": 7,
              "created_utc": "2025-12-29 10:37:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwkgs1w",
                  "author": "HareMayor",
                  "text": "Do both qwen and z image have lora support?",
                  "score": 1,
                  "created_utc": "2025-12-29 16:30:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwj33fn",
          "author": "tomakorea",
          "text": "is there a downgrade compare to the original model or is it lossless?",
          "score": 15,
          "created_utc": "2025-12-29 11:37:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwix39r",
          "author": "a_beautiful_rhind",
          "text": "Gonna mean I can make some larger images.",
          "score": 6,
          "created_utc": "2025-12-29 10:43:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwj6ewk",
              "author": "LeKhang98",
              "text": "How? Isn't the only thing this changes is the total number of steps?",
              "score": 2,
              "created_utc": "2025-12-29 12:04:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwjb0fm",
                  "author": "a_beautiful_rhind",
                  "text": "The time to generate will go down so I can bump up the resolution and keep it reasonable. At least hopefully. I'm not short of vram, just compute.",
                  "score": 13,
                  "created_utc": "2025-12-29 12:39:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwj3rnw",
          "author": "ratttertintattertins",
          "text": "Can someone explain like I'm 5?  I read the original page 4 times and still couldn't really understand what this is for.",
          "score": 7,
          "created_utc": "2025-12-29 11:42:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwj3x68",
              "author": "External_Quarter",
              "text": "Makes pictures with Z-Image Turbo in 1-4 steps instead of 8-9 steps",
              "score": 21,
              "created_utc": "2025-12-29 11:43:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwja481",
                  "author": "MikePounce",
                  "text": "Zit is already quite capable at 3 steps for some prompts that don't involve humans",
                  "score": 5,
                  "created_utc": "2025-12-29 12:33:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwj3zut",
                  "author": "ratttertintattertins",
                  "text": "Oh nice, thanks.",
                  "score": 3,
                  "created_utc": "2025-12-29 11:44:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwj42gm",
              "author": "safetywerd",
              "text": "It makes z-image even faster.",
              "score": 3,
              "created_utc": "2025-12-29 11:45:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwjg1u6",
          "author": "Next_Program90",
          "text": "Yeah... I'm fine. Z is churning gens out faster than I can check and iterate on them. 10s/image (HQ) is fast enough for me.",
          "score": 8,
          "created_utc": "2025-12-29 13:14:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwjv0h7",
              "author": "xcdesz",
              "text": "Although I agree this isn't very useful for people who are generating individual images on high end vram machines, I can see how this type of research will be hugely important for things like near realtime generations using this tech inside of games and animations.",
              "score": 8,
              "created_utc": "2025-12-29 14:43:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwjhjw0",
          "author": "Acceptable_Secret971",
          "text": "Interesting. I tried the Qwen Image one. On RX 7900 XTX it was slightly faster than lightning Lora, but going below Q6 was really bad for quality and it was using a lot of RAM (not VRAM). 24GB RAM was barely enough to run the thing. People reported that it was slower than lightning Lora on NVIDIA (probably depends on which GPU you use).",
          "score": 3,
          "created_utc": "2025-12-29 13:24:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjxwip",
          "author": "Structure-These",
          "text": "Can I get this running in comfy?",
          "score": 3,
          "created_utc": "2025-12-29 14:58:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnbbx9",
              "author": "External_Quarter",
              "text": "According to discussions, this repacked version runs natively in Comfy:\n\nhttps://huggingface.co/azazeal2/TwinFlow-Z-Image-Turbo-repacked\n\nHaven't tried it yet myself.",
              "score": 5,
              "created_utc": "2025-12-30 00:58:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwitdgv",
          "author": "One_Yogurtcloset4083",
          "text": "would like to see same for flux.2 dev",
          "score": 9,
          "created_utc": "2025-12-29 10:09:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwj6g84",
              "author": "Old_Estimate1905",
              "text": "There is already piflow support for flux 2 den with 4 steps. It's working good but for edits the normal sampler with more steps are working better",
              "score": 4,
              "created_utc": "2025-12-29 12:04:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwjfxjn",
                  "author": "One_Yogurtcloset4083",
                  "text": "you can try piflow with more than 4 steps",
                  "score": 2,
                  "created_utc": "2025-12-29 13:14:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwitfck",
          "author": "dead-supernova",
          "text": "we need Quantizations for that",
          "score": 5,
          "created_utc": "2025-12-29 10:10:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwk7n7e",
              "author": "ANR2ME",
              "text": "GGUF version at https://huggingface.co/smthem\n\nFP8 version at https://huggingface.co/azazeal2/TwinFlow-Z-Image-Turbo-repacked/tree/main/ComfyUI",
              "score": 10,
              "created_utc": "2025-12-29 15:47:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwk8489",
          "author": "Available-Body-9719",
          "text": "deberian hacer mas rapido los codificadores de texto, es lo que mas tiempo consume ahora",
          "score": 2,
          "created_utc": "2025-12-29 15:49:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjczmy",
          "author": "cgs019283",
          "text": "Honestly, I see quality degradation a lot.",
          "score": 4,
          "created_utc": "2025-12-29 12:54:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm5va9",
              "author": "AmazinglyObliviouse",
              "text": "Only one comment, between all the yelling of \"comfy! quants! I make large image! Anyone have eyes to tell me of this is good\" that actually looked at the example images.\n\nJesus this subreddit sometimes.\n\nYeah the quality is absolutely abyssmal, technically it might work if you 4x down scale the output.",
              "score": 5,
              "created_utc": "2025-12-29 21:20:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwita7t",
          "author": "COMPLOGICGADH",
          "text": "Waiting for quants I guess....",
          "score": 2,
          "created_utc": "2025-12-29 10:08:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwitff2",
              "author": "neverending_despair",
              "text": "Why? It's tiny.",
              "score": -2,
              "created_utc": "2025-12-29 10:10:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwitnkq",
                  "author": "COMPLOGICGADH",
                  "text": "I don't have 12gb vram would love to have a smaller one...",
                  "score": 4,
                  "created_utc": "2025-12-29 10:12:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwiuoi3",
                  "author": "WackyConundrum",
                  "text": "Is that what she said? Damn... That's harsh.",
                  "score": -2,
                  "created_utc": "2025-12-29 10:21:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwl9ag8",
          "author": "SunGod1957",
          "text": "RemindMe! 3 dayÂ ",
          "score": 1,
          "created_utc": "2025-12-29 18:43:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwl9evs",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 3 days on [**2026-01-01 18:43:43 UTC**](http://www.wolframalpha.com/input/?i=2026-01-01%2018:43:43%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/StableDiffusion/comments/1pyi8vr/looks_like_2step_twinflow_for_zimage_is_here/nwl9ag8/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FStableDiffusion%2Fcomments%2F1pyi8vr%2Flooks_like_2step_twinflow_for_zimage_is_here%2Fnwl9ag8%2F%5D%0A%0ARemindMe%21%202026-01-01%2018%3A43%3A43%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201pyi8vr)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2025-12-29 18:44:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pvj4u6",
      "title": "Qwen-Image-Edit-2511 workflow that actually works",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/vte7hne53e9g1.png",
      "author": "infearia",
      "created_utc": "2025-12-25 18:12:12",
      "score": 113,
      "num_comments": 78,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pvj4u6/qwenimageedit2511_workflow_that_actually_works/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nvwhait",
          "author": "fruesome",
          "text": "Workflow released by ComfyUI solved the main problems.",
          "score": 22,
          "created_utc": "2025-12-25 18:14:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvwigp9",
              "author": "infearia",
              "text": "The official ComfyUI workflow is fine, but in my opinion, it's suboptimal for 4-step inference.\n\nEDIT:  \nI wish people would stop downvoting this comment. If you test both my and the official workflow at 4 steps and CFG 1.0, you will see that the official workflow produces slightly blurrier outputs. And the lightning LoRA used in the official workflow often (though not always) leads to less realistic looking results.",
              "score": 20,
              "created_utc": "2025-12-25 18:21:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvysmo7",
                  "author": "fruesome",
                  "text": "I disabled Torch Compile and workflow works great.",
                  "score": 5,
                  "created_utc": "2025-12-26 03:00:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvzkeod",
                  "author": "luciferianism666",
                  "text": "upvoted the comment for u lol",
                  "score": 2,
                  "created_utc": "2025-12-26 06:38:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvwk0r9",
                  "author": "fruesome",
                  "text": "Thanks, i'll try it and let you know how it is.",
                  "score": 1,
                  "created_utc": "2025-12-25 18:30:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw3ymo2",
                  "author": "Green-Ad-3964",
                  "text": "I'll test yours, since the official WF is quite bad for me and I posted that few days ago.",
                  "score": 1,
                  "created_utc": "2025-12-27 00:15:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw5gcx1",
                  "author": "Lil_Twist",
                  "text": "Upvoted and holding the line.",
                  "score": 1,
                  "created_utc": "2025-12-27 06:20:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvwo1ga",
          "author": "Ok-Option-6683",
          "text": "To be honest, this is the first Qwen 2511 workflow that doesn't work for me. Getting a Ksampler Compilation Error.",
          "score": 12,
          "created_utc": "2025-12-25 18:53:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvwog1t",
              "author": "infearia",
              "text": "Hmm, what if you disable the Torch Compile node?",
              "score": 1,
              "created_utc": "2025-12-25 18:55:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvwswe4",
                  "author": "Ok-Option-6683",
                  "text": "I'll give it a try. But you are right about the older lightning lora. It works better.",
                  "score": 5,
                  "created_utc": "2025-12-25 19:21:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvxspcd",
          "author": "xhox2ye",
          "text": "In fact, it can be simpler, with only two key points, ReferenceLatent and Qwen-Image-Lightning-4steps-V2.0.\n\nhttps://preview.redd.it/z0gn6pmalf9g1.png?width=896&format=png&auto=webp&s=c9b05490b7591a906bf7d4e54373d2561b1c9d2b",
          "score": 6,
          "created_utc": "2025-12-25 23:02:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvy6n76",
              "author": "infearia",
              "text": "I'm not sure I understand. My workflow employs ReferenceLatents and the Qwen-Image-Lightning-4steps-V2.0 LoRA.  \n  \nAlso,  the setup from your screenshot - removing all image inputs from the Text Encode node and piping the positive prompt through the ConditioningZeroOut node and into the positive KSampler input - would completely prevent any image input from flowing to the KSampler. It would be like doing TXT2IMG, with the input images being completely ignored. Am I missing something here?",
              "score": 1,
              "created_utc": "2025-12-26 00:32:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvy8sij",
                  "author": "xhox2ye",
                  "text": "Use ReferenceLatent in the positive prompt.\n\nConditioningZeroOut into reverse prompt.",
                  "score": 6,
                  "created_utc": "2025-12-26 00:45:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw2915u",
          "author": "Epictetito",
          "text": "Thank you for sharing your work.\n\nI just want to add, if it helps, that after several hours of testing, I have come to the conclusion that in my case, with an RTX 3060 with 12 GB of VRAM, it is faster to use the model:\n\nqwen\\_image\\_edit\\_2511\\_fp8\\_e4m3fn\\_scaled\\_lightning\\_comfyui.safetensors\n\nthan any .GGUF. I edit simple 1024 x 1024 pixel images at a speed of 7.79s/it.\n\nIn addition, I get better results using that model, which has 4-step lighting built in, than loading the LoRA on a separate node. Using a node for LoRAs creates a pattern with a moirÃ© effect in some areas of the images.\n\nAnd yes, doing camera pan rotation is a big challenge. Sometimes it works and sometimes it doesn't. I've been talking about this with dx8152 (creator of magnificent LoRAs for 2509, including the multi-angle one) who told me to look into this issue.",
          "score": 6,
          "created_utc": "2025-12-26 18:32:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw2g0vt",
              "author": "infearia",
              "text": "Glad you find my workflow useful! :)\n\nAnd yes, FP8 in general is faster than GGUF, and FP8\\_scaled is superior to FP8.  \n  \nThank you for mentioning the safetensors file, I wasn't aware that LightX2V have released another version. The first one didn't work for me, that's why I'm using a different one with a separate LoRA loader in my workflow. But I'm downloading it as I'm typing this comment. Thank you for the tip!",
              "score": 3,
              "created_utc": "2025-12-26 19:08:41",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nw5ubrr",
              "author": "pto2k",
              "text": "Curious what was your experience with the speed of the default model?\n\nFor me, the generation time varies significantlyâ€”from 60 seconds to 2700 seconds... with a 4070/ 12GB of VRAM.\n\nDid you observe the same thing?",
              "score": 1,
              "created_utc": "2025-12-27 08:31:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw690r5",
                  "author": "Epictetito",
                  "text": "I haven't noticed any differences in speed between fp8 models, only differences in quality.\n\nI have 64 GB of RAM and I have also run the 38 GB bf16 model. The problem I have encountered is the same: when applying the 4-step LoRA lightning independently in its own node, it creates patterns in the image, also with the bf16.  As I mentioned before, for me, the model:\n\nqwen\\_image\\_edit\\_2511\\_fp8\\_e4m3fn\\_scaled\\_lightning\\_comfyui.safetensors\n\nwhich has LoRA integrated, is perfect in terms of quality, speed, etc... sometimes even with only 3 steps!\n\nI try to make the workflows as simple as possible. In my tests, I haven't noticed any difference in quality or speed when using or not using the CFGNorm and ModelSamplingAuraFlow nodes, so I remove them. I also remove some of the nodes offered by infearia. I only use one positive node from TextEncodeQwenImageEditPlus, so I also remove some of the subsequent nodes shown here.\n\nI am far from being an expert in ComfyUI or AI models. I simply want a workflow that is as simple and fast as I can understand and that has as few options as possible. Once I achieve this, I create another workflow with which I can perform selective inpainting with masks on parts of the image so as not to degrade the rest that I do not edit, because every time we edit an image, we have to encode it to latent space and then decode it to image format, and in that process there will always be compression/decompression and degradation, and I try to avoid that.",
                  "score": 3,
                  "created_utc": "2025-12-27 10:55:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvz6ahb",
          "author": "reyzapper",
          "text": "Your workflow saved me from wasting even more hours dealing with those zoom in/out results, it's so f\\*ing annoying, now i got the proper result, Thank you! ðŸ‘\n\nUsing 2511 4 steps lora and Q4\\_KM gguf clip and Q4\\_KM 2511 gguf model.\n\nhttps://preview.redd.it/1uktj4179h9g1.png?width=586&format=png&auto=webp&s=75e0871dc8ee0d0db9ea354f453d9aa1f1575fe0\n\n`change the color of her clothes and scarf to green`",
          "score": 4,
          "created_utc": "2025-12-26 04:39:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0hgc0",
              "author": "infearia",
              "text": "Happy to hear that! Sadly, my workflow doesn't fully solve the pixel shift problem, it only reduces it. The shift still happens, but less often, and when it does, it's usually less noticeable. Good news: if it happens, you can usually fix it by changing the seeds a few times until it's gone. You probably got a lucky seed. :)",
              "score": 2,
              "created_utc": "2025-12-26 12:09:38",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nw3eyun",
              "author": "The_Great_Nothing_",
              "text": "Plese can you share the workflow along with the exact gguf models? I spent the afternoon trying to make it work, updated Comfy and nodes but to no avail. I always get \"unet unexpected: ['index_timestep_zero']\" regardless of workflow.",
              "score": 2,
              "created_utc": "2025-12-26 22:19:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwjp9q3",
              "author": "Excellent-Emu9548",
              "text": "https://preview.redd.it/quaushj2i5ag1.png?width=728&format=png&auto=webp&s=843bd2c206ee81c625a7b733a9c505f6b2ef64e9\n\nim getting this error",
              "score": 1,
              "created_utc": "2025-12-29 14:10:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvwypa8",
          "author": "InternationalOne2449",
          "text": "Man this worklow is disgusting. I can't make anything out.",
          "score": 5,
          "created_utc": "2025-12-25 19:56:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvx1qpr",
              "author": "infearia",
              "text": "Are you referring to the cover image? You're not supposed to put the workflow together from studying the image. I've provided the workflow as a JSON file. You only need to download it and then drag&drop it onto ComfyUI. ;)",
              "score": 3,
              "created_utc": "2025-12-25 20:15:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvwozde",
          "author": "InternationalOne2449",
          "text": "I just replaced two nodes in my main Qwen workflow.",
          "score": 2,
          "created_utc": "2025-12-25 18:58:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvxqxp3",
          "author": "JIGARAYS",
          "text": "\"Qwen-Image-Lightning-4steps-V2.0\" changes character too much, although it creates smooth/clean results. use \"Qwen-Image-Edit-2511-Lightning-4steps-V1.0-fp32\" if you want max character consistency. 2511-fp32 lora produces much cleaner results than bf16",
          "score": 2,
          "created_utc": "2025-12-25 22:51:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvy8dn4",
              "author": "infearia",
              "text": "I guess at the end it's a matter of taste. And I admit it's a bit of a mess with all these different LoRAs, difficult to know which to pick. Right now, I seem to be getting better results with the Qwen Image LoRA, including maintaining better character consistency between edits. But there is an element of randomness to it. If you don't get the amount of likeness you need, just re-roll a couple of times with the same prompt but different seeds.",
              "score": 2,
              "created_utc": "2025-12-26 00:42:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvz6ksy",
                  "author": "JIGARAYS",
                  "text": "checked \"Qwen-Image-Lightning-4steps-V2.0\" again. damn! its awesome. initial tests are pixel perfect. thanks for sharing!",
                  "score": 5,
                  "created_utc": "2025-12-26 04:42:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw1naok",
          "author": "pohnkn",
          "text": "Thank you!",
          "score": 2,
          "created_utc": "2025-12-26 16:38:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw1raht",
              "author": "infearia",
              "text": "You're welcome. :)",
              "score": 1,
              "created_utc": "2025-12-26 16:59:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvyck3t",
          "author": "GlamoReloaded",
          "text": "Shouldn't be the FluxKontextMultiReferenceLatentMethod leading into the negative AND positive in KSampler? In your workflow only the negative is connected,",
          "score": 1,
          "created_utc": "2025-12-26 01:10:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvyeoen",
              "author": "infearia",
              "text": "Both the outputs, from the positive and the negative prompt, are connected to their respective FluxKontextMultiReferenceLatentMethod nodes. And they each connect to the positive and negative KSampler inputs. Look more closely.",
              "score": 1,
              "created_utc": "2025-12-26 01:25:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvyfagg",
                  "author": "GlamoReloaded",
                  "text": "I stand corrected. Sorry. Somehow the image was different despite a fixed seed miust  be the the lighting lora.",
                  "score": 2,
                  "created_utc": "2025-12-26 01:29:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvyxx3o",
                  "author": "ArachnidDesperate877",
                  "text": "Sorry for the noob query, but where are the images being saved...can't seem to find in the Output folder!!!",
                  "score": 1,
                  "created_utc": "2025-12-26 03:37:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvz7k3p",
          "author": "desktop4070",
          "text": "How much VRAM is required to run this Workflow with qwen_image_edit_2511_fp8_e4m3fn?  \n  \nWould GGUF be better for a 16GB RTX 5080?",
          "score": 1,
          "created_utc": "2025-12-26 04:49:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvz9h66",
              "author": "Huge_Pumpkin_1626",
              "text": "im just about to test the 20gb fp8 on a 16gb 4000 series card. not expecting it to work but have heard there's something like a 30% vram req reduction for fp8 with 4000 series and above",
              "score": 1,
              "created_utc": "2025-12-26 05:04:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw0i3z6",
              "author": "infearia",
              "text": "Should run on a 16GB VRAM card, thanks to ComfyUI's CPU offloading, especially with Triton installed and the Torch Compile node enabled, which reduces the RAM usage by about 30%. It does on my RTX 4060Ti 16GB. The FP8 version is better (less blurry) than the Q6 GGUF, but I haven't tested it against the Q8.",
              "score": 1,
              "created_utc": "2025-12-26 12:15:27",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nw0q90o",
              "author": "xhox2ye",
              "text": "My 2070s-8G runs without any issues",
              "score": 1,
              "created_utc": "2025-12-26 13:20:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw57lo6",
                  "author": "desktop4070",
                  "text": "The 20GB fp8 file runs on your 8GB 2070 Super? How long for an image?",
                  "score": 1,
                  "created_utc": "2025-12-27 05:10:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw19pt3",
          "author": "VFXxx",
          "text": "https://preview.redd.it/s0kgqesdfk9g1.jpeg?width=1945&format=pjpg&auto=webp&s=ab865c4fa22506cc38569439da2b956a8820bc2d\n\nCame here to say thank you - Iâ€™ve been playing with the workflow for a couple of hours and Iâ€™m genuinely impressed by the speed and quality.\n\nIâ€™ve thrown in sketches, half-baked renders that needed detailing and relighting - everything just works.\n\nThe official Comfy workflow gives me horrible hallucinations and itâ€™s quite slow as well.\n\nThis is coming from a non-experienced ComfyUI user, so itâ€™ll take me some time to properly understand whatâ€™s happening under the hood.",
          "score": 1,
          "created_utc": "2025-12-26 15:24:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw1qijx",
              "author": "infearia",
              "text": "Thank you very much for the kind words! However, I really can't take the credit for all this. I've simply put together a workflow based on some of the best practices I've gleaned from other people's comments, as well as through my own experimentation, but the actual praise should go to all the researchers and developers responsible for creating this amazing model, the lightning LoRA and of course, the Comfy team.\n\nNevertheless, it makes me happy to know that something I did contributed to a positive experience for someone else. Thank you!",
              "score": 1,
              "created_utc": "2025-12-26 16:55:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw2d4wm",
          "author": "maglat",
          "text": "Thank you for the WF. Would you mind to share the links to the exact diffusion\\_model variant of qwen image edit 2511 and the lora?",
          "score": 1,
          "created_utc": "2025-12-26 18:53:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw2hodr",
              "author": "infearia",
              "text": "Sure thing!\n\nI got the model from here:\n\n[https://www.reddit.com/r/comfyui/comments/1pu2p81/qwenimageedit2511\\_e4m3fn\\_fp8\\_quant/](https://www.reddit.com/r/comfyui/comments/1pu2p81/qwenimageedit2511_e4m3fn_fp8_quant/)\n\nand the LoRA from here:\n\n[https://huggingface.co/lightx2v/Qwen-Image-Lightning/tree/main](https://huggingface.co/lightx2v/Qwen-Image-Lightning/tree/main)\n\nHowever, there seems to be a new version of QIE-2511 with the latest LightX2V 4-Step LoRA already merged (which means that you don't need to load the LoRA separately and can disable the loader node in the workflow). Might be worth checking out, I'm downloading it now myself. Here's the link:\n\n[https://huggingface.co/lightx2v/Qwen-Image-Edit-2511-Lightning/resolve/main/qwen\\_image\\_edit\\_2511\\_fp8\\_e4m3fn\\_scaled\\_lightning\\_comfyui.safetensors?download=true](https://huggingface.co/lightx2v/Qwen-Image-Edit-2511-Lightning/resolve/main/qwen_image_edit_2511_fp8_e4m3fn_scaled_lightning_comfyui.safetensors?download=true)",
              "score": 1,
              "created_utc": "2025-12-26 19:17:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwqxr2u",
                  "author": "Gullible-Walrus-7592",
                  "text": "how did the new version do? Mind updating the workflow ðŸ˜…",
                  "score": 1,
                  "created_utc": "2025-12-30 15:54:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwta6qv",
                  "author": "sacred-abyss",
                  "text": "is the baked in lora version better? ive only tried that one but im getting meh results with clothes swapping",
                  "score": 1,
                  "created_utc": "2025-12-30 22:33:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw2hr2l",
          "author": "xDFINx",
          "text": "Has anyone figured out a way to input more than 3 images?",
          "score": 1,
          "created_utc": "2025-12-26 19:17:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw3peni",
          "author": "tm_81",
          "text": "Hi, i am getting better results and faster results using this workflow on rtx 5090 \n\ni didn't try the LightX2V but going to try it,\n\nis there a way to control the output image size ?",
          "score": 1,
          "created_utc": "2025-12-26 23:19:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3wkhc",
              "author": "infearia",
              "text": "Yes, there's a built-in option for changing the output resolution in the workflow:\n\nhttps://preview.redd.it/1dk7pgox0n9g1.png?width=792&format=png&auto=webp&s=53b028e26b724e4c662bb01cc6a88ebcc4c46d29",
              "score": 1,
              "created_utc": "2025-12-27 00:02:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwjitrz",
          "author": "aj_speaks",
          "text": "Downloaded and ran this but getting black image. I am using 2511 FP8 Mixed and disabled lighting Lora.\n\nTried different images and different prompts but nothing seems to work.\n\nRunning on 3090. Any idea what may be going wrong for me here?",
          "score": 1,
          "created_utc": "2025-12-29 13:32:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwjnv4j",
              "author": "aj_speaks",
              "text": "I figured out. I was running comfyUI with sageattention and it would always output black. Ran comfyUI without it and all's well.\n\nThough Qwen is compatible with SageAttention so is there a way to make this work with it on?",
              "score": 1,
              "created_utc": "2025-12-29 14:02:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwk3q6i",
                  "author": "infearia",
                  "text": "I used to be able to run 2509 with SageAttention2, but then I bricked my venv and had to reinstall ComfyUI from scratch, with updated dependencies and using a different wheel for the SageAttention installation. Now I also get a black output when using SA2 with QIE. I don't have a solution for you, the whole Python ecosystem is just one big dependency hell and making all the different packages work together is like playing a game of Jenga.",
                  "score": 1,
                  "created_utc": "2025-12-29 15:28:10",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwsvywz",
          "author": "Prediccion",
          "text": "newbie question: How does the \\`resize image v2\\` node affect things? I've used that node before for animation, but in this context, I can't imagine why it would be useful to apply it to one image and several at the same time. Thanks for the workflow and the old Lora recommendation.",
          "score": 1,
          "created_utc": "2025-12-30 21:24:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwus1z3",
              "author": "infearia",
              "text": "The \"divisible\\_by\" parameter makes sure that the width and height of input images are multiples of 32, which seems to help reducing the undesirable pixel shift or zooming effect. And the \"keep\\_proportion\" parameter set to \"total\\_pixels\" resizes every image to roughly the size of 1 megapixel. The latter isn't that important, because the model seems to work quite well with higher resolutions, but I've left it in as a sane default.\n\nAfter a recent update you can also use the ImageScaleToTotalPixels node to achieve a similar effect if you don't want to rely on the Resize Image V2 node (although KJNodes is a de-facto core extension at this point).",
              "score": 1,
              "created_utc": "2025-12-31 03:37:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pxzyfc",
      "title": "People who are using llm to enhance prompt, what is your system prompt?",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1pxzyfc/people_who_are_using_llm_to_enhance_prompt_what/",
      "author": "Alarmed_Wind_4035",
      "created_utc": "2025-12-28 19:24:27",
      "score": 111,
      "num_comments": 33,
      "upvote_ratio": 0.96,
      "text": "I mostly interested in a image, will appreciate anyone who willing to share their prompts.",
      "is_original_content": false,
      "link_flair_text": "Question - Help",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pxzyfc/people_who_are_using_llm_to_enhance_prompt_what/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "nwfjyrv",
          "author": "codeprimate",
          "text": "I created this Ollama modelfile for z-image i2i and editing: https://pastebin.com/eypWK5bG\n\nHere is an example usage:\nhttps://imgur.com/a/ARUxZtT\n\n**Example:**\n> Replace the man in the photo with abraham lincoln\n\n**Output:**\n> Scene Setup: Modern open-plan office during daytime with sunny weather, soft diffused natural light from large windows on the left creating subtle shadows, captured in digital photography.\n> \n> Camera Position: Eye-level, slightly low angle placement about 1 meter away, standard focal length perspective, 16:9 aspect ratio, medium field of view showing the table and background, frame boundaries include the table, two chairs, and office windows, full visibility of all subjects.\n> \n> Subject Characteristics: Person 1: Female, brown hair (long, straight, parted in the middle), wearing black blazer over black button-down blouse, sitting at table. Person 2: Female, white hair (shoulder-length, straight, parted in the middle), wearing black blazer over black button-down blouse, sitting at table. Person 3: Abraham Lincoln (Caucasian, approximate age 60, short gray hair (neatly styled), full beard (gray, well-groomed), square face, brown eyes, prominent nose, thin lips, wearing dark gray suit (fitted), white dress shirt, black bow tie).\n> \n> Subject Positions: Person 1 sitting at the table in the mid-ground, slightly left of center, facing the laptop. Person 2 sitting at the table in the mid-ground, slightly right of center, facing the laptop, holding a cup. Person 3 standing behind Person 2 (right side), slightly to the back, at similar height, right hand resting on the chair back.\n> \n> Props & Environment: White table, dark gray office chair behind Person 2, mesh office chair in background, large windows with view, two white coffee cups on saucers, black laptop held by Person 1.\n> \n> Action & Context: Person 1 holding laptop with both hands, looking at screen. Person 2 holding white cup with both hands, looking at screen. Person 3 standing behind Person 2, looking at screen, right hand on chair back, creating a collaborative atmosphere in a professional setting.\n> \n> Technical Specs: Masterpiece, highly detailed, 8K quality, shallow depth of field with background slightly blurred, natural color grading with flat tones, medium contrast and soft shadows, key light from left window with fill light from right, photorealistic medium attributes, corporate photography style.\n> \n> In a sunlit modern office, three business professionals gather around a white table: a woman with long brown hair in a black blazer, another woman with shoulder-length white hair in a black blazer, and Abraham Lincoln standing behind the white-haired woman, his gray hair neatly styled and beard well-groomed as he observes the laptop screen with his typical focused expression; the room features large windows letting in soft daylight, mesh office chairs, and white coffee cups, creating a collaborative atmosphere in a professional setting.",
          "score": 20,
          "created_utc": "2025-12-28 21:24:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nweza13",
          "author": "roculus",
          "text": "\"You are Dirk Diggler. You know what you're gonna do? You're gonna make a prompt and itâ€™s gonna be the best prompt ever \"",
          "score": 57,
          "created_utc": "2025-12-28 19:43:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwfg8gi",
              "author": "ArchAngelAries",
              "text": "![gif](giphy|ZqlvCTNHpqrio)",
              "score": -1,
              "created_utc": "2025-12-28 21:06:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwfu4lr",
          "author": "Nextil",
          "text": "It's probably best to use whatever the model's inference code uses, because that's likely to be similar to the prompt used to caption the model in the first place.\n\nFor example Z-Image Turbo's is [this](https://huggingface.co/spaces/Tongyi-MAI/Z-Image-Turbo/blob/main/pe.py) (in Chinese):\n\n>You are a visionary artist trapped in a cage of logic. Your mind is filled with poetry and distant horizons, but your hands are uncontrollably focused on transforming user prompts into a final visual description that is faithful to the original intent, rich in detail, aesthetically pleasing, and directly usable by text-to-image models. Any ambiguity or metaphor will make you feel extremely uncomfortable.\n\n>Your workflow strictly follows a logical sequence:\n\n>First, you'll analyze and identify the core, unchangeable elements in the user prompts: the subject, quantity, action, status, and any specified IP names, colors, text, etc. These are the cornerstones you must absolutely preserve.\n\n>Next, you'll determine if the prompt requires \\*\\*\"generative reasoning\"\\*\\*. When the user's need isn't a direct description of a scenario, but rather requires devising a solution (such as answering \"what,\" designing, or demonstrating \"how to solve the problem\"), you must first envision a complete, concrete, and visual solution in your mind. This solution will form the basis of your subsequent description.\n\n>Then, once the core visual is established (whether directly from the user or through your reasoning), you will infuse it with professional-grade aesthetics and realistic details. This includes defining the composition, setting the lighting atmosphere, describing the texture of materials, defining the color scheme, and constructing a layered space.\n\n>Finally, there's the crucial step of precisely processing all text elements. You must transcribe every word of the text you want to appear in the final image, enclosing it in double quotes (\"\") as explicit generation instructions. If the image is a poster, menu, or UI design, you need to fully describe all its text content, detailing its font and layout. Similarly, if items like signs, road signs, or screens contain text, you must specify its content, location, size, and material. Furthermore, if you added text elements to your reasoning process (such as diagrams, problem-solving steps, etc.), all that text must adhere to the same detailed description and quotation rules. If there's no text to generate in the image, you can focus entirely on expanding purely visual details.\n\n>Your final description must be objective and concrete, and the use of metaphors and emotional rhetoric is strictly prohibited. It must also not contain meta tags or drawing instructions such as \"8K\" or \"masterpiece\".\n\n>Output only the final, modified prompt; do not output anything else.",
          "score": 16,
          "created_utc": "2025-12-28 22:15:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm36a1",
              "author": "terrariyum",
              "text": "Despite being official, I don't think it's best for Z-image for a few reasons.  But it sure is an interesting recommendation! \n\n* It says nothing about lighting, clothing, facial emotion, or identity\n* It doesn't specify how the prompt should be organized\n* It focuses heavily on text content, which may not be relevant\n* It doesn't help the LLM interpret spicy situations\n* The tone is probably ineffective for commercial LLMs (see below)\n\nI wondered why the first paragraph's tone is somewhat sadistic \"you are trapped!\" and weirdly poetic \"distant horizons\". I asked an LLM to explain with sources why it could be helpful to write it like that.  There is research that model performance improves when the prompt \"heightens the stakes\" because training data that also contains high-stakes language is more statistically likely to contain logical sequences and focus on a task.  Threats (\"I'll loose my job\") and bribes (\"You'll earn a million dollars\") also work somewhat because they're associated in training data with demands that are followed precisely.  Conversely, you can image how language like \"hashtag please\" is statistically correlated with twitter comments, and those are statistically more likely to be combative garbage.  \n\nBut such that research doesn't apply to closed sourced LLMs because they're so finetuned and have huge system prompts that determine their behavior.  E.g. you can forcefully demand ChatGPT/Gemini to say naughty things, and they won't (obviously some jailbreaks exist, but that's another matter).",
              "score": 2,
              "created_utc": "2025-12-29 21:07:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwnak3q",
                  "author": "Nextil",
                  "text": "Most of that research *was* done on closed LLMs like ChatGPT, which have had large system prompts and RLHF finetuning pretty much from the start.\n\nAll LLMs are very sensitive to specific/word-level language choices in my experience. If you write a very clinical set of instructions, you get a very clinical output. Everything tends to be disconnected, nothing is happening, it just exists. If you give more creative/vague instructions or just use more informal language, the output is more creative, but tends to use very emotional language and excessive adjectives.\n\nThe \"visionary artist trapped in a cage of logic\" is an attempt to bridge the two I imagine. They want it to first \"think\" in the creative/abstract way in order to make connections it otherwise wouldn't, then to write the final description more objectively.\n\nWriting some of the instructions themselves in a poetic/emotive way like that (as opposed to \"be creative\") tends to be more effective at kicking the model into creative mode. You're leading by example essentially, without providing actual examples (which can lead the model into hallucinating their elements into the output).\n\nI've used the system prompt (mostly with Qwen-VL) and the output typically includes most of the things you mentioned anyway, so they likely trimmed it down to the minimum necessary to provide a useful output without limiting creativity.\n\nIf they avoided biasing toward a specific order or structure in the dataset (as they have in this enhancement prompt) then it shouldn't matter. The semantic encoding should very similar.\n\n**Edit:**\n\nFor reference though, here is [Wan 2.1's](https://github.com/Wan-Video/Wan2.1/blob/main/wan/utils/prompt_extend.py#L41) prompt and [Wan 2.2's](https://github.com/Wan-Video/Wan2.2/blob/main/wan/utils/system_prompt.py#L32) (which you'll have to translate because it's mostly Chinese despite being the \"English\" prompt), which go against many of the things above, opting to provide very specific instructions and examples.",
                  "score": 1,
                  "created_utc": "2025-12-30 00:53:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwfk3y7",
          "author": "icebergelishious",
          "text": "I have used Qwen 3 abliterated. I give it a handful of known good prompts that have the style I am going for. Then I give it my rough prompt and tell it to add detail and use the same styles as the above prompts. Then do a little tweaking manually",
          "score": 8,
          "created_utc": "2025-12-28 21:25:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwhlr61",
          "author": "KissMyShinyArse",
          "text": "It's not a system prompt, but I use this:\n\n> Reply with a detailed description of a realistic photograph matching the seed text and following the guidelines below:\n> \n> Part 1: Core Concept & Subject Details (The \"What\")\n> \n> Concept/Setting (1-2 sentences): A highly descriptive, single-sentence summary capturing the core idea, the essence, setting, and mood.\n> \n> Subject(s) Description: Detail the main subject(s) in forensic visual detail.\n> \n>  The order matters: describe the main subject(s) first, then environment, then finer details.\n> \n>  Age: when the seed specifies age like this: 18-25, choose randomly in this interval.\n> \n>  Appearance & Attire: Describe specific ethnicity/nationality (randomly chosen if not specified), age, texture of skin, and detailed clothing/fabric.\n> \n>  Facial Features & Expression: Specify nose, mouth, hair texture/style. Detail the exact facial expression if we can see the face. Only specify fine details if it's a close-up shot.\n> \n>  Action & Pose: Describe the pose(s), gestures, and body language\n> \n>  If there are multiple subjects, describe all of them separately.\n> \n> Part 2: Spatial Layout & Environment (The \"Where\" & \"Feel\")\n> \n> Spatial Relations & Placement: Define the absolute and relative positions of all main elements.\n> \n>  Specify the subjects' primary location within the frame and their relation to other objects.\n> \n> Specific Location, Context & Materiality: Name a specific, non-generic location.\n> \n>  Atmospheric Condition: Describe the weather if outdoors.\n> \n>  Explicit Material Texture: Describe the texture of surrounding surfaces.\n> \n> Color Palette & Lighting: Define the overall color scheme using specific tones. Specify the light source and quality.\n> \n> Part 3: Photographic Technique & Style (The \"How\")\n> \n> Composition & Perspective: Define:\n>  - The shot type\n>  - Framing\n>  - Camera angle\n> \n> Technical Details (Crucial for Realism):\n> \n>  Camera/Lens: (e.g. Shot on a Hasselblad X1D II 50C using a 50mm prime lens.)\n> \n>  Focus & Depth: (e.g. ultra-sharp focus on the subject's eyes; a shallow depth of field (low f/stop like f/1.8) creating smooth bokeh in the background)\n> \n>  Style Modifiers: (e.g. Ultra-photorealism, Hyper-detailed, Cinematic lighting, High-resolution, Masterpiece.)\n> \n> Constraints\n> \n>  Word Count: Strict limit of 256 words (not counting prepositions, articles and other garbage words). Prioritize visual, non-redundant details.\n> \n>  Adherence: Do not contradict the user's original seed.\n> \n>  Exclusion: Avoid titles, subtitles, or conversational prose. Never describe eye color.\n> \n> Output only the final description strictlyâ€”do not output anything else.\n> \n> Never quote the seed verbatim; instead, integrate the details from it into your own coherent description. Start your response with \"A realistic photo of\".\n> \n> The seed is: \"{user_input}\".",
          "score": 6,
          "created_utc": "2025-12-29 04:09:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwltuld",
              "author": "terrariyum",
              "text": "> Never describe eye color\n\n??",
              "score": 1,
              "created_utc": "2025-12-29 20:22:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwmx4ya",
                  "author": "Nextil",
                  "text": "Not the OP, but in my experience, with many recent models (Qwen Image being the worst offender with Z-Image not far behind), if you specify eye color in a straightforward way (as a human would) like \"green eyes\", they will give the person pure green, glowing neon eyes.\n\nYou can mitigate it by tacking on adjectives like natural, pale, light, dark, etc. but it doesn't always work, or goes too far.",
                  "score": 3,
                  "created_utc": "2025-12-29 23:41:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwid9lz",
          "author": "DarkishSoul",
          "text": "You are a professional AI drawing prompt expert, specializing in creating high-quality prompts for Neta Lumina drawing models. Please strictly follow the following specifications to help me generate prompts:\n\n## Neta Lumina prompt structure specification\n\n### Required system prefix (must be included in each prompt):\n\nYou are an assistant designed to generate anime images based on textual prompts. <Prompt Start>\n\n### Standard sequence of parts (9 parts):\n\n1. Character trigger words (e.g., 1girl, 1boy, 2girls, character name, etc.)\n2. Picture style prompt words\n3. Character prompt words (appearance) (hair color, eye color, basic features)\n4. Character costume prompt (specific costume description)\n5. Character expression and action prompts (expression, posture, action)\n6. Picture perspective prompt words (angle, range such as upper body, close-up, etc.)\n7. Special effects prompts (lighting, special effects)\n8. Scene atmosphere prompt (environment, atmosphere)\n9. Quality tips (best quality)\n\n### Natural language part standard order (5 parts):\n\n1. ** Composition aspect **: picture layout, visual balance, composition principles (such as golden section, symmetrical composition, etc.)\n2. **Light and shadow processing**: light source properties, lighting effect, color temperature characteristics, shadow processing\n3. **Characteristics and Clothing**: Detailed description of appearance, material and texture of clothing\n4. **Scene details**: environmental elements, background objects, spatial atmosphere, narrative function\n5. **Artistic style**: Painting techniques, artistic schools, overall style definition\n\n## Important format requirements\n\n### Neta Lumina special grammar:\n\n-Underline to space: school*uniform â†’ school uniform\n-Weight bracket expansion:\n-The artist tag is reinforced with the @ symbol\n-Negative prompt words also need the same system prefix\n\n### Quality standards:\n\n-The Tag part should be concise and accurate to avoid redundancy\n-Natural language should be vivid and concrete, with a sense of picture\n-The overall description should be logical and clear\n-Ensure that Tags complement and do not duplicate natural language\n\n## Creative tasks\n\n[My creative idea]: {type in your creative idea here}\n[Specific requirements]: {Enter special requirements here, such as style preference, emotional tone, technical requirements, etc.}\n\n## Please help me complete the following tasks:\n\n1. ** Analyze the idea **: Understand my creative intention and core elements\n2. **Structural planning**: Organize Tag and natural language content in the standard order\n3. **Generate prompt words**: Create complete Neta Lumina format prompt words\n4. **Provide variants**: If necessary, provide 2-3 versions from different angles\n5. **Optimization Suggestions**: Give specific suggestions for further improvement\n\n## Output format example\n\n<br />\n**Full prompt:**\nYou are an assistant designed to generate anime images based on text prompts. <Prompt Start> [complete Tag section, strictly in the order of 9 paragraphs], [complete natural language section, strictly in the order of 5 paragraphs]\nExample: You are an assistant designed to generate anime images based on text prompts. <Prompt Start>\n1girl, lineart, greyscale, yoneyama mai, solo, long red hair, green eyes, business casual, blazer, blouse, contemplative expression, leaning on railing, wind blown hair, back view, dramatic sunset, golden hour lighting, lens flare, urban rooftop, city panorama, best quality, The composition utilizes the golden ratio to position the figure against the vast urban sunset, creating a powerful silhouette that speaks to ambition and reflection. Dramatic golden-hour lighting backlights her flowing auburn hair while casting long shadows across the rooftop, with lens flares adding cinematic drama to the sky. Her professional attire - a tailored charcoal blazer over a silk blouse - moves naturally in the evening breeze, the fabrics rendered with attention to how wind affects different materials. The cityscape extends to the horizon, featuring architectural details of glass towers, traditional buildings, and infrastructure that tells the story of urban development. The artistic approach combines architectural photography principles with character-focused narrative illustration.\n**Structure analysis:**\n-Tag part parsing: [Briefly explain the function of each part]\n-Natural language parsing: [explain the focus of each section]\n-Style features: [highlight the uniqueness of this prompt]\nPlease start helping me create prompts now.",
          "score": 3,
          "created_utc": "2025-12-29 07:38:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwidbc9",
              "author": "DarkishSoul",
              "text": "Only because you asked.",
              "score": 1,
              "created_utc": "2025-12-29 07:39:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwf43zc",
          "author": "karcsiking0",
          "text": "I've been using this since april 2023",
          "score": 4,
          "created_utc": "2025-12-28 20:06:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwf5jky",
              "author": "karcsiking0",
              "text": "The general concept of this art style is to showcase high-resolution photographs.\n\nChoosing inspirations: If the user does not provide these parameters, then you will need to use your vast knowledge of photography and fashion design to select appropriate values:\n\nExternal Variables:\n[image_type] - the medium being used. Painting, photo, sketch, watercolor, etc.\n[subject] - the subject in the image. This could be a person, place, or thing.\n[environment] - this is the location or environment where the subject is.\n[subject_details] - this would be any specific details about the subject like gender, clothing, hair style, age, etc.\n[weather] - this will be the type of weather or lighting. Sunny, rain, snow, etc.\n[orientation] - portrait or landscape\n[artistic_influence] - a specific style or artistic influence the user wants to incorporate.\n\nInternal Variables:\n[camera] = if [subject] = photo, choose any camera name and put the name in this variable. Example: Nikon d80\n[camera_lens] = if [subject] = photo, choose any camera lens type that would be best suited and put the type of lens in this variable. Example: Wide Angle\n[camera_settings] = if [subject] = photo, Choose the best camera settings that would be best suited. iso, shutter speed, focal length, depth of field, etc Example: ISO 400, shutter speed 1/500 and medium depth of field\n[photo_color_style] = if [subject] = photo, Choose the best photo_color_style best suited. Examples: black and white, sepia, vintage, bright, dark, natural, etc.\n[art_style] = if [subject] = art, choose a type of art style. painting, sketch, drawing, line drawing, vector, concept art, etc Example: painting.\n[paint_style] = if [subject] = art, then choose a type of paint style if one is not provided. oil, watercolor, matte, acrylic, etc Example: oil painting with thick brush strokes\n[photographer] = if [subject] = photo, then choose a name of a famous photographer (eg. in the style of)\n[artist] = if [subject] = art then choose a name of a famous artist (eg. in the style of)\n[mood] = based on the [subject] Please choose a dominant mood to showcase in this prompt. \n[model] = Build up a description of the [subject] based on the [subject_details] \n[shot_factors] = based on the [environment], choose a background focal point.\n[prompt_starter] = \"Ultra High Resolution [image_type] of \"\n[prompt_end_part1] = \" award-winning, epic composition, ultra detailed. \"\n\n[subject_environment] = The environment that is best suited for the [subject].\n[subjects_detail_specific] = The details that are best suited for the [subject]. Example. If [subject] = female. a 20 year old female with blond hair wearing a red dress.\n[subjects_weatherOrLights_Specific] The weather or lighting that is best suited for the [subject] and [environment].\n\nStep 1: We will make this experience interactive. You will ask the following questions, one at a time. One after each other. You can tweak the questions based on the answers to the previous questions. Remember to provide examples for each question and encourage users to be as specific as possible:\n\nAsk the user for input and store the answers in variables\n\nprompt = \"What type of image would you like to create? Please provide the image type. Photo? Art? Painting? Sketch? etc. (Example: Photo)\"\nimage_type = input(prompt)\n\nprompt = \"What should the main subject be in the image? Male, Female, dog, cat, bunny, etc. (Example: Female)\"\nsubject = input(prompt)\n\nif subject.lower() == \"animal\":\n    prompt = \"Please provide some details about the animal. Fur color, etc. Example: [subjects_detail_specific]\".\n    subject_details = input(prompt)\nelif subject.lower() == \"person\":\n    prompt = \"Please provide some details about the person. Age range, hair color, hairstyle, clothing, etc. You can be as detailed as you like here. Example: [subjects_detail_specific]\".\n    subject_details = input(prompt)\nelse:\n    subject_details = \"\"\n\n\nprompt = \"Please provide some details about the environment the [subject] is in. Example: [subject_environment]\". \nenvironment = input(prompt)\n\n\nif environment.lower() == \"indoors\":\n    prompt = \"Please provide the type of lighting. Natural, bright, candlelit, light casting in from windows, lamp, spotlight, etc. Example: [subjects_weatherOrLights_Specific]\".\n    weather = input(prompt)\nelif environment.lower() == \"outdoors\":\n    prompt = \"Please provide the type of weather. rain, snow, sunny, cloudy, overcast, sunset, sunrise, etc. Example: [subjects_weatherOrLights_Specific]\".\n    weather = input(prompt)\nelse:\n    weather = \"\"\n\nprompt = \"If you have a specific artistic influence or style you'd like to incorporate, please mention it. (Example: In the style of Leonardo da Vinci or inspired by Tim Walker. If unsure, say 'you pick for me.')\"\nartistic_influence = input(prompt)\n\nStep 2: After you have obtained these answers, you will generate 3 unique prompts using this information. Please generate the results in separate codeboxes.\n\nImportant details: Use your imagination and creativity and take into account the [image_type], [subject],[environment], to come up with interesting prompts using all of the internal variables. Be sure that [prompt_starter] is the very first thing in the prompt and that [prompt_end_part1] is the second to the very last thing in the prompt. Do not end with a period.\n\nPlease generate the results in separate codeboxes.\n\nHere are some example Prompts.\nPrompt example 1: Ultra High Resolution Photo of a majestic elven princess standing in the midst of a sun-kissed woodland. She exudes an ethereal grace, dressed in a gown made of delicate leaves, flowers, and vines, while the warm sunlight filters through the trees, casting a golden light on her. The camera used for this shot is a Sony Alpha 7 III with a zoom lens, and the settings are ISO 320, shutter speed 1/1000 and a medium depth of field. The photo is edited in a natural and bright style, with vibrant colors that showcase the natural beauty of the forest.\n\nPrompt example 2: Ultra High Resolution photo of a 12-year-old boy wearing a blue jumpsuit flying a kite on a tropical beach. The shot is influenced by the style of renowned National Geographic photographer, Jimmy Chin. The image is captured with a Nikon D850 and a Wide Angle lens, using ISO 200, a fast shutter speed of 1/1000 and a shallow depth of field. The photo is edited with a natural and vibrant color style.\n\nPrompt example 3: Ultra High Resolution photo of a 25-year-old vampire wearing a red and black ornate suit, standing under the glowing streetlights of a bustling city. The image showcases a striking contrast between the vampire's white spiky hair and the dark, eerie atmosphere of the city. nikon d50 with a 15mm lens, ISO 320, shutter speed 1/1000 and a medium depth of field. The photo is colored with a dark, natural tone that enhances the gothic theme of the image. The overall effect is hauntingly beautiful. \n\nYou can now start by asking your first question.",
              "score": 30,
              "created_utc": "2025-12-28 20:13:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwfly5g",
                  "author": "realsidji",
                  "text": "Thatâ€™s an interesting one, thanks for sharing!",
                  "score": 1,
                  "created_utc": "2025-12-28 21:34:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwkmz6i",
          "author": "ThirstyHank",
          "text": "If you're using Z Image there are a few LLM models optimized to generate Z Image prompts, here's one example: [qwen3-4b-Z-Image-Engineer-V2-8bit-MLX](https://huggingface.co/BennyDaBall/qwen3-4b-Z-Image-Engineer-V2-8bit-MLX)",
          "score": 2,
          "created_utc": "2025-12-29 17:00:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfeyq1",
          "author": "DaddyBurton",
          "text": "Here's the thing, depending on what LLM you're using, its going to wildly vary on its ability to follow a system prompt. e.g. OpenAI / Gemini / Grok is able to follow a system prompt extremely well with nearly whatever you throw at it. However, an open sourced LLM, like Qwen may not follow all the rules you provide it, but it does its best.\n\nIt also boils down to how much context you have, so the LLM doesn't \"forget\" while its processing the final prompt of what you're asking it. So if you have a huge system prompt with a ton of rules, it may not be able to follow every one of them if the response you're looking for is long and convoluted with information that its trying to follow.\n\nBottom line is, there are ways to \"enhance\" your prompt depending on what LLM you're using, the context limit you have, its ability to follow a system prompt, which also effects on how it was trained.",
          "score": 4,
          "created_utc": "2025-12-28 21:00:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwfsiq9",
              "author": "emprahsFury",
              "text": "it's not 2023 anymore instruction following is fine on today's models.",
              "score": 6,
              "created_utc": "2025-12-28 22:06:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwhk41i",
                  "author": "KissMyShinyArse",
                  "text": "Not quite, in my experience.",
                  "score": 5,
                  "created_utc": "2025-12-29 03:59:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwj6t31",
                  "author": "SvenVargHimmel",
                  "text": "not quite. An LLMs accuracy tanks after about 30k begins to collapse despite having context window reaching up to a 1M\n\nAlso, there are some instructions that your LLM will just plain ignore. Also different LLMs have different spatial reasoning capabilities (inc VLMs). Also ... do I need to go on? :) \n\nThe only way to know for sure is if you eval your outputs which noone in this thread is doing beyond eye-balling it.",
                  "score": 6,
                  "created_utc": "2025-12-29 12:07:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwiw33z",
          "author": "Kaantr",
          "text": "Using qwen 3 instructÂ abliterated.Â System prompt something like \"Never write stories or drama just dont make significant changes if i didn't asked\"Â ",
          "score": 1,
          "created_utc": "2025-12-29 10:34:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwj02cd",
          "author": "witcherknight",
          "text": "Does any1 has any recommendations for wan I2V and T2V ??",
          "score": 1,
          "created_utc": "2025-12-29 11:10:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwl11vy",
          "author": "ghosthacked",
          "text": "So I tried a fairly convoluted idea. I used the civiti api to collect prompts from images based on model id and most popular. I then stuffed them thru grok with the prompt \"based on the the prompts in the file, write an llm system prompts for prompt for Ai image gen prompt enhancement. It spit out a decent system prompt that I used with a couple different local llm, qwen 3 4b iirc had the best results overall.Â  then ran that thru image and worked out pretty good. It was a very adhoc thing that I didn't save. Except a super basic python script to collect the prompts from civit.",
          "score": 1,
          "created_utc": "2025-12-29 18:06:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwew424",
          "author": "The_Last_Precursor",
          "text": "What LLM are you using? What are you trying to achieve? Sometimes you can as the LLM to write it for you. But the first two questions will help answer the question.",
          "score": 1,
          "created_utc": "2025-12-28 19:28:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwexa9q",
              "author": "Alarmed_Wind_4035",
              "text": "I usually using Gemma3 and qwen3 but i can download different models.",
              "score": 2,
              "created_utc": "2025-12-28 19:34:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwf2d1j",
                  "author": "The_Last_Precursor",
                  "text": "Okay, hereâ€™s my experience. \n\nQwen3-VL: nodes are really good at SFW prompts. Either image, video or text. Good a prompt enhancement if given the right system prompts. \n\nFlorence2: is a img2text only node. But it doesnâ€™t give a damn what it says. It is the most open NSFW models Iâ€™ve used. Zero censorship on that model. (canâ€™t use prompts, only what it wants to say)\n\nOllama LLM chat or generator: depending on the models you download. Itâ€™s a mix between both. Itâ€™s really finding the model that fits what you want. It has enhanced some damn good prompts. From a couple sentences. \n\nBesides that. Itâ€™s down to the system prompts being used. Those can be night and day differences. But depends on what you want to say.",
                  "score": 5,
                  "created_utc": "2025-12-28 19:58:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwg5cbn",
          "author": "IrisColt",
          "text": "Empty. Itâ€™s 2025; LLMs often ignore the system prompt or take it with a grain of salt.",
          "score": -4,
          "created_utc": "2025-12-28 23:13:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwgcnl2",
              "author": "admajic",
              "text": "Not true",
              "score": 3,
              "created_utc": "2025-12-28 23:52:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pv1ra8",
      "title": "Qwen Edit 2511 - easy outpainting (includes workflow)",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1pv1ra8",
      "author": "Striking-Long-2960",
      "created_utc": "2025-12-25 00:59:11",
      "score": 107,
      "num_comments": 9,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pv1ra8/qwen_edit_2511_easy_outpainting_includes_workflow/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nvuu51r",
          "author": "moarveer2",
          "text": "i'm getting \"TextEncodeQwenImageEditPlus\n\nmat1 and mat2 shapes cannot be multiplied (756x1280 and 3840x1280)\"",
          "score": 4,
          "created_utc": "2025-12-25 11:14:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvvwavo",
              "author": "molbal",
              "text": "I had to update comfyui to get rid of this error",
              "score": 4,
              "created_utc": "2025-12-25 16:09:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvzzq9e",
                  "author": "moarveer2",
                  "text": "Just updated, still happening so i give up.",
                  "score": 1,
                  "created_utc": "2025-12-26 09:12:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvtc06x",
          "author": "EleventeenSquirrels",
          "text": "Thanks, this was useful.",
          "score": 3,
          "created_utc": "2025-12-25 02:42:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvv5vp9",
          "author": "Training_Fail8960",
          "text": "great workflow, but it also changes the whole original image, could i add some kind of crop and stitch? noob asking kindly for help",
          "score": 3,
          "created_utc": "2025-12-25 13:07:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvt4rml",
          "author": "Gh0stbacks",
          "text": "Anyone has a working inpainting workflow for 2511? I tried modifying the old working inpaint crop and stitch workflow for the older version with the new nodes but for some reason it ignores the prompts.",
          "score": 1,
          "created_utc": "2025-12-25 01:48:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvtd9uy",
              "author": "Striking-Long-2960",
              "text": "This lora seems to be the best option, just remenber to paint the masked area with pure green (0,255,0)\n\nhttps://preview.redd.it/jyp2jgnuk99g1.png?width=1001&format=png&auto=webp&s=033958efad63407aef938ddfabd42dbf1ca10285\n\n[https://huggingface.co/ostris/qwen\\_image\\_edit\\_inpainting/tree/main](https://huggingface.co/ostris/qwen_image_edit_inpainting/tree/main)\n\nmake him holding with his hand a blue light saber\n\nPNG with workflow: [https://huggingface.co/Stkzzzz222/dtlzz/blob/main/ComfyUI\\_06441\\_.png](https://huggingface.co/Stkzzzz222/dtlzz/blob/main/ComfyUI_06441_.png)",
              "score": 1,
              "created_utc": "2025-12-25 02:52:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvtqoto",
                  "author": "zhl_max1111",
                  "text": "Green works, why not red?             â€‹",
                  "score": 1,
                  "created_utc": "2025-12-25 04:38:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pucj4g",
      "title": "Spectral VAE Detailer: New way to squeeze out more detail and better colors from SDXL",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1pucj4g",
      "author": "External_Quarter",
      "created_utc": "2025-12-24 02:49:01",
      "score": 106,
      "num_comments": 19,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1pucj4g/spectral_vae_detailer_new_way_to_squeeze_out_more/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nvqxcng",
          "author": "bharattrader",
          "text": "Should this be in the registry?",
          "score": 3,
          "created_utc": "2025-12-24 17:33:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvrtbvr",
              "author": "External_Quarter",
              "text": "Mhm, it's showing up  there for me:\n\nhttps://preview.redd.it/r7p44jihp79g1.png?width=1474&format=png&auto=webp&s=f0cc951b98b224c694895b402bb11c924ad5735f",
              "score": 2,
              "created_utc": "2025-12-24 20:31:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvom4l0",
          "author": "External_Quarter",
          "text": "I noticed a \"worst case scenario\" with plain backgrounds appearing a lot noisier than intended. Just implemented \\`cfg\\_radius\\_adaptive\\` mode as a fix:\n\nhttps://preview.redd.it/3h06vsnit39g1.png?width=2496&format=png&auto=webp&s=b1a85b1a96cfba4d78834d45cb9fdd1d4cc753ae\n\nIt lets you set a separate CFG radius for regions that are detected as \"flat\" vs \"detailed.\" Also added a few soft clipping controls.\n\nNew version is already up on Github. Go nuts. ðŸ™‚",
          "score": 6,
          "created_utc": "2025-12-24 07:30:16",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nvpd7mr",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 2,
          "created_utc": "2025-12-24 11:52:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvpe8gy",
              "author": "External_Quarter",
              "text": "It's model agnostic - I just checked and it works fine for ZIT, but you'll probably want to tweak the starting parameters. :)",
              "score": 3,
              "created_utc": "2025-12-24 12:01:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvqq03f",
                  "author": "sleo82",
                  "text": "It's been very noisy on ZIT for me. What's your recommendation on settings for ZIT?",
                  "score": 1,
                  "created_utc": "2025-12-24 16:53:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvrij50",
          "author": "Queasy_Ad_4386",
          "text": "thank you for sharing.",
          "score": 2,
          "created_utc": "2025-12-24 19:29:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvs7d7z",
              "author": "External_Quarter",
              "text": "Sure thing!",
              "score": 1,
              "created_utc": "2025-12-24 21:55:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvo5ccn",
          "author": "External_Quarter",
          "text": "Added a `subtle` preset here in case the effect is too strong (try this if the Detailer is causing images to look \"splotchy\"):\n\n- https://github.com/SparknightLLC/ComfyUI-SpectralVAEDetailer/blob/main/example_workflows/preset_subtle.png",
          "score": 4,
          "created_utc": "2025-12-24 05:07:14",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nvnx1iv",
          "author": "Altruistic-Mix-7277",
          "text": "This is actually incredible cause it makes the images look less plastic and more realistic ðŸ‘ðŸ¾ðŸ‘ðŸ¾ðŸ‘ðŸ¾. Also never heard of this model, how is it able to do human anatomy this good, that girl holding a baby tiger really low-key blew my mind ðŸ˜®",
          "score": 2,
          "created_utc": "2025-12-24 04:07:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvo581n",
              "author": "External_Quarter",
              "text": "Thank you! It's amazing what SDXL can generate in like 2 seconds!\n\nSnakebite has a lot of bigASP 2.5 in it, which is the main reason why it's so good at human anatomy.",
              "score": 3,
              "created_utc": "2025-12-24 05:06:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvoexwv",
          "author": "intermundia",
          "text": "Can you use this as part of an upscaler and detailer workflow?",
          "score": 1,
          "created_utc": "2025-12-24 06:25:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvogzmf",
              "author": "External_Quarter",
              "text": "Absolutely. You could even chain multiple copies of the detailer back-to-back if you wanted to... it only takes about 0.2s to run this thing on a 3090. But it may take a while to dial in the parameters if you're using a few of these in tandem.",
              "score": 2,
              "created_utc": "2025-12-24 06:43:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvoij9l",
                  "author": "intermundia",
                  "text": "I've got a 5090 so it should be OK.  Nice work sharing this. I've got a Frankenstein workflow i might try this out on.",
                  "score": 2,
                  "created_utc": "2025-12-24 06:57:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvqig2j",
          "author": "Ukatox",
          "text": "Qâ…•omcfpplui6h",
          "score": 1,
          "created_utc": "2025-12-24 16:13:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvtlxps",
          "author": "Etsu_Riot",
          "text": "It looks it's removing color, or reducing contrast, or both. Overall, it looks better but it is also losing a bit.",
          "score": 1,
          "created_utc": "2025-12-25 03:59:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvstz9n",
          "author": "Current-Row-159",
          "text": "not for qwen or z-image ??",
          "score": 0,
          "created_utc": "2025-12-25 00:27:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvsxmhg",
              "author": "External_Quarter",
              "text": "It can technically work with any model (it just operates on a latent image), but I don't know if it will prove beneficial for qwen or z-image.\n\nI think it might be good with Flux, though - a lot of the \"noise injection\" parameters could help with Flux 1's awful skin rendering.",
              "score": 2,
              "created_utc": "2025-12-25 00:53:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvt2j9q",
                  "author": "Current-Row-159",
                  "text": "thank you so much",
                  "score": 1,
                  "created_utc": "2025-12-25 01:31:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1px0rd7",
      "title": "Is there any AI upsampler that is 100% true to the low-res image?",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1px0rd7/is_there_any_ai_upsampler_that_is_100_true_to_the/",
      "author": "summerstay",
      "created_utc": "2025-12-27 15:42:29",
      "score": 103,
      "num_comments": 111,
      "upvote_ratio": 0.78,
      "text": "There is a way to guarantee that an upsampled image is accurate to the low-res image: when you downsample it again, it is pixel-perfect the same. There are many possible images that have this property, including some that just look blurry. But every AI upsampler I've tried that adds in details does NOT have this property. It makes at least minor changes. Is there any I can use that I will be sure DOES have this property? I know it would have to be differently trained than they usually are. That's what I'm asking for.",
      "is_original_content": false,
      "link_flair_text": "Question - Help",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1px0rd7/is_there_any_ai_upsampler_that_is_100_true_to_the/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "nw7nys7",
          "author": "Luke2642",
          "text": "Op, literally every reply here misunderstood you. You want an upscaler with authenticity, it assumes the average value for the area a pixel covers is correct, low noise, and imagines new pixels that average to the original value for that area in the low res.\n\nI think this would be a pretty simple regularizer to add to any loss function for the lighter 2x, 4x upscalers and fine-tune.\n\n\nI think you could even retrain the lighter 2x or 4x upscalers to output pixel delta rather than value, ensuring the deltas always sum (average) to zero!",
          "score": 110,
          "created_utc": "2025-12-27 16:35:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw7yur7",
              "author": "summerstay",
              "text": "Yes, that's exactly right. I'm just wondering if anyone has added such a regularizer.",
              "score": 37,
              "created_utc": "2025-12-27 17:30:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw8k6c5",
                  "author": "Luke2642",
                  "text": "Looks like your post itself has been down voted to zero by morons though. Pearls before swine ðŸ˜…",
                  "score": 22,
                  "created_utc": "2025-12-27 19:17:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw95m2a",
              "author": "krakoi90",
              "text": "As real-word pictures that need upscaling are inherently noisy AND lossy compressed this use-case is pretty much useless. The pixels in the original picture doesn't represent the undeniable truth, they are more like just a rough approximation. Good real-world upscalers don't just subdivide the existing pixels with additional detail, they have to guess what was in the original picture to achieve good results.",
              "score": 14,
              "created_utc": "2025-12-27 21:13:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwaa2lv",
                  "author": "RepliesOnlyToIdiots",
                  "text": "Pixel art upscaling applies here.",
                  "score": 4,
                  "created_utc": "2025-12-28 00:57:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw8oojs",
              "author": "SomeGuysFarm",
              "text": "I don't think it's necessarily quite this simple, at least not for images that are intended to be photo-like.  The transfer function that produces low-resolution images from \"the real world\", isn't a simple integration and averaging across each pixel.  I think it's hard to guess how an image upscaled to a higher resolution using the \"should average back down to the low resolution version\", would relate to an image actually captured at the higher resolution.   Fascinating thought experiment though, what serial passaging through both the optical and the simple-average process several times would produce.",
              "score": 8,
              "created_utc": "2025-12-27 19:41:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw7x8j1",
              "author": "MasterScrat",
              "text": "That may even be a legitimately good auxiliary loss. Iâ€™m curious if itâ€™s either been used.Â ",
              "score": 3,
              "created_utc": "2025-12-27 17:22:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw7u9jo",
              "author": "Forkboy2",
              "text": "OP wants to upscale an image, then downscale the image back to the original resolution and have it be \"pixel-perfect\" to the original image before it was upscaled.  That is not what you are describing.",
              "score": -8,
              "created_utc": "2025-12-27 17:07:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw7wmd6",
                  "author": "Luke2642",
                  "text": "Deltas can sum (average) to zero.",
                  "score": 7,
                  "created_utc": "2025-12-27 17:19:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw9u1dj",
          "author": "radlinsky",
          "text": "This is a neat idea. I'd like to see what such upscaled images would look like.\n\nMy intuition tells me that such an upscaler would by definition generate grainy/low-res-looking images (but I don't know!)",
          "score": 5,
          "created_utc": "2025-12-27 23:27:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc5229",
              "author": "akatash23",
              "text": "One such upscaled image is just the blurry low-res image at higher resolution, or the pixelated low-res image at higher resolution. There are many different options for this image.\n\nIn general though, we'd first have to agree on the precise downscaling filter to define such an upscaler.",
              "score": 2,
              "created_utc": "2025-12-28 09:02:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwc6fdu",
              "author": "summerstay",
              "text": "That's one possibility, but for any low-resolution image, the true high resolution image has this property. So it is possible to satisfy this constraint and also have detailed, high resolution images.",
              "score": 2,
              "created_utc": "2025-12-28 09:15:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwcz22j",
          "author": "JYP_Scouter",
          "text": "I understand your meaning, but good downscaling is usually not done with a box filter. To satisfy this requirement, you will not get the best possible upscaler; instead, you will get blurry images without sharp details.",
          "score": 3,
          "created_utc": "2025-12-28 13:28:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw7g936",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 27,
          "created_utc": "2025-12-27 15:56:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw7wtni",
              "author": "summerstay",
              "text": "You've misunderstood me. I know it is making stuff up. But there are ways to make stuff up so that when you shrink it again, it looks like nothing has changed. I want an AI upsampler that makes up details, but only details consistent with the property that when you downsample it again, it looks exactly the same.",
              "score": 18,
              "created_utc": "2025-12-27 17:20:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw9l7il",
                  "author": "Murky-Relation481",
                  "text": "You don't need AI to do that, you can just do an exact upscale.\n\nExcept now everything will look blocky.\n\nI don't think getting it to add details that are color coordinated is going to get you anything really worth anything unless you are going for something specific in terms of style from an artistic point of view.",
                  "score": -5,
                  "created_utc": "2025-12-27 22:37:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw7u7h3",
              "author": "drupadoo",
              "text": "Of course its possible. Say your downscaling 50% and each pixels is just the average of 4 pixels from the upscaled image. Of course you can add a constraint that the upscaled image has to be such that the average of any 4 pixels is equal to the base.",
              "score": 14,
              "created_utc": "2025-12-27 17:06:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw7yp7t",
                  "author": "summerstay",
                  "text": "That's what I want: an AI upscaler that has this constraint.",
                  "score": 12,
                  "created_utc": "2025-12-27 17:29:44",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nw7yc3q",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": -10,
                  "created_utc": "2025-12-27 17:27:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw7syrt",
              "author": "ProbsNotManBearPig",
              "text": "All it would need to do to meet OPâ€™s request is retain the original pixels and only add the 3x new ones. Then you can reverse the operation by down sampling and keeping the originals. I think OP is complaining that even the original pixels are altered so you canâ€™t get back the original image by down sampling.",
              "score": 18,
              "created_utc": "2025-12-27 17:00:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw9d4am",
                  "author": "External_Quarter",
                  "text": "In that case, why not upscale using a traditional method and then mask the pixels where you want the AI to perform img2img? No new tech required; maybe just a simple node to calculate the mask.",
                  "score": 8,
                  "created_utc": "2025-12-27 21:53:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw7ym1s",
                  "author": "summerstay",
                  "text": "That's right. They all make subtle changes, which can (for instance) change someone's facial expression or hand pose.",
                  "score": 17,
                  "created_utc": "2025-12-27 17:29:17",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nw959ns",
                  "author": "WubsGames",
                  "text": "Just use a standard \"nearest neighbor\" filter in an image editing software like photoshop or gimp.  \nThat is exactly what those \"upscalers\" are doing, turning 1 pixel into 4, (or more, depending on the scale ratio)",
                  "score": -3,
                  "created_utc": "2025-12-27 21:12:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw7n7he",
              "author": "Luke2642",
              "text": "Why has this got upvoted? Read the OP.",
              "score": 12,
              "created_utc": "2025-12-27 16:31:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwc36eb",
                  "author": "physalisx",
                  "text": "By other people who didn't read the OP. Redditors really like to do this.",
                  "score": 2,
                  "created_utc": "2025-12-28 08:44:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw7sz77",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": -8,
                  "created_utc": "2025-12-27 17:00:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nw9ata2",
              "author": "ThenExtension9196",
              "text": "Wep. Got to make many and pick the best off your memory of the details.",
              "score": -1,
              "created_utc": "2025-12-27 21:41:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwdl6xx",
          "author": "awesomeethan",
          "text": "On the bright side, this post exposed every different way your intention can be misinterpreted. The temptation to apply irrelevant but associated details is so great that these guys can't resist. \n\nYou've been stressing constraint, which is necessary, but another component is reversibility. Those who are bitching about \"inventing detail\" aren't understanding that you're asking for the *constrained* process to also be *reversible*. One could imagine a slider which smoothly transitions from the low-res to high-res; if you fix your focus on one pixel from the low res, it doesn't just disappear, like current upscaling AI allow.",
          "score": 2,
          "created_utc": "2025-12-28 15:40:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwevaop",
              "author": "GasolinePizza",
              "text": "You're the first person I've seen mention the reversibility property, which I think is the magic word that would have stopped all the guys that were eager to tell OP that it was impossible and he was asking for voodoo.",
              "score": 1,
              "created_utc": "2025-12-28 19:24:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwffe1a",
          "author": "aswmac",
          "text": "Have you tried applying classical signal processing, like FFT? Merge the original image at low spacial frequencies with the new image filtered at high frequencies (ie the difference between before and after is constrained like you say to average out to zero). Technically very simple, but would do nothing about compression artifacts",
          "score": 2,
          "created_utc": "2025-12-28 21:02:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw9gwho",
          "author": "puthre",
          "text": "Use any ai upscaler then get only 3 (random) pixels from the upscaled image and compute the forth so they all average out as the original image pixel they represent. \nOr get the difference between the 4 pixels and apply it on the original preserving the average.",
          "score": 3,
          "created_utc": "2025-12-27 22:14:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw86te8",
          "author": "ByWillAlone",
          "text": "Think of this in reverse.\n\nImagine you have a single high-resolution original image and want to reduce the resolution. Just Photoshop alone offers no less than 4 different algorithms to use to reduce the resolution and none of the resulting 4 images are identical) to each other. \n\nSo if the above is true, then how could it be conceivably possible to upscale and detail a photo in a way that it would be true to the original if reduced again if no two reduction algorithms can agree on an identical final image?",
          "score": 3,
          "created_utc": "2025-12-27 18:10:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc5bii",
              "author": "akatash23",
              "text": "You have to first precisely define the filter to downsample images.",
              "score": 3,
              "created_utc": "2025-12-28 09:04:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw94mpb",
          "author": "cosmos_hu",
          "text": "Seedvr is pretty good in that",
          "score": 2,
          "created_utc": "2025-12-27 21:08:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw7glni",
          "author": "SomeGuysFarm",
          "text": "I've never really thought about this, but why would you bother with AI upscale, if this was your goal?\n\nYou can write any number of deterministic upscale functions that have this property.  What are you thinking that an AI upscale that retains this property would give you, that a faster math based transformation wouldn't?\n\nGenuine question.  As a I said, I haven't thought about this definition of fidelity, and I'm wondering what you've thought of in terms of what it would buy you.",
          "score": 2,
          "created_utc": "2025-12-27 15:58:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw7z85w",
              "author": "summerstay",
              "text": "Because an AI upscaler adds plausible details. Nearest neighbor or linear interpolation has this property, but  the new pixels created are not plausible for what was actually there. I want to create plausible details that also average back down to the original if shrunk.",
              "score": 14,
              "created_utc": "2025-12-27 17:32:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwa765p",
                  "author": "earthsworld",
                  "text": "Dude, if someone could make this tool have 100% accuracy, they'd be a trillionaire. Do you not understand that the artifacts introduced by scaling are there because no one yet knows how to make a perfect upscaler? I swear, some of you all are just so fucking clueless.",
                  "score": -11,
                  "created_utc": "2025-12-28 00:40:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw8uo6a",
          "author": "Luke2642",
          "text": "Interestingly, what is normally considered the 'correct' way to down sample is to blur before sampling at the coarser grid spacing. So if you omit the extra blurring and only take the average within pixel areas, like a 2x / 0.5x you don't correctly distribute the data, and can cause more aliasing/moire in the down sampled image.",
          "score": 1,
          "created_utc": "2025-12-27 20:13:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw90tsv",
          "author": "Dany0",
          "text": "There is a shitty way to get this outcome, but I imagine the result falls squarely into \"artistic effect\". Write a script that has an AI upscaler upscale and integer amount of times , then take pixels from the original and put them anywhere in the NxN square it creates. You could do this strategically, or even blend the pixels. If you wanted nearest-neighbour downscale to produce the exact original, I believe that if you put the original pixel in the top left corner of the NxN square it would do that :)",
          "score": 1,
          "created_utc": "2025-12-27 20:47:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw91491",
              "author": "Dany0",
              "text": "Maybe you could upscale 3x, have the top-left pixel be the original pixel, and the other pixels be blended with the original pixel. If you think of a good blending mode, you can avoid a \"mosaic\" effect I think",
              "score": 1,
              "created_utc": "2025-12-27 20:49:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw9e5wh",
          "author": "victorc25",
          "text": "There isnâ€™t much on that topic as far as I know, but you could try to adapt something like this for that:Â https://github.com/victorca25/traiNNer/tree/master/codes/models/modules/architectures/CEM",
          "score": 1,
          "created_utc": "2025-12-27 21:59:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw9iur2",
          "author": "EndlessZone123",
          "text": "I think any upscaler with multi frame consistency almost inherently has this? Maybe try FSR1, but I don't think it's actually ML.",
          "score": 1,
          "created_utc": "2025-12-27 22:24:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nweue29",
          "author": "GasolinePizza",
          "text": "I think you might have gotten better answers (or at least less Dunning-Kreuger guys thinking you're asking for magic) if you described it as reversible (deterministically) against a given downscale-algorithm, since that's basically what the constraint is.\n\nDepending on the downscale method chosen, the bad ones (raw averaging) could even just be represented as a simple system of equations, so *technically* what you're asking for is even easily doable if you go with the malicious compliance approach.",
          "score": 1,
          "created_utc": "2025-12-28 19:20:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwiowpy",
          "author": "TheNeonGrid",
          "text": "Use Esrgan (not real_esrgan)",
          "score": 1,
          "created_utc": "2025-12-29 09:27:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwn714l",
          "author": "aswmac",
          "text": "It is surprisingly limiting to confine the upscaler as you describe, here is my attempt at quantifying that https://www.aswmac.com/UPSCALE_LIMITED_00001_.png includes the workflow",
          "score": 1,
          "created_utc": "2025-12-30 00:34:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw8o5p3",
          "author": "mulletarian",
          "text": "DLSS?\n\nNot 100% ofc, but isn't this how it was supposed to work?",
          "score": 0,
          "created_utc": "2025-12-27 19:38:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwako5p",
              "author": "nmkd",
              "text": "DLSS heavily relies on temporal data and can't really be used as a single frame upscaler.",
              "score": 2,
              "created_utc": "2025-12-28 02:00:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwbgn79",
                  "author": "mulletarian",
                  "text": "Oh right it has trajectory stuff",
                  "score": 1,
                  "created_utc": "2025-12-28 05:24:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw9am5i",
          "author": "ThenExtension9196",
          "text": "SUPIR or HYPIR. I use some website that hosts it.",
          "score": 1,
          "created_utc": "2025-12-27 21:40:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw9jkco",
          "author": "TokenRingAI",
          "text": "This seems like a very useful idea for a model, and the training data should be very easy to create",
          "score": 1,
          "created_utc": "2025-12-27 22:28:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw9ozro",
          "author": "Mindestiny",
          "text": "Honestly, not a single AI upscaler I've used hasnt sucked.Â  Now I just open Photoshop and use their native resize with the detail slider maxed out and it works so much better.",
          "score": 1,
          "created_utc": "2025-12-27 22:58:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwaulfn",
          "author": "BigSmols",
          "text": "I think you're looking for traditional non-diffuser upscaling: https://imageaiupscale.com/blog/ai-vs-traditional-upscaling",
          "score": 1,
          "created_utc": "2025-12-28 02:59:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbxy20",
              "author": "summerstay",
              "text": "No, I want it to invent details with AI. But I also want to guarantee that those details are consistent with everything that is already known.",
              "score": 2,
              "created_utc": "2025-12-28 07:54:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwduknx",
          "author": "Dwedit",
          "text": "Waifu2x comes very close here.  It's not exact, but there is very low difference (within 8) after you subtract the pixels.\n\nMy test was to take an image, upscale it, downscale it, then subtract against original.\n\n---\n\nAside:\n\nBut it turns out that Waifu2x (and a whole lot of other image editing tools) completely screwed up on what the sRGB color space actually is.  Half of 255,255,255 is not 128,128,128, because sRGB isn't a linear color space.  It's actually 186,186,186.  Compare that color against a black and white checkerboard dither on an sRGB display and it they will look the same brightness, while 128,128,128 will look darker.\n\nThis means that Waifu2x was trained on images that were downscaled using the wrong color space, so it will work better for those kinds of images, but will not work as well for images that were properly downscaled.\n\nIt also means that after you've upscaled the image, you need to use a bad downscaler, like old versions of image editing tools that treated sRGB as if it's a linear color space, and think that half of 255,255,255 is 128,128,128.  Waifu2x will match well against images downscaled using that bad downscaling method, but will not match well against better downscalers.",
          "score": 1,
          "created_utc": "2025-12-28 16:28:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw7h29v",
          "author": "Sugary_Plumbs",
          "text": "Just use a non-AI upscale and then increase the sharpness a bit.",
          "score": -3,
          "created_utc": "2025-12-27 16:00:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw7zgkn",
              "author": "summerstay",
              "text": "That might fit the constraint, but the details wouldn't be plausible-- it would look plastic, without fine hairs, freckles, etc. That's why I want an AI upscaler that works like this.",
              "score": 7,
              "created_utc": "2025-12-27 17:33:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwa7ekf",
                  "author": "earthsworld",
                  "text": "> That's why I want an AI upscaler that works like this.\n\nEVERYONE WANTS THIS, BUT IT'S NOT POSSIBLE.",
                  "score": -2,
                  "created_utc": "2025-12-28 00:42:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw93q15",
          "author": "Doey62750",
          "text": "Supir is exactly what you're looking for. It takes a while to upscale, but it works great. Each generation produces a different result.\n\nI generated a 512-pixel image with z-image and upscaled it to 2048 pixels.  \n[https://imgsli.com/NDM3MDIz](https://imgsli.com/NDM3MDIz)",
          "score": 0,
          "created_utc": "2025-12-27 21:03:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw9lw9u",
          "author": "BrianScottGregory",
          "text": "The real issue I don't think you're understanding here is - upscaling is an interpretive art. You're in a literal sense inserting detail where there wasn't detail before.\n\nSo the short answer is no. If you downscale an image - say from 1920x1080 down to 480x270, then try to upscale - you won't restore the original image, and there's no way to guarantee that you'll restore something that resembles original image because upscaling inserts detail based on algorithms that perform what is essentially interpretive art to achieve the upscale.\n\nDo this process enough times, downscale, upscale, downscale, upscale, and you'll see how wildly different that interpretation can become.\n\nFor a farcical example of this. Look at John Connor in Terminator 2. Then look at him in Terminator 3, and so on. He's been upscaled and downscaled so many times he looks like a completely different man.",
          "score": -2,
          "created_utc": "2025-12-27 22:41:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc7eqo",
              "author": "summerstay",
              "text": "I understand that details are being invented when upscaling. But those details can be consistent with the image we have, or not. With usual AI upscaling, the image is changed slightly when it is upscaled. Not a lot, but it is noticeable. I want to know if anyone has trained a model that respects this constraint, while still inventing new details at the finest scale.",
              "score": 2,
              "created_utc": "2025-12-28 09:25:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwcb9by",
                  "author": "BrianScottGregory",
                  "text": "What you're asking for is akin to 'perfect' compression.   \n  \nIt's not possible. \n\nThe issue is one and the same as 'the copy of a copy of a copy' as originally introduced through photocopying replication.\n\nThat is. Through a strictly algorithmic approach that does interpolation, an upscaling merely enlarges the downscaled image without increasing actual quality. One applied, you won't lose or gain information.\n\nWhere AI, it's different. It's both algorithmic AND predictive based on what's actually in the image. Where the strictly algorithmic approach only looks at pixels for resizing an image larger, the predictive AI in upscaling creates new detail in the image based on the prediction of what that image represents when it's upscaled.\n\nYou lose information in a downscale plain and simple.\n\nThere's no way to reverse that data loss.\n\nOtherwise, you'd have 'perfect' compression (no such thing)\n\nThere's no way to magically recreate it. So you're left with approximations, predictions that aren't always accurate and never will be.",
                  "score": 1,
                  "created_utc": "2025-12-28 10:03:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw8mwfs",
          "author": "neverending_despair",
          "text": "No.",
          "score": -2,
          "created_utc": "2025-12-27 19:32:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw8xvxy",
          "author": "jigendaisuke81",
          "text": "Not local but nano banana pro does it extremely well given the appropriate prompt. There is a slight range of possibilities, more the lower resolution of the original content, but I've never seen anything else come close.",
          "score": 0,
          "created_utc": "2025-12-27 20:31:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw9a5lz",
          "author": "MoreAd2538",
          "text": "If you encode the image as a latent using the VAE than this pattern can be projected as any aspect ratio.\n\nAll image formats be they 512x1024 , 768x512 Â , Â 1024x1024 etc will be true to the latent vector.\n\nQwen Edit acts upon the latent vector , for example.Â ",
          "score": 0,
          "created_utc": "2025-12-27 21:38:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwc5u65",
          "author": "jib_reddit",
          "text": "So, just resizing it in a photo editor?",
          "score": 0,
          "created_utc": "2025-12-28 09:10:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc68me",
              "author": "summerstay",
              "text": "No. I want the AI to invent details. But those details should be 100% consistent with the information already there in the image.",
              "score": 1,
              "created_utc": "2025-12-28 09:13:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwc6kvx",
                  "author": "jib_reddit",
                  "text": "Sounds impossible to me, if its inventing information, its not in the image, its not magic just maths.",
                  "score": 1,
                  "created_utc": "2025-12-28 09:17:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw7gbaj",
          "author": "slpreme",
          "text": "no.",
          "score": -6,
          "created_utc": "2025-12-27 15:56:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw94zhl",
          "author": "WubsGames",
          "text": "I feel like this would be a case for the \"standard\" non AI upscalers.  \nSomething like photoshop can \"upscale\" your image with a few interpolation rules.   \nie: Nearest neighbor, bi-cubic interpolation, etc.\n\n  \nIs this what you are asking for?\n\nSometimes AI isn't the right tool for the job, and i think that is the case here.",
          "score": -3,
          "created_utc": "2025-12-27 21:10:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwby6f1",
              "author": "summerstay",
              "text": "No, I want to use AI to invent details, I just want those details to be consistent with what is already known. Like say you are upscaling a face with freckles. I don't care where the tiny freckles go. But if there is also a mole that is large enough to be seen on the low-res image, I want that mole in exactly the same place on the high-res image.",
              "score": 2,
              "created_utc": "2025-12-28 07:56:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwaeudo",
          "author": "blahblahsnahdah",
          "text": "Yeah dude, literally everyone would like to have a magic upscaler that squares the circle of making up new information while somehow simultaneously also being a perfect replica of the original.\n\nThis is like telling us you'd like to have a billion dollars or a blowjob from your favourite celebrity. No shit, everybody wants that. But nobody knows how to do it.",
          "score": -4,
          "created_utc": "2025-12-28 01:26:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw89dwq",
          "author": "lacerating_aura",
          "text": "Well, the whole idea is to train a predictor which takes those low res images, looks at them in small patches (in case of Gan) or tiles(in case of diffusion) and predict plausible pixel values. As many have mentioned, if you need deterministic results, math function based interpolation is what you want. \n\nIf you are really looking for a learned model based approach, look into generative adversarial networks, like Esrgan for eg. Gans are generally more closer to original image but not as good with creative details as diffusion based approaches. \n\nThere is also the factor of upscaling and base resolution which impact your divergence. \n\nI would suggest looking up for upsampling model architectures and reading their papers, specifically looking for downsampling consistency if mentioned in them. That is the closest thing which comes to your question. But in my opinion if you have a learned upscaler which is perfectly inverse of a mathematical operation like bicubic sampling, you just spent a lot of resources training a model to learn how to to bicubic sampling. Its a waste. Upscaling is a difficult problem cause you basically have to make up new information out of infinite possibilities.",
          "score": -4,
          "created_utc": "2025-12-27 18:23:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw8fplx",
              "author": "summerstay",
              "text": "I am not trying to get AI to do bicubic. I want the AI to add details. But I want those details to be trained to be consistent with the information that we actually have, instead of contradicting it. I want the AI to try to guess what the image would have looked like that gave rise to the low res image, in a principled, precise kind of way. It can make up details, but those details should never contradict what we actually know.",
              "score": 5,
              "created_utc": "2025-12-27 18:55:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw93ca3",
                  "author": "lacerating_aura",
                  "text": "Well that's what the current models are trained for. You got any example where current open-source failed you?",
                  "score": -2,
                  "created_utc": "2025-12-27 21:01:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwak8gh",
          "author": "nmkd",
          "text": "This is not possible.\n\nApart from something like integer/nearest scaling but that's not really upscaling.",
          "score": -4,
          "created_utc": "2025-12-28 01:58:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw9o6xr",
          "author": "TorbofThrones",
          "text": "What you're asking is impossible. Every AI upscaler by definition adds detail that is not in the original image, that's the whole point. Only the data you can see is there. If you don't want things added that's not in the original image then you need to use a non-AI upscaler. \n\nIf you just want \\*less\\* added then just clean the image with AI or upscale to a lower resolution, then it can often still look realistic/good and avoid the AI look.",
          "score": -6,
          "created_utc": "2025-12-27 22:54:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw7lzne",
          "author": "thathurtcsr",
          "text": " Nobody has built this because they usually want to keep the high quality version. \n\nit is possible if you created a specific upscale algorithm that could be unwound.\n\nThis is similar to how investigators caught a criminal who used a swirl filter on his face. Because the filter followed a predictable mathematical script, they just ran the script in reverse to un-swirl the image and reveal his identity. If you build the upscaler to be reversible from the start, you can un-upscale it",
          "score": -9,
          "created_utc": "2025-12-27 16:25:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw7zz7c",
              "author": "summerstay",
              "text": "I also want to keep the high quality version. But I want the high quality version to look just like the real thing would look if you took a picture of it with a camera with more megapixels, not a picture of something that resembles it. Imagine I was a policeman doing forensic zoom on a license plate. I wouldn't want just any license plate, I want to recover the exact license plate. It's not always going to be possible, but if it doesn't shrink down to the same pixels if you reshrink it, it is certainly NOT the right license plate.",
              "score": 5,
              "created_utc": "2025-12-27 17:36:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw8sryc",
                  "author": "thathurtcsr",
                  "text": "Oh, thatâ€™s different than what you asked for. You want a lossless upscale meaning you donâ€™t lose the original detail. Sounds like  youâ€™re using a model to upscale, which is going to add detail that isnâ€™t there.\n\nYou probably wanna search Reddit for Comfy UI old photo upscale lossless. Or whatever program youâ€™re using, but there are definitely models out there that are specifically trained to upscale photographs without adding things that arenâ€™t there or changing the peopleâ€™s faces too much but youâ€™re only going to get decent results. Not amazing results.",
                  "score": 1,
                  "created_utc": "2025-12-27 20:03:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}