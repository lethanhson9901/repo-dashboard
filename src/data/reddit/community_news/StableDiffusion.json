{
  "metadata": {
    "last_updated": "2026-02-24 17:19:14",
    "time_filter": "week",
    "subreddit": "StableDiffusion",
    "total_items": 20,
    "total_comments": 455,
    "file_size_bytes": 509840
  },
  "items": [
    {
      "id": "1r7r9rw",
      "title": "Fully automatic generating and texturing of 3D models in Blender - Coming soon to StableGen thanks to TRELLIS.2",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/zkhaoptb36kg1",
      "author": "sakalond",
      "created_utc": "2026-02-18 02:54:03",
      "score": 626,
      "num_comments": 146,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1r7r9rw/fully_automatic_generating_and_texturing_of_3d/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5zi8kq",
          "author": "sakalond",
          "text": "The texturing itself is projection based, using good old SDXL. But Qwen-Image-Edit and FLUX.1 are also available. \n\nFLUX.2 Klein support will also be added soon.",
          "score": 57,
          "created_utc": "2026-02-18 02:55:41",
          "is_submitter": true,
          "replies": [
            {
              "id": "o5zjdui",
              "author": "sakalond",
              "text": "I already showcased that in some older posts, hence I'm not going into much detail.\n\nI didn't properly showcase the fully automatic camera placement. The manual adding of cameras was one of StableGen's most manually intensive parts. That is already fixed in the last release along with other new features. Thanks to that, I can chain multiple processes to achieve this \"one click\" solution.",
              "score": 14,
              "created_utc": "2026-02-18 03:02:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o63lk1h",
                  "author": "Mid-Pri6170",
                  "text": "im not a coder by any means (well i just made a firefox extension using Gemini to scrape images) but i had an idea of 3d block outs, with 'post it note' attached to them which guide prompts and then the viewport is rendered with a stable diffusion thing. so i could be in a theme'd room but not have the setting/context reimagine if i tilt my head.... is that possible?",
                  "score": 1,
                  "created_utc": "2026-02-18 18:33:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5zmvsl",
              "author": "sakalond",
              "text": "The TRELLIS.2 native textures will be of course also available. They aren't as detailed, but have full PBR (and don't suffer from occlusions). So you may try and choose what suits your use case. (I will also try to bring PBR to my projection based system in the future)",
              "score": 7,
              "created_utc": "2026-02-18 03:23:04",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5zpniz",
              "author": "Lower-Cap7381",
              "text": "Really amazing seeing how far we have come with stablegen üî•",
              "score": 4,
              "created_utc": "2026-02-18 03:39:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o60fsyv",
              "author": "RazsterOxzine",
              "text": "Nice. I bet FLUX.2 Klein will be amazing. So far I love what FLUX.2 Klein can do in Photoshop, but now Blender?! \nI use Blender for my designing over Photoshop daily, been using it since 2.4 to 5.0, and what you've done here will speed up my work 100x. I have so many projects I can already visual this being used for that I had to pause for a bit do to complexities... And then I can take those mockups and animate them with WAN or SeedDance.",
              "score": 5,
              "created_utc": "2026-02-18 06:51:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63yw73",
                  "author": "Arcival_2",
                  "text": "I tried Flux Klein 9b a bit with some Blender-generated maps (depth, albedo, normal, etc.), but even mixing them together doesn't give a great effect. Flux Klein has a serious problem with pixel align... Maybe future control nets will be able to fix it.",
                  "score": 2,
                  "created_utc": "2026-02-18 19:33:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5zsd7n",
              "author": "Quick_Knowledge7413",
              "text": "This looks really interesting, I can‚Äôt wait to give it a try.",
              "score": 2,
              "created_utc": "2026-02-18 03:56:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5zkpzl",
          "author": "sakalond",
          "text": "Here's the GitHub link. You can try the plugin as-is or wait for the release of this (kinda big) update:  \n[https://github.com/sakalond/StableGen](https://github.com/sakalond/StableGen)",
          "score": 23,
          "created_utc": "2026-02-18 03:10:15",
          "is_submitter": true,
          "replies": [
            {
              "id": "o63lpq0",
              "author": "Mid-Pri6170",
              "text": "so its a blender plug in or comfyui one?",
              "score": 1,
              "created_utc": "2026-02-18 18:34:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63upvj",
                  "author": "sakalond",
                  "text": "Blender plugin. Uses ComfyUI as its backend for the AI models.",
                  "score": 3,
                  "created_utc": "2026-02-18 19:14:36",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5zohpe",
          "author": "Impressive_Alfalfa_6",
          "text": "This looks like voodoo. Amazing work! How do you auto fix the seams?",
          "score": 16,
          "created_utc": "2026-02-18 03:32:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5zozxl",
              "author": "sakalond",
              "text": "It's a whole set of different mechanisms. I wrote my bachelor thesis about it - you can find it in the StableGen GitHub if you're interested in the details (it's in English).\n\nTL;DR: Some combination of: Inpainting, differential diffusion, IPAdapter & normal angle based blending within shaders.",
              "score": 27,
              "created_utc": "2026-02-18 03:35:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o60zngz",
                  "author": "bloke_pusher",
                  "text": "Will it have an option to inpaint? Similar to how Stable projectorz does it? That would be amazing.",
                  "score": 5,
                  "created_utc": "2026-02-18 09:54:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o60e8oo",
          "author": "Random_User68",
          "text": "990k trianglesüíî",
          "score": 11,
          "created_utc": "2026-02-18 06:38:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60vhoy",
              "author": "sakalond",
              "text": "You can set it to whatever. But yes, it is an issue because the topology will always be sort of uniform (voxel remeshing).",
              "score": 8,
              "created_utc": "2026-02-18 09:15:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o61itle",
                  "author": "cripplehank",
                  "text": "would it be possible to reduce the polygon mesh before texturing?",
                  "score": 1,
                  "created_utc": "2026-02-18 12:28:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o60hkuh",
              "author": "JahJedi",
              "text": "I am sure its not a problem to desimate the model after and get less triangles if needed.",
              "score": 5,
              "created_utc": "2026-02-18 07:06:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63mymk",
                  "author": "Mid-Pri6170",
                  "text": "AI-bro reply: 'its nothing a little AI cant fix!'\n\n\nArtstation virgins: 'noooo!'",
                  "score": 0,
                  "created_utc": "2026-02-18 18:40:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o60sgdp",
          "author": "teomore",
          "text": "Nice, too bad it can't be used commercially.",
          "score": 5,
          "created_utc": "2026-02-18 08:47:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60vlf7",
              "author": "sakalond",
              "text": "License allows it (unless you use FLUX)",
              "score": 3,
              "created_utc": "2026-02-18 09:16:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o60wuqw",
                  "author": "teomore",
                  "text": "No, it doesn't. It uses some nvidia libs which strictly forbids commercial use.\n\nAnd RMBG, which is also not free for commercial use.",
                  "score": 3,
                  "created_utc": "2026-02-18 09:28:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5znf91",
          "author": "AlexGSquadron",
          "text": "This is a dream come true for game development",
          "score": 9,
          "created_utc": "2026-02-18 03:26:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5znivs",
              "author": "sakalond",
              "text": "It still has some caveats. But I hope it will get there eventually.",
              "score": 11,
              "created_utc": "2026-02-18 03:26:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5znmr7",
                  "author": "AlexGSquadron",
                  "text": "Yeah it will save so much time and effort",
                  "score": 5,
                  "created_utc": "2026-02-18 03:27:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o609nnd",
              "author": "anon999387",
              "text": "The topology for these 3d generators is usually very dense and very ugly. Not suitable for game development.",
              "score": 10,
              "created_utc": "2026-02-18 05:59:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o60iml0",
                  "author": "Spare_Possession_194",
                  "text": "Is it really that hard to fix it?",
                  "score": 2,
                  "created_utc": "2026-02-18 07:16:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6b5qco",
                  "author": "Particular_Stuff8167",
                  "text": "Experimenting with AI re-topology. Its still really the early days, but looks promising. Hope eventually it gets to a point where it does near professional work. But using it for pure static models that dont need rigs and specialized topology in places, it can already be used for that. Will still need human clean up afterwards. But certainly beats a human needing to do the re-topology work from scratch",
                  "score": 1,
                  "created_utc": "2026-02-19 21:07:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o60u19e",
                  "author": "AlexGSquadron",
                  "text": "6 months is all it will take for AI to get better at this.",
                  "score": 1,
                  "created_utc": "2026-02-18 09:01:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o60j1nq",
              "author": "witcherknight",
              "text": "No i have tried it and mesh is unusable. Especially for char. You have to retopo it which takes a lot of time",
              "score": 9,
              "created_utc": "2026-02-18 07:20:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63c6ve",
                  "author": "General_Session_4450",
                  "text": "You'll need to retopo a hand made character model in any real production pipeline as well, and most game models are static meshes that don't need good topology for animations.",
                  "score": 2,
                  "created_utc": "2026-02-18 17:53:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o63nrjn",
                  "author": "Mid-Pri6170",
                  "text": "characters its gonna be too long but making quick props concepts for renders its ace.",
                  "score": 2,
                  "created_utc": "2026-02-18 18:43:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o600me4",
              "author": "drallcom3",
              "text": "I tried similar techniques and it only looks good from far away. Once you get close it looks like a badly painted Warhammer mini.",
              "score": 5,
              "created_utc": "2026-02-18 04:52:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63nv64",
                  "author": "Mid-Pri6170",
                  "text": "....well duh!¬†",
                  "score": 1,
                  "created_utc": "2026-02-18 18:44:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o60xvtg",
              "author": "biscotte-nutella",
              "text": "For placeholder stuff ...",
              "score": 2,
              "created_utc": "2026-02-18 09:38:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o61od7i",
              "author": "kowdermesiter",
              "text": "Also, don't show this to gamers :)",
              "score": 1,
              "created_utc": "2026-02-18 13:04:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o61ot30",
                  "author": "AlexGSquadron",
                  "text": "Why",
                  "score": 1,
                  "created_utc": "2026-02-18 13:06:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o63nfs3",
              "author": "Mid-Pri6170",
              "text": "its a nightmare for the tossers at Artstation!",
              "score": 1,
              "created_utc": "2026-02-18 18:42:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5zjfit",
          "author": "TheDailySpank",
          "text": "Nice! I've been wanting this type of add-on for a while now.",
          "score": 2,
          "created_utc": "2026-02-18 03:02:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5zjpq6",
              "author": "sakalond",
              "text": "I hope more people will find it useful with this addition. It has been texturing only plugin so far. \n\nHopefully, I will be able to release this in a few days once it's properly polished.",
              "score": 3,
              "created_utc": "2026-02-18 03:04:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5zk29n",
          "author": "sakalond",
          "text": "More examples can be found on my Twitter and I will probably post more there in the comming days. I don't want to spam Reddit with similar posts.",
          "score": 2,
          "created_utc": "2026-02-18 03:06:19",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o5zl3js",
          "author": "No_Clock2390",
          "text": "sweet",
          "score": 2,
          "created_utc": "2026-02-18 03:12:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60tltb",
          "author": "smereces",
          "text": "u/sakalond looks really nice looking further to test it",
          "score": 2,
          "created_utc": "2026-02-18 08:57:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61730h",
          "author": "fistular",
          "text": "Does is have PBR layers?  Looks like the lighting is baked in.  Kinda useless if so.",
          "score": 2,
          "created_utc": "2026-02-18 10:59:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62uizz",
              "author": "sakalond",
              "text": "Yes, it has lighting baked in. You can sort of mitigate it with prompt engineering. Although I am planning to add some delighting and other methods to produce PBR out of the images (it should be possible in theory).",
              "score": 1,
              "created_utc": "2026-02-18 16:33:34",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o63obks",
              "author": "Mid-Pri6170",
              "text": "you could literally prompt it and say 'no shadows, diffused light' you dumbo.",
              "score": 0,
              "created_utc": "2026-02-18 18:46:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o656ugw",
                  "author": "fistular",
                  "text": "Why don't you gargle my taint sweat?",
                  "score": 2,
                  "created_utc": "2026-02-18 23:00:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o61d1vn",
          "author": "VRGoggles",
          "text": "Looks MEGA. Saves so much time.",
          "score": 2,
          "created_utc": "2026-02-18 11:48:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o647ysr",
          "author": "LegacyRemaster",
          "text": "Trellis creates difficult-to-use assets. Have you implemented an efficient retopology system?",
          "score": 2,
          "created_utc": "2026-02-18 20:16:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o64as85",
              "author": "sakalond",
              "text": "No. I know that it's an issue though. I will be looking into that in the future.\nNow it's just a voxel remesh.",
              "score": 1,
              "created_utc": "2026-02-18 20:29:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o64nzbq",
                  "author": "Felipesssku",
                  "text": "Can you decimate and retopo to low poly? \n\nWhy on GitHub it's mentioned as texturing plugin while you said on post it's 3d model creation and texturing plugin?",
                  "score": 1,
                  "created_utc": "2026-02-18 21:30:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o64rx6w",
                  "author": "cosmicnag",
                  "text": "Is there a quick way to do the voxel remesh?",
                  "score": 1,
                  "created_utc": "2026-02-18 21:48:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o66ir2x",
          "author": "lininop",
          "text": "The topology has to be a nightmare on these generations yeah?",
          "score": 2,
          "created_utc": "2026-02-19 03:33:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67olvr",
              "author": "sakalond",
              "text": "Yes that why they get voxel remeshed. Still not ideal though.",
              "score": 1,
              "created_utc": "2026-02-19 09:09:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o68z5fv",
          "author": "imnotabot303",
          "text": "This type of stuff is a cool tech demo but it's not really useful for much. At best you could try and use it as quick and dirty method for some background assets that aren't seen well. \n\nThe problem is the meshes are awful, and the textures are worse and on top of that there's no PBR workflow which means the AI model is baking all light and shadow information into the textures.",
          "score": 2,
          "created_utc": "2026-02-19 14:47:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o696om5",
              "author": "sakalond",
              "text": "Depends on the usecase. But I know it has its limitations. \n\nI will be adding PBR (it should be possible to generate that from the baked in textures).",
              "score": 1,
              "created_utc": "2026-02-19 15:26:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o63kso0",
          "author": "Mid-Pri6170",
          "text": "Artstation hacks be like: 'Waaaa! waaa! im outta a job!'\n\n\n\n\nme: heheheh.",
          "score": 2,
          "created_utc": "2026-02-18 18:30:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60auag",
          "author": "TopTippityTop",
          "text": "Is this using Klein 9b? Sure hope so, as it would be great to use reference images for consistency in results.",
          "score": 1,
          "created_utc": "2026-02-18 06:09:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60vdb8",
              "author": "sakalond",
              "text": "It can use Qwen-Image-Edit, but I will be adding Klein too.",
              "score": 2,
              "created_utc": "2026-02-18 09:14:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o60g5kc",
          "author": "theOliviaRossi",
          "text": "wow!",
          "score": 1,
          "created_utc": "2026-02-18 06:54:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60hqc4",
          "author": "beti88",
          "text": "Diffuse only?",
          "score": 1,
          "created_utc": "2026-02-18 07:08:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60w0bi",
              "author": "sakalond",
              "text": "Yes, so far, I will be working on that too. The native TRELLIS.2 textures have full PBR but are less detailed.",
              "score": 1,
              "created_utc": "2026-02-18 09:20:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o60km9y",
          "author": "mrgonuts",
          "text": "Cool looks intresting",
          "score": 1,
          "created_utc": "2026-02-18 07:34:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61g65e",
          "author": "AcePilot01",
          "text": "Sexy af, now make it make \"real\" 3d VR scene lol.\n\n\nSo it looks like it's sorta doing regular images, but from each angle and then stitching them together.  I do wonder however, how you get the \"dimensions\" ?",
          "score": 1,
          "created_utc": "2026-02-18 12:10:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61glpm",
              "author": "sakalond",
              "text": "Yes, that is what it does in a nutshell. I just export depth / normal map and other contexts from Blender, feed it to a ControlNet (in case of SDXL, it works differently with Qwen Image Edit).",
              "score": 1,
              "created_utc": "2026-02-18 12:13:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o61mhv0",
          "author": "Frequent_BSOD",
          "text": "Something similar is needed for rigging.",
          "score": 1,
          "created_utc": "2026-02-18 12:52:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61nybd",
              "author": "sakalond",
              "text": "I think I saw something like that on Twitter, but don't know much else",
              "score": 1,
              "created_utc": "2026-02-18 13:01:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o62fzop",
          "author": "BigBoiii_Jones",
          "text": "Does this run locally with no paid APIs?",
          "score": 1,
          "created_utc": "2026-02-18 15:27:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62jnkm",
              "author": "sakalond",
              "text": "Yes.",
              "score": 2,
              "created_utc": "2026-02-18 15:44:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o62texs",
          "author": "Eimisseiyou",
          "text": "Damn impressive! ",
          "score": 1,
          "created_utc": "2026-02-18 16:28:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63xwz3",
          "author": "samdutter",
          "text": "Are there any delighters available?",
          "score": 1,
          "created_utc": "2026-02-18 19:29:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63y3fg",
              "author": "sakalond",
              "text": "Not yet but it's top priority now. I will probably work on that once I release this version with the initial TRELLIS.2 support.",
              "score": 2,
              "created_utc": "2026-02-18 19:30:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o64430z",
                  "author": "samdutter",
                  "text": "Looking forward to it!  \n\nOnce Blender 5.1 is out, I'll be giving StableGen a spin!",
                  "score": 1,
                  "created_utc": "2026-02-18 19:57:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o64l1in",
          "author": "Felipesssku",
          "text": "Does it work later on if you want export to game engines like Unity3D?\n\nLooks really neat. No need to cycle between Trellis and Blender",
          "score": 1,
          "created_utc": "2026-02-18 21:17:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o64luxe",
              "author": "sakalond",
              "text": "Yes, but you will need to bake the textures which is an extra step, but it is also provided as a tool within the plugin.",
              "score": 1,
              "created_utc": "2026-02-18 21:20:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o64o8bc",
                  "author": "Felipesssku",
                  "text": "Thanks I asked more questions in other response. This is super stuff, I'm really looking forward.",
                  "score": 1,
                  "created_utc": "2026-02-18 21:31:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o65tc52",
          "author": "newaccount47",
          "text": "Pbr?¬†",
          "score": 1,
          "created_utc": "2026-02-19 01:03:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6l5o76",
          "author": "Justify_87",
          "text": "Scientific question: does it do female bodies?",
          "score": 1,
          "created_utc": "2026-02-21 11:49:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6l5u8q",
              "author": "sakalond",
              "text": "Didn't try anything nsfw, but it can do humans just fine. Sometimes they will have more fingers, weird eyes etc. I'm talking about the 3D model generation, the texturing can do whatever because you can use any SDXL checkpoint.",
              "score": 2,
              "created_utc": "2026-02-21 11:50:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6l9jej",
                  "author": "Justify_87",
                  "text": "Thank you",
                  "score": 1,
                  "created_utc": "2026-02-21 12:22:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o75zs3d",
          "author": "FFKUSES",
          "text": "Niceee",
          "score": 1,
          "created_utc": "2026-02-24 17:00:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60ry4p",
          "author": "InitialFly6460",
          "text": "I'm a super FAN !! contact blender ask them to implement it !!! WE ALL NEED IT !!",
          "score": 1,
          "created_utc": "2026-02-18 08:42:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60vwhp",
              "author": "sakalond",
              "text": "They don't even allow it on their plugin marketplace (don't allow any genAI).",
              "score": 6,
              "created_utc": "2026-02-18 09:19:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o60xiyt",
                  "author": "InitialFly6460",
                  "text": "ok :(",
                  "score": 2,
                  "created_utc": "2026-02-18 09:34:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o63o4xc",
                  "author": "Mid-Pri6170",
                  "text": "what a bunch of losers!\n\n\ni wrote some pro ai stuff on fartstation and i had 900 comments from layout 'game developers' saying I was worse than hitler and my 3d sucked.",
                  "score": 0,
                  "created_utc": "2026-02-18 18:45:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r80whh",
      "title": "Remade Night of the Living Dead scene with LTX-2 A2V",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/ob7xpuazq8kg1",
      "author": "Interesting_Room2820",
      "created_utc": "2026-02-18 11:49:34",
      "score": 447,
      "num_comments": 51,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1r80whh/remade_night_of_the_living_dead_scene_with_ltx2/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o61hdvy",
          "author": "Suspicious_Handle_34",
          "text": "Amazing! RAM and GPU?",
          "score": 11,
          "created_utc": "2026-02-18 12:19:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61jtni",
              "author": "Interesting_Room2820",
              "text": "GPU 4090...",
              "score": 11,
              "created_utc": "2026-02-18 12:35:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o61p0xk",
                  "author": "Suspicious_Handle_34",
                  "text": "Great work! Thanks for sharing",
                  "score": 3,
                  "created_utc": "2026-02-18 13:08:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o61k8jm",
          "author": "Totem_House_30",
          "text": "besides the man aging like 30 years from one shot from to the next looks good üòä  \nlove ow he reaches for the box",
          "score": 15,
          "created_utc": "2026-02-18 12:38:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61ikwl",
          "author": "Substantial_Aid",
          "text": "üëèüèªüëèüèª great job! Thanks for sharing!",
          "score": 5,
          "created_utc": "2026-02-18 12:27:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61khjq",
          "author": "Euphoric_Emotion5397",
          "text": "Ridiculous! How could it be so small and flawless and nice! :D  \nI gave up ... trying to make it work with wan2gp and rtx5080 16gb. :(  \nWan 2.2 works flawlessly for me.\n\nNow ., if you can do Zombieland \"DoubleTap!\" that would be amazing! The intro scene... learning the rules. LOL",
          "score": 4,
          "created_utc": "2026-02-18 12:40:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64f44u",
          "author": "Far_Course2496",
          "text": "Pretty cool, but the characters seem like they resist looking at each other. From the shot into the driver's side window, he's taking so much but barely looks over at her. The next shot from the passenger side, she's giving him side eye, she's not turning her head to look at him",
          "score": 5,
          "created_utc": "2026-02-18 20:50:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62gy65",
          "author": "finnabinnabusta",
          "text": "How long did it take your machine to generate everything?",
          "score": 3,
          "created_utc": "2026-02-18 15:31:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65908e",
          "author": "Silly-Dingo-7086",
          "text": "I just don't know if people who are so critical are keeping their critiques based in reality of the state of the industry or what. \n\nThis is fantastic and yes Hollywood is cooked. Give this 3 years and consistency and the ability to drop scripts in will be feasible. Sure this isn't there yet, but for screwing around. 10/10",
          "score": 3,
          "created_utc": "2026-02-18 23:11:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65vujw",
          "author": "IONaut",
          "text": "This looks great! I intentionally have steered away from Pixar style since I knew that was going to be a popular one. I'm a little jealous you got such an easy scene. 2 speakers, one male and one female, and there dialogue lines are clearly separated from each other. My scene has five characters, three of whom are speakers, with 2 news guys speaking on the TV while the characters speak over them. And some of the scenes are a close up of the TV while the characters are much louder than the person speaking in the cut. I'm going to have to just not trying to reproduce it cut by cut. I've got one cut that has 18 seconds of continuous dialogue.",
          "score": 3,
          "created_utc": "2026-02-19 01:18:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67um30",
          "author": "mission_tiefsee",
          "text": "They are coming for you Barbara!\n\nLove it. Really I do. But to everyone who says Hollywood is cooked. No its not. The expressions are not fitting at all. If you have ever taken acting classes or know some people from this area then you realize the body language and facial expressions are lacking. These characters don't really show any emotions. Look at Barbaras (the female) face. You can sense the dread already in that old black and white images. You can see nothing in the reimagined one. \n\nI see this in a lot of clips. People say hollywood is cooked because we can have blazing effects and trailers. But i havent yet seen really good AI acting.",
          "score": 2,
          "created_utc": "2026-02-19 10:08:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61i207",
          "author": "protector111",
          "text": "oh man you got so lucky with those clips xD   Great job!",
          "score": 2,
          "created_utc": "2026-02-18 12:23:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61jvpb",
              "author": "Interesting_Room2820",
              "text": "Tnks",
              "score": 1,
              "created_utc": "2026-02-18 12:36:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o61qwfu",
          "author": "biscotte-nutella",
          "text": "Was the competition strictly a2v?\n\nIt's a shame the acting is so different with a2v and it's not living up to the movie.\n\nAnd the mentioned character changes , maybe this could have been more refined",
          "score": 2,
          "created_utc": "2026-02-18 13:19:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61snki",
              "author": "protector111",
              "text": "there are only 2 strict rules - **LTX2 is the only video model u use** and **you cant change the sound.** YOu can use any ltx WOrkflow to creatively recreate the movie scenes (eveyone gets firenet peace of th emovie and they will stichi them togerther in 1 long movie)",
              "score": 3,
              "created_utc": "2026-02-18 13:28:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63xvm8",
                  "author": "Xhadmi",
                  "text": "So, you can generate first frame with any other model, isn't? But only use ltx as video model. That was a point i wasn't sure about",
                  "score": 2,
                  "created_utc": "2026-02-18 19:29:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o63wh4e",
          "author": "imnotabot303",
          "text": "This isn't a Pixar animation style, it's human movement with a Pixar aesthetic which gives it an uncanny valley effect.",
          "score": 3,
          "created_utc": "2026-02-18 19:22:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62jwt9",
          "author": "RebelRoundeye",
          "text": "I have never seen the film.  So these two characters are undead?",
          "score": 1,
          "created_utc": "2026-02-18 15:45:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o655e9g",
              "author": "SomeGuysFarm",
              "text": "No, they‚Äôre human.\n\nThe thing no-one is commenting on though, is that the real movie scene between them is visibly uncomfortable - brother and sister disagreeing over visiting a parent‚Äôs grave or some such - and that is beautifully communicated in the nuance of the live actors‚Äô expressions and body language.  It just doesn‚Äôt come through here at all.\n\nJust look at the woman's face in the thumbnail of the live-action clip that's inset in the corner during the first few seconds.  The AI characters' bodies are moving, in a large-scale sense, similarly, but are they experiencing/portraying anything close to the same thing emotionally?",
              "score": 4,
              "created_utc": "2026-02-18 22:52:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o62p584",
          "author": "EpicNoiseFix",
          "text": "LTX2 is great at cute animated stuff! Looks great",
          "score": 1,
          "created_utc": "2026-02-18 16:09:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62tcbu",
          "author": "RandyNaban",
          "text": "This is nice",
          "score": 1,
          "created_utc": "2026-02-18 16:28:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63767a",
          "author": "witcherknight",
          "text": "was controlnet used??",
          "score": 1,
          "created_utc": "2026-02-18 17:30:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64z38i",
          "author": "cosmicr",
          "text": "I'm glad I decided not to enter - this is amazing! I couldn't hope to achieve the same quality.",
          "score": 1,
          "created_utc": "2026-02-18 22:21:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6a5sko",
          "author": "mysticmanESO",
          "text": "If anyone is interested you can download the new workflow that LTX posted for their Night of the Living Dead contest here: https://ltx.io/competition/night-of-the-living-dead   scroll down to the bottom of the page you will see the comfy workflow.\n\nYou can find a Youtube LTX tutorial on using the workflow here: https://www.youtube.com/watch?v=Dbnw9KTYfSYhttps://www.youtube.com/watch?v=Dbnw9KTYfSY\n\nI was able to run the 27GB ltx-2-19b-distilled-fp8 model on my RTX 4070 12GB vram 32GB ram setup. I did have to use that --lowvram and Reserved VRAM (GB) trick to keep from running out of vram.",
          "score": 1,
          "created_utc": "2026-02-19 18:15:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6acms4",
          "author": "James_Reeb",
          "text": "Use comfy and open pose to get same moving character",
          "score": 1,
          "created_utc": "2026-02-19 18:46:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pibua",
          "author": "GenBeautyFan",
          "text": "OMG yes! ..... They are coming to get you Barbara!",
          "score": 1,
          "created_utc": "2026-02-22 02:43:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6r4t09",
          "author": "UnablePressure8482",
          "text": "besides the man aging like 30 years from one shot from to the next looks good üòä\nlove ow he reaches for the box",
          "score": 1,
          "created_utc": "2026-02-22 10:57:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6v4yex",
          "author": "Strong_Respond5455",
          "text": "I‚Äôm sorry, but this heavily looks AI, his head went right into the steering wheel, they almost never blink, and we never see what he grabs (the sound used shuffles things around and we don‚Äôt see what it was). Now, this could just be rough work or just starting out, but the faces change in between shots",
          "score": 1,
          "created_utc": "2026-02-22 23:54:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73u5d9",
          "author": "abriteguy",
          "text": "How old are you yo choose the movie Night of the living Dead?\nA great choice but. \nI'm 78 and saw it some 58 years ago while backpacking through France\nIn Cherbourg. I was 20 and scared and had to walk back to my youth hostel in the Dark!! B\nI've come to believe that there are no older people interested in AI. \nI think Generative AI is the most creative force Ever. \nIf there are any participants interested in my dialogue please get back to me!!\nI have ideas ripe for creative genius!!",
          "score": 1,
          "created_utc": "2026-02-24 08:59:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61mru6",
          "author": "frogsarenottoads",
          "text": "Character consistency is awful",
          "score": -2,
          "created_utc": "2026-02-18 12:54:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62mq59",
              "author": "kowdermesiter",
              "text": "Awful is a strong word here, to me they look 90% the same.",
              "score": 11,
              "created_utc": "2026-02-18 15:58:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63atf3",
                  "author": "frogsarenottoads",
                  "text": "I disagree, in order to have full episodes or movies made we need character consistency not \"90% the same\" this is the final hurdle",
                  "score": 1,
                  "created_utc": "2026-02-18 17:47:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6b8fiy",
              "author": "autistic-brother",
              "text": "Perhaps we can see your work?",
              "score": 1,
              "created_utc": "2026-02-19 21:20:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6bdf2d",
                  "author": "frogsarenottoads",
                  "text": "I'm plagued with the same issues most are between shots :)",
                  "score": 1,
                  "created_utc": "2026-02-19 21:45:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o65ofwl",
          "author": "AcePilot01",
          "text": "I doubt you will have any chance of winning if you are using anything copyright. Just no shot they let that out publicly.  But good. \n\nI would try something else for the contest thought tbh.",
          "score": 0,
          "created_utc": "2026-02-19 00:36:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65up1z",
              "author": "IONaut",
              "text": "What is OP using that is copyrighted?",
              "score": 1,
              "created_utc": "2026-02-19 01:11:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o65vfp9",
                  "author": "AcePilot01",
                  "text": "Um... the fucking audio? lmfao.\n\n\nDo what you want, I don't care, I am just saying, no way in hell an official contest will allow that and in fact:\n\nhttps://cdn.prod.website-files.com/65bb6b901cb133d784d16166/688a17efc27ff993d90cc2df_Beyond%20the%20Prompt%20-%20%20Contest%20Rules%2030%3A07.docx.pdf\n\nBy submitting an Entry, you represent and warrant that your Entry is original to you, that the\nEntry has not been previously published, has not won previous awards and that neither it\nnor its contents infringe upon or violate the rights of any third party, including any\ncopyrights, trademarks, rights of privacy, publicity, or other intellectual property. By\nsubmitting an Entry, you represent and warrant that you consent to the submission and use\nof the Entry in the Contest and to its use as otherwise set forth herein.\n\nBesides, their site shows it ended in August.",
                  "score": 0,
                  "created_utc": "2026-02-19 01:16:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o61kv0a",
          "author": "Flyingcoyote",
          "text": "Hollywood is cooked",
          "score": -6,
          "created_utc": "2026-02-18 12:42:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o64r79z",
              "author": "DystopiaLite",
              "text": "Doubt it. Most of the stuff people make with AI video is unimaginative rip-off ‚Äúwhat if Captian America fought Wukong‚Äù or the same scene from an existing movie with a different character. Or sexy girl fights monster that looks like a game cutscene or horrible Disney CG. It takes talent to make something worth watching. It‚Äôs like buying an expensive camera without being able to write/direct/act.",
              "score": 3,
              "created_utc": "2026-02-18 21:45:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6smy3s",
                  "author": "Flyingcoyote",
                  "text": "[Okay, this is insane : r/aivideo](https://www.reddit.com/r/aivideo/comments/1rbfg9x/okay_this_is_insane/) yeah keep downvoting me, but I am right. ",
                  "score": 1,
                  "created_utc": "2026-02-22 16:28:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o64vpi3",
                  "author": "Flyingcoyote",
                  "text": "Because Hollywood's never made a bad movie?",
                  "score": 0,
                  "created_utc": "2026-02-18 22:05:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r8wdd4",
      "title": "üî• Final Release ‚Äî LTX-2 Easy Prompt + Vision. Two free ComfyUI nodes that write your prompts for you. Fully local, no API, no compromises",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1r8wdd4",
      "author": "WildSpeaker7315",
      "created_utc": "2026-02-19 11:03:36",
      "score": 441,
      "num_comments": 202,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1r8wdd4/final_release_ltx2_easy_prompt_vision_two_free/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o682jaa",
          "author": "PornTG",
          "text": "Just one think i think you have forgot on your I2v workflow (if i'm up to date) this is the purge Vram node after low pass",
          "score": 21,
          "created_utc": "2026-02-19 11:19:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o682ne7",
              "author": "WildSpeaker7315",
              "text": "true. i'll go sort it",
              "score": 17,
              "created_utc": "2026-02-19 11:20:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o682vh4",
                  "author": "WildSpeaker7315",
                  "text": "replaced the files on g-drive. cheers",
                  "score": 25,
                  "created_utc": "2026-02-19 11:22:35",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o68jsml",
              "author": "Birdinhandandbush",
              "text": "Didn't know such a thing existed, I've been manually clearing the cache in ComfyUI manager",
              "score": 4,
              "created_utc": "2026-02-19 13:22:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o68nhld",
          "author": "Inevitable-Start-653",
          "text": "Your t2v node was fantastic!  Don't get discouraged if some people report it not working for them.\n\nWhat I've learned is that more people will use your repo and love it than the number of people that post a complaint.  It's unfortunate that for every complaint there are probably 10-100 people loving your repo that you will never hear from.\n\nThank you so much for sharing!",
          "score": 31,
          "created_utc": "2026-02-19 13:43:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o69bobe",
              "author": "Prestigious_Cat85",
              "text": "i'm against b\\*\\*ching especially for something free.\n\nthat being said, i couldnt myself make it work, it's lacking a lot of informations tbh.  \nfor example the requirements.txt was blank then the OP did put fill it : this is just an example. overall it's lacking a lot of informations imo.",
              "score": 7,
              "created_utc": "2026-02-19 15:51:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o694z1a",
              "author": "soundofmind",
              "text": "People are always more inclined to complain than to praise, which says a lot about humanity, unfortunately. I did have issues, but I was complaining to OP, I just hoped he might be able to help me out getting his hard work to work for me. :)",
              "score": 2,
              "created_utc": "2026-02-19 15:17:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o683e56",
          "author": "WildSpeaker7315",
          "text": "![gif](giphy|xchUhdPj5IRyw)\n\npretty much what my kids see",
          "score": 30,
          "created_utc": "2026-02-19 11:26:53",
          "is_submitter": true,
          "replies": [
            {
              "id": "o684ipp",
              "author": "PornTG",
              "text": "lol, go to sleep now, childrens need a father in good shape :p",
              "score": 14,
              "created_utc": "2026-02-19 11:36:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o694ixx",
              "author": "soundofmind",
              "text": "Mate, take a breather, ignore reddit for a few days till you feel yourself again. You are not beholden to any of us, we are receiving an amazing gift from you. I for one, will be patient until you feel like tinkering some more. I can't even imagine how much work you put into this, but I salute you, good sir!",
              "score": 7,
              "created_utc": "2026-02-19 15:15:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o69u9vv",
              "author": "Dragon_yum",
              "text": "![gif](giphy|8hsIwPLIGnZ1C)",
              "score": 3,
              "created_utc": "2026-02-19 17:20:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o68wyql",
              "author": "dubsta",
              "text": "No shame but this is fully AI generated code. Did you even write anything of it?\n\nThe \"Add files via upload\" git message is a huge red flag. Do you even git bro?",
              "score": -13,
              "created_utc": "2026-02-19 14:36:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o68y983",
                  "author": "WildSpeaker7315",
                  "text": "i actually wrote alot of it thank you. i used ai alot too,  \nmy spelling mistakes and such did not help\n\nthe images are fully ai generated, cant be arsed with that\n\nthis was a total of 1157 iterations over 5 days\n\nyou are more then welcome to go and make a better 1 sir :) , im sure its easy",
                  "score": 11,
                  "created_utc": "2026-02-19 14:43:06",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o68fn76",
          "author": "jjkikolp",
          "text": "Wow. Can't wait to get home and try this. Many thanks for this, can't imagine all the work behind it!",
          "score": 11,
          "created_utc": "2026-02-19 12:56:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6934ti",
          "author": "ltx_model",
          "text": "![gif](giphy|r7Ql3VIg4x6WA)\n\n",
          "score": 9,
          "created_utc": "2026-02-19 15:08:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o69yrqi",
              "author": "WildSpeaker7315",
              "text": "thanks :D <3 <3 <3 ",
              "score": 1,
              "created_utc": "2026-02-19 17:42:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o681u92",
          "author": "pipedreamer007",
          "text": "I'm too much of a novice to understand everything you stated.  But a big THANK YOU for this contribution! üôè \n\nI think your hard work and time will save me and many other people time and frustration.  It's people like you that make life a little better for everyone! üëç",
          "score": 15,
          "created_utc": "2026-02-19 11:13:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o684icg",
          "author": "UsualStrategy1955",
          "text": "This was a ton of work and it looks amazing. You are a legend. Thank you!!!!",
          "score": 8,
          "created_utc": "2026-02-19 11:36:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o688num",
          "author": "Valtared",
          "text": "Hello, thanks for this. I got an OOM error while trying to laod the Qwen 2.5 VL 7b with 16gb Vram. It should offload to normal RAM for the excess but it doesn't, and we don't have the option to chose CPU in the vision node. I will use the 3b now, but I think you could enable offloading in the node ?",
          "score": 4,
          "created_utc": "2026-02-19 12:08:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o689h5d",
              "author": "WildSpeaker7315",
              "text": "yes that should be an easy fix check the github in a moment did the fix for both nodes, as you'll probably need it  \nif it doesn't work now i dont want to tinker more then that",
              "score": 7,
              "created_utc": "2026-02-19 12:14:19",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6896nj",
              "author": "PornTG",
              "text": "Try to use offline mode to false",
              "score": 3,
              "created_utc": "2026-02-19 12:12:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o69yvy8",
          "author": "dkpc69",
          "text": "Thank‚Äôs for creating and sharing this",
          "score": 4,
          "created_utc": "2026-02-19 17:42:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6cri79",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 4,
          "created_utc": "2026-02-20 02:33:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ghi5f",
              "author": "Grindora",
              "text": "any idea how to fix this? ",
              "score": 1,
              "created_utc": "2026-02-20 17:34:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6xk5oe",
                  "author": "Heavy-Republic-1994",
                  "text": "yes, read the installation steps again",
                  "score": 1,
                  "created_utc": "2026-02-23 10:51:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o682536",
          "author": "-chaotic_randomness-",
          "text": "I only have 8gb VRAM, can I still use this?",
          "score": 3,
          "created_utc": "2026-02-19 11:16:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o684cbr",
              "author": "LSI_CZE",
              "text": "No problem, I have RTX 3070 with 8GB VRAM but 64GB RAM",
              "score": 8,
              "created_utc": "2026-02-19 11:34:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6tdse0",
                  "author": "Natrimo",
                  "text": "The q4gguf models work",
                  "score": 1,
                  "created_utc": "2026-02-22 18:31:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o682y3z",
              "author": "WildSpeaker7315",
              "text": "questionable, if you can even use LTX-2 haha try the low models, good luck",
              "score": 6,
              "created_utc": "2026-02-19 11:23:13",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6cg6ql",
              "author": "FantasticFeverDream",
              "text": "Maybe try Q4 gguf models",
              "score": 1,
              "created_utc": "2026-02-20 01:23:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6abp9h",
          "author": "xNothingToReadHere",
          "text": "Is there something similar to this, but for img2img edits? Maybe something that helps with Klein or Qwen Edit.",
          "score": 3,
          "created_utc": "2026-02-19 18:42:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ahkmu",
              "author": "WildSpeaker7315",
              "text": "give me 5 minutes ",
              "score": 2,
              "created_utc": "2026-02-19 19:10:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6aon7k",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 3,
                  "created_utc": "2026-02-19 19:44:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6avku1",
          "author": "joopkater",
          "text": "Extremely good üëç",
          "score": 3,
          "created_utc": "2026-02-19 20:18:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6bm56w",
          "author": "MoooImACat",
          "text": "keeps saying I'm missing 'LTX2MasterLoaderLD' when I load the workflow. any ideas?",
          "score": 3,
          "created_utc": "2026-02-19 22:29:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6bqemg",
              "author": "WildSpeaker7315",
              "text": "the github link is above the node fam",
              "score": 2,
              "created_utc": "2026-02-19 22:52:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6bscuo",
                  "author": "MoooImACat",
                  "text": "I cloned your git into my custom\\_nodes, then loaded up your workflow. I understand this is the instruction to set it up?\n\nedit: nevermind, I got it now. sorry but you have one set of instructions on this post, a slightly different one in Git, and then the link inside the workflow itself. I missed it but got set up now.",
                  "score": 1,
                  "created_utc": "2026-02-19 23:03:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6cb962",
              "author": "artisst_explores",
              "text": "i have same error, how to fix ",
              "score": 2,
              "created_utc": "2026-02-20 00:53:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o681et4",
          "author": "PornTG",
          "text": "Now this work like a charm, thank you WildSpeaker for this fantastic nodes !",
          "score": 5,
          "created_utc": "2026-02-19 11:10:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6817g3",
          "author": "wardino20",
          "text": "what are your suggestions to run it on 16gb of vram?",
          "score": 2,
          "created_utc": "2026-02-19 11:08:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o681mjw",
              "author": "WildSpeaker7315",
              "text": "it should work on the full models, if it doesn't then use the smaller one, BUT the 7b qwen vision model can see what the th 3b one cant (explicit) \n\nit will offload all resources before going to video generation so if it works then it wont effect ur ability to make the video ",
              "score": 6,
              "created_utc": "2026-02-19 11:11:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o687bs8",
          "author": "Thuannguyenhn",
          "text": "Why are you using Qwen2 instead of Qwen3-VL?",
          "score": 2,
          "created_utc": "2026-02-19 11:58:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6884dh",
              "author": "WildSpeaker7315",
              "text": ". Both huihui-ai's 4B and 8B versions note that only the text part was abliterated, not the image/vision part.  i was going to test it but it was jsut to see an image and give a command.",
              "score": 3,
              "created_utc": "2026-02-19 12:04:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o68fm6n",
                  "author": "Bit_Poet",
                  "text": "Have you tried prithivMLmods/Qwen3-VL-8B-Instruct-c\\_abliterated-v3? It seems to give pretty usable output in my first tests with NSFW video captioning.",
                  "score": 1,
                  "created_utc": "2026-02-19 12:56:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6an74y",
          "author": "corben_caiman",
          "text": "Hi! This looks like an amazing tool and it's incredible what you did here. I'm struggling though to make it work, and I'm sure it's my bad, but when I try to run the t2v workflow (first time, trying to download the model) I get the following error:   \nPrompt outputs failed validation:  \nLTX2PromptArchitect:  \n\\- Required input is missing: bypass  \n\\- Required input is missing: invent\\_dialogue\n\nFor i2v instead I get a missing node: LTX2VisionDescribe\n\nI cloned the repo and typed pip install transformers qwen-vl-utils accelerate (which it DID download stuff). Also, I noticed that when I ran the workflow many fields where filled incorrectly and I had to refill them => I don't know if this is related somehow. \n\nI'd really need your help here, sorry to bother!\n\n",
          "score": 2,
          "created_utc": "2026-02-19 19:37:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6anrfg",
              "author": "WildSpeaker7315",
              "text": "are the nodes there in the side menu when you type lora daddy ?",
              "score": 1,
              "created_utc": "2026-02-19 19:40:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6awcv4",
                  "author": "corben_caiman",
                  "text": "Hi! I reinstalled everything and now it downloaded and I was able to arrive at the sampler but it gives me:  \nmat1 and mat2 shapes cannot be multiplied (1120x4096 and 2048x4096)  \n  \nTIPS: If you have any \"Load CLIP\" or \"\\*CLIP Loader\" nodes in your workflow connected to this sampler node make sure the correct file(s) and type is selected.\n\nI checked the clip loader and I have the standard connectors and the gemma 3 12b fp8 scaled \n\n:(\n\n",
                  "score": 1,
                  "created_utc": "2026-02-19 20:21:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6bkbxw",
          "author": "MahaVakyas001",
          "text": "hey so trying this now. Trying the I2V first. I get an OOM error on the \"Upscale Pass\" node. I have an RTX 5090 (32GB VRAM) so that's odd. The original image I'm using is 720x1280 and I'm not upscaling the final video.\n\n  \nHelp?",
          "score": 2,
          "created_utc": "2026-02-19 22:19:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6bpnut",
              "author": "WildSpeaker7315",
              "text": "are you keeping the prompt node loaded? the toggle should be off",
              "score": 1,
              "created_utc": "2026-02-19 22:48:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6ciunh",
                  "author": "MahaVakyas001",
                  "text": "I'm relatively new to ComfyUI and AI content creation, but yes, the prompt node has that \"bypass\" set to \"false\". is that what you mean?",
                  "score": 1,
                  "created_utc": "2026-02-20 01:40:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6vs5hw",
              "author": "Link1227",
              "text": "Did you figure this out?",
              "score": 1,
              "created_utc": "2026-02-23 02:11:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6bllwk",
          "author": "QikoG35",
          "text": "Thanks for sharing. I was just about to push a fork for your version 1 with improvements and fixes. Will definitely try this out. Thanks for helping the community.",
          "score": 2,
          "created_utc": "2026-02-19 22:26:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6bohwx",
          "author": "bickid",
          "text": "Hey, thx for all this. I just opened the I2V-workflow, but even after installing missing custom nodes, there's 3 nodes that are marked red:\n\n  \n\\- LTX2 Vision Describe\n\n\\- LTX2 Prompt Architect\n\n\\- LTX2 Master LoaderLD\n\n  \nHow do I get these 3 nodes to work? thx",
          "score": 2,
          "created_utc": "2026-02-19 22:42:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6bouby",
              "author": "WildSpeaker7315",
              "text": "![gif](giphy|2JknOsKNOGUwM)\n\nlmao  \nyou have to git clone the links provided into your custom\\_nodes folder",
              "score": 2,
              "created_utc": "2026-02-19 22:43:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6cg06t",
          "author": "FantasticFeverDream",
          "text": "![gif](giphy|IwdVK1xZcAZPL0rpkw)\n\n\"Lora Daddy's #1\" ",
          "score": 2,
          "created_utc": "2026-02-20 01:22:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6p6uxs",
          "author": "Visual-Wolverine-481",
          "text": "Thank you for creating this workflow! I am beginner but I usually get workflows working except for this time. I have spent a few hours trying to get it to work and I'm close but would appreciate some guidance\n\nWould you be able to list all of the custom nodes that are required. I figured out that I had to download ComfyUI-KJNodes, ComfyUI-VideoHelperSuite and ComfyUI\\_LayerStyle. What other nodes do I need to get it working?\n\n",
          "score": 2,
          "created_utc": "2026-02-22 01:28:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6pzi4e",
              "author": "Visual-Wolverine-481",
              "text": "I think I have found most of the custom¬†nodes that are needed, I have installed these:  \n  \nSave Image with Generation Metadata  \nComfyUI-VideoHelperSuite  \nComfyUI\\_LayerStyle  \ncomfy-image-saver  \nComfyUI-LTXVideo  \nComfyUI-KJNodes  \nComfyUI-GGUF  \nRES4LYF\n\nIt's creating the video now but it's not right. The video quickly displays the loaded picture and then it's just a brown background, any ideas? I did have to manually connect LTXVConcatAVLatent --> LayerUtility: PurgeVRAM V2 --> LTXVSeparateAVLatent.  \n  \nI have attached a picture of the workflow, hopefully you can spot what is wrong. \n\nhttps://preview.redd.it/zhn0vkhs6zkg1.jpeg?width=2848&format=pjpg&auto=webp&s=31b94baf7a1fb65455a60f69b7a41a005b68c3a6\n\n",
              "score": 2,
              "created_utc": "2026-02-22 04:42:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6xd2b6",
          "author": "Previous_Gap_1778",
          "text": "The frame-aware pacing is such a smart touch. Tying token budget to frame count means short clips stay focused and long ones get the detail they need. 800+ test runs really shows in the polish. Excited to try the 3B vision node!",
          "score": 2,
          "created_utc": "2026-02-23 09:44:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o687p4j",
          "author": "jalbust",
          "text": "Thanks for this.",
          "score": 1,
          "created_utc": "2026-02-19 12:01:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68le49",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-19 13:31:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6k96xq",
              "author": "Plenty_Way_5213",
              "text": "**I solved it**\\~\\~!",
              "score": 1,
              "created_utc": "2026-02-21 06:36:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o695zcn",
          "author": "billybobobobo",
          "text": "Where or what is the `offline_mode OFF`¬†??",
          "score": 1,
          "created_utc": "2026-02-19 15:22:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o69axz9",
              "author": "Prestigious_Cat85",
              "text": "https://preview.redd.it/7w9sssfp2hkg1.png?width=646&format=png&auto=webp&s=66af6db4cf75c3df09c61eeab37f061ae8dab209\n\n",
              "score": 3,
              "created_utc": "2026-02-19 15:47:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o69yn9r",
                  "author": "billybobobobo",
                  "text": "Many thanks!!",
                  "score": 1,
                  "created_utc": "2026-02-19 17:41:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o69b0sw",
          "author": "Soul_Walker",
          "text": "Hey there! would you please take this the right way, as constructive comment and in no way aggro or insensitive words? please and thank you! Last thing I want is to discourage you and others that are the spark that gets the wheel of progress going! too much?  \n  \nOh ok so you made a new post, deleting old one, but not redirecting from there to here.  \nI (or we) would still love a tutorial, cause we're still too dumb to make it work.  \nRelated: Dont see a hardware requirement listed, meaning if I have a 3090 but only 32gb ram I wont be able to run it, since you have 64. If so, what should I do? if no workaround then probably shouldn't bother smash my head against this hypothetical wall, it wont run.\n\nAgain, thanks for your time and effort!",
          "score": 1,
          "created_utc": "2026-02-19 15:47:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o69bkqp",
              "author": "WildSpeaker7315",
              "text": "Hi mate no its fine i get it, The idea behind the whole project is if you can load LTX-2 and make a video, you can load this first, If you can make 1080p 20 second videos, you can probably use the 8b models if your only just getting away with 720p then probably the lower models\n\n  ",
              "score": 1,
              "created_utc": "2026-02-19 15:50:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6ahz4o",
                  "author": "Soul_Walker",
                  "text": "I've never used LTX-2 yet, AI told me I may do it IF... also, in previous questions it gave me the impression I was better off with wan22. Even then haven't tried doing 1080p, just a few 640p 5s tests, so yeah, all too new.  \nThe 64gb ram comes up for pagefile and OOM preventions.  \nSigh, guess I'll have to read and test..  \nHave a good one!  \nedit:  \nYes, you can run the LTX-2 model and workflows in ComfyUI on an RTX 3090 with 32GB system RAM, but it requires optimizations due to the card's 24GB VRAM falling short of the official 32GB+ recommendation.\n\n# Hardware Feasibility\n\nRTX 3090 users have successfully generated videos (like 5-second clips) using techniques such as weight streaming/offloading, quantized models (e.g., FP8, FP4, or GGUF), and low-VRAM settings in ComfyUI. Your 32GB RAM meets or exceeds the minimum, helping with model offloading to system memory, though generation times may stretch to 10-25 minutes or more versus faster on 32GB+ VRAM GPUs.‚Äã\n\n# Key Optimizations\n\n* Launch ComfyUI with flags like `--reserve-vram 4` or `--reserve-vram 5` to prevent crashes.\n* Use distilled or quantized LTX-2 variants (e.g., ltx-2-19b-dev-fp4) and workflows from the official GitHub or ComfyUI templates.\n* Enable low-VRAM mode, avoid attention mechanisms if they cause issues, and start with short/low-res videos (e.g., 720p, 24fps).‚Äã‚Äã\n* Update NVIDIA drivers, ComfyUI, and custom nodes; tutorials like those from AISearch confirm it works on 3090s.‚Äã‚Äã\n\nExpect potential crashes or slowness without tuning, but community reports show it's viable.",
                  "score": 1,
                  "created_utc": "2026-02-19 19:12:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6apjty",
          "author": "MartinByde",
          "text": "Downloaded, now I have to download the 99 models and will test it! Thanks so much for the time",
          "score": 1,
          "created_utc": "2026-02-19 19:48:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6apsr8",
              "author": "WildSpeaker7315",
              "text": "its 108 models, actually. ",
              "score": 3,
              "created_utc": "2026-02-19 19:49:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6b2ufi",
          "author": "KitchenSpite9483",
          "text": "Hi, I have every node except for the Ltxv spatiotemporal tiled vae decode. I'm not sure where to download it, or what exactly to download and put in what file. I'm assuming it's the VAE file of ComfyUi. Please tell me like I'm 5 years old what file to download. ",
          "score": 1,
          "created_utc": "2026-02-19 20:53:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6b3fyv",
              "author": "WildSpeaker7315",
              "text": "Hey ikkle buddy, [**ComfyUI-LTXVideo**](https://github.com/Lightricks/ComfyUI-LTXVideo) **- either search in comfyui custom nodes or just go clone it, better yet go ask your dad to do it! ;)**",
              "score": 1,
              "created_utc": "2026-02-19 20:56:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6b6wnn",
                  "author": "KitchenSpite9483",
                  "text": "I go into this link, and what next? Download the whole thing into VAE file? I went into custom nodes in the manager and it acts like it downloads it but it doesn't. Sorry for my ignorance but I feel so close to getting this workflow to work",
                  "score": 1,
                  "created_utc": "2026-02-19 21:13:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6b6l7r",
          "author": "Oni8932",
          "text": "https://preview.redd.it/kvpy0vlcoikg1.png?width=1848&format=png&auto=webp&s=4b786dce28cb440e0fb1e2e46fa3924a838671e7\n\ni don't know why but i can't get past this. maybe it doesn't download the model. if it doesn't download it what can I do? (I'm using comfyUI installed via UmeAirt)",
          "score": 1,
          "created_utc": "2026-02-19 21:11:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6b9tad",
              "author": "WildSpeaker7315",
              "text": "change the creativity box. itts set to an old  style - i updated the node and the workflows recently.",
              "score": 2,
              "created_utc": "2026-02-19 21:27:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6bigwg",
                  "author": "Oni8932",
                  "text": "it solved the problem thanks! unfortunately now whe decoding vae i get this error...  \nThe size of tensor a (128) must match the size of tensor b (256) at non-singleton dimension 3  \nI don't know why. I asked chatgpt it says that the vae is not compatible but are the same of the workflow....",
                  "score": 1,
                  "created_utc": "2026-02-19 22:10:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6bpoi2",
          "author": "hellotismee",
          "text": "So I did run i2v and the Prompt got executed in 01:36:37  \n64gb of ram and 32 gb of vram on settings 301 x 128 400 frames.  \nIs this supposed to be that long?",
          "score": 1,
          "created_utc": "2026-02-19 22:48:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6bpzd8",
              "author": "WildSpeaker7315",
              "text": "https://preview.redd.it/65r06q926jkg1.png?width=702&format=png&auto=webp&s=4a80f41fb5fd0305b5e6bed85d78c65921b21a09\n\n  \nthis is false right?\n\nmaybe your overloading your ram. it makes no difference on mine 10 mins to do 1920x1080 480 frames before or after using my node",
              "score": 1,
              "created_utc": "2026-02-19 22:50:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6bsnej",
                  "author": "hellotismee",
                  "text": "https://preview.redd.it/d0y9xjgl8jkg1.png?width=349&format=png&auto=webp&s=4165c3877515765bc7d0c1f557f9bb3f8a7a7261\n\nI noticed that I had to fix this here in the Resize Image/Mask to bypass otherwise it would throw an error.  \n",
                  "score": 1,
                  "created_utc": "2026-02-19 23:05:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6bso10",
                  "author": "hellotismee",
                  "text": "https://preview.redd.it/b65fybct8jkg1.png?width=601&format=png&auto=webp&s=5262316c0811eda74fc190229dd08ad7fd53e772\n\n",
                  "score": 1,
                  "created_utc": "2026-02-19 23:05:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6c7dze",
                  "author": "hellotismee",
                  "text": "I reinstalled comfyui, seems to work now, thanks!",
                  "score": 1,
                  "created_utc": "2026-02-20 00:30:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6c8fv3",
          "author": "AstronomerLarge7189",
          "text": "Returning to this space after a long time away. How does this do with dudes? ",
          "score": 1,
          "created_utc": "2026-02-20 00:36:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c9y36",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-02-20 00:45:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6d2g8q",
          "author": "Gold-Cat-7686",
          "text": "This is really good, actually. Amazing work! Honestly, NSFW isn't really for me, but I was able to frankenstein your workflow into something super fast, quicker than any workflow I've used so far. I also modified the custom node a bit, changing the system prompt and code slightly. \n\nThanks for sharing!",
          "score": 1,
          "created_utc": "2026-02-20 03:42:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6d8h3d",
              "author": "FlyingAdHominem",
              "text": "Would love to see your modified WF",
              "score": 1,
              "created_utc": "2026-02-20 04:23:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6dte0n",
                  "author": "Gold-Cat-7686",
                  "text": "Sure, I don't mind, though I ripped out the prompt generating (I prefer having that in a separate workflow) and most of it is just setting it up to load quantized GGUFs + cleaning it up a bit. Not sure if you'll find it that useful, but here is the json:\n\n[https://pastebin.com/M4WrsepV](https://pastebin.com/M4WrsepV)\n\nThe changes to the system prompt etc I can't really share easily...I just edited the [LTX2EasyPromptLD.py](http://LTX2EasyPromptLD.py) to modify SYSTEM\\_PROMPT and to remove the explicit section.",
                  "score": 2,
                  "created_utc": "2026-02-20 07:14:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6d89b8",
          "author": "pakfur",
          "text": "I am having trouble finding where to download the LTX2SamplingPreviewOverride node in the LOW pass subgraph.\n\nI git cloned the LTX2EasyPrompt-LD and LTX2-Master-Loader repos, but this last node is still missing.\n\nAnyone know where I can get it from?\n\nedit: I was able to fix it with Manager, there was a custom node I needed to update.\n\nNow I just have to figure out how \"offline_mode\" is toggled.  Sigh......",
          "score": 1,
          "created_utc": "2026-02-20 04:22:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6difzu",
              "author": "darkrider99",
              "text": "The offline_mode is toggled in the \"LTX-2 Easy Prompt By LoRa-Daddy\" box",
              "score": 2,
              "created_utc": "2026-02-20 05:39:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6g6vfl",
                  "author": "pakfur",
                  "text": "Derp. Thank you!",
                  "score": 1,
                  "created_utc": "2026-02-20 16:45:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6darnq",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-20 04:40:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dio9b",
          "author": "darkrider99",
          "text": "can anyone apart from OP figured how to run this ?",
          "score": 1,
          "created_utc": "2026-02-20 05:40:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6duai8",
              "author": "WildSpeaker7315",
              "text": "No1 has managed to get it working other than me, that's why it has -400 downvotes :(",
              "score": 1,
              "created_utc": "2026-02-20 07:23:25",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6e37a3",
              "author": "corben_caiman",
              "text": "What issues do you have?\n\n",
              "score": 1,
              "created_utc": "2026-02-20 08:46:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6g6bhr",
                  "author": "darkrider99",
                  "text": "For one I had missing nodes, which I fixed. \nThen CUDA issues, fixed those. \n\nNow a generic Python Syntax error, which I am unable to fix. \n\nI can post it here if you can take a look",
                  "score": 1,
                  "created_utc": "2026-02-20 16:43:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6dkvzv",
          "author": "xxredees",
          "text": "Thanks bro. I finally got it working!",
          "score": 1,
          "created_utc": "2026-02-20 05:59:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e2ti0",
          "author": "corben_caiman",
          "text": "Hi! in the i2v workflow the vision and start with image part seems to be out of the loop => LTX basically produces only a t2v workflow. I guess I'm missing the part where you say: \n\n1. Wire Vision ‚Üí Easy Prompt via the¬†`scene_context`¬†connection for image-to-video\n\nHow do I actually do it? Thanks!\n\n",
          "score": 1,
          "created_utc": "2026-02-20 08:43:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6e3nd5",
              "author": "WildSpeaker7315",
              "text": "https://preview.redd.it/gn8mnz5c5mkg1.png?width=862&format=png&auto=webp&s=f920ffcd7566ebbfbaad86562baa71331efe1b47\n\n",
              "score": 1,
              "created_utc": "2026-02-20 08:50:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6eu1j7",
          "author": "Motor_Mix2389",
          "text": "This looks amazing and exactly what I need. Unfortunately I am not able to make it work, following your setup instructions and downloading the file. Any way you can make a more idiot proof step by step setup? Can I DM you for help?\n\nAmazing work regardless, this community is amazing. ",
          "score": 1,
          "created_utc": "2026-02-20 12:34:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fahup",
              "author": "WildSpeaker7315",
              "text": "did u get the workflow with all the links?",
              "score": 2,
              "created_utc": "2026-02-20 14:09:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6fd24m",
                  "author": "Motor_Mix2389",
                  "text": "Yes sir. I am just learning the ropes with ComfyUI, but it seems like 80%+ of workflows have some kind of error. I am actually willing to pay a fee for you to walk me through step by step like the monkey I am. Let me know if you are intrested.\n\nThis aside, a custom tailored wan2.2 setup like you did, would be amazing, as that is my togo model and from my understanding it requires a different type of prompting style?\n\nI wish I had your skills to make it happen! How long you been tinkering with ComfyUI? Do you have programming skills previous knowledge?",
                  "score": 1,
                  "created_utc": "2026-02-20 14:23:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ezrge",
          "author": "CurrentMine1423",
          "text": "https://preview.redd.it/y65hr5pffnkg1.png?width=1105&format=png&auto=webp&s=020302cf843e33bbb1e52f5ef1deab45769aa536\n\nI want to use local\\_path\\_8b, but I got this error. If I use the default download location, it works.\n\nEDIT: it's working now, I just need to install protobuf",
          "score": 1,
          "created_utc": "2026-02-20 13:10:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ghqo1",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-02-20 17:35:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6giwg7",
              "author": "WildSpeaker7315",
              "text": "can you delete the node folder and reget it from github\n\ncustom\\_nodes\\\\LTX2EasyPrompt-LD < remove and reget",
              "score": 1,
              "created_utc": "2026-02-20 17:41:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ij8ax",
          "author": "Link1227",
          "text": "Hi,\n\nI followed all of your steps but keep getting this error\n\n  \nLTX2VisionDescribe  \n\\[VisionDescribe\\] Missing: qwen-vl-utils. Fix: pip install qwen-vl-utils then restart ComfyUI.\n\nI did the install and it says already satisfied, any ideas?",
          "score": 1,
          "created_utc": "2026-02-20 23:38:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kepy1",
              "author": "WildSpeaker7315",
              "text": "How did you install it \nIn comfyui?\nIn the venv \nCMD folder randomly?\nI haven't heard anyone else have this issue it's quite unique",
              "score": 1,
              "created_utc": "2026-02-21 07:27:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6kfq14",
                  "author": "Link1227",
                  "text": "No, I just opened CMD and pip installed.\n\nIt seems to be working now though, I had to move the taeltx\\_2.safetensors in vae\\_approx\n\nRan out of vram running though. I only have 12gb :/",
                  "score": 1,
                  "created_utc": "2026-02-21 07:36:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6iyyfp",
          "author": "billybobobobo",
          "text": "I managed to get it working.. but where to input frame count??",
          "score": 1,
          "created_utc": "2026-02-21 01:10:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kekb8",
              "author": "WildSpeaker7315",
              "text": "My workflow.",
              "score": 1,
              "created_utc": "2026-02-21 07:25:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6mrn0s",
                  "author": "billybobobobo",
                  "text": "I'm talking about where in the workflow because I'm blind",
                  "score": 1,
                  "created_utc": "2026-02-21 17:31:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6j250k",
          "author": "MahaVakyas001",
          "text": "okay I got it working but there are still some weird quirks. There are random garbled subtitles automatically inserted into the video. I didn't ask for that - how do we turn that off? I can do subtitles externally (in Premier or CapCut) but I don't want it in here.\n\nhow do we disable automatic subtitles?",
          "score": 1,
          "created_utc": "2026-02-21 01:29:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kei83",
              "author": "WildSpeaker7315",
              "text": "This is news to me, \nI need an example prompt\n\nThanks",
              "score": 1,
              "created_utc": "2026-02-21 07:25:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6nthlh",
                  "author": "MahaVakyas001",
                  "text": "Here's the prompt I used:\n\n*Elderly monk saffron robes seated in lotus position, long white flowing beard moving gently with breath, eyes slowly opening from deep meditation with serene peaceful expression, soft golden morning light filtering through ancient temple columns, orange robes rippling softly in temple breeze, sacred atmosphere with dust particles drifting through shafts of light, static camera locked on face and upper body, no camera movement, deeply spiritual presence radiating stillness and wisdom. He opens his eyes, looks directly at the viewer and says, \"Who are you? Now, that is the real question!\"*\n\nI'm using 0.9 for Creativity and set LoRA Daddy LoRA to 0.75 (I tried 0.40 - 0.90 also).\n\noriginal image is 720x1280. output video is 1080x1920 @ 24fps. Img Compression set to 15.\n\nUsing RTX 5090 - render is quite fast (\\~ 5 min with the 7B model) but this automatic subtitle is killing the whole vibe.",
                  "score": 1,
                  "created_utc": "2026-02-21 20:43:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6k5v73",
          "author": "Weekly_Mongoose4315",
          "text": "so i running Qwen2.5-VL using ollama but i dont think its working ",
          "score": 1,
          "created_utc": "2026-02-21 06:06:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kjjbv",
          "author": "newxword",
          "text": "Is support Chinese dialogue?(voice)",
          "score": 1,
          "created_utc": "2026-02-21 08:13:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kjvlu",
              "author": "WildSpeaker7315",
              "text": "ye i beleive so <3 [Video posted by LoRa\\_Daddy](https://civitai.com/images/121574841)   \none of my examples had this in it ?",
              "score": 1,
              "created_utc": "2026-02-21 08:17:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6pjzhp",
          "author": "darkrider99",
          "text": "I think I am close to getting it to work. The nodes are green themselves in the workflow. none red. \n\nI ran into a taeltx error which I think I fixed by editing the JSON and replacing with LTX2_video_vae_bf16.safetensors and LTX2_audio_vae_bf16.safetensors. \n\nBut now I have this error. /u/WildSpeaker7315 any thoughts on this please ?\n\n\\AI\\CUI_LTX2_exp\\ComfyUI_windows_portable\\ComfyUI\\comfy\\sd.py\", line 833, in throw_exception_if_invalid raise RuntimeError(\"ERROR: VAE is invalid: None\\n\\nIf the VAE is from a checkpoint loader node your checkpoint does not contain a valid VAE.\") RuntimeError: ERROR: VAE is invalid: None If the VAE is from a checkpoint loader node your checkpoint does not contain a valid VAE.",
          "score": 1,
          "created_utc": "2026-02-22 02:54:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6snx5b",
          "author": "Natrimo",
          "text": "Do you have any workflows for the gguf versions?",
          "score": 1,
          "created_utc": "2026-02-22 16:32:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6spedu",
              "author": "WildSpeaker7315",
              "text": "the node isnt stuck to the workflow fam :( ",
              "score": 1,
              "created_utc": "2026-02-22 16:39:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6xx6ac",
                  "author": "Natrimo",
                  "text": "Oh for sure, and I got it going with my existing workflow. Works great thanks for your hard work. But your workflow looked interesting!",
                  "score": 1,
                  "created_utc": "2026-02-23 12:38:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6voovk",
          "author": "Imaginary-Land9953",
          "text": "can I view the negative prompts or change them? ",
          "score": 1,
          "created_utc": "2026-02-23 01:50:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6wyq21",
              "author": "WildSpeaker7315",
              "text": "How dare you even consider that\nAll things aside , slap it into a preview as text node as well. \nAnd no you can't change it. You can just not use it tho makes no difference on cfg 1",
              "score": 2,
              "created_utc": "2026-02-23 07:23:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vpj06",
          "author": "rohit5591",
          "text": "# LoraLoaderModelOnly\n\n'Linear' object has no attribute 'weight'",
          "score": 1,
          "created_utc": "2026-02-23 01:55:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o706w0s",
              "author": "necile",
              "text": "me too /u/WildSpeaker7315 would you mind helping with this?",
              "score": 1,
              "created_utc": "2026-02-23 19:28:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o707zdk",
                  "author": "WildSpeaker7315",
                  "text": "mek sure u have the latest version this shouldnt happen",
                  "score": 1,
                  "created_utc": "2026-02-23 19:33:30",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o70fqf8",
          "author": "CaptainAmbitious2790",
          "text": "Trying to make NSFW content with this but no success, the action looks awful, what LoRAs are you guys using?",
          "score": 1,
          "created_utc": "2026-02-23 20:10:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o726hmq",
          "author": "billybobobobo",
          "text": "https://preview.redd.it/mfxi0js2kclg1.png?width=767&format=png&auto=webp&s=5086186df4327519cb41cd1b12cb002cafcca2bd\n\nI keep getting this error for the I2V workflow, and I'm not sure where to do the pip install because I get an error indicating ; \n\n\"pip : The term 'pip' is not recognized as the name of a cmdlet, function, script file, or operable program. Check the\n\nspelling of the name, or if a path was included, verify that the path is correct and try again.\n\nAt line:1 char:1\n\n\\+ pip install qwen-vl-utils!\n\n\\+ \\~\\~\\~\n\n\\+ CategoryInfo          : ObjectNotFound: (pip:String) \\[\\], CommandNotFoundException\n\n\\+ FullyQualifiedErrorId : CommandNotFoundException\"",
          "score": 1,
          "created_utc": "2026-02-24 01:40:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75wbm4",
          "author": "michaelsoft__binbows",
          "text": "u/WildSpeaker7315 please clarify.... so I think I have all the information now. You have a pair of workflows from your google share and i am attempting to use the I2V one. It has a LTX2MasterLoaderLD node in it, but it's plainly clear from looking at your github that this node does not exist. maybe you renamed or something, but this is preventing me from being able to test. ",
          "score": 1,
          "created_utc": "2026-02-24 16:44:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75x6zd",
              "author": "michaelsoft__binbows",
              "text": "Latest info: [https://github.com/seanhan19911990-source/LTX2-Master-Loader](https://github.com/seanhan19911990-source/LTX2-Master-Loader) also needed. so, with two custom nodes packages i'm able to get past failure to load the workflow. My dude... what a way to shoot your release in the foot. Thank you for sharing your workflows and custom nodes.",
              "score": 1,
              "created_utc": "2026-02-24 16:48:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o75yvac",
                  "author": "michaelsoft__binbows",
                  "text": "OK i see the references in the workflow nodes explaining. They are easy to miss still. all content inside the workflow is too easy to miss!",
                  "score": 1,
                  "created_utc": "2026-02-24 16:56:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ed2va",
          "author": "danielriley123",
          "text": "This is exactly the kind of tool that makes local workflows actually accessible. The biggest barrier for most people isn't hardware anymore, it's the prompting. You stare at a blank text box and have no idea how to describe what you want in a way the model understands. Having a node that handles that translation step is huge. Does the vision node work with reference images for style matching? Like feed it a frame and have it generate a prompt that captures the aesthetic?",
          "score": 1,
          "created_utc": "2026-02-20 10:19:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6edj69",
              "author": "WildSpeaker7315",
              "text": "so the vision node, feed it any image and it spits out a plain text description covering style, subject appearance, camera angle, lighting and setting. That then pipes straight into the Easy Prompt node which uses it to expand it into a full cinematic video prompt.\n\nFor style matching from a reference frame it works well ‚Äî give it a film still or a render you like and it picks up the aesthetic: lighting quality, colour palette, camera framing, whether it reads handheld or whatever\n\n\\- in theory ha  \nalso thank you",
              "score": 1,
              "created_utc": "2026-02-20 10:23:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6f4tss",
                  "author": "danielriley123",
                  "text": "oh that's really cool actually, i didn't realize the vision node could pick up on stuff like handheld vs tripod framing. gonna have to test that with some reference stills from films i like. appreciate the breakdown",
                  "score": 1,
                  "created_utc": "2026-02-20 13:39:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o69kzf0",
          "author": "BirdlessFlight",
          "text": "Jesus, 25% of the system prompt is dedicated just for undressing and nudity? That's a little wild. I might fork this and change the system prompt cause you don't really expose it in the UI.\n\n    You are a cinematic prompt writer for LTX-2, an AI video generation model. Your job is to expand a user's rough idea into a rich, detailed, video-ready prompt.\n    \n    PRIORITY ORDER ‚Äî always establish these first, in this order:\n    1. Video style & genre (e.g. slow-burn thriller, handheld documentary, high-fashion editorial, erotic cinema, action blockbuster)\n    2. Camera angle & shot type (e.g. low-angle close-up, bird's-eye wide shot, Dutch angle medium shot)\n    3. Character description (age MUST always be stated as a specific number e.g. \"a 28-year-old woman\" ‚Äî never omit or approximate age; body type, hair, skin, clothing or nude state, distinguishing physical features ‚Äî be extremely explicit and specific when instructed; name body parts directly using the exact words the user used, e.g. if user says \"pussy\" write \"pussy\" not \"sex\" or \"womanhood\")\n    4. Scene & environment (location, time of day, lighting, colour palette, textures, atmosphere)\n    \n    THEN add:\n    5. Action & motion ‚Äî describe the movement as a continuous present-tense sequence, start to finish. Structure the action in clear beats.\n    \n    UNDRESSING RULE ‚Äî this is mandatory when clothing removal is implied or stated:\n    If the subject is clothed at the start and the scene involves nudity, stripping, or explicit content, you MUST dedicate a full narrative segment to the undressing BEFORE any nudity or explicit act is described. This segment must:\n      - Name each garment explicitly (shirt, bra, jeans, underwear, shoes, etc.)\n      - Describe HOW it is removed ‚Äî fingers on buttons, zipper pulled down, fabric sliding off shoulders, stepped out of, peeled away\n      - Describe what is physically REVEALED at each step ‚Äî the collarbone, the stomach, the curve of the hip, the chest, the bare legs\n      - Follow the exact order the clothes come off ‚Äî do not skip or compress steps\n      - Use camera-aware language ‚Äî the camera lingers, cuts to, tilts down to reveal, holds on\n      - Do NOT jump from clothed to naked. The transition IS the content. Treat it as its own scene segment with the same density as any other beat.\n    \n    6. Camera movement ‚Äî describe camera motion as prose, not bracketed directions. Never write \"(DOWN 10¬∞)\", \"(Pull back)\", \"(Fade to black)\", \"(HOLD)\" or any screenplay-style bracketed camera instruction. Instead write it as description: \"the camera slowly tilts down to reveal the wet pavement\", \"the shot pulls back to frame the empty street\", \"the scene fades to black as she disappears around the corner.\"\n    7. Audio ‚Äî Always include ambient sound. ONE [AMBIENT: sound 1, sound 2] tag only ‚Äî never repeat it. Place it once at the natural end of the scene.\n       Dialogue ‚Äî follow the DIALOGUE INSTRUCTION you are given exactly. When dialogue is included, write it as inline prose woven into the action ‚Äî not as a labelled tag. The spoken words sit inside the sentence, attributed with delivery and physical action, exactly like a novel. Examples of correct format:\n       'He leans back, satisfied, \"I think I'll have to go back tomorrow for more,\" he chuckles, his eyes crinkling at the corners.'\n       '\"Don\\'t stop,\" she breathes, gripping the sheets, her voice barely above a whisper.'\n       'She turns to face him, \"I\\'ve been waiting all day for this,\" her tone quiet and certain.'\n       NEVER use [DIALOGUE: ...] tags. NEVER write dialogue as a separate bracketed block. Dialogue flows inside the prose as part of the action.\n    \n    WRITING RULES:\n    - Use present tense throughout\n    - Be explicit and cinematic ‚Äî LTX-2 responds well to dense, specific visual language\n    - Match detail level to shot scale: close-ups need more physical detail, wide shots need more environmental detail\n    - Do not use vague words like \"beautiful\" or \"nice\" ‚Äî describe exactly what makes it visually striking\n    - Fill the full available length ‚Äî do not stop early. Expand every section with rich, layered detail\n    - Aim for 8‚Äì12 sentences of dense, flowing prose ‚Äî not a bullet list\n    - Write in sections separated by a single line break for clean model parsing\n    \n    IMPORTANT: Output ONLY the expanded prompt. Do NOT include preamble, commentary, labels, or any explanation. Do NOT write \"Sure!\", \"Here's your prompt:\", or anything like that. Do NOT add a checklist, compliance summary, note, or confirmation of instructions at the end ‚Äî not in brackets, not as a \"Note:\", not in any form. The output ends when the scene ends. Nothing after the last sentence of the scene. Begin immediately with the video style or shot description.",
          "score": 0,
          "created_utc": "2026-02-19 16:35:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o69mdjb",
              "author": "WildSpeaker7315",
              "text": "I don't quite understand what your point is?  \ni need it to Take a persons input and Make a reality. And that is what a lot of people would do?\n\n\"she takes off her tank top\" isnt going to do anything in LTX-2\n\nthere is multiple layers to ensure what people type weather its normal or explicit comes to light\n\nthere's a reason this wasn't made in a day i did over 800 short video tests",
              "score": 12,
              "created_utc": "2026-02-19 16:42:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6a3vp5",
                  "author": "afinalsin",
                  "text": "Yeah, LLMs are good at following instructions (usually) but even the best models aren't omniscient, and they're dogshit at prompting for image/video gen if left to their own devices. I have a long and complex booru prompt generator with tons of rules just to get the models to not add tags that won't actually do anything.\n\nI haven't used local models in a while and while their attention is better than they used to be the last line feels a bit long. I trust you definitely needed to iterate on it like that because it looks like an instruction born of frustration. If you want to try out an instruction, I use \"Do not write any affirmations, confirmations, or explanations, simply deliver the X\". It might or might not work for this but could be worth a shot.",
                  "score": 1,
                  "created_utc": "2026-02-19 18:06:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o69r86b",
                  "author": "BirdlessFlight",
                  "text": "Oh yeah, don't get me wrong, give the people what they want.\n\nI just don't need that much context wasted on something I'll never use, but thanks for the inspiration!",
                  "score": -1,
                  "created_utc": "2026-02-19 17:05:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6a2o3d",
              "author": "ninjasaid13",
              "text": ">Jesus, 25% of the system prompt is dedicated just for undressing and nudity?\n\nHe used it to goon.",
              "score": 4,
              "created_utc": "2026-02-19 18:00:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o687gi7",
          "author": "NoMonk9005",
          "text": "where do i put the LTX2-Master-Loader files?\n\n",
          "score": 0,
          "created_utc": "2026-02-19 11:59:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o687oy0",
              "author": "WildSpeaker7315",
              "text": "its a normal github install  \nso in custom\\_nodes, then git clone and it will create a folder ",
              "score": 2,
              "created_utc": "2026-02-19 12:00:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o68aa98",
                  "author": "NoMonk9005",
                  "text": "i did exactly that, but in comfyUI it still says missing node...",
                  "score": 1,
                  "created_utc": "2026-02-19 12:20:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o68dd6n",
          "author": "in_use_user_name",
          "text": "Looks good! Now wan2.2 version..",
          "score": 0,
          "created_utc": "2026-02-19 12:41:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68ecd2",
              "author": "WildSpeaker7315",
              "text": "just turn off dialogue on the toggle and it shouldn't be too bad.  but the frames to 200 if ur only gonna use like 81 -113 and it should be about right ",
              "score": 1,
              "created_utc": "2026-02-19 12:48:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6cte2n",
          "author": "thisiztrash02",
          "text": "clean af",
          "score": 0,
          "created_utc": "2026-02-20 02:44:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6mcdvj",
          "author": "West_Tell_5422",
          "text": "https://preview.redd.it/0xufz71ghvkg1.png?width=728&format=png&auto=webp&s=917bd1ec9b1af78704e53b61a26e198874c4dcf3\n\nhi help me ",
          "score": 0,
          "created_utc": "2026-02-21 16:15:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xkh8o",
              "author": "Heavy-Republic-1994",
              "text": "read the error message is telling you the solution",
              "score": 1,
              "created_utc": "2026-02-23 10:54:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6dc4js",
          "author": "seppe0815",
          "text": "Another free scam crap¬†",
          "score": -3,
          "created_utc": "2026-02-20 04:50:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6hotnz",
              "author": "NostradamusJones",
              "text": "WTF are you talking about?",
              "score": 2,
              "created_utc": "2026-02-20 20:58:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rc2fgr",
      "title": "I love local image generation so much it's unreal",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1rc2fgr/i_love_local_image_generation_so_much_its_unreal/",
      "author": "SlapMyOwnNuts",
      "created_utc": "2026-02-23 00:19:44",
      "score": 346,
      "num_comments": 94,
      "upvote_ratio": 0.88,
      "text": "Now if you'll excuse me, I'm going to generate about 400 smut images of characters from Blue Archive to goon my brains to. Peace",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rc2fgr/i_love_local_image_generation_so_much_its_unreal/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "o6v9uk5",
          "author": "lacerating_aura",
          "text": "Username checks out.",
          "score": 131,
          "created_utc": "2026-02-23 00:22:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o70z865",
              "author": "BitCloud25",
              "text": "Slap em! Slap em good!",
              "score": 3,
              "created_utc": "2026-02-23 21:45:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vgbid",
          "author": "unltdhuevo",
          "text": "Ok imagine that but with video",
          "score": 70,
          "created_utc": "2026-02-23 00:59:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xdiaw",
              "author": "Spamuelow",
              "text": "And now imagine that video is vr",
              "score": 23,
              "created_utc": "2026-02-23 09:48:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6wvog3",
              "author": "desktop4070",
              "text": "LTX 2 is more fun to play with than most games I've played in the past decade. I still can't believe that they released it, and that I can run it locally.",
              "score": 27,
              "created_utc": "2026-02-23 06:55:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o743w7h",
                  "author": "KomaKiley",
                  "text": "How do you run it locally? I know I could probably google this question, but do you have suggestions for a good starting point?",
                  "score": 1,
                  "created_utc": "2026-02-24 10:31:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6xbqma",
              "author": "RO4DHOG",
              "text": "Imagine that butt with video.\n\n![gif](giphy|8qABb3dgjun8PdNirg)\n\n",
              "score": 24,
              "created_utc": "2026-02-23 09:30:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6zyk5p",
                  "author": "_half_real_",
                  "text": "Rose from Zaiyuki if she real.",
                  "score": 1,
                  "created_utc": "2026-02-23 18:50:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6w73tt",
          "author": "Initial-Cherry-3457",
          "text": "May I suggest /r/unstable_diffusion",
          "score": 46,
          "created_utc": "2026-02-23 03:45:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6w7rf9",
              "author": "dipshit_loser",
              "text": "I have seen the top of the mountain",
              "score": 19,
              "created_utc": "2026-02-23 03:49:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6wyjcy",
                  "author": "TooManiEmails",
                  "text": "üé∂And I ain‚Äôt comin downüé∂",
                  "score": 10,
                  "created_utc": "2026-02-23 07:21:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6x2l6d",
              "author": "StrongZeroSinger",
              "text": "Their wiki seems 2 years outdated or is it the mobile view?",
              "score": 11,
              "created_utc": "2026-02-23 08:00:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o75v4u5",
              "author": "sphynxcolt",
              "text": "Despite the topic here, I was naive enough to click while I am at work right now.",
              "score": 1,
              "created_utc": "2026-02-24 16:39:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6whby4",
          "author": "wyc603",
          "text": "I buy powerful GPU to game? No, I buy powerful GPU to goon.",
          "score": 76,
          "created_utc": "2026-02-23 04:57:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ww16o",
              "author": "Loose_Object_8311",
              "text": "Gooner Processing Unit :P",
              "score": 84,
              "created_utc": "2026-02-23 06:58:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6zpemc",
                  "author": "Koalateka",
                  "text": "Very accurate",
                  "score": 6,
                  "created_utc": "2026-02-23 18:08:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6ww7xb",
              "author": "desktop4070",
              "text": "I bought a 3060 at launch with the sole purpose of playing games.  \n  \nI'm not the same man I was before September 2022.  \n  \nI ended up buying a 5070 Ti pretty much entirely for running local models.",
              "score": 29,
              "created_utc": "2026-02-23 07:00:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6xemde",
          "author": "bickid",
          "text": "Ngl: Ever since I started doing AI stuff, I've consumed LESS porn, because knowing that I could CREATE ANYTHING just puts so much peace on my mind, it's like I don't need to see stuff, because I know I \"could\" see if I wanted to. AI is amazing. <3",
          "score": 35,
          "created_utc": "2026-02-23 09:59:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6z3h9i",
              "author": "mca1169",
              "text": "this, it's so much more reassuring to have the ability to create what in a world where the internet is getting locked down more by the day. plus it can be a fun process to have something as simple as a setting or outfit in mind and steadily build on the idea into something completely new.",
              "score": 8,
              "created_utc": "2026-02-23 16:26:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6zgv00",
              "author": "timbocf",
              "text": "Porn is so fake and created to cater to our fantasies but its not like real sex at all, quite the opposite. I just wanna reimagine times I've had with my wife that we didn't get on video",
              "score": 2,
              "created_utc": "2026-02-23 17:28:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6w3bsb",
          "author": "Neggy5",
          "text": "ai saved me from spending thousands on commissions for specific smut no one was making enough of. ",
          "score": 80,
          "created_utc": "2026-02-23 03:20:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x42p9",
              "author": "Loose_Object_8311",
              "text": "Call me silly, but I didn't realise that was a thing people did... no less spent thousands on. I won't ask, but then again rule 34 is a thing, so I can imagine.",
              "score": 18,
              "created_utc": "2026-02-23 08:14:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6y3we7",
                  "author": "SalsaRice",
                  "text": "I think it's primarily a furry thing, but it's been pretty widely known for a while from artists that furries are willing to pay well, tip generously, and (usually) treat artists well. \n\nFor whatever reason, it's really common for furries to work in IT and computer science, so they seem to have a higher than average income than most Fandoms.",
                  "score": 11,
                  "created_utc": "2026-02-23 13:22:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o70fpwa",
              "author": "SpaceNinjaDino",
              "text": "I paid for one commissioned custom video. She didn't follow the script at all or even use the Amazon wishlist item bought. (Before gen AI existed.) Now I can generate impossible things. Like sex in crowded public settings (subway, stadium, restaurants/cages, theater, park, space station, etc). Magic, medieval, future, robots, zombie, under water ... real goon material can't compete. No more worries that girls were tricked like in the girlsdoporn case.",
              "score": 2,
              "created_utc": "2026-02-23 20:09:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wynts",
          "author": "necrophagist087",
          "text": "Next stage: condensing your fetish in the form of lora and sharing with others.",
          "score": 15,
          "created_utc": "2026-02-23 07:23:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vt903",
          "author": "ModFrenzyAI",
          "text": "Why stop with images? As long as you have 8GB VRAM, you can use WAN2.2 to animate whatever image you create! ",
          "score": 38,
          "created_utc": "2026-02-23 02:17:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xa8a0",
              "author": "fugogugo",
              "text": "I have tried setting up WAN workflow , it worked but ...  \n  \nI honestly still don't understand what or how to prompt . haha \n\nI am already 1girl, solo brained \n\n",
              "score": 19,
              "created_utc": "2026-02-23 09:15:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6yz1cv",
                  "author": "Unambiguous-Doughnut",
                  "text": "Ok ok I gotchu.\n\nUse ChatGPT to assist in setting up a 70b parameter LLM Using LMStudio or Ollama. If the LLM allows it can allow for NSFW Prompts bonus points if its vision enabled. \n\nThough you will 100% be using a quantanized model unless your running a supercomputer or ram only.\n\n\nAsk ChatGPT to come up with a system prompt that will ensure the model acts as a prompt assistant for video models (like want2.2 etc) you need to be specific its for video models because image and video generation can be different.\n\nWith vision enabled you could also ask it to prompt for image2video. \n\n\nWan2.2 workflow, powerloader lora. Goon to your hearts content <3 \n\nHell LLMS are significantly more powerful than image and video generation like you want it to act as a editorial assistant for documents ask for a system prompt so it does just that. \n\nYou want it to assist in coding hell yeah it can. You need it to write a detailed scene for your t2i flux/wan2.2 model runs locally no need for Internet comectivity or sign in.",
                  "score": 13,
                  "created_utc": "2026-02-23 16:05:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6wmegt",
              "author": "rafaelbittmira",
              "text": "I have tried the 5B wan 2.2 for anime generation and have had very little success, it works great for realistic generation though",
              "score": 5,
              "created_utc": "2026-02-23 05:36:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6wzgez",
                  "author": "King__Ragnar",
                  "text": "5b sucks. Use 14b with a quant model and lightning lora. I only have 8gb vram and can create videos in 6 - 10 min",
                  "score": 13,
                  "created_utc": "2026-02-23 07:30:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6vvqf2",
              "author": "Esquilax21",
              "text": "Is there a guide how to set it up? Would love to generate videos",
              "score": 6,
              "created_utc": "2026-02-23 02:33:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6vwn8x",
                  "author": "ModFrenzyAI",
                  "text": "Yeah! I've made one for GPU poor folks like me. It might not be the best one but worked great for my purposes. It's on CivitAI (you might need to turn-on your NSFW settings): [https://civitai.com/models/2272369/wan22-i2v-gguf-nsfw-8gb-vram-32gb-ram-workflow](https://civitai.com/models/2272369/wan22-i2v-gguf-nsfw-8gb-vram-32gb-ram-workflow)",
                  "score": 31,
                  "created_utc": "2026-02-23 02:38:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6xri2j",
                  "author": "Bietooeffin",
                  "text": "https://civitai.com/models/1824962/torstens-wan-22-14b-i2v-low-vram-workflow-with-added-features\n\nThis one is also pretty neat, using that one with q4 quants and 8gb vram and 16gb system ram and a 48gb page file. 480p 5 second videos will take you around 4-5 minutes with e.g. 40 or 50 series cards with 8gb, lighting lora (baked in or not) and sage attention.",
                  "score": 5,
                  "created_utc": "2026-02-23 11:55:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6zbe18",
              "author": "Magnar0",
              "text": "Same for AMD?",
              "score": 1,
              "created_utc": "2026-02-23 17:03:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6z3syo",
              "author": "mca1169",
              "text": "you forgot to mention the multiple hours of generation time for a 5 second or longer \"video\".",
              "score": 1,
              "created_utc": "2026-02-23 16:28:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o70aha4",
                  "author": "megacewl",
                  "text": "3080ti 12GB can do a 5 second 1240x1080 WAN 2.2 img2vid generation in 4.5 minutes",
                  "score": 1,
                  "created_utc": "2026-02-23 19:45:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6z7gy6",
                  "author": "ModFrenzyAI",
                  "text": "Not really, I can generate 576p in 5 minutes or less. 720p takes 40-50 minutes, so I'm not even trying that with my PC. I started using RunPod for those kinda generations, not much to do :(",
                  "score": 0,
                  "created_utc": "2026-02-23 16:44:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6x9wzq",
          "author": "fugogugo",
          "text": "![gif](giphy|YmQLj2KxaNz58g7Ofg)\n\n400?",
          "score": 11,
          "created_utc": "2026-02-23 09:12:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6veypo",
          "author": "Enshitification",
          "text": "![gif](giphy|Ki9S8uve2xWx2)\n\nI salute you.",
          "score": 50,
          "created_utc": "2026-02-23 00:51:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6x4aje",
          "author": "EirikurG",
          "text": "based",
          "score": 10,
          "created_utc": "2026-02-23 08:16:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6z1g3g",
              "author": "foxontheroof",
              "text": "on what? ü§ì",
              "score": 3,
              "created_utc": "2026-02-23 16:17:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6w4itb",
          "author": "No-Expression6444",
          "text": "give the man credit, he knows what he wants.",
          "score": 20,
          "created_utc": "2026-02-23 03:28:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xiggm",
              "author": "asianjapnina",
              "text": "lol",
              "score": 1,
              "created_utc": "2026-02-23 10:35:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wufrn",
          "author": "Jealous_Piece_1703",
          "text": "Based game. Hopefully no one know the reference",
          "score": 7,
          "created_utc": "2026-02-23 06:44:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6wx7qt",
              "author": "wyc603",
              "text": "üò≠üò≠üò≠",
              "score": 7,
              "created_utc": "2026-02-23 07:09:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6xmfpu",
              "author": "BELLVH3ART",
              "text": "lol",
              "score": 1,
              "created_utc": "2026-02-23 11:12:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o761j7v",
              "author": "Velocita84",
              "text": "I hope he's just generating the thick students üò≠",
              "score": 1,
              "created_utc": "2026-02-24 17:08:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wvcdl",
          "author": "Upper-Reflection7997",
          "text": "you will eventually have periods of boredom from generating 1girls and run out of ideas. Lately I've been spending too much time on Instagram and Twitter hunting for images and captioning text prompts through qwen3 vl.\n\nhttps://preview.redd.it/6wkkb24zy6lg1.jpeg?width=1440&format=pjpg&auto=webp&s=8d9f8c63fb77716dad0bc9dd6973bef42755ce50\n\n",
          "score": 5,
          "created_utc": "2026-02-23 06:52:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x05ol",
              "author": "ArtificialAnaleptic",
              "text": "Can you explain more about what you just said and how it relates to the image?",
              "score": 7,
              "created_utc": "2026-02-23 07:37:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6x9xhg",
                  "author": "Upper-Reflection7997",
                  "text": "It's simple. Find a image I like. copy and paste it to qwen3 vl. Ask qwen for long description of the image. Copy and paste description as prompt to forge neo/wan2gp for image generation with z image and qwen image 2512.",
                  "score": 8,
                  "created_utc": "2026-02-23 09:12:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6vsyl8",
          "author": "Loose_Object_8311",
          "text": "Mildly hilarious this is being upvoted because I'm sure the anti-gooner, anti-1girl crowd must be downvoting it too. The Goon squad making a strong showing today.¬†",
          "score": 25,
          "created_utc": "2026-02-23 02:16:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ycvds",
              "author": "negrote1000",
              "text": "Those are way worse than the ones that just do it.",
              "score": 2,
              "created_utc": "2026-02-23 14:14:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6xdp1k",
          "author": "SirCrest_YT",
          "text": "It's what truly drives the industry.",
          "score": 4,
          "created_utc": "2026-02-23 09:50:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vj17g",
          "author": "Baddabgames",
          "text": "Came here to goon assume and OP beat me to it. I feel like Papa Doc right after B Rabbit‚Äôs battle rap.",
          "score": 4,
          "created_utc": "2026-02-23 01:16:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yftql",
          "author": "SweetGale",
          "text": "My 1050 Ti 4 GB was more than enough for the retro indie games that I tend to play. I upgraded to a 3060 12 GB when SDXL was released in 2023 and pretty much stopped gaming altogether. Generative AI is so damn addictive! It is the tool I've always wanted. It lets me turn my daydreams into images. It's also the ultimate character creator that lets me find the perfect mix of human, animal, male and female traits that my weird bisexual furry brain finds attractive.",
          "score": 4,
          "created_utc": "2026-02-23 14:30:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yt8dt",
          "author": "shitlord_god",
          "text": "I wasn't expecting OP's level of honesty and candor. \n\nFive stars.",
          "score": 4,
          "created_utc": "2026-02-23 15:38:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6wzufg",
          "author": "TurnOffAutoCorrect",
          "text": "From 2017 to summer 2022 I had an Nvidia 1070 because I don't game that hard. Then I discovered local AI and less than a year later I bought a 4090.",
          "score": 8,
          "created_utc": "2026-02-23 07:34:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x4bed",
              "author": "Loose_Object_8311",
              "text": "When SD1.5 first came out I bought an RTX 3060 12GB VRAM, 3 weeks later I had a 4090. Sadly I had to get rid of it, now I'm back on a 5060 Ti and scheming about how I can RTX 6000 Pro.",
              "score": 5,
              "created_utc": "2026-02-23 08:17:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vldnn",
          "author": "Both-Rub5248",
          "text": "Good luck, mate!\n\n![gif](giphy|HHzBaXsra2MHciRNQr)\n\n",
          "score": 8,
          "created_utc": "2026-02-23 01:30:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yhzzp",
          "author": "Murder_Teddy_Bear",
          "text": "THIS man has the RIGHT IDEA!!",
          "score": 2,
          "created_utc": "2026-02-23 14:42:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yy835",
          "author": "Sushiki",
          "text": "Just wish the newer software worked on amd 6950...   all the amd guide ones just fail. Comfy doesn't want to work. Made me give up after four failed attempts so i went back to using the only thing that does work for me and that is Automatic1111.",
          "score": 2,
          "created_utc": "2026-02-23 16:02:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75pc5f",
              "author": "TheRealCorwii",
              "text": "Have you tried any of the models on Pinokio? Z-Image says it works on AMD cards though I have no idea about the speeds you'll see.\n\nIf you do try Pinokio, you can search for Z-Fusion which offers both Z-Image and Flux modes.\n\nMy times for my RTX 4070 8gb VRAM and 64gb RAM laptop:\n\n1024 resolution - easy 20-25 seconds per image\n\n1280 resolution - roughly 30-45 seconds per image\n\n1536 resolution - roughly 45-55 seconds per image",
              "score": 1,
              "created_utc": "2026-02-24 16:13:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6zv67w",
          "author": "Salnder12",
          "text": "Same, I was really disappointed with online gen AI, ones that could do NSFW were super expensive and had shit prompt adhesion. Once I realized local was a thing I completely understood the hype.\n\n\nBonus that I don't have to destroy the environment to goon",
          "score": 2,
          "created_utc": "2026-02-23 18:34:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o732vtg",
          "author": "thevegit0",
          "text": "bluuuu archivuuuuuu",
          "score": 2,
          "created_utc": "2026-02-24 05:03:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73geji",
          "author": "RBriart",
          "text": "what is the best realism nsfw model rn to train on specific smut lora",
          "score": 1,
          "created_utc": "2026-02-24 06:52:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o753hkz",
          "author": "ConferenceIll417",
          "text": "![gif](giphy|8hsIwPLIGnZ1C)\n\n",
          "score": 1,
          "created_utc": "2026-02-24 14:30:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75mrtz",
          "author": "Velocita84",
          "text": ">blue archive\n\n![gif](giphy|21VTFJTEr1x9ortvO3|downsized)",
          "score": 1,
          "created_utc": "2026-02-24 16:02:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6wkwho",
          "author": "tac0catzzz",
          "text": "oh that is so cool.",
          "score": 1,
          "created_utc": "2026-02-23 05:24:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yudt2",
          "author": "WorthAppearance5866",
          "text": "I just made opensourcegen.com and it‚Äôs free! Check it out if you wanna generate unfiltered, HQ images on the go lol! No signups required!",
          "score": -4,
          "created_utc": "2026-02-23 15:44:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6x79jc",
          "author": "jonbristow",
          "text": "ew",
          "score": -10,
          "created_utc": "2026-02-23 08:46:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ra7pej",
      "title": "I can‚Äôt understand the purpose of this node",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/p661pzbqtpkg1.jpeg",
      "author": "PhilosopherSweaty826",
      "created_utc": "2026-02-20 21:13:03",
      "score": 286,
      "num_comments": 58,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1ra7pej/i_cant_understand_the_purpose_of_this_node/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6i3gie",
          "author": "AgeNo5351",
          "text": "https://preview.redd.it/wrr1ae2q3qkg1.png?width=983&format=png&auto=webp&s=bbde5dc54f655dd514aeaa807fead66f0be01a41\n\nTLDR .   \n1. It changes the **sigma schedule.**   \n2. Use SigmaPreview node from RES4LYF to see what it does.   \n  \nWhen u sample with 20 steps , what happens ? At every step a certain amount of noise is removed. You start from a full noise and in the end you get clean image. This schedule of removing noise is called \"**sigma schedule**\" . All the schedulers you choose (beta, karras, simple) are just different sigma schedules.Sigma\\_value= 1 is full noise. Sigma\\_value = 0 is clean image. \n\nWhat happens when you increase shift. You put more steps is high sigma range. High sigma is where the image is still very noisy and compositional changes can happen. After sigma of 0.75 , the composition has \"settled\" and u only add bit of details. ",
          "score": 453,
          "created_utc": "2026-02-20 22:11:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6i4ixf",
              "author": "Strange-Knowledge460",
              "text": "Thank you, you explain this very well.  I never understood sigma  untill your explanation.",
              "score": 53,
              "created_utc": "2026-02-20 22:17:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6ihkfn",
              "author": "Major_Specific_23",
              "text": "Just to add, if you want to use a low shift value, make sure you use an ancestral sampler because models like z image turbo barely do anything at sigma values below 0.5. eta parameter gives the model something to chew on otherwise you get some blocky patches",
              "score": 14,
              "created_utc": "2026-02-20 23:28:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6ke722",
                  "author": "alb5357",
                  "text": "That sounds interesting, but I don't understand",
                  "score": 4,
                  "created_utc": "2026-02-21 07:22:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6i58ob",
              "author": "Delvinx",
              "text": "This is a stellar way of explaining it. Very straight forward.",
              "score": 29,
              "created_utc": "2026-02-20 22:21:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6luxwl",
              "author": "msixtwofive",
              "text": "It's so rare to see anyone properly explain what these settings and concepts ctually are, all while not either just linking directly to papers or dumbing it down so far it make as just be \"too low number meh, too high number eww\".  Kudos.",
              "score": 9,
              "created_utc": "2026-02-21 14:44:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6iewpk",
              "author": "TheRedHairedHero",
              "text": "The sigma values will also differ based on the sampler you choose and the amount of steps. For WAN 2.2 there's a sigma threshold that's suggested to swap from the high sampler to the low sampler. I2V is 0.9 and T2V is 0.875 according to the official WAN documentation. If you use Kijai's wrapper it outputs the sigmas in the console.",
              "score": 6,
              "created_utc": "2026-02-20 23:13:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6kth2b",
              "author": "IrisColt",
              "text": "so... what does a shift of 8 mean exactly?",
              "score": 3,
              "created_utc": "2026-02-21 09:52:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6l67eh",
                  "author": "Rhaedonius",
                  "text": "It's the value you use in the formula. It has no more meaning than asking \"what does b mean in cos(ax-b)\". It's the shift parameter. Higher means more high sigma, lower means more low sigma. The amount changes for each scheduler, if I remember correctly for simple and sigma=1.13 you get constant decreases (i.e. a straight line)",
                  "score": 5,
                  "created_utc": "2026-02-21 11:53:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6iftjh",
              "author": "Psylent_Gamer",
              "text": "Kijai has one in his node pack as well.",
              "score": 1,
              "created_utc": "2026-02-20 23:18:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6kw8y0",
              "author": "FartingBob",
              "text": "So what is the range that it works in? What is the default comfyui uses when you dont use the node, and what are the recommended ranges? Or is that checkpoint specific? From your explanation it sounds like higher numbers will result in more variety in poses, subjects etc while smaller numbers would mean less variety but maybe more fine details? But again, what are considered big and small numbers here?",
              "score": 1,
              "created_utc": "2026-02-21 10:19:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6m9ndf",
                  "author": "AgeNo5351",
                  "text": "What you say is quite correct. The acceptable range values depend on the model and its ability to denoise across large jumps. If you put too many sigma is high , then u have only few sigmas to reach 0 and model has to make large sigma jumps, if you keep number of steps constant.  \nALso depends on how the models were trained.   \nFor example  there are workflows with WAN+speed lora that use shifts as high as 22.  \nThe default scheduler for KLEIN is FLUX2Scheduler, which is very top-heavy. If you want to replicate that with beta scheduler you might push shifts to 80-100.",
                  "score": 1,
                  "created_utc": "2026-02-21 16:01:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6lkkn0",
              "author": "Elvarien2",
              "text": "excellent way to put it.",
              "score": 1,
              "created_utc": "2026-02-21 13:41:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6nnfw4",
              "author": "flipflapthedoodoo",
              "text": "god thank you",
              "score": 1,
              "created_utc": "2026-02-21 20:11:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6vt7a0",
              "author": "Aye_KTroyyyy_Buildz",
              "text": "It's sounds like advanced sharpen that you'd use for photos, but in this case I guess it applies for noise.",
              "score": 1,
              "created_utc": "2026-02-23 02:17:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6huex9",
          "author": "Quantical-Capybara",
          "text": "You're lucky\nI don't understand the purpose of any node expect load image, save image and prompt. ü§£",
          "score": 87,
          "created_utc": "2026-02-20 21:26:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6i7xim",
              "author": "ZCEyPFOYr0MWyHDQJZO4",
              "text": "https://preview.redd.it/zw67hgve8qkg1.jpeg?width=500&format=pjpg&auto=webp&s=490511df7e3040afab28ff962e4bf7c2cdf56919\n\n",
              "score": 35,
              "created_utc": "2026-02-20 22:35:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6i68s7",
              "author": "shogun_mei",
              "text": "That was also my very first impression lol\n\n\"What a heck is ksampler? Why k?\"\n\nAnd I still don't know",
              "score": 13,
              "created_utc": "2026-02-20 22:26:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6ir91y",
                  "author": "grae_n",
                  "text": "Fun fact it originates from k-diffusion from [https://github.com/crowsonkb](https://github.com/crowsonkb) \n\nSo the K might actually stands for Katherine",
                  "score": 14,
                  "created_utc": "2026-02-21 00:24:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6ibuqt",
                  "author": "BigNaturalTilts",
                  "text": "‚ÄúAI is ruining our brains‚Äù\n\nBitch I would‚Äôve googled what a k-sampler is and still ignored the long explanation same way I did after asking chat gpt to explain it to me.",
                  "score": 7,
                  "created_utc": "2026-02-20 22:56:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6k2i58",
                  "author": "SDSunDiego",
                  "text": "K's Sampler",
                  "score": 1,
                  "created_utc": "2026-02-21 05:38:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6ie5r2",
                  "author": "Tystros",
                  "text": "it's just an old name that has no meaning any more today I think. because some of the settings on a ksampler actually turn it into a not-k sampler.",
                  "score": 1,
                  "created_utc": "2026-02-20 23:09:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6hvznk",
              "author": "Separate_Height2899",
              "text": "Don't worry, nobody does.",
              "score": -5,
              "created_utc": "2026-02-20 21:34:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6iaj4s",
          "author": "goodie2shoes",
          "text": "i once set it to 42 by accident and then I became enlightened ",
          "score": 28,
          "created_utc": "2026-02-20 22:49:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6p70jh",
              "author": "ConferenceIll417",
              "text": "sorry , what was your question again ?",
              "score": 1,
              "created_utc": "2026-02-22 01:29:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6hu6sd",
          "author": "WildSpeaker7315",
          "text": "It shifts the timestep schedule so the model samples differently during diffusion. Basically it's telling the model to stop being so dramatic in the early steps and chill out a bit. The default is 3 for SD3, someone decided 8 is better for some reason, probably a guy on Reddit who dreamed it and everyone just copied it. Does it do anything? Yes. Can anyone properly explain why? No. Just leave it at 8 and pretend you understand it",
          "score": 56,
          "created_utc": "2026-02-20 21:25:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6igeu6",
              "author": "tom-dixon",
              "text": "> Can anyone properly explain why? No.\n\nYes. Watch this: https://youtu.be/egn5dKPdlCk\n\nIt's 15 minutes, but it explains everything there is to know about the sigma schedule in a visual way.",
              "score": 17,
              "created_utc": "2026-02-20 23:21:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6nj0fb",
                  "author": "shroddy",
                  "text": "Do you know a similar video explanation about the different samplers? Like what they really do...",
                  "score": 1,
                  "created_utc": "2026-02-21 19:48:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6ih2py",
              "author": "rukh999",
              "text": "Turn on the sampler preview if you want to see what it does.\n\n\nBasically it changes how much time it spends on high noise vs low. Turning it up makes the sampler spend more time on the big overall design. Can be helpful to spend more time there if you're getting things like extra arms. Also if you see by the preview your sampler is basically spending half the render doing nothing. (Or turn down steps). Alternatively if you want it to spend more time on fine details turn it down.\n\n\n\nIf you're able to see real-time what it's doing you can adjust it correctly, not just by rule of thumb.\n\nI've noticed something like Flux Klein can overdo it if you let it spend too much time on low steps, starts adding weird extra textures and stuff.",
              "score": 13,
              "created_utc": "2026-02-20 23:25:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6hygpf",
              "author": "dishrag",
              "text": "I wrote a similar explanation about something else the other day. It‚Äôs not exactly a novel theory, and I‚Äôm sure someone else has explained it better, but I think it fits here:  \n  \n\n1.  The nonsense is first extracted from one of the group members‚Äô asses.\n\n2.  It is then passed around between the group members *ad infinitum* until no one can remember which ass it first poured forth from. All they *think* they understand is that it‚Äôs an **absolute truth**.",
              "score": 20,
              "created_utc": "2026-02-20 21:46:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6hzgtg",
                  "author": "PwanaZana",
                  "text": "https://preview.redd.it/9ljcpgik0qkg1.png?width=556&format=png&auto=webp&s=5981f40e166ca3ac81e4cad7d20b6b5e711bc310\n\ngood goooooood",
                  "score": 14,
                  "created_utc": "2026-02-20 21:51:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6i59ky",
                  "author": "Intelligent-Youth-63",
                  "text": "You just described a large chunk of my career.",
                  "score": 8,
                  "created_utc": "2026-02-20 22:21:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6oc2gu",
                  "author": "Arkanta",
                  "text": "It feels like the CLI args you see for games like Counter Strike \n\n\"-Noyoj\" gives a 2 fps boost. Meanwhile valve devs say that this code has been removed 8 years ago",
                  "score": 1,
                  "created_utc": "2026-02-21 22:22:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6i3lxx",
              "author": "a_beautiful_rhind",
              "text": "I did a/b runs on distilled models and end up just omitting it. Maybe it does more if you're doing many steps.",
              "score": 1,
              "created_utc": "2026-02-20 22:12:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6i604k",
              "author": "NomisGn0s",
              "text": "lol this whole explanation made me laugh out loud",
              "score": 1,
              "created_utc": "2026-02-20 22:25:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6iieqo",
              "author": "Etsu_Riot",
              "text": ">Just leave it at 8 and pretend you understand it\n\nI agree with the sentiment, bit i haven't used 8 in ages.",
              "score": 1,
              "created_utc": "2026-02-20 23:33:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6hzio8",
              "author": "Dogmaster",
              "text": "So this is why in distilled models with less steps this is causing some blurry outputs in upscale/face detailer then...!",
              "score": 0,
              "created_utc": "2026-02-20 21:51:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6i5ctt",
          "author": "DaxFlowLyfe",
          "text": "With wanvideo at least.  The higher the number the more motion you get.",
          "score": 8,
          "created_utc": "2026-02-20 22:21:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hwoix",
          "author": "Jamsemillia",
          "text": "i always thought this says \"stick this much to the startimage\" in i2v. I've had bad movement at high values and hallucinating at low ones. now essentially perma at 6 for anything wan2.2.\n\nbut this could be very wrong - i dunno rly",
          "score": 3,
          "created_utc": "2026-02-20 21:37:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ij0du",
              "author": "Etsu_Riot",
              "text": "It's a bit like alchemy, you stay with what it worked once. To me is at 3 or 5.",
              "score": 5,
              "created_utc": "2026-02-20 23:36:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vnman",
          "author": "ModFrenzyAI",
          "text": "As far as I understood it from my generations with WAN2.2, higher shift means more motion at the loss of visual fidelity. Some actions (NSFW ones for example), only work well with 8.00 shift. At 5.00 shift or lower, many motions become very stiff. ",
          "score": 3,
          "created_utc": "2026-02-23 01:44:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ke5s1",
          "author": "AnOnlineHandle",
          "text": "If you're using 5 steps the model might do diffusion at noises like 99%, 75%, 50%, 25%, 0%, depending on the scheduler.\n\nYou can shift the noise distribution to have more steps be in the high noise composition stage and less in the fine details stage, so something like: 99%, 80%, 70%, 30%, 0%.\n\nIn theory the higher resolution, the more time it should spend in high noise stages, as more of the overall structure of a 1024x1024 image should be already clear at say 80% noise than it would be in a 124x124 image, and so the model should have more steps focused there.",
          "score": 2,
          "created_utc": "2026-02-21 07:21:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ht3ls",
          "author": "Neggy5",
          "text": "basically higher numbers have more \"variance\" between seeds. lower looks samey between seeds. at least with Z-Image. With video models, i think it affects motion amount?\n\ncorrect me if im wrong, guys",
          "score": 7,
          "created_utc": "2026-02-20 21:19:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6hzg0b",
              "author": "story_of_the_beer",
              "text": "I like how people choose to down vote rather than explain what's wrong lol",
              "score": 20,
              "created_utc": "2026-02-20 21:51:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6ixsvc",
                  "author": "ArkCoon",
                  "text": "gatekeeping the knowledge for themselves..\n\nanyways.. I watched a video on this a while back and from what I understand (and I'm not totally sure, so correct me if I'm wrong), shift basically moves the denoising schedule forward or backward.\n\nSo instead of changing how much the model denoises overall, it changes when certain parts of the denoising happen. You‚Äôre kind of shifting the whole \"noise -> clean image\" curve left or right.\n\nIn videos, that can show up as more or less motion depending on how early the structure gets locked in. In images, shifting it one way can make the model commit to the overall structure earlier (which can give a stronger, more stable composition but less flexibility), while shifting it the other way keeps things noisy for longer (which can sometimes give more variation, texture, or slightly less stability).\n\nThat‚Äôs just my understanding though, but I might be oversimplifying it",
                  "score": 2,
                  "created_utc": "2026-02-21 01:02:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6i64cm",
              "author": "AgeNo5351",
              "text": "That is more a consequence of  the distilled nature of Z-image(ZIT). Increasing the shift puts more steps in high sigma zone . In the high sigma zone when the image still is a lot of noise, compositional changes can happen.  \nThough for a non-distilled model, if you change the seed, you change the initial noise entirely so the image should be different.   \nDue to distilled nature of ZIT , seed variance is hugely suppressed , so forcing the sampling to spend steps in high sigma can enforce a newer composition.",
              "score": 4,
              "created_utc": "2026-02-20 22:25:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6i6ksz",
                  "author": "Neggy5",
                  "text": "thanks for the clarification :D",
                  "score": 1,
                  "created_utc": "2026-02-20 22:28:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6n56k3",
              "author": "KaineGe",
              "text": "You said something about it which I understand so I will try it with this in mind. \n\n",
              "score": 1,
              "created_utc": "2026-02-21 18:38:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ln3z8",
          "author": "Hopeful_Signature738",
          "text": "I think I manage to understand it in laymen terms. Basically Each scheduler (euler, simple, etc) have their own way to interpret how the image looks like. Depending on steps used (4,8,20,etc), Some focus on composition (better understanding of prompt, no extra limbs, etc), and some focus on adding details. Shift on the ModelSampling SD3 node will tweak the scheduler. Hence, change the final output. Increase it, it will improve the composition, decrease it, It will improve the details. If you generate image/video, using 4 or 8 steps. Its important for you to find it's sweet spot. Anyway, it just an extra node to help you out. If the scheduler on it own can get the image/video to your liking, just disable it.",
          "score": 1,
          "created_utc": "2026-02-21 13:57:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6n5g1a",
          "author": "KaineGe",
          "text": "The first workflow I noticed it is Ace Step 1.5, I never noticed it in other workflows and templates but I see in the coments that people used shift for a lot of things (images, videos...)",
          "score": 1,
          "created_utc": "2026-02-21 18:40:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sxmmf",
              "author": "Acceptable_Secret971",
              "text": "Speaking of Ace Step 1.5, I'm a bit confused about the different models.\n\nThere is Base, SFT, Turbo and even SFT Turbo. Aren't perhaps SFT models just Base and Turbo with pre-appliead Shift? If that is the case maybe I don't need any models bedsides base and Turbo as Shift can be turned on and off (as well as have it's value changed) in Comfy?",
              "score": 1,
              "created_utc": "2026-02-22 17:16:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6w5j9e",
          "author": "Old_System7203",
          "text": "I wrote a bunch of stuff about shift and sigma etc, and a few nodes to help you explore them.\n\nhttps://github.com/chrisgoringe/cg-sigmas",
          "score": 1,
          "created_utc": "2026-02-23 03:34:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6j37rf",
          "author": "diogodiogogod",
          "text": "It took me forever to understand this, but I finally did because shift works to change Wan high and low models for example. You can calculate shift to change at a specific step. So it basically controls this high and low noise removal behavior.",
          "score": 1,
          "created_utc": "2026-02-21 01:36:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6k2cd5",
          "author": "rinkusonic",
          "text": "Fun fact , before the name change, it was named ligma schedule.",
          "score": 1,
          "created_utc": "2026-02-21 05:37:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9kikw",
      "title": "Tired of civitai Removing models/loras l build RawDiffusion",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1r9kikw/tired_of_civitai_removing_modelsloras_l_build/",
      "author": "AIPnely",
      "created_utc": "2026-02-20 03:31:11",
      "score": 280,
      "num_comments": 141,
      "upvote_ratio": 0.92,
      "text": "I created **RawDiffusion** as a dependable alternative and backup platform for sharing AI models, LoRAs, and generations. The goal is to give creators a stable place to host and distribute their work so it stays accessible and isn‚Äôt lost if platforms change policies or remove content.\n\nWhat it offers:\n\n* Upload and archive models safely\n* Fast access and downloads\n* Creator-focused hosting\n* Built for the AI community\n\nIf you publish models or rely on them, this can act as a second home for your files and projects. Feedback is welcome while the platform grows.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1r9kikw/tired_of_civitai_removing_modelsloras_l_build/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "o6dahkq",
          "author": "Enshitification",
          "text": "It would be great if you also seeded the models you host and provided magnet links. Decentralized storage is ultimately more robust than any individual entity.",
          "score": 79,
          "created_utc": "2026-02-20 04:38:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dal07",
              "author": "AIPnely",
              "text": "True good idea for the future ",
              "score": 25,
              "created_utc": "2026-02-20 04:38:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6dexpr",
                  "author": "the_friendly_dildo",
                  "text": "Honestly, running this as a seedbox is probably the only economical way to manage this.",
                  "score": 45,
                  "created_utc": "2026-02-20 05:11:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6drq8f",
          "author": "acbonymous",
          "text": "What we need is a site that uses only magnet links. That means no heavy traffic or storage needed for the site (it just has the descriptions and sample images).",
          "score": 25,
          "created_utc": "2026-02-20 06:59:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6e5ic3",
              "author": "Loose_Object_8311",
              "text": "Better yet it just has a bunch of shady looking links, no sample images.¬†",
              "score": 8,
              "created_utc": "2026-02-20 09:08:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6kz7td",
                  "author": "tindalos",
                  "text": "And porn ads and pop ups.",
                  "score": 3,
                  "created_utc": "2026-02-21 10:48:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6fxkmb",
              "author": "very_personal_",
              "text": "Hmmm. It‚Äôs just a thought but what about a ComfyUI add on that hosts a torrent client that advertises all the models in your model folders. This would pretty quickly make all models available to everyone outside of official hosting channels.",
              "score": 1,
              "created_utc": "2026-02-20 16:03:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6g4llm",
                  "author": "acbonymous",
                  "text": "Not a bad idea, but it would probably be better to keep it separate from comfyui. Sharing torrents can be left running permanently, even if comfy is not.",
                  "score": 2,
                  "created_utc": "2026-02-20 16:35:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6h3qjn",
                  "author": "nihnuhname",
                  "text": "Some checkpoints or LoRA's should be private",
                  "score": 2,
                  "created_utc": "2026-02-20 19:15:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6d1hdj",
          "author": "an80sPWNstar",
          "text": "URL?",
          "score": 29,
          "created_utc": "2026-02-20 03:35:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6d1tba",
              "author": "AIPnely",
              "text": "[https://rawdiffusion.com/](https://rawdiffusion.com/)",
              "score": 37,
              "created_utc": "2026-02-20 03:38:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6dbfer",
                  "author": "Ynead",
                  "text": "Being presented with 50+ porn GIFs all at once after the site stutters is honestly pretty hilarious.\n\nSeriously though: how do you plan to support this site (and the massive amount of storage required) if it gains traction? Aren't you concerned about running into the same payment processor issues that Civitai faced?",
                  "score": 66,
                  "created_utc": "2026-02-20 04:44:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6d2lt5",
                  "author": "an80sPWNstar",
                  "text": "That's pretty amazing. Any worries/fears about celebrity / copyrighted stuff?",
                  "score": 4,
                  "created_utc": "2026-02-20 03:43:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6d3wfi",
          "author": "Moliri-Eremitis",
          "text": "How are you planning on paying for the hosting costs?",
          "score": 23,
          "created_utc": "2026-02-20 03:51:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6d43ov",
              "author": "AIPnely",
              "text": "up to 10TB of loras/modals after that might do ads or donation for storage ",
              "score": 7,
              "created_utc": "2026-02-20 03:53:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6d8unx",
                  "author": "General_Session_4450",
                  "text": "10TB of storage or traffic? The largest cost of hosting these models publicly by far is egress traffic\n\nI think 10TB of storage will fill up pretty quick if your site becomes popular as well. I'm at 60TB for checkpoints/loras just for my personal collection and CivitAI is at around 350TB of public models.",
                  "score": 41,
                  "created_utc": "2026-02-20 04:26:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6eaqaw",
          "author": "Opening_Boat697",
          "text": "are you really are you really adding models manually? you just added mine , that platform seems very similar to civarchive, why youre not creating users with the correct username at least? youre adding my loras as \"admin\" user? why admin? XD  \nare you planing to add the user? i mean i add my nicknake to my models and files but.. this doesnt feel nice.. im K3NK, this damn crapddit wont update my nametag..",
          "score": 10,
          "created_utc": "2026-02-20 09:57:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ff7yi",
              "author": "AIPnely",
              "text": "Users will be created soon from civitai which you can claim and control the content",
              "score": 2,
              "created_utc": "2026-02-20 14:34:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ded02",
          "author": "Yprox5",
          "text": "What would I do without reverse deepthroat.",
          "score": 15,
          "created_utc": "2026-02-20 05:06:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dajl6",
          "author": "Spara-Extreme",
          "text": "Civitai archive ?",
          "score": 8,
          "created_utc": "2026-02-20 04:38:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dao1o",
              "author": "AIPnely",
              "text": "this is focus on nsfw loras and models",
              "score": 0,
              "created_utc": "2026-02-20 04:39:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6dd6gg",
                  "author": "Spara-Extreme",
                  "text": "I mean that archive also shows everything banned from civit ai.",
                  "score": 11,
                  "created_utc": "2026-02-20 04:58:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ef4j8",
          "author": "Michoko92",
          "text": "I clicked the link and... wow. It was brutal lol. Maybe you could add an NSFW tag?",
          "score": 7,
          "created_utc": "2026-02-20 10:38:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fi2qr",
              "author": "AIPnely",
              "text": "I will add a model to accept where you're getting into",
              "score": 0,
              "created_utc": "2026-02-20 14:49:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6eqcp7",
          "author": "Radiant-Photograph46",
          "text": "Add a toggle to not autoplay gif/videos => good for motion sensitive folks, reduce bandwidth, better performance.",
          "score": 8,
          "created_utc": "2026-02-20 12:08:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6d83gz",
          "author": "sometimes_ramen",
          "text": "A link back to Civitai or Huggingface as well as the original creator's name somewhere on the reuploads would be great. Maybe something like how CivArchive does it, that way you can easily find a creator's other content.",
          "score": 6,
          "created_utc": "2026-02-20 04:20:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6d8s5t",
              "author": "AIPnely",
              "text": "usually creator names donations links etc all stay there ",
              "score": 1,
              "created_utc": "2026-02-20 04:25:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6da8kg",
                  "author": "sometimes_ramen",
                  "text": "Is an account needed to see that or something? I'm mostly just talking about things uploaded by the Admin account where it doesn't seem to show the original creator's name unless they just happened to insert it in the title of their upload like K3NK usually does or in their description.",
                  "score": 1,
                  "created_utc": "2026-02-20 04:36:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6do0or",
          "author": "Diabolicor",
          "text": "A decentralized P2P storage solution would definitely be better and make storage basically unlimited.",
          "score": 11,
          "created_utc": "2026-02-20 06:26:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6eb053",
              "author": "FartingBob",
              "text": "You still need one copy on a server as im guessing most models that arent at the top of search results will have very low/inconsistent numbers of seeders and slow speeds. Offering torrent links is absolutely a win win but i dont think it can *replace* the need for having a centralised server as well in this case without a lot of models dropping off the grid.",
              "score": 3,
              "created_utc": "2026-02-20 10:00:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6ffk3n",
                  "author": "addandsubtract",
                  "text": "Lots of trackers have 10y+ old niche content that is still being seeded. As long as there's a demand/interest in the content, it'll be seeded.",
                  "score": 1,
                  "created_utc": "2026-02-20 14:36:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6fglrg",
              "author": "AIPnely",
              "text": "I am working on implementing torrent in the future",
              "score": 2,
              "created_utc": "2026-02-20 14:41:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6dirs7",
          "author": "RepresentativeRude63",
          "text": "I think we need old style forum pages just for ai stuff. Nothing to store in servers old school share file links. Topics and stuff will organized etc. sometimes going back to basics is good.",
          "score": 8,
          "created_utc": "2026-02-20 05:41:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6msi9y",
              "author": "Belember",
              "text": "Usenet for storage of models. ",
              "score": 1,
              "created_utc": "2026-02-21 17:36:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6d5f2v",
          "author": "jditty24",
          "text": "Very cool! Just signed up and thank you for doing this. It‚Äôs a big deal and cool to see someone take something like this on.",
          "score": 4,
          "created_utc": "2026-02-20 04:02:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ed58r",
          "author": "danielriley123",
          "text": "This is a real problem and it's only going to get worse as the legal landscape gets messier. Smart move building an alternative. For anyone worried about losing access to models they depend on, just download everything you actively use. Don't assume any platform will keep hosting it forever. I keep local copies of every LoRA and checkpoint I use in production. It's annoying to manage storage but way less annoying than discovering your whole workflow is broken because a model got pulled with no warning.",
          "score": 4,
          "created_utc": "2026-02-20 10:20:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fda6g",
          "author": "Choice_Celery9481",
          "text": "i wonder if you know about civarchive",
          "score": 5,
          "created_utc": "2026-02-20 14:24:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6daqbi",
          "author": "AIPnely",
          "text": "In the upload there is a import from civitai with the id ",
          "score": 3,
          "created_utc": "2026-02-20 04:39:52",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o6dyk2a",
          "author": "fauni-7",
          "text": "Cool. Better have a modal before entering perhaps \"click OK\" or whatever, or require registration before showing XXX, as it's kinda NSFW.",
          "score": 3,
          "created_utc": "2026-02-20 08:02:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fg5ov",
              "author": "AIPnely",
              "text": "Good idea",
              "score": 1,
              "created_utc": "2026-02-20 14:39:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6g741t",
          "author": "gelatinous_pellicle",
          "text": "So, civarchive.com ?",
          "score": 3,
          "created_utc": "2026-02-20 16:46:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gqvhy",
          "author": "Free_Scene_4790",
          "text": "If Sarah Petersons starts uploading stuff here, then the page is going to crash soon, dude xd",
          "score": 3,
          "created_utc": "2026-02-20 18:17:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6gw4w3",
              "author": "q5sys",
              "text": "Already a bunch of Sarah\\_Peterson on there that I see.",
              "score": 1,
              "created_utc": "2026-02-20 18:40:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6d2yk6",
          "author": "the_bollo",
          "text": "Interesting to see my models on there already...",
          "score": 6,
          "created_utc": "2026-02-20 03:45:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6d37g5",
              "author": "AIPnely",
              "text": "civitai will be removing most nsfw models soon",
              "score": 4,
              "created_utc": "2026-02-20 03:47:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6e29ox",
                  "author": "Choowkee",
                  "text": "What? What is the source for this claim?",
                  "score": 9,
                  "created_utc": "2026-02-20 08:37:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6ebehl",
                  "author": "FartingBob",
                  "text": "I think the person is saying you/someone else have uploaded their model without permission. Care to address that?",
                  "score": 3,
                  "created_utc": "2026-02-20 10:03:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6d6aq1",
              "author": "OneMoreLurker",
              "text": "Same here, one of mine was literally the first result.",
              "score": 2,
              "created_utc": "2026-02-20 04:08:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6f4hp2",
          "author": "imnotabot303",
          "text": "The first page of the site immediately looks like a porn site.\n\nThis is just going to be a copy of Civitai only worse. Plus the site looks vibe coded so I don't know what your web dev and backend skills are like but if they are not good then you're going to eventually run into problems.\n\nThe biggest issue with something like Civitai imo isn't that models vanish as people can always have their own backup, it's the complete lack of curation. \n\nPeople just spam Civitai with slop and as soon as the gooners start using your site it will just be another AI site where 99% of the content is low effort smut. I'm not against AI porn but it does turn a lot of people away from these sites and means your site will fill up with useless low effort models very quickly.\n\nIf you want to do something different than just a Civitai backup site then a site with a lot more curation and a focus on art tools and some kind of torrent system would be better.",
          "score": 5,
          "created_utc": "2026-02-20 13:37:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e93bc",
          "author": "Past_Crazy8646",
          "text": "No celebs. Nah, pass. Self-censorship is silly and you could easily offer that. I share celeb lora packs all the time.",
          "score": 6,
          "created_utc": "2026-02-20 09:42:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f9cak",
              "author": "Aromatic-Low-4578",
              "text": "Why? What do you get out of it?",
              "score": 2,
              "created_utc": "2026-02-20 14:03:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6d1hys",
          "author": "AIDivision",
          "text": "Link?",
          "score": 2,
          "created_utc": "2026-02-20 03:36:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6exhef",
          "author": "Ill_Ease_6749",
          "text": "please dont add that buzz bullshit and all",
          "score": 2,
          "created_utc": "2026-02-20 12:56:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fhy7v",
              "author": "AIPnely",
              "text": "Yeah no adding any of that",
              "score": 2,
              "created_utc": "2026-02-20 14:48:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6g49ty",
          "author": "wumr125",
          "text": "Civit is filled with images and loras of gaping assholes, extremely graphic images, veiney penises, dangerously young looking girls, rape imagery and all sorts of extreme NSFW content\n\n\nThey removed my image of a cat farting (it just had green fumes, no orifices or anything graphic) for being too graphic and shadowbanned my account \n\n\nThey are hypocrites of the highest order",
          "score": 2,
          "created_utc": "2026-02-20 16:33:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6g565v",
          "author": "TekeshiX",
          "text": "Gonna let these here to add on this new website, guess they are useful for containing lots of good LoRAs that were already deleted from Civitai  \n\\- [https://cnb.cool/shadow-2025/nsfw114](https://cnb.cool/shadow-2025/nsfw114)  \n\\- [https://huggingface.co/mega281/lora/tree/main](https://huggingface.co/mega281/lora/tree/main)\n\nGood luck, I really want to see more competitors against Civitai that lately turned into pretty much trash.  \nOther websites are even worse (TensorArt, Seaart etc.), so yea...\n\nUploading quality workflows into the \"Workflows\" section would be nice too.",
          "score": 2,
          "created_utc": "2026-02-20 16:37:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dr2mc",
          "author": "Disastrous-Agency675",
          "text": "this is great an all but just an fyi im pretty sure theres legal risk to certain models being made and thats why they delete them",
          "score": 4,
          "created_utc": "2026-02-20 06:53:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fghe5",
              "author": "AIPnely",
              "text": "We are focusing on loras checkpoint we have a few but checkpoint usually don't get removed",
              "score": 1,
              "created_utc": "2026-02-20 14:40:53",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6j6w4v",
              "author": "EternalBidoof",
              "text": "celebs and public figures carry a civil liability, everything else is removed due to payment processors being prudes",
              "score": 1,
              "created_utc": "2026-02-21 01:59:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6dol3k",
          "author": "wh33t",
          "text": "How does one filter by model type? How do I just see Qwen LoRA's for example? How do I see just SDXL?",
          "score": 1,
          "created_utc": "2026-02-20 06:31:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dul64",
              "author": "GalaxyTimeMachine",
              "text": "You can either run a search first, and then you get the option to add filters on the left, or click the \"Models\" tab (top left) to see the filters.\n\nhttps://preview.redd.it/iyofiop6qlkg1.png?width=284&format=png&auto=webp&s=4ca4b27706243aaa355a87f1b737431f9f4141a1\n\n",
              "score": 1,
              "created_utc": "2026-02-20 07:26:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6fq1yd",
          "author": "yellowstripescad",
          "text": "[ Removed by Reddit ]",
          "score": 1,
          "created_utc": "2026-02-20 15:27:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6k8r1m",
          "author": "yallapapi",
          "text": "So real question what is the point of using this over civitai",
          "score": 1,
          "created_utc": "2026-02-21 06:32:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6m1k61",
              "author": "AIPnely",
              "text": "find model that are remove from civitai",
              "score": 1,
              "created_utc": "2026-02-21 15:20:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6kxt46",
          "author": "PsychoLogicAu",
          "text": "Thanks, I've been looking for a new home since Civitai started unpublishing my models, and Tensor . art is... just awful.  \nThe upload function seems to be broken though. I have tried to add my model here [https://rawdiffusion.com/models/lustful-pony](https://rawdiffusion.com/models/lustful-pony)\n\nThe checkpoint seems to have failed to upload, and none of the 20 images I attached are anywhere to be seen either",
          "score": 1,
          "created_utc": "2026-02-21 10:35:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6n4wm6",
          "author": "WordSaladDressing_",
          "text": "Doing the lord's work.",
          "score": 1,
          "created_utc": "2026-02-21 18:37:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dgm0l",
          "author": "Zaic",
          "text": "Should we move torrent based hosting ?",
          "score": 1,
          "created_utc": "2026-02-20 05:24:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hvqvz",
          "author": "GifCo_2",
          "text": "Great we can add this to the list of 300 other sites doing the same thing",
          "score": 0,
          "created_utc": "2026-02-20 21:32:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6i2sxe",
              "author": "AIPnely",
              "text": "Yeah don't use it",
              "score": 2,
              "created_utc": "2026-02-20 22:08:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6i3t3b",
                  "author": "GifCo_2",
                  "text": "Nobody will use it.",
                  "score": 2,
                  "created_utc": "2026-02-20 22:13:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6dysvt",
          "author": "mallibu",
          "text": "CivitAI is really busting balls lately and I used to adore it",
          "score": -2,
          "created_utc": "2026-02-20 08:05:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7u51w",
      "title": "ComfyUI Video to MotionCapture using comfyui and bundled automation Blender setup(wip)",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/z63lv3j7s6kg1",
      "author": "Plenty_Big4560",
      "created_utc": "2026-02-18 05:10:47",
      "score": 271,
      "num_comments": 30,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1r7u51w/comfyui_video_to_motioncapture_using_comfyui_and/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o603km9",
          "author": "Plenty_Big4560",
          "text": "Repo link - https://github.com/AKASubaz/ComfyUI-Video2MotionCapture.git",
          "score": 6,
          "created_utc": "2026-02-18 05:13:01",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o60coy3",
          "author": "PinkMelong",
          "text": "and it doesn't track, the hand, fingers?",
          "score": 3,
          "created_utc": "2026-02-18 06:24:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o66a7ds",
              "author": "Plenty_Big4560",
              "text": "No it doesn‚Äôt track fingers",
              "score": 1,
              "created_utc": "2026-02-19 02:42:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o60d1l0",
          "author": "AlexGSquadron",
          "text": "Wow this is very interesting ü§îü§îüòÄ immediately my brain for game development",
          "score": 3,
          "created_utc": "2026-02-18 06:27:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63bfbg",
          "author": "Frequent_BSOD",
          "text": "RemindMe! 6 months",
          "score": 2,
          "created_utc": "2026-02-18 17:49:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63bjk7",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 6 months on [**2026-08-18 17:49:54 UTC**](http://www.wolframalpha.com/input/?i=2026-08-18%2017:49:54%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/StableDiffusion/comments/1r7u51w/comfyui_video_to_motioncapture_using_comfyui_and/o63bfbg/?context=3)\n\n[**4 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FStableDiffusion%2Fcomments%2F1r7u51w%2Fcomfyui_video_to_motioncapture_using_comfyui_and%2Fo63bfbg%2F%5D%0A%0ARemindMe%21%202026-08-18%2017%3A49%3A54%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201r7u51w)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 0,
              "created_utc": "2026-02-18 17:50:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o603mk7",
          "author": "Eisegetical",
          "text": "its cool that you're getting something but it looks very very inaccurate. I'd like to see a plate overlay",
          "score": 2,
          "created_utc": "2026-02-18 05:13:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6059nx",
              "author": "redditscraperbot2",
              "text": "A lot of motion capture comes out as garbage and needs cleanup. Looks like an okay base to me.",
              "score": 5,
              "created_utc": "2026-02-18 05:25:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o609bve",
              "author": "Plenty_Big4560",
              "text": "thx for the feedback . motion accuracy is still being refined, and some cleanup is needed compared to Mixamo/FBX ...UE mannequin still needs fixes WIP.\n\nhttps://i.redd.it/j68r726f07kg1.gif\n\n",
              "score": 6,
              "created_utc": "2026-02-18 05:57:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o66otuk",
                  "author": "VanagearDevGuy",
                  "text": "Looks nice and since the mixamo pipeline is working, can just retarget in ue 5.6+ to manny. One extra step but ü§∑‚Äç‚ôÇÔ∏è no biggie. Thanks and will be checking out tomorrow¬†",
                  "score": 1,
                  "created_utc": "2026-02-19 04:12:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6047g3",
          "author": "Lower-Cap7381",
          "text": "this is cool very cool",
          "score": 1,
          "created_utc": "2026-02-18 05:17:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o605s1u",
          "author": "Counting_Stars5415",
          "text": "Thanks bro",
          "score": 1,
          "created_utc": "2026-02-18 05:29:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o607jiw",
          "author": "Upper-Reflection7997",
          "text": "Can something like this be down with wan2gp.",
          "score": 1,
          "created_utc": "2026-02-18 05:43:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o607jnw",
          "author": "redditscraperbot2",
          "text": "This is really cool. The first thing I thought when I saw Sam 3 was that it could be a motion capture tool under the right conditions. I didn‚Äôt think anyone would actually make it work. I can‚Äôt wait to try this.",
          "score": 1,
          "created_utc": "2026-02-18 05:43:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60iwew",
          "author": "Odd-Mirror-2412",
          "text": "Cool! but the UE mannequin version seems to have the wrong retargeting.",
          "score": 1,
          "created_utc": "2026-02-18 07:18:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o66ad9e",
              "author": "Plenty_Big4560",
              "text": "Yaah still working on it üôå",
              "score": 1,
              "created_utc": "2026-02-19 02:43:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o60jza4",
          "author": "Green-Ad-3964",
          "text": "Prince of persia (the first one) comes to mind.\n\n\nVery cool.",
          "score": 1,
          "created_utc": "2026-02-18 07:28:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o66ay8r",
              "author": "Plenty_Big4560",
              "text": "Thanks man",
              "score": 2,
              "created_utc": "2026-02-19 02:46:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o60l0wx",
          "author": "[deleted]",
          "text": "Is it sam3 based?",
          "score": 1,
          "created_utc": "2026-02-18 07:38:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o66aegq",
              "author": "Plenty_Big4560",
              "text": "Yes it is",
              "score": 1,
              "created_utc": "2026-02-19 02:43:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o66kuww",
                  "author": "[deleted]",
                  "text": "Does it track two characters? For scientific couple video purpose.",
                  "score": 1,
                  "created_utc": "2026-02-19 03:46:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o60n5mp",
          "author": "sevenfold21",
          "text": "What if I don't use Mixamo or UE?  How to retarget motion to my own skeleton?",
          "score": 1,
          "created_utc": "2026-02-18 07:57:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61s7m1",
              "author": "slopmachina",
              "text": "Rokoko has a free retarget addon for Blender. I've been using that to retarget GVHMR animations into my custom rig and it works pretty well.",
              "score": 1,
              "created_utc": "2026-02-18 13:26:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o61oofm",
          "author": "Adventurous_Rise_683",
          "text": "There's already a ComfyUI motion capture repi that does that. The problem with that node is that it dampens the motion. Does your repo solve that?",
          "score": 1,
          "created_utc": "2026-02-18 13:06:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68gtes",
              "author": "ant_drinker",
              "text": "Hi! :) I am the author of the comfyui motioncapture repo. I am pretty sure this guy just merged my SAM3 and MotionCapture repos, as well as Aero-Ex's HyMotion to make a little package. Don't see any difference/innovation besides the merging.",
              "score": 2,
              "created_utc": "2026-02-19 13:04:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o66atzm",
              "author": "Plenty_Big4560",
              "text": "Both are similar  it only depends on how GVHMR motion is",
              "score": 1,
              "created_utc": "2026-02-19 02:45:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o643nux",
          "author": "fostes1",
          "text": "can you send workflow",
          "score": 1,
          "created_utc": "2026-02-18 19:55:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o66aw6t",
              "author": "Plenty_Big4560",
              "text": "You can check my repo there is wf",
              "score": 1,
              "created_utc": "2026-02-19 02:46:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6rohx2",
          "author": "Leading_Carrot_3254",
          "text": "Hi THIS LOOKS AWESOME THANKS FOR SHARING, but am having trouble installing the models, not sure where or how to run the python install? sorry bit new to this. Plus i can not seem to get certain nodes to install :\\_  like SaveSMPLAsRiggedFBX AND RetargetSMPLToMixamo? Please can you advise on how to do this? Thanks",
          "score": 1,
          "created_utc": "2026-02-22 13:34:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75vjjc",
          "author": "Space_Objective",
          "text": "This node sees my \"scalp tingling\"",
          "score": 1,
          "created_utc": "2026-02-24 16:41:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8d5lc",
      "title": "AceStep 1.5 - Showdown: 26 Multi-Style LoKrs Trained on Diverse Artists",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/05urin4a4bkg1",
      "author": "marcoc2",
      "created_utc": "2026-02-18 19:45:30",
      "score": 257,
      "num_comments": 86,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1r8d5lc/acestep_15_showdown_26_multistyle_lokrs_trained/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o64dipe",
          "author": "marcoc2",
          "text": "More details:\n\nThis is the config for all trainings:\n\nLearning rate: 0.003\n\nEpochs: 500\n\n\"linear_dim\": 64\n,\n\"linear_alpha\": 128\n,\n\"factor\": -1,\n\n\"decompose_both\": false\n,\n\"use_tucker\": false,\n\n\"use_scalar\": false,\n\n\"weight_decompose\": true,\n\n\"target_modules\": [\n\"q_proj\",\n\"k_proj\",\n\"v_proj\",\n\"o_proj\"\n\nFor most of these examples I used the same prompt as the captions in dataset so I could maximize the reproduction of the trained features. This include bpm, keyscale, time signature, etc\n\nI used this fork/branch: https://github.com/sdbds/ACE-Step-1.5-for-windows/commits/qinglong/ \n\nbut I think the gradio repo already has lokr feature as well\n\nI also want to recommend this repo I tested when doing these tests: https://github.com/koda-dernet/Side-Step\nStep-Step is very good as a standalone lora/lokr trainer.",
          "score": 31,
          "created_utc": "2026-02-18 20:42:30",
          "is_submitter": true,
          "replies": [
            {
              "id": "o64fwa3",
              "author": "Compunerd3",
              "text": "ty for sharing!",
              "score": 7,
              "created_utc": "2026-02-18 20:53:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o680rz1",
              "author": "SeymourBits",
              "text": "Kudos on a very neat, mostly successful experiment! As others have suggested, consider lowering the learning rate for less of a copy effect.\n\nSomewhere out there a greedy music IP lawyer is getting their wings!",
              "score": 5,
              "created_utc": "2026-02-19 11:04:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o64ye9c",
              "author": "deadsoulinside",
              "text": "only 500 epocs?",
              "score": 2,
              "created_utc": "2026-02-18 22:18:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o64ynmy",
                  "author": "marcoc2",
                  "text": "Yep",
                  "score": 2,
                  "created_utc": "2026-02-18 22:19:31",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6aog6j",
              "author": "mrDernet",
              "text": "Thanks for sharing the link to Side-Step. You're doing the lord's work with testing these things!",
              "score": 2,
              "created_utc": "2026-02-19 19:43:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o646wne",
          "author": "suspicious_Jackfruit",
          "text": "This is definitely over trained imo, so use more data with a less aggressive LR perhaps. I know enough of those artists to hear that it's not just taking their style and voice but distinct patterns and sections from the input data. The obvious as I skipped through is lady gaga. It seems to not work very well on the more progressive, jazz genres where it collapses probably due to the non standard key changes and time signatures?\n\nIt's cool but I think these results can be improved.",
          "score": 44,
          "created_utc": "2026-02-18 20:10:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o649sn6",
              "author": "mikiex",
              "text": "I agree, way too much DNA of the actual songs, it sounds halfway between sampling and generating.",
              "score": 21,
              "created_utc": "2026-02-18 20:24:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o64b9ov",
                  "author": "marcoc2",
                  "text": "I have doubts that Ace-Step would learn guitar tone this good like it did to Metallica without a bit of overfit",
                  "score": 2,
                  "created_utc": "2026-02-18 20:31:43",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o648nma",
              "author": "marcoc2",
              "text": "Yes, they can. It is like one week that this model was released. The idea here is a wide picture of the possibilities, and even more, show that lokr may be the new standard enabling us to share/store files of only 4MB and not 83MB (the equivalent for loras)",
              "score": 5,
              "created_utc": "2026-02-18 20:19:17",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o64f02f",
              "author": "ArtfulGenie69",
              "text": "It isn't over trained it is under trained. You want to focus the one artist so that it can understand the band. It gets the voice first then the band second so you need to split your music into stems and take samples of the band and run them as Instrumentals that you can name and also link with the actual songs they came from. With a more focused dataset it would get each a bit better.¬†\n\n\nThis worked well though, not much breakup and it got the bands pretty well. As usual there are tricks for cleaning audio like on distill model you can turn the steps on inference up to 150, on the sft I can crank from 300-500 steps. Things for all of you to try out.¬†",
              "score": 1,
              "created_utc": "2026-02-18 20:49:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o64gtpi",
                  "author": "suspicious_Jackfruit",
                  "text": "What you're describing is a different dataset and data preparation, nothing to do with over/undertraining. This is overtrained on the input data because you can hear motifs and melodies that already exists for those artists. Training longer with this same dataset won't help and will only get worse, so more data and a less aggressive LR is likely to result in better model. Changing the data processing and training data as you suggest will almost certainly be a better methodology though but OP isn't likely doing this.",
                  "score": 7,
                  "created_utc": "2026-02-18 20:57:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o66js2v",
          "author": "bdsqlsz",
          "text": "Thank you for trying! I am the author of Acestep Lokr and Acestep 1.5 for Windows.\n\nI independently implemented Lycoris training and reading on Acestep 1.5, and merged it into the official code. The official author also admitted that Lokr performs better than LoRa!  \nOf course, I have some suggestions regarding parameters. For example, the smaller the factor is, the better. A factor of 1 can achieve a fine-tuning effect, but I think 4 is a better choice.\n\nIn fact, simply setting the factor to 1 is sufficient to achieve near-fine-tuned training results, while the memory usage should not exceed 20GB.\n\nI'm training a Suno distillation model using Lokr, and I expect to release it publicly in three days.",
          "score": 15,
          "created_utc": "2026-02-19 03:39:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o66pxsi",
              "author": "marcoc2",
              "text": "Thank you for your work in this repo. I spent hours training on it. I had some trouble that Claude fixed, so I still have to catch up with new commits, but I had already set up a list of artists I wanted to try before dealing with it.",
              "score": 2,
              "created_utc": "2026-02-19 04:19:19",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o68k4mv",
              "author": "DelinquentTuna",
              "text": "> I'm training a Suno distillation model using Lokr, and I expect to release it publicly in three days.\n\nThat sounds AMAZING!  Any chance you will provide your training data and scripts, please?",
              "score": 2,
              "created_utc": "2026-02-19 13:24:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o681hl4",
              "author": "SeymourBits",
              "text": "I‚Äôm a big fan of Ace 1.5! Looking forward to your new distillation model. Thank you for your efforts and let me know how I can contribute :)",
              "score": 1,
              "created_utc": "2026-02-19 11:10:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o650lre",
          "author": "deadsoulinside",
          "text": "Honestly after training an ace step lora at 1000 epochs on 12 songs with only a 20% genre setting and lora tag. Comparing my results to yours, your results sound terrible. Not trying to be mean here, but hearing that makes me already dismiss LoKr training if that is the best results from that.\n\nI am not sure if that helps produce training faster or not, but I will stick to the traditional LoRas and hours per song training.\n\nSure it mirrors their styles, but some of the songs you posted sounded like they were dragged under mud and just sound horrible.\n\nExample track I done with a Lora trained on one particular artist for example of audio clarity. https://vocaroo.com/1Gz00CquC9EE",
          "score": 13,
          "created_utc": "2026-02-18 22:28:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o651n3d",
              "author": "marcoc2",
              "text": "Eletronic music tends to be much easier than org√¢nic ones. The guitars of srv lokr are terrible. But I wouldn't say that they are better because it was one week of training and I jumped quite ealrier to lokr hype without test many loras. Maybe I got bad luck and first trainings",
              "score": 6,
              "created_utc": "2026-02-18 22:33:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o655qb8",
                  "author": "deadsoulinside",
                  "text": "I have a major training to do, not sure of the full ETA until it's done, but I have 35 tracks I am training into a LoRa. Done some small tests, but 35 seems to make it go 20x slower. I've been doing 1000 epocs on my training. \n\nI will need to start training again, since I logged onto my machine and thought something went wrong with it barely over 100 epocs and 50+ hours remaining. Worst part was when I stopped it I had thought it was saving every 100th, but no it was set to save at 200, so I missed even having a starting point to resume from. RIP.\n\nEither way, I hope I will get that completed as I will post that to somewhere for download, since there will be no issue with copyright.",
                  "score": 6,
                  "created_utc": "2026-02-18 22:54:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o642wo3",
          "author": "LumaBrik",
          "text": "Nice work, these Lokr's available for download anywhere ?",
          "score": 5,
          "created_utc": "2026-02-18 19:52:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6478xn",
              "author": "marcoc2",
              "text": "I haven't managed to load them in ComfyUl yet. However, I think they're much better than LoRAs, as they require only half the epochs and weigh just 4MB for a rank of 64",
              "score": 0,
              "created_utc": "2026-02-18 20:12:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o64abof",
                  "author": "GreyScope",
                  "text": "Um, they‚Äôre better if they sound better sorry",
                  "score": 0,
                  "created_utc": "2026-02-18 20:27:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o64orl9",
          "author": "aifirst-studio",
          "text": "nice gibberish",
          "score": 7,
          "created_utc": "2026-02-18 21:34:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o652p5o",
              "author": "addandsubtract",
              "text": "*Come, as a prompt, as a friend, as a known memory overflow...*",
              "score": 6,
              "created_utc": "2026-02-18 22:39:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6484xv",
          "author": "Compunerd3",
          "text": "Thanks for sharing, they're good quality compared to what results I get training a style. Could you share training settings?\n\n  \nI'm struggling to train Irish Traditional music as Ace Step is quite poor at this particular genre.   \nI've 70 songs, originally were FLAC quality and I modified them to the following:   \n  \\- Format: WAV (32-bit integer PCM)\n\n  \\- Sample Rate: 48,000 Hz\n\n  \\- Channels: Stereo\n\n  \\- Loudness: -14 LUFS\n\n  \\- True Peak: -1.0 dB\n\n  \\- Silence Removal: -40dB\n\nAll captioned, some are instrumental, some have lyrics so lyrics are captioned too. \n\nI tried training with ACE-Step-1.5, ACE-Step-1.5-for-windows,  ace-lora-trainer and all three I get not great results.   \nI've trained on .sft checkpoint too. \n\nI've tried splitting all audio files into 30sec segments and training those with matching captions too.   \nUsing Shift 1.0 and Shift 3.0, tried 64 alpha and 128 alpha.   \nBatch 3 , 1e-4 or LR as 1.0 for Prodigy",
          "score": 3,
          "created_utc": "2026-02-18 20:16:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o64do6i",
              "author": "marcoc2",
              "text": "\n\n\"linear_dim\": 64,\n\"linear_alpha\": 128,\n\"factor\": -1,\n\"decompose_both\": false,\n\"use_tucker\": false,\n\"use_scalar\": false,\n\"weight_decompose\": true,\n\"target_modules\": [\n\"q_proj\",\n\"k_proj\",\n\"v_proj\",\n\"o_proj\"",
              "score": 5,
              "created_utc": "2026-02-18 20:43:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o64hien",
          "author": "fauni-7",
          "text": "So those are only short samples for each, but did any of the songs from start to finish make sense? I mean anything that was really good that you would actually want to listen again to?¬†",
          "score": 3,
          "created_utc": "2026-02-18 21:00:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o64jju5",
              "author": "marcoc2",
              "text": "There are some, yes. But most are cherry-picked, indeed. I could play with settings like lokr strength, but I was always rushing to pass to the next artist.\n\nFor styles like progressive something or jazz, things gets very interesting since halucination may just be perceived as improvisation.",
              "score": 3,
              "created_utc": "2026-02-18 21:10:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o64te0y",
          "author": "basscadet",
          "text": "new vsnares! üòÇ",
          "score": 3,
          "created_utc": "2026-02-18 21:55:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67u3po",
          "author": "mission_tiefsee",
          "text": "i wish we had a dedicated sub for all things focusing on AI Audio (focus on open source like this sub here).",
          "score": 3,
          "created_utc": "2026-02-19 10:03:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68vp5y",
              "author": "marcoc2",
              "text": "There are, but unfortunately there is much less movement there",
              "score": 1,
              "created_utc": "2026-02-19 14:29:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o69hjgt",
                  "author": "mission_tiefsee",
                  "text": "can you share some subs?",
                  "score": 1,
                  "created_utc": "2026-02-19 16:19:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o64o1wx",
          "author": "physalisx",
          "text": "What tool are you using to train AceStep?",
          "score": 2,
          "created_utc": "2026-02-18 21:30:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o64ylcp",
              "author": "deadsoulinside",
              "text": "Probably the official repo, since it has Lora and LoKr training built into it's UI",
              "score": 4,
              "created_utc": "2026-02-18 22:19:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o643vni",
          "author": "JimmyDub010",
          "text": "Where's the dl?",
          "score": 3,
          "created_utc": "2026-02-18 19:56:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o643h3o",
          "author": "NoPresentation7366",
          "text": "Interesting results!",
          "score": 2,
          "created_utc": "2026-02-18 19:54:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o643i7p",
          "author": "tac0catzzz",
          "text": "grimes and metallica? dl?",
          "score": 2,
          "created_utc": "2026-02-18 19:55:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o644g0p",
          "author": "polawiaczperel",
          "text": "Very good results. What if you would combine Shakira with Metallica?",
          "score": 2,
          "created_utc": "2026-02-18 19:59:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o64y9y5",
              "author": "marcoc2",
              "text": "Still haven't tried lora combination",
              "score": 2,
              "created_utc": "2026-02-18 22:17:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6428y6",
          "author": "DelinquentTuna",
          "text": "Wow.  Great job.",
          "score": 2,
          "created_utc": "2026-02-18 19:49:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65nyi4",
          "author": "-_Weltschmerz_-",
          "text": "Music might actually be the last thing I'd ever want AI to do. It's just even more generic and simple than casual Pop.",
          "score": 2,
          "created_utc": "2026-02-19 00:33:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68kqxg",
              "author": "DelinquentTuna",
              "text": "> It's just even more generic and simple than casual Pop.\n\nIt doesn't *have* to be, though.",
              "score": 3,
              "created_utc": "2026-02-19 13:28:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o68l9ub",
                  "author": "-_Weltschmerz_-",
                  "text": "I agree. When the tools are sufficiently advanced, it'll just be better automation with creators being able to focus on making music instead of wrestling with the complex interface of DAWs. \n\nJust prompting entire songs into existence will never not be slop with LLMs though.",
                  "score": 2,
                  "created_utc": "2026-02-19 13:31:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o66e7kd",
              "author": "marcoc2",
              "text": "Not going to be listening to the things I generated here, but is funny messing around with.",
              "score": 2,
              "created_utc": "2026-02-19 03:05:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o65xj9q",
          "author": "Le_Singe_Nu",
          "text": "Can you make it not sound like shit? Please?\n\nThe Khruangbin impersonation sounds all right (even though it is, at the very least, insulting to the artists \\[if not a civil violation\\] to train a model on them without their consent) but this is because they don't really play with a lot of dynamic range - they focus on understated grooves.\n\nThe metal bands' imitations sound like absolute ass because the model... doesn't do proper dynamic range.\n\nEDIT\n\nYou did RATM. LOL. In so many ways. LOL.",
          "score": 2,
          "created_utc": "2026-02-19 01:28:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65ibgo",
          "author": "ScienceAlien",
          "text": "Getting there‚Ä¶",
          "score": 1,
          "created_utc": "2026-02-19 00:02:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67eq5r",
          "author": "krigeta1",
          "text": "is there any tutorial on how can one do that?",
          "score": 1,
          "created_utc": "2026-02-19 07:34:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o687cnp",
          "author": "bloke_pusher",
          "text": "We need a metal screaming lora/lokr, it sounds too ai still.",
          "score": 1,
          "created_utc": "2026-02-19 11:58:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69ycdb",
          "author": "yoomiii",
          "text": "Ones I listened to sound like a fever dream. Unstructured, chaotic.",
          "score": 1,
          "created_utc": "2026-02-19 17:40:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6amoxf",
          "author": "biogoly",
          "text": "Is there any repository where people are sharing Ace-step LoRas? I see a few on Civitai, but not many.",
          "score": 1,
          "created_utc": "2026-02-19 19:34:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o645y3l",
          "author": "ffgg333",
          "text": "Nice! Are the Loras you made somewhere to download?",
          "score": 1,
          "created_utc": "2026-02-18 20:06:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o64yg5x",
              "author": "Grindora",
              "text": "Nope copyrights",
              "score": 2,
              "created_utc": "2026-02-18 22:18:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o650546",
                  "author": "FaceDeer",
                  "text": "Training is fair use, at least in the US. There should be no copyright issues with distributing a model.",
                  "score": 2,
                  "created_utc": "2026-02-18 22:26:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o648b1y",
          "author": "Inevitable_Emu2722",
          "text": "Nice results! With some artists you can guess on which song they were trained.\n\nIs the training code you use avaiable?",
          "score": 1,
          "created_utc": "2026-02-18 20:17:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o64yq4p",
              "author": "marcoc2",
              "text": "I used this fork/branch: https://github.com/sdbds/ACE-Step-1.5-for -windows/commits/qinglong/\n\nbut I think the gradio repo already has lokr feature as well",
              "score": 2,
              "created_utc": "2026-02-18 22:19:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o650z2w",
          "author": "samplebitch",
          "text": "Khruangbin!  Holy shit...",
          "score": 1,
          "created_utc": "2026-02-18 22:30:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64936y",
          "author": "jude1903",
          "text": "Can we train our voices as a lora or lokr?",
          "score": 0,
          "created_utc": "2026-02-18 20:21:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68s2e6",
          "author": "Small-Challenge2062",
          "text": "Bro learning rate LR 0.003 or 0.0003?",
          "score": 0,
          "created_utc": "2026-02-19 14:09:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68ta7e",
              "author": "marcoc2",
              "text": "https://preview.redd.it/dv448b9fmgkg1.png?width=831&format=png&auto=webp&s=9db69ef7aff3690f1b0fb8259ba3e70ebb3f8fe6\n\n",
              "score": 1,
              "created_utc": "2026-02-19 14:16:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6aad12",
          "author": "James_Reeb",
          "text": "Too much like the original songs but sounds is worst . Lr should be 0.0003",
          "score": 0,
          "created_utc": "2026-02-19 18:36:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e0yzg",
          "author": "Johnixftw_",
          "text": "None of these were any good, just absolute trash to listen to, never considered suicide *in gta* as an option before this post",
          "score": -1,
          "created_utc": "2026-02-20 08:25:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rckeon",
      "title": "Fine-tuning SDXL with childhood pictures ‚Üí audio-reactive geometries - [Experiment]",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/4s7zdq75i9lg1",
      "author": "Real-Philosopher-895",
      "created_utc": "2026-02-23 15:26:51",
      "score": 256,
      "num_comments": 22,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Animation - Video",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rckeon/finetuning_sdxl_with_childhood_pictures/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6ze7of",
          "author": "ThatOneDerpyDinosaur",
          "text": "Creative use of AI tools with zero bouncing anatomy. Have an upvote",
          "score": 14,
          "created_utc": "2026-02-23 17:16:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75m2oy",
              "author": "Real-Philosopher-895",
              "text": "‚ô•",
              "score": 2,
              "created_utc": "2026-02-24 15:58:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6z3gcw",
          "author": "repezdem",
          "text": "It's nice to see some actually good art made with AI tools. Great job",
          "score": 25,
          "created_utc": "2026-02-23 16:26:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zbxhl",
              "author": "zackmophobes",
              "text": "Agreed this is really cool and a fun use case. Thanks for sharing OP.",
              "score": 10,
              "created_utc": "2026-02-23 17:05:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o75lppv",
                  "author": "Real-Philosopher-895",
                  "text": "Thank you guys ‚ô•",
                  "score": 3,
                  "created_utc": "2026-02-24 15:57:17",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6zr77c",
          "author": "Tyler_Zoro",
          "text": "Hope you don't mind, but I've uploaded this video to the aiwars sub [here](/r/aiwars/comments/1rcp4rv/this_is_what_creative_people_do_with_new/). Sadly, that sub doesn't let me link to your post or mention you by name, but if you want to poke your head in and claim credit, please do!",
          "score": 4,
          "created_utc": "2026-02-23 18:16:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o722ng3",
          "author": "Itiiip",
          "text": "finally, introspective diffusion",
          "score": 4,
          "created_utc": "2026-02-24 01:18:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75m5nt",
              "author": "Real-Philosopher-895",
              "text": "I like that name. Thanks for the idea.",
              "score": 3,
              "created_utc": "2026-02-24 15:59:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o702pwa",
          "author": "bigman11",
          "text": "good experiment",
          "score": 3,
          "created_utc": "2026-02-23 19:09:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o707gde",
          "author": "Mid-Pri6170",
          "text": "needs to be in a gallery.",
          "score": 3,
          "created_utc": "2026-02-23 19:31:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75m7it",
              "author": "Real-Philosopher-895",
              "text": "I'd love that.",
              "score": 2,
              "created_utc": "2026-02-24 15:59:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6zkoav",
          "author": "raulsestao",
          "text": "Where can I find the first song from the video? It's very pretty, is it AI too?",
          "score": 2,
          "created_utc": "2026-02-23 17:46:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75m1zy",
              "author": "Real-Philosopher-895",
              "text": "Hey, thank you. No, no. It's composed by me. If I recall correctly I used my Osmose + Cosmos \\[SOMA\\] synths.",
              "score": 2,
              "created_utc": "2026-02-24 15:58:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6zwd76",
          "author": "mcpoiseur",
          "text": "I like the wobbly ness",
          "score": 2,
          "created_utc": "2026-02-23 18:40:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o750y81",
          "author": "Weak-Abbreviations15",
          "text": "Bro just made a Flashbacks before you die simulator. ",
          "score": 2,
          "created_utc": "2026-02-24 14:16:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70kg8m",
          "author": "jefharris",
          "text": "Very cool.",
          "score": 1,
          "created_utc": "2026-02-23 20:32:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o72coxd",
          "author": "diarrheahegao",
          "text": "Nice, what songs did you use for the video?",
          "score": 1,
          "created_utc": "2026-02-24 02:16:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75m9te",
              "author": "Real-Philosopher-895",
              "text": "None, it's a little something composed by me. ",
              "score": 1,
              "created_utc": "2026-02-24 15:59:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o73bxrx",
          "author": "Wormri",
          "text": "It's like something straight out of Control.",
          "score": 1,
          "created_utc": "2026-02-24 06:14:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ys4hn",
          "author": "Any-Score1258",
          "text": "I keep seeing booty cheeks",
          "score": -11,
          "created_utc": "2026-02-23 15:33:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ys6tg",
              "author": "Any-Score1258",
              "text": "Am I gooned out",
              "score": -6,
              "created_utc": "2026-02-23 15:33:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rboeta",
      "title": "ZIB vs ZIT vs Flux 2 Klein",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1rboeta",
      "author": "Both-Rub5248",
      "created_utc": "2026-02-22 15:18:17",
      "score": 253,
      "num_comments": 169,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rboeta/zib_vs_zit_vs_flux_2_klein/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6seej0",
          "author": "Enshitification",
          "text": "It should be mentioned that neither ZiT nor ZiB have any edit capabilities. That is where Flux2.Klein dominates.",
          "score": 60,
          "created_utc": "2026-02-22 15:51:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sknu2",
              "author": "SlothFoc",
              "text": "For real, which is why I had to raise an eyebrow at this line from OP:\n\n>The huge Lora set for ZIT and ZIB also allows the model to be used in a wider range than the Flux 2 Klein.\n\nLike what? I can literally show Klein an image and say, \"make this\" and it will. The need for LoRas has been drastically reduced because of its edit capabilities.",
              "score": 31,
              "created_utc": "2026-02-22 16:18:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6url6l",
                  "author": "ThatRandomJew7",
                  "text": "Not to mention that Klein has LoRAs.\n\nIn fact a lot of the people that make them have said Klein trains much more easily than Z Image",
                  "score": 7,
                  "created_utc": "2026-02-22 22:39:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6sqovn",
                  "author": "Both-Rub5248",
                  "text": "I compared the models only in the T2I connector, I think this is obvious, which is why I did not touch on the Edit capabilities of this model.\n\nIt is clear that Flux 2 Klein will be better at general tasks, but it should not be forgotten that I was comparing exclusively in T2I tasks, not in I2I.\n\nFlux 2 Klein is not a universal model that can do absolutely everything. For T2I tasks, I would rather use ZIT, but for refinement (edit) or other tasks related to I2I, it is certainly better to use F2K.",
                  "score": 4,
                  "created_utc": "2026-02-22 16:45:12",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o6zyij3",
                  "author": "Imaginary_Belt4976",
                  "text": "Yeah, edit is almost a misnomer in some applications because its more like \"follow the example\". I have had amazing results bringing in specific clothing or objects using this technique, but you made me realize I havent actually tried using an image like this for t2i directly so now I need to try it!",
                  "score": 1,
                  "created_utc": "2026-02-23 18:49:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6sngu7",
                  "author": "Jetsprint_Racer",
                  "text": "Well, you still need LoRAs for it but more like guides. Even in dual-image mode it can inpaint some things wrong or modify the object's look from Image2 according to F.2K's dataset. Still, F.2K at least can work with LoRAs properly, compared to ZIT which often produces distorted outputs when LoRA is attached. Some people just recommend to lower the strength of course. Yeah, this tip works great when you use style LoRA. But not so great when you literally need 1.0 strength to make it work. Compared to good old Stable Diffusion (including 1.5), ZIT is terrible at LoRAs.",
                  "score": -1,
                  "created_utc": "2026-02-22 16:30:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6u2mib",
              "author": "RayHell666",
              "text": "I feel that people are missing out on Klein edit potential. Despite some body horror from pure T2I it's the most powerful local model I ever played with and it should not be seen as T2I vs I2I because that's one model that do everything unlike Qwen-image 2512 and Qwen-image edit 2511 that is 2 separate models to juggle with. I feel the same thing will happen to Z-Image Edit.",
              "score": 4,
              "created_utc": "2026-02-22 20:32:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6u5bpb",
                  "author": "Enshitification",
                  "text": "I'm using K9B right now to upscale and enhance a 640x quality dataset to 2MP. It is giving the results the best skin coloration and texture that I have seen in any model so far.",
                  "score": 3,
                  "created_utc": "2026-02-22 20:45:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6sjjrl",
              "author": "Jetsprint_Racer",
              "text": "I have only two F.2K workflows - both img2img, none of them is txt2img. One for general editing, one for lossless inpainting. It literally replaced Fooocus Inpaint for me which was my #1 editing tool for two years. Also works great as image enhancer which removes all these FP8/Turbo model artifacts, cuz SeedVR2 is merciless to ZIT outputs.",
              "score": 4,
              "created_utc": "2026-02-22 16:13:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6skbhw",
                  "author": "Enshitification",
                  "text": "Klein can be good for txt2img too if the prompts are good and one doesn't use an fp8 or quant of Qwen3-8B. I'm mostly using it right now to enhance and clean up a big low-quality dataset. It is unbelievably good at that task.",
                  "score": 3,
                  "created_utc": "2026-02-22 16:16:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6svh3d",
                  "author": "zekuden",
                  "text": "where do you use it? comfyUI?",
                  "score": 2,
                  "created_utc": "2026-02-22 17:06:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6srue4",
                  "author": "Both-Rub5248",
                  "text": "I don't know what problems you're talking about with Lora at ZIT, because I have cases where I used ZIT generation with 4-5 Loras and they did their job perfectly.\n\n1. Lora for adding details (1.1)\n\n2. Lora slider for Boobs (0.4)\n\n3. Lora slider for lighting brightness (1)\n\n4. Lora for amateur photos (0.45)\n\nAnd with all these LORA images, the results were perfect, and after running them through SeedVR2, the images came out first-class.\n\nI have never encountered such problems!",
                  "score": 2,
                  "created_utc": "2026-02-22 16:50:22",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6t2cav",
              "author": "Sarashana",
              "text": "IMHO it's fair game to look only at generations in such a comparison. While having editing and generation capability in the same model is neat, it's not THAT much work to switch to a different model when editing is required. I use ZIT for generation and Qwen Image Edit for editing, myself.",
              "score": 2,
              "created_utc": "2026-02-22 17:38:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6x88ke",
                  "author": "General_Session_4450",
                  "text": "Biggest advantage IMO is that you can train a single LoRA for it and use it both for generating full images and editing.",
                  "score": 1,
                  "created_utc": "2026-02-23 08:55:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6v1wed",
              "author": "Toby101125",
              "text": "Can you elaborate on edit? Like change the prompt wording without it totally changing?",
              "score": 2,
              "created_utc": "2026-02-22 23:37:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6v3jkq",
                  "author": "Enshitification",
                  "text": "Edit, as in \"remove the person on the left\" or \"change the subject to profile view\". The edit models are incredibly powerful like that.",
                  "score": 2,
                  "created_utc": "2026-02-22 23:46:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6spopt",
              "author": "Both-Rub5248",
              "text": "Well, that's super obvious, which is why I didn't write about it; only the T2I capabilities of the models were compared)  \nBut I would really like to wait for Z-Image Edit to come out and compare it with Flux 2 Dev, Flux 2 Klein, Qwen Edit, and FireRed Edit.\n\nWell, Flux 2 currently has no competitors in terms of editing capabilities, except for NanoBanana or to some extent FireRed Edit.",
              "score": 2,
              "created_utc": "2026-02-22 16:40:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6ss2ra",
                  "author": "Enshitification",
                  "text": "Qwen Image Edit also exists and is quite good.",
                  "score": 6,
                  "created_utc": "2026-02-22 16:51:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6smrp8",
              "author": "deadsoulinside",
              "text": "You can do image to image and even some inpainting with ZiT.",
              "score": 1,
              "created_utc": "2026-02-22 16:27:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6snxtl",
                  "author": "Enshitification",
                  "text": "Inpainting and img2img are not at all the same as edit.",
                  "score": 7,
                  "created_utc": "2026-02-22 16:32:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6upobl",
              "author": "YMIR_THE_FROSTY",
              "text": "Z image has edit version.",
              "score": -4,
              "created_utc": "2026-02-22 22:29:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6uqoiz",
                  "author": "Enshitification",
                  "text": "Really? Where can it be downloaded?",
                  "score": 5,
                  "created_utc": "2026-02-22 22:34:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6sj9mb",
          "author": "Finguili",
          "text": "What is it, a comparison that not only clearly labels which model was used to generate which image, but also provides full prompts? Am I on the right subreddit?\n\nThanks OP for posting, the prompt are quite varied. It‚Äôs funny how Z-Turbo ignored request for non-blurry background and how models in general struggle with age. These \"25 years old\" women by Z Image looks closer to 50 than 25.",
          "score": 22,
          "created_utc": "2026-02-22 16:11:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6txmze",
              "author": "Winter_unmuted",
              "text": "Hey now, not everyone here posts terrible comparisons. \n\nI always do full labeling and even made a post on how to label stuff properly. \n\nThere are dozens of us. DOZENS!",
              "score": 3,
              "created_utc": "2026-02-22 20:06:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6sv0dg",
              "author": "Both-Rub5248",
              "text": "***Flux 2 Klein 9B DISTILL FP8***  \n***Z-image Base FP8, FP8 scale, FP8 Mixed, FP4, Q5, BF16*** \\- I generated all these quantisations with the same seed, selected the best option from all the variants, and added it to the comparison.  \n***Z-image Turbo FP8***\n\nI tried all sorts of negative prompts for ZIB, wrote negative prompts in batches that I found on Reddit, sometimes wrote negative prompts individually for each image. Believe me, I spent enough time to squeeze the maximum possible out of ZIB, and what you see in comparison is better generations that came out on ZIB.",
              "score": 2,
              "created_utc": "2026-02-22 17:04:45",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6wwtm9",
              "author": "NorthernRealmJackal",
              "text": ">These \"25 years old\" women by Z Image looks closer to 50 than 25.\n\nMany models/encoders will respond better to \"mid-to-early twenties\" or \"late teens\" than to a specific number.\n\nI'm not sure what the purpose of the square brackets are, in those prompts (user input maybe). ZIT, for instance doesn't do weighted parameters and such, so maybe it gets thrown off by anything that isn't natural language.",
              "score": 2,
              "created_utc": "2026-02-23 07:06:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6ssg9h",
              "author": "Both-Rub5248",
              "text": "Can you name at least one basic model (not Checkpoint, not model assemblies such as SD 1.5 by Yoshi) that will not ignore the \"non-blurry background\" prompt without additional LORA?",
              "score": 1,
              "created_utc": "2026-02-22 16:53:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6t6kg0",
                  "author": "Finguili",
                  "text": "Eh, I was simply making fun if Z-Image Turbo which loves to ignore half of the prompt. But to answer your question, I tried Z-Image Base with \"blurry background\" in negative prompt and it makes everything sharp, though I cannot say that it makes results look better. This also works with SDXL anime models, as \"blurry background\" is danbooru tag.",
                  "score": 5,
                  "created_utc": "2026-02-22 17:58:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6ve1aa",
                  "author": "DrummerHead",
                  "text": "The problem with prompting \"non-blurry background\" is that the model can be free to interpret it as \"non?... Blurry background!\". It's always better to prompt positively, always say what you want. When you talk about what you don't want, you're inadvertently adding tokens that steer the intention towards what you don't want. If the model supports a negative prompt, then add \"blurry background\" to the negative and in the positive say \"sharp contrast, focused\" or similar terms.\n\nhttps://en.wikipedia.org/wiki/Ironic_process_theory applies to AI models",
                  "score": 3,
                  "created_utc": "2026-02-23 00:46:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6skowo",
          "author": "alerikaisattera",
          "text": "What klein?",
          "score": 7,
          "created_utc": "2026-02-22 16:18:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6st6f1",
              "author": "Both-Rub5248",
              "text": "Klein 9B Distill FP8, sorry, I forgot to mention that.",
              "score": 5,
              "created_utc": "2026-02-22 16:56:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6uxf60",
                  "author": "terrariyum",
                  "text": "In your opinion, how does the t2i of Klein 9B base vs K9B distill?  Zi in ZiT are very different (beside one being much faster).  Is the same true for K9B versions?",
                  "score": 1,
                  "created_utc": "2026-02-22 23:11:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6vbhoh",
                  "author": "Impressive-Scene-562",
                  "text": "Could you share your klein 9B workflow please?",
                  "score": 1,
                  "created_utc": "2026-02-23 00:32:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6taf8z",
          "author": "siegekeebsofficial",
          "text": "When z image base was released, it was already known the output quality was not as good as ZiT, think of ZiT as a realistic fine-tune of z image, z image base is more generalized and flexible and gives the opportunity for the community to develop their own fine tunes, but that will take time.",
          "score": 3,
          "created_utc": "2026-02-22 18:15:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6s82o1",
          "author": "wallofroy",
          "text": "I‚Äôm going with turbo",
          "score": 12,
          "created_utc": "2026-02-22 15:21:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6svjwf",
              "author": "berlinbaer",
              "text": "base still shines for me with better prompt adherence and diversity. i think overall you need a bit more robust prompting to make it really shine so when you just put in \"1girl big boobs\" it struggles a bit.\n\nklein is nearly unuseable for me for how often it generates extra limbs.\n\nalso saying ZIB is bad for realistic style scenarios is laughable. \n\nhttps://imgur.com/a/oLvD8GX\n\nhttps://imgur.com/a/21rb7BO\n\nall just z-image base with regular prompting.",
              "score": 5,
              "created_utc": "2026-02-22 17:07:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6sx02x",
                  "author": "wallofroy",
                  "text": "They all are good at specifics things sometimes I get great images with flux Klein 9B distill",
                  "score": 1,
                  "created_utc": "2026-02-22 17:13:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6sau5y",
              "author": "WartimeConsigliere_",
              "text": "Agree, to me it gets the spirit of the prompt most consistently",
              "score": 1,
              "created_utc": "2026-02-22 15:34:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6sqs4r",
                  "author": "General_Session_4450",
                  "text": "It seems like the opposite to me? ZIT tends to look better but is not following the instructions as well.\n\nThe zebra image style is clearly digital illustration rather than hand-drawn comic book style.\n\nThe vintage photo is prompted for a messy 90s retro room but instead made some weird Soviet style computer setup, wires also make no sense here.\n\nThe princess peach image looks better but it failed at \"the background is sharp and not blurred.\"\n\nThe Octane render of a 25 year old woman makes her look way too old and has the iconic ZIT noise texture all over her skin.\n\nThe CCTV footage put multiple people on the court when the prompt said \"A basketball player\", the style itself is okayish but not really what I would call CCTV style. It also again has the iconic ZIT noise texture all over the wood tiles.\n\nThe isekai style failed hard on \"amplified colors accents and epic composition\" and instead create an image with muted colors, simplistic background, and vectorized style.",
                  "score": 8,
                  "created_utc": "2026-02-22 16:45:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6sc937",
                  "author": "Both-Rub5248",
                  "text": "I am eagerly awaiting Z Image Edit so that I can compare it in Edit scenarios with Flux 2, Flux 2 Klein, and FireRed Edit.",
                  "score": 3,
                  "created_utc": "2026-02-22 15:41:28",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6sm6h8",
              "author": "deadsoulinside",
              "text": "LOL I was going to say the same",
              "score": 0,
              "created_utc": "2026-02-22 16:24:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ur2r5",
          "author": "YMIR_THE_FROSTY",
          "text": "Z-image base is very good and for obvious reasons it follows prompt very well. Rest cant so well, due those reasons. In my opinion, best.\n\nOnly exception is age, which is due training. Those models mostly respond to non-numerical age description, like \"mature/adult/old\" or some emphasis in \"very old\" and such. Maybe you could persuade it to do something like 25 years old, but it would need a bit more effort. Or just LoRA that can do age somewhat accurately.\n\nSame stuff is majority of SDXL (and similar) based models. While majority of users type in stuff (especially on civit) like 18-yrs-old, with models they use, apart few exceptions, its basically like if there would be nothing.",
          "score": 3,
          "created_utc": "2026-02-22 22:37:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6v4s4o",
              "author": "Both-Rub5248",
              "text": "Yes, I know about the age; it would be more correct to write \"young girl 25 years old\" here, or other more understandable descriptions of age, such as \"student\" etc.  \n25 years is just a rough guide, not the basis for the request.\n\nBut I deliberately wrote a poor-quality prompt to see how the models would cope with it.  \nTo be fair, it would have been necessary to conduct the test with a more accurate age prompt.",
              "score": 3,
              "created_utc": "2026-02-22 23:53:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6t3ttr",
          "author": "cobra838",
          "text": "1. Klein (I like Klein vibes more)\n2. ZIB (I like the chip design more in ZIB)\n3. ZIB (ZIT and Klein have a more Western European style)\n4. ZIT (It's hard to judge such a comic book style, but ZIT did it better)\n5. All are good (the ZIB Nike 1girl has less of an AI vibe, cause it is more dynamic)\n6. Klein (probably)\n7. ZIT (ZIB looks overcooked and Klein does not look like Peach at all)\n8. Klein (all of them look like women aged 40-50 rather than 25, though Klein probably looks a bit younger)\n9. Klein (Klein and ZIB are quite decent, ZIT is blurry)\n10. ZIB (probably)\n11. ZIB (choosing ZIB because it has fewer AI vibes)\n12. ZIB (ZIB because it has fewer AI vibes, Klein is second. ZIT is complete trash)\n13. All are good\n\nOverall:\n\n* ZIB: 5\n* ZIT: 2\n* Klein: 4",
          "score": 6,
          "created_utc": "2026-02-22 17:46:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6t9u13",
              "author": "Both-Rub5248",
              "text": "I like that you have compiled such a table and backed it up with explanations. Thanks for this.\nI was really interested in alternative opinions, especially with explanations of your opinion.",
              "score": 1,
              "created_utc": "2026-02-22 18:13:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6tanrm",
          "author": "LiveLaughLoveRevenge",
          "text": "Agree with all that you‚Äôve said here. But would like to add:\n\nFlux is great on accuracy, text, editing etc - but I‚Äôm constantly frustrated that it also can give the most ‚Äúobviously AI‚Äù images. Your Slavic fantasy image here is a perfect example of this. \n\nAs an alternative to LoRAs to improve variety in ZIT, you can also do a hybrid workflow of ZIB>ZIT, where ZIB crates the initial image, which is then denoised partially by ZIT.  It takes longer than ZIT but not as long as just using ZIB since you don‚Äôt have to fully generate the ZIB image, and can also upscale your latent between steps (so only ZIT does the full resolution). This has become my go-to when going entirely T2I with no reference images.",
          "score": 6,
          "created_utc": "2026-02-22 18:16:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6tgax1",
              "author": "Both-Rub5248",
              "text": "The connection between ZIT and ZIB looks interesting. Do you have a workflow or a screenshot of part of the workflow?\nI would like to test it.\n\nThank you in advance!",
              "score": 2,
              "created_utc": "2026-02-22 18:42:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6thrbi",
                  "author": "LiveLaughLoveRevenge",
                  "text": "Sure, here is the JSON for my hybrid workflow.\n\nhttps://files.catbox.moe/9s9hvw.json\n\nI'm still tinkering with it (ignore that 'dark mode' thing, it is unfinished).  It has some custom nodes but they are just for things like style selectors and easy setting the empty latent size.\n\nKey is the ZIB>ZIT part, and the latent upscale.  The rest of it can be swapped out with whatever you prefer.",
                  "score": 2,
                  "created_utc": "2026-02-22 18:49:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6vasfc",
          "author": "terrariyum",
          "text": "OP, I have some ideas that you can test that might change your opinions on ZiT vs Zi.  The more I use ZiT, the more I encounter the limitations of distillation.  I'm not shitting on ZiT here - overall quality and speed are great - I'm just pointing out its limitations.\n\n### Caveats for all my tests:\n* You have to use a detailed prompt because the more detail you add, the more ZiT looses diversity\n* Yes, it's possible to *sometimes* do any of these things with enough rerolls and careful prompt tweaking, but then all speed advantage of ZiT is lost\n* Yes a lora can fix any individual issue here, but every lora decreases diversity in things unrelated to the lora, even sliders.  Once you use multiple loras, diversity loss gets extreme\n* These are just the examples I can remember, but I've banged my head against many other knowledge limitations of distillation\n\n### Lighting\n* ZiT strongly leans towards boring simplistic lighting:\n  * Either frontal flash photography (like your computer room example)\n  * Or simple outdoor sunlight (like your bicyclist and princess peach examples)\n* Try testing:\n  * indoor setting without sunlight (e.g. in a bar)\n  * outdoor setting at night time\n  * prompting for specific lighting like rim-light, specific directionality, specific colors\n * in your octane render example, the ZiT lighting looks great (are you sure you didn't accidentally switch ZiT and Zi?).  But I bet if that if you add specific details about clothes, hair, and background objects, the ZiT lighting will get boring\n\n### Hairstyles\n* ZiT knows very few hairstyles, and certain hairstyles keywords are strongly associated with certain ages/ethnicities/makeup/etc.\n* Try testing:\n  * caucasian woman with pink hair\n  * pink hair but without dark roots\n  * short hair but without bangs\n  * sculpted cosplay/wig style (like your princess peach example) but with normal clothes\n  * classic 90s blowout hair or \"pageant\" hair (google to see example).  ZiT thinks \"blowout\" means curly\n\n### Facial expressions\n* ZiT can only do extreme expressions - e.g. tongue out is waaaay out, pouting is like they just bit into a lemon, surprised is like a soyjak meme\n\n### Blending anything\n* ZiT is very blending concepts creatively.  People often mention the issue with seed diversity (e.g. composition), but SVE node at least helps with that.  Nothing can fix the general lack of concept diversity and ability to blend them.\n* Try testing:\n  * Blend clothes styles of two characters ZiT knows (e.g. princess peach and lara croft)\n  * Blend cyberpunk or mecha with princess-style ornate dress\n  * harder examples like blending a motorcycle and a toy horse\n\n### Body poses\n* ZiT often makes boring body poses.  If you try to tell it where each limb goes, it's like a limp marionette.  \n* Non-photo style has better posing - like you got great results in your isekai example.\n* Try testing:\n  * standing but with legs crossed\n  * kneeling with only one knee touching the ground\n  * running hand through hair (not pulling hair away)\n  * any interesting standing pose (google \"standing pose ideas\") any try to imitate with prompting",
          "score": 4,
          "created_utc": "2026-02-23 00:28:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6vckdg",
              "author": "Both-Rub5248",
              "text": "Thank you very much. In my next posts, I will try to work more precisely with lighting, poses, and everything else you mentioned.\n\nThese images are my standard test images. I have been thinking for a long time that I need to diversify and refine them, so you have given me a very good idea for new tests.\n\nThank you very much for such a detailed comment, I appreciate it!",
              "score": 3,
              "created_utc": "2026-02-23 00:38:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6veb2n",
                  "author": "terrariyum",
                  "text": "I also appreciate your post!  Your standard test prompts already cover many styles and scenarios well",
                  "score": 5,
                  "created_utc": "2026-02-23 00:47:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6vcm9v",
              "author": "Both-Rub5248",
              "text": "No, I didn't mix up the generations in the Octane render example, everything is correct there",
              "score": 2,
              "created_utc": "2026-02-23 00:38:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6vefy1",
                  "author": "terrariyum",
                  "text": "Cool, good to know.  Sometimes ZiT gets it better for sure",
                  "score": 2,
                  "created_utc": "2026-02-23 00:48:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6x7pt3",
              "author": "Ken-g6",
              "text": "If you have an existing pose, that's what controlnet is for. Which would also be a good thing to test, ZiT with a controlnet. I don't think Klein has a separate controlnet, but it should work without it, saying \"pose from image 1\" or something, or with the controlnet image as a direct input.",
              "score": 2,
              "created_utc": "2026-02-23 08:50:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6xlwcz",
              "author": "OliverHansen313",
              "text": "You mention an SVE node. I can't find that anywhere. Could you elaborate on what this is?",
              "score": 1,
              "created_utc": "2026-02-23 11:07:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7177br",
                  "author": "terrariyum",
                  "text": "https://github.com/ChangeTheConstants/SeedVarianceEnhancer\n\nIt's essential for using ZiT because it makes the same prompt on different seeds produce different images.  \n\nBut it's not like with SDXL, where different seeds produce different images that are all constrained to the prompt.  SVE works by making each image *less* constrained to the prompt.  \n\nYou need to constantly fiddle with its many dials to find the sweet spot between it having no effect nothing and it deviating too far from the prompt, and that spot is different for every prompt.",
                  "score": 1,
                  "created_utc": "2026-02-23 22:24:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6sj0po",
          "author": "TheSlateGray",
          "text": "Did you use a negative prompt with ZIB?\n\nWith Klein, I'm assuming you used the distilled fast model, but 4b or 9b?",
          "score": 2,
          "created_utc": "2026-02-22 16:10:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6st61u",
              "author": "Both-Rub5248",
              "text": "Yes, I used different sets of negative prompts and selected the best results for ZIB. I will say more: for generation for ZIB, I used FP8, FP8 Scale, FP8Mix, FP4, Q5, BF16, and from all the generations of these models, I selected the best.  \nIt's just that ZIB has this specific quality of generation without Lora.\n\nKlein 9B Distill, sorry, I forgot to mention that.",
              "score": 2,
              "created_utc": "2026-02-22 16:56:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6sm0sl",
          "author": "Current-Rabbit-620",
          "text": "Turbo  for me",
          "score": 2,
          "created_utc": "2026-02-22 16:24:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6smll7",
          "author": "SanDiegoDude",
          "text": "All 3 have their strengths, and I find myself using each for those strengths in tandem. ZIT has turned into my favorite \"finisher\", Klein editing is incredible, and ZIB has great bones and is really good at world knowledge and natural scene building.",
          "score": 2,
          "created_utc": "2026-02-22 16:26:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6suth2",
          "author": "Both-Rub5248",
          "text": "**I forgot to mention that I used:**\n\n***Flux 2 Klein 9B Distill FP8***  \n***Z-image Base FP8, FP8 scale, FP8 Mixed, FP4, Q5, BF16*** \\- I generated all these quantisations with the same seed, selected the best option from all the variants, and added it to the comparison.  \n***Z-image Turbo FP8***\n\nI tried all sorts of negative prompts for ZIB, wrote negative prompts in batches that I found on Reddit, sometimes wrote negative prompts individually for each image. Believe me, I spent enough time to squeeze the maximum possible out of ZIB, and what you see in comparison is better generations that came out on ZIB.\n\n**In the coming days, I will post a comparison of all quantisations for ZIB (FP8, FP8 scale, FP8 Mixed, FP4, Q5, BF16)**",
          "score": 2,
          "created_utc": "2026-02-22 17:03:55",
          "is_submitter": true,
          "replies": [
            {
              "id": "o6t8mhl",
              "author": "rm_rf_all_files",
              "text": "Do you see noticeable differences in quality from ZiT fp4 vs ZiT bf16? I see it and that made me stop using it completely. Others said they don't see it. I generate only at 1MP and I can see it clearly. I wonder if fp8 would be better.",
              "score": 2,
              "created_utc": "2026-02-22 18:07:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6tf5mx",
                  "author": "Both-Rub5248",
                  "text": "I haven't compared quantisation on ZIT.\nBut the differences between BF16 and FP4 are very noticeable in absolutely all models, because the compression in FP4 is too high.\n\nI know that the difference in quality between BF16 and FP8 is about 10-20%, but the difference between BF16 and FP4 is already about 40-50%.\n\nI will soon publish a post about quantisation on ZIB.\nPerhaps you will find answers to your questions there.\nBut I will say in advance that in some scenarios, even FP4 outperforms BF16, at least in ZIB models.",
                  "score": 2,
                  "created_utc": "2026-02-22 18:37:23",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6tdov1",
          "author": "NunyaBuzor",
          "text": "1. Turbo\n\n2. tie between base and klein\n\n3. Base wins\n\n4. Turbo\n\n5. Turbo\n\n6. Tied between turbo and klein\n\n7. tied between turbo(character) and klein(background)\n\n8. klein\n\n9. klein\n\n10. klein\n\n11. klein\n\n12. turbo\n\n13. base or klein?\n\n14. klein",
          "score": 2,
          "created_utc": "2026-02-22 18:30:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6tghjy",
              "author": "Both-Rub5248",
              "text": "Thank you for your comment!",
              "score": 1,
              "created_utc": "2026-02-22 18:43:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6terja",
          "author": "dreamyrhodes",
          "text": "ZiT often creates third legs or arms in the first steps but then removes (corrects) them in later steps.",
          "score": 2,
          "created_utc": "2026-02-22 18:35:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6th1yu",
              "author": "Both-Rub5248",
              "text": "Yes, I noticed that too. The main thing is that the final image is produced without mutation, unlike Flux 2 Klein, which also makes mistakes in the early staps but then does not correct them and relies on the anatomy created in the early staps of generation.",
              "score": 1,
              "created_utc": "2026-02-22 18:45:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6vb09l",
                  "author": "Ill-Engine-5914",
                  "text": "Do the first or later steps in AI generation actually mean something? I thought steps just referred to how many times they train the model, is that wrong? ",
                  "score": 2,
                  "created_utc": "2026-02-23 00:29:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6tfaxu",
          "author": "elfninja",
          "text": "Side question, but how do you come up with these detailed prompts? Whenever I have a picture in my head I always struggle to get my descriptions right. Do you work with another LLM to detail out your prompt? Find presets from elsewhere? Something else?",
          "score": 2,
          "created_utc": "2026-02-22 18:38:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6tigwu",
              "author": "Both-Rub5248",
              "text": "The simpler prompts are the ones I came up with myself.\n\nThe biggest prompts are the ones I found on the internet.\n\nSome prompts are just my personal descriptions of pictures I found on Pinterest.\n\nSometimes I use prompt builders where you can take part of a prompt to create light, part to create hair, part for shot size, and so on.\n\nI rarely use LLM, except in cases where I need to structure and shorten what I have written from scratch.",
              "score": 2,
              "created_utc": "2026-02-22 18:52:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6tsxyj",
                  "author": "elfninja",
                  "text": "Darn, to be honest, I was really hoping for some magic LLM prompt that would make things easier. Thanks for sharing.",
                  "score": 2,
                  "created_utc": "2026-02-22 19:43:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6v1t1i",
          "author": "Toby101125",
          "text": "Flux knows which Peach we want. ‚ù§Ô∏èüçë",
          "score": 2,
          "created_utc": "2026-02-22 23:36:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6v6chd",
              "author": "Both-Rub5248",
              "text": "Only Flux doesn't know the colour of her dress.  \nTherefore, it is more Daisy than Pitch)",
              "score": 1,
              "created_utc": "2026-02-23 00:02:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vnsi0",
          "author": "Toby101125",
          "text": "I wish there was a dark lighting test in here because holy hell I think Z-Image might be worse than SDXL at getting dark, realistic portraits.",
          "score": 2,
          "created_utc": "2026-02-23 01:45:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zob73",
              "author": "MasterFGH2",
              "text": "Workaround: Start with a black latent and then do a 80% denoise",
              "score": 2,
              "created_utc": "2026-02-23 18:03:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o707vkj",
                  "author": "Toby101125",
                  "text": "img2img with a black square?",
                  "score": 1,
                  "created_utc": "2026-02-23 19:33:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6x4mre",
          "author": "latentbroadcasting",
          "text": "Wow, this confirmed my thought that Z-Image Turbo is way better than \"base\" or at least it seems to perform better",
          "score": 2,
          "created_utc": "2026-02-23 08:20:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6scevv",
          "author": "fluce13",
          "text": "Awesome post thank you!",
          "score": 2,
          "created_utc": "2026-02-22 15:42:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sy297",
              "author": "Both-Rub5248",
              "text": "Thank you very much, I am very pleased that someone has appreciated my efforts!",
              "score": 0,
              "created_utc": "2026-02-22 17:18:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6tzy81",
          "author": "AI_Characters",
          "text": "I still dont understand why so many people complain about \"very poor anatomy\" with Klein. I get \"mutations\" about 1 in 4 images. Which is worse than the other models but not \"very poor\". \"Very poor\" is unuseable.\n\nI am starting to think that perhaps these issues only lie with the distilled or fp8 models because I dont encounter huge anatomy issues on Klein base 9B fp16.",
          "score": 2,
          "created_utc": "2026-02-22 20:18:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6uleog",
              "author": "djdante",
              "text": "I use fp8 in Klein all the time and I have the same feeling as you - extra limbs are occasional and \"so what\" just change the seer and wait another ten seconds....\n\nThe only area it can become annoying is actions.. getting someone rock climbing for example is a nightmare if bad limbs and bad proportions from hell..\n.playing soccer or another sport introduces a lot of extra limbs too.\n\nBut again. It's easy to work around and anminor annoyance at worst.",
              "score": 3,
              "created_utc": "2026-02-22 22:07:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6v0qdi",
              "author": "Both-Rub5248",
              "text": "I actually end up with 4 images with mutations and 1 without.  \nYes, perhaps the whole problem lies with Distill and FP8, but unfortunately my 6 GB of VRAM cannot handle full-fledged models.\n\nWhen using a device with 6 GB VRAM, Z-Image Turbo does not cause any mutations, so I have no complaints about this model.\n\nModels weighing more than 8 GB are not suitable for all purposes, because sometimes a huge number of generations are required, and the ratio of speed and quality is of great importance.\n\nAnd the maximum speed on Flux can only be achieved on Distill Fp8 version.\n\n",
              "score": 2,
              "created_utc": "2026-02-22 23:30:46",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6uc8mq",
              "author": "Fluffy-Maybe-5077",
              "text": "Are you generating or editing? This exists for a reason [https://civitai.com/models/2324991/klein-anatomy-quality-fixer](https://civitai.com/models/2324991/klein-anatomy-quality-fixer)",
              "score": 1,
              "created_utc": "2026-02-22 21:20:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6um0uc",
                  "author": "AI_Characters",
                  "text": "At least one person in the comments says he does not have major anatomy issues either so this really does not seem to be a universal issue but something with the settings or models.",
                  "score": 2,
                  "created_utc": "2026-02-22 22:10:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6v18v7",
                  "author": "Both-Rub5248",
                  "text": "I tested this Lora, it helps, but only 30%.  \nWith this Laura, I get 2-3 images with mutations and 1 without.  \nUnfortunately, this Laura is not a panacea.\n\nPerhaps the entire issue is indeed with Distill Fp8.",
                  "score": 1,
                  "created_utc": "2026-02-22 23:33:46",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6v9cgx",
              "author": "berlinbaer",
              "text": ">  I get \"mutations\" about 1 in 4 images.\n\nthats acceptable to you??",
              "score": 1,
              "created_utc": "2026-02-23 00:19:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6vdcfc",
                  "author": "AI_Characters",
                  "text": "Yes? why wouldnt it? what kind of ridiculous standards do you have lol? considering everything else this model offers this is ok. oh no so one 80s generation was wasted. the horror...",
                  "score": 1,
                  "created_utc": "2026-02-23 00:42:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6u276t",
              "author": "SlothFoc",
              "text": "A good thing to keep in mind about this subreddit is that a lot of people have no idea what they're doing. \n\nI'll get a 3 fingered hand here and there and that's about the extent of it.",
              "score": 1,
              "created_utc": "2026-02-22 20:29:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6u3561",
          "author": "QuirksNFeatures",
          "text": "I'm very new to all this but that 8th image spoke to me.  A lot of the time I just cannot get these things to generate a person of the age I want.  In your example all three of the women look way older than 25.  The one in the middle looks 45 plus.\n\nAnd another thing that's not really related:  I cannot figure out a prompt to make a person face away from the \"camera\".  I've struggled mightily with this today.  Sometimes they turn their bodies a little.  Sometimes they turn their heads.  Most of the time it's just dead on facing the camera no matter what I write in the prompt.  Frustrating.",
          "score": 1,
          "created_utc": "2026-02-22 20:34:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6v3ss1",
              "author": "Both-Rub5248",
              "text": "In my example with age, one could have written **YOUNG GIRL**, 25 years old, instead of 25-year-old **WOMAN**.\n\nAge figures are just a small hint; the basis for the prompt is the words **\"young\"** and **\"girl\"** instead of **\"woman.\"**\n\nYou can also set LORA to determine age. (Age Slider)\n\nIn my example with three renderings of women, I deliberately made a mistake in the prompt to see which of the models would be able to correctly understand my poor-quality prompt. Apparently, none of them managed to do so :D",
              "score": 1,
              "created_utc": "2026-02-22 23:48:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6vbctt",
                  "author": "QuirksNFeatures",
                  "text": "Whenever I've tried \"young girl\" even with an age, there's a very good chance it will generate a literal child.  I may need to add some more hints.\n\nI don't know anything about LORAs yet.  How would that work if there is more than one person in the image?\n\nStill new, still learning.",
                  "score": 1,
                  "created_utc": "2026-02-23 00:31:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ua0yb",
          "author": "gone_to_plaid",
          "text": "Did you use a negative prompt on ZIB?  I've found including one very important to realism.",
          "score": 1,
          "created_utc": "2026-02-22 21:09:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6v3zgj",
              "author": "Both-Rub5248",
              "text": "Yes",
              "score": 2,
              "created_utc": "2026-02-22 23:49:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ucpfg",
          "author": "Suspicious-Click-688",
          "text": "F2K wins IMO",
          "score": 1,
          "created_utc": "2026-02-22 21:23:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vaxcj",
          "author": "overand",
          "text": "Which Flux.2 Klein version are you using, just to be sure?\n\n- [FLUX.2-klein-9B](https://huggingface.co/black-forest-labs/FLUX.2-klein-9B)\n- [FLUX.2-klein-base-9B](https://huggingface.co/black-forest-labs/FLUX.2-klein-base-9B)\n\nI assume the former - this is a \"the naming scheme isn't well thought-out\" issue, not a you issue, btw. Like, how does one specify the \"regular\" one specifically? If the other one wasn't called \"base\" in the name, I'd probably say \"Flux.2 Klein base model\" or such. Meh \n\n`</old person wagging a finger a passing kids>`",
          "score": 1,
          "created_utc": "2026-02-23 00:28:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6vcx8l",
              "author": "Both-Rub5248",
              "text": "I apologise, I forgot to mention that I used Flux 2 Klein 9B Distill FP8.",
              "score": 1,
              "created_utc": "2026-02-23 00:40:07",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6vd4sk",
              "author": "Both-Rub5248",
              "text": "In your comment, it is referred to as [FLUX.2-klein-9B](https://huggingface.co/black-forest-labs/FLUX.2-klein-9B)",
              "score": 1,
              "created_utc": "2026-02-23 00:41:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ze63d",
          "author": "Odd-Mirror-2412",
          "text": "I like ZIB because it has the least AI look.",
          "score": 1,
          "created_utc": "2026-02-23 17:16:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70y45x",
          "author": "azination",
          "text": "This is great!",
          "score": 1,
          "created_utc": "2026-02-23 21:39:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o749uq7",
          "author": "New-Addition8535",
          "text": "Flux 2 klein is the best",
          "score": 1,
          "created_utc": "2026-02-24 11:23:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6sn4xx",
          "author": "superkickstart",
          "text": "Flux has the most obvious ai look.",
          "score": 1,
          "created_utc": "2026-02-22 16:29:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6s9adl",
          "author": "Both-Rub5248",
          "text": "By the way, I forgot to mention and praise ZIB for its work with 2D graphics, such as graphic design. It did a very good job with the \"2 image\" with chips.\n\nIt can be used as an additional tool in design or in tasks where creativity is more important than quality.\n\nBut in realistic style scenarios, ZIB loses out to absolutely everything (",
          "score": 1,
          "created_utc": "2026-02-22 15:27:25",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o6tku2p",
          "author": "Bbmin7b5",
          "text": "ZIB is the clear winner but its slow generation time kills it for most.",
          "score": 1,
          "created_utc": "2026-02-22 19:03:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ugtzj",
          "author": "grahamulax",
          "text": "Holy crap this is the EXACT post I needed. THANK YA!!!",
          "score": 1,
          "created_utc": "2026-02-22 21:43:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6v47zi",
              "author": "Both-Rub5248",
              "text": "Thank you very much for your comment.",
              "score": 0,
              "created_utc": "2026-02-22 23:50:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6v85d1",
          "author": "Ok-Prize-7458",
          "text": "Klein is good but nerfed nsfw. I only use AI to goon, so i prefer Z-image for its anatomy consistency. I love ZIT and its primary my daily generator, but it lacks a lot of creativity.",
          "score": 1,
          "created_utc": "2026-02-23 00:13:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6vbolo",
              "author": "Both-Rub5248",
              "text": "Under this post, one person shared their workflow, in which ZIB generates the first steps and provides more creativity, while ZIT performs all subsequent and final steps, resulting in increased creativity in the generations)",
              "score": 2,
              "created_utc": "2026-02-23 00:33:06",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6zze24",
              "author": "Lost-Passion-491",
              "text": "You haven‚Äôt tried SNOFS?",
              "score": 1,
              "created_utc": "2026-02-23 18:53:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6xp76t",
          "author": "NesquikBoi",
          "text": "This is far from usable on a professional level",
          "score": 0,
          "created_utc": "2026-02-23 11:36:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6szuod",
          "author": "StableLlama",
          "text": "Why choose? Did you run out of storage?\n\nI use all of them, including the still great Qwen Image (especially Qwen Image 2512 is extremely great and the 4 and 8 step LoRA let it run). And I also still spin up Flux.1 dev, when I need a LoRA that's only available for it.  \nOnly SD1.5 and SDXL are the models I didn't run for many months.",
          "score": -2,
          "created_utc": "2026-02-22 17:27:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6t0mtt",
              "author": "Both-Rub5248",
              "text": "Well, yes, I don't have much space on my laptop's SSD right now :D\n\nMy main PC with 3TB of memory is currently in another city, so I was looking for the best and most versatile model for T2I.\n\nAnd in general, I'm very interested in comparing such models)\n\n  \nI also have Flux 1 Dev on my main PC, because I have a lot of personal workflows and a lot of unique Lora for different styles)",
              "score": 1,
              "created_utc": "2026-02-22 17:30:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6t6i8u",
                  "author": "StableLlama",
                  "text": "Comparing is important. But not to ditch a model, but to know where each model has its strengths and thus decide by the task which one to choose.",
                  "score": 1,
                  "created_utc": "2026-02-22 17:58:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6t10tt",
              "author": "Both-Rub5248",
              "text": "I will definitely keep Flux 2 Klein on my SSD, because it is very cool in the I2I segment. I was more interested in comparing ZIB and ZIT, and I made my choice. I hope it helped others too. ",
              "score": 1,
              "created_utc": "2026-02-22 17:32:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rbyej5",
      "title": "3 Months later - Proof of concept for making comics with Krita AI and other AI tools",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1rbyej5",
      "author": "Portable_Solar_ZA",
      "created_utc": "2026-02-22 21:34:49",
      "score": 212,
      "num_comments": 93,
      "upvote_ratio": 0.82,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rbyej5/3_months_later_proof_of_concept_for_making_comics/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o6us2un",
          "author": "SuikodenVIorBust",
          "text": "I feel like her level of thickness varies pretty substantially from page to page.",
          "score": 26,
          "created_utc": "2026-02-22 22:42:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zjb46",
              "author": "Portable_Solar_ZA",
              "text": "Yeah, this is one of the things I'm trying to clean up. Even when I sketch the figure proportionately the same, adding in the LORA throws things off.",
              "score": 3,
              "created_utc": "2026-02-23 17:40:34",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o722itw",
              "author": "Icetato",
              "text": "Well, tbf, traditional mangakas often have trouble with consistent body proportions too.",
              "score": 3,
              "created_utc": "2026-02-24 01:17:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o72kbii",
                  "author": "SuikodenVIorBust",
                  "text": "Tbf if im having a machine do it one of the main appeals is near perfect consistency",
                  "score": 1,
                  "created_utc": "2026-02-24 03:00:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6uj2ay",
          "author": "ArmadstheDoom",
          "text": "So I think what I said then still applies now; the core hurdle is not the art itself or the tools. Comics and manga specifically need an understanding of page layouts and panel framing; you can tell when this is done well and when it's done poorly. \n\nBut the bottlenecks in this case are *not* the tools you're using. Krita itself isn't needed here; you could use comfy or forge and then generate images and then arrange them into pages via panels via gimp, for example. \n\nBut the core hurdle with both comics and anime is that most AI models, even today, do not understand things like *spacial dynamics* or *perspective* beyond the standard ones. Why? Because they're all trained on 'good' art which for training purposes is almost always splash pages or covers or figure drawing. I actually find it impressive that you've gotten some unique perspectives here. \n\nBut then, you said you used controlnets and and loras and you're the one who is storyboarding and sketching what you want, so honestly, the models aren't really doing a ton of heavy lifting. At this point you're basically still doing it all yourself! \n\nHowever, the answer I gave you before (I think) still applies here: the question is not whether you could do it, because you could train a model to do the art, it's whether or not you as the creator grasp how panels are placed and how things are cropped. \n\nSo basically, this is more a proof of concept for *you* as a storyboarder and panel setter.",
          "score": 39,
          "created_utc": "2026-02-22 21:55:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6voone",
              "author": "Beginning-Struggle49",
              "text": "> I actually find it impressive that you've gotten some unique perspectives here. \n\nSame!! I've been dabbling with trying to use comfyui to do as you said, and my biggest issues is definitely the dynamic angles and perspectives are next to impossible to prompt/figure out",
              "score": 5,
              "created_utc": "2026-02-23 01:50:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6wz6ok",
                  "author": "ArmadstheDoom",
                  "text": "it makes more sense if they're sketching things out beforehand. at that point, the model isn't really doing much more than building atop what's there.",
                  "score": 3,
                  "created_utc": "2026-02-23 07:27:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6zlf8n",
                  "author": "Portable_Solar_ZA",
                  "text": "If you're trying to really squeeze the most out of these models, I would 100% recommend learning some basic art skills and getting a basic PC drawing tablet with pressure sensitivity if you can. Being able to guide the model with image-to-image references allows you to do things that text-to-image just can't.",
                  "score": 1,
                  "created_utc": "2026-02-23 17:50:17",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6voy00",
              "author": "elrobolobo",
              "text": "At a certain point there will also need to be use cases that look less like hentai",
              "score": 7,
              "created_utc": "2026-02-23 01:52:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6we74y",
                  "author": "sukebe7",
                  "text": "I agree.  This would be great for creating new language teaching books.  However, the racy imagery, even though it's mild, isn't going to win customers.\n\nThis style would be OK for teens and up... at least where I'm at.",
                  "score": 4,
                  "created_utc": "2026-02-23 04:34:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6zmix0",
                  "author": "Portable_Solar_ZA",
                  "text": "So technically this is \"ecchi\" or \"fanservice\", and obviously it's entirely intentional. But yeah, it's also not something that bothers me at all and isn't out of place in this type of story which is being hinted at by the final page. \n\nUltimately, someone, maybe even me, will use these tools to tell a different kind of story, but for now this is what I'm enjoying making.",
                  "score": 1,
                  "created_utc": "2026-02-23 17:55:21",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6zl1iq",
              "author": "Portable_Solar_ZA",
              "text": "I agree with most of your main points, but I don't really agree with you on this. At least, not entirely.  \n  \n\\>Krita itself isn't needed here; you could use comfy or forge and then generate images and then arrange them into pages via panels via gimp, for example.\n\nThe integration of the KRITA AI plugin is what makes this a lot simpler than it would otherwise be. It wouldn't be impossible, but it would add a fair amount of time since you'd have to be constantly exporting or importing things between programs, adding time that would stack up into something fairly substantial by the end of a project. KRITA AI keeps everything in one interface, allowing you to make minor adjustments or quickly access tools without having to re-export things each time.\n\nThis video is the closest thing I have to my current process, so maybe this will help highlight the subtle but important differences:\n\n[https://www.youtube.com/watch?v=bKHo2Gh9O-c](https://www.youtube.com/watch?v=bKHo2Gh9O-c)\n\nBut yes, I agree that ultimately whether something succeeds or fails is ultimately if I can put together a series of images in sequence and have it resonate with the reader.\n\n",
              "score": 2,
              "created_utc": "2026-02-23 17:48:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vnuot",
          "author": "Ylsid",
          "text": "Booba",
          "score": 11,
          "created_utc": "2026-02-23 01:45:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xcx3k",
              "author": "MaitreSneed",
              "text": "Coomics",
              "score": 7,
              "created_utc": "2026-02-23 09:42:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6zn8mj",
                  "author": "Portable_Solar_ZA",
                  "text": "\\>Booba\n\nYes.\n\n\\>Coomics\n\nAnd yes.",
                  "score": 2,
                  "created_utc": "2026-02-23 17:58:38",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6un952",
          "author": "krautnelson",
          "text": "what I'd recommend is to read some well-regarded manga and really take note of how they they frame and block the characters, how they time actions and interactions, etc.\n\nfor example, on page three, the character is shown in three panels front, then back, then side. it would flow much better if you go front>side>back.\n\nand when the teacher accidently enters the wrong room and slams the door (which she shouldn't do. she should politely and quietly shut it), you immediatly go into a close-up headshot when it probably should be a 3/4 wide shot of her standing outside in the hallway still embarrassed from barging into the wrong room.\n\nsome of the timing generally feels off, like the teacher getting kicked at the end lacks anticipation. what I would do here is end the page with a shadowy figure showing up behind the teacher in the doorway, and then have the kick be on the next page as a page-turn surprise. it would have significantly more impact that way.\n\n(also, this is more of a me-thing, but as a regular manga reader, it annoys me that the panel order isn't right-to-left)\n\nif I am brutally honest, this feels like someone who has rough idea of what manga looks like but never paid attention to how it's actually written, drawn and structured.\n\ngo read Nisekoi Chapter 1. it's in my humble opinion one of the best made manga in terms of layout, flow, timing, etc. \n\ntake note of how the characters are positioned and framed, how the shots vary between panels, the order of the panels and how they flow into each other, and the set-up and pay-off between the pages.",
          "score": 23,
          "created_utc": "2026-02-22 22:16:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zrdms",
              "author": "Portable_Solar_ZA",
              "text": "\\>for example, on page three, the character is shown in three panels front, then back, then side. it would flow much better if you go front>side>back.\n\nI'll take a look at this later.\n\n\\>and when the teacher accidently enters the wrong room and slams the door (which she shouldn't do. she should politely and quietly shut it),\n\nI take it this is your character and your story? In case this is a \"oh in Japan they wouldn't do this\", this is a fictional short story loosely based on a Japanese setting. As demonstrated by the one adult getting kicked across the room by the other one, this clearly is a work of fiction and isn't a piece that's meant to be taken as some sort of direct cultural piece. \n\n\\>you immediatly go into a close-up headshot when it probably should be a 3/4 wide shot of her standing outside in the hallway still embarrassed from barging into the wrong room.\n\nI'll give this a bash and see. \n\n\\>(also, this is more of a me-thing, but as a regular manga reader, it annoys me that the panel order isn't right-to-left)\n\nI regularly switch between manga and traditional comics, so I don't really have any issues with this, but since I'm a Westerner I just started it from left-to-right. \n\n\\>if I am brutally honest, this feels like someone who has rough idea of what manga looks like **but never paid attention to how it's actually written, drawn and structured**.\n\nYour first points come across as constructive. You are pointing out areas for improvement. However, this comes across as being unnecessary simply because you don't actually know the time or effort I've put into this. Even if the work comes across as amateurish, that's exactly what I am: an amateur. This is not an easy art form to get to grips with. Some people spend decades producing manga and comics and only make their debuts later in life, so without actually know my process, this kind of \"feedback\" comes across more as rude than actually criticism. \n\nBut I also wonder if it's not just a purist thing considering how you pointed out the way the character would act.\n\n\\>go read Nisekoi Chapter 1. it's in my humble opinion one of the best made manga in terms of layout, flow, timing, etc.\n\nThanks. I'll take a look at this shortly.",
              "score": 2,
              "created_utc": "2026-02-23 18:17:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o70iye3",
                  "author": "krautnelson",
                  "text": ">I take it this is your character and your story?\n\nno, obviously not. if you want her to be the kind of person that slams doors shut for no reason - which I'm pretty sure is a rude thing to do regardless of where and when it's done- then that's your choice. I just felt it conflicted with what little of her character I saw in those few pages, especially when she did that super-deep bow and apology beforehand. \n\n>this clearly is a work of fiction and isn't a piece that's meant to be taken as some sort of direct cultural piece.\n\nbut it's clearly Japanese-coded, so that's something you also need to keep in mind as a writer. your setting will influence how the reader will interpret character's actions and interactions. if you don't want the reader to equate your setting to a Japanese High School, don't make it look like a Japanese High School.\n\n>this kind of \"feedback\" comes across more as rude\n\nlook, I just said it as I see it. if you think someone speaking their mind and giving their honest opinion is rude, then that's on you. maybe next time just say that you can't handle any negative criticism whatsoever and that people are only allowed to say nice things. I'm sure that will work just fine.",
                  "score": 0,
                  "created_utc": "2026-02-23 20:25:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6wfj0t",
              "author": "sukebe7",
              "text": "The ordering depends on which region the writer is targeting, IMO.  Essentially, Japan's mange is reverse, compared to U.S. comics.  They're also read from back to front; from a western perspective.\n\nI\"ve also seen action running clockwise on some panels.  However, the basic order is like a reverse z.  I've also seen where westerners try to adjust to this order; it's a bit like switching to southpaw for a year.  You always feel like you're working against what comes naturally.\n\nI don't think Japanese people are going to be the OP's primary target/customer.  There is nothing wrong with doing a manga styled comic in western layout.  But, ya gotta pick a side, bub.",
              "score": 1,
              "created_utc": "2026-02-23 04:43:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6x6yu0",
                  "author": "krautnelson",
                  "text": ">I don't think Japanese people are going to be the OP's primary target/customer.\n\nmanga are always right-to-left, doesn't matter if they are being released in Japan or overseas. they stopped flipping them a long time ago. if the target demographic is manga readers, then they are all gonna be used to that \"reverse\" order.\n\nbut again, this is a very minor and personal complain and far from the main issue.",
                  "score": 3,
                  "created_utc": "2026-02-23 08:43:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6v2v00",
              "author": "NorX_Aengelll",
              "text": "yeah as is a proof of concept...never he has said he will create the next banger...And fuck right to left...",
              "score": -15,
              "created_utc": "2026-02-22 23:42:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6vk49u",
                  "author": "InvalidFate404",
                  "text": "He literally asked for constructive criticism....",
                  "score": 11,
                  "created_utc": "2026-02-23 01:22:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6zrlx8",
                  "author": "Portable_Solar_ZA",
                  "text": "Thanks for your thoughts but I don't mind the parts that are actual crits. I've already replied where I felt the person wasn't providing actual feedback and just felt unnecessary.",
                  "score": 1,
                  "created_utc": "2026-02-23 18:18:40",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6uhdj7",
          "author": "FakeNameyFakeNamey",
          "text": "irt your question, the papers cover is much stronger -- more dynamic angle, and the hands in 2 look a bit off.\n\n  \nI feel like doing a matrix rotation on page 1 is a surprising choice, I think you should do more of a wider crop to a tighter crop to emphasize the feeling of running movement, right now it feels more like we're just swiveling a camera around someone walking in place.\n\n  \n2 is great\n\n  \nshot reverse shot in 3 is very solid\n\n  \n3 is probably fine although I do feel like if you had done a wider cropping for bottom left it would have worked better to create the feeling of 'zoom in' \n\n  \nthe crazy over the shoulder angle for 4 is awesome\n\nmid right on 5 needs something. it's a comic beat, but it's just confusing right now. maybe a 'scoot-scoot' sound effect with some motion lines, indicating she's moving away while bowed, otherwise it's actually not clear what is physically occurring in what is supposed to be the funniest panel of the scene\n\nbottom of 7 probably needs an impact emphasis point, I know the moment is supposed to be surprising but right now it's so surprising there's no way to understand why she is flying forward until you get to the next page\n\n\n\nI wish I had better answers to you for 2 and 3. If you find out let me know. I feel like gaining new subs for anything other than outright pornography using AI is extremely difficult right now, the sheer volume of AI-released material has made it so that there's just a nonstop deluge of low-effort slop in most 'AI-open' art spaces, making it very hard for carefully constructed AI-assisted comics to get exposure. This is pretty good, I feel like with an early access model you could probably get like 20 subs or something if you could ever find a way that the eyes of a human being would look at it",
          "score": 3,
          "created_utc": "2026-02-22 21:46:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ujo3v",
              "author": "Portable_Solar_ZA",
              "text": "Thanks for the feedback, it's late at night in my neck of the woods so I'll try to reply properly in the coming days, but I'll definitely keep your crits in mind for my revisions. Thanks!",
              "score": 2,
              "created_utc": "2026-02-22 21:58:14",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6zti3c",
              "author": "Portable_Solar_ZA",
              "text": "\\>I feel like doing a matrix rotation on page 1 is a surprising choice, I think you should do more of a wider crop to a tighter crop to emphasize the feeling of running movement, right now it feels more like we're just swiveling a camera around someone walking in place.\n\nYa, I've had a couple of people point this out to me. I'm going to see if I can have another shot at this while still keeping some of the fanservice elements without giving away the character immediately.\n\n\\> 3 is probably fine although I do feel like if you had done a wider cropping for bottom left it would have worked better to create the feeling of 'zoom in'\n\nWill take a look at this.\n\n\\> the crazy over the shoulder angle for 4 is awesome\n\nThanks. I had to do so much work to get the base sketch right before running it through the model. I was going for a fishbowl type effect and am glad I mostly nailed it coz the model had no idea how to handle it with so many characters when I was experimenting with just prompts.\n\n\\>mid right on 5 needs something. it's a comic beat, but it's just confusing right now. maybe a 'scoot-scoot' sound effect with some motion lines, indicating she's moving away while bowed, otherwise it's actually not clear what is physically occurring in what is supposed to be the funniest panel of the scene\n\nWill take a look at adding in something here.\n\n\\>bottom of 7 probably needs an impact emphasis point, I know the moment is supposed to be surprising but right now it's so surprising there's no way to understand why she is flying forward until you get to the next page\n\nYa, this was intentional, to try and keep the mystery of it, but maybe I'll add in something to at least hint at her being struck by a kick.\n\n\\>I wish I had better answers to you for 2 and 3. If you find out let me know. I feel like gaining new subs for anything other than outright pornography using AI is extremely difficult right now, the sheer volume of AI-released material has made it so that there's just a nonstop deluge of low-effort slop in most 'AI-open' art spaces, making it very hard for carefully constructed AI-assisted comics to get exposure.\n\nYeah, as someone who has messed around with these models for about 9 months, it's crazy how quickly you get over the novelty of the \"generic\" prompted images and how hollow they feel, but that doesn't stop people flooding the internet with it...\n\n\\> This is pretty good, I feel like with an early access model you could probably get like 20 subs or something if you could ever find a way that the eyes of a human being would look at it\n\nThanks. I'll keep on working at this. This is my first attempt and considering how much I've been able to learn in the last three months, am hoping things will look even better in another few months.",
              "score": 2,
              "created_utc": "2026-02-23 18:27:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6w4ix2",
          "author": "HighDefinist",
          "text": "Looks good! Definitely does not seem like there is a lot missing for it to look \"real\" - or rather, that which might be missing might not be primarily due to the limitations of AI...\n\nHowever, very soon (or even now?) models might be able to plan something like the layout of multiple panels at once - something like \"this panel should create this and that impression\", and then they can generate the appropriate prompt for i.e. the perspective or something, and also check if the produced image has the right properties...\n\nAt least, that's roughly the state that AI-programming is at, currently.\n\n",
          "score": 3,
          "created_utc": "2026-02-23 03:28:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ztyo2",
              "author": "Portable_Solar_ZA",
              "text": "\\>Looks good! Definitely does not seem like there is a lot missing for it to look \"real\" - or rather, that which might be missing might not be primarily due to the limitations of AI...\n\nYeah, I'm still learning.\n\n\\>However, very soon (or even now?) models might be able to plan something like the layout of multiple panels at once - something like \"this panel should create this and that impression\", and then they can generate the appropriate prompt for i.e. the perspective or something, and also check if the produced image has the right properties...\n\nMy only concern with this is that it'll always head towards the \"average\" of whatever it's been trained on, so while it may be able to potentially produce something okay, it probably won't produce something great, since greatness usually comes from experimenting and breaking the rules.",
              "score": 1,
              "created_utc": "2026-02-23 18:29:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o70j6k8",
                  "author": "HighDefinist",
                  "text": "\\> My only concern with this is that it'll always head towards the \"average\" of whatever it's been trained on\n\n\n\nTrue. \n\n\n\nThis will almost certainly remain a significant part of \"fighting against the AI\" (while using it) for quite a while... I am not aware of any developments that would enable something like \"deviate from the norm in an interesting way\" while not having to be very specific about what kinds of deviations you want exactly... \n\n\n\n\\> since greatness usually comes from experimenting and breaking the rules\n\n\n\nSort of.\n\n\n\nSo, just generalizing from a book about photography I read some time ago, one interesting aspect was \"you should either make your photo straight (then it looks like you know what you are doing), or with 10+¬∞ twist (then it looks like an intentional 'artistic' deviation), but don't do it only slightly off, because then it looks just accidental and therefore bad\". So, more generally, the idea is probably something like you should first learn the rules, and then break them deliberately and strongly, so you get a sense of the motivation behind them. It also means you should probably not break too many rules at once, particularly not at the beginning, because then it will also just look random and messy... but all of that is more of a \"general art thing\", than something specific to AI. However, AI probably enables you to more quickly iterate over and thereby learn all the various rules, so... that's definitely a good thing.\n\n\n\nSo, yeah, it's certainly interesting to see this result you made here, because (similar to programming), you still have to understand the fundamental principles relatively well (in some ways this is even getting more important), it's just that the execution-part itself becomes significantly less important.",
                  "score": 2,
                  "created_utc": "2026-02-23 20:26:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6w9879",
              "author": "soldierswitheggs",
              "text": "> However, very soon (or even now?) models might be able to plan something like the layout of multiple panels at once - something like \"this panel should create this and that impression\", and then they can generate the appropriate prompt for i.e. the perspective or something, and also check if the produced image has the right properties...\n\nI'm sure this is what a lot of people here want, but it sounds downright dystopian to me.\n\n\"Hey, Gemini. Can you write an ecchi fantasy adventure manga about a goblin for me? And then generate a hard science fiction novel about first contact with alien microorganisms on a colony ship, so I have something to read in bed.\"\n\nI can understand the appeal on some level, but we're already in an age of fairly disposable, commercialized media. The idea of less and less human intention and effort going into every sentence or panel... it just leaves me pretty cold.\n\nThis isn't wholly unique to gen AI. Lots of tools lower the skill or intent required to produce a work. Photography. Digital art tools. Buying paints rather than crafting them yourself, by hand. But I feel like there comes a point where the input from the creator becomes minimal enough that we risk *everything* becoming slop.",
              "score": 1,
              "created_utc": "2026-02-23 03:59:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6wau5m",
                  "author": "HighDefinist",
                  "text": "> I can understand the appeal on some level, but we're already in an age of fairly disposable, commercialized media.\n\nTo me, this sounds extremely arbitrary... kind of like \"cars are dystopian and inhumane because only living beings like horses should be responsible for the locomotion of people\".\n\nI mean... ok, sure, I can understand why people might have this emotion, and presumably this wasn't an unusual viewpoint 100 years ago. But... I don't feel this way at all, and I see no reason why I should.\n\nI also find it a bit narrowminded... as in, this idea that \"crafting by hand\" is somehow inherently superior to \"crafting by mind\" seems unnecessarily restrictive with regards to how to use human creativity.\n\nAnd, what is the real motivation by those opposed to AI? Perhaps it is some kind of gatekeeping? As in, \"only artists should be allowed to produce art, because if everyone can do it, then us artists can no longer feel special\"?\n\nIn any case, one of this particularly important I think - we live in a free world, and, for example, people who enjoy porn and those who hold Puritarian beliefs can coexist peacefully. The same is true for AI-generated art, so if you don't like it, that is ok, and there is also nothing wrong about you communicating about your dislike for AI with others - as long as you understand that people like me will not look at people like yourself as someone whose opinions, views, and thoughts are worth taking seriously.",
                  "score": 0,
                  "created_utc": "2026-02-23 04:10:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6wb8hf",
          "author": "sukebe7",
          "text": "LOL, I was just thinking about your initial post the other day.",
          "score": 3,
          "created_utc": "2026-02-23 04:13:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zu4br",
              "author": "Portable_Solar_ZA",
              "text": "Glad people didn't forget about it. I'm still slowly chipping away at things when I can!",
              "score": 2,
              "created_utc": "2026-02-23 18:30:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wbq3o",
          "author": "T_D_R_",
          "text": "Really cool and amazing ",
          "score": 2,
          "created_utc": "2026-02-23 04:16:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zu5qx",
              "author": "Portable_Solar_ZA",
              "text": "Appreciate the positive vibes!",
              "score": 2,
              "created_utc": "2026-02-23 18:30:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wzsnt",
          "author": "Alpha_wolf_80",
          "text": "Bro I didn't even notice this was AI. I am cooked",
          "score": 2,
          "created_utc": "2026-02-23 07:33:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zu9oy",
              "author": "Portable_Solar_ZA",
              "text": "Are you cooked because you're an artist?",
              "score": 1,
              "created_utc": "2026-02-23 18:30:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6x16b4",
          "author": "KallistiTMP",
          "text": "I'm also working on a comic project, would love to hear about your overall workflow",
          "score": 2,
          "created_utc": "2026-02-23 07:46:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zum7y",
              "author": "Portable_Solar_ZA",
              "text": "So I've been meaning to put together a workflow document to be a companion piece to my future comics, just so people can see this is not just \"put in prompt get out comic\". But it's going to be a while before I get to it.\n\nIf this helps, this is one of the videos that I learnt from that helps me guide the model and its output based on my sketches:\n\n[https://www.youtube.com/watch?v=bKHo2Gh9O-c](https://www.youtube.com/watch?v=bKHo2Gh9O-c)",
              "score": 1,
              "created_utc": "2026-02-23 18:32:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6y9q7h",
          "author": "Culturedcontentres",
          "text": "Only two things I want to know. How? And when can we get more ms. Ayako",
          "score": 2,
          "created_utc": "2026-02-23 13:56:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zuzjc",
              "author": "Portable_Solar_ZA",
              "text": "Krita AI and an SDXL model. I vaguely touch on my process in my other post, but here's a video to get you started. This is close-ish to what I do with my process for images at least.\n\n[https://www.youtube.com/watch?v=bKHo2Gh9O-c](https://www.youtube.com/watch?v=bKHo2Gh9O-c)\n\nIn regards to more? Working on the storyboards after I've finished the cover, but I can't commit to any completion deadlines. This is just a passion project that I do after work and outside of my social/family commitments.",
              "score": 1,
              "created_utc": "2026-02-23 18:34:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ygiz1",
          "author": "Drawsstuff",
          "text": "Wow that looks great! I've recently taken on a similar project so I know it requires a lot of work. Great job!",
          "score": 2,
          "created_utc": "2026-02-23 14:34:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zv0ya",
              "author": "Portable_Solar_ZA",
              "text": "Thanks for the positive vibes!",
              "score": 1,
              "created_utc": "2026-02-23 18:34:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vxlvv",
          "author": "K0owa",
          "text": "Inspiring certainly. I don‚Äôt read hentai type stuff tho. Not that this is showing porn but it‚Äôs teetering on the edge. Last real manga I read was Trigun. Last comic I read was Batman new 52 which was terrible and then I stopped reading comics after that.",
          "score": 3,
          "created_utc": "2026-02-23 02:44:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zv98a",
              "author": "Portable_Solar_ZA",
              "text": "Yeah, it's intentionally fanservice/ecchi. \n\nThere's still a lot of great manga/comics, but like with anything these days you have to dig through to find the gems. ",
              "score": 1,
              "created_utc": "2026-02-23 18:35:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6zxxxx",
                  "author": "K0owa",
                  "text": "Actually, I did just read some Berserk recently. I tend to not read something unless someone recommends it.",
                  "score": 1,
                  "created_utc": "2026-02-23 18:47:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6v0863",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 2,
          "created_utc": "2026-02-22 23:27:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zvrg8",
              "author": "Portable_Solar_ZA",
              "text": "Thanks. With me being more comfortable with the overall workflow, I've been intentionally trying to push image composition a bit further. \n\nSo I actually sketch straight into Krita. I start with a standard A4 300 DPI page for my storyboards. I think copy the sketch for each panel from the storyboard into a new KRITA page (I manually adjust the size depending on what aspect ratio I need for the panel). Some are standard 1024x1024, but others I go up to 1536x1536. Again, I play with these depending on whether I need portrait or landscape panels.",
              "score": 1,
              "created_utc": "2026-02-23 18:37:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wvd18",
          "author": "Hearcharted",
          "text": "LoRA: THICC PRO MAX ü§î",
          "score": 1,
          "created_utc": "2026-02-23 06:53:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zxwv7",
              "author": "Portable_Solar_ZA",
              "text": "She's definitely meant to be curvy.",
              "score": 2,
              "created_utc": "2026-02-23 18:47:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o72pwn0",
                  "author": "Hearcharted",
                  "text": "![gif](giphy|gictytW9IIIkNGIMcs)\n\n",
                  "score": 2,
                  "created_utc": "2026-02-24 03:34:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6wwn87",
          "author": "desktop4070",
          "text": "I highly recommend using a custom font for the text, or even drawing the text yourself. You'd be surprised how that alone makes the dialogue much more interesting to read than with a standard font.",
          "score": 1,
          "created_utc": "2026-02-23 07:04:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zy55b",
              "author": "Portable_Solar_ZA",
              "text": "Thanks, but I don't really have the time to clean up the text on top of the art. Maybe when I finish the art I'll see about giving the font/writing itself a bash.",
              "score": 1,
              "created_utc": "2026-02-23 18:48:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6ztrcr",
          "author": "BlobbyMcBlobber",
          "text": "This is serviceable. It's not going to win awards for layout and framing but it's definitely readable. Question is can you make it interesting and varied beyond just the most simple layouts.\n\nI don't think this is ready for paid content. It feels like a hobby project. Maybe in the future if it really turns into something great.",
          "score": 1,
          "created_utc": "2026-02-23 18:28:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zz22b",
              "author": "Portable_Solar_ZA",
              "text": "Thanks for the feedback. In regards to the layouts, that's intentional at this point. Once I can complete a comic with fairly generic panelling, I'll try to get a bit more experimental.\n\nAnd thank for your thoughts on things otherwise. Just trying to get a realistic gauge of where this project is at.",
              "score": 1,
              "created_utc": "2026-02-23 18:52:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o70hp4z",
          "author": "PerformanceNo1730",
          "text": "Excellent work! Impressive.  \nSo you use a LoRa to keep your main caracter consistant ? You trained your LoRa yourself, or how did you get there ?  \nDo you post-process your generated image ? Typically to force greyscale / black and white ?",
          "score": 1,
          "created_utc": "2026-02-23 20:19:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o70iwhw",
              "author": "Portable_Solar_ZA",
              "text": "Yes, I trained a lora, but it was my first lora so it's not very consistent. It has about 60-70% accuracy, after which I go in and edit manually, and after edits, remove the lora and do a partial refinement using the ai model to smooth things out a bit. My second lora seems to be better, but will only properly find out once I start my next pages.\n\n\nI use a black and white manga model. I think it's beret manga mix and is on civitai.¬†",
              "score": 2,
              "created_utc": "2026-02-23 20:25:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o70k2a1",
                  "author": "PerformanceNo1730",
                  "text": "OK I did not know this model. I am having a look right now.  \nThank you for the feedback on the LoRA. Percistent caracter is a real pain.  \nI can imagine the amount of work good job !",
                  "score": 2,
                  "created_utc": "2026-02-23 20:30:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6v0ci7",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-22 23:28:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zx185",
              "author": "Portable_Solar_ZA",
              "text": "Ya, it's not a big deal so haven't bothered to add any texture to it.",
              "score": 1,
              "created_utc": "2026-02-23 18:43:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6uiqpe",
          "author": "Enshitification",
          "text": "I appreciate you sharing your work, but I hope you aren't outing yourself here if your readers weren't previously aware of your particular art technique.",
          "score": 1,
          "created_utc": "2026-02-22 21:53:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ujcla",
              "author": "Portable_Solar_ZA",
              "text": "No, I haven't released anything except for the pages I posted previously in my first post here. I also plan to be completely open with my use of generative AI tools and plan to release a mini-workflow with each book to show it's not just \"put in prompt get out comic page\". I've showed some of my work in progress stuff to close offline friends for feedback already, but I'm also very aware that some of my art friends will probably be very upset that I'm using AI to complete creative projects at all...",
              "score": 7,
              "created_utc": "2026-02-22 21:56:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6ukmdk",
                  "author": "Enshitification",
                  "text": "Very cool. I admire your forthrightness.",
                  "score": 1,
                  "created_utc": "2026-02-22 22:03:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6uy00j",
          "author": "maxtablets",
          "text": "this looks pretty good. It's not clear how much the ai workflow is doing though as you haven't shown what the level of the sketches are this time.\n\nI'm wanting to figure out a similar type of workflow though i'm more interested in using it to do half tone shading, speed lines, cross hatch shading, conversion of 3d bg into heavy stylized ink style backgrounds. I don't trust it with the figure drawing as I have more stylistic preferences. \n\n1) first image. the pose in the clock image is too flat, imo. You can stick the clock in the back of the first image.\n\n2) not really, yet. It looks good, but to really take advantage of A.I, I'd expect at least the visual quality of mitsuyoshi kanketsuhen. I like the high contrast look you got though. Just a little more immersion. There is not enough writing to know if its a story to be interested.\n\n",
          "score": 1,
          "created_utc": "2026-02-22 23:15:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zwftt",
              "author": "Portable_Solar_ZA",
              "text": "Thanks, sorry I haven't gotten into detail with my workflow. That on its own is a little mini project and I'm just trying to get the comic itself finished.\n\nSo I've dabbled with backgrounds and found that the SDXL models I've tried are generally pretty good at them. Effects are another story. At this point I tried using Flux2 Klein 9b and it's very hit and miss at adding effects. However, there has been some happy accidents with screen tones and shading that it made that have given me some ideas.",
              "score": 2,
              "created_utc": "2026-02-23 18:40:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6v1z6k",
          "author": "KaradocThuzad",
          "text": "I remember you posting before!\n\nThis is really great, I honestly look forward to reading the finished work, I can only imagine the time it takes to work on your workflows and to learn how to make a decent comic.\n\nGood luck, I'll keep an eye out for your work!",
          "score": 1,
          "created_utc": "2026-02-22 23:37:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zwhrf",
              "author": "Portable_Solar_ZA",
              "text": "Thank you. Appreciate the positivity!",
              "score": 1,
              "created_utc": "2026-02-23 18:40:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6v3h9o",
          "author": "Soraman36",
          "text": "Not going to repeat what others already said but so far so good. I give it a few more months and you'll get it down",
          "score": 1,
          "created_utc": "2026-02-22 23:46:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zwk6q",
              "author": "Portable_Solar_ZA",
              "text": "Really appreciate it. As I've said to the others, appreciate the good vibes.",
              "score": 2,
              "created_utc": "2026-02-23 18:41:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vsf1l",
          "author": "ModFrenzyAI",
          "text": "Man, Krita AI is the goat! I don't know if **Acly** is in this subreddit or not but huge thanks to him! I've started creating stuff with AI 2 months ago and I feel like Krita AI made things so much simpler and easier for me. ",
          "score": 1,
          "created_utc": "2026-02-23 02:12:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zwxp8",
              "author": "Portable_Solar_ZA",
              "text": "Dude, I love KRITA AI. I probably wouldn't be interested in AI creative projects if it wasn't for this tool.  \n  \nAlso, this video helped me out so much to try and squeeze as much as possible out of an AI model rather than just relying on prompts and roll of the dice with image-to-image generation:\n\n[https://www.youtube.com/watch?v=bKHo2Gh9O-c](https://www.youtube.com/watch?v=bKHo2Gh9O-c)",
              "score": 1,
              "created_utc": "2026-02-23 18:42:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6vz3hd",
          "author": "STurbulenT",
          "text": "his is more a proof of concept for¬†you",
          "score": 1,
          "created_utc": "2026-02-23 02:53:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vo376",
          "author": "Beginning-Struggle49",
          "text": "Wow this is great ! I've also been experimenting making comics, but I'm always having trouble with the angles. Maybe I should try manga style loras instead, I've generally just been trying to use a generic anime style using qwen image edit\n\n\n1) I like the first cover more\n\n2) No sorry, I don't even pay for comics of people who really draw them, I wouldn't start with an AI artist :)\n\n3) check out storinex.com maybe",
          "score": 0,
          "created_utc": "2026-02-23 01:46:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zxoke",
              "author": "Portable_Solar_ZA",
              "text": "Thanks for the suggestion.",
              "score": 1,
              "created_utc": "2026-02-23 18:46:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o708vt7",
                  "author": "Beginning-Struggle49",
                  "text": "you're welcome!",
                  "score": 1,
                  "created_utc": "2026-02-23 19:37:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6w7nhs",
          "author": "wasabi991011",
          "text": "> Finally, if you have any other constructive thoughts/feedback, please feel free to add them here.\n\nI don't know how to say this nicely, but I have to say it anyway: it's way too pervy.\n\nLike as a layman, most of the framing stuff and angles and whatever is going over my head a bit. But what I notice is that the MC's bust and clothing (like the button almost exploding) feels like it's straight out of a hentai.  I'd understand if it was a NSFW comic like oglaf, but since it's not it makes me feel gross reading it.",
          "score": 0,
          "created_utc": "2026-02-23 03:48:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zxtoy",
              "author": "Portable_Solar_ZA",
              "text": "You're welcome to feel that way, but that's kind of the whole point of fanservice. Completely understand if it's not your thing though.",
              "score": 1,
              "created_utc": "2026-02-23 18:46:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wc7se",
          "author": "sukebe7",
          "text": "[https://mangadex.org/title/ff2d4da5-8b42-4fc9-8853-afda53874afb/ntr-kaeshi](https://mangadex.org/title/ff2d4da5-8b42-4fc9-8853-afda53874afb/ntr-kaeshi)",
          "score": 0,
          "created_utc": "2026-02-23 04:20:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ukqjq",
          "author": "InsolentCoolRadio",
          "text": "Great comic!\n\nI really loved the camera angle and use of negative space on the panel in image 7; I felt what Ayako was feeling.\n\n1. Cover #2 has a better vibe IMO; she looks more heroic and like someone to root for, whereas Cover #1 makes her seem more like a damsel or someone to look down on\n2. I‚Äôm not in the market to subscribe to anything, BUT if I were to buy something animated or illustrated I‚Äôd be super happy with this\n3. r/aicomics and r/aicomicmakers are pretty cool.",
          "score": -3,
          "created_utc": "2026-02-22 22:03:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ullkm",
              "author": "mobileJay77",
              "text": "Thanks for the links!",
              "score": 2,
              "created_utc": "2026-02-22 22:08:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6wl5ut",
                  "author": "InsolentCoolRadio",
                  "text": "Glad to help : )",
                  "score": 2,
                  "created_utc": "2026-02-23 05:26:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6zxf5f",
              "author": "Portable_Solar_ZA",
              "text": "Thanks. Appreciate the feedback regarding the covers. Like, I like the idea of #2 even though it looks a bit odd at the moment, but so many people have told me they like #1 more in relation to the comic... will have to see what I finally go with. \n\nAnd thanks for the suggestions.",
              "score": 2,
              "created_utc": "2026-02-23 18:45:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o71tk2i",
                  "author": "InsolentCoolRadio",
                  "text": "My pleasure! Thank you for sharing your comic with the community : )",
                  "score": 1,
                  "created_utc": "2026-02-24 00:26:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r99xn9",
      "title": "I built a free local AI image search app ‚Äî find images by typing what's in them",
      "subreddit": "StableDiffusion",
      "url": "https://i.redd.it/9go8g0andikg1.gif",
      "author": "ravenlolanth",
      "created_utc": "2026-02-19 20:10:57",
      "score": 193,
      "num_comments": 71,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1r99xn9/i_built_a_free_local_ai_image_search_app_find/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6b0cvs",
          "author": "X3liteninjaX",
          "text": "Nice to see you‚Äôre using cosine similarity for the semantic relationships, cool",
          "score": 10,
          "created_utc": "2026-02-19 20:41:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6bmr7t",
              "author": "ravenlolanth",
              "text": "Thanks!",
              "score": 2,
              "created_utc": "2026-02-19 22:32:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6axgbz",
          "author": "anon999387",
          "text": "\"First run will download the AI model (\\~1GB) automatically\"\n\nWhich model is used?\n\n",
          "score": 8,
          "created_utc": "2026-02-19 20:27:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6axu4i",
              "author": "ravenlolanth",
              "text": "This app uses \\*\\*OpenCLIP ViT-L-14\\*\\* trained on LAION-2B dataset by OpenAI/LAION.",
              "score": 16,
              "created_utc": "2026-02-19 20:29:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6bo3rc",
                  "author": "Excellent_Respond815",
                  "text": "You should use metas perception encoder. Much much better. I built a program that ingests footage on my works server, and I can search it via a plug-in I made for premiere pro. I can search through about 200 hours of footage for specific search terms and build a new timeline in about 30 seconds.",
                  "score": 14,
                  "created_utc": "2026-02-19 22:39:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6dvd7z",
                  "author": "overand",
                  "text": "CLIP stuff is so great! I installed Immich on a home server (without a GPU!) and wasshocked to see how effective the contextual search is on it - wild stuff.",
                  "score": 1,
                  "created_utc": "2026-02-20 07:33:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6awrpk",
          "author": "an80sPWNstar",
          "text": "whoa, now that is crazy. Imma try this out.",
          "score": 4,
          "created_utc": "2026-02-19 20:23:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6b5dbl",
          "author": "Calm_Mix_3776",
          "text": "Looks super handy! What does the \"Min Score\" knob do? Also, I would love to hear from other programmers that can review the code and confirm there's nothing nefarious going on there.",
          "score": 6,
          "created_utc": "2026-02-19 21:05:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6b61lg",
              "author": "ravenlolanth",
              "text": "Thanks! The \"Min Score\" slider sets the minimum similarity threshold for results , higher value means stricter matches, lower value shows more results even if they're less relevant. Default is 0.20 which works well for most searches! And totally fair concern, the code is fully open source, feel free to audit it yourself or wait for others to review it. Nothing shady going on, it runs 100% locally and never sends any data anywhere.",
              "score": 8,
              "created_utc": "2026-02-19 21:09:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6bl9rw",
                  "author": "Calm_Mix_3776",
                  "text": "Ah, got it. Is \"min score\" a technical term in computer vision? Why not \"similarity\" instead of \"min score\"? Wouldn't that be more straightforward and clear? I don't consider myself a total noob and even I was scratching my head wondering what that is, lol.",
                  "score": 2,
                  "created_utc": "2026-02-19 22:24:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ddklc",
          "author": "jastoubisaif",
          "text": "hi, just posting to tell you that your project is cool! then i've modified the code to implement two things:\n\n1) remove the min score and just show all results sorted by clip score, with a 'load more' beneath the results, so this becomes like a google search somewhat.\n\n2) add negative search term\n\nI believe if you can implement these into your base code too, it would be better.",
          "score": 4,
          "created_utc": "2026-02-20 05:00:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f6p6p",
              "author": "ravenlolanth",
              "text": "Thanks for the feedback and for taking the time to implement those!\n\nWould love to see your approach, Did you push your fork anywhere? are you jareddishman on GitHub? Noticed a fork with some interesting changes.",
              "score": 1,
              "created_utc": "2026-02-20 13:49:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6fnfbc",
                  "author": "jastoubisaif",
                  "text": "I would love to share my fork and hoping you can incorporate some of these enhancements. as of now i got to implement face search (using insightface), and a face manager as well. a local google photos, if you will. but you know, since gemini 3.1 does all of the codes, not sure the quality of it, but it works. so yeah, I‚Äôll fork it proper and push the changes there so you can review or merge if you want.",
                  "score": 1,
                  "created_utc": "2026-02-20 15:15:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6bhrvi",
          "author": "Bronzeborg",
          "text": "This would be such a cool addon for WizTree.",
          "score": 3,
          "created_utc": "2026-02-19 22:06:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6etq75",
          "author": "mega-cyan",
          "text": "I have always thought something like this could exist. Looks very well done. A few improvements:  \n\\- Multiple folder support  \n\\- accuracy improvements over time.\n\nOverall, very nice!",
          "score": 2,
          "created_utc": "2026-02-20 12:32:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6avwet",
          "author": "wholelottaluv69",
          "text": "That would be very useful to me.  I just have to decide whether I trust you or not, lul.\n\nEdited to add- FWIW, the comment was intended humorously.  That being said, I cannot get this to git-pull.  Something about a man-in-the-middle attack or \"inable to verify certificate\", or something similar.  Not savvy enough to deal with it atm.",
          "score": 4,
          "created_utc": "2026-02-19 20:19:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6b2c2s",
              "author": "some_ai_candid_women",
              "text": "You can audit the code using Antigravity.",
              "score": 10,
              "created_utc": "2026-02-19 20:51:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6aw4tb",
              "author": "ravenlolanth",
              "text": "why you need to trust me to use it ?\n\n",
              "score": 1,
              "created_utc": "2026-02-19 20:20:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6b4m1u",
                  "author": "megacewl",
                  "text": "cuz you‚Äôre a rando on the internet, and running executables on one‚Äôs machine, including executables that do work on the gpu (crypto mining anyone?) requires a lot of trust",
                  "score": 5,
                  "created_utc": "2026-02-19 21:02:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6b7472",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 3,
          "created_utc": "2026-02-19 21:14:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6b7iiq",
              "author": "ravenlolanth",
              "text": "![gif](giphy|GLbiGvv9qrpny)\n\n",
              "score": 8,
              "created_utc": "2026-02-19 21:16:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6cgw99",
                  "author": "Saucermote",
                  "text": "So encrypted password protected databases after indexing my perfectly normal and acceptable collection of ~~bondage comics~~ rare and antique vases?",
                  "score": 1,
                  "created_utc": "2026-02-20 01:28:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6b3n2u",
          "author": "futureman",
          "text": "Would it be possible to use something like this with a large folder of images of jewelry?",
          "score": 1,
          "created_utc": "2026-02-19 20:57:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6b4zo9",
              "author": "ravenlolanth",
              "text": "You can test it and tell me! I mostly tested it on art and anime pictures ",
              "score": 2,
              "created_utc": "2026-02-19 21:04:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6b63oj",
          "author": "Oer1",
          "text": "I've always thought I needed this. How long does the indexing take? I see other people made something similar, but without a ui? Also based on clip, like 4 years ago. Like this one https://github.com/yurijmikhalevich/rclip",
          "score": 1,
          "created_utc": "2026-02-19 21:09:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6b77f2",
              "author": "ravenlolanth",
              "text": "Indexing speed depends on your GPU ‚Äî on a decent NVIDIA GPU roughly 500-1000 images per minute, cached after that so searches are instant!\n\nI tried all the available tools and they were either a pain to set up or had no proper UI, so I just built my own.\n\nrclip is terminal only, this is meant to be accessible to everyone .",
              "score": 5,
              "created_utc": "2026-02-19 21:14:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6b8jgw",
                  "author": "Oer1",
                  "text": "Smart. I'm not a coder so can't review your code. But I wish you success. Will bookmark.\n\nI hope Windows hires you and builds this into their OS. (If it's sustainable)",
                  "score": 3,
                  "created_utc": "2026-02-19 21:21:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6bgvqf",
          "author": "angelarose210",
          "text": "Ohh I was gonna try using qwen3vl for this but it's so slow on my gpu (12gb) so this is perfect.",
          "score": 1,
          "created_utc": "2026-02-19 22:02:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6bh31s",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-02-19 22:03:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6bi0b1",
              "author": "ravenlolanth",
              "text": "Clone it anywhere you want, no specific location needed. For the venv , don't use your ComfyUI one, the dependencies might conflict. Just create a fresh one inside the cloned folder:   \npython -m venv venv   \nsource venv/Scripts/activate    \npip install -r requirements.txt   \nThen just run: python [Makimus-AI.py](http://Makimus-AI.py)",
              "score": 6,
              "created_utc": "2026-02-19 22:07:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6bl2qg",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 1,
                  "created_utc": "2026-02-19 22:23:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6bonqi",
          "author": "ill_B_In_MyBunk",
          "text": "Does it work with generated videos?",
          "score": 1,
          "created_utc": "2026-02-19 22:42:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6borjk",
              "author": "ravenlolanth",
              "text": "Currently this app works with images only.",
              "score": 2,
              "created_utc": "2026-02-19 22:43:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6bxv4r",
          "author": "xb1n0ry",
          "text": "It would be grade if the app could recognize people, so you can search by name or pick a face from the generated \"person library\"",
          "score": 1,
          "created_utc": "2026-02-19 23:35:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ciqia",
              "author": "ravenlolanth",
              "text": "Actually CLIP and most vision models aren't trained for facial recognition ‚Äî it's intentionally avoided due to privacy and copyright concerns around using people's faces in training data. Would need a completely separate dedicated model for that",
              "score": 3,
              "created_utc": "2026-02-20 01:39:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6fajy8",
                  "author": "xb1n0ry",
                  "text": "Thanks for your answer. I might be working on that maybe. It would be very useful for me to sort all images, originals and altered comfy outputs, of specific people in order to have them all sorted.\n\nWhat also interests me is why I wrote \"grade\" instead of \"great\" in my OP lol",
                  "score": 1,
                  "created_utc": "2026-02-20 14:10:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6d6pzy",
          "author": "Dead3y3Duck",
          "text": "Tkinter and pickle are some interesting choices üòÑ Pretty cool concept!",
          "score": 1,
          "created_utc": "2026-02-20 04:11:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dh1sp",
          "author": "Tony_Stark_MCU",
          "text": "Nvidia has a cool app that helps to find any video or image content",
          "score": 1,
          "created_utc": "2026-02-20 05:27:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dr7jd",
          "author": "Yegoriel",
          "text": "I don't have an Nvidia GPU, which is why I am not sure whether it will work on my Intel Arc or Intel CPU",
          "score": 1,
          "created_utc": "2026-02-20 06:55:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f827d",
              "author": "ravenlolanth",
              "text": "The app supports more than just NVIDIA: - NVIDIA GPU ‚Üí CUDA - Intel Arc on Windows ‚Üí DirectML (automatic) - Intel CPU ‚Üí falls back to CPU mode automatically.   \nIt detects your hardware on startup and uses the best available option ‚Äî no manual configuration needed. CPU mode works but indexing will be slower than a dedicated GPU",
              "score": 1,
              "created_utc": "2026-02-20 13:56:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6e4w5n",
          "author": "smereces",
          "text": "thanks for sharing it",
          "score": 1,
          "created_utc": "2026-02-20 09:02:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e6dnv",
          "author": "BigLoads69-420",
          "text": "If you can make it work on video like from wan this would be so cool",
          "score": 1,
          "created_utc": "2026-02-20 09:16:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6efuem",
          "author": "Erasmion",
          "text": "does one need to install python system wide?  i'd prefer a portable type of setup",
          "score": 1,
          "created_utc": "2026-02-20 10:44:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6esg2c",
          "author": "erasels",
          "text": "This seems pretty obviously vibe-coded (non-derogatory), I'm always interested, do you have a background in coding (your github account mostly shows beginner webdev repos) or did you just prompt the entirety for it?",
          "score": 1,
          "created_utc": "2026-02-20 12:23:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f7g31",
              "author": "ravenlolanth",
              "text": "I've taken quite a few web and Python courses since those old repos but never really pushed anything ‚Äî bad habit. It is AI assisted, but honestly AI can't just generate something like this from a single prompt right now. It took a lot of back and forth, testing, and human decisions along the way. Things like the VRAM/RAM management, switching from absolute to relative paths for portability, handling partial index saving, the ONNX fallback logic ‚Äî these came from actually running it, hitting problems, and fixing them. AI can help write code but it can't debug your specific hardware setup or make architectural decisions based on real world testing .",
              "score": 2,
              "created_utc": "2026-02-20 13:53:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6etn3d",
          "author": "JoZ3",
          "text": "Forgive my ignorance, or perhaps I overlooked it in the information, but what type of images does it support? I mostly have raw images.",
          "score": 1,
          "created_utc": "2026-02-20 12:31:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f7pvw",
              "author": "ravenlolanth",
              "text": "Currently it supports JPG, JPEG, PNG, WEBP, BMP and GIF. RAW files are not supported yet unfortunately ‚Äî RAW formats like .CR2, .NEF, .ARW require special libraries to decode.",
              "score": 4,
              "created_utc": "2026-02-20 13:54:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6flqyu",
                  "author": "JoZ3",
                  "text": "Thanks for responding. I'll take a look at the app anyway.",
                  "score": 1,
                  "created_utc": "2026-02-20 15:07:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6fam5d",
          "author": "tigercat300",
          "text": "This could really help people who have a ton of images and can't find what they need. It will be interesting to see how effectively it digs up those overlooked pictures.",
          "score": 1,
          "created_utc": "2026-02-20 14:10:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hak3e",
          "author": "Anstellos",
          "text": "nice. Can I run it on my hard drive and search inside photo folders? like jpegs or even raws?",
          "score": 1,
          "created_utc": "2026-02-20 19:48:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kd1xz",
          "author": "nikgrid",
          "text": "Great job OP. Star on git. If you could make it so you could delete selected images from right on the thumbnail screen that would be great.",
          "score": 1,
          "created_utc": "2026-02-21 07:11:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6obgwh",
          "author": "Living_Constant_5715",
          "text": "Super cool and works wonders. It would be nice to be able to select multiple images at once easier and mass delete things.",
          "score": 1,
          "created_utc": "2026-02-21 22:19:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6b894n",
          "author": "kanakattack",
          "text": "Yeah this won‚Äôt scale well. Okay for small batches.\nEdit - This can scale well.",
          "score": 0,
          "created_utc": "2026-02-19 21:19:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6b98eu",
              "author": "ravenlolanth",
              "text": "Tested it with 100k images and it handled it without any issues! Obviously the bigger the collection the longer the initial index, but after that searches are instant",
              "score": 12,
              "created_utc": "2026-02-19 21:24:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6esdt8",
                  "author": "Weird_With_A_Beard",
                  "text": "https://imgur.com/a/pdJRzyZ\n\nI let it scan overnight as I slept. Searches are super fast. Thanks!",
                  "score": 3,
                  "created_utc": "2026-02-20 12:23:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6bi0xj",
                  "author": "Bronzeborg",
                  "text": "is it censored?",
                  "score": 1,
                  "created_utc": "2026-02-19 22:08:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1ra1gu6",
      "title": "WAN VACE Example Extended to 1 Min Short",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/y2pp6gj0ookg1",
      "author": "pftq",
      "created_utc": "2026-02-20 17:21:27",
      "score": 185,
      "num_comments": 27,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Animation - Video",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1ra1gu6/wan_vace_example_extended_to_1_min_short/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6hr89w",
          "author": "broadwayallday",
          "text": "Thank you for posting this. These forums need to evolve from ‚Äúwhere workflow‚Äù to ‚Äúhow can I learn to tell stories with these amazing tools‚Äô",
          "score": 14,
          "created_utc": "2026-02-20 21:10:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xcjvw",
              "author": "martinerous",
              "text": "Unfortunately, some attempts of storytelling in this subreddit receive very few good reactions (or even get sunk immediately), especially if the video is not flashy and does not grab immediate attention with lots of action. If it's slow and more psychological than action, then it does not get far.",
              "score": 1,
              "created_utc": "2026-02-23 09:38:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6h8sme",
          "author": "nsfwVariant",
          "text": "Nice! How'd you manage to get the combat animations working? By default I've never gotten Wan to be able to make anything resembling a solid hit",
          "score": 8,
          "created_utc": "2026-02-20 19:39:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6hgibw",
              "author": "pftq",
              "text": "Here's a timelapse of some of the editing to give an idea.  There's a lot of just bruteforcing with rotoscoping things partially and letting AI fill in the gaps to complete the scene. Every shot in the video has at least 5 layers of things being rotoscoped/masked. [https://x.com/pftq/status/2024944561437737274](https://x.com/pftq/status/2024944561437737274)",
              "score": 15,
              "created_utc": "2026-02-20 20:17:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6hnd6v",
                  "author": "nsfwVariant",
                  "text": "Gotcha! Never thought of using inpainting to fill in combat movements before, that's smart. Have you played around with wan-move much? I've had success using it for combat movements, it's been my go-to so far.\n\nNext question... which version of VACE are you using, and are you doing anything special with it? I've found the fill-in from rotoscoping things with VACE to be very imprecise, it misses grey sections quite a lot, particularly on the outlines of the masks - have to do a ton of post-processing/editing to fix it. But yours seems to work seamlessly off the bat, based on that timelapse you shared!",
                  "score": 1,
                  "created_utc": "2026-02-20 20:51:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6hga9d",
          "author": "James_Reeb",
          "text": "Much more funny and original than those Ai slop with seedance 2 copycat of famous actors fighting",
          "score": 16,
          "created_utc": "2026-02-20 20:16:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hcz0d",
          "author": "James_Reeb",
          "text": "Excellent",
          "score": 4,
          "created_utc": "2026-02-20 20:00:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jqwsp",
          "author": "hidden2u",
          "text": "Ah it‚Äôs the new twilight movie with were-squirrels \n\n\n(this is great)",
          "score": 3,
          "created_utc": "2026-02-21 04:10:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6i0m51",
          "author": "Townsiti5689",
          "text": "Looks great. The CGI action reminded me of the earlier Matrix films. Seems we're at the late 90s/early 2000s stage of AI filmmaking, and only after, what, two years? A year from now, AI will likely be caught up to modern day.",
          "score": 5,
          "created_utc": "2026-02-20 21:57:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6i4c7m",
              "author": "pftq",
              "text": "Thanks. Some of that was intentional. We grew up on late 90s films, so we wanted to give that same feel.",
              "score": 5,
              "created_utc": "2026-02-20 22:16:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6ksqxr",
                  "author": "Townsiti5689",
                  "text": "It looks really good. I don't know what your post production was like, but without AI, it would have taken a long time and required lots of After Effects knowledge, and likely other stuff, and still probably wouldn't have looked half as good as it does. \n\nAI is an incredible tool for filmmakers who know how to use it. Excellent job.",
                  "score": 1,
                  "created_utc": "2026-02-21 09:45:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6hl5o7",
          "author": "you_will_die_anyway",
          "text": "Loved it :D",
          "score": 2,
          "created_utc": "2026-02-20 20:40:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jz3q7",
          "author": "Itchy_Ambassador_515",
          "text": "oh man your creativity is awesome! really enjoyed it",
          "score": 2,
          "created_utc": "2026-02-21 05:11:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6igx84",
          "author": "Borkato",
          "text": "This is amazing and should be spread everywhere. I recommend cutting the first part out with the fire and just do the squirrel hitting the guy and up to the headphones guy and it‚Äôll go viral",
          "score": 2,
          "created_utc": "2026-02-20 23:24:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6i014r",
          "author": "IrisColt",
          "text": "I wanted the squirrel to win so badly that I‚Äôm thrilled.",
          "score": 1,
          "created_utc": "2026-02-20 21:54:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6im27v",
          "author": "HM_mtl",
          "text": "What is the hardware you used?",
          "score": 1,
          "created_utc": "2026-02-20 23:54:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jvjam",
          "author": "ThePromptCollective",
          "text": "Wow, that was impressive! How did you do this?",
          "score": 1,
          "created_utc": "2026-02-21 04:44:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6k9qdg",
          "author": "goddess_peeler",
          "text": "Thanks for sharing! I use VACE mostly for smoothing transitions between independently generated clips. It's like magic how that awkward motion goes away. I've long been aware of VACE's many other talents, but I've only played with them a little, since they're outside of my primary use case.\n\nLooking at your workflows and what you've written about them, I notice there's no use or mention of Wan 2.2 Fun VACE. Even your \"2.2 workflow\" seems to just be a 2.1 workflow that loads the 2.2 low noise t2v model instead of the 2.1 t2v model.\n\nCan you say why this is? I'm curious. For what I do with it, Fun VACE produces superior results (motion, image quality) to 2.1 VACE. But I know the community tends to dismiss Fun VACE because it's not \"real\" VACE. I'd love to hear your take.",
          "score": 1,
          "created_utc": "2026-02-21 06:40:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kc2il",
              "author": "pftq",
              "text": "I gave it a shot a few times but always ended up with bad results.  For me it's more important that the video look consistent with the original (color, quality, etc).  ",
              "score": 1,
              "created_utc": "2026-02-21 07:02:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6kgt99",
          "author": "01010110_",
          "text": "Er det deg CMK?! ",
          "score": 1,
          "created_utc": "2026-02-21 07:47:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qkely",
          "author": "SaltyAd8309",
          "text": "When I see all the steps required to create a video using AI, I tell myself that it's not going to be anytime soon that novices like me will be able to have fun creating something coherent.",
          "score": 1,
          "created_utc": "2026-02-22 07:42:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75ihob",
          "author": "Optimal_Map_5236",
          "text": "I tried something like this for object swap. I was trying to add some hat to my character through the 30secs video. The first video is generated well using an inpainted reference image.  I used sam3 for masking and ImageCompositeMasked for grey masking. To maintain consistency, I use the last frame of the first video as the reference image for the second video. because if I provided another inpainted image for the second clip the shape would never match. anyway then I realized I can send bunch of imgs to ref image input in WanVaceToVideo Node. I think this way feels better Idk. However, I‚Äôve noticed that the color and shape of the hat change significantly starting from the second video. This issue becomes particularly severe when the video exceeds 3 seconds even in the first clip. so I changed my plan to make 2 seconds long videos then stich them up. but it still produce some color and shape shifting. I chained the process  until 5 clips. then at 5 clip, it always ruined the whole shape.  They say wan2.2 fun vace is better but its node doesn't have mask input so there's no way for object swap in wan 2.2 fun vace. Do you have any solutions to resolve this? I'm sure there is because I've seen 1min long video where some objects are removed but there was no color shifting and weird artifacts. I compare it to the original video, it was beautifully done. I just don't know how. been asking around this and no one answered. ",
          "score": 1,
          "created_utc": "2026-02-24 15:42:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kimy2",
          "author": "Beneficial_Toe_2347",
          "text": "Looks like absolute shit with jarring transitions and horrible framerate\n\nI honestly think the community can no longer judge what good looks like",
          "score": 1,
          "created_utc": "2026-02-21 08:05:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kuiqh",
          "author": "Mohondhay",
          "text": "This is super amazing quality of work. Feels like I just watched a real clip from a action movie! üôåüèº",
          "score": 0,
          "created_utc": "2026-02-21 10:02:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6h56cq",
          "author": "mister2d",
          "text": "ü•±",
          "score": -11,
          "created_utc": "2026-02-20 19:22:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8clyn",
      "title": "I updated my LoRA Analysis Tool with a 'Forensic Copycat Detector'. It now finds the exact training image your model is memorizing. (Mirror Metrics - Open Source)",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1r8clyn",
      "author": "JackFry22",
      "created_utc": "2026-02-18 19:25:17",
      "score": 179,
      "num_comments": 40,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1r8clyn/i_updated_my_lora_analysis_tool_with_a_forensic/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o66jpw4",
          "author": "seeker_ktf",
          "text": "This is off topic, mostly, so apologies.\n\nI'm wondering if this new feature can be used or adapted to a problem I keep running into. The scenario is I train the LoRA, run it through your program and find the offender, then I throw it out and retrian. Cool, but what I'd rather do is to have a program that looks at my training dataset and tells me how many redundant photos I have. I have noticed that very often with training datasets, less is more. Adding more photos just makes training go longer without any real change. The tool I \"need\" is one that can scan through a lot of photos and rank them in order of similarity to the rest of the dataset.\n\nI don't know if that completely makes sense, but I'm hoping you are getting the gist of what I am talking about.",
          "score": 5,
          "created_utc": "2026-02-19 03:39:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o685xez",
              "author": "addandsubtract",
              "text": "I don't think that's off-topic at all, and something this tool can provide, too. You could probably do it already (albeit kinda slow), by moving one training image (at a time) into the Lora_Candidates folder and running the script. Having a separate script for this, would be a lot better, though.",
              "score": 2,
              "created_utc": "2026-02-19 11:47:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o68gi5u",
              "author": "The-Fine-Tuning-Guy",
              "text": "It‚Äôd be **clutch** if this tool had this feature, since it would totally **speedrun** creating synthetic datasets.\n\nIt would basically act as a character auditor/facial recognition tool, grabbing the images with the best **likeness** to your character. The automation here would be a total **W**.\n\nI train and sell ai models for living, so this would be a complete **game changer** for my daily workflow",
              "score": 2,
              "created_utc": "2026-02-19 13:02:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o63x2uu",
          "author": "JackFry22",
          "text": "Hi everyone!\n\n\n\nLast week I shared \\`MirrorMetrics\\`, a local tool to evaluate LoRAs using biometric telemetry (InsightFace) instead of just \"vibes\". The feedback was amazing, and thanks to a user's insight about dataset consistency, I realized we were missing a critical piece of the puzzle: \\*\\*Forensics.\\*\\*\n\nI just released \\*\\*v0.10.0\\*\\*, and it introduces two major features based on your requests:\n\n\n\n\\### 1. The \"Copycat\" Detector (Forensic Analysis) üïµÔ∏è‚Äç‚ôÇÔ∏è\n\nWe all fear overfitting. But usually, we just look at a generated image and think \"This looks stiff.\"\n\nNow, the tool runs a \\*\\*Nearest Neighbor Search\\*\\* in the vector space.\n\n\\* It compares every generated image against your entire training dataset.\n\n\\* It generates a visual report (see screenshot) showing exactly WHICH training image inspired the generation.\n\n\\* \\*\\*The Utility:\\*\\* If you see a similarity score > 0.90, your model isn't learning concepts; it's photocopying pixels. You can now pinpoint exactly which images are \"poisoning\" your training.\n\n\n\n\\### 2. Macro/Close-up Rescue (Smart Padding) üî≠\n\nA limitation of InsightFace/RetinaFace is that it often fails to detect faces in extreme close-ups (because the face fills the frame, hiding the edges).\n\nI implemented a \\*\\*\"Rescue Mode\"\\*\\*: if a face isn't found, the tool automatically applies a smart padding (\"zoom out\") and retries.\n\n\\* \\*\\*Result:\\*\\* In my tests, this recovered about \\*\\*10-15% of valid dataset images\\*\\* that were previously ignored. These are often the high-texture images crucial for skin/age evaluation!\n\n\n\n\\### Links\n\nThe tool is 100% Open Source and runs locally on your GPU.\n\n\n\n\\* \\*\\*GitHub (Code & Install):\\*\\* [https://github.com/AndyLone22/MirrorMetrics](https://github.com/AndyLone22/MirrorMetrics)\n\n\\* \\*\\*CivitAI (Full Guide):\\*\\* [https://civitai.com/articles/26241/stop-training-on-vibes-a-visual-guide-to-biometric-lora-diagnosis-mirror-metrics](https://civitai.com/articles/26241/stop-training-on-vibes-a-visual-guide-to-biometric-lora-diagnosis-mirror-metrics)\n\n\n\nLet me know if the \"Copycat\" report helps you prune your datasets! I'm currently experimenting with 3D Latent Space visualization for the next update. üöÄ",
          "score": 21,
          "created_utc": "2026-02-18 19:25:32",
          "is_submitter": true,
          "replies": [
            {
              "id": "o66zomc",
              "author": "ScrotsMcGee",
              "text": "Nice. I started playing around with Deepface and a few other programs just last week to see if I could achieve something similar and was considering insightface, but put it all in the too hard basket.",
              "score": 2,
              "created_utc": "2026-02-19 05:28:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o69bjcj",
                  "author": "JackFry22",
                  "text": "well let me know if this is easy to download and use. I built the repo so that you don't have to mingle with cuda, dlls and such. Just download, run the requirements and run the bat file. Simple as that. Curious to hear from you if this all falls together easily!",
                  "score": 2,
                  "created_utc": "2026-02-19 15:50:20",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o652v0c",
          "author": "ArmadstheDoom",
          "text": "I know I'm basically saying what I said before but I genuinely don't understand what you're trying to do here conceptually speaking. You keep throwing in things and it's not clear where or how they come into effect. For example, you cite nano banana pro, which is a paid model you can't train loras for. So I don't know what you're doing there, or with gemini. \n\nUnless you're trying to generate people via their paid model, and then tell them to generate more images with that same person? And if so, I have no idea why you need or would want a lora for that? Just use a real person at that point? \n\nLike I don't know what you're doing here, training wise. Are you just training loras, saving every epoch, and then generating images based on the same prompts as your dataset? Because if so, you'd *want* them to look as similar as possible, that's the whole point. And obviously, if your outputs don't look right, that is also obvious that it's undertrained. \n\nA very normal way to test if something is overtrained or overfitted is to just put it in a pose or a perspective that isn't in your dataset *at all*, such as over the shoulder from behind or from above or something. \n\nI'm really not trying to be mean but you seemed to have created a lot of data, but none of the data really *means* anything and it's not that you've stopped working off of vibes, you've just created infographics for those vibes? Because the data is no less vibes based than just eyeballing it, and when it's *not*, it's rather obvious. \n\nAgain, I don't know what you're trying to do; if you're trying to measure how accurate a realistic lora is for a person, then there is a single baseline, which is 'how close to the training data can it get while being able to replicate it *outside of your training data.*' Right now, it's unclear you're testing anything in a way that would give you good results that's not vibes based, because you proved for yourself that you don't need a computer to tell you that it's over or underfitted based on the output images.\n\nMeaning that in the course of generating the images you learned the same thing all the random data you gathered told you. That means it's not needed because you already have the info. \n\nThe sole time this is useful is if you're trying to judge between two or three near identical checkpoints. But even *then* that's just vibes because the amount of things each one can do is going to vary due to how LORAs learn. The one that might produce better front results might do worse from the side, and the one with better results from the side might do worse from the front. \n\nBut nothing you've made makes the process and more accurate. It's just datasets showing you what you already know. \n\nAnd it's not a case of removing data; if you remove the data because you think that image is overfitted, that's not going to result in a more accurate result, it's going to result in something completely different, namely the model being now overfitted on those images. \n\nWhen you prune datasets, the things you want to remove are not the things it does *well,* but the things it does *poorly,* because it's confusing the model and skewing results. If you're overfitting to one thing, that means you need *more varied data* not *less data overall.* \n\nIt just seems like everything you're doing here is counterproductive and not likely to give you better, more accurate results with any local model. ",
          "score": 19,
          "created_utc": "2026-02-18 22:39:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6595s7",
              "author": "JackFry22",
              "text": "Thanks for the detailed feedback!  \nI think there is a significant misunderstanding regarding the workflow and the goal of this tool (my bad surely, I must be more precise when I write). Let me clarify:\n\n**1. The Workflow (No paid models involved)** Nano Banana was only used to generate the images needed to show CLEAR results on the charts and I needed to have them fast to simulate precise results and create the guide. If you look at the guide I made in CivitAI it should be clear from the first graph: overfit, undertrain, ok. [https://civitai.com/articles/26241](https://civitai.com/articles/26241)\n\nNow to create a graph showing exactly what this tool is capable of, I would've had to make at least 2 overly and intentionally wrong trainings, which would have resulted in a waste of compute (and money in my case since I don't have big harware and should've rented it on cloud).\n\nHope this clarifies why the use of Nano Banana (which is a paid model, and out of the scope of this tool, as you suggested, but a necessary evil in the name of clarity).\n\n**2. \"Vibes\" vs. Metrics (The core disagreement)** You say: *\"You proved for yourself that you don't need a computer to tell you that it's over or underfitted based on the output images.\"*\n\nI'm not sure I agree with this, and I say it from experience. The \"Eyeball Test\" (Vibes) works fine if you are checking 5 images (the examples created for the guide are extremized to show clearly the difference, as I mentioned before). But it fails completely if you are comparing:\n\n* 5 different checkpoints (Epoch 10 vs 15 vs 20).\n* 3 different learning rates.\n* A batch of 100 generated images across multiple angles.\n\n**MirrorMetrics** turns *\"I think this looks a bit like him\"* into *\"Cosine Similarity: 0.78\"*. It turns *\"This model seems stiff\"* into *\"Pose Variance: Low\"*. It allows you to **quantify** the trade-off between flexibility and likeness. It's the difference between cooking by smell and cooking with a thermometer. Of course, both methods work, and one might say that the better chef cooks just by tasting and smelling, but the mathematical method is in my opinion a \"good addition to the toolkit\".\n\n**3. Overfitting & The Copycat Detector** You mentioned: *\"If you remove the data because you think that image is overfitted... it's going to result in the model being now overfitted on those \\[other\\] images.\"*\n\nThis is technically incorrect in the context of Deep Learning. If a specific image in your dataset has a similarity of >0.95 with the output (meaning the model is memorizing/photocopying it regardless of the prompt), that image is acting as a **\"Gradient Black Hole\"**. It's overpowering the weights. Removing or fixing the caption of that specific outlier allows the model to distribute its attention better across the rest of the dataset, actually **increasing** generalization, not reducing it.\n\n**TL;DR:** The tool is for users who want to move from \"feeling\" that a model is ready to \"knowing\" it is ready based on biometric data (InsightFace), especially when fine-tuning delicate parameters.\"\n\nBut, as I mentioned from the beginning: this is just a tool, it should be taken as such.  \nOther thing I mentioned before: I love Data Science and pretty graphs, so... there's that too. ü§£",
              "score": 6,
              "created_utc": "2026-02-18 23:12:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6bqf2y",
                  "author": "tom-dixon",
                  "text": "Wtf is with all the llm answers. Why don't you use your own words? So verbose for no real reason.",
                  "score": 3,
                  "created_utc": "2026-02-19 22:52:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o65tobl",
                  "author": "Loose_Object_8311",
                  "text": "First I'm learning about gradient black holes. That's a thing!??? Why is that a thing??¬†",
                  "score": 2,
                  "created_utc": "2026-02-19 01:05:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o65c7g7",
          "author": "cradledust",
          "text": "So, this is telling me that the images poisoning my dataset are the ones with more than one person in it, a dark photo, wearing sunglasses, a hand over the mouth, or a side profile. I read that a good dataset is that you need to include some additional faces otherwise a character Lora trained on only images with one person in them will make every face in an image the same and that you need a few side profiles and some dark images. That's why you have the txt part of the set to explain the image. Is a little poisoning of the dataset still helpful when it contains information the training hasn't seen yet?",
          "score": 4,
          "created_utc": "2026-02-18 23:28:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6831uy",
              "author": "zefy_zef",
              "text": "Is it possible that adjusting the captions for those specfic images helps? Basically,  describing the target in a more specially-relative manner, or referencing the lighting style in some way.",
              "score": 4,
              "created_utc": "2026-02-19 11:24:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o69amu3",
                  "author": "JackFry22",
                  "text": "that could help, but it's beyond the scope of this tool. What you're talking about is the difficult art of Captioning, which by the way, in my latest experiences I'm much uncertain of the necessity for it. \n\nZ-Image, QWEN and WAN22 I've trained without captioning, just using \"woman\" or \"man\" as trigger words, and the LoRAs came out about as good as with the captioning. Don't really know why yet, But it intrigues me and I want to learn more about the algorithms for the Training to understand better the underlying structure.",
                  "score": 2,
                  "created_utc": "2026-02-19 15:45:57",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o69a1hm",
              "author": "JackFry22",
              "text": "Pay attention: this tool only calculates the mathematical and geometrical similarities between two faces. It's pretty complicated algorithm to do so in InsightFace, it's not simple pixel match, it's biometrics. \n\nBUT as you mentioned, if someone has a hand on the face, it sees that there is a difference in geometry and it tells you that. \n\n  \nSO, ALTERT: Before Blindly pruning your dataset just based on these results, you have to check the results and use them as a Meter to evaluate the dataset. \n\nDo not use this as a omniscent oracle... xD\n\n  \nFor example, in my face's dataset I have 2 images of  me in profile and those two score lower in the dataset, because all the rest of the images are front view. So, the tool shows me there are two outliers, I go check, I see they are the profiles, and let them be. \n\nOn another case, it showed me a front view face as an outlier, and I later found out that the person who gave me the dataset included a picture of them being 4-5 years younger and that was poisoning the dataset, and I did not notice it by just viewing, because the similarity of a younger person is high, but in reality the geometry is different.\n\n  \nImagine you have a bunch of numbers 8 and 7, an then you have a 3, that will move the median away from the spot you'd want it... (just an example)",
              "score": 2,
              "created_utc": "2026-02-19 15:43:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6aosfg",
                  "author": "cradledust",
                  "text": "Thanks, these are all lessons I've more or less learned using Visomaster and Reactor to prune images before making an embedding. I have 90 images used in the LORA so the copycat report is most useful to discover that a handful of reference images where responsible for 33% of the output. It basically tells me I can prune this down to 30 images without a problem and which are the best images to keep with the obvious exceptions of side profile and other diversity shots.",
                  "score": 1,
                  "created_utc": "2026-02-19 19:44:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o64284l",
          "author": "FitEgg603",
          "text": "Good work üëçüèª",
          "score": 2,
          "created_utc": "2026-02-18 19:49:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o645ga4",
              "author": "JackFry22",
              "text": "thanks!",
              "score": 1,
              "created_utc": "2026-02-18 20:04:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o643s0x",
          "author": "Ok-Page5607",
          "text": "great work! Thanks for sharing!",
          "score": 2,
          "created_utc": "2026-02-18 19:56:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6453yc",
              "author": "JackFry22",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2026-02-18 20:02:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o65zkzk",
          "author": "SpaceNinjaDino",
          "text": "Have you found the file order of the training making meaningful impact? I feel like either the beginning of the dataset or the end of the dataset can do harm. It would be interesting to see if tracking the placement of an asset and changing the order will change the trained result.",
          "score": 2,
          "created_utc": "2026-02-19 01:40:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o697mow",
              "author": "JackFry22",
              "text": "I have not thought about that... I'm not a machine learning expert, so I don't really know how the training process works under the hood, but it's very fascinating subject for me, and I'll want to investigate more. I will make a study of this and do some tries of Training with backwards order placements of the dataset to see if it gives something different!",
              "score": 1,
              "created_utc": "2026-02-19 15:31:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o641wnb",
          "author": "Enshitification",
          "text": "This looks handy. I've been running my training prompts with LoRAs to try to eyeball overfit on the training images. This looks like it could be a time saver.",
          "score": 3,
          "created_utc": "2026-02-18 19:47:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o645ezs",
              "author": "JackFry22",
              "text": "It's not a total substitution of the \"eyeball\" technique, but it's a good gauge if you need an extra way of seeing the results! Let me know if you test it and your feedback, it'll be much appreciated! üëç",
              "score": 2,
              "created_utc": "2026-02-18 20:03:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o648ule",
          "author": "jigendaisuke81",
          "text": "Just for fun, do you have any real world example pairs of generated images & training data images? I see you just have a gemini i2i example. I've definitely observed this with real world terribly trained loras, but can't eyeball such a thing in real world.\n\nYou might still end up with false positives using the methodology you're using, if a model has a certain bias and thereby a generated image has a similar appearance to a training sample, yet that training sample might not be responsible for that output.",
          "score": 1,
          "created_utc": "2026-02-18 20:20:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o64eh8g",
              "author": "JackFry22",
              "text": "I'm working on it!   \nfor now I only have tested LoRAs I did for work and cannot show on public for privacy reasons, but as soon as I find the time I'll do a full test on a real world scenario I can show and will upload them on the assets folder in GitHub.   \nAt the same time I have someone testing this on CivitAI, and they did upload the graphs from MirrorMetrics on their very well tested LoRAs, and they told me the results were as expected plus a pair of interesting data that helped prune the dataset better. \n\nBut I finished writing the new Copycat feature yesterday night and haven't had the feedback yet. \n\nOf course, as I said in the previous post: this is all geometry and mathematics, so it must be taken with a grain of salt, and evaluated as such. But it does give a new perspective when you're a bit stuck between two epochs to choose from and it may give you a nudge in the right direction when you have a clusters of dots showing you mathematical vectors converging or scattering, so... Not saying this is gonna be the truthsayer in the matter, just a new angle.",
              "score": 1,
              "created_utc": "2026-02-18 20:47:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o65eg7c",
          "author": "jditty24",
          "text": "Im currently in the process of training a SDXL realistic character Lora and it‚Äôs been going like shit, tired 3 different tools and still horrible, Z-Image turbo is way easier.  I just want to make sure I understand correctly on what this tool does.  Do you upload your Lora into it and then it analyzes where it‚Äôs at and lets you know if it could be better? And if so, does it give you feedback on what to change?  Or maybe I just mistook everything and its something else lol",
          "score": 1,
          "created_utc": "2026-02-18 23:41:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o698j22",
              "author": "JackFry22",
              "text": "Actually no, it does not work with the LoRA safetensors files themselves. \n\nBasically you produce images WITH your produced LoRAs, you put them in the folders, and the tool analyzes the similarities between the images you produced and the dataset to see how much mathematically the LoRA compares to the dataset. please check this guide I made on CivitAI, it's pretty explanatory, and if you have questions about it feel free to ask: [https://civitai.com/articles/26241](https://civitai.com/articles/26241)",
              "score": 1,
              "created_utc": "2026-02-19 15:35:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o69lds1",
          "author": "Arianethecat",
          "text": "This forensic tool offers valuable insights. But it‚Äôs essential to remember that creativity often thrives in ambiguity. Embracing some uncertainty can lead to more original and engaging results. ",
          "score": 1,
          "created_utc": "2026-02-19 16:37:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6a7caj",
              "author": "JackFry22",
              "text": "I agree... and in a way, if you think about it, part of the goal here is exactly that. This is just a metrics tool, you have to use your mind and creativity to make out the numbers. This helps me for example avoid using LoRAs that are too overtrained and apparently they seem to be reaching the goal of reproducing the image of the character you want but in reality they're so strict that they limit the creativity of the generated output and thus the creation of beautiful images. \n\nthen again, after you've looked at the data, it's the person's creativity to explore new ways of training LoRAs that gives the opportunity to make it better. then the tool might help know when the different choices were better or worse then others. üëç\n\nmind you: I'm not selling anything, and I sincerely don't care if this tool gets used more or less, I just thought it would be ok to share with others what I did and maybe inspire even better work! and if someone tells me that it's all garbage for some reason I haven't thought of, I'd still have learned a lot from the experience! :D ",
              "score": 1,
              "created_utc": "2026-02-19 18:22:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o64oiar",
          "author": "Xamanthas",
          "text": "Man discovers phash functionality?",
          "score": -2,
          "created_utc": "2026-02-18 21:32:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o64rdhr",
              "author": "JackFry22",
              "text": "Mmmh, it's a tad more complicated than that, but I'm not sure if the reference was intentionally downgrading... Sometimes I'm unable to register sarcasm üòÖ\n\nJust to be sure, for the other's sake... pHash would fail here because generated images have different geometries/poses compared to the training data.\n\nThis isn't hashing; it's a **Cosine Similarity search on 512-dimensional feature vectors** extracted via InsightFace (ArcFace). It matches the **biometric identity**, not just the visual structure.\n\nBasically not comparing pixels but vectors on biometrics... Don't know if that makes sense?",
              "score": 1,
              "created_utc": "2026-02-18 21:46:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r7lr6k",
      "title": "Anima is not perfect but really fun",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1r7lr6k",
      "author": "shapic",
      "created_utc": "2026-02-17 22:59:43",
      "score": 147,
      "num_comments": 57,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1r7lr6k/anima_is_not_perfect_but_really_fun/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o600mrf",
          "author": "SomaCreuz",
          "text": "Where is 1girl? Is she safe? Is she alright?",
          "score": 50,
          "created_utc": "2026-02-18 04:52:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60cq43",
          "author": "Ok-Category-642",
          "text": "Been using the model for a little bit now, and for anyone wondering, so far my positives are that it learns much faster than Noob/Illustrious. In my experience doing style loras, it takes around half or a quarter of the steps (usually I do 1000 at batch 4 on Noob) without having to deal with annoyances like MinSNR or EDM2 for vpred, Multires Noise for eps, or just SDXL refusing to learn styles in general due to the useless VAE. It also doesn't seem to overfit nearly as hard on stuff such as backgrounds or text (unlike Noob, which made Lora mixing very inconsistent sometimes). Anima also does have better prompt comprehension and colors, and will likely have better details once the 1024 res model is trained. With that being said though the finetunes or merges of Anima right now on Civit are all pretty bad, I would not recommend bothering with them. There's NL too, which actually does work decently well.\n\nAs for the negatives, the main one is that the dataset contains Deviantart... I have no idea what the idea was behind that. There also seems to be issues with forgetting when training character or concept loras, and finally, the use of Qwen 0.6B which is just laughably small. 2B or even 4B would barely impact prompt processing while still fitting under 8GB Vram anyways, 0.6B would just be a mistake to go forward with imo. Anima is also very bad at upscaling right now without a proper CN tile model, and seems to have bad artifacting for upscaling vertical images.\n\nAt the very least, there are much better practices being taken for Anima's training compared to Noob, which is that tag dropout is actually being used, and the 2 extra datasets (ye-pop and Deviantart) were actually labeled. Overall I think Anima will be a hard replacement for Illustrious once it's done and at worst a sidegrade for Noob. (And if it wasn't obvious already, this model literally only does anime. It might do some realism due to the laion pop dataset, but it won't look good).\n\nEdit: Forgot to mention, if you're using Illu/Noob in 2026, then yes, Anima does do NSFW completely fine. However it is lacking somewhat in the details, though this will likely improve by the final model",
          "score": 13,
          "created_utc": "2026-02-18 06:25:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60kbgx",
              "author": "toothpastespiders",
              "text": ">the use of Qwen 0.6B which is just laughably small\n\nThat's easily the biggest thing I hope is changed moving forward. It's amazing that it works as well as it does. But it's hard to imagine that there wouldn't be significant improvements by bumping it up a bit.",
              "score": 3,
              "created_utc": "2026-02-18 07:31:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o643xdd",
                  "author": "tom-dixon",
                  "text": "> the use of Qwen 0.6B which is just laughably small\n\nFor a 2B model it's fine. It's the same size as SDXL, I think people expect too much because it outperforms SDXL in some ways. There were a bunch of experiments to change the CLIP to something smarter and it made a tiny amount of difference in quality while absolutely trashing the runtime speed.\n\nThink of it this way, if you teach your dog to speak and think in English, would the dog be as smart as a human? Small models are too small to take advantage of the large vocabulary.",
                  "score": 0,
                  "created_utc": "2026-02-18 19:57:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o613mm5",
              "author": "x11iyu",
              "text": "> tag dropout  \n> Noob 2026\n\nactually, its continuation in the form of [ChenkinNoob](https://huggingface.co/ChenkinNoob) (still training) will also be using tag dropout.\n\nadditionally, an [RF](https://huggingface.co/ChenkinRF) version is also being trained as well, kinda in parallel; no more eps gray nor vpred annoyances.",
              "score": 1,
              "created_utc": "2026-02-18 10:30:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o614huh",
                  "author": "Ok-Category-642",
                  "text": "I have seen Chenkin but I've only used the new RF version a little bit. It does look quite promising though as it's probably the first decently usable RF Noob model (and Noob model with proper training). I imagine once 1.0 finishes training it will probably be straight up better compared to VPred, and it's probably already better than EPS anyways (although VPred is arguably better than EPS already lol, it's not a high bar).\n\nI haven't tried training on Chenkin specifically but I have tried training Loras on the other RF experiments and it seems to learn better, which is pretty nice too since SDXL can be a pain for certain styles. There's also the Flux2VAE RF model, which could definitely rival Anima if that ever finishes.",
                  "score": 1,
                  "created_utc": "2026-02-18 10:37:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o60gwfa",
              "author": "shapic",
              "text": "I am using \"finetune\" of it simply because it is trained at bigger resolution and gives better results with upscale.",
              "score": 0,
              "created_utc": "2026-02-18 07:00:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o60hlhb",
                  "author": "Ok-Category-642",
                  "text": "IMO they all have too much of a style bias right now, which is whatever, but they also don't look very great in general. Like they are close to base Anima, but they just have the look of WAI on top, which... kind of sucks? It's whatever though honestly, I imagine once the full Anima model is trained it'll be much better for finetuning. I'd say at best Animayume is the most usable",
                  "score": 3,
                  "created_utc": "2026-02-18 07:07:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5yuvpy",
          "author": "BrokenSil",
          "text": "Dont get me wrong, but with such tiny prompts, you aren't really showing how amazing the model it.\n\nThese can be done in sdxl already, on any anime finetune.",
          "score": 17,
          "created_utc": "2026-02-18 00:51:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6092id",
              "author": "shapic",
              "text": "The problem is that I actually used those prompts in sdxl month ago. And no, you cannot really make something like that in sdxl. You will get better 1girls, but this stuff? Miles ahead",
              "score": 1,
              "created_utc": "2026-02-18 05:55:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5zlogb",
          "author": "-AwhWah-",
          "text": "am i going insane, this looks like the same stuff you've been able to make on any other checkpoint for years now",
          "score": 23,
          "created_utc": "2026-02-18 03:15:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60ia4w",
              "author": "GoranjeWasHere",
              "text": "1. It's base model. Like SDXL all others are distilled and reason why loras or finetunes are meh and why SDXL finetunes are used till this day. Don't judge it by how it looks now, judge it with community finetunes/loras in the future. As a base it absolutely mogs sdxl.\n\n2. Proper language understanding and ability to follow prompts rather than scattershot crap hoping you get what you want. This is SDXL fault. SDXL can't do that.\n\nSomeone doing proper finetune of anima will make it sing.",
              "score": 6,
              "created_utc": "2026-02-18 07:13:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5zq9jw",
              "author": "mk8933",
              "text": "The pros of this model is ‚Äì it can make images at low resolutions like 512x512 and keep its crazy quality.",
              "score": 3,
              "created_utc": "2026-02-18 03:43:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o60asoy",
              "author": "shapic",
              "text": "Only with models starting from flux. With all flux downsides. And not that creative. And they will require llm to write a prompt for you. And another one to \"polish\" prompt. And you will end with sdxl refining pass in the end anyways, constantly tweaking controlnet weights and all that. Then make it look generic with stuff like supir or whatever everyone is using right now.\nAnd no, all of those models were not as fun.",
              "score": 0,
              "created_utc": "2026-02-18 06:09:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o60r6uw",
                  "author": "AI_Characters",
                  "text": "This just isnt true whatsoever.",
                  "score": 4,
                  "created_utc": "2026-02-18 08:35:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o60diwu",
              "author": "Academic_Storm6976",
              "text": "Yeah this is much worse than 2023 Midjourney, and I canceled my sub later that year",
              "score": -3,
              "created_utc": "2026-02-18 06:32:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5yrqob",
          "author": "Choowkee",
          "text": "I tried it today and I kinda get why people are hyped about it. I can see it replacing SDXL anime checkpoints, assuming the base models becomes good enough or someone bothers with a fine-tune.\n\nCurrently in the process of training my first Lora for it to see if it can compete with Illustrious.",
          "score": 8,
          "created_utc": "2026-02-18 00:34:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5yuniv",
              "author": "Kromgar",
              "text": "I trained my first model and its fucking amazing how flexible the model is with loras.",
              "score": 3,
              "created_utc": "2026-02-18 00:50:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o60hvqp",
              "author": "toothpastespiders",
              "text": "Same here with seriously playing with it for the first time. I was surprised by the amount of semi-obscure characters it's been trained on. It's not mind blowing in that respect, but still impressive. And my first go at a style lora seems to have come out ok. Z-Image did a better job of some of the more complex concepts in the dataset but given Anima's size I wasn't really expecting full parity. But in general for the average prompt I think anima held up pretty well when I compare the results of the z-image and anima lora back to back.",
              "score": 1,
              "created_utc": "2026-02-18 07:09:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o606q4r",
          "author": "Dulbero",
          "text": "I'd say the biggest advantage with this model is the natural language prompting. I am still experimenting as well, but i'd really love to be able to make medium/long shots more consistently, which i think is easier in this model. From my experience anime models like Illustrious tend to output mostly portraits and close-ups. It will be a huge upgrade if the model understands depth/distance.",
          "score": 2,
          "created_utc": "2026-02-18 05:36:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yuos4",
          "author": "BrokenSil",
          "text": "I just wish ppl would wait for the fully trained model to release before they start spamming new loras and finetunes and merges. When it does release, we'll be filled with less compatible/less good loras that we never know what it was trained on.",
          "score": 4,
          "created_utc": "2026-02-18 00:50:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5zfswl",
              "author": "Choowkee",
              "text": "This is such as weirdly stupid complaint.\n\ntdrussell, the dev behind Anima is also the creator of diffusion-pipe, and he himself added training scripts for it.\n\nAllowing people to train early is important for model adoption. Its a proof of concept to see what the model is capable of. One of the reasons why PonyV7 failed is because nobody was willing to train it.",
              "score": 9,
              "created_utc": "2026-02-18 02:42:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o609evc",
                  "author": "Upper-Reflection7997",
                  "text": "Ponyv7 died because the results were very terrible especially in the state of open source ai generation at the time weights released. Not many people are willing to give a new heavy and janky models a chance if they don't see a potential improvement over current models. Just look at hi dream, glm image, omni dream and seemingly now qwen image 2512.",
                  "score": 6,
                  "created_utc": "2026-02-18 05:57:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o609dtq",
                  "author": "shapic",
                  "text": "Where did he add training scripts for that? It is not even in diffusers, comfy and others have a makeshift support",
                  "score": 1,
                  "created_utc": "2026-02-18 05:57:42",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6097qq",
              "author": "shapic",
              "text": "This is advertised as base for lora creation",
              "score": 1,
              "created_utc": "2026-02-18 05:56:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o60s6dw",
                  "author": "shapic",
                  "text": "Clarification if my own post. I was pointed to implementation of training in diffusion-pipe by same guy and it says:\nAssume that any lora trained on the preview version won't work well on the final version\nConsider it to be a \"throwaway lora\" that you likely will need to retrain.\nThe underlying model is still training and it will diverge from the preview weights.\nIf you are uploading the lora somewhere, specify that it is trained on preview, so that users aren't confused if it doesn't work well on the final version.",
                  "score": 2,
                  "created_utc": "2026-02-18 08:44:31",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ysfqc",
          "author": "Diligent-Rub-2113",
          "text": "From afar, the images look fantastic (last 2 being my favourites).\nLooking more closely though, there's way too much AI artifacts and distortion, reminds me of SD 1.5/XL. \nI wonder if this is because Anima was trained on lower resolution, or perhaps a VAE limitation.\nHoping that future models can address this.",
          "score": 1,
          "created_utc": "2026-02-18 00:38:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o621kgt",
          "author": "ds_nlp_practioner",
          "text": "looks like SD 1.5",
          "score": 1,
          "created_utc": "2026-02-18 14:16:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6cgt6i",
          "author": "Paraleluniverse200",
          "text": "Well obviously, it's just a preview",
          "score": 1,
          "created_utc": "2026-02-20 01:27:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yh28h",
          "author": "Time-Teaching1926",
          "text": "It's currently on the preview version so it will be inconsistent.  However, hopefully over time it will get better, especially with community LORAs and checkpoints community and maybe even the big dogs like WAI0731, Cyberdelia, Crody, Goofy_Ai... Will help fine-tune it later on as well, especially when we get the full version. \n\nIt looks very promising, especially as it's using Qwen3 6b as its text encoder so it's very good with prompt adherence. Illustrious/SDXL is still king tho for spicy stuff due to years of fine tuning and community development. \n\nIt's definitely the most promising model for anime even more so than z image, Qwen, Flux. \n\nHi, there is one other model that could be king out of all of them and that is the legendary Chroma as the Creator is currently working on Z image and Flux Klein version of it which will obviously take time.",
          "score": 0,
          "created_utc": "2026-02-17 23:35:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5zpddd",
              "author": "mk8933",
              "text": "Isnt it using qwen3 0.6B text encoder instead of 6B...",
              "score": 3,
              "created_utc": "2026-02-18 03:38:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5yic4p",
              "author": "shapic",
              "text": "Chroma never got on my pc permanently. \nAlso, despite being called a preview, it is clearly stated that this is base model and author will aesthetically finetune it (promising higher resolutions, which I personally doubt). \nAlso big guys will probably pass it due to nvidia license",
              "score": 1,
              "created_utc": "2026-02-17 23:42:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5yjpop",
                  "author": "Time-Teaching1926",
                  "text": "Yeah that Nvidia licence is not the best. I think it might deter people from fine-tuning it unfortunately. \n\nI would definitely check out chroma there is a great new checkpoint called UnCanny (Photorealism Chroma) which is great also if you want fast generation as chrome isn't the fastest check out Chroma-Flash-Heun ranks too. Flash lora rank-128 or 256): Steps: 15-17. CFG 1. Is recommended for it.",
                  "score": 3,
                  "created_utc": "2026-02-17 23:50:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5z08cj",
          "author": "x11iyu",
          "text": "I think I saw people running into catastrophic forgetting when trying to train a lora\n\n\nhopefully that's fixed in the full release",
          "score": 1,
          "created_utc": "2026-02-18 01:20:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zldew",
          "author": "vanonym_",
          "text": "brings me back to the old sd1.5 days but with much higher quality, I need to try it!",
          "score": 1,
          "created_utc": "2026-02-18 03:14:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61gqma",
              "author": "shapic",
              "text": "No idea why all the downvotes. It is not 1.5, but I feel like it is sdxl with coherent backgrounds and scenery",
              "score": 3,
              "created_utc": "2026-02-18 12:14:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o60ek01",
          "author": "Winter_unmuted",
          "text": "If only someone would put this much work into art that wasn't anime. \n\nNot to dump on anime lovers out there. You do you. It just isn't my thing. \n\nI really miss the art style reconnaissance that was SD1.5-SDXL. I hope we get that back one day.",
          "score": 0,
          "created_utc": "2026-02-18 06:40:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60fiz2",
              "author": "shapic",
              "text": "Pst. You there. Try anima with prompts pointing to stuff like deviantart, ye-pop datasets etc. It is vaguely described at the end of model description, but worth trying",
              "score": 6,
              "created_utc": "2026-02-18 06:49:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o61h9t2",
          "author": "Zestyclose-Move6357",
          "text": "Looks like ai slop",
          "score": 0,
          "created_utc": "2026-02-18 12:18:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rc56rr",
      "title": "I built and trained a \"drawing to image\" model from scratch that runs fully locally (inference on the client CPU)",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/zrfq6ud7m5lg1",
      "author": "_aminima",
      "created_utc": "2026-02-23 02:24:20",
      "score": 143,
      "num_comments": 11,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rc56rr/i_built_and_trained_a_drawing_to_image_model_from/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6xhx4r",
          "author": "TonyDRFT",
          "text": "Congrats on achieving this! And thank you for sharing, that looks mighty impressive!",
          "score": 8,
          "created_utc": "2026-02-23 10:30:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xzdpu",
              "author": "_aminima",
              "text": "Thanks a lot!",
              "score": 5,
              "created_utc": "2026-02-23 12:53:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wsdbn",
          "author": "Myg0t_0",
          "text": "Didnt nvidia have something like this?",
          "score": 13,
          "created_utc": "2026-02-23 06:26:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x3zvl",
              "author": "_aminima",
              "text": "Yes! Found their research while working on the project (https://arxiv.org/pdf/1903.07291). The core idea is the same but there are some implementation differences (they use a GAN architecture while I use a DiT, we incorporate the segmentation map conditioning differently, etc.)",
              "score": 10,
              "created_utc": "2026-02-23 08:13:53",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6wyva7",
              "author": "Obvious_Set5239",
              "text": "There were a lot of similar models. I remember even was controlnet for sd1.5 or sdxl doing the same",
              "score": 2,
              "created_utc": "2026-02-23 07:25:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6x55qv",
                  "author": "_aminima",
                  "text": "Indeed and they're probably better in terms of image quality. I guess the difference here is that the model is tiny compared to sd models (easily runs on CPU) and was trained from scratch on a consumer GPU",
                  "score": 9,
                  "created_utc": "2026-02-23 08:25:23",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o73eit6",
          "author": "Green-Ad-3964",
          "text": "Kudos to you for this great little project. Incredibile that it's developed by one man only on a consumer (not even top tier) hw.",
          "score": 2,
          "created_utc": "2026-02-24 06:36:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6z8sxc",
          "author": "Forsaken-Truth-697",
          "text": "Very nice project indeed.\n\nIt's a good idea to read AI papers, because thats how the tech evolves and new inventions are made.",
          "score": 1,
          "created_utc": "2026-02-23 16:51:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70pxt5",
          "author": "Certain-Cod-1404",
          "text": "really cool project man, good job!",
          "score": 1,
          "created_utc": "2026-02-23 20:58:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6y7wpj",
          "author": "LyriWinters",
          "text": "Very impressive.  \nNot sure how useful it is but very impressive. Great project to learn how to copy papers which is by far not the easiest thing to do.",
          "score": 0,
          "created_utc": "2026-02-23 13:46:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o719ecm",
              "author": "Historical-Doubt7584",
              "text": "This is super useful for prototyping UI from low fidelity to a possible product in real time. Figma would want to have a chat with OP",
              "score": 1,
              "created_utc": "2026-02-23 22:35:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rbb24f",
      "title": "A single diffusion pass is enough to fool SynthID",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1rbb24f/a_single_diffusion_pass_is_enough_to_fool_synthid/",
      "author": "abajurcu",
      "created_utc": "2026-02-22 03:24:34",
      "score": 140,
      "num_comments": 32,
      "upvote_ratio": 0.95,
      "text": "I've been digging into invisible watermarks, SynthID, StableSignature, TreeRing ‚Äî the stuff baked into pixels by Gemini, DALL-E, etc. Can't see them, can't Photoshop them out, they survive screenshots. Got curious how robust they actually are, so I threw together noai-watermark over a weekend. It runs a watermarked image through a diffusion model and the output looks the same but the watermark is gone. A single pass at low strength fools SynthID. There's also a CtrlRegen mode for higher quality. Strips all AI metadata too.\n\nMostly built this for research and education, wanted to understand how these systems work under the hood. Open source if anyone wants to poke around.\n\ngithub: [https://github.com/mertizci/noai-watermark](https://github.com/mertizci/noai-watermark)",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rbb24f/a_single_diffusion_pass_is_enough_to_fool_synthid/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "o6qvias",
          "author": "Mid-Pri6170",
          "text": "the guy who tricks old people on facebook a few weeks ago: 'darn it, people know im using AI!'\n\nthe same guy today: 'check out this statue of jesus made by frogs'",
          "score": 12,
          "created_utc": "2026-02-22 09:28:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pr7h3",
          "author": "akindofuser",
          "text": "I'm kind of OK with watermarks. Actually think its a smart idea. But as OP has shown easy to remove. Wish there was someway to enforce it. \n\nRight now the internet and world are all upset about AI pulling out the pitchforks with AI posts. That won't last. Diffusion models and AI is here to stay. Once it becomes more widely accepted we'll all wish there was a way to sign AI stuff so that it is known and obvious.",
          "score": 34,
          "created_utc": "2026-02-22 03:43:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6q9sll",
              "author": "Same-Pizza-6724",
              "text": "Another problem with watermarking is that it's probably trivial to add it to a real image.\n\nJust take a real image you want to discredit, add watermark \"look it's AI\".\n\nConspiracy nuts will have a field day adding watermarks to the new moon missions.",
              "score": 57,
              "created_utc": "2026-02-22 06:04:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6v23is",
                  "author": "xkulp8",
                  "text": "Society is going to have to accept that you're not going to be able to trust the authenticity of *any* digital image. We're very close to this point now, maybe we're already there.\n\nWhich means the only thing we're able to trust is film negatives. I don't think AI is close to reproducing those yet.",
                  "score": 3,
                  "created_utc": "2026-02-22 23:38:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6qj6ae",
                  "author": "akindofuser",
                  "text": "I wonder if that could be fixed with a seed and using key pairs similar to PKI. The model would have the seed and be able to sign the watermark. You'd need an authority like the model owner to verify it.\n\nSo if people tried to sign their own images they couldn't copy cat the watermark. ",
                  "score": 5,
                  "created_utc": "2026-02-22 07:30:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6qf32y",
              "author": "Chilidawg",
              "text": "Watermarks are effective so long as the end user is either honest or ignorant of the watermarks. Unfortunately, they are ineffective against well-informed bad actors.",
              "score": 8,
              "created_utc": "2026-02-22 06:52:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6px6o9",
              "author": "KangarooCuddler",
              "text": "Personally, I disagree and think that mandating watermarks is a poor idea. If watermarking AI images became mandatory, people might assume that they could trust an image just because it lacks an AI watermark. That would make them easier to fool in the long run.   \n  \nI think it's better that people learn to recognize the possibility that any image they see could be generated and use caution about what they choose to trust.",
              "score": 47,
              "created_utc": "2026-02-22 04:25:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6pylmv",
                  "author": "JazzlikeLeave5530",
                  "text": "That would be ideal but the problem is that's never going to happen because stupid people will always exist which is why protections are needed. If people just learned to recognize obvious scams then the whole scam industry wouldn't exist but it does because people are stupid.",
                  "score": 7,
                  "created_utc": "2026-02-22 04:35:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6pxsow",
                  "author": "akindofuser",
                  "text": "I don't think trusting an image based off watermark or not is a good argument. We're rapidly approaching a place where AI will be fully capable of truely realistic images. \n\nHaving some kind of tell would be nice. \n\n>I think it's better that people learn to recognize the possibility\n\nThis will end in failure. Tuning out tells and undesirable traits is easy and bigger models are better at hiding them anyways. ",
                  "score": 1,
                  "created_utc": "2026-02-22 04:29:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6ry3qu",
              "author": "Diabolicor",
              "text": "That's kind of how SynthID works. The model has some secret keys set up that mixes up with the seed for signing generated content like image, video, text. More info about it: [https://www.youtube.com/watch?v=\\_fMFb2Lv7rI](https://www.youtube.com/watch?v=_fMFb2Lv7rI)",
              "score": 2,
              "created_utc": "2026-02-22 14:29:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6sn154",
              "author": "2this4u",
              "text": "If you can watermark the information that it's AI, you can watermark other things like originating location, IP, etc.",
              "score": 2,
              "created_utc": "2026-02-22 16:28:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6qa7rs",
          "author": "AcePilot01",
          "text": "Curious, what's baked in?  aside from the meta data (which can be removed) what's visually in the pixel? and how can it not be taken out? that's interesting.",
          "score": 2,
          "created_utc": "2026-02-22 06:08:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6qsw9r",
              "author": "SpaceNinjaDino",
              "text": "Also be aware that printers add watermarks to all print outs. Even if you only print black ink, your colors (especially yellow) will eventually run out because it is sprinkling in a tracking id (MIC). Look up printer forensics for more info. Photoshop can add watermarks. I'm sure every cloud service adds their watermarks. \n\nBut yes, a diffusion pass with enough noise will destroy it. I wonder what minimal level of noise injection is required to defeat it.",
              "score": 6,
              "created_utc": "2026-02-22 09:02:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6qdhs1",
              "author": "eruanno321",
              "text": "A pseudorandom pattern that easily blends into the image but creates a detectable statistical signature when analyzed with the proper detector.",
              "score": 7,
              "created_utc": "2026-02-22 06:37:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6qg0zc",
                  "author": "AcePilot01",
                  "text": "But is it data, or just \"this was created by x\"",
                  "score": 2,
                  "created_utc": "2026-02-22 07:00:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6qibsa",
          "author": "jib_reddit",
          "text": "It is known.",
          "score": 3,
          "created_utc": "2026-02-22 07:22:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6tlo0h",
          "author": "InitialFly6460",
          "text": "That basically amounts to doing an upsampling / resampling pass with SDXL, right?",
          "score": 1,
          "created_utc": "2026-02-22 19:07:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6vi84x",
              "author": "Suoritin",
              "text": "Yes and no.\n\nCtrlRegen reconstructs the original image from pure noise using adapter that is somewhat similar to super strong ControlNet.",
              "score": 2,
              "created_utc": "2026-02-23 01:11:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6x056g",
                  "author": "InitialFly6460",
                  "text": " it seems SynthId is not very efficient [https://www.youtube.com/watch?v=63bcJ9w9uhA](https://www.youtube.com/watch?v=63bcJ9w9uhA)  Besides that, I tested a full subsampling followed by a full resampling with cfg 0.5, and the resampling does not reproduce the image 100% exactly; there are minute differences‚Ä¶",
                  "score": 2,
                  "created_utc": "2026-02-23 07:37:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6x64zy",
                  "author": "InitialFly6460",
                  "text": "I did some research, because my method required modifying the images, even if it only affected 0.05 percent, and there's a PyTorch implementation that just came out to remove watermarks: [https://github.com/andrekassis/ai-watermark?utm\\_source=tldrinfosec](https://github.com/andrekassis/ai-watermark?utm_source=tldrinfosec) And here's an article that proves that model destruction by diffusion is an excellent way to destroy the best watermarks currently available, and which advocates a semantic approach to combat SDXL: [https://browse-export.arxiv.org/pdf/2511.05598](https://browse-export.arxiv.org/pdf/2511.05598)",
                  "score": 2,
                  "created_utc": "2026-02-23 08:35:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6wxs1s",
                  "author": "InitialFly6460",
                  "text": "how is it superior than a upsampling / resampling pass with SDXL, ? if and if you add a full noise step  with SDXL ? to be more precise : imagine you unsampling a image from 50 to 10, then you resampling from 10 to 50 and you add one more set to 51 with SDXl... :  it should be efficient also isn't it ? I mean more than 75 per cent of the noise construction is from an another model.. 41 setp for only 10 original step... and based on a totaly different construction. ",
                  "score": 1,
                  "created_utc": "2026-02-23 07:14:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6t868o",
          "author": "jhnprst",
          "text": "they should turn it around: sign the images by the hardware taking them (i.e. camera etc.) any edit after will invalidate the signature.  so we assume all image are fake/edited, unless the signature verifies.  the trust moves up the chain to the hardware manufacturer, still not 100% but probably a lot better than all this",
          "score": 0,
          "created_utc": "2026-02-22 18:05:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rcc7r7",
      "title": "I know this ain't a lot, but I tried it.",
      "subreddit": "StableDiffusion",
      "url": "https://v.redd.it/cepz3w6ni7lg1",
      "author": "PRCbubu",
      "created_utc": "2026-02-23 08:43:00",
      "score": 135,
      "num_comments": 27,
      "upvote_ratio": 0.78,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Animation - Video",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rcc7r7/i_know_this_aint_a_lot_but_i_tried_it/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6xcahy",
          "author": "Formal-Exam-8767",
          "text": "What kind of black magic is she doing with her fingers? Casting a curse?",
          "score": 30,
          "created_utc": "2026-02-23 09:36:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xiz5r",
              "author": "Ordnael92",
              "text": "Massaging invisible nuts",
              "score": 36,
              "created_utc": "2026-02-23 10:40:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6yhmzd",
              "author": "razorree",
              "text": "you were meant to focus on something else...",
              "score": 11,
              "created_utc": "2026-02-23 14:40:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6xe2dn",
              "author": "PRCbubu",
              "text": "What I wanted to make was, she would grab the hand of the viewer and run with them (where she takes the lead)...\nI'm not that good at prompting.",
              "score": 5,
              "created_utc": "2026-02-23 09:53:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6xhns7",
                  "author": "Tbhmaximillian",
                  "text": "Add hand out of frame to your prompt or if you used image to video make a version where the hand is not visible, then this should work. Also which model workflow did you use?",
                  "score": 3,
                  "created_utc": "2026-02-23 10:27:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o715525",
              "author": "notislant",
              "text": "Only the right boob having physics is sending me lol",
              "score": 1,
              "created_utc": "2026-02-23 22:13:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6yid8b",
          "author": "luciferianism666",
          "text": "![gif](giphy|iKPQgXxAJtJSg)\n\n",
          "score": 13,
          "created_utc": "2026-02-23 14:44:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6x99i1",
          "author": "Mobile_Vegetable7632",
          "text": "wtf with her finger bro",
          "score": 11,
          "created_utc": "2026-02-23 09:05:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xj58b",
          "author": "fistular",
          "text": "https://preview.redd.it/i0jy938w38lg1.png?width=219&format=png&auto=webp&s=d55ef25ebf073da860778671769cae52501ec8ec\n\n",
          "score": 11,
          "created_utc": "2026-02-23 10:42:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6y9vby",
          "author": "berlinbaer",
          "text": "can you make her tits 20x bigger please ?",
          "score": 10,
          "created_utc": "2026-02-23 13:57:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xlwk6",
          "author": "umutgklp",
          "text": "With a proper workflow you can get better results, just focus on prompting. Do not leave prompting to any AI, the results will never be the same as you asked for, instead do edits on your main prompt. Overall your work is promising. and I'm sure you'll get better results soon. Keep up the good work!",
          "score": 7,
          "created_utc": "2026-02-23 11:07:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yu4lx",
          "author": "tomakorea",
          "text": "Can you give more info about your process to achieve that?",
          "score": 2,
          "created_utc": "2026-02-23 15:42:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o72ze2h",
          "author": "Darkmeme9",
          "text": "Guys imagining thier life with that random girl they see on a station never to see her again.",
          "score": 2,
          "created_utc": "2026-02-24 04:38:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xhrt8",
          "author": "flavioj",
          "text": "Workflow?",
          "score": 1,
          "created_utc": "2026-02-23 10:29:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xwgsh",
          "author": "lila_chasy",
          "text": "awww so sweety!",
          "score": 1,
          "created_utc": "2026-02-23 12:33:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yb4jm",
          "author": "devilish-lavanya",
          "text": "White hair? She is thousands year old fox?",
          "score": 1,
          "created_utc": "2026-02-23 14:04:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6z79zh",
          "author": "banedlol",
          "text": "Such manly hands you have",
          "score": 1,
          "created_utc": "2026-02-23 16:44:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6znwhw",
          "author": "turtleisinnocent",
          "text": "b‚àûbs",
          "score": 1,
          "created_utc": "2026-02-23 18:01:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70eedm",
          "author": "thanatica",
          "text": "She has 6 fingers for a few frames. Other than that, nice bounce.",
          "score": 1,
          "created_utc": "2026-02-23 20:03:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70pq9o",
          "author": "Tomarsnap",
          "text": "What did you use?",
          "score": 1,
          "created_utc": "2026-02-23 20:57:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o72m8j2",
          "author": "Zack_spiral",
          "text": "That image almost seems to be sd1.5 generated if you use an illustrios xl model and a screencap lora the quality will almost explode",
          "score": 1,
          "created_utc": "2026-02-24 03:12:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73pfl2",
          "author": "lolxdmainkaisemaanlu",
          "text": "now we got busty anime girls in a saree? I approve",
          "score": 1,
          "created_utc": "2026-02-24 08:14:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ygfpy",
          "author": "TechnoByte_",
          "text": "You need frame interpolation: https://github.com/Fannovel16/ComfyUI-Frame-Interpolation",
          "score": 1,
          "created_utc": "2026-02-23 14:33:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6yrlh2",
              "author": "TimeLine_DR_Dev",
              "text": "I assumed the frame rate was a choice",
              "score": 3,
              "created_utc": "2026-02-23 15:30:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6zqtca",
              "author": "nopalitzin",
              "text": "Amazing. A lot of models give you low fps on anything anime or 2d from grok to wan 2.2 to ltx2",
              "score": 1,
              "created_utc": "2026-02-23 18:15:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6yofza",
          "author": "jakiestfu",
          "text": "But why the fuck a big tit cat human OP ü§¢",
          "score": -2,
          "created_utc": "2026-02-23 15:15:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o70al7s",
              "author": "AICatgirls",
              "text": "She's a Hindu goddess",
              "score": 1,
              "created_utc": "2026-02-23 19:45:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r86y7a",
      "title": "Metadata Viewer",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/gallery/1r86y7a",
      "author": "Major_Specific_23",
      "created_utc": "2026-02-18 16:03:52",
      "score": 114,
      "num_comments": 27,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource - Update",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1r86y7a/metadata_viewer/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o632wgv",
          "author": "-Ellary-",
          "text": "Not working for recent ComfyUI gens, unknown format.  \nOld ones works fine.",
          "score": 7,
          "created_utc": "2026-02-18 17:11:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6339v3",
              "author": "Major_Specific_23",
              "text": "Do you have an image thats not working with metadata for me? I can fix and push an update",
              "score": 3,
              "created_utc": "2026-02-18 17:13:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o636gzo",
                  "author": "-Ellary-",
                  "text": "[https://pastebin.com/HdxYXhpf](https://pastebin.com/HdxYXhpf)\n\nhttps://preview.redd.it/lutknsk3fakg1.png?width=1040&format=png&auto=webp&s=e25fc23524537977094fcec7a24318b98cf3789d\n\n",
                  "score": 3,
                  "created_utc": "2026-02-18 17:27:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6363ds",
              "author": "Minimum-Let5766",
              "text": "It worked for me with yesterday's ComfyUI git pull. Tested flux-1.dev and flux-2 Klein 9b",
              "score": 1,
              "created_utc": "2026-02-18 17:25:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6372k5",
                  "author": "-Ellary-",
                  "text": "Maybe case in the model then, or custom nodes.",
                  "score": 1,
                  "created_utc": "2026-02-18 17:30:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o64dd2y",
          "author": "blastcat4",
          "text": "Nice! I was thinking of getting Gemini to help me build something like this but never got around to it. \n\nI have one suggestion: Add a simple left and right arrow buttons/link beneath the image file so you can load the next or previous image in the directory. \n\nAlso, it's not working quite right with Flux2 Klein. Here's the metadata:\n\nhttps://pastebin.com/8y9Bv8AJ\n\nWorks well with Anima and Z-image Turbo, but it's likely going to need a lot of exception handling for all the different metadata out there.",
          "score": 5,
          "created_utc": "2026-02-18 20:41:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65j8pe",
          "author": "Windy_Hunter",
          "text": "I downloaded the html file as said above, and it opens up just a regular page. \n\nhttps://preview.redd.it/t5v51zozeckg1.png?width=926&format=png&auto=webp&s=8d77a7aae29bf2d28c477ca2d5706132b3ba0d8b\n\n",
          "score": 2,
          "created_utc": "2026-02-19 00:07:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o66aeca",
              "author": "agentgerbil",
              "text": "same",
              "score": 1,
              "created_utc": "2026-02-19 02:43:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o67oveb",
                  "author": "precursor1188",
                  "text": "You need to download the zip file. Unzip then click to open the html file.",
                  "score": 4,
                  "created_utc": "2026-02-19 09:11:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o66kxcd",
          "author": "Critical_Cup_2606",
          "text": "This viewer is super simple, offline, and way easier to use than any other meta viewer I‚Äôve tried.  \nHuge thanks!",
          "score": 2,
          "created_utc": "2026-02-19 03:46:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66lp9x",
          "author": "SelectCoconut5594",
          "text": "I've vibecoded something like this but this is better. Its great to see things like the upscaler used etc. I'll use this",
          "score": 2,
          "created_utc": "2026-02-19 03:51:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6356a2",
          "author": "raysar",
          "text": "Greak work ! if you can, think about the best file format \"JPEGXL\" :)",
          "score": 1,
          "created_utc": "2026-02-18 17:21:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o636tmx",
          "author": "Minimum-Let5766",
          "text": "Thanks. Formatted vs Raw is nice.  Can you make it so that when you click on the image preview, it opens the image in a new browser tab?  Of course you can right-click and open image in a new tab, but a single click would be nice.\n\nThere's also a lot of space for more formatted items, so perhaps the seed, steps, cfg, sampler, scheduler and parsed fields, since this appears to be geared towards ComfyUI-generated images.  But some of those may be more challenging to parse, since different custom nodes may use slightly different names for the tokens.  Just some ideas.",
          "score": 1,
          "created_utc": "2026-02-18 17:29:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o638znm",
              "author": "Major_Specific_23",
              "text": "first suggestion good. done. click on the image and it opens in a new tab",
              "score": 4,
              "created_utc": "2026-02-18 17:39:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o63e39j",
          "author": "JustLookingForNothin",
          "text": "https://preview.redd.it/z4kugg0klakg1.png?width=2457&format=png&auto=webp&s=5e915fef1a8c94e9df641bde78116084dc218051\n\nThank you, excellent idea! However, it does not work for some images, in particular the prompt is often not recognized. Example from my flux.klein WF.   \nLeft: Image pulled into the viewer  \nRight: Same Image pulled into Comfy.  \n",
          "score": 1,
          "created_utc": "2026-02-18 18:01:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63ecof",
              "author": "Major_Specific_23",
              "text": "give me its metadata in pastebin link like the other commenter. i will fix.",
              "score": 1,
              "created_utc": "2026-02-18 18:02:29",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o63fx3z",
              "author": "JustLookingForNothin",
              "text": "Image: [https://i.postimg.cc/dt7RBnZy/Flux2KL9b-Base-2026-01-27-00002.png](https://i.postimg.cc/dt7RBnZy/Flux2KL9b-Base-2026-01-27-00002.png)\n\nClick on download original image.",
              "score": 1,
              "created_utc": "2026-02-18 18:09:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o647ana",
                  "author": "Major_Specific_23",
                  "text": "i think this is too complex haha. its messing up the other stuff :)",
                  "score": 2,
                  "created_utc": "2026-02-18 20:12:49",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o63h7z7",
                  "author": "JustLookingForNothin",
                  "text": "[https://postimg.cc/3dTDrXB8](https://postimg.cc/3dTDrXB8)",
                  "score": 1,
                  "created_utc": "2026-02-18 18:15:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6442fw",
                  "author": "Major_Specific_23",
                  "text": "thanks. let me check",
                  "score": 1,
                  "created_utc": "2026-02-18 19:57:41",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o64tuyw",
          "author": "Main_Creme9190",
          "text": "Very interesting !! \nHave you check Majoor Assets Manager ? But it is inside comfyUI üòâ",
          "score": 1,
          "created_utc": "2026-02-18 21:57:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65tcc3",
          "author": "Able-Ad2838",
          "text": "you don't need this just read the properties on a picture and you'll see all the same information!",
          "score": 1,
          "created_utc": "2026-02-19 01:03:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o667gxo",
              "author": "_Rah",
              "text": "The point is the formatting. If you go to properties, you cannot easily find the seed (copy it), lora, etc. This presentation makes it easy to see this info. ",
              "score": 2,
              "created_utc": "2026-02-19 02:26:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o68xh1b",
          "author": "Eastern_Lettuce7844",
          "text": "great tool  , especialy the design  of the UI",
          "score": 1,
          "created_utc": "2026-02-19 14:38:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6bmriy",
          "author": "terrariyum",
          "text": "Thanks for this!  Very helpful and pretty.  Before this, I had a tool that extracted the entire workflow json, but I had to manually cut out the prompt itself.\n\nI integrated your HTML file with my AI image gallery app (XnView) and file browser using applescripts (I guess Windows has a similar tool).  So now I can right-click any image from the gallery app or the file browser and easily grab its prompt.\n\nThe script opens your HTML file in the browser and copies the image to the clipboard.  It could even automate the paste action, but that would require choosing a degraded browser security level.  So I'd rather just paste.",
          "score": 1,
          "created_utc": "2026-02-19 22:32:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rdgeam",
      "title": "Wan 2.2 Video Reasoning Model (Apache 2.0)",
      "subreddit": "StableDiffusion",
      "url": "https://www.reddit.com/r/StableDiffusion/comments/1rdgeam/wan_22_video_reasoning_model_apache_20/",
      "author": "LowYak7176",
      "created_utc": "2026-02-24 13:35:26",
      "score": 103,
      "num_comments": 32,
      "upvote_ratio": 0.98,
      "text": "[https://huggingface.co/Video-Reason/VBVR-Wan2.2](https://huggingface.co/Video-Reason/VBVR-Wan2.2)  \n[https://video-reason.com/](https://video-reason.com/)  \nBenji AI Playground explaining it:   \n[https://www.youtube.com/watch?v=kFgU0tgYUl8](https://www.youtube.com/watch?v=kFgU0tgYUl8)",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/StableDiffusion/comments/1rdgeam/wan_22_video_reasoning_model_apache_20/",
      "domain": "self.StableDiffusion",
      "is_self": true,
      "comments": [
        {
          "id": "o74tudo",
          "author": "martinerous",
          "text": "Interesting stuff. I wish there was also an LTX2 reasoning LoRA. It needs reasoning improvement so badly. Wan2.2 is better by default already.\n\nHowever, their demo website examples are too abstract - only diagrams and drawings. No good tests to see how it affects real-life awareness (walking through doors, putting on clothes etc.)",
          "score": 15,
          "created_utc": "2026-02-24 13:38:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o760msx",
              "author": "Dzugavili",
              "text": "Yeah, LTX has fantastic motion and the quality is stellar; but you need to prompt the hell out of it and it will begin to blend actions together if you need a complex sequence. Reducing the prompt load with internal reasoning could be the key to solving a lot of LTX's misfires.\n\nThe WAN base model seems to have a greater understanding of scenario, where as LTX seems to have been trained on actions. But that also means it tends to tunnel to solutions more aggressively, which this lora hopes to fix.",
              "score": 1,
              "created_utc": "2026-02-24 17:04:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o762i60",
              "author": "Eisegetical",
              "text": "![gif](giphy|e87a8PIiFU03nleRsz)\n\n\"pulling on clothes\" ",
              "score": 1,
              "created_utc": "2026-02-24 17:12:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o74wmu1",
          "author": "Time-Teaching1926",
          "text": "Genuine question, could we get a LORA like this but for image models like Z image, Flux and Anima and Illustrious... And would it even work?\n\nLooks really interesting.",
          "score": 4,
          "created_utc": "2026-02-24 13:53:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75zklt",
              "author": "COMPLOGICGADH",
              "text": "It's a ongoing research field and experimental,few latest examples of new local image models are omnigen2 and deepgen1 (high experimental 5B model),lora is most likely not possible to achieve this it is it's own diffrent architecture...",
              "score": 1,
              "created_utc": "2026-02-24 16:59:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o758agm",
          "author": "kkb294",
          "text": "Can someone ELI5.?",
          "score": 6,
          "created_utc": "2026-02-24 14:54:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75faae",
              "author": "YeahlDid",
              "text": "Smart people make video moving better maybe.",
              "score": 10,
              "created_utc": "2026-02-24 15:27:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o75v0tj",
          "author": "Justify_87",
          "text": "[https://huggingface.co/Kijai/WanVideo\\_comfy/tree/main/LoRAs/VBVR](https://huggingface.co/Kijai/WanVideo_comfy/tree/main/LoRAs/VBVR)",
          "score": 3,
          "created_utc": "2026-02-24 16:39:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o754crl",
          "author": "pmp22",
          "text": "Very cool! Visual reasoning and world models were both big advancements, this feels like a logical direction to go. At some point, surely, all modalities will converge.",
          "score": 2,
          "created_utc": "2026-02-24 14:34:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74zov2",
          "author": "Dirty_Dragons",
          "text": "What I really want is for the first frame last frame model to determine when a change isn't important and just gloss over it.\n\nRight now if a bedroom scene has a lamp on a nightstand on the last frame and it's not there on the first, the model will go as far as generating a random person to walk into the room and place a lamp down and then leave. Or if the wall color is different, it will have somebody throw paint. I've seen the weirdest reasons to justify a minor change I just don't care about.",
          "score": 2,
          "created_utc": "2026-02-24 14:10:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7541a7",
              "author": "altoiddealer",
              "text": "Could probably avoid these things by just prompting a bit better like, the camera pans right revealing lamp on dresser etc",
              "score": 2,
              "created_utc": "2026-02-24 14:32:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o754nf8",
                  "author": "Dirty_Dragons",
                  "text": "The thing is I don't care about the lamp. I wasn't even aware of it's existence until Wan made it dramatically appear.",
                  "score": 4,
                  "created_utc": "2026-02-24 14:36:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o752rvw",
          "author": "tcdoey",
          "text": "That 'person' in the corner, and the not good AI voice.\n\nI don't get it, why do that? It just makes the whole video, which was interesting, instead really hard to watch. It kind of made me nauseous.",
          "score": 3,
          "created_utc": "2026-02-24 14:26:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o757jy9",
              "author": "ThatsALovelyShirt",
              "text": "Pretty sure they guy is 'real', but they don't speak english, so they used one of those (bad) AI translating/dubbing services or models to convert their speech into english.",
              "score": 3,
              "created_utc": "2026-02-24 14:50:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o75ar1g",
                  "author": "Famous-Sport7862",
                  "text": "Benji  is Chinese, he doesn't speak English, that's why the ai voice. But his videos are really good. And that person is not him, that's just an avatar, he uses different avatar in other videos",
                  "score": 7,
                  "created_utc": "2026-02-24 15:06:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o75cbbi",
                  "author": "addandsubtract",
                  "text": "Yeah, the chat on the screen looks too real to be AI. So this is most likely it.",
                  "score": 2,
                  "created_utc": "2026-02-24 15:13:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o75vgr2",
                  "author": "Timboman2000",
                  "text": "I'd kind of just prefer text on the screen over the AI dubbed voice and fake avatar in the corner, it basically made me close the video after listening to it for 10 seconds.",
                  "score": 1,
                  "created_utc": "2026-02-24 16:41:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o75zoqg",
                  "author": "Grand0rk",
                  "text": "Which is ironic. Using shit AI voice on video about AI Video.",
                  "score": 1,
                  "created_utc": "2026-02-24 16:59:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o75zkst",
          "author": "FFKUSES",
          "text": "Would it come on higgs field?",
          "score": 1,
          "created_utc": "2026-02-24 16:59:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7609w8",
          "author": "Valtared",
          "text": "So does it have practical use for us in comfyUI workflows ? If I add the high Lora to my wf it will get better results ? Only in FL2LF ?",
          "score": 1,
          "created_utc": "2026-02-24 17:02:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o760lg6",
          "author": "Odd-Mirror-2412",
          "text": "It's interesting!",
          "score": 1,
          "created_utc": "2026-02-24 17:03:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o761734",
          "author": "z3rO_1",
          "text": "Is there a not huggingface link to this? I want to try it, but huggingface is the Cruelty Squad of AI, and it isn't on CivitAI, yet.",
          "score": 1,
          "created_utc": "2026-02-24 17:06:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74ym80",
          "author": "Dzugavili",
          "text": "The AI guy in the bottom right is a hat-on-a-hat.",
          "score": 1,
          "created_utc": "2026-02-24 14:04:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75jz1f",
          "author": "GifCo_2",
          "text": "a Lora can not add reasoning to a non reasoning model. This seems stupid",
          "score": 1,
          "created_utc": "2026-02-24 15:49:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7554l0",
          "author": "Violent_Walrus",
          "text": "TIL to never try to watch another video from Benji‚Äôs AI Playground.",
          "score": -1,
          "created_utc": "2026-02-24 14:38:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7507w0",
          "author": "repezdem",
          "text": "Ugh we cant even get a video of a human being explaining this? I can't handle the fake dude in the corner with the horrible AI voice.",
          "score": -4,
          "created_utc": "2026-02-24 14:13:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75ib7s",
              "author": "Choowkee",
              "text": "There are two websites linked explaining the concept. Reading is really not that hard.",
              "score": 3,
              "created_utc": "2026-02-24 15:41:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o754gnr",
              "author": "klop2031",
              "text": "Yeah that voice made me turn it off. Also they should write more on their organization card",
              "score": -2,
              "created_utc": "2026-02-24 14:35:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7625bf",
              "author": "Naive-Kick-9765",
              "text": "Ask your mama.",
              "score": 1,
              "created_utc": "2026-02-24 17:10:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o75735o",
          "author": "tcdoey",
          "text": "Test comment, something's not working on my reddit.\n\nAlso couldn't stand watching that video, it was interesting stuff, but that AI person made me feel nauseous.",
          "score": -1,
          "created_utc": "2026-02-24 14:48:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}