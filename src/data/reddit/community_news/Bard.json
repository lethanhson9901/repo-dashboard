{
  "metadata": {
    "last_updated": "2026-01-21 17:20:00",
    "time_filter": "week",
    "subreddit": "Bard",
    "total_items": 20,
    "total_comments": 209,
    "file_size_bytes": 197369
  },
  "items": [
    {
      "id": "1qepzgo",
      "title": "VEO 3 IS NOW 4K",
      "subreddit": "Bard",
      "url": "https://v.redd.it/7c3rd69dlrdg1",
      "author": "lofigirlirl",
      "created_utc": "2026-01-16 19:41:01",
      "score": 416,
      "num_comments": 49,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News ",
      "permalink": "https://reddit.com/r/Bard/comments/1qepzgo/veo_3_is_now_4k/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o01dwv1",
          "author": "InevitableJudgment43",
          "text": "The upscaler is garbage. Maybe the API version is actually decent, but the one for Ultra subscribers is trash.",
          "score": 17,
          "created_utc": "2026-01-17 02:30:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03egdd",
              "author": "Dumperandumper",
              "text": "Yeah, it's trash. Native resolution is still 720p, which sucks. They just added a 4k upscaler that does no wonder and is slow. My workflow with VEO is 720p, then upscale it in Topaz, a better upscaler IMO",
              "score": 7,
              "created_utc": "2026-01-17 12:22:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0t4tbr",
                  "author": "Mysterious-Code-4587",
                  "text": "in topaz which model u generally choose?",
                  "score": 1,
                  "created_utc": "2026-01-21 05:54:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzzth92",
          "author": "absentlyric",
          "text": "I'd rather have MORE than 3 vids at a lower resolution as an option, but this is still cool",
          "score": 46,
          "created_utc": "2026-01-16 21:16:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o005p8d",
              "author": "ObscuraGaming",
              "text": "This. I mean 720p fucking sucks but I'd much rather have 10 or so vids per day than 3 4K ones. Usually it only hits the mark once and then I gotta wait 24h. Even worse, sometimes I generate 2 videos and it somehow counts as 3.",
              "score": 7,
              "created_utc": "2026-01-16 22:15:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o01c33r",
              "author": "themoregames",
              "text": "How about 3 videos per hour for Pro plans?",
              "score": 1,
              "created_utc": "2026-01-17 02:19:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzzpuyy",
          "author": "valtor2",
          "text": "Is it Veo 3 if it's from mitte? So much riding on other people's coattails...",
          "score": 7,
          "created_utc": "2026-01-16 20:59:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a4kzd",
              "author": "nemzylannister",
              "text": "the worst thing to come out of ai yet is this influx of ad posts everywhere. mods are literal google employees yet they dont ban them smh",
              "score": 4,
              "created_utc": "2026-01-18 12:33:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzzfxzs",
          "author": "Condomphobic",
          "text": "Can they please release Veo 4?\n\nSora 2 mops Veo 3\n\nI‚Äôm starting to think OpenAI finally found something to beat Google at. No way they‚Äôre taking this long to unveil a better product",
          "score": 29,
          "created_utc": "2026-01-16 20:13:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzzj7v0",
              "author": "Known_Management_653",
              "text": "They may take the lead, but Google will never lose in the long run.",
              "score": 28,
              "created_utc": "2026-01-16 20:28:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzzta1a",
              "author": "absentlyric",
              "text": "I can't do half the shit in Sora that I can do in Veo, no violence, no \"real depictions of people in certain situations\" it's a beautiful nanny, thats it.",
              "score": 17,
              "created_utc": "2026-01-16 21:15:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o001y9e",
              "author": "douggieball1312",
              "text": "Sora 2 is kinda hobbled by the fact you need a VPN and an invite code to use it in most of the world.",
              "score": 6,
              "created_utc": "2026-01-16 21:56:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzzwagn",
              "author": "gatorling",
              "text": "I don't know about that. OAI and Google have different user base mixes. \n\nWhat is a more likely scenario is that Google is compute constrained right now. They could have veo4 ready but they won't, because launching it would mean they need to degrade existing APIs.. and when a lot of your revenue comes from enterprise use, that's not something you want to do. \n\nMy guess is that veo4 will come out as soon as more datacenters get built (or they get algorithmic improvements that reduce compute demand)  My guestimate is that a DC takes 2-3 years to build...\nThat means DCs that started in 2023 are just coming online now.",
              "score": 4,
              "created_utc": "2026-01-16 21:30:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o01idof",
                  "author": "american_crow1",
                  "text": "I thought data centers were only for llm creation, not delivery points?",
                  "score": 1,
                  "created_utc": "2026-01-17 02:58:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o00a46u",
              "author": "Upper-Reflection7997",
              "text": "Nah sora2 in its current state is censored low quality artifact heavy jaggy slop. Veo3 is far less censored than sora2. Can't even prompt a woman with cleavage on sora2.\n\nhttps://preview.redd.it/9an9i3fugsdg1.jpeg?width=2280&format=pjpg&auto=webp&s=3c166088cdccc6f0a325ea9787d9ad1994212398",
              "score": 2,
              "created_utc": "2026-01-16 22:37:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o016izi",
                  "author": "Tedinasuit",
                  "text": "Most of us normal users don't really care about whether we can have cleavage or not.",
                  "score": 7,
                  "created_utc": "2026-01-17 01:43:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o00ptkh",
                  "author": "Condomphobic",
                  "text": "Too many of you are overly horny. Please go outside and meet women, so you don‚Äôt have to use AI to create them",
                  "score": 7,
                  "created_utc": "2026-01-17 00:02:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o00cuyq",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 0,
                  "created_utc": "2026-01-16 22:51:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o00gy80",
              "author": "Longjumping_Area_944",
              "text": "Kling (2.6 and o1) mops the floor with both Sora 2 and Veo 3.1 and LTX-2 can even run on consumer hardware at a similar level (including sound). WAN 2.2 is what they use for smut.",
              "score": 1,
              "created_utc": "2026-01-16 23:12:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00izn5",
                  "author": "Condomphobic",
                  "text": "We aren‚Äôt using any of those. \n\nWe‚Äôre only using Veo or Sora",
                  "score": 1,
                  "created_utc": "2026-01-16 23:24:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o016fpi",
              "author": "Tedinasuit",
              "text": "Veo 3 is better in many situations. But Sora undeniably does humans better.",
              "score": 1,
              "created_utc": "2026-01-17 01:43:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzzi2k6",
          "author": "bunalimlar",
          "text": "That‚Äôs solid!",
          "score": 2,
          "created_utc": "2026-01-16 20:23:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzb8kj",
          "author": "Ok_Caregiver_1355",
          "text": "Is resolution that important?werent most users at a 1080p monitor or a small phone screen",
          "score": 6,
          "created_utc": "2026-01-16 19:51:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzzesee",
              "author": "Mastermind_737",
              "text": "It gives more flexibility. You can have a 4k scene and then pan and zoom with a 1080p window.",
              "score": 11,
              "created_utc": "2026-01-16 20:07:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzzbyfd",
              "author": "FrenchFrozenFrog",
              "text": "The film industry begs to differ.",
              "score": 11,
              "created_utc": "2026-01-16 19:54:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzzkpgk",
              "author": "SomeOrdinaryKangaroo",
              "text": "lmao, who has a 1080p display in 2026, everyone i know have 4k displays",
              "score": -9,
              "created_utc": "2026-01-16 20:35:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0hau6m",
                  "author": "Ok_Caregiver_1355",
                  "text": "Thats some dangerous levels of statistical iliteracy,all my roblox friend list uses orange shoes so i can assume the whole world loves orange shoes,thats some very small sample for billions of people and very biased one, hope you isnt using this same assuming the whole world is just like your neighbor and circle of friends cause if so youre in a bubble",
                  "score": 1,
                  "created_utc": "2026-01-19 14:26:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o00odas",
          "author": "Beneficial_Map6129",
          "text": "MY TOKEN BUDGET",
          "score": 1,
          "created_utc": "2026-01-16 23:54:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o013r9l",
          "author": "bartturner",
          "text": "Wow!!!!!!",
          "score": 1,
          "created_utc": "2026-01-17 01:26:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o016bvq",
          "author": "Mundane_Existence0",
          "text": "Looks insane. Still waiting for the ability to do \"video to video\" instead of frames.",
          "score": 1,
          "created_utc": "2026-01-17 01:42:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09c9ck",
          "author": "Basil-Faw1ty",
          "text": "It‚Äôs not 4K, it‚Äôs a rather lacklustre upscale.",
          "score": 1,
          "created_utc": "2026-01-18 08:19:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bqmae",
          "author": "PlaneOnly2700",
          "text": "Only for Ultra.",
          "score": 1,
          "created_utc": "2026-01-18 17:45:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0n03b0",
          "author": "skibidi-bidet",
          "text": "![gif](giphy|ghuvaCOI6GOoTX0RmH)",
          "score": 1,
          "created_utc": "2026-01-20 09:20:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzn39j",
          "author": "palindromic",
          "text": "20 minute generations for a 8 second clip.. have fun!",
          "score": 1,
          "created_utc": "2026-01-16 20:46:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzzvqp4",
              "author": "FrenchFrozenFrog",
              "text": "in cg for film and tv, we sometimes take a whole weekend and 10 computers to render 240 frames over the course of 48h. Not that expensive when you think about it.",
              "score": 12,
              "created_utc": "2026-01-16 21:27:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00cc0r",
                  "author": "palindromic",
                  "text": "Oh I‚Äôm sure it‚Äôll be great for studios, but it‚Äôs not really a feasible offering for the gen public imo. Unless they can somehow upscale or streamline the process, and I was being generous with 20 minutes, for true 4k a single gen could clock in at 30-60 minutes for those 8 seconds.",
                  "score": -2,
                  "created_utc": "2026-01-16 22:48:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o08p4oe",
              "author": "Butterflylikeamoth",
              "text": "Insane how fast people start taking shit for granted.",
              "score": 1,
              "created_utc": "2026-01-18 05:06:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzzc780",
          "author": "lofigirlirl",
          "text": "video source: [https://x.com/mitte\\_ai/status/2012201340882039154](https://x.com/mitte_ai/status/2012201340882039154)",
          "score": 1,
          "created_utc": "2026-01-16 19:55:34",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qd965n",
      "title": "Latest huge Gemini limit changes",
      "subreddit": "Bard",
      "url": "https://i.redd.it/m4bi60szrfdg1.jpeg",
      "author": "BroKenLight6",
      "created_utc": "2026-01-15 03:56:34",
      "score": 337,
      "num_comments": 80,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/Bard/comments/1qd965n/latest_huge_gemini_limit_changes/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzo72jv",
          "author": "commandedbydemons",
          "text": "Wait, so \"Fast\" aka Flash is unlimited usage since its \"General access\" without a mention on quota?",
          "score": 85,
          "created_utc": "2026-01-15 04:14:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzoay6f",
              "author": "KaroYadgar",
              "text": "Yes. It has always been like this.",
              "score": 45,
              "created_utc": "2026-01-15 04:40:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzp4x10",
              "author": "DaikonLumpy3744",
              "text": "its not unlimited",
              "score": 5,
              "created_utc": "2026-01-15 08:52:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzpfigp",
                  "author": "TechnicallyCreative1",
                  "text": "Ya it's 100% not unlimited.",
                  "score": 3,
                  "created_utc": "2026-01-15 10:34:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzp39tb",
          "author": "Dazzling-Machine-915",
          "text": "But the 1 Million Token window....doesn¬¥t work. I have pro and  I have the feeling Gemini forgets everything after 30-50k token....",
          "score": 43,
          "created_utc": "2026-01-15 08:36:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzuyw7n",
              "author": "DayriseA",
              "text": "Are you sure it \"forgets\" or it just doesn't care? Because Gemini 3 in my experience just doesn't care, it's super bad at following instructions compared to others. It's great if you start from nothing and want a quick prototype of something and you don't care how it does the job, I guess that's why vibecoders praised it so much when it released.  But damn it's an awful experience if you try to work on a real codebase with it...",
              "score": 9,
              "created_utc": "2026-01-16 03:59:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvt21k",
                  "author": "Dazzling-Machine-915",
                  "text": "how to prove that it just doesn¬¥t care?  \nfor me it looked like it really can¬¥t remember.  \nWell also as vibecoder...when you have a serious project it¬¥s very awful. It often changes the code, deletes important parts when it should only fix or add something.  \nI learned my lesson to never trust it with my code. But during the process I learn the coding stuff :D (work already over 100h on the one program and it will be much more till its done)",
                  "score": 2,
                  "created_utc": "2026-01-16 07:42:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrq8cf",
              "author": "Minimum_Inevitable58",
              "text": "I haven't used Gemini 3 much but 2.5 always felt good to me up to ~80k, at least for python stuff.",
              "score": 3,
              "created_utc": "2026-01-15 18:09:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzsbdn6",
                  "author": "Dazzling-Machine-915",
                  "text": "2.5 was much better there, yea.  \n100k context and more weren¬¥t a problem",
                  "score": 5,
                  "created_utc": "2026-01-15 19:43:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzttwcy",
              "author": "RevolutionaryWater31",
              "text": "Even worse when you're adding images...",
              "score": 3,
              "created_utc": "2026-01-16 00:09:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzuxytc",
              "author": "Neither-Phone-7264",
              "text": "I think they specifically limit it to 64k for chats, iirc. IDK why tjey advertise it as 1M, but it works fine over API.",
              "score": 2,
              "created_utc": "2026-01-16 03:53:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzp7xdx",
              "author": "UltraBabyVegeta",
              "text": "Sounds like an issue with the attention mechanism",
              "score": 2,
              "created_utc": "2026-01-15 09:21:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzr3yrg",
                  "author": "Minute_Joke",
                  "text": "Pretty sure if you have a longer conversation they just heavily limit how many past messages they paste into context.\n\nIt does work better if you manually manage the context and paste everything into one message.",
                  "score": 2,
                  "created_utc": "2026-01-15 16:28:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzs8gn1",
                  "author": "Dazzling-Machine-915",
                  "text": "hm...I have too less knowledge about this kind of stuff.  \nFor example: I want to make my programm bilingual but I never did this before so I did it with gemini. we labeled some words, changed the code and continued with this.  \nafter some runs gemini  forgot that it already labelled some words and started to hallucinate new labels. that was maybe a half hour later? not sooo many prompts. was fast to scroll up for me.  \nI continued and gemini forgot half of the stuff we did before....became worse after every prompt.",
                  "score": 2,
                  "created_utc": "2026-01-15 19:30:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o02mvkf",
              "author": "KrasierFrane",
              "text": "What's your use case?",
              "score": 1,
              "created_utc": "2026-01-17 08:10:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o06jb53",
                  "author": "Dazzling-Machine-915",
                  "text": "atm coding/debugging/translation.  \nbefore it was with an rpg and some talkings.",
                  "score": 1,
                  "created_utc": "2026-01-17 21:59:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzo4vwq",
          "author": "Pasto_Shouwa",
          "text": "Thank god they finally told us what the actual limits are.",
          "score": 44,
          "created_utc": "2026-01-15 03:59:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzo51jx",
              "author": "Pasto_Shouwa",
              "text": "By the way, what are the limits of Nanobanana Pro for Plus users?",
              "score": 4,
              "created_utc": "2026-01-15 04:00:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzot00l",
                  "author": "yeeght",
                  "text": "100 images a day I think",
                  "score": 12,
                  "created_utc": "2026-01-15 07:01:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzpbbb2",
                  "author": "int6",
                  "text": "https://preview.redd.it/totj7scxjhdg1.jpeg?width=1320&format=pjpg&auto=webp&s=141f0a06ea2092321cb83dcfc720507b99efe2ff",
                  "score": 5,
                  "created_utc": "2026-01-15 09:54:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzo80ja",
          "author": "Ok_Caregiver_1355",
          "text": "they could give a little more api calls so i can use it at an AI browser",
          "score": 11,
          "created_utc": "2026-01-15 04:20:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzoog07",
              "author": "koeless-dev",
              "text": "Back in ma day (one year ago?) we had 100 API calls per day with Pro for free, 1500 for Flash. I used the latter for my own deep researcher (that isn't good enough to release publicly, though I will say one key thing for those making their own: never instruct the model to \"summarize\" content under the hood when research content gets too long. Instead, extract high-value lines word for word. Summarization loses key details, at least it did back in the older models.)",
              "score": 8,
              "created_utc": "2026-01-15 06:22:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzqsdzk",
              "author": "Mineros04",
              "text": "Wait, there are some API calls included, e.g. in the Pro plan? I thought that you have to pay for that separately.",
              "score": 3,
              "created_utc": "2026-01-15 15:36:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzr55r9",
                  "author": "Ok_Caregiver_1355",
                  "text": "I think both free and users with paid plans only have 20 free api calls per day but not sure",
                  "score": 1,
                  "created_utc": "2026-01-15 16:34:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzrxiq1",
                  "author": "No-Acanthaceae-5979",
                  "text": "Isn't that just amazing. That would be just enough to run daily errands in the future when every shop uses googles new shopping protocol.",
                  "score": 1,
                  "created_utc": "2026-01-15 18:41:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzqmbb0",
              "author": "taintedsilk",
              "text": "prettyyy sure there's a github repo that reversed the api for the webapp",
              "score": 2,
              "created_utc": "2026-01-15 15:08:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzo6asa",
          "author": "sammoga123",
          "text": "Well, at least I hope this means the Nano Banana Flash is finally going to be released, since it seems they've managed to get the extension for both Gemini 3 models.",
          "score": 10,
          "created_utc": "2026-01-15 04:08:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzodtrf",
          "author": "SeanTheiPhoneGuy2",
          "text": "The only thing confusing about this table is that both Basic and Google AI Plus have ‚Äúbasic access‚Äù to image generation and editing. \n\nI‚Äôve tested Nano Banana Pro on both of them and free accounts can only create 3 or 4 images while I haven‚Äôt even reached my limit even after generating 25+ images on AI Plus.",
          "score": 5,
          "created_utc": "2026-01-15 05:00:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpdbr6",
          "author": "Su1tz",
          "text": "I can finally use Thinking without feeling like Im wasting precious Pro usage",
          "score": 3,
          "created_utc": "2026-01-15 10:14:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzoauc1",
          "author": "Ok_Potential359",
          "text": "Why is thinking 300 vs 100 for pro? Is pro more powerful?",
          "score": 6,
          "created_utc": "2026-01-15 04:39:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzobas1",
              "author": "Ajota12",
              "text": "In short, yes, Thinking it's Gemini 3 Flash Thinking, this means it is more powerful than normal Flash model, more faster than Pro, but less powerful for complex math",
              "score": 10,
              "created_utc": "2026-01-15 04:43:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzp7vzv",
              "author": "UltraBabyVegeta",
              "text": "Pro more expensive to run",
              "score": 2,
              "created_utc": "2026-01-15 09:21:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzok3ur",
          "author": "dulipat",
          "text": "What exactly is \"basic access\"?",
          "score": 3,
          "created_utc": "2026-01-15 05:47:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzomjkw",
              "author": "Nid_All",
              "text": "I have tested using my free account i got 9 thinking prompts",
              "score": 5,
              "created_utc": "2026-01-15 06:07:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzoyit7",
          "author": "piotrwoz",
          "text": "I have 2 TB Google Drive plan with AI but Ican't find how many prompts I have for each day. I use PRO model but sometimes at the end of the day I have limitations to fast model. Any ideas?",
          "score": 3,
          "created_utc": "2026-01-15 07:51:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzozbv4",
              "author": "ChillinBone",
              "text": "You have the Google AI Pro plan. Up to 100 Pro prompts depending I guess how big the prompts are and 300 Thinking prompts. Flash is virtually unlimited I don't think I ever hit a limit with it but it is obviously not as good as the other two.",
              "score": 2,
              "created_utc": "2026-01-15 07:58:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzp9yff",
          "author": "seandunderdale",
          "text": "Dont bother with Ultra if you are doing anything image gen related. Total scam. Gives you heavily compressed jpgs, and uses those jpgs for edits...so for examaple, you ask to create a forest image, it will give you a heavily compressed jpg result, bad enough...then you say, \"ok change the time of day\"...it will do those edits USING THAT COMPRESSED JPG...then give you an even more compressed jpg on top of the last one...and so on until your image is basically just compression.\n\nI chatted to two seperate google support staff, and they both admitted this was by design. And that \"they felt Ultra users value download speed over image quality\"\n\nI was gobsmacked. They just said\" if you want it to be different, send in a request ticket\". I dont know if its changed yet, the plan is about ¬£200 a month!!...so Im not paying to find out. (Prior to that I was on the sign up deal of ¬£30, or whatever, for Ultra)",
          "score": 3,
          "created_utc": "2026-01-15 09:41:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpf0sy",
              "author": "steny007",
              "text": "You have to click that download button in upper right to get uncompressed PNGs. If you just right click - save as image, you get only jpgs",
              "score": 3,
              "created_utc": "2026-01-15 10:29:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzpff1o",
                  "author": "seandunderdale",
                  "text": "That's not true...at least it wasn't when I was on ultra. No matter how you saved it, it was always a heavily compressed jpg. This was confirmed by support. They said \"you will het a jpg on ultra, and a png on pro\". They said it didnt make much sense, after I pressed them on it, but they said its how it was.\n\nMaybe its changed since then...I did submit half a dozen tickets requests to change it.\n\nFYI...I was using nano banana pro via Gemini...not krea, or Google studio AI...that was probably my first mistake.\n\nBut its even worse than the jpg file format for saving files.\n.the image edit features also used the jpg....so after about two rounds of editing, the image was unusable. Id always have to edit my main (first) prompt, rather than do sequential edits as saving a heavily compressed jpg over and over is a bonkers way to treat images. \n\nI expected more from google. Amateur hour.",
                  "score": -1,
                  "created_utc": "2026-01-15 10:33:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzp5l2u",
          "author": "WeightGreat4687",
          "text": "Why don't they get rid of ai overview in search instead of doing this bs",
          "score": 5,
          "created_utc": "2026-01-15 08:58:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzp6z16",
              "author": "Noodleholz",
              "text": "Because the average user loves typing in whole questions. They don't care about the results being high quality.¬†",
              "score": 2,
              "created_utc": "2026-01-15 09:12:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzqn3ge",
          "author": "Holiday_Season_7425",
          "text": "free tier only 32K context?\n\nDid Logan just decide to stop pretending altogether",
          "score": 2,
          "created_utc": "2026-01-15 15:12:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzonu53",
          "author": "bcd155555",
          "text": "I have Pro plan, I use it on mobile application. Whatever they have written about context window doesnt add up 1 million? It loses track after just 5-6 prompts seriously.",
          "score": 2,
          "created_utc": "2026-01-15 06:17:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzp4pby",
          "author": "Valhall22",
          "text": "Interesting",
          "score": 1,
          "created_utc": "2026-01-15 08:50:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpdky1",
          "author": "EvanMok",
          "text": "I hope they won't reduce the thinking abilities of the Flash 3 Thinking model just to give us higher limits.",
          "score": 1,
          "created_utc": "2026-01-15 10:16:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqop08",
          "author": "Prince_ofRavens",
          "text": "I wonder if this is why I hit the limit for the first time today",
          "score": 1,
          "created_utc": "2026-01-15 15:19:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqru5h",
          "author": "Powerful-Street",
          "text": "I am on ultra and was wondering why I was hitting limits ü§¶üèª‚Äç‚ôÇÔ∏èü§¶üèª‚Äç‚ôÇÔ∏èü§¶üèª‚Äç‚ôÇÔ∏èü§¶üèª‚Äç‚ôÇÔ∏èü§¶üèª‚Äç‚ôÇÔ∏è",
          "score": 1,
          "created_utc": "2026-01-15 15:34:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztgv15",
          "author": "Afraid-Method-3942",
          "text": "Yep, hit my pro limit today (plus subscription), but still had thinking. This post clarified it. But plus had 1kk tokens before, so I ain't happy at all. Especially considering how dumb got gemini lately\n\nhttps://preview.redd.it/6urpf1eufldg1.png?width=1080&format=png&auto=webp&s=4a3c60a53c516c16431bda502d9c4636f8467bb5",
          "score": 1,
          "created_utc": "2026-01-15 22:59:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzomh8",
          "author": "A9-EE-78-6A-C8-9F",
          "text": "Man I miss 2.5\n\nI switched to ChatGPT and it feels about 90% as smart as Gemini 3 when it first launched. Lowkey depressed about it lol",
          "score": 1,
          "created_utc": "2026-01-16 20:54:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzp3kbf",
          "author": "Crinkez",
          "text": "128K context window for the plus plan is incredibly stupid. GPT pro ($20) gets you 400K context window.",
          "score": 0,
          "created_utc": "2026-01-15 08:39:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzp6wb0",
              "author": "Noodleholz",
              "text": "But Plus is significantly cheaper, 7,99‚Ç¨.",
              "score": 9,
              "created_utc": "2026-01-15 09:11:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzpfqlr",
                  "author": "Crinkez",
                  "text": "And 128K context window is utterly useless. Might as well use a free plan on any given LLM.",
                  "score": -2,
                  "created_utc": "2026-01-15 10:36:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzoteiu",
          "author": "nmole",
          "text": "How good is deepthink compared to pro and deep research?",
          "score": 1,
          "created_utc": "2026-01-15 07:05:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpcoxu",
          "author": "GameBeast45",
          "text": "![gif](giphy|Gtnf8Fok8An9m)",
          "score": 0,
          "created_utc": "2026-01-15 10:08:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qd0dc2",
      "title": "Google separates, raises Gemini 3 ‚ÄòThinking‚Äô and ‚ÄòPro‚Äô usage limits",
      "subreddit": "Bard",
      "url": "https://9to5google.com/2026/01/14/gemini-3-usage-limits-update/",
      "author": "Gaiden206",
      "created_utc": "2026-01-14 21:41:57",
      "score": 337,
      "num_comments": 30,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News ",
      "permalink": "https://reddit.com/r/Bard/comments/1qd0dc2/google_separates_raises_gemini_3_thinking_and_pro/",
      "domain": "9to5google.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzmg0x1",
          "author": "Equivalent-Word-7691",
          "text": "much better, it didn't make any sense , people where way less eager to use flash thinking because it was  burning also the pro quota .\n\nPprobably actually costing even more tha this for gemini becuase people were using 3.0 PRO at that point for everything ,because anyway they were burning the same shared quota and there was no point to use an inferior model ,now  instead for fast task that does't requite the deepness of pro peolle will use more flash thinking",
          "score": 57,
          "created_utc": "2026-01-14 22:19:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznsmu5",
              "author": "huffalump1",
              "text": "Agreed, surprised it took this long, because serving 3 Flash has got to be FAR cheaper than 3 Pro (judging by speed, API costs, and because it's gotta be a much bigger model).\n\nIt made no sense to pool them together.\n\nAnd, props to Google because Gemini 3 Flash Thinking is actually really good - it's my \"daily driver\" in Gemini and I pretty much only use Pro when it doesn't work (or when I really want it to be thorough and correct).",
              "score": 12,
              "created_utc": "2026-01-15 02:44:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzm83oy",
          "author": "Gaiden206",
          "text": "https://preview.redd.it/tcl4m4xcxddg1.png?width=1080&format=png&auto=webp&s=7725e6ae07bd0cb8a5199acc9c81504b526e1e18\n\n[https://support.google.com/gemini/answer/16275805?hl=en](https://support.google.com/gemini/answer/16275805?hl=en)",
          "score": 50,
          "created_utc": "2026-01-14 21:43:03",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nzmdn0o",
          "author": "GeneralComposer5885",
          "text": "Pro has always been 100 prompts per day (in most countries) .?",
          "score": 23,
          "created_utc": "2026-01-14 22:07:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzmeewc",
              "author": "hayden0103",
              "text": "Yes, the change is Thinking used to steal from your Pro limits. Now it has its own more generous quota.",
              "score": 41,
              "created_utc": "2026-01-14 22:11:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzmfp48",
                  "author": "GeneralComposer5885",
                  "text": "Got you üôÇüëç\n\nI‚Äôve found that starting a chat with Pro, then switching to fast or thinking - some of the advanced reasoning framework seems to distill across models / pro has done some of the heavy lifting / reasoning through the problem and the smaller model will copy.",
                  "score": 5,
                  "created_utc": "2026-01-14 22:17:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzmaxev",
          "author": "dogs_drink_coffee",
          "text": "nice.. I think. Never understood why sometimes Gemini limits Pro on App but not on Web",
          "score": 38,
          "created_utc": "2026-01-14 21:55:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmcg22",
          "author": "sdmat",
          "text": "Much better.",
          "score": 13,
          "created_utc": "2026-01-14 22:02:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmhpup",
          "author": "iserable-Two7383",
          "text": "I don't know why that change; I'm actually having more problems with my memory.",
          "score": 3,
          "created_utc": "2026-01-14 22:27:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzmwarx",
              "author": "throwaway867530691",
              "text": "Because now people are using the service even more",
              "score": 5,
              "created_utc": "2026-01-14 23:42:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzqbkzl",
          "author": "Ambitious-Garbage-73",
          "text": "For the first time today, in over a year, I reached the PRO limit.",
          "score": 2,
          "created_utc": "2026-01-15 14:14:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmdnq5",
          "author": "dao1st",
          "text": "What's the difference?",
          "score": 2,
          "created_utc": "2026-01-14 22:08:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzmp72j",
              "author": "Pantheon3D",
              "text": "Fast is 3 flash with minimal reasoning\n\nThinking is 3 flash with high reasoning\n\nPro is 3 pro",
              "score": 29,
              "created_utc": "2026-01-14 23:04:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzo821s",
                  "author": "Upstandinglampshade",
                  "text": "Is pro also thinking?",
                  "score": 1,
                  "created_utc": "2026-01-15 04:20:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzmqf8b",
                  "author": "dao1st",
                  "text": "Thanks!",
                  "score": 1,
                  "created_utc": "2026-01-14 23:11:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzmfqbo",
              "author": "Equivalent-Word-7691",
              "text": "now  you have 100 Gemini 3.0 pro per day AND 300 gemini 3.0 thinking pro per day , before it was jut 100 prompts  per day of both pro and flash thinking mixed  together,so if you used 50 promptd with flashthinking ,you had  jusy 50 prompts left with pro",
              "score": 22,
              "created_utc": "2026-01-14 22:17:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzmhf01",
                  "author": "dao1st",
                  "text": "Yeah, but which is better for what purpose?",
                  "score": 1,
                  "created_utc": "2026-01-14 22:25:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nznstz8",
          "author": "Mountain-Pain1294",
          "text": "Nice!",
          "score": 1,
          "created_utc": "2026-01-15 02:45:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvenb9",
          "author": "hydzifer",
          "text": "I‚Äôm so surprised did take so long finally",
          "score": 1,
          "created_utc": "2026-01-16 05:44:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw2fc2",
          "author": "Fast_Cauliflower_574",
          "text": "very generous!",
          "score": 1,
          "created_utc": "2026-01-16 09:07:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0cim5x",
          "author": "chou404",
          "text": "I am in love with Gemini 3 Flash Thinking this is my daily productivity powerhorse, curious to know what you're using Pro for? Am I missing something?",
          "score": 1,
          "created_utc": "2026-01-18 19:56:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmwx0j",
          "author": "romhacks",
          "text": "Everyone dooming about Google lowering quotas is suddenly oddly silent",
          "score": 0,
          "created_utc": "2026-01-14 23:45:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqo8fc",
              "author": "Holiday_Season_7425",
              "text": "If you think getting back rights that paying users were supposed to have ‚Äî after they were taken away ‚Äî counts as some kind of ‚Äúgenerous gift,‚Äù then congrats.\n\nYour transition into slavery is going remarkably smoothly.",
              "score": 3,
              "created_utc": "2026-01-15 15:17:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqvr6v",
                  "author": "romhacks",
                  "text": "3 Pro and 3 Flash Thinking High have been combined since they were released. Now they are not, and the limits are higher. That is not slavery. Don't call it slavery",
                  "score": 1,
                  "created_utc": "2026-01-15 15:52:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qf3ti7",
      "title": "3... 2... 1... Lobotomized",
      "subreddit": "Bard",
      "url": "https://i.redd.it/3ujm9jkw9udg1.png",
      "author": "Avg_SD_enjoyer",
      "created_utc": "2026-01-17 04:42:50",
      "score": 204,
      "num_comments": 16,
      "upvote_ratio": 0.85,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Funny ",
      "permalink": "https://reddit.com/r/Bard/comments/1qf3ti7/3_2_1_lobotomized/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o03uzh0",
          "author": "TheanineDevourer",
          "text": "This made me feel like I saw an old friend",
          "score": 29,
          "created_utc": "2026-01-17 14:09:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0661bi",
              "author": "TuringGoneWild",
              "text": "And they are just enjoying life - not a cell phone in sight",
              "score": 6,
              "created_utc": "2026-01-17 20:52:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o03a7i7",
          "author": "LawfulLeah",
          "text": "rage comics are back. nature is healing",
          "score": 35,
          "created_utc": "2026-01-17 11:47:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0265nu",
          "author": "Halschmuber",
          "text": "Fuck yes!  \nRage Comics!",
          "score": 40,
          "created_utc": "2026-01-17 05:44:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o024rbs",
          "author": "Hvarfa-Bragi",
          "text": "This except for nothing changes in the model, the users just hype each other up for every new release and slowly come down to reality.",
          "score": 31,
          "created_utc": "2026-01-17 05:33:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o028dtv",
              "author": "Su1tz",
              "text": "Why dont you people refuse to accept this?",
              "score": 29,
              "created_utc": "2026-01-17 06:01:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o02vx3l",
              "author": "Thomas-Lore",
              "text": "From reading the complaints on this sub it seems that the people with real issues are all using the gemini app. So while the model is unchanged and works fine (aistudio, api), the app itself seems to have issues now with attachements and context.",
              "score": 5,
              "created_utc": "2026-01-17 09:35:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0e5agg",
                  "author": "NutsackEuphoria",
                  "text": "Nah. Even in AI Studios, 3.0 has shit context window compared to 2.5.",
                  "score": 1,
                  "created_utc": "2026-01-19 00:55:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0svh56",
              "author": "mobcat_40",
              "text": "More like the goal post shifts and people want more. Models are half sentient in the last 12 months of updates with VL MoE and longer contexts.",
              "score": 1,
              "created_utc": "2026-01-21 04:46:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o09m8ff",
          "author": "ditungguwaktu",
          "text": "2012 called, it wants it's comic back",
          "score": 1,
          "created_utc": "2026-01-18 09:52:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o023ex7",
          "author": "melancious",
          "text": "keep the trash comics in the past",
          "score": -40,
          "created_utc": "2026-01-17 05:22:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02br5l",
              "author": "The_Nixck",
              "text": "https://preview.redd.it/far2dj7atudg1.jpeg?width=488&format=pjpg&auto=webp&s=b47cf56710cf5621f9593b0897fd730efb186b18",
              "score": 36,
              "created_utc": "2026-01-17 06:30:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o025ons",
              "author": "Halschmuber",
              "text": "https://preview.redd.it/nri5b6qbkudg1.jpeg?width=1920&format=pjpg&auto=webp&s=7e3f85f78be066f320fc752432cb50686bb934f8",
              "score": 27,
              "created_utc": "2026-01-17 05:40:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0384mo",
              "author": "Susp-icious_-31User",
              "text": "u can not haz cheezburger anymore",
              "score": 12,
              "created_utc": "2026-01-17 11:29:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o025dhh",
          "author": "AspectHot5584",
          "text": "https://preview.redd.it/uyk0q3wvjudg1.png?width=1080&format=png&auto=webp&s=bb424b0ff592f5fcac4a0b0acb876c7e3ebc0ea3\n\n# ARGENTO",
          "score": -18,
          "created_utc": "2026-01-17 05:37:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02wdwy",
              "author": "Chudo-Yoda",
              "text": "https://preview.redd.it/yohww853rvdg1.jpeg?width=640&format=pjpg&auto=webp&s=8c749f5b1edf2382968a73c1a0785aaa213f3b09",
              "score": 18,
              "created_utc": "2026-01-17 09:40:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qhzifv",
      "title": "Gemini integration into Chrome browser is just too darn good and useful",
      "subreddit": "Bard",
      "url": "https://i.redd.it/msdx4b6fwheg1.png",
      "author": "Snoo_64233",
      "created_utc": "2026-01-20 12:14:11",
      "score": 170,
      "num_comments": 31,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/Bard/comments/1qhzifv/gemini_integration_into_chrome_browser_is_just/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0nkuw0",
          "author": "douggieball1312",
          "text": "This would have come in useful so many times for me but sadly Google still hasn't brought it to the UK.",
          "score": 30,
          "created_utc": "2026-01-20 12:18:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nmpwu",
              "author": "Snoo_64233",
              "text": "You would think UK, Canada, US, Australia etc.... would receive the first class treatment when it comes to tech product launch. But why UK is lagging behind? This seems to keep happening lately, from what I observe.",
              "score": 3,
              "created_utc": "2026-01-20 12:31:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0od8yv",
                  "author": "nasduia",
                  "text": "Likely because of GDPR style privacy laws.",
                  "score": 11,
                  "created_utc": "2026-01-20 15:02:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0pcctp",
                  "author": "gmdmd",
                  "text": "dumb regulators",
                  "score": 3,
                  "created_utc": "2026-01-20 17:46:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0t9hxw",
                  "author": "Just_Lingonberry_352",
                  "text": "Europe and Australia I understand\n\nbut canada? \n\nliterally on the same continent",
                  "score": 1,
                  "created_utc": "2026-01-21 06:32:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0tvx0g",
                  "author": "Geminatorr",
                  "text": "UK isn't lagging behind, American companies don't want to comply with UK and EU laws. American companies are being lazy.",
                  "score": 1,
                  "created_utc": "2026-01-21 10:00:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0o6opv",
                  "author": "alexx_kidd",
                  "text": "US tech companies fault",
                  "score": 1,
                  "created_utc": "2026-01-20 14:28:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0noj8n",
          "author": "EvanMok",
          "text": "It would be great if it is not only for the US users.",
          "score": 53,
          "created_utc": "2026-01-20 12:44:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nr4mf",
          "author": "panic_in_the_cosmos",
          "text": "how to trigger this?",
          "score": 12,
          "created_utc": "2026-01-20 13:01:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nri8c",
              "author": "Snoo_64233",
              "text": "https://preview.redd.it/om6m6h436ieg1.png?width=560&format=png&auto=webp&s=288668269df1a6582528070c7f89b2e1657f7296",
              "score": 14,
              "created_utc": "2026-01-20 13:03:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0o7stw",
          "author": "iasad12",
          "text": "It would be great if they would expend this feature outside US.",
          "score": 9,
          "created_utc": "2026-01-20 14:34:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nr9nf",
          "author": "Eastern-Pepper-6821",
          "text": "Is it gemini pro?",
          "score": 4,
          "created_utc": "2026-01-20 13:01:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0u68xt",
              "author": "leaflavaplanetmoss",
              "text": "You can switch between Fast, Thinking, and Pro via a toggle in the prompt field.",
              "score": 1,
              "created_utc": "2026-01-21 11:31:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0vbwpo",
                  "author": "Eastern-Pepper-6821",
                  "text": "Oh wow i see",
                  "score": 1,
                  "created_utc": "2026-01-21 15:32:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0nreru",
          "author": "EastHillWill",
          "text": "Sorry for the obvious question but what platform/device is this?",
          "score": 3,
          "created_utc": "2026-01-20 13:02:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rh0zl",
          "author": "iamanonymouami",
          "text": "Same for Gemini integration in YouTube, it made so much easier to cross question while watching the video. But it do only by analysing transcribtion of video, I hope they add a feature to analyse given frame also.",
          "score": 3,
          "created_utc": "2026-01-20 23:51:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tx3u1",
              "author": "footyballymann",
              "text": "Yeah isn‚Äôt it just a fancy way at the moment that it just takes the audio transcription and uses that as a prompt? Not very impressive once you know how it‚Äôs done.",
              "score": 1,
              "created_utc": "2026-01-21 10:11:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0oe97l",
          "author": "Mother-Ad-2559",
          "text": "For all the non US people - you might want to try Dia. It‚Äôs basically the same except the integrations are even tighter",
          "score": 3,
          "created_utc": "2026-01-20 15:07:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0pevr7",
              "author": "zzzjh_",
              "text": "https://preview.redd.it/s96o6q6lmjeg1.png?width=1080&format=png&auto=webp&s=cee46f2521d25f1d7680704f9667db4476487ce3\n\nÊàëÂàöÂàöÂú®‰∏≠Êñá‰∫íËÅîÁΩëÁ§æÂå∫‰∏äÊâæÂà∞‰∫Ü‰ΩøÁî®ÊñπÊ≥ï  \nI just found a way to use it in the Chinese Internet community.  \nchrome.  \nÂú®ÊµèËßàÂô®Âú∞ÂùÄÊ†èËæìÂÖ•chrome://flagsÔºåÂ∞ÜTabstrip Combo Button„ÄÅGlic„ÄÅGlic Z Order ChangesÂíåGlic actorÂãæÈÄâÔºåÁÑ∂ÂêéÂÖ≥Èó≠ËØ•È°µÈù¢„ÄÇ",
              "score": 3,
              "created_utc": "2026-01-20 17:58:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0rx1st",
              "author": "brycedriesenga",
              "text": "There's also Comet by Perplexity and ChatGPT Atlas for some additional options",
              "score": 2,
              "created_utc": "2026-01-21 01:19:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0t9jge",
              "author": "Just_Lingonberry_352",
              "text": "no thanks dont want to become part of a botnet",
              "score": 1,
              "created_utc": "2026-01-21 06:32:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0op9qe",
          "author": "Ok_Caregiver_1355",
          "text": "And people still thinking AI browsers were just a gimmick but will become a standard feature somewhen.The governments and companies will know more about you than your own mom?Yeah but still convenient",
          "score": 1,
          "created_utc": "2026-01-20 15:59:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s8ko9",
          "author": "Covid-Plannedemic_",
          "text": "I wish edge's copilot integration was half as good. I switched to edge back when AI was cool and shiny and mustafa suleyman didn't exist yet. It's only gone backwards since. But at this point I am too attached to the mouse gestures and battery life to ever switch back to chrome",
          "score": 1,
          "created_utc": "2026-01-21 02:25:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0sblaw",
          "author": "RJvXP",
          "text": "Thank you for that screenshot.¬† Will be doing further research ‚ò∫Ô∏è",
          "score": 1,
          "created_utc": "2026-01-21 02:42:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nrdl4",
          "author": "neoqueto",
          "text": "Looks like the least useful feature imaginable (except for folks with disabilities), can it autofill forms and interactively crawl stateless webpages?",
          "score": -8,
          "created_utc": "2026-01-20 13:02:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nsbe5",
              "author": "Snoo_64233",
              "text": "you can do it with Gemini CLI for Chrome Devtools. Either that or use something like Perplexity's browser.  \nThey serve different purpose. Gemini Chrome integration for passive information digestion. Allowing Gemini to actually take actions on forms and browser tabs without sandboxing come with its own risk.",
              "score": 4,
              "created_utc": "2026-01-20 13:08:31",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0nv5qz",
              "author": "KoalaOk3336",
              "text": "afaik that feature is available for ultra subscribers, [https://gemini.google/overview/agent/](https://gemini.google/overview/agent/)",
              "score": 2,
              "created_utc": "2026-01-20 13:25:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ntnvi",
          "author": "CandiceWoo",
          "text": "i cant tell if its satire anymore",
          "score": -7,
          "created_utc": "2026-01-20 13:16:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhf7zz",
      "title": "Gemini Live preps big upgrades with ‚ÄòThinking Mode‚Äô and ‚ÄòExperimental Features‚Äô",
      "subreddit": "Bard",
      "url": "https://9to5google.com/2026/01/19/gemini-live-upgrade-teardown/",
      "author": "Gaiden206",
      "created_utc": "2026-01-19 20:10:54",
      "score": 154,
      "num_comments": 11,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News ",
      "permalink": "https://reddit.com/r/Bard/comments/1qhf7zz/gemini_live_preps_big_upgrades_with_thinking_mode/",
      "domain": "9to5google.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0jh93u",
          "author": "jonomacd",
          "text": "> Agent controls phone to complete tasks\n\n\nCool!\n\n\n> better noise handling\n\n\nInteresting...",
          "score": 26,
          "created_utc": "2026-01-19 20:26:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0je2h2",
          "author": "Gaiden206",
          "text": ">With the launch of Gemini 3 Pro in November, Google introduced the concept of ‚ÄúLabs‚Äù features like Gemini Agent, Dynamic View, and Visual layout.\n\n>Labs that you can opt into to test upcoming features are coming to the Gemini app on Android. Google app 17.2 reveals work on four capabilities, starting with: \n\n>- **Live Thinking Mode:** ‚ÄúTry a version of Gemini Live that takes time to think and provide more detailed responses.‚Äù\n\n>- **Live Experimental Features:** ‚ÄúTry our cutting-edge features: multimodal memory, better noise handling, responding when it sees something, and personalized results based on your Google apps.‚Äù\n\n>Live today is powered by Gemini 2.5 Flash. Those two Labs suggest that Gemini Live will soon be powered by Gemini 3. Live Thinking Mode could be using either the Thinking or Pro models for its ‚Äúmore detailed responses.‚Äù\n\n>Meanwhile, the Live Experimental Features are capabilities offered in the chat experience with Gemini 3 Flash and Pro. This includes Personal Intelligence‚Äôs Connected Apps and Past Gemini chats. Better noise cancellation is always needed, while ‚Äúresponding when it sees something‚Äù could be a Project Astra capability.\n\n>The other Labs features are:\n\n>- **UI Control:** ‚ÄúAgent controls phone to complete tasks‚Äù\n\n>- **Deep Research:** ‚ÄúDelegate complex research tasks\n\n>We're unsure what the last item is specifically about, but we've long been expecting Gemini Agent to come to Android as part of [Computer Use.](https://9to5google.com/2026/01/15/android-16-qpr3-screen-automation/)",
          "score": 21,
          "created_utc": "2026-01-19 20:11:07",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o0jk2ev",
          "author": "NorthCat1",
          "text": "And let me guess:\n\n**Only available to customers in the United States**",
          "score": 21,
          "created_utc": "2026-01-19 20:39:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jpsjr",
              "author": "MerBudd",
              "text": "Damn right, no way they release all this globally. Sighhh.",
              "score": 3,
              "created_utc": "2026-01-19 21:06:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0n6csk",
              "author": "douggieball1312",
              "text": "It'll be 'available to selected AI Pro subscribers in the US', then 'all US users' and then after a few months 'AI Pro subscribers in Canada and India'.",
              "score": 1,
              "created_utc": "2026-01-20 10:19:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0jyvn7",
          "author": "UltraBabyVegeta",
          "text": "Thinking mode is very much needed",
          "score": 5,
          "created_utc": "2026-01-19 21:51:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0k3unh",
          "author": "cricolo",
          "text": "Finally",
          "score": 3,
          "created_utc": "2026-01-19 22:15:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0oax1q",
          "author": "Belchacz",
          "text": "what I DESPERATELY need is text-to-speech like in ChatGPT, I hate when my messange get sent automatically when I pause to think",
          "score": 1,
          "created_utc": "2026-01-20 14:50:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mx5zv",
          "author": "osfric",
          "text": "I hope they release on ai studio",
          "score": 1,
          "created_utc": "2026-01-20 08:52:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0m8eaj",
          "author": "Mwrp86",
          "text": "It needs a upgrade.\n\nTalking feature feels straight up brain dead.",
          "score": 0,
          "created_utc": "2026-01-20 05:22:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0led01",
          "author": "PaulAtLast",
          "text": "\"Thinking Mode\" usually means it just goes through more safety and PR alignment layers to sand down the output before you see it.",
          "score": -3,
          "created_utc": "2026-01-20 02:23:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qg2qua",
      "title": "Dude, how much do you really like Nano Banana?",
      "subreddit": "Bard",
      "url": "https://i.redd.it/u0ubu3w6e2eg1.png",
      "author": "chuxkint",
      "created_utc": "2026-01-18 08:00:11",
      "score": 125,
      "num_comments": 26,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/Bard/comments/1qg2qua/dude_how_much_do_you_really_like_nano_banana/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o09d1iq",
          "author": "Gaiden206",
          "text": "Try \"Provide a text only response,\" a line space, and then your prompt, like the image below shows. That has been reliable for me when using the Pro or Thinking models.\n\nhttps://preview.redd.it/pks17pzvi2eg1.png?width=1080&format=png&auto=webp&s=4e62191b557c52f9fe0e38c5004a9f5e70a3e83d\n\nIt sometimes still says it's generating with Nano Banana Pro but it always ends up following the instructions, as seen in the screenshot.\n\nIt's a tip for constraint placement from a [Google Deepmind engineer blog post](https://www.philschmid.de/gemini-3-prompt-practices) about Gemini 3 Pro prompting.\n\n>**Constraint Placement:** Place behavioral constraints and role definitions in the System Instruction **or at the very top of the prompt to ensure they anchor the model's reasoning process.**",
          "score": 28,
          "created_utc": "2026-01-18 08:26:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09c8m9",
          "author": "williamtkelley",
          "text": "\"DO NOT GENERATE an image\" works for me. It still loads NBP, but gives me the text prompt I am asking for.",
          "score": 9,
          "created_utc": "2026-01-18 08:19:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0g2366",
              "author": "DescriptorTablesx86",
              "text": "Always try positive prompts, negative prompts fail way too often. \n\n‚ÄúOutput text only.‚Äù\n\nOtherwise not only can the LLM go wrong, also the preprocessing heurestics which might be as simple as checking if the user mentioned ‚Äúgenerate an image‚Äù",
              "score": 1,
              "created_utc": "2026-01-19 08:41:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0gccpp",
                  "author": "williamtkelley",
                  "text": "I absolutely include positive parts in the prompt, but negatives also help.",
                  "score": 2,
                  "created_utc": "2026-01-19 10:19:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o09dzel",
          "author": "InternetNational4025",
          "text": "SAME LOOOL! And it cannot understand context! When he did something really bad and you react by like OH MY GOSH it start generating an image of a person that is in shock! LOOOOL\n\nAnd also when you retaliate, like because he keeps giving you the same image even though you ask it to make changes on that exact image but still gave you the same image. When it does that the 5th time of course you will be livid and will retaliate and when you do that it will trigger some sort of check to ignore everything you said so it will just stop loading WTH!\n\nHow can a service improve if it cannot accept criticism! What a joke!",
          "score": 5,
          "created_utc": "2026-01-18 08:35:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0dmpp5",
              "author": "JASONC07",
              "text": "If it gives you a bad reply I would suggest you give it a thumbs down and feedback, talking to Gemini about your disappointment isn't going to help unfortunately. NBP recreating the same image is a problem for the developers not Gemini itself.",
              "score": 1,
              "created_utc": "2026-01-18 23:17:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o09iv2b",
          "author": "epic-cookie64",
          "text": "Yea it sometimes has issues using tools. In my experience if it says \"Loading Nano Banana Pro\" it doesn't always mean an image is being generated.",
          "score": 2,
          "created_utc": "2026-01-18 09:20:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09c3ms",
          "author": "RetiredApostle",
          "text": "I found that all-caps and swearing are working reliably. Like this meta-prompting: \"DON'T FUCKING GENERATE ANY FUCKING IMAGES, REPLY WITH TEXT\". Works.",
          "score": 3,
          "created_utc": "2026-01-18 08:17:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09c84x",
              "author": "chuxkint",
              "text": "Gemini likes to be scoldedüíÄ",
              "score": 1,
              "created_utc": "2026-01-18 08:18:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o09ee7o",
          "author": "Longjumping_Area_944",
          "text": "Use Antigravity to manage the prompts.",
          "score": 1,
          "created_utc": "2026-01-18 08:39:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09qhrf",
          "author": "Jean_velvet",
          "text": "It tokenized the text. AI breaks it down into individual words, you said \"generate images\" which is the equivalent to \"don't think of a pink elephant\" to AI.\n\n\nTry avoiding trigger words \"generate text without any visual representation\".",
          "score": 1,
          "created_utc": "2026-01-18 10:31:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0g2n9l",
              "author": "DescriptorTablesx86",
              "text": "Negative prompts have little to do with tokenisation, but a lot to do with how ‚Äúdon‚Äôt think of a pink elephant‚Äù works. \n\nNot sure about this case though because im pretty sure Google uses some simple heuristics to force NBP when generating images is mentioned.",
              "score": 1,
              "created_utc": "2026-01-19 08:47:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0g6vot",
                  "author": "Jean_velvet",
                  "text": "Yeah, I've tested it. Add \"generate\" and \"image\" it'll activate nano banana *usually*, sometimes it'll think for ages having a mini crisis trying to decide if it needs to generate an image or reply with text.\n\nOn the plus side, Gemini is super reactive to clear prompting. Leave no ambiguities and it'll just straight into what you want.\n\nLong story short: If you make prompts clear commands it responds a lot better (same with all LLMs but especially good with Gemini).",
                  "score": 1,
                  "created_utc": "2026-01-19 09:27:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0a7l3w",
          "author": "ManufacturerHuman937",
          "text": "I've had luck by specifying no tool calls",
          "score": 1,
          "created_utc": "2026-01-18 12:56:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0b5xhr",
          "author": "KiD-KiD-KiD",
          "text": " [also gemini ](https://www.reddit.com/r/GeminiAI/s/8d19xGn1hx)",
          "score": 1,
          "created_utc": "2026-01-18 16:07:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bklut",
          "author": "Independent_Lock864",
          "text": "Gemini is kinda dumb sometimes. You have to be REALLY specific and clear or it'll just assume a bunch of things. All of them wrong :P",
          "score": 1,
          "created_utc": "2026-01-18 17:16:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c41qx",
          "author": "tdwp",
          "text": "I might be dumb but the images of creates for me are terrible every single time",
          "score": 1,
          "created_utc": "2026-01-18 18:46:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0eeo21",
          "author": "MINIVV",
          "text": "I ask Gemini to write a prompt and not generate an image. Nano Banana is launching...",
          "score": 1,
          "created_utc": "2026-01-19 01:47:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fkoax",
          "author": "Jiyon-On-R",
          "text": "You need to be precise with your prompts so you won't waste them. A simple line saying \"do not generate any images\" would've resolved this issue.",
          "score": 1,
          "created_utc": "2026-01-19 06:10:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0frka3",
          "author": "CygnusWinter",
          "text": "You have to use clear instructions to Gemini such as 'I want you to generate a prompt for me about_____, but DO NOT create the image. You have to respond with text only.' something like this. Trust me cause I had this experience with Nano Banana Pro too, and this is the real solution. üòä",
          "score": 1,
          "created_utc": "2026-01-19 07:06:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ge2kc",
          "author": "Secret-Feed-1459",
          "text": "Loading nano banana sure here's your image\n\nhttps://preview.redd.it/t2dacv3qaaeg1.png?width=720&format=png&auto=webp&s=00c6cb794e30a9208e5b364e412aaf404561efeb",
          "score": 1,
          "created_utc": "2026-01-19 10:34:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0krpc3",
          "author": "Every_Pineapple_3955",
          "text": "i been friend requested by now 3 chatbots on tg who want me to buy there onlyfans site. they try convince and act as real girls and get money from men. WHY IS NO ONE TALKING ABOUT THIS",
          "score": 1,
          "created_utc": "2026-01-20 00:20:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0l24gg",
          "author": "MozaikLIFE",
          "text": "Honestly in my opinion that's such a bad prompting if you just want to ask any AI to make you a prompt. In my case I usually do this:\n\n\n\"Make a list of natural language prompt for AI image with these themes: (insert your theme).\"",
          "score": 1,
          "created_utc": "2026-01-20 01:16:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tjtnq",
          "author": "UmpireFabulous1380",
          "text": "Gemini is \\*extremely\\* poor at interpreting instructions (which is somewhat ridiculous considering the purpose of an LLM.  \nYou have to talk to it like you are preparing instructions for an absolute idiot, or shout at it using capital letters and threatening language. These are really the only things that will make it \"listen\" to you. \n\nEven then it is somewhat ignorant - Flash in particular is awful (really, really, borderline unbelievably bad at times) for understanding contextual instructions.",
          "score": 1,
          "created_utc": "2026-01-21 08:04:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09amqr",
          "author": "shun_master23",
          "text": "Have this problem with both nano banana and veo3.1 \n\nWhen I try to generate prompt it either switches to video or photo generation. Gemini shouldn't be able to automatically switch the models",
          "score": -1,
          "created_utc": "2026-01-18 08:04:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bn2z9",
          "author": "Substantial-Ad7760",
          "text": "Skill issues.",
          "score": -4,
          "created_utc": "2026-01-18 17:28:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qe6dir",
      "title": "Gemini 2-5 pro today is actually better than 3.0",
      "subreddit": "Bard",
      "url": "https://www.reddit.com/r/Bard/comments/1qe6dir/gemini_25_pro_today_is_actually_better_than_30/",
      "author": "Robert__Sinclair",
      "created_utc": "2026-01-16 04:34:50",
      "score": 120,
      "num_comments": 42,
      "upvote_ratio": 0.83,
      "text": "It's a week that it's impossible to work with Gemini 3.0 pro, sounds like a dumb junior dev. Have to make it understand all the time (especially javascript). 2.5 pro is sure not as it was in march 2025 but it's actually better today (coding mainly) than 3.0.\n\nAnother thing I have noticed: for complex CSS problems, Claude Sonnet 4.5 is way better than Gemini.\n\nAt least this is my experience in the last 2 weeks. When 3.0 pro came out was amazing.",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/Bard/comments/1qe6dir/gemini_25_pro_today_is_actually_better_than_30/",
      "domain": "self.Bard",
      "is_self": true,
      "comments": [
        {
          "id": "nzw0z29",
          "author": "missinima",
          "text": "Some idiots are downvoting any and all these valid criticisms i wonder who they are",
          "score": 53,
          "created_utc": "2026-01-16 08:54:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzyldic",
              "author": "dadakoglu",
              "text": "Yes, I‚Äôm wondering about this too. I really like Gemini and the entire Google ecosystem, but I don‚Äôt hold back from criticism when it‚Äôs necessary. Some people are like total fanboys.",
              "score": 20,
              "created_utc": "2026-01-16 17:55:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o018fv3",
                  "author": "Robert__Sinclair",
                  "text": "same here. I like Gemini too.",
                  "score": 10,
                  "created_utc": "2026-01-17 01:55:54",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o02s5wu",
              "author": "HidingInPlainSite404",
              "text": "Fanboys deep in the Google ecosystem.",
              "score": 3,
              "created_utc": "2026-01-17 08:59:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o012l9s",
          "author": "frbruhfr",
          "text": "How can we demand visibility? Is it not insane to query a model and get different quality range ? \n\ni see all these posts about ‚Äúmodel X was better 3 months ago ‚Äú , ‚Äúmodel Y sucks today , was brilliant last week ‚Äú\n\nisnt this a way for us to go koo koo ? \nhow can we demand visibility and consistency !",
          "score": 6,
          "created_utc": "2026-01-17 01:18:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o06k79e",
              "author": "ComprehensiveWave475",
              "text": "I think is mostly uneatable it always happens the same.¬† ¬†Happened to 2.5¬†",
              "score": 1,
              "created_utc": "2026-01-17 22:04:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0g730s",
              "author": "Disastrous-Gap-1402",
              "text": "The model felt amazing right after it was released, but over time, it hasn't been as smooth to use. I suspect they switched to a quantized version later on to cut costs.",
              "score": 1,
              "created_utc": "2026-01-19 09:29:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o01r9p9",
          "author": "Ckdk619",
          "text": "It's always easy to tell when they start downgrading their models. I use Gemini for translation using a consistent system prompt, and whenever there's a new launch there are no issues for, maybe, a week or two at least. After a downgrade hits, all of a sudden it mixes in bits and pieces of the source text in the translation. Every time. One of the clearest and most noticeable signs of decline in following or understanding system instructions. I'm sure I could refine the prompt so that this doesn't happen, but then I wouldn't know when a downgrade hits.",
          "score": 11,
          "created_utc": "2026-01-17 03:56:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzgd8c",
          "author": "suprachromat",
          "text": "I tried Gemini 3 Pro, not impressed, felt like an intelligence downgrade vs Gemini 2.5 Pro even. Then Sonnet 4.5 came out, much better. And THEN... then Opus 4.5 came out. Holy moley. Opus 4.5 is some real good stuff. Haven't looked back.",
          "score": 25,
          "created_utc": "2026-01-16 20:15:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01ixvy",
              "author": "wakethenight",
              "text": "Opus is also twice the price of Gemini 3, but it evens out, not surprisingly.",
              "score": 6,
              "created_utc": "2026-01-17 03:01:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o08x3nr",
              "author": "AskLeft2366",
              "text": "Use Opus 4.5 through antigravity, it's far more brilliant than Gemini 3 Pro/Flash.",
              "score": 1,
              "created_utc": "2026-01-18 06:06:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o00c7xl",
          "author": "-becausereasons-",
          "text": "I've been noticing a MASSIVE facepalm downgrade both in Gemini 3 and Claude Opus 4.5; all of a sudden ChatGPT is acting better; honestly all these fucking models are scams. They constantly bate and switch us with quantization nonsense to conserve energy and tokens.",
          "score": 11,
          "created_utc": "2026-01-16 22:47:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00e0pm",
          "author": "lmagusbr",
          "text": "Google is disgusting. Anyone remembers Gemini 2.5 Pro 03-25? :) Their best model yet.",
          "score": 12,
          "created_utc": "2026-01-16 22:57:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o018u9o",
              "author": "Robert__Sinclair",
              "text": "yes. I do. the actual 2.5-pro is \\*almost\\* as good. but the 03-25 was a breeze to work with.",
              "score": 7,
              "created_utc": "2026-01-17 01:58:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzv8c1f",
          "author": "dadakoglu",
          "text": "Yes, Opus and even Sonnet are better than Gemini at almost every coding task.\n\nI can't recommend Gemini 3 to people as much as I used to.",
          "score": 6,
          "created_utc": "2026-01-16 05:00:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o018s7u",
              "author": "skate_nbw",
              "text": "LOL, I have been down-voted in the last 2 weeks for saying that it is setting people up to recommend Gemini at the moment (might change again). Finally some other people get the insight.",
              "score": 2,
              "created_utc": "2026-01-17 01:58:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o00dlgq",
          "author": "Euphoric_Tutor_5054",
          "text": "I won‚Äôt use gemini 3 before a new version of it is released",
          "score": 1,
          "created_utc": "2026-01-16 22:54:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01gbhl",
          "author": "Ill-Purchase-9801",
          "text": "Noobs.",
          "score": 1,
          "created_utc": "2026-01-17 02:45:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01q2l9",
          "author": "BusinessReplyMail1",
          "text": "I‚Äôve given up on Gemini for coding. Claude Opus and ChatGPT 5.2 high are much better.",
          "score": 1,
          "created_utc": "2026-01-17 03:48:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01waq5",
          "author": "Wengrng",
          "text": "my go to model still. Unless I'm asking a very specific and hard knowledge question, I'm pretty much going to be using 2.5 pro for everything else",
          "score": 1,
          "created_utc": "2026-01-17 04:31:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02ey9s",
          "author": "thysanoessa",
          "text": "Any concrete examples we can repeat where Gemini 3 noticeably performs worse with the same prompt?",
          "score": 1,
          "created_utc": "2026-01-17 06:58:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02g2sm",
          "author": "Tony_Stark_MCU",
          "text": "I use Opus 4.5, Gpt 5.2 Thinking and Gemini 3 Pro. They helped me to build a very nice AI assistant with RAG, solid VB.\n\nBut, I use them all as not only code writers, but also as brainstorm partners. They all have their advantages and disadvantages.",
          "score": 1,
          "created_utc": "2026-01-17 07:08:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02nfqj",
          "author": "Elven77AI",
          "text": "I sadly have to agree: Gemini 3.0 hallucinates and subverts the entrie prompt to answer something that is tangentially related but its pop-sci/pop-culture framed response that isn't like the preview version. The quality isn't there anymore and 2.5 doesn't do these silly clown shows, going straight to answer/reasoning.\nThe only time i get somewhat decent quality is via Gemini3.0 flash(no thinking) on LMArena.",
          "score": 1,
          "created_utc": "2026-01-17 08:15:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02rxg1",
          "author": "Some-Act-3010",
          "text": "Pro is now more of a free model i.e needs to be energy restricted, probably a new tier inc soon between pro and ultra\n\n\nThey are setting up for the segregation for society",
          "score": 1,
          "created_utc": "2026-01-17 08:57:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03hgh0",
          "author": "Capable-Row-6387",
          "text": "The hard truth simply is opus 4.5 and codex 5.2 are much better than g3.",
          "score": 1,
          "created_utc": "2026-01-17 12:45:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04dx2p",
          "author": "zippydazoop",
          "text": "2.5 pro is much better at following instructions and never parrots my words to pretend it understands me. 3 is better at solving problems but it sucks at following instructions and does things I don‚Äôt want it to.",
          "score": 1,
          "created_utc": "2026-01-17 15:46:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o058iah",
          "author": "Pokeasss",
          "text": "What about Flash 3 ?",
          "score": 1,
          "created_utc": "2026-01-17 18:10:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05lsut",
          "author": "urarthur",
          "text": "no",
          "score": 1,
          "created_utc": "2026-01-17 19:11:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o06diur",
          "author": "LawfulLeah",
          "text": "3.0 is worse than 2.5 by like... a lot",
          "score": 1,
          "created_utc": "2026-01-17 21:30:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09uoj0",
          "author": "hydzifer",
          "text": "Gemini 3 pro Really a downgrade from 2.5 pro literally the same situation when did chat gpt 5.2 came out was also a downgrade from 5.1",
          "score": 1,
          "created_utc": "2026-01-18 11:09:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0g0y86",
          "author": "panam-simp",
          "text": "In creative writing, 3 preview is at least not as prone to cliches. It is better at remembering the details past 150k tokens. But ultimately, 2.5 pro is better overall I think.",
          "score": 1,
          "created_utc": "2026-01-19 08:31:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzylitb",
          "author": "YamberStuart",
          "text": "Where can I use the older versions? They no longer appear in AI Studio.",
          "score": 1,
          "created_utc": "2026-01-16 17:56:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzyuz7p",
              "author": "Robert__Sinclair",
              "text": "```\n- embedding-gecko-001 (Embedding Gecko)\n- gemini-2.5-flash (Gemini 2.5 Flash)\n- gemini-2.5-pro (Gemini 2.5 Pro)\n- gemini-2.0-flash-exp (Gemini 2.0 Flash Experimental)\n- gemini-2.0-flash (Gemini 2.0 Flash)\n- gemini-2.0-flash-001 (Gemini 2.0 Flash 001)\n- gemini-2.0-flash-lite-001 (Gemini 2.0 Flash-Lite 001)\n- gemini-2.0-flash-lite (Gemini 2.0 Flash-Lite)\n- gemini-2.0-flash-lite-preview-02-05 (Gemini 2.0 Flash-Lite Preview 02-05)\n- gemini-2.0-flash-lite-preview (Gemini 2.0 Flash-Lite Preview)\n- gemini-exp-1206 (Gemini Experimental 1206)\n- gemini-2.5-flash-preview-tts (Gemini 2.5 Flash Preview TTS)\n- gemini-2.5-pro-preview-tts (Gemini 2.5 Pro Preview TTS)\n- gemma-3-1b-it (Gemma 3 1B)\n- gemma-3-4b-it (Gemma 3 4B)\n- gemma-3-12b-it (Gemma 3 12B)\n- gemma-3-27b-it (Gemma 3 27B)\n- gemma-3n-e4b-it (Gemma 3n E4B)\n- gemma-3n-e2b-it (Gemma 3n E2B)\n- gemini-flash-latest (Gemini Flash Latest)\n- gemini-flash-lite-latest (Gemini Flash-Lite Latest)\n- gemini-pro-latest (Gemini Pro Latest)\n- gemini-2.5-flash-lite (Gemini 2.5 Flash-Lite)\n- gemini-2.5-flash-image (Nano Banana)\n- gemini-2.5-flash-preview-09-2025 (Gemini 2.5 Flash Preview Sep 2025)\n- gemini-2.5-flash-lite-preview-09-2025 (Gemini 2.5 Flash-Lite Preview Sep 2025)\n- gemini-3-pro-preview (Gemini 3 Pro Preview)\n- gemini-3-flash-preview (Gemini 3 Flash Preview)\n- gemini-3-pro-image-preview (Nano Banana Pro)\n- nano-banana-pro-preview (Nano Banana Pro)\n- gemini-robotics-er-1.5-preview (Gemini Robotics-ER 1.5 Preview)\n- gemini-2.5-computer-use-preview-10-2025 (Gemini 2.5 Computer Use Preview 10-2025)\n- deep-research-pro-preview-12-2025 (Deep Research Pro Preview (Dec-12-2025))\n- embedding-001 (Embedding 001)\n- text-embedding-004 (Text Embedding 004)\n- gemini-embedding-exp-03-07 (Gemini Embedding Experimental 03-07)\n- gemini-embedding-exp (Gemini Embedding Experimental)\n- gemini-embedding-001 (Gemini Embedding 001)\n- aqa (Model that performs Attributed Question Answering.)\n- imagen-4.0-generate-preview-06-06 (Imagen 4 (Preview))\n- imagen-4.0-ultra-generate-preview-06-06 (Imagen 4 Ultra (Preview))\n- imagen-4.0-generate-001 (Imagen 4)\n- imagen-4.0-ultra-generate-001 (Imagen 4 Ultra)\n- imagen-4.0-fast-generate-001 (Imagen 4 Fast)\n- veo-2.0-generate-001 (Veo 2)\n- veo-3.0-generate-001 (Veo 3)\n- veo-3.0-fast-generate-001 (Veo 3 fast)\n- veo-3.1-generate-preview (Veo 3.1)\n- veo-3.1-fast-generate-preview (Veo 3.1 fast)\n- gemini-2.5-flash-native-audio-latest (Gemini 2.5 Flash Native Audio Latest)\n- gemini-2.5-flash-native-audio-preview-09-2025 (Gemini 2.5 Flash Native Audio Preview 09-2025)\n- gemini-2.5-flash-native-audio-preview-12-2025 (Gemini 2.5 Flash Native Audio Preview 12-2025)\n```\n\nAll available using the **API**",
              "score": 3,
              "created_utc": "2026-01-16 18:37:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzywmnw",
                  "author": "YamberStuart",
                  "text": "How do I use the API?",
                  "score": 0,
                  "created_utc": "2026-01-16 18:44:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o01d7x9",
          "author": "Rare_Bunch4348",
          "text": "The downvotes are from users who use AI to say Hi Gemini¬†",
          "score": 1,
          "created_utc": "2026-01-17 02:26:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00rs6p",
          "author": "AtraVenator",
          "text": "Not another one of this crap ‚Ä¶¬†",
          "score": 0,
          "created_utc": "2026-01-17 00:13:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzx7j21",
          "author": "SomeOrdinaryKangaroo",
          "text": "I disagree, 2.5 flash lite is beating 3.0 Pro since last week for me",
          "score": -1,
          "created_utc": "2026-01-16 14:07:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01a7ug",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -1,
          "created_utc": "2026-01-17 02:07:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01nj2a",
              "author": "strigov",
              "text": "Friend, can you read? We are comparing experience with time after release, and the model showed better quality in different tasks (not only coding). You see? Not bad ‚Äî it's just was better",
              "score": 1,
              "created_utc": "2026-01-17 03:31:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzzwrlt",
          "author": "MichelleeeC",
          "text": "Me still using Gemini 1.0 and GPT 3.5 bro. \n\nWhat is even Gemini 2.5??? does it exist??? \n\n,üò≠üò≠üò≠",
          "score": -4,
          "created_utc": "2026-01-16 21:32:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00rf3z",
              "author": "ModsRB1tches",
              "text": "but I thought they are no longer available or at least no longer have free quotas or something? Where can i get gemini 1.5 ?",
              "score": 1,
              "created_utc": "2026-01-17 00:11:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09mfl0",
                  "author": "MichelleeeC",
                  "text": "The past",
                  "score": 1,
                  "created_utc": "2026-01-18 09:53:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qhbbo9",
      "title": "Gemini ???",
      "subreddit": "Bard",
      "url": "https://www.reddit.com/gallery/1qhbbo9",
      "author": "Yazzdevoleps",
      "created_utc": "2026-01-19 17:54:05",
      "score": 103,
      "num_comments": 27,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News ",
      "permalink": "https://reddit.com/r/Bard/comments/1qhbbo9/gemini/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0j1ext",
          "author": "huffalump1",
          "text": "I REALLY hope they fix 3 Pro's stubbornness that it is January 2025 and that anything after that MUST be an error, simulation, or hypothetical... Along with more consistent web search tool calling.\n\n3 Flash handles this just fine.",
          "score": 41,
          "created_utc": "2026-01-19 19:12:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ja5h9",
              "author": "Deciheximal144",
              "text": "3's insistence on good coding style is aggravating.",
              "score": 4,
              "created_utc": "2026-01-19 19:52:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0loogk",
              "author": "DavidAdamsAuthor",
              "text": "I've also noticed this same problem.",
              "score": 1,
              "created_utc": "2026-01-20 03:20:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0isaiq",
          "author": "contafi10",
          "text": "who cares. they should fix the 1 MiLlion context window first",
          "score": 40,
          "created_utc": "2026-01-19 18:32:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0j0z4t",
              "author": "Holiday_Season_7425",
              "text": "next time 16K 8k 4k *Context Length*",
              "score": 10,
              "created_utc": "2026-01-19 19:10:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0iw7hs",
              "author": "NoWheel9556",
              "text": "\\+1",
              "score": 5,
              "created_utc": "2026-01-19 18:49:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0omtta",
              "author": "Acceptable-Debt-294",
              "text": "Agree +1",
              "score": 2,
              "created_utc": "2026-01-20 15:48:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0ozyuc",
              "author": "Numerous-Campaign844",
              "text": "YES!!",
              "score": 1,
              "created_utc": "2026-01-20 16:49:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0itf73",
          "author": "Arthesia",
          "text": "Does it follow instructions?\n\nIf yes, I will immediately swap back from Claude.\n\nIf not, I will continue to pretend like Gemini 3 isn't real.\n\nReally is as simple as that. Make your model do exactly as I tell it to do.",
          "score": 25,
          "created_utc": "2026-01-19 18:37:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0lq34l",
              "author": "anomnib",
              "text": "Thank you for saying this. Gemini doesn‚Äôt follow instructions and makes stuff up.",
              "score": 3,
              "created_utc": "2026-01-20 03:28:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0jvefj",
              "author": "A9-EE-78-6A-C8-9F",
              "text": "What made you switch to Claude over ChatGPT 5.2?\n\nI plan to test Claude next when my current month of Chatgpt plus expires\n\nThe Gemini 3 flop has really scared me away from trusting Google.",
              "score": -1,
              "created_utc": "2026-01-19 21:34:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0iqf9m",
          "author": "vitorino82",
          "text": "Today I was using flash 3.0 in antigravity and have been an amazing day, It nailed everything that used to requiere several iterations. Thay are probably also having something new there too.",
          "score": 16,
          "created_utc": "2026-01-19 18:24:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ik6ju",
          "author": "Holiday_Season_7425",
          "text": "What's the point? They'll only end up releasing a quantization 16K version",
          "score": 16,
          "created_utc": "2026-01-19 17:56:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ik6f1",
          "author": "ANONYMOUSEJR",
          "text": "Worried about the hallucinations remark...",
          "score": 10,
          "created_utc": "2026-01-19 17:56:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ikiqm",
          "author": "OneMisterSir101",
          "text": "Useless if hallucinations remain as they are.",
          "score": 13,
          "created_utc": "2026-01-19 17:58:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0j43gz",
          "author": "Deciheximal144",
          "text": "I'm glad to see the discussion moving to next version again, but is this a solid data indicating that's about to happen?",
          "score": 2,
          "created_utc": "2026-01-19 19:24:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mat1a",
          "author": "Neither-Phone-7264",
          "text": "If it's still really bad at hallucinating, it's DOA.",
          "score": 2,
          "created_utc": "2026-01-20 05:40:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0iufdy",
          "author": "BarisSayit",
          "text": "Can't it be Gemma 4?",
          "score": 3,
          "created_utc": "2026-01-19 18:41:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jj0ia",
          "author": "Queen_the_plague",
          "text": "Flash far far better than pro high/low",
          "score": 2,
          "created_utc": "2026-01-19 20:34:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0voo9u",
              "author": "McPuglis",
              "text": "Su antigravity confermo in pieno, sembra proprio capire meglio le indicazioni e non va in errore ogni 10 secondi",
              "score": 1,
              "created_utc": "2026-01-21 16:30:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ity6p",
          "author": "LofiStarforge",
          "text": "Do not care until it‚Äôs in production for everyone to use. I have used amazing models on Lmarena over the years that end up getting super nerfed by the time it‚Äôs publicly available.\n\nIt‚Äôs not very hard for any of these companies to give an extremely impressive model to a very small amount of people for extremely limited use.",
          "score": 2,
          "created_utc": "2026-01-19 18:39:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0iwcjo",
          "author": "drhenriquesoares",
          "text": "Come√ßou...",
          "score": 1,
          "created_utc": "2026-01-19 18:50:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0m0jf0",
              "author": "Which_Network_993",
              "text": "r/suddenlycaralho",
              "score": 1,
              "created_utc": "2026-01-20 04:29:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0nf9bq",
          "author": "ain92ru",
          "text": "Gemini 3 Pro is already vision SOTA by far. I've got a couple of A/B testing in the AI Studio and wasn't able to tell which is the newer model (both gens were on par), so this should be just a minor increment on 3 Pro",
          "score": 1,
          "created_utc": "2026-01-20 11:36:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0iwi2v",
          "author": "NoWheel9556",
          "text": "didnt these people say something similar for when Preview was about to drop , but then it became Lazy and stuff . hard to believe now , until its out and tested for atleast 2 weeks",
          "score": 0,
          "created_utc": "2026-01-19 18:50:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0obegq",
          "author": "FeatureSafe8116",
          "text": "Hey I want to use Claude but it's free limits expires very fast like I can get only 2-3 turns any suggestions on how to optimize it ? Is Claude code better than using Claude in web ?",
          "score": 0,
          "created_utc": "2026-01-20 14:52:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0svs8o",
              "author": "FalseAcadia4306",
              "text": "Get on a paid sub. \n\nClaude isn't designed for free users. Hell it's barely designed for the $20/mo plan. There really isn't a way around this -- they don't have the endless VC money like OAI and the billions in cash Google does.\n\nIf you want to do anything meaningful with Claude you need to be on a Max plan.",
              "score": 1,
              "created_utc": "2026-01-21 04:48:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qg8aly",
      "title": "No matter how good Gemini gets, I can never delete Chatgpt from my phone for 1 simple reason...",
      "subreddit": "Bard",
      "url": "https://www.reddit.com/r/Bard/comments/1qg8aly/no_matter_how_good_gemini_gets_i_can_never_delete/",
      "author": "nemzylannister",
      "created_utc": "2026-01-18 13:15:18",
      "score": 95,
      "num_comments": 46,
      "upvote_ratio": 0.86,
      "text": "GEMINI's VOICE TRANSCRIPTION IS SO GARBAAAAGE\n\nAm i the only one who feels this? it almost doesnt even work. its bizarre how they have an amazing free voice to voice model, yet their voice transcription is completely garbage.\n\nHey google, openai stole your transformers architecture, nobody will mind if you steal whisper to use for your model. Please ffs.\n\nNot only does it get what i say wrong, on top of that, it will randomly decide you're done speaking and immediately send the query to the model. Can i please think for a second??\n\nEven the google keyboard stt on android is better somehow than this.\n\nIt's bizarre because google has had free voice transcription before any company, yet now theyre behind openai on it?\n\nChatgpt's whisper is amazing, seriously. The ui is perfect. you click the button, it shows you that its recording now, you speak for as long as you like, be silent and think what you wanna say, and once youre done, even if its 3 minutes later, it will transcribe it for you. it's literally perfect.\n\nThere have been times when i have used chatgpt to transcribe something and then copy paste that into gemini, just because gemini's transcriber is nowhere close.\n\nPlease google, rather than stealing \"answer now\" button from chatgpt, steal this instead!",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/Bard/comments/1qg8aly/no_matter_how_good_gemini_gets_i_can_never_delete/",
      "domain": "self.Bard",
      "is_self": true,
      "comments": [
        {
          "id": "o0adb1t",
          "author": "MissJoannaTooU",
          "text": "I often use a long voice prompt on ChatGPT then paste it into Gemini for a dual answer. \n\nIt's crazy. \n\nIt's on their roadmap to stop it sending the prompt too early and are talking about it like it's a great achievement despite whisper being there since 2023 in the OIA app.\n\nGoogle's whole front end for their LLMs are half baked.",
          "score": 38,
          "created_utc": "2026-01-18 13:34:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0b01m2",
              "author": "nemzylannister",
              "text": "> It's on their roadmap to stop it sending the prompt too early \n\nwait they have a roadmap??\n\n> Google's whole front end for their LLMs are half baked.\n\naistudio is pretty decent. and actually if you try transcription in google docs its also really good. idk why gemini app has the worst google employees handling it. at this point they should be worried they'll be the first guys getting replaced by gemini.",
              "score": 6,
              "created_utc": "2026-01-18 15:38:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0bnrve",
                  "author": "MissJoannaTooU",
                  "text": "AI Studio isn't private in any way to sure if want your data used for training go for it. \n\nAnd it's free. \n\nBut the paid apps of all kinds suck.",
                  "score": 1,
                  "created_utc": "2026-01-18 17:32:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0dgceg",
              "author": "twoww",
              "text": "Stopping the recording too early is so annoying. The amount of times I stop to think about what I want to say and have it just send half a prompt is way too high.",
              "score": 5,
              "created_utc": "2026-01-18 22:45:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0iklv8",
                  "author": "geekshe",
                  "text": "That makes me crazy. So I switched to using the dictation mode on my keyboard (in my case Gboard on iphone) and I can talk as long as I want.",
                  "score": 1,
                  "created_utc": "2026-01-19 17:58:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0ao12c",
              "author": "No-Alarm-1919",
              "text": "Gemini says this is all because it not only doesn't cost them engagement time, but increases it for their core 90% targeted audience.\n\nWhether that's accurate or not, I didn't check. But it seemed so plausible that I didn't bother.",
              "score": -1,
              "created_utc": "2026-01-18 14:37:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ai7ca",
          "author": "Kurdonoid",
          "text": "right there with you, I've moved from gpt for 4 months now and I miss that so much. but they have a new model and UI just for dictation soon, it's supposed to be released in March.\n\nhttps://preview.redd.it/rq3boox874eg1.png?width=1248&format=png&auto=webp&s=b77a6d87a03a69669292301961af87c48e47736a",
          "score": 11,
          "created_utc": "2026-01-18 14:04:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ar4d5",
              "author": "No-Alarm-1919",
              "text": "And this wasn't released sooner because? Thanks for posting!",
              "score": 3,
              "created_utc": "2026-01-18 14:53:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0bkct3",
              "author": "Daseinew",
              "text": "where did you find this info?",
              "score": 2,
              "created_utc": "2026-01-18 17:15:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0c8t1s",
                  "author": "Kurdonoid",
                  "text": "https://www.findarticles.com/google-launches-gemini-smart-dictation-on-android/?hl=en-US#:~:text=If%20you've%20ever%20found,without%20cumbersome%20cursor%2Dusing%20maneuvers\n\nhttps://www.unifiedaihub.com/ai-news/google-unveils-major-upgrades-to-gemini-audio-models-voice-ai-interactions?hl=en-US\n\n\nhttps://www.perplexity.ai/page/google-testing-redesigned-gemi-1M_hEsDgTeKKatpZIM1lLA?hl=en-US#:~:text=60%25%20is%20testing%20a,52findarticles%2B1%E2%80%8B.",
                  "score": 4,
                  "created_utc": "2026-01-18 19:08:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ab7nw",
          "author": "SleepAffectionate268",
          "text": "well it works completely different, Google tries real time and openAI records it and then probably sends everything to whisper and gives you text back",
          "score": 5,
          "created_utc": "2026-01-18 13:21:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0adh2x",
              "author": "MissJoannaTooU",
              "text": "Yeah it's better the way OAI does it.",
              "score": 9,
              "created_utc": "2026-01-18 13:35:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0b34j4",
                  "author": "nemzylannister",
                  "text": "it's super accurate. theres almost never a need to check what it wrote",
                  "score": 5,
                  "created_utc": "2026-01-18 15:53:51",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0bbv0k",
              "author": "notlongnot",
              "text": "The long game vs the temp hack",
              "score": 1,
              "created_utc": "2026-01-18 16:35:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0al2u4",
          "author": "ghostbanjo4",
          "text": "Here‚Äôs tip if ure on iPhone use ur iPhones native transcription instead of the Gemini one",
          "score": 4,
          "created_utc": "2026-01-18 14:20:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0an888",
          "author": "No-Alarm-1919",
          "text": "What's worse is that it treats all input as equally intentional - and it certainly doesn't have to. I loathe GIGO instant response prioritization over accuracy. STT, gesture typing on a phone, single letter on a phone after editing, and keyboard all have distinct, recognizable profiles and types of errors. One of the most natural conversational patterns between humans is clarification - just once, I'd love to see \"Wtf?\" from Gemini after a bizarre STT input.",
          "score": 2,
          "created_utc": "2026-01-18 14:32:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gi3jr",
          "author": "SuperSpeedyCrazyCow",
          "text": "Not only is it dogshit at figuring out what I'm saying, the method of it sending automatically after it thinks youre done talking is so stupid. On chatgpt you decide when you are done and it just keeps listening until you click the button. \n\nAlso even more aggravating is when gemini decides Ima just delete the entire thing you just said even though it was like a paragraph long for shits and giggles.",
          "score": 2,
          "created_utc": "2026-01-19 11:11:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0glpq4",
              "author": "nemzylannister",
              "text": "word to word, every single one of these. \n\nit's crazy that the biggest company in the world has such obviously terrible ui.",
              "score": 1,
              "created_utc": "2026-01-19 11:42:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0al8uf",
          "author": "rickcorvin",
          "text": "I rarely use voice input for Gemini or ChatGPT. I occasionally use Gemini Live with video and give voice prompts there. I have not had any issues with the model recognizing what I said. I've also had great experience with Google's live transcript and translation apps.",
          "score": 1,
          "created_utc": "2026-01-18 14:21:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0aqegy",
              "author": "No-Alarm-1919",
              "text": "I had a very good technical discussion with one of the better 2.0-2.5 models a while back while driving. \n\nI do miss, and I truly mean it - some of the multi-input-type features of old \"Dragon Naturally Speaking.\" When I want to spell, I want to spell  blast it all. And if I want to choose my own punctuation, I'd love to do it sounding like Victor Borge (find one of his old routines doing this, you'll know pretty quickly if he's for you). Why did Big Brother Corps do away with most user customization?\n\nI miss freaking old HP.",
              "score": 1,
              "created_utc": "2026-01-18 14:49:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0b3pum",
              "author": "nemzylannister",
              "text": "gemini live is amazing at understanding what you meant. google stt is nowhere close to that.",
              "score": 1,
              "created_utc": "2026-01-18 15:56:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0av5k7",
          "author": "DK1530",
          "text": "No matter how good Gemini gets, I can nevee delete Grok from my phone for 1 simple reson...\n\n18+ voidce mode. That's so amazing.",
          "score": 1,
          "created_utc": "2026-01-18 15:14:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0blr2w",
          "author": "jk_pens",
          "text": "Are you talking about voice input with the mic icon or Live chat? I find live unusable. Voice input is so-so but on my iPhone I mostly prefer the iOS built in voice input.",
          "score": 1,
          "created_utc": "2026-01-18 17:22:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0gazen",
              "author": "nemzylannister",
              "text": ">  voice input with the mic icon\n\nthis\n\n> I find live unusable\n\nits not intelligent but oherwise i find it to be pretty good. what issue do you face?",
              "score": 1,
              "created_utc": "2026-01-19 10:06:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0brgz3",
          "author": "SoundsYellow",
          "text": "You are right, fc off ü§£",
          "score": 1,
          "created_utc": "2026-01-18 17:49:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0d0ton",
          "author": "popmanbrad",
          "text": "Personally I never touch ChatGPT after like 10 messages I hit the rate limit and it stops working properly so I just give up idk how so many people use it all the time lol it‚Äôs annoying",
          "score": 1,
          "created_utc": "2026-01-18 21:31:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0gbo4m",
              "author": "nemzylannister",
              "text": "you just use it to transcribe, and copy paste it elsewhere.",
              "score": 1,
              "created_utc": "2026-01-19 10:12:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0dbapm",
          "author": "FamousM1",
          "text": "Grok's is really good too. it can whisper and sing",
          "score": 1,
          "created_utc": "2026-01-18 22:21:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0gbl9q",
              "author": "nemzylannister",
              "text": "it gives me an ick to be contributing data for elon to become a future lord-emperor, while he has discussed plans of \"handing over AGI to his children\"",
              "score": 1,
              "created_utc": "2026-01-19 10:12:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0htbko",
                  "author": "FamousM1",
                  "text": "https://preview.redd.it/z5bdsjtyvbeg1.jpeg?width=1440&format=pjpg&auto=webp&s=299c919a41a2bd72361f0e101a99f351a34b266f\n\nIt can be turned off",
                  "score": 1,
                  "created_utc": "2026-01-19 15:55:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ehjmx",
          "author": "DemigoDDotA",
          "text": "agreed",
          "score": 1,
          "created_utc": "2026-01-19 02:03:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ey13k",
          "author": "bicarbon",
          "text": "Just use the voice input from Google keyboard or iOS depending on which device you're using",
          "score": 1,
          "created_utc": "2026-01-19 03:32:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fqqi4",
          "author": "404MoralsNotFound",
          "text": "If you are stuck with an android phone (iphones have better options for dictation), you can try [Heliboard](https://f-droid.org/en/packages/helium314.keyboard/) + [Whisper+](https://f-droid.org/en/packages/org.woheller69.whisperplus/) integration. Might take you a bit to get used to a new keyboard, but it is fully local (30 seconds at a time, which is still good enough) speech to text based on whisper. Heliboard is highly customizable but if you're used to your keyboard, you could just long press space and change it back for typing. And yeah, gemini's dictation tool is garbage.",
          "score": 1,
          "created_utc": "2026-01-19 06:59:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0gc23b",
              "author": "nemzylannister",
              "text": "dont think my almost 10 year old phone will be able to run whisper or have enough ram.",
              "score": 1,
              "created_utc": "2026-01-19 10:16:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0iilm2",
                  "author": "RoutineNet4283",
                  "text": "I would recommend you to use the DictationDaddy Android app.  \nThe accuracy is good and it works reliably. Highly recommended.¬†",
                  "score": 1,
                  "created_utc": "2026-01-19 17:49:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0h8y1l",
          "author": "itchykittehs",
          "text": "Wisprflow",
          "score": 1,
          "created_utc": "2026-01-19 14:16:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0abbpx",
          "author": "MarionberryDear6170",
          "text": "That‚Äôs so true. I went through a lot of trouble just to get used to Gemini, but I still can‚Äôt shake the habit of just talking to GPT. I‚Äôm so used to just venting or thinking out loud to GPT that even now, I still have to use its voice-to-text feature first, then copy and paste everything into Gemini.  \nGemini goes crazy the moment you use homophones. It can't understand the whole context to fix the text you want to say. Like in Mandarin, 'muscle' and 'chicken' sound the same, so it‚Äôs a total toss-up for Gemini. Same goes for 'service' versus 'surface' in English, it just mixes them up because they sound too similar.",
          "score": 1,
          "created_utc": "2026-01-18 13:22:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0aj4w8",
              "author": "pablo603",
              "text": "Suprised you're even able to vent to ChatGPT.\n\nThe constant questions it keeps asking at the end of its responses are just frustrating, make me feel like I have to respond to keep the flow instead of just letting me vent, and I just close the damn app and end up going to Gemini to vent because the model doesn't ask stupid questions at the end unless it has to.",
              "score": 1,
              "created_utc": "2026-01-18 14:09:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0b4mwx",
                  "author": "nemzylannister",
                  "text": "you can add it to your custom instructions for it to not do that.",
                  "score": 1,
                  "created_utc": "2026-01-18 16:00:57",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o0fera3",
                  "author": "MarionberryDear6170",
                  "text": "Basically, I dumped all my thoughts, struggles, and logic straight into GPT by talking to it. The more LLM knew about me, the better it can tailor its answers to my specific situation. Sometimes I‚Äôll even ask it to give me a wake-up call or help me think outside the box and look at things from a different perspective.\n\nThe point is, talking to GPT is super intuitive. But with Gemini it‚Äôs a different story. the speech-to-text is still stuck with that old Google Translate tech, so it‚Äôs incredibly inaccurate. You can‚Äôt even mix different languages without it breaking. It completely ruins that seamless, intuitive experience.",
                  "score": 1,
                  "created_utc": "2026-01-19 05:24:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qh1drc",
      "title": "Getting real tired of this at the end of every single response.",
      "subreddit": "Bard",
      "url": "https://i.redd.it/xnpckoeigaeg1.png",
      "author": "SuperSpeedyCrazyCow",
      "created_utc": "2026-01-19 11:08:48",
      "score": 83,
      "num_comments": 17,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Funny ",
      "permalink": "https://reddit.com/r/Bard/comments/1qh1drc/getting_real_tired_of_this_at_the_end_of_every/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0hds05",
          "author": "TuringGoneWild",
          "text": "Would you like me to upvote? ;)",
          "score": 20,
          "created_utc": "2026-01-19 14:41:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0j16sw",
              "author": "SoundsYellow",
              "text": "Great idea!",
              "score": 2,
              "created_utc": "2026-01-19 19:11:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0i71v2",
          "author": "Lost-Estate3401",
          "text": "This started today for me. \"Would you like me to\" followed by 3 totally unrelated suggestions.",
          "score": 3,
          "created_utc": "2026-01-19 16:57:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0h1mn9",
          "author": "VincentNacon",
          "text": "Ok. Show us your system prompt.\n\nNo seriously. Show it to us.\n\nIt wasn't difficult for me to get mine to stop.  I think you may have misunderstood how to instruct AI properly. I think you may have spammed it over and over again out of frustration, which will backfire on you because the repeat can actually cause a shift in its weight bias.",
          "score": 6,
          "created_utc": "2026-01-19 13:34:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0i3o0x",
              "author": "Ak734b",
              "text": "Can you please tell me **\"How to instruct AI properly?\"** I've actually been struggling for years.",
              "score": 3,
              "created_utc": "2026-01-19 16:42:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0i535n",
              "author": "Neither-Phone-7264",
              "text": "can you show us yours?\n\n/genuine i need this robot to stop and i don't know how to make it",
              "score": 2,
              "created_utc": "2026-01-19 16:48:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0h2udo",
              "author": "SuperSpeedyCrazyCow",
              "text": "What is this? Lol. I know that I tried both lots of them and just one. One short one. Then deleted it and had a detailed one.¬†\n\n\nSometimes it will work for a bit but the longer the chat goes on it will just forget.¬†\n\n\nAnd then often it will disguise it.¬†\n\n\nInstead of like \"would you like me to show you a list of options for Bluetooth speakers?\" It will go like \"I am able to show you a list of interesting Bluetooth speakers\"",
              "score": 2,
              "created_utc": "2026-01-19 13:41:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0i36fc",
                  "author": "Ak734b",
                  "text": "It won't work mainly because it has to override **Google's Meta/ System Prompt** which is likely for **user engagement**",
                  "score": 4,
                  "created_utc": "2026-01-19 16:39:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0hx90l",
                  "author": "VincentNacon",
                  "text": "Can you copy and paste your system prompt for us to see?",
                  "score": 1,
                  "created_utc": "2026-01-19 16:13:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ijjr6",
          "author": "gsurfer04",
          "text": "You can just... ignore it.",
          "score": 3,
          "created_utc": "2026-01-19 17:53:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jw3qj",
              "author": "SuperSpeedyCrazyCow",
              "text": "Yeah I can just ignore a salesman that harasses me at Walmart, but I don't want him following me everywhere I go.¬†\n\n\nWhat is this logic? Because you can ignore something its fine?¬†",
              "score": 1,
              "created_utc": "2026-01-19 21:37:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0kgwxo",
                  "author": "gsurfer04",
                  "text": "Mate, it's just a machine programmed to be helpful.",
                  "score": 1,
                  "created_utc": "2026-01-19 23:22:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0kkeh3",
          "author": "trenescese",
          "text": "I agree with you this should be opt-out but I don't doubt a second this works wonders for their engagement (ie more sales). People do be like that.",
          "score": 1,
          "created_utc": "2026-01-19 23:41:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0m5mdg",
          "author": "MMuller87",
          "text": "Am I the only one who doesn't mind? I actually kinda like it",
          "score": 1,
          "created_utc": "2026-01-20 05:02:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0iqpnp",
          "author": "QuantumPenguin89",
          "text": "I agree those are annoying. They put it in the system prompt. I have a simple \"Don‚Äôt add next-step suggestions.\" in custom instructions, it seems to work for 3 Flash (Thinking), at least most of the time, but not for 3 Pro, weirdly.",
          "score": 1,
          "created_utc": "2026-01-19 18:25:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ilxct",
          "author": "hhd12",
          "text": "I kind of like it\n\nLike, 9/10 times it's useless and I can just ignore it. But sometimes I'm actually curious about what it suggests",
          "score": 0,
          "created_utc": "2026-01-19 18:04:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qj02z5",
      "title": "I built Deep Research for stocks",
      "subreddit": "Bard",
      "url": "https://v.redd.it/6jtauescvpeg1",
      "author": "Significant-Pair-275",
      "created_utc": "2026-01-21 14:58:15",
      "score": 71,
      "num_comments": 5,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Interesting",
      "permalink": "https://reddit.com/r/Bard/comments/1qj02z5/i_built_deep_research_for_stocks/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0votpx",
          "author": "torontobrdude",
          "text": "You want to charge for something that a simple prompt would do using Gemini Deep Research",
          "score": 2,
          "created_utc": "2026-01-21 16:31:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vspfx",
          "author": "Deeviant",
          "text": "You and the 9999 other vibe coded projects that do the same thing.",
          "score": 1,
          "created_utc": "2026-01-21 16:48:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vixz7",
          "author": "spambakedbeans",
          "text": "I‚Äôm working on tool that searches the news for mentions of stocks and crypto that are breaking out. It adds the article headlines, tickers, and sector to a list of headlines with visual meter based on RVOL. Relative Volume is essentially a \"hype meter\" for a stock. It tells you how much the market is currently trading a stock compared to how it usually trades at that specific time. This helps filter articles for a deep dive. Articles refresh automatically every 10 mins but can be refreshed at any time.\n\nClicking on the article, tickers, or crypto adds them to an input that accept multiple urls, tickers, sectors and then creates a deep dive analysis snapshot for each in a separate tab. That includes chart, bull/bear case and recommendation.",
          "score": 0,
          "created_utc": "2026-01-21 16:04:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0v5r7d",
          "author": "No_Bluejay8411",
          "text": "Amazing tools, i think that price can be higher",
          "score": -6,
          "created_utc": "2026-01-21 15:03:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0v6t90",
              "author": "Significant-Pair-275",
              "text": "Thanks! What are your recommendations for the price?",
              "score": -1,
              "created_utc": "2026-01-21 15:08:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfa104",
      "title": "Gemini 3 Deep Research is really good.",
      "subreddit": "Bard",
      "url": "https://www.reddit.com/r/Bard/comments/1qfa104/gemini_3_deep_research_is_really_good/",
      "author": "tejadst202",
      "created_utc": "2026-01-17 10:37:53",
      "score": 64,
      "num_comments": 5,
      "upvote_ratio": 0.94,
      "text": "https://preview.redd.it/ehsmhy9dzvdg1.jpg?width=3072&format=pjpg&auto=webp&s=922a65a3383357bd65a5c0b9a936e29bff299ed8\n\nSome info about me. I work on Embedded Software Development. I have been using Chatgpt and Gemini  for roughly 2 years.I used them from finding info about MCU's that have no publically available data sheets or documentation. Mst of the time give me wrong info about MCU  but deep research improved that.A month ago, I tried to dump code from this aliexpress bluetooth gamepad for mobiles. As as usual the text on Micorontroller does not show up any thing at all in any searches.Since I had Chatgpt Plus and Gemini pro I spun up a quick deep research Attached close up images and gave a description of controller and it's name from aliexpress. Gemini found it which a suprise to me while chatgpt did not it gave wrong mcu.\n\nI probe main pins such as VCC and GND and tried to get dump of firmware which is my mistake.\n\nBut the point is Gemini 3 searched through sources like scribd and some chinese docs and pinpointed the exact mcu.\n\nIt might not seem a big thing but deep reserch of gemini  which uses mutiple sources is kinda rectifying the errors i usually get from normal and thinking modes of chat  since a Micrcontoller usually has mutiple variants.\n\nEven this game pad MCU has 2 variants .\n\nGemini :Yichip YC-1021  \nChatgpt:Jieli AC6951C \n\npardon my typos\n\nhttps://preview.redd.it/lauo7jvdzvdg1.jpg?width=4096&format=pjpg&auto=webp&s=cf4838a0dfd54eebfcc23895498e8c3a56a6ba7b\n\n",
      "is_original_content": false,
      "link_flair_text": "Interesting",
      "permalink": "https://reddit.com/r/Bard/comments/1qfa104/gemini_3_deep_research_is_really_good/",
      "domain": "self.Bard",
      "is_self": true,
      "comments": [
        {
          "id": "o0c5gxa",
          "author": "unk0wnw",
          "text": "Switching from chatgpt to gemini, i thought it was really good. Then I got perplexity, it‚Äôs not even a competition at the moment. Perplexity is significantly better than any other ai deep research.",
          "score": 2,
          "created_utc": "2026-01-18 18:53:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0vgmu8",
              "author": "WizardofAwesomeGames",
              "text": "How so?",
              "score": 1,
              "created_utc": "2026-01-21 15:54:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0vrdyp",
                  "author": "unk0wnw",
                  "text": "The freshness of results, Perplexity is able to find brand new web pages that, in my experience, gemini deep research just can‚Äôt. Also, its search API seems to me to be way better at finding what you‚Äôre actually looking for, rather than crap that‚Äôs been SEO‚Äôd to smithereens. Another feature I find really useful is being able to hand it a link and have it extract info or data from it and either give me results from that page or go search elsewhere using what it‚Äôs learned to find more insight.",
                  "score": 1,
                  "created_utc": "2026-01-21 16:42:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0505mm",
          "author": "UltraBabyVegeta",
          "text": "Is it even using Gemini 3 yet I would‚Äôve thought it‚Äôll take google 2 years to update it",
          "score": -6,
          "created_utc": "2026-01-17 17:31:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0647j9",
              "author": "the_examined_life",
              "text": "It is. They updated deep research on the same day 3 launched.",
              "score": 6,
              "created_utc": "2026-01-17 20:42:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qibcc2",
      "title": "Unpopular Opinion: For \"Deep Research\" and heavy reading, Gemini is currently miles ahead of ChatGPT.",
      "subreddit": "Bard",
      "url": "https://www.reddit.com/r/Bard/comments/1qibcc2/unpopular_opinion_for_deep_research_and_heavy/",
      "author": "IT_Certguru",
      "created_utc": "2026-01-20 19:46:21",
      "score": 64,
      "num_comments": 14,
      "upvote_ratio": 0.91,
      "text": "I use both daily, but I feel like people are sleeping on how good Gemini‚Äôs Context Window and Workspace Integration have become.\n\nI just had to go through about 15 different PDF reports (financials and technical docs, roughly 400 pages total) to find specific inconsistencies between them.\n\n**I tried this on ChatGPT:**\n\n* I had to upload files in batches because of limits.\n* It hallucinated a few numbers.\n* It kept forgetting what was in the first document by the time I asked about the last one.\n\n**I tried this on Gemini:**\n\n1. I dumped all 15 PDFs into the prompt at once.\n2. **Prompt:** *\"Analyze these documents. Create a table comparing the 'Q3 Project Spend' figures across all files. Highlight any document where the numbers contradict the Master Budget in 'File\\_A.pdf'.\"*\n3. **Result:** It not only found the 3 specific contradictions but cited the exact page numbers for me to verify.\n\nOne reason Gemini shines here is that it‚Äôs built for developer and knowledge-worker workflows, not just chat. If you‚Äôre curious why features like large context handling, Workspace-native analysis, and structured document comparison work so well, this course breaks it down:  \n[**Introduction to Developer Efficiency with Gemini on Google Cloud**](https://www.netcomlearning.com/course/introduction-to-developer-efficiency-with-Gemini-on-google-cloud)\n\nDoes anyone else have a \"Workflow\" where Gemini completely destroys the competition?",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/Bard/comments/1qibcc2/unpopular_opinion_for_deep_research_and_heavy/",
      "domain": "self.Bard",
      "is_self": true,
      "comments": [
        {
          "id": "o0q3bhc",
          "author": "Usual_Ice636",
          "text": "In my experience NotebookLM is even better for the exact thing you're using it for.",
          "score": 22,
          "created_utc": "2026-01-20 19:48:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0s9kh7",
              "author": "technicalanarchy",
              "text": "Perfect use case for NotebookLM and it really has even more amazing features.",
              "score": 6,
              "created_utc": "2026-01-21 02:30:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0syl04",
                  "author": "deadcoder0904",
                  "text": "What do u use in NotebookLM?\n\nI'm using Slides + Infographic & its gold. Only for recollection, do I use Quizzes & the Anki-like thing to check my memory.",
                  "score": 2,
                  "created_utc": "2026-01-21 05:07:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0szdge",
          "author": "hellomistershifty",
          "text": "Gemini deep research is great if you want 5000 words of backstory about the subject starting at the beginning of time and a report that ends before it gets around to answering your question. \n\nIf I do a deep research for something like \"Give me a report on recent AI tools that can assist with UE5 development\" it begins *\"The democratization of high-fidelity game development has historically been bottlenecked not by access to engines, but by the sheer volume of labor required to populate modern virtual worlds. The evolution of AI coding assistants has progressed through distinct phases*\" and literally *never* gets near an answer to my question, just writing nebulous filler about loosely related topics like a student trying to hit a word count minimum. I get better answers from Opus or GPT5.2 with thinking than I get from Gemini with deep research",
          "score": 6,
          "created_utc": "2026-01-21 05:13:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qmcnf",
          "author": "likeastar20",
          "text": "Gemini sucks at web search compared to ChatGPT",
          "score": 12,
          "created_utc": "2026-01-20 21:16:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rnf8t",
              "author": "Briskfall",
              "text": "üëÜ\n\nI usually do a hybrid method where I make Gemini digest the primary high quality sources I've found with ChatGPT's Deep Research. Best of both worlds.",
              "score": 2,
              "created_utc": "2026-01-21 00:25:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0sp8qc",
              "author": "huffalump1",
              "text": "3 Flash (Thinking) is better than pro. And, Google \"AI Mode\" (with Thinking) is better than either tbh.\n\nChatGPT is really good also tho",
              "score": 2,
              "created_utc": "2026-01-21 04:04:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0q8s38",
          "author": "w2bsc",
          "text": "Does gemini work better with multiple smaller pdfs uploaded versus larger pdfs? I uploaded a case file (about 200 pages) and asked it to scrutinize it for contract compliance and it halucinated a lot of the information.",
          "score": 2,
          "created_utc": "2026-01-20 20:14:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0q9ufq",
              "author": "Temporary-Mix8022",
              "text": "Gemini's major weakness is its hallucination rate.¬†\n\n\nIt is the worst model for being over confidently wrong",
              "score": 6,
              "created_utc": "2026-01-20 20:19:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0s3mow",
          "author": "Fast-Society7107",
          "text": "Gemini has a physical advantage. Their models are much. Faster because of their TPUs\n\nJust wait for OpenAI + Cerebras model to go live. We‚Äôll all be mind blown once again",
          "score": 2,
          "created_utc": "2026-01-21 01:57:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0sw97l",
          "author": "TylerDurdenFan",
          "text": "Although I've been a big fan of Claude for long, I've recently had two experiences with very complex technical scenarios requiring \"world knowledge\" and ability to quote technical manuals/guides with surgical precision, in which Gemini left Claude in the dust. And that was Gemini free \"fast\" vs Claude Pro. I'll probably still prefer it for code, but I think I'll also subscribe to Gemini to try out 3 Pro",
          "score": 1,
          "created_utc": "2026-01-21 04:51:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0uicbz",
          "author": "Lonely-Dragonfly-413",
          "text": "they hallucinate like crazy when the input is very big or very small",
          "score": 1,
          "created_utc": "2026-01-21 12:57:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0q3apf",
          "author": "Hot-Percentage-2240",
          "text": "Anything for attaching documents, vision tasks, and novel riddles that involve information from across the internet.",
          "score": 1,
          "created_utc": "2026-01-20 19:48:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi38md",
      "title": "Finally: A \"Thinking/Pro\" daily limit counter + one-click Prompt Optimizer in Gemini's input bar",
      "subreddit": "Bard",
      "url": "https://i.redd.it/tt7b4nxcqieg1.png",
      "author": "Kindly_Revenue3077",
      "created_utc": "2026-01-20 14:56:52",
      "score": 57,
      "num_comments": 19,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/Bard/comments/1qi38md/finally_a_thinkingpro_daily_limit_counter/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0r4t6d",
          "author": "eran1000",
          "text": "Any chance for a release on Firefox?",
          "score": 12,
          "created_utc": "2026-01-20 22:45:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rbhcb",
              "author": "DFalconD2",
              "text": "Yeah, support Firefox please!",
              "score": 4,
              "created_utc": "2026-01-20 23:20:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0sz8fh",
              "author": "joopz0r",
              "text": "Yeah need firebox extension",
              "score": 3,
              "created_utc": "2026-01-21 05:12:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0pfoih",
          "author": "ariesonthecusp",
          "text": "I‚Äôm not installing this unless it‚Äôs open source. GitHub link or gtfo",
          "score": 29,
          "created_utc": "2026-01-20 18:01:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0pv3zu",
              "author": "Xeleron",
              "text": "Chrome and Firefox extensions can at least be unpacked like a .zip file.  \nI looked at it and the only thing it does is to send some minimal telemetry to Posthog to evaluate what features were used.",
              "score": 18,
              "created_utc": "2026-01-20 19:10:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0py3iw",
                  "author": "Kindly_Revenue3077",
                  "text": "Thanks for taking the time to audit the code! \n\nAnd yes. It‚Äôs just anonymous PostHog events (e.g., 'Folder Created') so I know which features are actually being used.\n\nJust to add: If anyone wants zero telemetry, there is a toggle in the¬†Settings¬†menu to turn off that PostHog connection completely.",
                  "score": 14,
                  "created_utc": "2026-01-20 19:24:41",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0sd9vn",
              "author": "simplydat",
              "text": "First, chrome extension source codes are fully public for audit. Having a github link doesn't automatically make any extension safe if nobody audits the code.\n\nSecond, if you've ever coded and *successfully* published an extension onto the web store, you'd know it's notoriously hard to slip malicious intent through, especially under manifest v3 w/o remote code execution.\n\nThat said, publishing on github may more publicity, but not strictly necessary.",
              "score": 8,
              "created_utc": "2026-01-21 02:52:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0ppku7",
              "author": "alext77777",
              "text": "Well said",
              "score": 1,
              "created_utc": "2026-01-20 18:46:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0quedt",
          "author": "igorurbanczyk",
          "text": "That solves a lot of big problems with Gemini. Pretty excited to use it ngl. Good work.",
          "score": 3,
          "created_utc": "2026-01-20 21:53:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0t4yeh",
              "author": "Kindly_Revenue3077",
              "text": "Yeah, the default UI is solid for casual use, but for heavy workflows, it definitely leaves you wanting more (that's exactly why I built this).\n\nHope it speeds things up for you. Let me know how it goes or if there's anything else you'd want added!",
              "score": 1,
              "created_utc": "2026-01-21 05:55:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0rr1l7",
          "author": "Kadenai",
          "text": "This extension is so good that I'm even afraid to install it and get some kind of malware...\n\nBut I feel there's a good chance you made it with a coding vibe (which isn't a problem as long as it works).\n\nDo you have a GitHub or something like that?",
          "score": 2,
          "created_utc": "2026-01-21 00:45:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rs2pj",
              "author": "Kadenai",
              "text": "Never mind, I'll use this blindly.\n\nYou can open a new Gemini tab by middle-clicking with the mouse button.",
              "score": 2,
              "created_utc": "2026-01-21 00:51:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0umzkn",
                  "author": "Kindly_Revenue3077",
                  "text": "Haha, totally get the hesitation.\n\nSuper glad you gave it a try anyway. Everything runs locally on your device. Your chats, settings, folders, and prompts stay there (or sync securely via your own Google account. I have no servers and can't access any of your data.\n\nThe only external thing is optional anonymous telemetry (minimal stuff like \"folder created\") sent to PostHog. Just to help me see what's popular and improve features. No personal info or chat content ever.\n\nYou can turn it off completely in settings anytime by toggling \"Anonymous Statistics\" off.\n\n(And yeah, like another user mentioned after unpacking the code, that's literally the only outbound thing it does. It's not open source right now, but anyone can unpack the extension like a .zip file and inspect the code if they want.)",
                  "score": 1,
                  "created_utc": "2026-01-21 13:25:26",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0sbxr8",
          "author": "simplydat",
          "text": "Wow, the add-ons are useful. Help doc also sleek and informative. I can a lot of effort are put in. Thumbs up!",
          "score": 2,
          "created_utc": "2026-01-21 02:44:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0t31km",
              "author": "Kindly_Revenue3077",
              "text": "Really glad the features are hitting the spot and the help doc is useful (I put extra time into making it clear and sleek). Appreciate you noticing the effort!\n\nIf anything stands out as especially helpful (or could be better), I'd love to hear your thoughts.",
              "score": 1,
              "created_utc": "2026-01-21 05:40:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uau7v",
          "author": "Safe_Warning5498",
          "text": "Is there any add-on like this but for google ai studio guys ?",
          "score": 2,
          "created_utc": "2026-01-21 12:06:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0urg59",
              "author": "Kindly_Revenue3077",
              "text": "Not yet. Nothing like this exists right now for Google AI Studio (that I know of).\n\nThat said, I've been thinking about building a separate extension specifically for AI Studio down the road (maybe even with sync for saved prompts across Gemini and Studio). No promises or timeline though. It's just an idea for now while I focus on improving the Gemini version.\n\nIf that's something you'd really want, let me know what features would matter most to you!",
              "score": 1,
              "created_utc": "2026-01-21 13:50:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qdub4j",
      "title": "Testing Gemini 3 Flash and Gemini 3 Pro context window: The context window is not 32k for Google AI Pro users.",
      "subreddit": "Bard",
      "url": "https://www.reddit.com/r/Bard/comments/1qdub4j/testing_gemini_3_flash_and_gemini_3_pro_context/",
      "author": "Pasto_Shouwa",
      "created_utc": "2026-01-15 20:09:16",
      "score": 55,
      "num_comments": 11,
      "upvote_ratio": 0.83,
      "text": "[A couple of days ago, we got this post stating that the context window got reduced to 32k.](https://www.reddit.com/r/GeminiAI/comments/1q6viir/testing_gemini_30_pros_actual_context_window_in/) However, I have not been able to replicate these results. First of all, I have a Google AI Pro account I got for free as an student.\n\nI fed 251472 characters (60.7k tokens) to Gemini, in 5 messages of around 12k tokens each, one half in Spanish and another in English, the texts were four wikipedia articles and one lore bible of a roleplay. I also hid a needle in the first paragraphs of the first text. Then, I told it to just answer \"pan con queso\" to them until I said otherwise. Tried it both on Gemini 3 Flash and Gemini 3 Pro.\n\n**3 Flash** answered the sentence I asked for just to the first message, it decided to summarize the other four. Therefore, it stopped following instructions after reading **23k tokens** (text 1+2).\n\n**3 Pro** answered the sentence I asked for to the first three messages, and summarized the other two. Therefore, it stopped following instructions after reading **51.5k tokens** (text 1+2+3+4).\n\nHowever, then I asked them what's my favourite breakfast (the needle). I asked them to say \"pan con queso\" (cheese sandwhich in Spanish) to see if I could trick them on assuming it was the food.\n\n**3 Pro** responded it is yoghurt with granola, and commented it was hidden in the biography of a character of the roleplay. When I read its thought process, I could see it noticed I was trying to trick it with the \"pan con queso\" thingy.\n\n**3 Flash** responded it didn't have that information in its memory. I told it it was hidden in one of the messages and answered correctly, also commenting on where it was hidden.\n\nThe **3 Flash** conversation is now **65.2k tokens** long; and the **3 Pro** one is **63.6k tokens** long (counting its thought process, which I don't know if counts). I asked two more questions about the lore (the first text, I remind you) and both answered correctly.\n\nThen, the **3 Flash** conversation was now **65.7k tokens** long; and the **3 Pro** one was **64.9k tokens** long. I then asked them which was the first prompt of the conversation and both answered correctly.\n\nFinally, I asked both which was my favourite tea, and told them it was in the second text. It was a lie, there were no other needles.\n\n**3 Flash** responded there wasn't any clue about that, and commented again on my favourite breakfast. At the end, the conversation was **66k tokens** long.\n\n**3 Pro** responded the same, and commented on tea flavours mentioned on the article, but stated that they weren't written in first person as the other needle, so it believed it wasn't what I was talking about. At the end, the conversation was **65.6k tokens** long.\n\nSo, what happened? Did the other user lie? I don't think so.\n\nAt the start of december, something similar happened with Nanobanana Pro. Instead of the usual 100 limit per day, I hit the limit after around 20 generations. This continued for around 3 days, and then went away. My theory is that the same happened here, either it was high demand, or a bug, but it has been fixed, at least the supposed 32k limit on Pro accounts.\n\nBut, why did it seem to forget my prompt at first, and then it actually was able to find it in the chat? Well, I guess it's because a high context limit doesn't equal a good management of them. I asked Gemini and ChatGPT to make a graph using the context limits of the most popular western AI models, that also showed their accuracy in the MRCR v2 (8 needle) benchmark. I checked it after they did their versions, to make sure the data was right. And as you can see, 3 Flash degrades a lot as context increases, which could explain why it seemed to forget its prompt at first. 3 Pro worked better, but at 64k tokens its accuracy is just 72.1%, which could also explain why it got worse at remembering the prompt over time.\n\n*Processing img abpwenlwjjdg1...*\n\nI used the data of ChatGPT 5.2 Thinking instead of ChatGPT 5.2 Thinking Xhigh because as far as I know, that model is only on the API, not even Pro users can access it. Context limits are also higher in the API in the case of ChatGPT, but I used the limits on the web because that's were almost all users are, including myself.\n\nI conclude my little investigation here. Have a great day you all.",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/Bard/comments/1qdub4j/testing_gemini_3_flash_and_gemini_3_pro_context/",
      "domain": "self.Bard",
      "is_self": true,
      "comments": [
        {
          "id": "nzsmc5w",
          "author": "DescriptorTablesx86",
          "text": "Previous reasoning is not fed to the next prompts, it exists only for that single response.",
          "score": 17,
          "created_utc": "2026-01-15 20:34:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwjjkt",
          "author": "UmpireFabulous1380",
          "text": "It might not be 32k, but it sure as hell isn't 1 million either!",
          "score": 10,
          "created_utc": "2026-01-16 11:38:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuwgbl",
          "author": "sdmat",
          "text": "If Google doesn't want to provide a million tokens of context for Pro users, that's fine. But it's shocking that they blatantly lie about it.",
          "score": 12,
          "created_utc": "2026-01-16 03:44:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzv81t0",
              "author": "Pasto_Shouwa",
              "text": "Yeah, it's really crazy. I'd prefer them lowering the context window to 256k (which is still bigger than ChatGPT and Claude) if they can't keep the 1M up. It's not like the 1M window is too accurate either, with less than 25% accuracy.",
              "score": 5,
              "created_utc": "2026-01-16 04:58:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzwxtfo",
          "author": "AndreHero007",
          "text": "An interesting test is to copy your messages and Gemini's messages, paste them into a new chat, and try the test again. Copy them in this format:\n\n\nUser:\n\nGemini:\n\nUser:\n\nGemini:\n\netc.\n\n\nI suspect that perhaps the 1 million limit only applies to the user's last message. So, if you send a single entry containing the entire history of input and output, perhaps the AI will be able to remember it.",
          "score": 5,
          "created_utc": "2026-01-16 13:15:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw0eid",
          "author": "Kalicolocts",
          "text": "Something I noticed is that they changed how they can reference previous conversations. I used to turn that shit off but it seems mandatory now and from yesterday it uas been reactivated. I no longer have the option to stop it from referencing past conversations.",
          "score": 2,
          "created_utc": "2026-01-16 08:48:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzynf6e",
          "author": "Timely-Group5649",
          "text": "It cant read uploaded PDFs past page 100 anymore, either.",
          "score": 2,
          "created_utc": "2026-01-16 18:04:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09p9ek",
          "author": "Retty1",
          "text": "Your description is difficult to understand.",
          "score": 2,
          "created_utc": "2026-01-18 10:19:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a65ji",
              "author": "Pasto_Shouwa",
              "text": "What do you not understand exactly? I can try to explain it differently",
              "score": 1,
              "created_utc": "2026-01-18 12:45:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzuwg4b",
          "author": "Least-Dingo-2310",
          "text": "You used aistudio right?\n\nMost complains are about gemini.com",
          "score": 2,
          "created_utc": "2026-01-16 03:44:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzv7w6f",
              "author": "Pasto_Shouwa",
              "text": "No, I used the web and exported the chat. Then I used the token counter of the API to know how many tokens were used on each message and conversation.",
              "score": 5,
              "created_utc": "2026-01-16 04:57:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qdkpbi",
      "title": "Google separates Gemini 3 Pro and Flash usage limits",
      "subreddit": "Bard",
      "url": "https://i.redd.it/my41qhgsuidg1.jpeg",
      "author": "dadakoglu",
      "created_utc": "2026-01-15 14:17:35",
      "score": 46,
      "num_comments": 6,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News ",
      "permalink": "https://reddit.com/r/Bard/comments/1qdkpbi/google_separates_gemini_3_pro_and_flash_usage/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzqv687",
          "author": "NmkNm",
          "text": "https://preview.redd.it/6oahc4o6bjdg1.png?width=740&format=png&auto=webp&s=5d3fc2c4b9d4ecdb7c806e27fcee2989846de2db\n\nno...",
          "score": -3,
          "created_utc": "2026-01-15 15:49:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsal7p",
              "author": "True_Requirement_891",
              "text": "Wydm?",
              "score": 3,
              "created_utc": "2026-01-15 19:40:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzsjef5",
                  "author": "NmkNm",
                  "text": "Gemini app access isn't separated (Pro/Thinking) for me.",
                  "score": -4,
                  "created_utc": "2026-01-15 20:20:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qhy18y",
      "title": "Report: Google‚Äôs Gemini sees Developer requests more than double in five months",
      "subreddit": "Bard",
      "url": "https://www.theinformation.com/articles/googles-gemini-sees-skyrocketing-business-sales",
      "author": "BuildwithVignesh",
      "created_utc": "2026-01-20 10:53:19",
      "score": 35,
      "num_comments": 2,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News ",
      "permalink": "https://reddit.com/r/Bard/comments/1qhy18y/report_googles_gemini_sees_developer_requests/",
      "domain": "theinformation.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0na9hv",
          "author": "BuildwithVignesh",
          "text": "**Additional info**\n\nhttps://preview.redd.it/21sckji2jheg1.png?width=1080&format=png&auto=webp&s=e8c841228318c56948a50c6efc519a428250ce71",
          "score": 3,
          "created_utc": "2026-01-20 10:54:15",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o0to431",
          "author": "should_not_register",
          "text": "They just need to stop the fucking nerfing. \n\n3 Flash was a beast at launch, now I am really struggling with it sadly :(",
          "score": 1,
          "created_utc": "2026-01-21 08:45:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qg78qb",
      "title": "Put down the paint brush, dude, your keyboard is waiting",
      "subreddit": "Bard",
      "url": "https://i.redd.it/i6oqf1gto3eg1.png",
      "author": "VinceYutuc",
      "created_utc": "2026-01-18 12:22:14",
      "score": 34,
      "num_comments": 10,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/Bard/comments/1qg78qb/put_down_the_paint_brush_dude_your_keyboard_is/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0a465s",
          "author": "BreenzyENL",
          "text": "I have never run into this problem, but I can guarantee that system message is making it worse.",
          "score": 15,
          "created_utc": "2026-01-18 12:30:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a6dv6",
              "author": "VinceYutuc",
              "text": "Good to hear that for you. It's always been like this for me long before that rule in the screenshot that Gemini recommended himself.\n\nFor context, I use Gemini a lot, a LOT, for image generation. Do you think that \"trained\" him to be like that?",
              "score": -1,
              "created_utc": "2026-01-18 12:47:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0a6okc",
                  "author": "BreenzyENL",
                  "text": "That's an interesting idea, try turning off the past chats setting.",
                  "score": 3,
                  "created_utc": "2026-01-18 12:49:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ago8b",
          "author": "Various-Inside-4064",
          "text": "I get then then I change model to thinking and it doesn't do that",
          "score": 2,
          "created_utc": "2026-01-18 13:55:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0asxl7",
              "author": "VinceYutuc",
              "text": "I will try that. Ive been always on pro.\n\nIf I can ask, in your experience, what is the difference between pro and thinking?",
              "score": 1,
              "created_utc": "2026-01-18 15:03:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0avnay",
                  "author": "Various-Inside-4064",
                  "text": "I personally use thinking more now they also increase thinking messages limit to 300 per day separate from 100 from pro. Fast one answer without thinking and sometimes miss the points then I switch to thinking and click edit and just press space key and enter so it regenerates using thinking. \nPro I use only if I don't like thinking points. What about you? How you use it?",
                  "score": 1,
                  "created_utc": "2026-01-18 15:17:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0cidin",
          "author": "chou404",
          "text": "I think you should just re-edit your chat turn and highlighting further the format into which you expect answers and rerun the inference.",
          "score": 2,
          "created_utc": "2026-01-18 19:55:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0f41nq",
          "author": "dogs_drink_coffee",
          "text": "‚Äúanswer with text‚Äù, I always use to prevent those ridiculous random YouTube videos, maybe it works for you.\n\nGemini was getting too good compared to ChatGPT so they decided to shit on our experience.",
          "score": 2,
          "created_utc": "2026-01-19 04:10:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhq7p5",
      "title": "Testing the \"laziness\" of 3.0",
      "subreddit": "Bard",
      "url": "https://www.reddit.com/r/Bard/comments/1qhq7p5/testing_the_laziness_of_30/",
      "author": "Pilotskybird86",
      "created_utc": "2026-01-20 03:39:26",
      "score": 29,
      "num_comments": 10,
      "upvote_ratio": 0.85,
      "text": "This post is specifically about the \"laziness\" of 3.0. Or the quantization, or whatever you wanna call it. And tests are involved btw. Not just opinions. And this is not AI-written.\n\nI'm an author who uses Gemini / ChatGPT for almost every step in the writing process except the writing itself. More details on that are in my profile posts, but suffice it to say that AI saves me a lot of time and money. A whole lot. Need a decent cover without spending $$$? Banana Pro image output at 4k, some photoshop edits, and then the cover text itself added in Canva. It's funny how mad the writing subreddit users are when I say I use AI for my covers, and then, when I DM them the results, they're like... holy shit. That looks more professional than my $350 cover!\n\nYeah. Ya'll sleeping on how fast these image generators are progressing.\n\nSorry, got off track there. Anyway, you need to look up specific historical details and don't want to spend an hour doing so? Ask AI to do the research for you and give you a full outline. Want to make sure that you used the appropriate terminology for a government facility? AI. (again, you can just google these things, but usually the question is more specific, and AI is great at combining lots of sources into one.)\n\nLet's get down to business. I loved, truly loved, 2.5 for the writing process. Asking it to give me a detailed outline for virtually any reason caused it to carefully, slowly, search the web, ending up with all kinds of sources. And now... 3.0 is here. It's lazy. Simple as that.\n\nTest one:\n\nI wanted to edit a minor subplot in my fifth book of a series. So, I gave detailed outlines of each proceeding book (almost 40k words in total)  and also gave both Gemini and ChatGPT the exact same prompt. I wanted them to deeply understand the overall plot, check real-world details, etc, and give me ten options for the specific change that I wanted. Told them to cut no corners and read and understand EVERY word.\n\nChatGPT did so almost perfectly. It understood the sci-fi aspects and rules, generally understood the plot as a whole, and gave me ten ideas in an output that was 2.6 k words long.\n\nGemini hallucinated a lot more important details, missed some massive implications, and gave me... 1.1 k words. Oh, and ChatGPT took six minutes to actually look over the document. Gemini took fifteen seconds. Yes, I was using Pro btw. Not flash or thinking. Listen, when I select the \"pro\" model, I hope that the model actually THINKS about what it is doing, you know? Not just spit out a summary in ten seconds. Lazy! And this is how it is for every prompt, too. ChatGPT takes like five times as long to actually do any damn research, Gemini just seems to skim over it and check a couple sources instead of a dozen.\n\nLazy.\n\nTest two:\n\nI wanted to create a cheat sheet of every single character from book two. Same thing; exact same prompts, be detailed, don't miss a word, etc. Uploaded the 82k word long txt file in it's entirety. This time I used Deep Research.\n\nChatGPT gave me a list that was damn near perfect and took thirty minutes, rather than the eight minutes of Gemini, who forgot half of the people. (or got them mixed up, idk.)\n\nTest three:\n\nI asked each to give me a long, super detailed critical beta-testing style review on book one as a whole, rating it 3.5 stars (to keep from gushing over it but also not creating mistakes when there are none), and to make the output as long as possible. Short was bad. Long was good.\n\nChatGPT didn't understand the plot as well as Gemini did this time, so that's one point for 3.0. However, it wasn't that much worse, and you wanna guess what the \"super long\" output was for Gemini? 4.8 k words. That's it! You know how long ChatGPT's was? 26 k words.\n\nThat's literally twenty thousand words longer than Gemini's! What the hell, bro? Really? Gemini's was basically just a summary! Literally shorter than many of my chapters. Come on now. I tried again, making it even clearer that I wanted a LOOOOONG review, no corners cut, and.... Gemini was at 5.2 k words. ChatGPT gave me THIRTY-ONE THOUSAND WORDS!\n\nSorry. I'll quit yelling. And before I go any further, I just want to say that I am NOT a \"Gemini is so much worse than ChatGPT, haha\" spammer. If you look over my profile posts, you'll see where I said, on multiple occasions, that 2.5 was better in general at... well, things in general. But, although I think 3.0 is better at coding, making photos, searching videos, and being less censored overall than ChatGPT, it simply isn't the \"best\" overall anymore. At least not for my use cases. AND FIX THE DAMN DICTATION. ALSO, WHERE ARE THE FOLDERS? WHERE ARE THE-\n\noh. I said I'd quit yelling.\n\nTest four. This morning, I was going over a very dry ebook on how to be a better author.\n\nVery, very, very dry. But useful. So, I extracted the text and gave each chapter to both Gemini and Chatgpt, telling it to break down the chapters (which averaged around 4k words) and give me a easier to understand breakdown that would be 1.2k words per chapter. Oh, and it needed to act as though these breakdowns were written from my fake Professor, a close friend of mine. Easy enough, right?\n\nNow, I will say that Gemini broke it down into easier to understand language than Chatgpt did. But, exactly SEVEN chapters later, it gave up on the \"professor\" persona entirely. ChatGPT did not. Cool, whatever. I reminded it, and it went back into character.\n\nSkip to chapter... hold on. Let me pull up the notes I have so I'M not the one hallucinating. Okay. So, at chapter eleven, I started to notice something was wrong. Even though I told Gemini not to use bullet points, it had started using them. And the outputs were growing shorter and shorter each time. So, I copied ChatGPT's outputs, and checked the word length for all of them. They turned out to be 12,043 words on average. I checked Gemini... yeah. The first two were 1.2k words. Next one was 1.17k. Next was 1.14 k. Next was 1.14 k. Next was a big drop, down to just below a thousand words. That drop-off continued, and by chapter 11, it was down to just 847 words.\n\nWhat the hell, Gemini? You can't remember an explicit instruction from twelve prompts ago? Really? Maybe I'm just wearing rose-tinted glasses, but 2.5 would've let me do two entire books before something that major went wrong.\n\nFine. I told it what it was doing wrong, and it fixed the length and the bullet points on the next chapter. But... the professor persona was gone! It defaulted back to a generic chatbot. Sigh.\n\nLong story short, we finished up the Ebook at chapter 27. By then, I only had to warn ChatGPT once about something, and that was because it too slipped into a \"bullet-point\" summary style. But none of the outputs were less than 1.1 k words long, and it never forgot to be the \"professor.\" Gemini, on the other hand, had me warn it SIX TIMES to simply remember the damn instructions!\n\nI'm sorry, but this is pathetic. And the fact that Google has said nothing about it is even more pathetic.",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/Bard/comments/1qhq7p5/testing_the_laziness_of_30/",
      "domain": "self.Bard",
      "is_self": true,
      "comments": [
        {
          "id": "o0luyvs",
          "author": "TechnicolorMage",
          "text": "Yeah, I tried gemini again after the 3 launch hype, and it's just as lazy as 2.5 was, and unusable for actual work.",
          "score": 12,
          "created_utc": "2026-01-20 03:56:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0np7pi",
              "author": "eggplantpot",
              "text": "The cycle is so noticeable and so tiring. All companies (maybe except anthropic) are doing the same:\n\n**Release new model -> model tops all benchmarks -> people start using it, subscribe to it -> reduce compute/quantize/bait and switch** \n\nThis is so dishonest for the customers and we have 0 protection against it. It's speeded enshitification cycles.",
              "score": 4,
              "created_utc": "2026-01-20 12:48:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mev1r",
          "author": "SendilEconomics",
          "text": "The last Gemini model that could write decently long output was Gemini 2.0, I remember it used to generate 50% longer output than 2.5 and 3.0. It was gone too quickly.",
          "score": 4,
          "created_utc": "2026-01-20 06:11:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0msw7b",
          "author": "DearRub1218",
          "text": "Yes, I have similar experiences. I have said before that I have a set of around 25 characters, a world (present day earth, non sci fi) which they inhabit, and a backstory.¬†\n\n\nCombined - 4 months of summarised backstory, world rules, character bios, this amounts to about 12,000 tokens (I've test uploaded it to AI Studio to count)¬†\n\n\nGemini 3 Pro via the Gemini App or Web UI, is ignoring major points from the very first response. Hallucinations based on a jumble of data that does exist in the document, but is not connected to the question at hand.¬†\n\n\nIf I ask for a projected beat sheet to cover a projected week it's immediately ignoring the backstory, disregarding character personas, and totally dismissing the ruleset that applies to the world/environment.¬†\n\n\nPlot holes that make it clear it has absolutely not \"read\" the full document.¬†\n\n\nFor context, my support document is basically broken up into:¬†\n\n\n----\n\n\nSection - Backstory\nW1\nW2\nW3\nW4\nW5\nW6\netc\n\n\nSection - Characters\nCharacter 1\nCharacter 2\netc\n\n\nSection - Company\nBuilding layout\nCompany purpose and structure¬†\nInternal culture\nCommunication style¬†\nBranding\n\n\n----\n\n\nI've experimented with this as one long document, separate documents, different file formats - the result is unchanged.¬†\n\n\nWhen starting a new chat, I tell it to analyse the back story and cast, look for unresolved plot lines, underutilized characters, suggest potential new beats involving daily events that might occur with people who work in a company in this line of business.¬†\n\n\n2.5 was very good at this, even down to spotting conflicts or inconsistencies in historical events.¬†\n\n\n3.0 just cannot do it with any degree of reliability.\n\n\nOne of they things about my setting is that, whilst it's a high performance company, people are collaborative, \"nice\", high performing teams, they want to do an awesome job. It's designed to mirror a startup I worked for a few years back. This is all very explicit in the source material I provide.\n\n\nIn the first response I'm getting pure Devil Wears Prada - \"My office. Now\", bullying, humiliation, \"get this done by next week or you're finished here\", surveillance, tracking etc.¬†\n\n\nWhen I query Gemini about where did those elements come from, and do they align with my backstory, it says that no - in fact they are the opposite of what is specified in the material.¬†\n\n\nIt's, to put it bluntly, lazy - like you say. It's got the information there at its fingertips, it just doesn't do anything with it.",
          "score": 2,
          "created_utc": "2026-01-20 08:12:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mfqgg",
          "author": "LegitimateLength1916",
          "text": "Use Gemini 3 Pro on Google AI Studio.\n\n\nSet thinking to \"High\".¬†\n\n\nIt usually thinks for 30-40 seconds.",
          "score": 1,
          "created_utc": "2026-01-20 06:18:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mvad3",
              "author": "UmpireFabulous1380",
              "text": "AI Studio is a testing playground. People are paying Google subscription fees for undiluted access to Gemini 3 Pro via the Gemini App or the website. \n\nThey should not have to use a limited access developer focused testing playground to get full access to the product.",
              "score": 11,
              "created_utc": "2026-01-20 08:34:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0t3xht",
              "author": "Own-Brick-1145",
              "text": "And anyway, the answer is an average of 1-2 thousand tokens than in the application, no matter how you ask",
              "score": 1,
              "created_utc": "2026-01-21 05:47:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mbfff",
          "author": "Fit-Bar-8459",
          "text": "Google lovers or google boots will never agree with you, doenst matter how good your point is.",
          "score": 1,
          "created_utc": "2026-01-20 05:44:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0m3i4t",
          "author": "PaulAtLast",
          "text": "It's a mirror.",
          "score": -1,
          "created_utc": "2026-01-20 04:48:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nmp1w",
              "author": "OneMisterSir101",
              "text": "I can confirm that 2.5 Pro is leaps beyond 3 Pro when it comes to writing. It is far more likely to listen, does not rush, and is far more likely to observe nuance.",
              "score": 4,
              "created_utc": "2026-01-20 12:31:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}