{
  "metadata": {
    "last_updated": "2026-01-17 16:48:00",
    "time_filter": "week",
    "subreddit": "programming",
    "total_items": 20,
    "total_comments": 336,
    "file_size_bytes": 717504
  },
  "items": [
    {
      "id": "1qa0ujk",
      "title": "Thanks AI! - Rich Hickey, creator of Clojure, about AI",
      "subreddit": "programming",
      "url": "https://gist.github.com/richhickey/ea94e3741ff0a4e3af55b9fe6287887f",
      "author": "captvirk",
      "created_utc": "2026-01-11 14:35:41",
      "score": 808,
      "num_comments": 114,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qa0ujk/thanks_ai_rich_hickey_creator_of_clojure_about_ai/",
      "domain": "gist.github.com",
      "is_self": false,
      "comments": [
        {
          "id": "nz03o8v",
          "author": "the_halfmortal",
          "text": "His point around eliminating the path to experience really hits home for me. Entry level positions have gone through the floor and the junior engineers I do have on my team seem to have given up that spark for learning.",
          "score": 278,
          "created_utc": "2026-01-11 17:19:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz07ss5",
              "author": "PotaToss",
              "text": "Juniors using AI is the fucking worst.  It's basically a fast junior dev, and if you don't have the judgement to manage a junior dev, you have no business using it.  And them using it slows the development of their judgement, because they're not making enough of their own decisions.",
              "score": 185,
              "created_utc": "2026-01-11 17:38:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz15hsq",
                  "author": "CryptoTipToe71",
                  "text": "Totally agree, I'm an intern rn and I actively try to avoid using AI (aside from the ethical problems around it) because I know I need to learn.  The times I have used it I just feel so guilty because I know I'm robbing myself of that crucial experience",
                  "score": 56,
                  "created_utc": "2026-01-11 20:09:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz22vcs",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 20,
                  "created_utc": "2026-01-11 22:45:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz1iw26",
                  "author": "ExiledHyruleKnight",
                  "text": "> if you don't have the judgement to manage a junior dev\n\nA FUCKING MEN I keep saying this, AI is a junior dev. \n\nIt's ok if a junior uses it but they should treat it as a fellow dev and both learn from it, and correct it.  If they just accept it treating it like \"it knows more than me\" they shouldn't use it.  \n\nIf they get paired with a senior dev, and the senior dev does something they don't understand what would they do?     Would they just accept it?  Would they go behind their back and look at the code and understand what they are doing?  Would they ask the senior to explain their code?    I mean only one of those is a bad answer, and at least with a senior, they might be afraid to question it (I remember being a junior and working with the most senior guy in the company... )   But with an AI, you don't need to be afraid and you SHOULD be questioning everything. \n\nYou also should be considering how you prompt ai, are you writing a full description of the problem?  Are you missing important information that the AI is making assumptions on and so on.  These are actually tools as well because these help you write effective design docs. \n\nMy point being is if juniors are using AI, they really need to be focusing on something that helps them grow, whether it's improving architecture, or learning new coding habits, styles.  But I also agree it will slow the development of weaker programmers, because they are constantly paired with a \"better\" dev, which would stunt anyone's growth. (Imagine if your entire career you followed around the lead dev and did his grunt work with out him reviewing your code, you'd have amazing experience, but low skill development)",
                  "score": 6,
                  "created_utc": "2026-01-11 21:11:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz5oppz",
                  "author": "Aozi",
                  "text": "I wouldn't even mind them using AI, if they actually used AI to *learn* instead of build.\n\nOne of the best ways to use AI as a dev, is to use it as a rubber duck. Ask it questions, have it criticize your code, point out potential issues. Ask it about new tech, explanations about a framework you might not understand or provide some guidance on new tech.\n\nIt's great for that and I've found it to be genuinely helpful. But it still means I am the one building things, the AI simply works as a second pair of eyes over the work I'm doing.\n\nBut too often it's more like \"Hey Claude, here's the ticket that defines the things I need to do, do them for me\"",
                  "score": 2,
                  "created_utc": "2026-01-12 13:23:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz1cbno",
                  "author": "pl0nk",
                  "text": "They are building experience in a what is actually a new, different and easier to acquire skillset: software generation.\n\nThere is a vast amount of software to be (re-)generated, almost entirely rote variation on what has come before and been memorized by the AI.  It really is amazing to be able to retrieve and remix it all.\n\nBut there will continue to be “10x” engineers, i.e. people with skill, experience, and knowledge as opposed to prompt jockeys.  Some of the juniors excited by prompting will dig deeper and build those skills, but that drive will be as rare and consequently valuable as ever.",
                  "score": -14,
                  "created_utc": "2026-01-11 20:41:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz20o6f",
                  "author": "Pyryara",
                  "text": "Juniors using AI as a learning tool is actually really good. I don't need to handhold them as much as I used to.\nBut they really gotta understand the limitations and not take shortcuts with AI that they don't understand. And as a senior that's easy to notice.",
                  "score": -10,
                  "created_utc": "2026-01-11 22:35:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz12g11",
              "author": "spicybright",
              "text": "Its extra awful because junior roles have already been drying up even before AI. Its actually a problem in different industries too, but especially now with things based in text (writing, coding, record keeping, etc)\n\nIts already starting to bite companies like Boeing, who need to build a new plane platform but all the guys that know how to do it are retiring.",
              "score": 36,
              "created_utc": "2026-01-11 19:55:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz1hr6g",
              "author": "ExiledHyruleKnight",
              "text": "> Entry level positions have gone through the floor and the junior engineers I do have on my team seem to have given up that spark for learning.\n\nEntry levels will come back when people realize the problem... but juniors who don't want to learn should be bounced immediately.  \n\nYou can see AI as \"this will replace me\" or AI as \"This tool can make me more efficient make me learn something different\".  \n\nThere's this really negative discussion about Vibe coding, but the thing is to a programmer, vibe coding should feel disgusting.  \"LGTM\" is a BAD mentality, yes it does get said, yes some programmers will use that as their code review process, but a programmer who is willing to use that on their code, with out writing tests, creating it, tuning the output, investigating the edge cases, are no longer programmers. \n\nVibe coding is \"script kiddies\" and if you're old enough to know that reference, you're old enough to know script kiddies is a negative term, as is \"Vibe coder\".",
              "score": 16,
              "created_utc": "2026-01-11 21:06:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz40wfg",
                  "author": "Chii",
                  "text": "> Entry levels will come back when people realize the problem\n\nnot really, because this problem has some externalized costs that would make the company slightly less competitive in the short term if they internalized that cost. \n\naka, even if you know the lack of juniors->seniors is going to become a problem, spending resources training up new seniors from juniors in the mean time will mean those to-be-seniors can leave for a better pay elsewhere after gaining experience/training (there will always be a company that will not have had to pay for the training and so could afford spending more as salary for poaching). \n\nTherefore, the best course of action is to poach the senior off those companies \"stupid\" enough to train up a good senior. This is why back in the old days, apprenticeships have a requirement that you continue working for the master after you're fully trained for X years at Y salary (which is less than the market rate you could've gotten). But that has been seen as too restrictive, and therefore, fell out of vogue in the modern day.",
                  "score": 4,
                  "created_utc": "2026-01-12 05:04:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nza767m",
                  "author": "PLEXT0RA",
                  "text": "dont worry the term skid is alive and well in 2026",
                  "score": 1,
                  "created_utc": "2026-01-13 02:43:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz3muyf",
              "author": "Winsaucerer",
              "text": "When I first started learning rust, I gave copilot a whirl.  I switched it off shortly after because I realised I wasn’t going to learn it properly unless I went through the trenches first.",
              "score": 5,
              "created_utc": "2026-01-12 03:38:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz4vome",
                  "author": "pragmojo",
                  "text": "Might get hate for this, but this is part of the reason I usually prefer hiring degree-holding SWE's over self-taught, unless the self-taught candidate is exceptional.\n\nSay what you want about degree programs, but for the most part they will force you to go through the trenches on a lot of topics a self-taught person is likely to glaze over.",
                  "score": 0,
                  "created_utc": "2026-01-12 09:31:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz5yrf5",
              "author": "creepy_doll",
              "text": "It’s my biggest concern too. And ai usage mandates are probably going to degrade the abilities of experienced engineers too. All in a gamble to cut costs in the future. The threat of falling behind in case it does end up being able to replace most labor keeps everyone in this stupid race to the bottom",
              "score": 1,
              "created_utc": "2026-01-12 14:19:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz61nr4",
              "author": "Spasmochi",
              "text": "Exact same experience for us. I think we’re all going to pay the cost of this in the next generation of seniors and beyond.",
              "score": 1,
              "created_utc": "2026-01-12 14:34:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz0joix",
              "author": "Fatallight",
              "text": "Eh, I disagree that coding is the \"path to experience\" in software engineering. All it is is a necessary labor for us to turn software engineering practice into software but it's not even the most important part. If it was, it wouldn't be a task we'd entrust to juniors in the first place.\n\nIf AI can generate significant amounts of code quickly, all it does is lower the cost of projects. That means projects which were formerly too costly and risky for a junior to take on suddenly become a viable early career assignment. It makes juniors more useful, not less. And it puts them in a more valuable experience gaining role sooner.",
              "score": -50,
              "created_utc": "2026-01-11 18:32:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz0qze5",
                  "author": "hbgoddard",
                  "text": "> If AI can generate significant amounts of code quickly, all it does is lower the cost of projects.\n\nThis genius has never heard of \"tech debt\"",
                  "score": 39,
                  "created_utc": "2026-01-11 19:04:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz0muc4",
                  "author": "theryan722",
                  "text": "But they are not gaining experience having AI generated tons of code for them and solve things for them. If you think \"generating significant amounts of code quickly\" is a helpful bar for the rest of the team, I fear for you if you claim to be a senior.",
                  "score": 18,
                  "created_utc": "2026-01-11 18:46:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz121uc",
                  "author": "runawayasfastasucan",
                  "text": "And who is going to review and maintain all that code that the junior vibe coded?",
                  "score": 4,
                  "created_utc": "2026-01-11 19:53:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyzq8vw",
          "author": "fuck_the_mods",
          "text": "> For running the second biggest and most damaging con of this century (running hard at first)?\n\nWhat's the first? Crypto?",
          "score": 162,
          "created_utc": "2026-01-11 16:15:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz0vobh",
              "author": "Raunhofer",
              "text": "It's *funny* because you have so many options that you don't know which to choose.",
              "score": 55,
              "created_utc": "2026-01-11 19:25:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz0d2x8",
              "author": "husky_whisperer",
              "text": "I was thinking the subprime mortgage debacle that caused the crash in 2008",
              "score": 40,
              "created_utc": "2026-01-11 18:03:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz2z1au",
                  "author": "myhf",
                  "text": "i bet in 2026 we will see AI-backed mortgages",
                  "score": 9,
                  "created_utc": "2026-01-12 01:30:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyzt8ha",
              "author": "nzmjx",
              "text": "Probably. Considering power consumption of crypto.",
              "score": 61,
              "created_utc": "2026-01-11 16:29:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz0hh6d",
                  "author": "throwaway1736484",
                  "text": "Ai will beat crypto power consumption by miles. Crypto was a nuisance and a drain on existing infrastructure but ai is forcing new infra build outs. Ai has more buy in and support bc it’s pushed by existing major companies.",
                  "score": 70,
                  "created_utc": "2026-01-11 18:23:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz0b0rp",
              "author": "Lothrazar",
              "text": "NFTs?",
              "score": 10,
              "created_utc": "2026-01-11 17:53:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyzw7no",
              "author": "naequs",
              "text": "trump/maga",
              "score": 23,
              "created_utc": "2026-01-11 16:43:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz2abl7",
              "author": "wk_end",
              "text": "The Iraq War?",
              "score": 6,
              "created_utc": "2026-01-11 23:23:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz4aboh",
              "author": "peripateticman2026",
              "text": "The U.S \"government\".",
              "score": 2,
              "created_utc": "2026-01-12 06:16:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz56atp",
              "author": "feketegy",
              "text": "I was thinking the dotcom bubble",
              "score": 2,
              "created_utc": "2026-01-12 11:10:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyzdzyw",
          "author": "xFallow",
          "text": "Rich is such a king his talk on agile is one of my all time favourites ",
          "score": 89,
          "created_utc": "2026-01-11 15:15:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyzerfd",
              "author": "SpeedOfSound343",
              "text": "I liked his talks Simple Made Easy and Hammock Driven Development. Do you have the link to his talk on agile? I couldn’t find it.",
              "score": 33,
              "created_utc": "2026-01-11 15:19:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyzfspd",
                  "author": "bring_back_the_v10s",
                  "text": "His talk The Value of Values is an eye opener too.",
                  "score": 24,
                  "created_utc": "2026-01-11 15:25:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyzjqf2",
              "author": "Mysterious-Rent7233",
              "text": "I Googled and I could not find a Rich Hickey talk on Agile.",
              "score": 9,
              "created_utc": "2026-01-11 15:44:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz05o5e",
                  "author": "stickman393",
                  "text": "I found a short where he rips on \"Sprints\" for a bit, but not sure which talk it is from. the watermark said \"kapwing\"",
                  "score": 7,
                  "created_utc": "2026-01-11 17:28:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz11rf5",
                  "author": "itsgreater9000",
                  "text": "I think the closet I could find is his talk [here](https://www.youtube.com/watch?v=SxdOUGdseq4), but it's not a talk on agile, it's just some discussion that includes some digs at agile/xp/scrum ideas, not the main focus.",
                  "score": 7,
                  "created_utc": "2026-01-11 19:52:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz1eykk",
              "author": "captvirk",
              "text": "Hey can you link this agile talk? I only know the \"Simple Made Easy\", which I also adore. ",
              "score": 4,
              "created_utc": "2026-01-11 20:53:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyza662",
          "author": "sweetnsourgrapes",
          "text": "As an aside but related.. David Bowie was astoundingly prescient about what the internet would bring to society. \n\nhttps://www.youtube.com/watch?v=8tCC9yxUIdw\n\nListening to that, he perfectly describes the state of things 20 years ahead of time. It makes me wonder what he would say today about how generative Ai will change society 20 years from now.\n\nIf only he were still here to say, so we could at least be prepared.",
          "score": 92,
          "created_utc": "2026-01-11 14:55:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyzskqs",
              "author": "cinyar",
              "text": ">“Regardless of the number and power of the tools used to extract patterns from information, any sense of meaning depends on context, with interpretation coming along in support of one agenda or another. A world of informational transparency will necessarily be one of deliriously multiple viewpoints, shot through with misinformation, disinformation, conspiracy theories and a quotidian degree of madness. We may be able to see what’s going on more quickly, but that doesn’t mean we’ll agree about it any more readily.”\n\n- William Gibson, [Road to Oceania](https://www.nytimes.com/2003/06/25/opinion/the-road-to-oceania.html) (2003, unfortunately paywalled)",
              "score": 101,
              "created_utc": "2026-01-11 16:26:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz0dl8w",
                  "author": "husky_whisperer",
                  "text": "[Wall breached](https://archive.ph/K31Fc)",
                  "score": 10,
                  "created_utc": "2026-01-11 18:05:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyzbl8q",
              "author": "loiveli",
              "text": "https://youtu.be/0QAiJ5rJALE",
              "score": 7,
              "created_utc": "2026-01-11 15:03:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz6bs5f",
              "author": "CloudsOfMagellan",
              "text": "He also said the leader of World War II Germany was \"the first rockstar\", so I don't think you can take too much of what he said too seriously",
              "score": 0,
              "created_utc": "2026-01-12 15:26:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz1jmo6",
              "author": "ExiledHyruleKnight",
              "text": ">  It makes me wonder what he would say today about how generative Ai will change society 20 years from now.\n\nBut with Generative AI we can know what Bowie would say...\n\nI'll show myself out.",
              "score": -7,
              "created_utc": "2026-01-11 21:14:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyzrqn2",
          "author": "PublicFurryAccount",
          "text": ">***When did we stop considering things failures that create more problems than they solve?***\n\nAround the time Facebook redesigned to be social media rather than just MySpace without customization features.\n\nThe entire \"social media\" concept was a pretty whopping failure that also never succeeded, created loads of problems, etc. Only once it pivoted to algorithmically-curated television did it actually make much money. LLMs are the ultimate barrier destroyer, which is why they're such crap. Removing barriers to entry just makes life worse for everyone after a certain point.",
          "score": 82,
          "created_utc": "2026-01-11 16:22:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz0dban",
              "author": "Seref15",
              "text": "The business case of social media was always data collection, even in a time where there was no productive use for that quantity of data. \"Having data\" had a dollar value to investors, though for a long time that data was really only used for targeted advertising.\n\nIn some way LLMs are kind a natural consequence of the mass data collection campaigns of the 2010s.",
              "score": 27,
              "created_utc": "2026-01-11 18:04:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz61jf6",
                  "author": "Full-Spectral",
                  "text": "Well, to be fair, it was always about advertising, and it turned out that it also became possible to do very targeted advertising and charge more for that, which you can do a lot better with a lot of information, then the information started becoming a goal onto itself.",
                  "score": 2,
                  "created_utc": "2026-01-12 14:34:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz2u1t9",
              "author": "PurpleYoshiEgg",
              "text": "> The entire \"social media\" concept was a pretty whopping failure that also never succeeded...\n\nWhat's your definition of success here?  Because they've been involved in generating a ton of profit and found engagement to be the metric to maximize those profits.  So companies have been wildly successful, even though the detrimental effects make it quite a failure for those who it entraps.",
              "score": 1,
              "created_utc": "2026-01-12 01:03:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz3la70",
                  "author": "[deleted]",
                  "text": "Read after that",
                  "score": 0,
                  "created_utc": "2026-01-12 03:29:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz04ofb",
              "author": "SideQuest2026",
              "text": "Can you elaborate on how removing barriers to entry makes life worse for everyone? Wouldn't that allow for more innovation into a given domain and eventually allow for a better experience?",
              "score": -13,
              "created_utc": "2026-01-11 17:23:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz06qtx",
                  "author": "PPatBoyd",
                  "text": "The barriers to entry are on the path to experience.  Reducing barriers on the path is different from shortcutting the path entirely.",
                  "score": 21,
                  "created_utc": "2026-01-11 17:33:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz09f4p",
                  "author": "omgFWTbear",
                  "text": "If there are no logs that need stepping over, why would legs ever evolve? They’re expensive compared to ooze.",
                  "score": 8,
                  "created_utc": "2026-01-11 17:46:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz067wf",
                  "author": "PublicFurryAccount",
                  "text": "Barriers to entry select for ability and desire to overcome them.\n\nI see little reason to believe that innovation is linked to the mean motives of the population, namely being richer than their reference group and making their closest social relations like them more.",
                  "score": 24,
                  "created_utc": "2026-01-11 17:31:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz4241w",
              "author": "Chii",
              "text": "> Removing barriers to entry just makes life worse for everyone after a certain point.\n\nthe _after a certain point_ is doing a lot of work, because i say barriers to entry is never bad when removed. Of course, what i consider \"barrier to entry\" are things that make no difference to the quality of the outcome - so a doctor being certified by examination/testing and experience is _not_ a barrier to entry (but a requirement to meet minimum acceptable standard). However, the american medical association setting limits on the number of qualified seats to accept per year is a barrier to entry through and through.",
              "score": -1,
              "created_utc": "2026-01-12 05:12:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz4wncz",
                  "author": "pragmojo",
                  "text": "Certification certainly is a barrier to entry.  Barriers to entry are good when they effectively enforce a quality standard, in order to avoid harm.\n\nBarriers to entry are bad when they artificially bias the market towards incumbents for the purpose of material gain.",
                  "score": 2,
                  "created_utc": "2026-01-12 09:41:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz4wf98",
              "author": "pragmojo",
              "text": "I think LLM's are useful, they're just being inaccurately rated.\n\nImo LLM's are like the next iteration of google/stack-overflow for programming.  They help immensely for accessing information you as a programmer might need and don't have, like how to use an unfamiliar API or technology.\n\nThey also can take away some of the grunt work, like hammering out some obvious boilerplate.\n\nI think where they're being mis-rated is that they can get a non-programmer a lot farther than they ever could.  Like an absolutely non-technical person can go on Loveable and make a web app that they can actually click around and it does things.  And they get the perception from this that now they too can make software.\n\nBut we've always known that the last 20% of a software project is where 80% of the effort goes.  So far LLM's only address the first 80%, which is the easy part.",
              "score": -2,
              "created_utc": "2026-01-12 09:38:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz0dc4n",
          "author": "Maki_the_Nacho_Man",
          "text": "So true. The world lost a lot of his charm on the last years, but now we should get used to that.",
          "score": 11,
          "created_utc": "2026-01-11 18:04:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4suqv",
              "author": "mrmckeb",
              "text": "Or find ways to bring back the charm, even if just in your free time.",
              "score": 6,
              "created_utc": "2026-01-12 09:03:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz1dccn",
          "author": "philanthro-pissed",
          "text": "I've gotta say, it's pretty nice having big names like Rob Pike and Rich Hickey lending their voices to the pushback",
          "score": 21,
          "created_utc": "2026-01-11 20:46:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz04gv4",
          "author": "stickman393",
          "text": "Hmm. Just like AI, I am going to steal this and use it in my own response to people. \nThank you Rich Hickey for a concise list of all the things we've known for the last couple years.",
          "score": 12,
          "created_utc": "2026-01-11 17:22:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz02wjh",
          "author": "CornedBee",
          "text": "> When did we stop considering things failures that create more problems than they solve?\n\nDid we ever do that? Especially when somebody stands to gain/not lose a lot of money as longs as the thing isn't considered a failure...",
          "score": 10,
          "created_utc": "2026-01-11 17:15:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyznlh6",
          "author": "Tack1234",
          "text": "based",
          "score": 11,
          "created_utc": "2026-01-11 16:02:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0xex7",
          "author": "levodelellis",
          "text": "> For replacing search results with summary BS?\n\nTo be fair, the search results were already BS to begin with",
          "score": 9,
          "created_utc": "2026-01-11 19:32:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyzk09b",
          "author": "phil_davis",
          "text": "Couldn't have said it better myself.",
          "score": 9,
          "created_utc": "2026-01-11 15:45:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz60ze5",
          "author": "Full-Spectral",
          "text": "The destructive potential of AI was prototyped a couple decades ago, in the music world, with the same results. Up until the 2000s, if you wanted to put out music that sounded pretty professional (well, other than in pure electronic music which had been fairly practical at home for a while by then), you had to either have talented people help you, or put in a lot of time becoming a good musician so you could get good performances, and also a good engineer capture those performances well, a good mixer, etc...\n\nAnd there had been a real emphasis on and appreciation of musicianship, at least within the community of music creation, even if not so much in the consumer camp.\n\nThen extremely powerful digital audio manipulation tools became widely available, and suddenly it was not about skill anymore, it was about posting songs. It was about 'performances' being nothing but raw materials for someone to sit at the computer (often for far longer than they spent actually creating the material) editing the content, so that they could post it. It created a huge wall of white noise and undermined the value of skill to a huge degree, because it was no longer a discriminator to at least create what sounded like professional content to the average listener.\n\nNow it's happening to software, and it'll happen to movies and art, and of course music will now get Part II, the Revenge as well. All of those people who didn't have the skill to actually create something themselves will no longer be held back by little things like skill.\n\nObviously it wasn't as dangerous in the music world, but it will be in the software world, and for the same reason, which is that the consumers don't understand how the sausage is made, they just see sausage on the shelf. The value of skill in music was highly devalued because consumers couldn't tell the difference, and the same will happen in software, just with far worse consequences.\n\nAnd, as happened in music at that time, the emphasis will become more about becoming proficient in the use of the tools of manipulation, not the tools of creation. Interestingly, music became more of a part of the IT world, while now a lot software will become less a part of it. So the two I guess will meet in the middle in a big pool of mediocrity, along with movies, photography, etc...",
          "score": 2,
          "created_utc": "2026-01-12 14:31:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyzns9l",
          "author": "Nissepelle",
          "text": "Very nicely put",
          "score": 4,
          "created_utc": "2026-01-11 16:03:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4kbpc",
          "author": "Difficult_Scratch446",
          "text": "This resonates deeply, especially the point about eliminating entry-level positions. We're creating a paradox where AI is trained on human expertise, but we're simultaneously removing the pathways for humans to gain that expertise in the first place.\n\nThe irony of receiving AI-generated fan mail is particularly sharp - it perfectly illustrates the \"emotion unfelt\" problem. When everything becomes optimized for output rather than genuine human connection, we lose something fundamental.\n\nThanks for articulating what many of us in the developer community have been feeling but struggling to express clearly.",
          "score": 1,
          "created_utc": "2026-01-12 07:43:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4vj41",
          "author": "osirisguitar",
          "text": "Zero click search results will just choke the creation of new information. What are they going to train on when noone will post blogs or tutorials anymore?",
          "score": 1,
          "created_utc": "2026-01-12 09:30:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3fp1p",
          "author": "Lowetheiy",
          "text": "Why does he care about a troll sending him a piece of AI generated nonsense? Are we living in Cyberpunk 2077 now?",
          "score": -2,
          "created_utc": "2026-01-12 02:59:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyzvhvb",
          "author": "Absolute_Enema",
          "text": "Least based Rich Hickey opinion.",
          "score": -31,
          "created_utc": "2026-01-11 16:40:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz1kwwe",
              "author": "Natural_Builder_3170",
              "text": "If I understand this correctly, its supposed to be a compliment yh? like all his opinions are so very based. I'm not sure tho",
              "score": 8,
              "created_utc": "2026-01-11 21:20:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz23ahg",
                  "author": "pojska",
                  "text": "Yeah, I think you're correct.",
                  "score": 3,
                  "created_utc": "2026-01-11 22:48:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz4ag8k",
                  "author": "Absolute_Enema",
                  "text": "Correct.",
                  "score": 1,
                  "created_utc": "2026-01-12 06:17:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz72ru3",
          "author": "databeestje",
          "text": "This kind of take lacking in nuance is hard to take seriously and easy to dismiss. Are there real, serious problems with AI? Sure. But can we not pretend that it's not incredibly useful as well in our line of work? Both can be true, you don't have to lie about it. It somehow simultaneously only generates BS bad quality code while also apparently being good enough to actually eliminate entry level jobs. Which is it? It feels like the opinion of someone who barely writes code anymore and gave GPT 3.5 a surface level try 3 years ago and never updated his view since then. To be fair, it's really only been a couple of weeks (with Opus 4.5) that I would much rather have Opus than a junior engineer (or even most seniors to be honest) to collaborate with on code. This time last year I was still building my own tools to feed the right kind of context to GPT 4o to try and get decent results on a large existing code base, but at this point you can just point Opus in the right direction and tell it to get to work. Code review with Claude and Codex is finding pretty complicated interconnected concurrency issues for me.",
          "score": -3,
          "created_utc": "2026-01-12 17:30:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7gaxt",
              "author": "Full-Spectral",
              "text": "Well, the point is that it's eliminating entry level jobs because the people who are in a position to do that (management) don't understand that it's not actually good enough to do that, and also that  even if it was, it would be a very bad idea.",
              "score": 4,
              "created_utc": "2026-01-12 18:31:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz99uym",
                  "author": "databeestje",
                  "text": "I'm not management and AI tools are absolutely good enough to completely wipe the floor with junior developers. It's honestly not even close. Whether it's a good idea on a societal level to eliminate new positions is a different discussion, but not something I'm very worried about, we're going to simply need fewer programmers. I'm not necessarily *happy* about it, I like writing code and there is less and less reason to.",
                  "score": -2,
                  "created_utc": "2026-01-12 23:43:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz9n6pu",
              "author": "NuclearVII",
              "text": "> But can we not pretend that it's not incredibly useful as well in our line of work\n\n\"Hey guys, plagiarism is really useful. I don't understand why you hate plagiarism. I really love the automated plagiarism machine, it makes the plagiarism much easier.\"\n\nThis \"tool\" that you find so useful (with basically 0 credible statistical evidence) cannot exist without *unprecedented* amounts of theft. LLMs will never pay for their cost - not their on paper cost, and certainly not the externalities they cause.",
              "score": 7,
              "created_utc": "2026-01-13 00:55:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzcq8x1",
                  "author": "databeestje",
                  "text": "I define plagiarism as the act of taking someone else's work and passing it off as your own. I assume you're not referring to me passing off Claude's work as my own, but to Claude being trained on other people's code. How is that plagiarism or theft? You can't 'steal' intellectual property like this, you can only violate a copyright, and while I'm sure Claude can output certain overly represented pieces of code verbatim (violating a copyright) due to overtraining, it's incidental at best (never seen it) and clearly also not the goal or intention of Anthropic as storing and retrieving code snippets verbatim would be an \\*incredibly\\* inefficient way to distribute code. While I would agree it would be a plagiarism machine if Anthropic simply offered a query engine for a database that consists entirely of scraped code, that's clearly not what Claude is. There's also only so many ways to write a for-loop. If I ask Claude to write a Fibonacci function, is it stealing someone's code? \n\nYou pretend like being able to distribute copies of Quake 3's fast inverse square root function is somehow Anthropic's goal, it's clearly not. I'm sure you'll latch onto incidental cases of copyright violation by Claude and declare it a mortal sin but nobody who uses Claude values its ability to regurgitate code verbatim and only its ability to apply its learned patterns in a generalized way. \n\nIf you are still beating on the dead horse of training an LLM on open source code, let me be clear about that: 'looking' at open source code (be it GPL, MIT, etc) is never a copyright violation, only distribution can be. And looking is exactly what training does, although at a scale that we have no human equivalent for so suddenly we dub it 'theft' because it scares us. \n\nAs for 'statistical evidence' that Claude Code is useful to me: barely anything in software engineering has a solid statistical foundation, it's more art than science. But it's so goddamn obvious, like how writing tests improves code quality. And again, which is it: either it's useful and displacing junior level positions or it's not useful and how is it then replacing those positions?",
                  "score": -1,
                  "created_utc": "2026-01-13 14:02:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz8c2nq",
              "author": "drewcape",
              "text": "This is exactly what I see. Coding tools now provide help of very high quality. I don't know about agents (they may be hard to control), but as auxiliary tooling they are fantastic.",
              "score": 1,
              "created_utc": "2026-01-12 20:58:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qdo9r3",
      "title": "Cursor CEO Built a Browser using AI, but Does It Really Work?",
      "subreddit": "programming",
      "url": "https://www.finalroundai.com/blog/cursor-ceo-browser-made-using-ai",
      "author": "ImpressiveContest283",
      "created_utc": "2026-01-15 16:32:27",
      "score": 645,
      "num_comments": 378,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qdo9r3/cursor_ceo_built_a_browser_using_ai_but_does_it/",
      "domain": "finalroundai.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzr79fh",
          "author": "suckfail",
          "text": "It's in Rust and uses a lot of OSS packages to do CSS parsing etc.\n\nSo I wonder what the 3 million lines of code actually do.",
          "score": 817,
          "created_utc": "2026-01-15 16:43:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzr7iyw",
              "author": "grumpy_autist",
              "text": "unit tests /s",
              "score": 383,
              "created_utc": "2026-01-15 16:44:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzr93i1",
                  "author": "blazarious",
                  "text": "Not the worst idea",
                  "score": 153,
                  "created_utc": "2026-01-15 16:51:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzt8mkk",
                  "author": "catfrogbigdog",
                  "text": "AI unit tests are the most mock heavy tests I’ve ever seen!\n\nWhen you prompt it “go until you hit 80% coverage but don’t change the app code” it’ll bend over backwards to get those lines covered.\n\nThen you go back to the tests later and realize “oh, it’s verifying buggy behavior” or “oh, it just mocked around that runtime error” lol",
                  "score": 15,
                  "created_utc": "2026-01-15 22:18:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzs7dq4",
                  "author": "Actual__Wizard",
                  "text": "No joke man. Every time I see a crappy project on github that doesn't really do anything useful, I always check to make sure their unit testing framework is in place and that's when \"I know what's going on.\" \n\n\"Ohhh, I see, so it *works*, but it doesn't really do anything useful. Okay...\"",
                  "score": 6,
                  "created_utc": "2026-01-15 19:25:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrdf38",
              "author": "lilB0bbyTables",
              "text": "They’re all different iterations of lingering markdown code that cursor generated to recap and “document” the stuff it did for offloading context to flat files.",
              "score": 105,
              "created_utc": "2026-01-15 17:11:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzre6zg",
                  "author": "Sparaucchio",
                  "text": "A colleague of mine mistakenly opened a PR that contained 30k lines of random AI-generated markdown files",
                  "score": 57,
                  "created_utc": "2026-01-15 17:14:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzydzsx",
                  "author": "Garland_Key",
                  "text": "You can tell Claude to not do that, and instead to keep it in its context file, which should be in .gitignore so that this never happens.",
                  "score": 1,
                  "created_utc": "2026-01-16 17:22:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzr8exi",
              "author": "MilkEnvironmental106",
              "text": "It's just 30k lines of rust, but all the types are fully qualified.",
              "score": 109,
              "created_utc": "2026-01-15 16:48:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzr9yzq",
                  "author": "RustOnTheEdge",
                  "text": "“Hey wait a minute, two types in one module? Not on my watch you don’t!!”",
                  "score": 26,
                  "created_utc": "2026-01-15 16:55:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzt4f88",
                  "author": "twigboy",
                  "text": "And it used a swimming pools worth of water to generate",
                  "score": 10,
                  "created_utc": "2026-01-15 21:57:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0028tw",
                  "author": "Jan-Snow",
                  "text": "Sorry but what does fully qualified mean in this context?",
                  "score": 1,
                  "created_utc": "2026-01-16 21:58:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrx5ft",
              "author": "franklindstallone",
              "text": "It's someone in software that wants to be rewarded for doing something useless.\n\nIf it generated 3 million lines of code that's a giant codebase that no one will understand because no one wrote it and even then it's only created a basic product of no value which by their own words \"kind of works\".\n\nHow long for someone to sit there and understand and review the code base so they can add to it and to ensure it's actually safe and secure?",
              "score": 23,
              "created_utc": "2026-01-15 18:39:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzsgnz4",
                  "author": "omac4552",
                  "text": "It won't happen because you will run out of money and developers before this is understood and you can make it work, it's easier to start over",
                  "score": 14,
                  "created_utc": "2026-01-15 20:08:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzso07l",
                  "author": "Antique-Special8025",
                  "text": "> How long for someone to sit there and understand and review the code base so they can add to it and to ensure it's actually safe and secure?\n\nLonger then itll take someone to figure out (what is likely one of many) security holes to exploit for something nefarious. :p",
                  "score": 6,
                  "created_utc": "2026-01-15 20:42:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzuizpa",
                  "author": "vytah",
                  "text": "Obligatory: https://web.archive.org/web/20031207022832/http://hackles.org/cgi-bin/archives.pl?request=334",
                  "score": 3,
                  "created_utc": "2026-01-16 02:28:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzvsumm",
                  "author": "CornedBee",
                  "text": "The file containing the main function is 33k lines long. The main function is a thin wrapper around a run function, which is ~4k lines long by itself.\n\nSo my estimate for \"how long\" is \"infinite\". I would consider it impossible to understand the code base sufficiently to make changes, and definitely to ensure it's secure.",
                  "score": 2,
                  "created_utc": "2026-01-16 07:40:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzwl1jy",
                  "author": "5977c8e",
                  "text": "\\> \"kind of works\" \n\nShould be the slogan of any complex use of AI.   \nWith enough of it, people might actually start appreciating \"fully works\".",
                  "score": 1,
                  "created_utc": "2026-01-16 11:49:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzudmud",
                  "author": "voidstarcpp",
                  "text": ">If it generated 3 million lines of code that's a giant codebase that no one will understand\n\nMost browsers are tens of millions of lines so it's not inappropriate in scale. If you think nobody can understand that then you're both kind of right (no individual fully understands all of a codebase of that size) but you're also kind of saying complex software is impossible. But obviously browsers and operating systems exist and are simply that large.",
                  "score": -2,
                  "created_utc": "2026-01-16 01:58:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzt9vta",
              "author": "levodelellis",
              "text": "Does the 3M include all those packages? Bc that's what I really would like to know",
              "score": 5,
              "created_utc": "2026-01-15 22:24:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzv6nut",
              "author": "Timetraveller4k",
              "text": "Either he counted the oss code too or he vibed in all sorts of garbage",
              "score": 3,
              "created_utc": "2026-01-16 04:48:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzs7kmb",
              "author": "okawei",
              "text": "I'm sure they're counting dependencies in that.  It's not 3M of novel lines of code",
              "score": 2,
              "created_utc": "2026-01-15 19:26:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzsbo79",
                  "author": "suckfail",
                  "text": "I actually think it is 3M novel lines. I think it's 6-9M including dependencies.",
                  "score": 10,
                  "created_utc": "2026-01-15 19:45:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztul18",
              "author": "winky9827",
              "text": "Introduce security flaws, duh.",
              "score": 1,
              "created_utc": "2026-01-16 00:12:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzr8uqw",
          "author": "Shadowsake",
          "text": "Took a look at its github page. There is not a single CI succesfully run. The future of engineering, folks!",
          "score": 595,
          "created_utc": "2026-01-15 16:50:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzr9zjj",
              "author": "arwinda",
              "text": "Just ask Copilot to fix the remaining bugs /s",
              "score": 170,
              "created_utc": "2026-01-15 16:55:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrct53",
                  "author": "damesca",
                  "text": "Copilot's idea of fixing bugs is commenting out the tests.",
                  "score": 81,
                  "created_utc": "2026-01-15 17:08:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzuouee",
                  "author": "dalepo",
                  "text": "You are absolutely right!",
                  "score": 4,
                  "created_utc": "2026-01-16 03:00:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzs7zw2",
                  "author": "Shadowsake",
                  "text": "AI-Agent Based Programming™",
                  "score": 2,
                  "created_utc": "2026-01-15 19:28:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzuzpmy",
                  "author": "voidstarcpp",
                  "text": "For whats it's worth I cloned the repo and asked Claude Code to get it working. It succeeded after about a half hour and was able to run the renderer in headless mode and produce a correct screenshot of my blog.",
                  "score": 1,
                  "created_utc": "2026-01-16 04:04:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzs4ycw",
              "author": "GlobalIncident",
              "text": "Yeah, it's not even that the code has bugs in it, it's that it can't even compile in its current form.",
              "score": 68,
              "created_utc": "2026-01-15 19:14:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzs8ctj",
                  "author": "Shadowsake",
                  "text": "\"Kinda works\" he said. Well, we are officially on the path of a thousand monkeys with typewriters eventually rewrite Chrome in Rust.",
                  "score": 48,
                  "created_utc": "2026-01-15 19:29:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzsrv97",
              "author": "AlSweigart",
              "text": "I cloned the repo and tried to compile it: I only got compiler warnings and errors.\n\nThere are no git tags to find a working release.",
              "score": 31,
              "created_utc": "2026-01-15 21:00:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzuhy9h",
                  "author": "Jwosty",
                  "text": "He must have forgotten to ask ChatGPT to make git tags along the way",
                  "score": 8,
                  "created_utc": "2026-01-16 02:22:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzthxie",
              "author": "TwoPhotons",
              "text": "I saw all those red Xs and literally laughed out loud. Over 2000 pages of them!",
              "score": 14,
              "created_utc": "2026-01-15 23:04:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzsugsm",
              "author": "neuronexmachina",
              "text": "From skimming the docs, I think tests were primarily run locally by the agent rather than using GitHub Actions.",
              "score": 12,
              "created_utc": "2026-01-15 21:12:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzui8pu",
                  "author": "Jwosty",
                  "text": "Prediction: eventually we will reach the point where people are just writing unit tests in natural language and asking the LLM to tell them the results.",
                  "score": 8,
                  "created_utc": "2026-01-16 02:24:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrcwwr",
              "author": "Goducks91",
              "text": "Can you link the GitHub page?",
              "score": 20,
              "created_utc": "2026-01-15 17:09:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrdhr9",
                  "author": "thuiop1",
                  "text": "https://github.com/wilsonzlin/fastrender",
                  "score": 34,
                  "created_utc": "2026-01-15 17:11:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzuzu0f",
              "author": "voidstarcpp",
              "text": "For whats it's worth I cloned the repo and asked Claude Code to get it working. It succeeded after about a half hour and was able to run the renderer in headless mode and produce a correct screenshot of my blog.",
              "score": 12,
              "created_utc": "2026-01-16 04:04:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzwwlpz",
              "author": "Relative-Scholar-147",
              "text": "Is because are using the wrong model, prompt or socks.",
              "score": 2,
              "created_utc": "2026-01-16 13:07:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzy7qwy",
                  "author": "Shadowsake",
                  "text": "Shit...you are right. I forgot to wear my programming socks.\n\nHERE WE GO, LET'S PROMPT IT ON!!!",
                  "score": 2,
                  "created_utc": "2026-01-16 16:55:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzsuepx",
              "author": "elperroborrachotoo",
              "text": "Why do you call that the future? That sounds like my present!",
              "score": 2,
              "created_utc": "2026-01-15 21:12:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzu1nnc",
              "author": "SpaceShrimp",
              "text": "The program becomes a pile of intermittent bugs and intermittent functionality.\n\nMaybe one could make a system fault tolerant enough that you could make it from only intermittent functionality?",
              "score": 1,
              "created_utc": "2026-01-16 00:51:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzv5lnz",
              "author": "beall49",
              "text": "What’s your title?\n\nMe: Code Janitor 3",
              "score": 1,
              "created_utc": "2026-01-16 04:41:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o03sthm",
              "author": "Glum-Psychology-6701",
              "text": "Many Handwritten repos are also the same. Actually this is the future, whether you like it or not ",
              "score": 0,
              "created_utc": "2026-01-17 13:57:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nztqcfk",
              "author": "bzbub2",
              "text": "and my firefox still does not pass the acid test, might not be such a damning thing. would you rather it skip tests? [http://acid3.acidtests.org/](http://acid3.acidtests.org/)",
              "score": -9,
              "created_utc": "2026-01-15 23:49:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzts4ms",
                  "author": "terablast",
                  "text": "why are you even comparing a web standards test to a project not be able to build..?",
                  "score": 9,
                  "created_utc": "2026-01-15 23:59:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzr7e2i",
          "author": "East-Law-2877",
          "text": "looking at the dependencies: is this 3 million lines of glue code for servo and quickjs? wtf",
          "score": 423,
          "created_utc": "2026-01-15 16:44:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzr7qp2",
              "author": "my_new_accoun1",
              "text": "Must be 3 million lines of AGENTS.md 😂",
              "score": 180,
              "created_utc": "2026-01-15 16:45:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzrkn7s",
              "author": "Proper-Ape",
              "text": "It's not glue code if it doesn't hold the project together.",
              "score": 71,
              "created_utc": "2026-01-15 17:44:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzusl69",
                  "author": "mcknuckle",
                  "text": "The glue code holds itself together",
                  "score": 6,
                  "created_utc": "2026-01-16 03:21:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztfu6c",
              "author": "TryingT0Wr1t3",
              "text": "Thinking quickly, CEO constructs a Browser, using only AI, a squirrel, and a Browser.",
              "score": 42,
              "created_utc": "2026-01-15 22:53:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztu1ub",
                  "author": "UszeTaham",
                  "text": "Love this reference",
                  "score": 6,
                  "created_utc": "2026-01-16 00:09:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztwgro",
              "author": "Western_Objective209",
              "text": "it's legitimately using servo? So the article is just lying?",
              "score": 17,
              "created_utc": "2026-01-16 00:22:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzu2jh0",
                  "author": "East-Law-2877",
                  "text": "yes. it uses parts from servo for css and html parsing. they also depend on resvg, taffy (flexbox), and tiny-skia for rendering",
                  "score": 18,
                  "created_utc": "2026-01-16 00:55:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o03b1q4",
                  "author": "jl2352",
                  "text": "It really depends on the definition of \\*'building a new browser'\\*. If we are talking about a different browser experience, like Arc or Brave, then reusing things is a good approach.\n\nIf we are talking about a brand new browser from scratch, then obviously it's just wrong at that point.\n\nThere is also a middle ground of leveraging existing libraries for some parts.",
                  "score": 1,
                  "created_utc": "2026-01-17 11:54:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzr9n44",
              "author": "logosobscura",
              "text": "Rookie numbers- what you really need is to secretly spin up a Linux VM that then execute code like a RAT. Then Wall St will proclaim that you’ve solved software and start shorting software vendors while you breach the Developer Program terms on the platform.",
              "score": 25,
              "created_utc": "2026-01-15 16:54:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzvxa4s",
              "author": "ithkuil",
              "text": "That number must include the dependencies then.",
              "score": 1,
              "created_utc": "2026-01-16 08:19:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzudytm",
              "author": "voidstarcpp",
              "text": "QuickJS is used as a reference and test against their own JS engine. If you are unsure you can clone the repo and have Claude Code explain the structure in a minute or two before posting an uninformed comment that gets upvoted to the top of the page. The dependencies are also included in the \"three million\" figure along with a bunch of test inputs.",
              "score": -8,
              "created_utc": "2026-01-16 02:00:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzv2okk",
                  "author": "Maybe-monad",
                  "text": "Claude's hallucinations are worse than supposedly uninformed comments",
                  "score": 6,
                  "created_utc": "2026-01-16 04:22:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzr7ie3",
          "author": "BladeBreak3R",
          "text": "“The real work begins when they need to remove the “kind of”. They might have stopped the “experiment” after one week because continuing further simply wasn’t worth the cost.”\n\nOh, you don’t say.\nYou got something that “kind of worked” and then decided nobody wanted to dig through the slop to implement the rest eh?\nColour me shocked.",
          "score": 855,
          "created_utc": "2026-01-15 16:44:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrely2",
              "author": "Kusibu",
              "text": "\"AI made me an amazing blueprint, we just need an architect to add the dimensions\" - someone about to make an architect's job harder than it was without the \"help\"",
              "score": 305,
              "created_utc": "2026-01-15 17:16:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzs2vma",
                  "author": "ItsSadTimes",
                  "text": "All because an AI gave you a blueprint you think is good, doesnt mean its actually good. I had a junior dev give me this super long PR to review made with AI. It had so much extra shit to solve what I thought was gonna be a simple problem. Syntactically it looked good and the solution technically worked so by those standards its a Grade A solution. But I dug a bit deeper and learned that the problem I asked them to fix could also be fixed with a tiny change to our packages config file. Took me 10 minutes to find it, implement it, and test it.\n\nAI doesnt make bad devs better, it makes bad devs faster. And sometimes faster is worse. They dont do the investigation step and thus miss out on easy fixes.",
                  "score": 120,
                  "created_utc": "2026-01-15 19:04:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzrxi2y",
                  "author": "ThreeLeggedChimp",
                  "text": "Perfect analogy.",
                  "score": 10,
                  "created_utc": "2026-01-15 18:41:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzs17kt",
                  "author": "Direct-Salt-9577",
                  "text": "Being useful versus feeling useful lol",
                  "score": 5,
                  "created_utc": "2026-01-15 18:57:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzryw0t",
              "author": "exscape",
              "text": "> One developer on HackerNews even said trying to locate core components like the JavaScript engine or DOM implementation in the generated code is difficult. \n\nThat's pretty hilarious TBH.",
              "score": 33,
              "created_utc": "2026-01-15 18:47:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzuigho",
                  "author": "Jwosty",
                  "text": "Maybe we're just using it wrong, and LLMs turn out to be the best code obfuscation tool",
                  "score": 6,
                  "created_utc": "2026-01-16 02:25:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzslp0i",
              "author": "i_wear_green_pants",
              "text": "The major problem with AI is that it kind of works. But in many cases it's easier and not mentally exhausting to just make it yourself instead of removing that \"kind of\"\n\nI just hate it when managers are so excited because they can do something that kind of works with very little technical experience. Then they think it super easy to make professional devs just fix the rest.",
              "score": 18,
              "created_utc": "2026-01-15 20:31:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzt5rqs",
                  "author": "usrnmz",
                  "text": "Man.. exactly this.",
                  "score": 5,
                  "created_utc": "2026-01-15 22:04:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzthugn",
                  "author": "Deranged40",
                  "text": "Imagine my manager's face when he asks me if that feature with a deadline of tomorrow works and I look him dead in the eye and say \"yeah, kinda\".",
                  "score": 3,
                  "created_utc": "2026-01-15 23:04:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzu2ooy",
              "author": "ModernRonin",
              "text": "\"Those who do not comprehend Kernighan's Law, are damned to spend eternity single-stepping in the debugger.\" -Me, here, 2026\n\nhttps://www.laws-of-software.com/laws/kernighan/",
              "score": 6,
              "created_utc": "2026-01-16 00:56:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzstpv9",
              "author": "paeschli",
              "text": "'It kind of works' is the official AI slogan",
              "score": 7,
              "created_utc": "2026-01-15 21:08:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzreo5c",
              "author": "AgustinCB",
              "text": "You had a chance to say “cursor me shocked.” These opportunities don’t present themselves twice.\n\nAn AI wouldn’t make that mistake. That is all I am saying.",
              "score": 27,
              "created_utc": "2026-01-15 17:17:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrf6x8",
                  "author": "Mental_Estate4206",
                  "text": "Cursor me rm -rf",
                  "score": 16,
                  "created_utc": "2026-01-15 17:19:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzshpec",
                  "author": "BladeBreak3R",
                  "text": "You know what? You’re right, damn that’s good",
                  "score": 1,
                  "created_utc": "2026-01-15 20:12:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrvi8d",
              "author": "Maybe-monad",
              "text": "Debugging human generated slop is a pita (vscode), AI slop must be at least an order of magnitude worse.",
              "score": 6,
              "created_utc": "2026-01-15 18:32:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzu0t5v",
                  "author": "SpaceShrimp",
                  "text": "Fixing things gets worse the larger the codebase becomes, and fixing one bug is harder when there are many more bugs.\n\nIf the project is big enough and/or buggy enough, it will be cheaper to start from scratch.",
                  "score": 3,
                  "created_utc": "2026-01-16 00:46:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrq4hn",
              "author": "vaporeng",
              "text": "And they probably burned enough energy to power a city for a year",
              "score": 2,
              "created_utc": "2026-01-15 18:08:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzv0t2r",
              "author": "Hand_Sanitizer3000",
              "text": "I just used copilot to slap some last minute requirements on a project for a demo. Idk how anyone who is a professional in this field can look at the output of some od these llms and think “yea this is good”",
              "score": 1,
              "created_utc": "2026-01-16 04:10:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzvcpbc",
              "author": "AlSweigart",
              "text": "\"It's 99% done. We just need someone to come in and finish the other 99%.\"",
              "score": 1,
              "created_utc": "2026-01-16 05:30:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzryvb0",
              "author": "nrith",
              "text": "Wait, are you telling me the 80/20% rule applies even to vibe-coded projects?!",
              "score": 0,
              "created_utc": "2026-01-15 18:47:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzsnkhf",
              "author": "Blothorn",
              "text": "I feel like half the world forgot the 10-90 rule over the last year.",
              "score": 0,
              "created_utc": "2026-01-15 20:40:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzrxaqm",
              "author": "maxximillian",
              "text": "It turns out the last 10% is the hard part even with ai agents. You don't say. ",
              "score": -1,
              "created_utc": "2026-01-15 18:40:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzuebqi",
              "author": "voidstarcpp",
              "text": "> Oh, you don’t say. You got something that “kind of worked” and then decided nobody wanted to dig through the slop to implement the rest eh?\n\nThis was a research project of unprecedented scale; of course nobody is going to invest millions of dollars of human labor to \"implement the rest\" now for a product nobody wants (another duplicative, half-maintained browser). This is an impressive step forward for large-scale and longer run agent interaction.",
              "score": -3,
              "created_utc": "2026-01-16 02:02:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzr51ga",
          "author": "tedbarney12",
          "text": "Lol 'kinda works' software 🤣",
          "score": 251,
          "created_utc": "2026-01-15 16:33:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzr56t2",
              "author": "Therabidmonkey",
              "text": "So you're saying we should push to prod?",
              "score": 68,
              "created_utc": "2026-01-15 16:34:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzr7i5r",
                  "author": "RobespierreLaTerreur",
                  "text": "We test in prod.\n\nThere's an ad on reddit telling us we can do just this.",
                  "score": 24,
                  "created_utc": "2026-01-15 16:44:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzr9l4g",
                  "author": "arwinda",
                  "text": "Just Docker it and ship it, \"works on my system\". /s",
                  "score": 3,
                  "created_utc": "2026-01-15 16:54:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrs8vo",
              "author": "Kale",
              "text": "\"There's a memory safety condition. But I threw in a \"sleep(3)\" in one and a \"sleep(13)\" on the other thread. The GCD(3,13) is 1 so it's really unlikely they try to access the same memory at the same time....\"\n\nSmart solutions to dumb problems 👍🏾",
              "score": 7,
              "created_utc": "2026-01-15 18:17:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrz7kl",
                  "author": "BtcVersus",
                  "text": "39 seconds later ... Oops :)",
                  "score": 10,
                  "created_utc": "2026-01-15 18:48:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrnzso",
              "author": "Ranra100374",
              "text": "To be fair, a lot of software 'kinda works' lol.",
              "score": 9,
              "created_utc": "2026-01-15 17:58:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzsmla6",
                  "author": "KeytarVillain",
                  "text": "Yup, sadly AI arrived at just the right time, where software has become so enshittified that people already accept \"kinda works\". We don't _like_ it, but we put up with it, and companies make billions of dollars with shitty software.\n\nAI is going to make this much worse.",
                  "score": 1,
                  "created_utc": "2026-01-15 20:35:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzwstop",
              "author": "zazzersmel",
              "text": "I would gladly support a paradigm of AI lowering engineering standards as opposed to the current reality of increased expectations.",
              "score": 1,
              "created_utc": "2026-01-16 12:44:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzt4h08",
              "author": "FarFlugAsi",
              "text": "Could you build a web browser in a week that kind of works?",
              "score": 1,
              "created_utc": "2026-01-15 21:58:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztafc7",
                  "author": "lightninhopkins",
                  "text": "This doesn't build or run. So \"kind of\" is not true. It doesn't work period.",
                  "score": 5,
                  "created_utc": "2026-01-15 22:26:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrgdp7",
          "author": "mikat7",
          "text": "> See, rendering a webpage is not the hard part.\n\nis it not? I used to follow the servo project and the bits that made it into Firefox and I was under the impression that rendering a web page correctly, with CSS and with a JS engine AND supporting all the quirks that accumulated over the decades AAAND making it fast enough and resource efficient was damn freaking difficult.",
          "score": 89,
          "created_utc": "2026-01-15 17:24:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsb4lb",
              "author": "Jaded-Asparagus-2260",
              "text": "Almost as if there is a reason we have only two serious rendering engines. And Safari.",
              "score": 61,
              "created_utc": "2026-01-15 19:42:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzt2oit",
              "author": "caltheon",
              "text": "yeah, this is literally the HARDEST part of a browser.  The rest is just CRUD, state management, network streams, and event control",
              "score": 18,
              "created_utc": "2026-01-15 21:49:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nztohnc",
              "author": "lqstuart",
              "text": "Is that why they don’t bother making Firefox resource efficient?\n\nJk I love Firefox",
              "score": 3,
              "created_utc": "2026-01-15 23:39:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzurn5y",
              "author": "A_modicum_of_cheese",
              "text": "no cap i'm primed to assume the article is mostly AI generated with how much AI stuff the website is promoting",
              "score": 3,
              "created_utc": "2026-01-16 03:16:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzwx0hx",
              "author": "Relative-Scholar-147",
              "text": "Developers: We even created a new programming language called Rust to help us write the renderer.\n\nVibecoders: Rendering a webpage is not the hard part.",
              "score": 3,
              "created_utc": "2026-01-16 13:10:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzxqguv",
              "author": "crappy_entrepreneur",
              "text": "Reminds me of this fantastic article about \"Chuck Norris red\" and how the internet is built to be incredibly forgiving to decades of legacy web code \n\nThe fact that most websites built in the 90s can still work perfectly well is nothing short of an absolute software miracle. \n\n[https://www.htmhell.dev/adventcalendar/2024/20/](https://www.htmhell.dev/adventcalendar/2024/20/)",
              "score": 2,
              "created_utc": "2026-01-16 15:38:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzt4svs",
              "author": "FarFlugAsi",
              "text": "Human developers are really good at moving the goal posts when it comes to AI.",
              "score": -6,
              "created_utc": "2026-01-15 21:59:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzr7rz7",
          "author": "grumpy_autist",
          "text": "It's funny how quick we're back to 70's with \"lines of code as asset and performance metrics\".\n\nFunny enough few try to vibe code in assembly",
          "score": 243,
          "created_utc": "2026-01-15 16:46:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzr9hp4",
              "author": "ta9876543205",
              "text": "Now that's an idea. Give a largish piece of code to AI and ask it to generate the equivalent optimised assembly",
              "score": 58,
              "created_utc": "2026-01-15 16:53:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrvz7a",
                  "author": "DetectiveOwn6606",
                  "text": "I don't why these ai bros are even writing code in high level language . If the human is bottleneck in coding(according to them) they should just start generating and vibing machine code",
                  "score": 18,
                  "created_utc": "2026-01-15 18:34:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzrjaq6",
                  "author": "GergelyKiss",
                  "text": "Great! I propose we call this groundbreaking innovation... \"compiler\"!",
                  "score": 80,
                  "created_utc": "2026-01-15 17:38:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzsyo53",
              "author": "SpezLuvsNazis",
              "text": "My company is literally doing this, in part because labor laws where I live are very strict about firing people so they need bullshit “metrics” to rationalize it.",
              "score": 2,
              "created_utc": "2026-01-15 21:31:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzs32wt",
              "author": "Richandler",
              "text": "I was looking for a strictly markdown editor with a preview that runs well and doesn't have 5000 other bells and whistles. There is really only one for mac, MarkEdit, and still had a weird step to get preview to work. Why can't we just make good, simple, just works software?",
              "score": 4,
              "created_utc": "2026-01-15 19:05:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzza0nf",
              "author": "kjuneja",
              "text": "Never went away.  Just as bad now as then",
              "score": 1,
              "created_utc": "2026-01-16 19:45:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzso8th",
          "author": "Dave3of5",
          "text": "Had a quick look at the code on github and even though I'm no expert in rust a few things stood out to me:\n\nThere is virtually no human readable documentation. The main thing here seems to be giants bullet point lists of things that went wrong with all these agents interacting with each other it's totally confusing Example:\n\nRuthless triage: If you can't turn a symptom into a task with a measurable outcome quickly, stop and split the work.\n\nOk what on earth does that mean ... It's like a VC writing your documentation.\n\nThere is no actual build at all anywhere that I can download to see if this is actually working. The actions has 63,302 workflow runs which I can't find a single one that has actually ran successfully.\n\nThe git history is complete and utter chaos every day there has been thousands and thousands of git commits for seemingly random stuff all just mixed in with no real proper overarching description. The commit messages don't tell you why but are simply a summary of the diff.\n\nThere are test everywhere. Some of it inline with the code some of it in separate dedicated files. Some of these tests are labelled as test some are not. I think there is an order to this chaos but it's hard to tell as there is no clear docs just giant bullet point lists with VC like speech in them.\n\nThere seems to already be abandoned stuff in this repo for example there are 2 very important structures:\n\nBrowserDocument\nBrowserDocument2\n\nThey seem similar at a high level but seem to be 2 different implementations of the same thing. This is a common pattern to go into a folder and see 2 of the same thing seemingly used for the same thing but with differences. It's like the agent couldn't change one and so just built a different one and changed that instead and left the old one there.\n\nMost of the files are like 500 lines long but there are some mega objects in here that are like 6500 line long files with no structure. The worst one is this:\n\nhttps://github.com/wilsonzlin/fastrender/blob/main/src/resource.rs\n\n30,000 lines in a single file.\n\nSome serious wtf in that file btw have a look through some of those functions my fav is normalize_http_url_for_fetch which seems to be a function to encode a url.\n\nComments are wild. Some files have almost ever single line covered by a comment like the typically LLM generated code that over explains itself as an example other files have no comments whatsoever. There is no pattern at all like a comment block at the top of each file explaining the file some have these some do not.\n\nThere is a mixture of long winded sentences as function names mixed in with almost code golf style 3 character acronym old school 1980's naming.\n\nIt's using an older version of Rust 1.70.0 not sure why.\n\nThere are a shitload of dependencies here I mean like > 100. The most important seems to be a binding lib to quickjs. To me that's not really writing you own js engine but I guess the authors here didn't review this in any way and because it looks like there is a js engine here that's been custom built then they are happy.\n\nI think my summary is that this is a dead end project that will never see the light of day. There is just too much \"stuff\" here and because the authors let this go way too far before they reviewed the thing or because the didn't really know how to build a properly structured browser this can't really go any further.\n\nI suspect the reason this stopped was that the majority of changes that have been happening on the last few days have seen very little progress but just so many changes i.e. the LLMs are now just \"spinning the plates\" and not really progressing. That means this dude probably is thinking \"I better stop spending money now and just let the world see this and declare success\". A bit like how George W declared missioned accomplished.\n\nTo me this is a cautionary tale. Current day LLMs are not ready to tackle large scale projects like this themselves when they are not driven by people whom have a very clear defined vision of how that project should be structured.",
          "score": 45,
          "created_utc": "2026-01-15 20:43:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzstiam",
              "author": "AlSweigart",
              "text": "Thank you. This is one of the few informative comments in this thread, and it's deeply needed. Thanks.",
              "score": 11,
              "created_utc": "2026-01-15 21:07:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzuvjh1",
              "author": "Buzzard",
              "text": "> Most of the files are like 500 lines long but there are some mega objects in here that are like 6500 line long files with no structure. The worst one is this:\n> \n> https://github.com/wilsonzlin/fastrender/blob/main/src/resource.rs\n> \n> 30,000 lines in a single file.\n\nI found https://github.com/wilsonzlin/fastrender/blob/main/src/style/cascade.rs\n\n41,374 lines\n\n(Maybe cheating as half of it is inline tests)",
              "score": 7,
              "created_utc": "2026-01-16 03:38:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzvaj4g",
              "author": "Maybe-monad",
              "text": ">It's using an older version of Rust 1.70.0 not sure why.\n\nThat was the latest version in the training data for the LLM",
              "score": 3,
              "created_utc": "2026-01-16 05:15:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzujxwg",
              "author": "voidstarcpp",
              "text": ">That means this dude probably is thinking \"I better stop spending money now and just let the world see this and declare success\".\n\nThey didn't declare the browser a success, but they considered the project a success because it ran for longer and with more agents than previous experiments, and at one point produced a half-working application that rendered a web page. That's kind of funny and impressive at the same time. They didn't claim it was anything that it wasn't.\n\n>To me this is a cautionary tale. Current day LLMs are not ready to tackle large scale projects like this themselves when they are not driven by people\n\nWhat part of the company's blog post on this project made you think they were trying to say otherwise?",
              "score": -6,
              "created_utc": "2026-01-16 02:33:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrdf7e",
          "author": "mdbuck",
          "text": "Tired of these AI tech-bros making claims like this, then having to retract or backtrack said claims when people look into what they've done. They don't disclose the caveats until after they've made their audacious declarations. I think this is one of the (small) reasons people do not like AI: it's presented in such a way that appears dishonest.",
          "score": 91,
          "created_utc": "2026-01-15 17:11:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs3jxz",
              "author": "scoopydidit",
              "text": "My company (one of the larger tech companies out there) is entering people into a $200 raffle if they post about our AI product \"wins\" on LinkedIn. \n\nSurely a good product doesn't need giveaways to employees for them to advertise it?\n\nThe AI hype and promotion is so fake.",
              "score": 10,
              "created_utc": "2026-01-15 19:07:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzromk4",
              "author": "elh0mbre",
              "text": "I think AI tools are great and I completely agree with you.\n\nThis isn't necessarily an AI problem though. Unfortunately, the world rewards people who behave this way (see: Elon Musk, blockchain, etc).",
              "score": 13,
              "created_utc": "2026-01-15 18:01:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzt6som",
                  "author": "xmBQWugdxjaA",
                  "text": "At least Elon Musk has Starlink, Falcon 9 and Tesla FSD working.\n\nThese crazy claims remind me more of the NFT stuff.",
                  "score": -6,
                  "created_utc": "2026-01-15 22:09:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzujcmy",
              "author": "Jwosty",
              "text": "For real. These LLM tools truly are amazing feats of engineering. I don't want to hate them, but damn, all the AI hype bros (especially the ones IRL) are doing a REALLY good job making me hate it.\n\nIt's not the tool itself or ignorance that drives me insane, it's the blatant widespread careless abuse of it that does. An alarming number of people just *refuse* to use it correctly and responsibly and instead just completely offload their thinking to it.\n\nLike I've been saying for years now: if Google makes us stupid, AI makes us stupider. It's being proven true more and more each day.",
              "score": 3,
              "created_utc": "2026-01-16 02:30:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzuhmg7",
              "author": "voidstarcpp",
              "text": "> They don't disclose the caveats until after they've made their audacious declarations.\n\nThey posted the entire repo and were completely open about how it was set up and what the limitations and results were. I don't know what you think the \"audacious declaration\" is here or what they're hiding.",
              "score": -4,
              "created_utc": "2026-01-16 02:20:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzt4oqm",
              "author": "FarFlugAsi",
              "text": "They built a web browser in a week...",
              "score": -8,
              "created_utc": "2026-01-15 21:59:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzu2pa6",
                  "author": "SirReal14",
                  "text": "> They built a web browser in a week...\n\nThe code does not even build! What on earth are you people talking about. Here, an AI made me a NASA level quantum physics simulation, go ahead and run it: `:(){ :|:& };:`",
                  "score": 4,
                  "created_utc": "2026-01-16 00:56:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzr8ltw",
          "author": "qzxfc",
          "text": "are you sure its from scratch when 90% of code is from importing libraries? also interesting why they choose almost 3 year old cargo version, this piece of shit doesn't even builds properly, also the CEO is lying about using custom js vm. i am astonished at how much these people lie on narrative that they have created something wonderful and easily get away with it after the hype dies",
          "score": 146,
          "created_utc": "2026-01-15 16:49:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs64b0",
              "author": "raven_raven",
              "text": "CEOs lie because journos will parrot absolutely everything they say. So in order to rise your stock you just lie through your teeth with as much as you can get away with it. Everybody will forget your bold claims in a year, and even if someone fact checks you it’ll reach far lesser audience than the original claims.",
              "score": 35,
              "created_utc": "2026-01-15 19:19:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzrqcwy",
              "author": "CoreParad0x",
              "text": "100%. As some one who uses AI tools like cursor for some specific use cases (not this vibe coding shit) this bullshit helps nobody but potentially investor hype. Even if the \"*kind of works*\" in this wasn't doing an astronomical amount of heavy lifting, can you imagine auditing this shit? It's a security nightmare, among many other things.\n\nIf the tech can't stand on it's own valid use cases, then it should die (and even then I can make arguments for why it should die even if it can stand on it's own.) All this dishonest hype train crap is doing is prolonging and worsening a bubble that is going to absolutely fuck things up when it pops.",
              "score": 15,
              "created_utc": "2026-01-15 18:09:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztaa49",
                  "author": "hacker_of_Minecraft",
                  "text": "What will happen when it pops? Mega-corps losing tons of money? People dependent on closed source ais (or anything using their apis) not being able to do anything? I don't think it'll mess up anything important.",
                  "score": 1,
                  "created_utc": "2026-01-15 22:26:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztgg0j",
                  "author": "QuickQuirk",
                  "text": "> can you imagine auditing this shit? It's a security nightmare, among many other things.\n\nIronically, an LLM would probably be very quick at auditing and finding bugs, and writing short exploit scripts.",
                  "score": -1,
                  "created_utc": "2026-01-15 22:56:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzsr9pi",
              "author": "No_Attention_486",
              "text": ">also interesting why they choose almost 3 year old cargo version\n\nBecause they literally have NO IDEA how any of this works. This whole thing is a marketing bit for ignorant VCs to keep investing because they are BURNING through cash. The problem with their product is completely reliant on other things (vscode fork, 3rd party models) they have composer but people will prefer something like opus or GPT 5.2. So at some point people will just use something like opencode or claude code with their favorite editor.",
              "score": 9,
              "created_utc": "2026-01-15 20:57:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nztqu4d",
              "author": "ZjY5MjFk",
              "text": "> are you sure its from scratch when 90% of code is from importing libraries?\n\nI had a junior dev do this.  He said something like \"yea, I wrote an entire full feature web server over the weekend, it was fun.  It's really fast too\"\n\nI was like \"that's cool\" and he sent me his public github.  It was basically:\n\n    import http.server;\n    httpserver.start(80);\n\n\nLike ok... I guess, kind of",
              "score": 9,
              "created_utc": "2026-01-15 23:52:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nztd0f0",
              "author": "takobaba",
              "text": "It might not be a lie maybe not aware of doesn't know. most of the ai vomit(vibe code) I see people are not even aware what's there. kinda works software makes it to news. what about my 1000 ideas that never built or published",
              "score": 3,
              "created_utc": "2026-01-15 22:39:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nztkdol",
              "author": "SnugglyCoderGuy",
              "text": "> are you sure its from scratch when 90% of code is from importing libraries?\n\nPython devs hate this",
              "score": 2,
              "created_utc": "2026-01-15 23:17:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzuhur5",
              "author": "voidstarcpp",
              "text": "> the CEO is lying about using custom js vm\n\nWhat are you basing this on? There looks to be a custom JS implementation, alongside a third party implementation they test against.",
              "score": 1,
              "created_utc": "2026-01-16 02:21:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrybc8",
          "author": "Pharisaeus",
          "text": "Now the reality:\n\n1. The repo doesn't build, so it's curious how they measured that it \"kind of works\". Maybe that's what they meant, that it \"almost compiles\"? :) We can even check https://github.com/wilsonzlin/fastrender/actions?query=is%3Asuccess that the last successful build was... 3 days ago. And since then the agents were just piling-up more and more code, to already broken software. At this point I seriously doubt it's possible to figure out how to fix the build. There are 58 pages of \"successful build\" and 2324 pages of \"failed builds\".\n2. We're talking about writing software that has complete examples on the internet so the model contains the information about how every single of the exact problems was solved in the past. Not \"similar\" problem, not some \"analogy\", the exact problem.\n3. This software also has very clear, fixed guidelines and requirements in the form of RFCs and HTML and JS specs. In a way, this is much closer to solving ACM/LC-style problem than what \"normal software development\" is, where the requirements are fuzzy and ever changing. So they could have, in theory, run a complete suit of tests with each change, making sure that there is no regression. So why didn't they? Because a single build, when it was still building few days ago, took 42 minutes.\n4. They mention how \"fast\" they wrote it, but omitted how much it actually costed, with their multi-level agent orchestration. But \"billions of tokens\" suggests tens o thousands of $ and I suspect we're talking much more than that. \n\nNow imagine if the headline was: \"we just spent few million $ on code that doesn't even compile, while attempting to solve a very well-defined, clearly constrained problem\"",
          "score": 59,
          "created_utc": "2026-01-15 18:44:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzssbre",
              "author": "nnomae",
              "text": "Am I reading that right? The project hasn't been building for over 97.5% of its lifetime?",
              "score": 9,
              "created_utc": "2026-01-15 21:02:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzszeyx",
                  "author": "Pharisaeus",
                  "text": "I didn't check the timeline, but from the perspective of number of repository pushes, indeed only 2% of them resulted in a successful build.\n\nThe timeline is a bit weird, because the official statement was that they let the agent for \"for a week\", while this repo started getting commits mid December already, but indeed it got majority, about 20k commits just last week, and that's also when it \"broke\"...",
                  "score": 12,
                  "created_utc": "2026-01-15 21:35:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztmaig",
              "author": "wasdninja",
              "text": "The entire exercise is a waste of time and nobody will ever use it even if it did work but browsers are everything but well defined and constrained. They are layers and layers and layers of quirks, learned best practices, patched security holes and semi esoteric legacy that just have to work.",
              "score": 7,
              "created_utc": "2026-01-15 23:27:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztnfns",
                  "author": "Pharisaeus",
                  "text": "> but browsers are everything but well defined and constrained. They are layers and layers and layers of quirks, learned best practices, patched security holes and semi esoteric legacy that just have to work.\n\nYou're talking about \"historical legacy\", which is a problem when developing such software further, but is not a real problem when developing the initial version. Yes, those historical quirks might be weird, but they are well known and well defined (again, in RFCs and in standards). They might not make much sense, and introduce \"special cases\", but you sill know that they need to be included, and you can relatively easily write test cases to make sure it's covered.\n\nThe real difficulty in writing software is when you start adding features and modifying stuff, while trying not to break what is already there - this is when \"bad design decisions\" bite you in the ass.",
                  "score": 5,
                  "created_utc": "2026-01-15 23:34:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzuif4l",
              "author": "voidstarcpp",
              "text": ">We're talking about writing software that has complete examples on the internet so the model contains the information about how every single of the exact problems was solved in the past.\n\nIncredible levels of cope here; Browsers are some of the most complicated software to exist. AI could create a new operating system on demand in a week and you could come back with \"well operating systems are a widely published and well defined problem, so that doesn't count\".\n\nLike yeah most of what people are doing is variations on things that were previously invented. That's why people take CS classes and learn about OS, compiler, and filesystem design. It's not cheating to have simply studied and know how to do things! I'm curious what you think the vast majority of human programmers are getting paid to do every day that isn't solving defined and constrained problems that are amenable to testing and involve recombining libraries and patterns as widely used in other programs.",
              "score": -4,
              "created_utc": "2026-01-16 02:25:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzuvzoo",
              "author": "GBcrazy",
              "text": "> We're talking about writing software that has complete examples on the internet so the model contains the information about how every single of the exact problems was solved in the past. Not \"similar\" problem, not some \"analogy\", the exact problem.\n\nYeah every developer should be able to write a browser right?\n\nThis is just insane level of AI hating. Like, there are issues with it, but it is also a pretty interesting experiment",
              "score": -4,
              "created_utc": "2026-01-16 03:41:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzt62d0",
              "author": "FarFlugAsi",
              "text": "Look at you, moving those goal posts as far as possible. \n\n>The repo doesn't build, so it's curious how they measured that it \"kind of works\". Maybe that's what they meant, that it \"almost compiles\"? :) We can even check https://github.com/wilsonzlin/fastrender/actions?query=is%3Asuccess that the last successful build was... 3 days ago. And since then the agents were just piling-up more and more code, to already broken software. At this point I seriously doubt it's possible to figure out how to fix the build. There are 58 pages of \"successful build\" and 2324 pages of \"failed builds\".\n\nGet an AI model to tell you what's wrong with the build.\n\n>We're talking about writing software that has complete examples on the internet so the model contains the information about how every single of the exact problems was solved in the past. Not \"similar\" problem, not some \"analogy\", the exact problem.\n\nAnd? \n\n> This software also has very clear, fixed guidelines and requirements in the form of RFCs and HTML and JS specs. In a way, this is much closer to solving ACM/LC-style problem than what \"normal software development\" is, where the requirements are fuzzy and ever changing. So they could have, in theory, run a complete suit of tests with each change, making sure that there is no regression. So why didn't they? Because a single build, when it was still building few days ago, took 42 minutes.\n\nAll software development should have fixed guidelines and requirements. \n\n>They mention how \"fast\" they wrote it, but omitted how much it actually costed, with their multi-level agent orchestration. But \"billions of tokens\" suggests tens o thousands of $ and I suspect we're talking much more than that.\n\nSo still hundreds of thousands cheaper than what it would have cost to get a human to develop it.\n\n>Now imagine if the headline was: \"we just spent few million $ on code that doesn't even compile, while attempting to solve a very well-defined, clearly constrained problem\"\n\nSo they've already reached human level of coding, but managed to achieve what a team of devs would take 6 months to do in a week.",
              "score": -14,
              "created_utc": "2026-01-15 22:05:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzt9k4g",
                  "author": "Pharisaeus",
                  "text": "> Get an AI model to tell you what's wrong with the build.\n\nAh yes, Coursor was running multiple agents in layers on this project for days, and they didn't figure out such an easy fix. I think they should hire you as consultant!\n\n> And? \n\nAnd it's much easier to type something from memory compared to figuring out a solution.\n\n> All software development should have fixed guidelines and requirements. \n\nI wish that was true, however in real life that's not the case. Have you ever worked on a software project in your life? 80% of requirements are not known before the project starts. The whole point of Agile-craze was prompted by the fact that software requirements were changing all the time and a classic waterfall strategy didn't work. If requirements were \"fixed\" you could easily do waterfall.\n\n> So still hundreds of thousands cheaper than what it would have cost to get a human to develop it.\n\nI can generate 3 million lines of code that doesn't compile to $1. That's much cheaper.\n\n> So they've already reached human level of coding, but managed to achieve what a team of devs would take 6 months to do in a week.\n\nAgain, I assure you, there is no need fr a team of devs and 6 months to generate a lot of garbage code that doesn't build.",
                  "score": 18,
                  "created_utc": "2026-01-15 22:22:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzttjw5",
                  "author": "Thrwwccnt",
                  "text": "Wanting it to successfully build is not shifting goalposts, that's a pretty essential thing. I agree people have a tendency to cope at times but a piece of software that can't compile doesn't \"kind of work\", it's just useless.",
                  "score": 8,
                  "created_utc": "2026-01-16 00:07:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzr8wsp",
          "author": "LoneL1on",
          "text": "Challenge him to build a god damn original text editor next",
          "score": 21,
          "created_utc": "2026-01-15 16:51:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzt9ioe",
              "author": "levodelellis",
              "text": "He (and other vc funded people) aren't going to do a better job than I will\n\nLatest screenshots in my [nov devlog](https://bold-edit.com/devlog/25-11-summary.html)",
              "score": 2,
              "created_utc": "2026-01-15 22:22:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzrmkxp",
              "author": "Flat_Wing_6108",
              "text": "One that… runs in a browser?",
              "score": 1,
              "created_utc": "2026-01-15 17:52:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrzqoq",
                  "author": "Maybe-monad",
                  "text": "One that runs in the terminal",
                  "score": 1,
                  "created_utc": "2026-01-15 18:50:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrb557",
          "author": "OttersEatFish",
          "text": "The future belongs to companies that get consumers to accept “kinda works” and that sucks.",
          "score": 42,
          "created_utc": "2026-01-15 17:01:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrdgdi",
              "author": "fun__friday",
              "text": "Gaming companies have already succeeded at that.",
              "score": 42,
              "created_utc": "2026-01-15 17:11:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrexpa",
                  "author": "Sparaucchio",
                  "text": "My company sells a product that barely works in the happiest of the happy paths, and we get customers... who makes the decision to buy is not the same person that uses our product, we are B2B",
                  "score": 10,
                  "created_utc": "2026-01-15 17:18:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzrxxmq",
                  "author": "edgmnt_net",
                  "text": "This is why we need to reduce the extent of copyrights. Weak copyrights favor efficient, open, community-backed development over relying on a state-enforced monopoly that inevitably leads to such issues with no way in sight to fix them. Yeah, ok, you don't get to make a product then figure out how to sell it knowing your premature investment is safe, maybe it means less AAA stuff. You no longer have these black holes attracting all talent into working for legal monopolies. But if there's a need, people will finance it and it's getting cheaper in the long run considering open assets and code.",
                  "score": 2,
                  "created_utc": "2026-01-15 18:42:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzsdxya",
              "author": "Richandler",
              "text": "I mean, there are tons of Amazon Prime and Netflix subscriptions that go completely unused. Customers have kind of given up on participating in the market in many ways.",
              "score": 2,
              "created_utc": "2026-01-15 19:55:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nztro1s",
              "author": "kupo-puffs",
              "text": "bro you just described evolution. if it works that's good enough",
              "score": 0,
              "created_utc": "2026-01-15 23:57:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzri1j0",
          "author": "testfire10",
          "text": "I’m not a developer, just a hobbyist, but I have questions. \n\nSo basically AI generated 3m lines of code. Presumably no one has any real clue what those 3m lines of code are doing, and why it couldn’t be 1m, or 5m? And now that it’s out there, they make a claim it “kind of” works? How do you know what works? What does “works” mean? Is it secure? Who is writing the tests? \n\nBasically now you have a 3m line code base that no human can ever comprehend, and therefore troubleshoot and refactor, so what’s the plan? We just trust it and ship it and wait for the consumer to figure out what’s cooked?",
          "score": 39,
          "created_utc": "2026-01-15 17:32:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrlkgt",
              "author": "ionixsys",
              "text": "In programming this is called a ball of mud.  The complexity of fixes to patches to fixes has reached a point where there isn't anything to fix, it's just fucked.",
              "score": 37,
              "created_utc": "2026-01-15 17:48:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrm1qq",
                  "author": "testfire10",
                  "text": "So rather than taking years (presumably) for a codebase to become a ball of mud, now the plan is to start at that point right out of the gate? And just hope you can troubleshoot it with ai?",
                  "score": 26,
                  "created_utc": "2026-01-15 17:50:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzulxsx",
              "author": "Jwosty",
              "text": "I sure hope there aren't any critical bugs in there that, say, wipe your hard drive or something...",
              "score": 1,
              "created_utc": "2026-01-16 02:44:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzsulmz",
              "author": "paeschli",
              "text": "The thing is that building a browser that 'kind of works' is easy. Ladybird has achieved that years ago. The hard part is building a webbrowser that can render the 20% of websites that feature edge cases, legacy solutions, etc.",
              "score": 0,
              "created_utc": "2026-01-15 21:12:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzt509r",
                  "author": "FarFlugAsi",
                  "text": "Did ladybird do it in a week?",
                  "score": -5,
                  "created_utc": "2026-01-15 22:00:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrwiw9",
              "author": "dbbk",
              "text": "That's why you use TDD though. The tests are the source of truth of what should be happening. Once you've got solid tests, you can set the AI off to refactor as much as it wants, as long as the tests still pass.",
              "score": -8,
              "created_utc": "2026-01-15 18:36:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrygbf",
                  "author": "neopointer",
                  "text": "Good luck writing good tests for a browser or writing tests for anything interesting for that matter.\n\nAh, but wait, isn't it the case that developers should not be needed..? So AI should write the tests as well...\n\nWe all know where this is going...",
                  "score": 9,
                  "created_utc": "2026-01-15 18:45:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsw9xl",
                  "author": "AdrianoML",
                  "text": "Tests in TDD are for catching bugs, edge cases, regressions and usual gotchas. They are not a source of truth and don't attest correctness, other than maybe trivial tests.",
                  "score": 8,
                  "created_utc": "2026-01-15 21:20:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzusc85",
                  "author": "A_modicum_of_cheese",
                  "text": "tests aren't gonna cover the vulnerabilities in 3 million lines of code",
                  "score": 2,
                  "created_utc": "2026-01-16 03:20:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsiw9e",
                  "author": "omac4552",
                  "text": "psst, interested in buying a bridge?",
                  "score": 1,
                  "created_utc": "2026-01-15 20:18:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o03c0jk",
                  "author": "jl2352",
                  "text": "You're being downvoted, but you're right. That sets a hard gate to stop the AI. Things must compile and work. You can subdivide the project down to build that testing.\n\nThe problem I have though is no one is going to be able to figure out all of the needed behaviour and edge cases within a week. Ensure all of those tests are correct.\n\nIf I were asked to fix a project like this. I'd spend 90% of my time working with people asking \\*'what should this do when ... ?'\\* No one will know.",
                  "score": 1,
                  "created_utc": "2026-01-17 12:02:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzropqm",
          "author": "iamapizza",
          "text": "We really need to stop giving these slop artists attention. \n\nIn case you're wondering why they did this, it's purely investor attention. They aren't idiots, they _know_ the browser won't work. That isn't the point, the point is to convince the people with the money that they are \"doing things\" and keeping the buzz going and investor attention on them. It's a form of advertising.\n\nThere's a popular one about the vending machine running AI, and oh look, they convinced it to give them free stuff, what a lark. Yep that's attention.  Think on this on any AI related thing you see. It's hype first and reality later.",
          "score": 36,
          "created_utc": "2026-01-15 18:02:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsewgw",
              "author": "realqmaster",
              "text": "Isn't calling out the fact it's a non working hot mess a counter to investors attention?",
              "score": 2,
              "created_utc": "2026-01-15 19:59:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzt5efg",
              "author": "FarFlugAsi",
              "text": "> We really need to stop giving these slop artists attention.\n\nThey don't really care if you give them attention or not. The people who buy software love what they're doing. \n\nI actually find the whining about AI coding far more annoying.",
              "score": -6,
              "created_utc": "2026-01-15 22:02:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzra27n",
          "author": "K3idon",
          "text": "CEO: Works on my machine and no tests failing. Ship it!",
          "score": 14,
          "created_utc": "2026-01-15 16:56:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzssxtu",
          "author": "AlSweigart",
          "text": "\"Wow. Big if true.\"\n\nI saw this yesterday. One thought I had: If the AI is so smart, why can't it make installers so people can try it out?\n\nI cloned the repo and tried to build it. I got several compiler warnings and errors. I thought maybe I should find a different tag to get a working release, but the project has zero tags.\n\nI looked through the repo. It's 63,000 files. All I can say is: *Yes. It certainly looks like the source code for a working web browser.*\n\nI'd dismiss it entirely (especially after seeing another guy on Reddit claim he made an AI-generated browser from scratch that was just a wrapper around a webview control), but a guy on Twitter (who looks legit) says he's a browser developer and got it to compile after two hours of messing with it. He posted screenshots and it looks like the browser renders websites well enough. I trust he isn't fabricating them.\n\nEDIT: Apparently the guy \"fixed it\" by having an LLM just iterate on it until it compiled. It took about two hours.\n\nStill, I'm... deeply skeptical of these [Potemkin](https://en.wikipedia.org/wiki/Potemkin_village) apps. How much of this is \"from scratch\" and how much is libraries? Why should I trust anything he says? This is the CEO of Cursor, which just reskinned Microsoft Visual Studio Code and integrated it with OpenAI and other APIs. They didn't make an editor and they didn't make an LLM fine-tuned for coding. Any engineering team could do that, but Cursor did it first so the company is now ~~worth~~ valued at $29.3 billion.\n\nI don't even think it's worth the time to investigate these claims anymore. I'm tired of cloning the repos and finding code that doesn't compile. I'm tired of pointing out fake screenshots and broken UIs. I'm just going to give \"ok boomer\" responses to AI news:\n\n\"Wow. Big if true.\"",
          "score": 14,
          "created_utc": "2026-01-15 21:05:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzu5s93",
              "author": "_TRN_",
              "text": "Could you link me to the guy who managed to make it compile? Asking out of curiosity.\n\nI also don't think this is from scratch just based off the libraries it's using. It almost seems like to me that the Cursor CEO didn't even read any of the code? Either that or he's lying.",
              "score": 8,
              "created_utc": "2026-01-16 01:14:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzv9cbc",
                  "author": "AlSweigart",
                  "text": "https://x.com/CanadaHonk/status/2011612084719796272\n\nHuh, I just found this reply and his response:\n\n\"That’s crazy. 2 hours? Share your prompt\"\n\n\"just gave it the command to compile and said iterate until it builds successfully\"\n\nSo it sounds like he had ChatGPT fix it through random fucking around for a couple hours until the compilation errors went away. The screenshots he posted are legible, which is impressive. Though now I wonder how much of the code is actually original, or if the fucking around just inserted a web view control at the last second. I mean, when I \"made a web browser with AI\" that's basically what it was.",
                  "score": 3,
                  "created_utc": "2026-01-16 05:06:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrevua",
          "author": "dethnight",
          "text": "Hey all, I was able to design an aircraft with AI.  I think it kind of flies, anyone ready to hop in?",
          "score": 28,
          "created_utc": "2026-01-15 17:18:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrnq8r",
              "author": "iamapizza",
              "text": "Found Boeing's reddit account",
              "score": 20,
              "created_utc": "2026-01-15 17:57:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzssi58",
                  "author": "nnomae",
                  "text": "Oof.",
                  "score": 3,
                  "created_utc": "2026-01-15 21:03:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzs0wvp",
              "author": "swutch",
              "text": "The Spruce Moose! ",
              "score": 2,
              "created_utc": "2026-01-15 18:56:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrj3sb",
          "author": "realqmaster",
          "text": "Lol looks like it doesn't even build https://github.com/wilsonzlin/fastrender/issues/98",
          "score": 13,
          "created_utc": "2026-01-15 17:37:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrnzq5",
          "author": "valarauca14",
          "text": "The repo literally doesn't built -> https://github.com/wilsonzlin/fastrender/issues/98",
          "score": 11,
          "created_utc": "2026-01-15 17:58:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrcwzx",
          "author": "Seanitzel",
          "text": "I would bet 1$ for every line of code(not a millionaire lol) that it would take YEARS to turn this into something actually usable, and I pity real developers that will work on it.\nI wouldn't do it even if it would have made me a millionaire.\nOfcourse that will never happen and this is just a shitty POC they invested in for hype",
          "score": 8,
          "created_utc": "2026-01-15 17:09:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrg1pp",
          "author": "Vtempero",
          "text": "Is the size of the slop you are able to require AI to implement the new tech dick measurement contest?\n\n\n\n\"Cursor CEO asked to kinda create a browser while Elon musk kinda made a full OS!\"\n\n\n\nWow look at the number of tokens available!",
          "score": 8,
          "created_utc": "2026-01-15 17:23:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsc0t6",
          "author": "Imnotneeded",
          "text": "Betteridge's law of headlines...",
          "score": 7,
          "created_utc": "2026-01-15 19:46:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzstqoj",
              "author": "AlSweigart",
              "text": "For those who don't know: [Betteridge's law of headlines is an adage that states: \"Any headline that ends in a question mark can be answered by the word no.\"](https://en.wikipedia.org/wiki/Betteridge%27s_law_of_headlines)",
              "score": 3,
              "created_utc": "2026-01-15 21:08:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrkwku",
          "author": "ionixsys",
          "text": "I wonder how much money they spent on the agents to create a big ball of mud?  \n\nI mean it's cool in the same way it's cool to see how someone on cocaine (more likely meth) sorted out a 10lb bag of M&M candies by color.",
          "score": 8,
          "created_utc": "2026-01-15 17:45:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrt94q",
          "author": "dyndhu",
          "text": "Who else is ready for the golden age of maxslop AI software development where you need a degree in mysticism instead of computer science to work in tech?",
          "score": 7,
          "created_utc": "2026-01-15 18:22:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsggp2",
          "author": "Suspicious-Ad7360",
          "text": "\"alright Bois, time to maintain it\"",
          "score": 7,
          "created_utc": "2026-01-15 20:07:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt9hlg",
          "author": "lightninhopkins",
          "text": "An article about AI written by an AI. Slop in slop out.",
          "score": 5,
          "created_utc": "2026-01-15 22:22:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzryn2c",
          "author": "neopointer",
          "text": "It's all fun and games until someone dies because someone wrote a medical equipment firmware with Cursor.",
          "score": 8,
          "created_utc": "2026-01-15 18:46:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzso4mm",
              "author": "captain_obvious_here",
              "text": "> someone dies\n\nNope. Someone KIND OF dies.",
              "score": 5,
              "created_utc": "2026-01-15 20:42:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzs8yy1",
              "author": "diagraphic",
              "text": "It’s not that, it’s just careless engineering.",
              "score": 1,
              "created_utc": "2026-01-15 19:32:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrqf67",
          "author": "bennett-dev",
          "text": "Weird how dev velocity 10x'd and all we did was increase the rate of enshittification",
          "score": 4,
          "created_utc": "2026-01-15 18:09:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs94p2",
          "author": "Volodian",
          "text": "Before AI : 90% of the time spent on the last 10% before actually shipping a product.\n\nAfter AI : 99% of the time spent on the remaining 1%.\n\nIt's just too early for the industry to actually experience those last horrible 1%, so everybody is speaking about the first 99%.",
          "score": 5,
          "created_utc": "2026-01-15 19:33:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztiesd",
          "author": "r2vcap",
          "text": "Honestly, no one can truly claim their code is “from scratch” if they use agents like Cursor. In this example, the browser is a well-established component, and I am quite certain that all LLMs have been trained on W3C specifications as well as on browser source code. But in truth, the same applies even when LLMs are not involved. All human creations are built upon others’ previous work.",
          "score": 5,
          "created_utc": "2026-01-15 23:07:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzr7e1e",
          "author": "clhodapp",
          "text": "Nope. Only way that's gonna work is if the starting point is a working browser.",
          "score": 5,
          "created_utc": "2026-01-15 16:44:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrae8g",
              "author": "arwinda",
              "text": "The AI had several open source engines as input (Firefox, Chromium, maybe the KDE browser engine, others).",
              "score": 5,
              "created_utc": "2026-01-15 16:57:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzti6qu",
                  "author": "Gibgezr",
                  "text": "...and it still doesn't even build XD",
                  "score": 6,
                  "created_utc": "2026-01-15 23:06:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrv9j2",
          "author": "nonlogin",
          "text": "If GPT was trained using Firefox it makes sense",
          "score": 3,
          "created_utc": "2026-01-15 18:31:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs8md8",
          "author": "diagraphic",
          "text": "Garbage.",
          "score": 3,
          "created_utc": "2026-01-15 19:31:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsgf0y",
          "author": "Dunge",
          "text": "So what's the ACID test results?",
          "score": 3,
          "created_utc": "2026-01-15 20:06:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu6q8x",
          "author": "ChazR",
          "text": "I would put cash money on it being a thin layer over existing free software, but abusing the licenses in exciting new ways.\n\nThe integration exists largely to add some thrilling new classes of security failure.",
          "score": 3,
          "created_utc": "2026-01-16 01:19:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuozjf",
          "author": "PadyEos",
          "text": "> Michael Truell, the 25-year-old CEO of Cursor\n\n\nHold up. No matter how smart you are how much knowledge and experience could you ever have gathered by 25 to be the CEO of one of the \"leading edge world changing technologies\"?\n\n\nImagine people with decades of experience in AI research taking orders for a 25 year old. This is insulting. ",
          "score": 4,
          "created_utc": "2026-01-16 03:01:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw1j1r",
              "author": "Maybe-monad",
              "text": "assuming there are people with decades of experience in AI research working under him",
              "score": 2,
              "created_utc": "2026-01-16 08:59:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzs8pe5",
          "author": "bogas04",
          "text": "Most of such large scale projects are simply forks and clones with some glue code. Something devs have been able to do for a long time, but LLMs definitely make you feel more confident and competent to tackle all that code, and in some ways that’s neat. ",
          "score": 2,
          "created_utc": "2026-01-15 19:31:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsekep",
          "author": "Rocheley-IV",
          "text": "a shitty ai article on a probably shitty ai browser",
          "score": 2,
          "created_utc": "2026-01-15 19:58:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvctt6",
              "author": "Maybe-monad",
              "text": "a browser that can't browse",
              "score": 1,
              "created_utc": "2026-01-16 05:31:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsn4ib",
          "author": "ObviousLavishness197",
          "text": "If you gotta ask, the answer is probably no",
          "score": 2,
          "created_utc": "2026-01-15 20:38:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsy4m5",
          "author": "nitin42",
          "text": "CDD - Clout Driven Development",
          "score": 2,
          "created_utc": "2026-01-15 21:29:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzre3uh",
          "author": "DirkTheGamer",
          "text": "A browser? The thing that there are a million examples of online and a basic coding exercise for anyone getting into app development? Can it do “Hello World” too? \n\nLLMs can do anything that’s been done a thousand times, yes, no one is disputing that.\n\nEdit: apparently this is a browser engine, not just a browser. My bad. That is much more complicated.",
          "score": 2,
          "created_utc": "2026-01-15 17:14:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrke9j",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 10,
              "created_utc": "2026-01-15 17:42:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzry8w6",
                  "author": "DetectiveOwn6606",
                  "text": "Another thing is these guys claim is their models have beat top competitive programmers but I tried it  on codeforces it was easy problem and the code it gave me was an hard coded solution on sample test cases . With the amount of data on solutions on competitive programming it is trained on giving an hardcoded solution is outrightly bad.",
                  "score": 3,
                  "created_utc": "2026-01-15 18:44:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzriydw",
              "author": "Caraes_Naur",
              "text": "LLMs can't do a thing for the *first* time, and never will.",
              "score": 5,
              "created_utc": "2026-01-15 17:36:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzt322y",
                  "author": "FarFlugAsi",
                  "text": "Yes, dear, keep on telling yourself that.",
                  "score": -4,
                  "created_utc": "2026-01-15 21:51:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzs2fvo",
              "author": "awesomeusername2w",
              "text": "Building a browser is a basic exercise for anyone getting into app development? Damn bro, what kind of apps are you doing with this level of basics?",
              "score": 5,
              "created_utc": "2026-01-15 19:02:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzs2sim",
                  "author": "DirkTheGamer",
                  "text": "I’ve never made a browser but aren’t there dozens of packages that will do all the basic HTTP parsing and converting to a display? I doubt that whatever browser he built wasn’t heavily based on existing work.",
                  "score": 1,
                  "created_utc": "2026-01-15 19:04:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzs30it",
              "author": "exscape",
              "text": "It's supposedly a browser engine, not a browser based on e.g. Chromium.  \nI promise you there are not a million examples or building browser engines. Is there even one?\n\nThat said, I do believe this project is pure crap.",
              "score": 1,
              "created_utc": "2026-01-15 19:05:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzs33o9",
                  "author": "DirkTheGamer",
                  "text": "Ah ok that’s different then.",
                  "score": 1,
                  "created_utc": "2026-01-15 19:05:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzt9pyh",
          "author": "levodelellis",
          "text": "How many lines with the packages?",
          "score": 1,
          "created_utc": "2026-01-15 22:23:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztprl7",
          "author": "lqstuart",
          "text": "Cursor put out a pretty cool blog post on how they wrote their own fp8 kernels for training their model\n\nIt didn’t mention the fact that their model fucking sucks and everyone just uses Claude\n\nThat’s basically “AI” in a nutshell",
          "score": 1,
          "created_utc": "2026-01-15 23:46:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztsk7a",
          "author": "lanthos",
          "text": "Is this just an AI article completing some words about someone making an AI browser",
          "score": 1,
          "created_utc": "2026-01-16 00:01:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzudpa9",
          "author": "nick_storm",
          "text": "Thanks for raising our electricity bill just to develop yet another browser that we don't need.\n\nMaybe next time, you can use all of our water to reinvent Microsoft Teams.",
          "score": 1,
          "created_utc": "2026-01-16 01:58:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzus2nl",
          "author": "Extension-Tap2635",
          "text": "I didn’t know Ed Sheeran is the cursor CEO",
          "score": 1,
          "created_utc": "2026-01-16 03:18:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzusgk0",
          "author": "kevinsyel",
          "text": "3 million lines of code across thousands of files? Yeah that shits breaking AND will be impossible to debug",
          "score": 1,
          "created_utc": "2026-01-16 03:21:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzux6ex",
          "author": "jyf",
          "text": "back to 20 years ago, i use vb6 and that ie component , made myself web browser too :D",
          "score": 1,
          "created_utc": "2026-01-16 03:48:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv1mlh",
          "author": "ThisGuyCrohns",
          "text": "“Kind of works”",
          "score": 1,
          "created_utc": "2026-01-16 04:16:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvqseh",
          "author": "CornedBee",
          "text": "> See, rendering a webpage is not the hard part. The real complexity of a modern browser lives in everything around it, including extensions, password managers, security, accessibility, crash handling, and thousands of edge cases. \n\nUh ... the thousands of edge cases are part of rendering a webpage, and the other stuff isn't the hard part.",
          "score": 1,
          "created_utc": "2026-01-16 07:22:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvy2io",
          "author": "Smooth-Zucchini4923",
          "text": ">See, rendering a webpage is not the hard part. The real complexity of a modern browser lives in everything around it, including extensions, password managers, security, accessibility, crash handling, and thousands of edge cases.\n\nThis is such a strange caveat to add. I don't think that e.g. password management is a particularly hard problem next to correctly rendering a web page. \n\nThe 'thousands of edge cases' part is a fair point - though I would include that in the 'rendering a web page' requirement. After all, if you are satisfied with a browser that can only render a particular page, then the browser can be made quite simple. :)",
          "score": 1,
          "created_utc": "2026-01-16 08:27:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw9aj5",
          "author": "kkania",
          "text": "Some one sentence comments itt are more in-depth than this article",
          "score": 1,
          "created_utc": "2026-01-16 10:11:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwata6",
          "author": "Key_River7180",
          "text": "3M SLoC, written in Rust, and vibe-coded? Scam, 0/10, absolute BS",
          "score": 1,
          "created_utc": "2026-01-16 10:25:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwik27",
          "author": "mua-dev",
          "text": "Did he short his own company ?",
          "score": 1,
          "created_utc": "2026-01-16 11:30:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwsju5",
          "author": "gianni1986",
          "text": "Oh Cursor, the company where you can smell other people's stinky feet because it's part of their company culture.",
          "score": 1,
          "created_utc": "2026-01-16 12:42:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzz1byt",
          "author": "omac4552",
          "text": "So, it builds now. \nhttps://github.com/wilsonzlin/fastrender/actions",
          "score": 1,
          "created_utc": "2026-01-16 19:05:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01clft",
          "author": "Equivalent_Loan_8794",
          "text": "VCs funding these articles smh",
          "score": 1,
          "created_utc": "2026-01-17 02:22:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02dyrf",
          "author": "unsolvedrdmysteries",
          "text": "screw you anthropic!  screw the claude code agentic mode users!  may it agentically send you to hell!",
          "score": 1,
          "created_utc": "2026-01-17 06:49:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02qf7t",
          "author": "MarionberryNormal957",
          "text": "It is literally a scam to say that. The code is just a bad UI with open-source packages doing the real work and clued together with millions lines of unmaintainable rust code.\n\nI would love to see the performance. Many of those libs are not known for performance...\n\nThe problem is that if you are vibecoding an app that needs a browser you would be better of using a webview2 or something already build and if you really need a own browser the ai need to understand that it can't create something like this slop. If you now need to optimize performance and write all 3rd party libs (rendering...) yourself, you can start from green...\n\nThis is the delusional view of ai this days. Yes it can code even complex problems but you can't really use them for real business cases because they are not really production ready.\n\nNobody is making money with those prototypes, but Nvidia and the ai provider...",
          "score": 1,
          "created_utc": "2026-01-17 08:43:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrusdk",
          "author": "ArkBirdFTW",
          "text": "I don’t know why people here are being obtuse and taking this at face value. Nowhere do they claim their agents are ready to autonomously build and deploy production software. It’s a demonstration of current capabilities. 6 months ago there wasn’t a single LLM that could run for a week uninterrupted on a long time scale project. Does no one else here see the rate of progress?",
          "score": -4,
          "created_utc": "2026-01-15 18:29:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw900k",
              "author": "TopBlopper21",
              "text": "Not sure if uninformed or what but as soon as ChatGPT took off, one of the first projects that people started working on was Auto GPT and ChaosGPT\n\n\nThe objectives were to have LLM's run forever on themselves for as long as possible because that should eventually lead to AGI (?)\n\n\nSo you are categorically incorrect about your statement.",
              "score": 1,
              "created_utc": "2026-01-16 10:08:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzx9plb",
                  "author": "ArkBirdFTW",
                  "text": "It was attempted but it was not functional. GPT3 was not capable of long horizon tasks. It could barely code without hallucination in a short term chat setting.",
                  "score": 1,
                  "created_utc": "2026-01-16 14:18:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o000wye",
              "author": "cdb_11",
              "text": "I was genuinely convinced that agents were doing things like this for a year or two now, with similar end results. Isn't it literally what DevinAI was about? If you don't want it to be seen as disappointment, then maybe stop overpromising and overhyping.",
              "score": 1,
              "created_utc": "2026-01-16 21:51:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzubky5",
          "author": "RepresentativeAspect",
          "text": "I don’t understand the criticism.\n\nIt’s an amazing result. So what if the browser doesn’t work? Could you imagine AI doing this five years ago? What can it do for us in another five? What can it do for us now, given the limitations?\n\nHonestly these are really , really great tools and they will only keep getting better.",
          "score": -4,
          "created_utc": "2026-01-16 01:46:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw1y8s",
              "author": "Maybe-monad",
              "text": "You could imagine some LLM spit out millions of lines of code that doesn't work decades ago, LLMs aren't, in fact, new, they're old ideas that were stuck in academic circles because there wasn't hardware powerful enough to implement them.",
              "score": 3,
              "created_utc": "2026-01-16 09:03:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrw6jh",
          "author": "dbbk",
          "text": "To be honest he did way more than he needed to, there's already strong open source foundations for building a browser with eg Electron",
          "score": -4,
          "created_utc": "2026-01-15 18:35:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzt5xbk",
              "author": "Alan_Shutko",
              "text": "I would love to see a browser built on top of Electron which does not simply use the Chromium built into Electron but actually builds a browser from scratch. \n\nMy mind would shatter into pieces and fall to the floor, but it would be a fun way to go.",
              "score": 3,
              "created_utc": "2026-01-15 22:05:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzt64hg",
                  "author": "dbbk",
                  "text": "Why not the Chromium inside Electron? The innovation to be done is in UX, not the rendering engine.",
                  "score": 0,
                  "created_utc": "2026-01-15 22:05:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzs1fac",
          "author": "throwaway490215",
          "text": "I'm a big Code/Codex user and use it all the times. \n\n> The real work begins when they need to remove the “kind of”\n\nLol fuck no - the real work began way up front when they also had to design how to design stuff. The idea that devs are being replaced is marketing slop.\n\nLets be real here: When devs do their job they automate work. The AI guys want to sell the idea that they can replace devs automating work. \n\nSome people say 10x more productive - which i dont believe - but what is obviously true is that devs get 10x more out of using the tools than the average user. Everybody is using it.",
          "score": -2,
          "created_utc": "2026-01-15 18:58:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt4qh6",
          "author": "Lowetheiy",
          "text": "In 3 years, AI will build a better browser than human coded ones, it is inevitable. \n\nEdit: To the Luddite downvoters, 3 years ago AI couldn't even code up CS 101 problems, and now look at how far things progressed. Do not bury your head in the sand, you are missing out on career defining opportunities!",
          "score": -12,
          "created_utc": "2026-01-15 21:59:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzu6ghp",
              "author": "_TRN_",
              "text": "https://xkcd.com/605/",
              "score": 5,
              "created_utc": "2026-01-16 01:17:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzvcovo",
              "author": "Maybe-monad",
              "text": "In 3 years you'll get models trained mostly on AI slop which won't be able to build anything, it's called model collapse",
              "score": 1,
              "created_utc": "2026-01-16 05:30:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzuil0r",
              "author": "suhcoR",
              "text": "Only the possibility of downvoting gives full expression to the worst in people ;-)",
              "score": -6,
              "created_utc": "2026-01-16 02:25:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzs6u3f",
          "author": "MiniGiantSpaceHams",
          "text": "I'm probably going to get downvoted on this sub for this, but people are super missing the point of this, including this article. It's not like they're selling a browser. They very specifically highlighted that it \"kind of\" works. *No one* thinks an AI just built a replacement for browsers that have been developed for 20+ years. It's being labeled an experiment for a reason.\n\nThe point is how much better AI is getting at this. It's not there yet for this kind of scale, obviously, but go try to run this experiment with year-old models and I doubt it would get anywhere close. Now imagine a year from now. That's the point. It's impressive that it worked for a week straight and came up with something reasonable, even if far from perfect.",
          "score": -9,
          "created_utc": "2026-01-15 19:22:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzt03q2",
              "author": "Pharisaeus",
              "text": "> They very specifically highlighted that it \"kind of\" works\n\nOnly that it doesn't even build, and hasn't been for days. It broke almost immediately after agents started working on this and agents were just piling up commits on top of a broken build ever since. You can check for yourself https://github.com/wilsonzlin/fastrender/actions",
              "score": 7,
              "created_utc": "2026-01-15 21:38:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qd3mko",
      "title": "Ken Thompson rewrote his code in real-time. A federal court said he co-created MP3. So why has no one heard of James D. Johnston?",
      "subreddit": "programming",
      "url": "https://substack.com/home/post/p-184599371",
      "author": "Traditional_Rise_609",
      "created_utc": "2026-01-14 23:50:27",
      "score": 572,
      "num_comments": 138,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qd3mko/ken_thompson_rewrote_his_code_in_realtime_a/",
      "domain": "substack.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzo104c",
          "author": "rodrigocfd",
          "text": "> Twenty minutes later, he walked into my office, other end of the same corridor, and said ‘**I can’t read this crap**, come down to the Unix room and tell me what it does.’\n\nIt's interesting to notice how Ken, back in those days, already had no patience for languages he considered \"hard to read\". He rewrote the code in C, which he considered easier to read.\n\nAlmost 20 years later, he had no patience to read C++, and thus Go was created... which, again, he considered easier to read.",
          "score": 89,
          "created_utc": "2026-01-15 03:35:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpcawg",
              "author": "OlivierTwist",
              "text": "To be honest, some C++ constructions aren't easy to beat in \"hard to read\" competition. (And I write/read mostly C++).",
              "score": 34,
              "created_utc": "2026-01-15 10:04:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqc6ii",
                  "author": "more_exercise",
                  "text": "Time to re-peruse [The International Obfuscated C Code Contest](https://www.ioccc.org)! \n\nI like the [donut one](https://www.a1k0n.net/2011/07/20/donut-math.html)",
                  "score": 12,
                  "created_utc": "2026-01-15 14:17:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsi86p",
                  "author": "rodrigocfd",
                  "text": "I work with C++ since 2002, and I've written an unhealthy amount of SFINAE... so, yeah.",
                  "score": 5,
                  "created_utc": "2026-01-15 20:15:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzriwye",
              "author": "NocturneSapphire",
              "text": "C and Go are both easier to read than either Fortran or C++",
              "score": 7,
              "created_utc": "2026-01-15 17:36:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrrqw3",
                  "author": "otherwiseguy",
                  "text": "I mean, of course go is easy to read. Half of it is ```if err != nil```. :p",
                  "score": 8,
                  "created_utc": "2026-01-15 18:15:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzxvw8e",
              "author": "PublicFurryAccount",
              "text": "lol\n\nDeep down I knew that Go had to be created by a man after my own “C is the only legible language” heart.",
              "score": 2,
              "created_utc": "2026-01-16 16:02:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzn0pf1",
          "author": "Deranged40",
          "text": "Same reason people think Edison invented the light bulb, probably...\n\nHe owned a very large and successful business, out-marketed everyone else by a million miles, and claimed for himself the accolades of the people he employed.",
          "score": 333,
          "created_utc": "2026-01-15 00:06:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznqv6m",
              "author": "Ameisen",
              "text": "> and claimed for himself the accolades of the people he employed.\n\nI mean, there are two names on the patent.",
              "score": 31,
              "created_utc": "2026-01-15 02:34:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzothmd",
                  "author": "valarauca14",
                  "text": "Edison & Joseph Swan purchased the rights of another patent (Woodward & Evans). Who were using carbon filaments & evacuated bulbs. While Edison was using inert gas & tungsten.\n\n[Saying one person/group of people 'invented the light bulb'](https://en.wikipedia.org/wiki/Incandescent_light_bulb#Early_pre-commercial_research) really doesn't work as for the better part of 110 years people knew how a lightbulb 'should work' (scientifically speaking) and were routinely demonstrating & patenting them. There wasn't material science, commercial industry, and mass electrical infrastructure to support them",
                  "score": 38,
                  "created_utc": "2026-01-15 07:05:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzonelx",
                  "author": "SlowThePath",
                  "text": "And are any of them household names like Edison?",
                  "score": 7,
                  "created_utc": "2026-01-15 06:14:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nznc45f",
              "author": "yellowseptember",
              "text": "I think it's safe to say at this point that there is no need to use \"probably,\" because it's pretty much established that Edison definitely did not invent the light bulb. He had the foundations for it and simply created something that he was able to market en masse, and he sucked.",
              "score": 37,
              "created_utc": "2026-01-15 01:09:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzngbts",
                  "author": "AdreKiseque",
                  "text": "The \"probably\" was in regard to \"same reason why...\", I believe.",
                  "score": 44,
                  "created_utc": "2026-01-15 01:33:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nznuwod",
                  "author": "Deranged40",
                  "text": "Oh I'm sorry if you interpreted that probably as me questioning whether Edison invented the light bulb. He did not. I felt the rest of my comment made that pretty clear, though.",
                  "score": 16,
                  "created_utc": "2026-01-15 02:58:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nznqtdv",
                  "author": "Ameisen",
                  "text": "> and he sucked.\n\nBased upon? He wasn't any more or less sucky than anyone else at the time, as far as I can tell.\n\nUnless you subscribe to the weird pop history that has arisen around him and Tesla (none of which makes sense) or that he \"stole\" patents.\n\nThe worst thing that he did was engage in the \"War of the Currents\" by killing animals, but even *that's* misrepresented (AC *was* actually less safe especially at the time [thus why he wasn't alone], and people always bring up Topsy even though that was completely unrelated to both the \"War of the Currents\" and Edison).\n\n---\n\nEd: Since [/u/missmuffin__](https://www.reddit.com/u/missmuffin__) blocked me after replying... \n\nName a single patent that he stole. Just one. Just provide a patent number. They're all public.\n\nEvery time someone claims that he \"stole patents\", they are strangely completely unable to actually provide a single example of such a stolen patent.",
                  "score": 6,
                  "created_utc": "2026-01-15 02:34:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzoqlcg",
              "author": "Proper-Ape",
              "text": "I don't think it's the same reason. Edison was a pure POS credit stealer. In this case you had two people converge on the same or similar solution independently. They collaborated, and one of them got more recognition. \n\n\nThey obviously both deserve recognition for it.",
              "score": 7,
              "created_utc": "2026-01-15 06:40:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqhraz",
                  "author": "chasetheusername",
                  "text": ">  They collaborated, and one of them got more recognition. \n\nYup, Brandenburg actually researched this stuff since the beginning of the early 80's, and wrote his dissertation on it. That's far away from Edisons behavior.",
                  "score": 3,
                  "created_utc": "2026-01-15 14:46:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzp45gi",
              "author": "Plank_With_A_Nail_In",
              "text": "Its not really the same, most regular people do not know who any of these people are and probably fall asleep when they are told about them. \n\nAlso people never seem to understand that maybe James D. Johnston doesn't give a shit about any of this and that's why we haven't heard much of him.",
              "score": 2,
              "created_utc": "2026-01-15 08:44:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzntc7o",
              "author": "Supuhstar",
              "text": "Wealthy white English-speaking men tend to get credit over their colleagues",
              "score": -7,
              "created_utc": "2026-01-15 02:48:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzo65pl",
                  "author": "NSRedditShitposter",
                  "text": "Or their wives",
                  "score": 4,
                  "created_utc": "2026-01-15 04:08:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nznas7y",
          "author": "RequirementsRelaxed",
          "text": "Why not make a Wikipedia page for him while you are at it?",
          "score": 42,
          "created_utc": "2026-01-15 01:01:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznq625",
              "author": "Firepal64",
              "text": "\"substack.com\" is not a reliable source, deleted, discussion locked to extended confirmed",
              "score": 29,
              "created_utc": "2026-01-15 02:30:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzp1e58",
                  "author": "guepier",
                  "text": "You should use the same sources underlying the Substack article. They’re reliable and notable.",
                  "score": 16,
                  "created_utc": "2026-01-15 08:18:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzo4ey4",
                  "author": "missmuffin__",
                  "text": "You forgot \"submitted to ArbCom and permanently banned\"",
                  "score": 3,
                  "created_utc": "2026-01-15 03:56:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzn8hhj",
          "author": "javaru",
          "text": "What do you mean by \"in real-time\" here?",
          "score": 78,
          "created_utc": "2026-01-15 00:48:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzn9osw",
              "author": "ggchappell",
              "text": "From the article. Quotes are from Johnston.\n\n> “Ken called me up one noon or so and said ‘send me the damn Fortran code.’ So I did. Twenty minutes later, he walked into my office, other end of the same corridor, and said ‘I can’t read this crap, come down to the Unix room and tell me what it does.’”\n\n> What followed was a live coding session for the ages.\n\n> “He rewrote it in real time while I explained the various functions. A week later, it worked in C, bitwise identical. Then we fixed a few bugs we found along the way, and voila, real-time PAC encoder.”\n\nSo I guess it means that Johnston explained, and Thompson coded, at the same time. (But note that Thompson's code is not said to be working until a week later.)",
              "score": 143,
              "created_utc": "2026-01-15 00:55:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzndg7g",
                  "author": "ElectronRotoscope",
                  "text": "I feel like there's some clarity editing to be done\n\n\nMaybe it's just me, but when it says that Ken Thompson rewrote his code, my first reading was \"it wasn't up to snuff, and needed a rewrite\" but instead it seems to be meant to say \"Ken Thompson was intimately familiar with the algorithms involved, having been the one to translate them from Fortran to C\"\n\n\nThere's also the issue that it first says Johnson was declared a co-inventor of MP3, and then in the next sentence it's the bit about Ken Thompson calling it \"vastly superior\".\n\n\nMy first read of that whole bit was \"Ken Thompson rewrote Johnson's substandard code, and once Ken Thompson was done rewriting it Ken Thompson said the new code was vastly superior to Johnson's code, which is MP3\"\n\n\nBut after going over it a few times and reading this, I think what the author intended to convey was \"Johnson's invention was so integral to MP3, a court credited him as a co-author (even though Johnson wasn't involved in the product called MP3, just the tech behind it). And that even such a luminary of Ken Thompson said that Johnson's implementation of the core tech was superior to the MP3 implementation. Ken Thompson should know, since it was Ken Thompson that translated it from Fortran to C\"",
                  "score": 77,
                  "created_utc": "2026-01-15 01:16:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzo25dl",
                  "author": "McGlockenshire",
                  "text": "> I can’t read this crap, come down to the Unix room and tell me what it does.\n\nSoftware people looking at science people's fortran and going WHAT THE FUCK: a tale apparently as old as time.",
                  "score": 38,
                  "created_utc": "2026-01-15 03:42:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzp56k1",
                  "author": "aanzeijar",
                  "text": "Ah yes, the real-time rewrite that only works a week later. If we got a cookie for every one of those.",
                  "score": 7,
                  "created_utc": "2026-01-15 08:54:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzr2e2g",
                  "author": "Suppafly",
                  "text": "These sorts of stories aren't actually how most events happen though, they are how someone years later describes something to simplify it to an audience when telling a story.",
                  "score": 6,
                  "created_utc": "2026-01-15 16:21:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzn9i9w",
              "author": "_xiphiaz",
              "text": "Presumably it means not by email. Could be in person or on the phone",
              "score": 3,
              "created_utc": "2026-01-15 00:54:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzogkl0",
          "author": "flukus",
          "text": ">AT&T even had a working iPod competitor in 1998,\n\nThis is less impressive than it sounds. The first commercial MP3 player was released in 1998, 3 years before the iPod was released into a crowded market.\n\nThe ipod had no wireless, less space than a nomad, lame!",
          "score": 24,
          "created_utc": "2026-01-15 05:20:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrmej4",
              "author": "aaaantoine",
              "text": "I understood that reference.",
              "score": 3,
              "created_utc": "2026-01-15 17:51:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzn9fso",
          "author": "ggchappell",
          "text": "He doesn't seem to have a Wikipedia page, either.",
          "score": 18,
          "created_utc": "2026-01-15 00:53:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzq5b2r",
          "author": "ExoticMandibles",
          "text": "Oh, there's even more to the story.  JJ was also behind AAC, which I'd describe as \"what MP3 should have been in the first place, except for politics\".\n\nsource: I know JJ personally, I own speakers hand-assembled by him",
          "score": 16,
          "created_utc": "2026-01-15 13:40:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqd4co",
              "author": "SkoomaDentist",
              "text": "People forget how bad MP3 was before Lame and other modern style encoders were hand tuned to work around the format's limitations.\n\nAAC got rid of the idiotic time-domain subband filterbank (which people in the know say was voted in there by a company who had their own competing codec they wanted to promote), equally idiotic SFB21 limitation and short term bitrate limit as well as made long blocks longer (for better coding efficiency) and short blocks shorter (to better avoid pre-echo).",
              "score": 7,
              "created_utc": "2026-01-15 14:22:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nznvklr",
          "author": "VictoryMotel",
          "text": "I don't know the name of who invented mp3s either.",
          "score": 16,
          "created_utc": "2026-01-15 03:01:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznyuiy",
          "author": "my_password_is______",
          "text": "> Brandenburg became famous. \n\nLOL, uh, no",
          "score": 31,
          "created_utc": "2026-01-15 03:21:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpfz57",
              "author": "kairos",
              "text": "He even has a gate named after him in Berlin.",
              "score": 13,
              "created_utc": "2026-01-15 10:38:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzpn0xh",
                  "author": "hoppla1232",
                  "text": "bruh",
                  "score": 5,
                  "created_utc": "2026-01-15 11:39:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzopiz1",
              "author": "Ran4",
              "text": "Exactly, Ken Thompson is much much more famous as the one implementing mp3 (...as well as other things lol)",
              "score": 13,
              "created_utc": "2026-01-15 06:31:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o02y00w",
              "author": "obrhoff",
              "text": "I know him personally. Yep he did not get famous or rich. It was his PhD work and the work belonged to the Frauenhofer Institute.\n\nAfaik several people were working on the idea and it was just a matter of time.",
              "score": 2,
              "created_utc": "2026-01-17 09:55:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzp3yjz",
          "author": "Plank_With_A_Nail_In",
          "text": "Why does it have to be a conspiracy James D. Johnston probably just isn't an ego manic asshole and just wants a quite life.",
          "score": 6,
          "created_utc": "2026-01-15 08:42:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzphv6h",
              "author": "wosmo",
              "text": "Newton famously said \"If I have seen further it is by standing on the shoulders of giants\", and if anything modern technology has made that more relevant, not less.  Almost any development you care to point at, is built on the foundation of others.\n\nNo matter what technology you try to describe, you'll leave someone out - you pretty much have to.  Otherwise the invention of mp3 starts with Ugh the Elder bashing two rocks together.",
              "score": 6,
              "created_utc": "2026-01-15 10:55:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzr5nrc",
          "author": "Nine99",
          "text": "> AT&T even had a working iPod competitor in 1998, killed it because \"nobody will ever sell music over the internet,\"\n\nThe iPod wasn't a thing until 3 years later. What was a thing in 1998 is the Rio, which was well-known.",
          "score": 5,
          "created_utc": "2026-01-15 16:36:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt3rvf",
          "author": "gresendial",
          "text": "> Ken Thompson rewrote his code in real-time. A federal court said he co-created MP3. So why has no one heard of James D. Johnston?\n\nWhat an odd title.  Ken Thompson plays a very minor role in the whole story.",
          "score": 3,
          "created_utc": "2026-01-15 21:54:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzywd8y",
              "author": "Traditional_Rise_609",
              "text": "Fair point - that title is poorly phrased. The way it reads, it sounds like Thompson co-created MP3, which isn't what the article says at all.\n\nThompson rewrote Johnston's *PAC* codec (a different, competing codec he called \"vastly superior to MP3\"). The federal court statement about co-creating MP3 refers to Johnston and *Brandenburg* working together.\n\nTwo separate facts got jammed together in a way that's confusing. The Thompson angle is a colorful sidebar - a Bell Labs legend validating Johnston's work - but you're right that it's not central to the MP3 story itself. The real headline is the Johnston-Brandenburg collaboration that got erased from popular history.\n\nThanks for the catch.",
              "score": 1,
              "created_utc": "2026-01-16 18:43:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzz552q",
                  "author": "Traditional_Rise_609",
                  "text": "My bad for a poorly worded title.",
                  "score": 1,
                  "created_utc": "2026-01-16 19:22:55",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nznx9u4",
          "author": "chucker23n",
          "text": "The article mentions perceptual coding, but doesn’t mention MP2 (which had perceptual coding as well), so — only having skimmed it — I assume it doesn’t really address what MP**3** specifically had as its innovation.",
          "score": 6,
          "created_utc": "2026-01-15 03:12:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzo9j42",
              "author": "barsoap",
              "text": "MP3 is not derived from MP2. The latter was developed for digital radio by a consortium of Phillips and German broadcasters, the former by Fraunhofer specifically for inclusion in the MPEG standards. MP3 compresses harder at equivalent quality but is also more computationally intensive.\n\nThe MPEG-1 standard includes both, plus MP1 which is a variant of MP2 using even fewer resources.",
              "score": 8,
              "created_utc": "2026-01-15 04:30:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzq1qgy",
                  "author": "chucker23n",
                  "text": "Right. I guess I'm saying I wish the article got into that a little more.",
                  "score": 5,
                  "created_utc": "2026-01-15 13:20:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzqb90j",
                  "author": "SkoomaDentist",
                  "text": "> MP3 is not derived from MP2\n\nIt is. MP3 specifically includes very similar (if not exactly identical - I can't recall) time-domain subband filter as a mandatory part of the encoding pipeline before the MDCT transform even though this subband filter is completely superfluous (and in fact harmful) in a transform codec. AAC got rid of this subband filter and thus aliases less between subbands.",
                  "score": 3,
                  "created_utc": "2026-01-15 14:12:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nztg5ub",
          "author": "TillWinter",
          "text": "All of this is not true in the way it is presented here. It is like so many other stories distorted in favor of the present americans.\n\nAll the science behind this psycho acoustic analysis started in 1982 in Nürnberg-Erlangen under Musmann. Brandenburg did his doctorate there. Bell-Lab as well as Thompson \"just\" sponsored the program.\n\nTo fully understand the implications you need to understand the german scientific system. Most data and concepts, already done work by students were send to the company's as in the agreement. Alsmost all of the hard work was already finished by the germans. \n\nThe rest was production ready codex and standarts design. An extremly hard endeavor on its own, which should be applauded on its own. But to force this narratives, as well as the typical american lawsuit should be put in its correct context.\nThe context, American always clam ownership.\n\nWhile we are at it:\n\nNO the internet as a concept or first implementation is not American, its france, like the modern chip card. Arpa was just one of the networks. The Russian had one too, before they killed one of the most advanced systems because of infighting in the early 70s. Russia had a cybernetic model of train logistics and production systems like todays industry 4.0 models. \n\nThe first programmable computer is a Zuse, whose patents and designs were stolen by the allies after the war and given to IBM. There are still many artefacts in the first American programlanguage from Zuses design, presented as new inventions.",
          "score": 5,
          "created_utc": "2026-01-15 22:55:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzyw0xs",
              "author": "Traditional_Rise_609",
              "text": "I think you may have misread the piece. The article explicitly states:\n\n>\n\nThe entire point is that MP3 was a *transatlantic collaboration* \\- not an American invention. The article quotes Brandenburg himself acknowledging he worked at Bell Labs with Johnston, and it credits Brandenburg extensively throughout.\n\nWhat the article corrects is the narrative that Brandenburg was the *sole* inventor - the \"lone genius\" framing that Fraunhofer's marketing has promoted. The IEEE calls Johnston \"the father of perceptual audio coding\" and a federal court stated both men \"together\" created the standard. Brandenburg's own interviews confirm this.\n\nAs for Ken Thompson - he didn't \"sponsor\" anything. He personally rewrote Johnston's PAC codec (a different codec, not MP3) from Fortran to C. That's not funding, that's engineering.\n\nThe Erlangen work under Musmann was foundational - no one disputes that. But Johnston had working perceptual coding software in 1987, documented under oath in court records. Both streams of research mattered. That's the point.\n\nI'd gently suggest the Zuse and ARPANET tangents aren't really relevant to whether Johnston's contributions to MP3 have been overlooked - which the documentary evidence clearly shows they have been.",
              "score": 0,
              "created_utc": "2026-01-16 18:42:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzzdgi9",
                  "author": "TillWinter",
                  "text": "Same as it ever was...\n\nLook. Before I awnser here are my failings in that post above.\n\n- I wrote in a hast on the toilet, I fucked up grammar, orthography and in part cohesive ordering. English being my 2nd language.\n- I used Thompson as a reference, I meant the france company not the person\n- to explain all the intricate details I needed to write way more, but I choose to summarize in an equally superficial way\n\nOn to your reaction:\nThere is a motivation why I even bothered to write in an day old post like this.\n\nMainly the annoyance with the ever repeating distortion of history. Again and again Media such as this reframes collectiv human efforts in a way that frames a limited number of people as sole magician of the new arcane. But thats seldom enough, there is also the need to nationalize the narrative. To force it down and bind it to a perversed limited view.\n\nHere you posted a story of a man left with limited notice to his efforts. Being exclude from the grand narrative stated before.\n\nWhat I was trying to express was that this grand narrative in itself was flawed and wrong in the way it was presented. To my that story is part of a collection of storie: \"the broad and superficial self gradulation of the american mind\".\n\nAgain and again, when any form of Kopernican Revolution are changing the views of an topic, here the encoding of sound,  an intrusive narrative is spune. An american side character takes center stage, saving the day. Almost always independent of what really happend. Missing all the little people who actually planed and build the pyramids.\n\nHere an extraordinary massive part of the actual science was done by drone like minons in the university of erlangen. 4th semester students, to diplomstudents. Helpers helper. All put together, orchestrated by Musmann, long before any Idea of a standard. The collaboration was born because of ISDN. Thats why the france and the bell labs wanted in. Super cheap digital telephony over glass fiber. The music part was an addition for phone loops. Nothing more. Thats where it started. \n\nThey needed Musmanns expertise, got the data long before starting themselves. And building on that.Alot of the really hard bits were already found solutions for, what was left was variations.\n\nAs for the american judicial system in question of inventions. Its has a  horrible history winning liars and cheater. Stealing from all over the world, silencing the true owner. I have no idea what exactly this lawsuit was realy about. But I know that all the titles an accolades are not as earned as presented.\n\nI hope you can follow now why Zuse and the digital network had its place here.\n\nAnd also the other reasion I was annoyed, triggered even, by the article:\n\nI had a stind of 1 semester as an post doc at erlangen. I was brought to a alumni after party in the late 2000s. There I had the pleasure to listen to the stories of the small people, the greavens over the absolut arrogance of the bell lab people. How the bell lab people seemed to be under so much pressure that they constantly tried to reframe ideas of the team as their own. That some diploma final works had to be scraped because the ideas and data was already published without respectfull communication. How the france company was basically fobbed out of millions, thanks to the american way of working. How many were disillusioned by working with so called the best of the best, because some of the stars beyond the pond couldnt even build the experiments correctly without stealing from 22 year old german nobodies who just got pennies because it was just an helper job.\n\nAs my own jorney later on brought me to surprisingly simular realisations. I worked with almost matha-magical indians, chinese, russian and other europeans who had to work with  american companies and universities. \n\nThe pure horror of the in part abysmal differences in competence are still personal horror stories. A few of which are public known by many as grand american successes.\n\nAnd so. Same as it ever was.",
                  "score": 1,
                  "created_utc": "2026-01-16 20:01:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzpu12z",
          "author": "Big_ifs",
          "text": "clickbait, there's no story here. Perceptual audio coding was not invented by one individual (almost nothing ever is), but by a group of engineers. This is even more obvious in the case of mp3, as it was clearly developed by the Moving Picture Experts Group, which is where mp3's very name originated.",
          "score": 4,
          "created_utc": "2026-01-15 12:31:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqdgs8",
              "author": "SkoomaDentist",
              "text": "> as it was clearly developed by the Moving Picture Experts Group\n\nIt was _standardized_ by MPEG. All MPEG standards are essentially just combinations of features developed by independent companies and researchers that are then hacked together into a common bitstream format in the committees.",
              "score": 9,
              "created_utc": "2026-01-15 14:24:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzz4guw",
              "author": "Traditional_Rise_609",
              "text": "You're agreeing while thinking you're disagreeing with the article.\n\nThe whole point is that MP3 *was* a collaborative effort - including Johnston's contributions at Bell Labs. The problem is the popular narrative *doesn't* treat it that way. Brandenburg gets profiled as \"the inventor of MP3\" in mainstream press, inducted into the Internet Hall of Fame, treated as the lone genius.\n\nIt explicitly states: \"Neither can claim sole invention.\"\n\nIf the public understanding was already \"this was developed by a group of engineers at MPEG,\" there'd be nothing to write. The story is that one collaborator became famous and the others - particularly Johnston, whose psychoacoustic models are in the standard and who hosted Brandenburg at Bell Labs during development - got written out of the popular narrative.\n\nYou're right that \"group of engineers\" is the accurate history. That's the point.   \n  \nThe clickbait version is \"Brandenburg invented MP3\" -which is what most people believe.",
              "score": 2,
              "created_utc": "2026-01-16 19:19:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o00e4a8",
                  "author": "Big_ifs",
                  "text": "Fair enough. But how present is Brandenburg in \"mainstream media\"? Besides that one book about the history of music piracy, which is massively overrated and stylizes Brandenburg as some subversive proto-pirate (which couldn't be further from the truth - internet media piracy was never even an afterthought of anyone who worked on compression algorithms), I don't see a mainstream narrative about the invention of mp3 at all. It's not like the public could name more than 3 inventors of any modern technology anyway.\n\nI admit that I stopped reading the article when I encountered the statement that \"JJ is as much of a rockstar as anyone we’ve ever featured on this show.\" To me, this is a misrepresentaion of the work and the self-image of engineers that makes them look like some bad-ass Hollywood characters. I'm not interested in such narratives.",
                  "score": 1,
                  "created_utc": "2026-01-16 22:57:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzr0toy",
          "author": "Suppafly",
          "text": "> The IEEE calls Johnston \"the father of perceptual audio coding\" but almost no one knows his name.\n\nAlmost know one knows the names of any of the inventors of the things they use. And even when they do know some inventor's name, it's often because of a propaganda campaign that oversells the inventor's actual contributions.",
          "score": 2,
          "created_utc": "2026-01-15 16:14:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztyrnj",
          "author": "splicer13",
          "text": "JJ is well known in the field and Brandenburg isn't exactly famous.  Good writeup but I question the premise.",
          "score": 2,
          "created_utc": "2026-01-16 00:35:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzywquf",
              "author": "Traditional_Rise_609",
              "text": "That's a fair distinction. Within the audio coding community - AES, IEEE, MPEG working groups - you're right that JJ is well known and respected. The premise is really about *popular* tech history: the Wikipedia articles, the \"who invented MP3\" Google results, the Internet Hall of Fame induction, the mainstream tech journalism narratives.\n\nWhen Gizmodo or Wired or NPR tells the MP3 story, it's typically framing Brandenburg as the lone inventor. When the general public has heard of anyone, it's always Brandenburg. That's the imbalance the piece is addressing - not recognition among peers who actually work in the field.\n\nProbably should have been clearer about that distinction. Thanks for the pushback.",
              "score": 1,
              "created_utc": "2026-01-16 18:45:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzu49r1",
          "author": "mtechgroup",
          "text": "Does anyone know the URL of the author's original podcast?",
          "score": 1,
          "created_utc": "2026-01-16 01:05:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzyvcvb",
              "author": "Traditional_Rise_609",
              "text": "Rogues' Gallery? I took those offline a while ago, but some episodes still exist in the wild. ;-)",
              "score": 1,
              "created_utc": "2026-01-16 18:39:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzv0z3s",
          "author": "bascule",
          "text": "This article is total bullshit. Perceptual codecs using the Modified Discrete Cosine Transform that actually underpins MP3 were being worked on over a decade prior to 1988:\n\nhttps://en.wikipedia.org/wiki/Modified_discrete_cosine_transform\n\n> The discrete cosine transform (DCT) was first proposed by Nasir Ahmed in 1972,[11] and demonstrated by Ahmed with T. Natarajan and K. R. Rao in 1974.[12] The MDCT was later proposed by John P. Princen, A.W. Johnson and Alan B. Bradley at the University of Surrey in 1987,[13] following earlier work by Princen and Bradley (1986)[14] to develop the MDCT's underlying principle of time-domain aliasing cancellation (TDAC) as the core component of an analysis/synthesis filter bank system. TDAC provided efficient critically sampled representations for subband coding applications. Building on this, a 1987 refinement by Princen, A. W. Johnson, and Bradley proposed the \"oddly stacked\" MDCT configuration, which became the predominant form due to its computational efficiency and suitability for real-valued signals",
          "score": 1,
          "created_utc": "2026-01-16 04:11:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzyxwn9",
              "author": "Traditional_Rise_609",
              "text": "You're conflating two different things. The MDCT is a mathematical transform - a way to convert audio into the frequency domain. Perceptual coding is about psychoacoustic modeling - figuring out what audio data the human ear can't perceive so you can discard it.\n\nMP3 uses both. The article explicitly addresses this:\n\n>\n\nSo you're actually reinforcing the article's point. The MDCT came from Princen, Johnson, and Bradley at Surrey. Brandenburg brought that to Bell Labs. Johnston contributed the psychoacoustic models. The combination became MP3.\n\nNobody is claiming Johnston invented the MDCT. The IEEE calls him \"the father of *perceptual* audio coding\" - the masking thresholds and psychoacoustic analysis that determine what bits you can throw away. That's a different contribution than the transform itself.",
              "score": 2,
              "created_utc": "2026-01-16 18:50:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzz7m16",
          "author": "Traditional_Rise_609",
          "text": "OP here. This thread has been incredibly useful - thank you all for the engagement, including the pushback.\n\nA few things I'm taking away:\n\n**The title was really bad.** Several of you pointed out it reads like Thompson co-created MP3. He didn't - he rewrote Johnston's PAC codec (a different, competing codec). The federal court statement is about Johnston and *Brandenburg* together creating MP3. Two separate facts got mashed together. *My bad. Reddit won't let me fix the title, only the body - ugh*.\n\n**I should have been clearer about audience.** Multiple commenters noted that JJ is well known in the audio coding community - AES, IEEE, MPEG circles. That's true. The article is addressing the *popular* narrative: Wikipedia, mainstream tech journalism, the \"who invented MP3\" Google results. Among peers, Johnston is respected. In public tech history, he's largely absent while Brandenburg gets the \"lone inventor\" treatment.\n\n**The MDCT point is in the article, but could be clearer.** Johnston contributed psychoacoustic modeling; Brandenburg brought MDCT from the Surrey work. The article says \"Brandenburg brought MDCT; Johnston brought perceptual modeling. Neither had the complete picture alone.\" But I can see how that got lost.\n\nI will update the doc to address these points. Also got a comment from Howie Singer, who was actually *at* a2b and wrote a book on it - so there's more to dig into there!\n\nAppreciate the corrections and the good-faith debate. This is how tech history should get refined.",
          "score": 1,
          "created_utc": "2026-01-16 19:34:22",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nznrqlo",
          "author": "DocMcCoy",
          "text": "Stop trying to rewrite history and plugging random USians everywhere",
          "score": -4,
          "created_utc": "2026-01-15 02:39:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpehpn",
          "author": "terem13",
          "text": "thanks, very interesting story. As always, progress is often defined by irrational people motives.",
          "score": 0,
          "created_utc": "2026-01-15 10:24:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzp0sp3",
          "author": "mgedmin",
          "text": "Another case of [Stigler's Law](https://en.wikipedia.org/wiki/Stigler%27s_law_of_eponymy).",
          "score": 0,
          "created_utc": "2026-01-15 08:12:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzr7d36",
              "author": "Nine99",
              "text": "No.",
              "score": 1,
              "created_utc": "2026-01-15 16:44:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzpc6vv",
          "author": "Careless-Score-333",
          "text": "I thought MP3 was just a Fast Fourier Transform?",
          "score": 0,
          "created_utc": "2026-01-15 10:03:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpfa83",
              "author": "aanzeijar",
              "text": "Not an expert, but they do some really fancy tricks with noise shaping to move it to frequencies where the human ear is less perceptive. If you look at the raw bitrate and compare it with the dynamic range, you'll notice that mp3 has a few dB more dynamic range than the bitrate should allow for.",
              "score": 7,
              "created_utc": "2026-01-15 10:32:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzpmpgc",
                  "author": "Careless-Score-333",
                  "text": "Awesome.  I should have known better than to doubt Ken Thompson.  A lot of supporting work outside of the central maths, goes into file format specs too.  Not just headers.",
                  "score": 2,
                  "created_utc": "2026-01-15 11:36:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzqe6vt",
              "author": "SkoomaDentist",
              "text": "MP3 is based on MDCT (like AAC), not FFT. Fourier transform is only used as part of the (intentionally not standardized) psychoacoustics models.\n\nFourier transform is great for analysis but horrible for manipulation because any manipulation besides fixed gain causes discontinuity artifacts at block edges. MDCT improves significantly on that by having the blocks overlap so that there are no discontinuities when the transformed data is manipulated (by quantization).",
              "score": 3,
              "created_utc": "2026-01-15 14:27:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzwyhii",
                  "author": "Careless-Score-333",
                  "text": "Great to know.  Thankyou.",
                  "score": 1,
                  "created_utc": "2026-01-16 13:18:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzn4zd1",
          "author": "astrange",
          "text": "It's not hard to be superior to MP3. It's overcomplicated for no reason and the complex features made it worse, not better.",
          "score": -28,
          "created_utc": "2026-01-15 00:29:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzn8gf3",
              "author": "oliyoung",
              "text": "Yeah, and that's why in the 30 years since it was developed it's been surpassed, we even had much better options within a few years (OGG etc)\n\nBut at the time in the mid 90s \"compressing\" a 30mb+ audio file to something listenable for 1/10th the size was revolutionary on those of us with 56kb modems\n\nIt wasn't perfect, it was the start",
              "score": 38,
              "created_utc": "2026-01-15 00:48:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nznkfyx",
                  "author": "happyscrappy",
                  "text": "I couldn't even play mp3s on my computer at the start. At least ones which were encoded at bitrates high enough for music. Decoding them was too complicated. MP3 was certainly pretty exciting at the start.",
                  "score": 6,
                  "created_utc": "2026-01-15 01:57:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nznsohd",
                  "author": "astrange",
                  "text": "Vorbis was also a pretty complicated codec to implement, which is why it had poor hardware support.\n\nAAC is simpler than MP3 and better. Opus is… hmm I'm not sure if it's simpler than AAC, but it is again better and the current best codec.",
                  "score": 2,
                  "created_utc": "2026-01-15 02:44:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nznssq6",
              "author": "astrange",
              "text": "What a strange comment to get downvoted. People must love quadrature mirror filters. And the scalefactor 31 which is missing for no reason, ensuring you can't encode cymbals at any quality!",
              "score": -3,
              "created_utc": "2026-01-15 02:45:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzo2orh",
                  "author": "oliyoung",
                  "text": "It's the way you appeared to dismiss the *work*, without showing you understood the *context*\n\nBecause, yes in the context of audio encoding **in 2026** no-one is rationally using MP3 and yes it's overly complicated and complex, but this article is about the importance of the development of the codec **in the early 1990s.**\n\nIt's like a conversation I regularly have with my teenagers. Yes, 90s video games look and play like trash *now*, but back *then* **in context** those games were mind-blowingly good\n\nHindsight is 20/20, and not acknowledging that makes you sound like you're dismissing one of the biggest practical technological leaps in our lifetimes",
                  "score": 10,
                  "created_utc": "2026-01-15 03:45:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzn2lgl",
          "author": "supasamurai",
          "text": "I got bad news, dog.  nobody knows who any of these people are.",
          "score": -76,
          "created_utc": "2026-01-15 00:16:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzn3z0l",
              "author": "pdpi",
              "text": "\"Any of these people\"? Ken Thompson is a freaking legend.",
              "score": 59,
              "created_utc": "2026-01-15 00:24:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzn53c9",
                  "author": "supasamurai",
                  "text": "if you took 100 people off the street 100 of them will not know who any of these people are. I don't even understand what part he plays here.  is he edison in this scenario?",
                  "score": -63,
                  "created_utc": "2026-01-15 00:30:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzngd7w",
              "author": "feketegy",
              "text": "you are confidently incorrect",
              "score": 11,
              "created_utc": "2026-01-15 01:33:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nznk71r",
                  "author": "supasamurai",
                  "text": "keep tellin yourself that, nerd",
                  "score": -8,
                  "created_utc": "2026-01-15 01:55:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nznnh2c",
              "author": "Irregular_Person",
              "text": "Ken Thompson invented Unix, dog. Ever used a cell phone? the internet? Thank that guy for laying the groundwork. He literally invented the way the text on your screen is stored.",
              "score": 7,
              "created_utc": "2026-01-15 02:14:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nznp5a5",
              "author": "TankorSmash",
              "text": "I'd say most programmers are familiar with the name Ken Thompson, certainly anyone who went to school for it",
              "score": 5,
              "created_utc": "2026-01-15 02:24:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzo3xak",
              "author": "oliyoung",
              "text": "Ken Thompson is *maybe* the single most influential software engineer ... ever\n\nThe man created UNIX, UTF, ed, C **and** golang (and arguably the MP3 codec)\n\nIf *you* don't know who he is, that's a *you* problem, because you're the direct beneficiary of A LOT of his work",
              "score": 4,
              "created_utc": "2026-01-15 03:53:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzo7szh",
                  "author": "supasamurai",
                  "text": "I never said I didn't know who he was, there's no reason to get all butthurt.",
                  "score": -7,
                  "created_utc": "2026-01-15 04:19:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzn3gfu",
              "author": "supasamurai",
              "text": "also, what other speed are you supposed to code at besides real-time?",
              "score": 8,
              "created_utc": "2026-01-15 00:21:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzoj3ij",
                  "author": "cgoldberg",
                  "text": "I do a sort of two-step with syncopated typing on off beats.",
                  "score": 6,
                  "created_utc": "2026-01-15 05:39:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzn4of6",
                  "author": "Crowley-Barns",
                  "text": "Two hands, two halves of a brain: double time!\n\n(10 fingers; infinitely divisible brain… 10x. (Or maybe I’m logarithmic, baby!))",
                  "score": 2,
                  "created_utc": "2026-01-15 00:27:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nznk0to",
                  "author": "happyscrappy",
                  "text": "Yeah. Anything that happens happens in real time. The idea of other than real-time is when you are reviewing something that happened in the past.\n\nOn a more snarky front I feel compelled to say that translating FORTRAN to C rapidly is a lot easier if you delay for a week the constraint that it has to work. Isn't that more like \"taking a week to convert an algorithm from FORTRAN to C\"? Which still is not bad at all for a non-trivial algorithm.",
                  "score": 2,
                  "created_utc": "2026-01-15 01:54:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzn30y4",
              "author": "hereswhatipicked",
              "text": "Even after reading the above I’m still not sure who got credit and who was forgotten.",
              "score": 8,
              "created_utc": "2026-01-15 00:19:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qci8z5",
      "title": "LLMs are a 400-year-long confidence trick",
      "subreddit": "programming",
      "url": "https://tomrenner.com/posts/400-year-confidence-trick/",
      "author": "SwoopsFromAbove",
      "created_utc": "2026-01-14 08:43:49",
      "score": 508,
      "num_comments": 329,
      "upvote_ratio": 0.75,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qci8z5/llms_are_a_400yearlong_confidence_trick/",
      "domain": "tomrenner.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzk8shc",
          "author": "robhaswell",
          "text": ">despite it being common knowledge that they hallucinate frequently.\n\nNot common knowledge, not even nearly. Your average retail user MAY have read the warning \"AIs can make mistakes\" but without knowing how they work I'd say it's difficult to understand the ways in which they can be wrong. You see this on posts to r/singularity, r/cursor etc all the time, and outside of Reddit I bet it's 100x worse.",
          "score": 49,
          "created_utc": "2026-01-14 16:21:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzu9j09",
              "author": "ConceptJunkie",
              "text": "I subscribed to to r/singularity briefly, but it mostly seemed like a cult for dumb people.",
              "score": 5,
              "created_utc": "2026-01-16 01:35:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzulk6j",
                  "author": "robhaswell",
                  "text": "You can have an upvote for that",
                  "score": 1,
                  "created_utc": "2026-01-16 02:42:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzz90gu",
                  "author": "EnchantedSalvia",
                  "text": "It was a dumb place a year ago but got better recently as more reasonable and moderate voices entered, all the crazies went to r/accelerate ",
                  "score": 1,
                  "created_utc": "2026-01-16 19:40:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o00886s",
              "author": "Intrepid-Stand-8540",
              "text": "Yeah. Everyone I've talked to IRL that is not a programmer, thinks AI is always correct. Very scary.",
              "score": 1,
              "created_utc": "2026-01-16 22:27:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzj1op8",
          "author": "Smallpaul",
          "text": "The article mocks OpenAI for being slow to release GPT-3 because OpenAI was concerned about it being abused. The article claims that OpenAI was lying because LLMs are safe and not harmful at all. \n\n> The rhetoric around LLMs is designed to cause fear and wonder in equal measure. GPT-3 was supposedly so powerful OpenAI refused to release the trained model because of “concerns about malicious applications of the technology”.\n\nIt also links to the GPT-3 [announcement](https://openai.com/index/better-language-models/) where OpenAI said that they were reluctant to release it. \n\nWhy were they reluctant?\n\n“We can also imagine the application of these models for malicious purposes⁠, including the following (or other applications we can’t yet anticipate):\n\nGenerate misleading news articles\n\nImpersonate others online\n\nAutomate the production of abusive or faked content to post on social media\n\nAutomate the production of spam/phishing content\n“\n\nGood thing those fears were so overblown! Turns out those liars at OpenAI claimed we might end up a world filled with blog spam and link spam and comment spam but good thing none of that ever happened! It was all just a con, and there were no negative repercussions to releasing the technology at all!",
          "score": 324,
          "created_utc": "2026-01-14 12:35:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzl489k",
              "author": "ii-___-ii",
              "text": "And yet they still released it...",
              "score": 10,
              "created_utc": "2026-01-14 18:42:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzleibr",
                  "author": "Smallpaul",
                  "text": "What would you have done? Especially with the knowledge that competitors are working on the same thing?",
                  "score": -5,
                  "created_utc": "2026-01-14 19:28:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzk5oax",
              "author": "bduddy",
              "text": "I mean they obviously don't actually care about any of that. We should not be taking what they say at face value.",
              "score": 33,
              "created_utc": "2026-01-14 16:07:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzl76pl",
                  "author": "Smallpaul",
                  "text": "Okay, so if they didn’t care about any of that then why wouldn’t they our GPT-3 out into the world and start making money from it as quickly as possible?",
                  "score": -11,
                  "created_utc": "2026-01-14 18:55:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzjcg4p",
              "author": "qubedView",
              "text": "And how dare they make an attempt to take responsibility for a new technology they created which they don’t yet understand!",
              "score": 64,
              "created_utc": "2026-01-14 13:41:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzmk8q2",
                  "author": "Xirious",
                  "text": "That sure lasted a long time.",
                  "score": 14,
                  "created_utc": "2026-01-14 22:39:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzkbx2q",
                  "author": "txmail",
                  "text": "> they created\n\nDid they though? Seems like this stems from tech created in the late 70's and 80's during the first AI bubble. We have done this before, we are just repeating it again but with more hardware and the bubble is much bigger this time. Look at the history of the Symbolics Corporation for a geeky history lesson.\n\nIf we got anything out of this bubble it is better compression techniques for raw text... though it is completely destructive and irreversible and actually is not compression at all (tokenization)... \n\nActually I am not sure what this AI bubble has given us that we did not have from the 80's. Just the same shit done faster. Full text search is still better than a LLM when you need to cite sources / find the original content or want actually relevant results not crawled a year ago. \n\nReally the coolest shit is being done with machine learning, especially the computer vision side that lets us spot cancer in images or identify birds or bird songs. Even google knows this, and it is why you have to click the blocks with a motorcycle on pages to identify your not a robot, when really your helping tag objects for their computer vision models.",
                  "score": -18,
                  "created_utc": "2026-01-14 16:35:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzjxqgo",
              "author": "splork-chop",
              "text": "> Good thing those fears were so overblown!\n\nIn the context of the article the author is correct.  The AI money bros and technologists have been rabidly saying all sorts of inflammatory nonsense about how they're 'scared' of AI and how dangerous it will become.  This fits into the main point of the article in that these people are being intentionally disingenuous to stoke fear so that people pay attention and get sucked into the scam. If the AI fearmongers just said \"well of course you might get some extra email spam or fake social media posts\" no one would pay attention.  OpenAI and others are clearly taking advantage of this climate of fear by suggesting they might have to delay or gimp their software because \"oh no what might happen.\" Either that or the're bullshitting to justify release delays.",
              "score": 59,
              "created_utc": "2026-01-14 15:31:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzmdahj",
                  "author": "AlSweigart",
                  "text": "> all sorts of inflammatory nonsense about how they're 'scared' of AI and how dangerous it will become.\n\nThey want people talking about how AI will bring prosperity and profits. They also want people talking about how AI could cause a robot revolution against humanity.\n\nThey don't want people talking about how AI is boring and doesn't live up to the hype.",
                  "score": 13,
                  "created_utc": "2026-01-14 22:06:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzl271m",
                  "author": "drekmonger",
                  "text": "> The AI money bros and technologists have been rabidly saying all sorts of inflammatory nonsense about how they're 'scared' of AI and how dangerous it will become.\n\nThose people have been screaming about that for *decades*. The concern far, far predates big money rolling in.",
                  "score": 12,
                  "created_utc": "2026-01-14 18:33:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzkdvu6",
                  "author": "RyanCargan",
                  "text": ">*OpenAI and others are clearly taking advantage of this climate of fear by suggesting they might have to delay or gimp their software because \"oh no what might happen.\" Either that or they're bullshitting to justify release delays.*\n\nI think it's a bigger attention-economy / marketing thing.\n\nThere's a problem where some people don't seem to realize that, to paraphrase a certain person:\n\n>*Better to be seen as evil than incompetent.*\n\nPeople already have a kind of subconscious assumption that risk/danger = opportunity/utility.\n\nPeople who think they're opposing 'corpos' just act as free marketing for them most of the time.\n\nThe narrative gravity thing happens even outside of tech. Ever seen politicians court controversy for free press? Because reaching their target niche is what matters, even if the press appears to paint them negatively for most people. If they reach who they need to, the rest of the world can pound sand. Happens with some cult stocks too.\n\nThere was a [recent vid](https://www.youtube.com/watch?v=1IQ9IbJVZnc), that alleged with some receipts, that a certain popular infotainment channel (that is maybe a little overly concerned about the threat of AI) got soft-conned into acting as free marketing/hypemen for the AI industry. *Bootleggers & baptists* type stuff if true.\n\nPredictions without expiry dates are meaningless and unfalsifiable. \n\nVague open-ended threats create narrative gravity that can't be ignored if you believe them (and attract attention and funding).\n\nThey also divert attention from more concrete immediate threats, while also making the tech a scapegoat for individual bad actors.",
                  "score": 16,
                  "created_utc": "2026-01-14 16:44:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzkyn41",
                  "author": "Putrid_Giggles",
                  "text": "It doesn't have to be perfect at all. It just has to be \"good enough\". Whether or not it meets that standard yet is still up for debate.",
                  "score": 1,
                  "created_utc": "2026-01-14 18:18:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzl6coe",
                  "author": "Smallpaul",
                  "text": "You, I guess are a mind reader and can always know when people are telling the truth versus lying. I’m not, a mind reader and I admit to strong uncertainty. But we have a lot of evidence that they could be sincere.\n\nWe have ample evidence that many people were sounding the alarm on these risks going back long before these businesses even existed and sometimes it was the same people.\n\nRecall that Bostrum, who is not invested in any of these companies had called out the risks in the book Superintelligence.\n\nEliezer Yudkowsky has dedicated his whole life to this and he also is not paid by any of these companies and did so before most of them existed.\n\nAlso, Hinton, who has the Nobel prize and resigned from Google specifically so he could speak freely says these same things about the risks of AI. He does so on almost a weekly basis.\n\nWe also have their internal emails from the early days when they expressed the same fears. Their INTERNAL, PRIVATE emails said:\n\n“The goal of OpenAI is to make the future good and to avoid an AGI dictatorship,” Altman wrote. “You are concerned that Demis [Hassabis, the founder of Google’s DeepMind AI lab] could create an AGI dictatorship. So [are] we. So it is a bad idea to create a structure where you could become a dictator if you chose to, especially given that we can create some other structure that avoids this possibility.”\n\nRecall as well that the organization was founded as a non-profit. This was a recruiting tool because they believed that many top researchers believed that AI was dangerous and could be better managed by a non-profit. That’s how they recruited Ilya.\n\nI am baffled why people think that Ilya could not possibly hold the same views as his one-time mentor Geoff Hinton. Or that e.g. Dario who was involved in all of the same circles could not feel the same way.",
                  "score": -1,
                  "created_utc": "2026-01-14 18:52:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzljbra",
                  "author": "IAmRoot",
                  "text": "It's not AI itself that I fear but what powerful people might do with it. If we actually get to the point of true AGI one day, there's nothing stopping these CEOs from creating robot armies to kill the 99% of the population who lost their jobs so they can have all of Earth's resources for themselves. We don't exist in their futuristic \"utopias.\" AI doesn't have the motivation to slaughter 99% of humanity. Billionaires do if they can replace us all with AGI.",
                  "score": -1,
                  "created_utc": "2026-01-14 19:50:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzjua5f",
              "author": "gmeluski",
              "text": "It's my understanding that the people from Anthropic were more safety minded and that's why they split from OpenAI. If I'm getting the dates right, GPT-3 was released in 2020 and anthropic started up in 2021. Based on this, it's completely reasonable that the safety camp had influence over the release process and then when they left OpenAI had way less reason to give a shit about any of that.",
              "score": 10,
              "created_utc": "2026-01-14 15:14:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzl7m7y",
                  "author": "Smallpaul",
                  "text": "According to the blogger and many of the skeptics on Reddit, none of them were ever safety minded and it was all just a form of marketing.",
                  "score": -4,
                  "created_utc": "2026-01-14 18:57:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzm7pc8",
              "author": "csman11",
              "text": "Both views here are true, it’s not so black and white. There’s definitely some harms and the ones you called out are the most realistic ones, and they can all be summed up as “abuse of LLMs to spread misinformation”. I don’t think anyone should disregard just how harmful this is to our already broken and polarized societies.\n\n\nBut these AI labs and other companies in the AI bubble have also been overstating capabilities of LLMs to drive attention to the space. Framing those capabilities as “disruptive and dangerous” in the ways the article’s author is getting at, is overblown. These dangers attract the attention of the general public, which in turn attracts the attention of policymakers, which then turns into the AI industry capturing state regulators because they’ve convinced us “we need to move fast to make sure the existential worst cases are avoided”. The big one is obviously financial/securities regulation avoidance. They can extract tons of wealth from both institutional and retail investors by creating attractive signals in the stock market with their revenue cycles. In an ideal world they wouldn’t be allowed to do that, but for some reason the policymakers have bought into the idea that the AI industry is important to national security instead of seeing them for the rent seekers they’re trying to be.",
              "score": 3,
              "created_utc": "2026-01-14 21:41:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzjwn76",
              "author": "TheESportsGuy",
              "text": ">Good thing those fears were so overblown! Turns out those liars at OpenAI claimed we might end up a world filled with blog spam\n\nAs if the internet hasn't been headed that direction for at least the last 20 years. Maybe AI accelerated it a bit...but not that I could tell. Mainstream internet content has been trash and/or marketing since the AOL days. And the skill required to parse it hasn't changed with the advent of AI. Google search was a temporary hack for a while, but it also fell off as a viable way to find value in internet content long before GPT-3 was released.\n\nEverything about AI is just the usual financial hype cycle, 20-100 years early.",
              "score": -5,
              "created_utc": "2026-01-14 15:26:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzlco7f",
                  "author": "Kusibu",
                  "text": "> Maybe AI accelerated it a bit...but not that I could tell.\n\nThere were garbage websites, but it used to be at least a little difficult to completely falsify an entire article on a breaking topic like five minutes after it happened, or generate a new fake website to match Google's SEO changes each time they happen.",
                  "score": 2,
                  "created_utc": "2026-01-14 19:20:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nziei5a",
          "author": "personman",
          "text": "i agree with you completely, but where did you come up with 400 years?",
          "score": 186,
          "created_utc": "2026-01-14 09:19:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzigxhw",
              "author": "sickhippie",
              "text": "It's literally the title of the linked article, and it references the invention of the mechanical calculator in 1623.",
              "score": 209,
              "created_utc": "2026-01-14 09:42:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nziitp5",
                  "author": "personman",
                  "text": "oh wow the fact that there was text in the post made me completely miss that there was a link, thanks",
                  "score": 123,
                  "created_utc": "2026-01-14 10:01:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzkqt3c",
                  "author": "bdmiz",
                  "text": "You’re absolutely right to ask. The “400 years” comes directly from the title of the linked article itself, which points back to the invention of the mechanical calculator in 1623—roughly four centuries ago. That’s the historical reference being used, not an arbitrary estimate.",
                  "score": 4,
                  "created_utc": "2026-01-14 17:43:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzjmgnj",
              "author": "desmotron",
              "text": "From the LLM he used to make sense of the other LLM’s",
              "score": -5,
              "created_utc": "2026-01-14 14:35:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nziz8rl",
          "author": "A1oso",
          "text": "The title implies that Wilhelm Schickard intended to scam us with AI **in 1623**, by inventing the calculator. Most of your points are valid, but the conclusion is just insane.",
          "score": 43,
          "created_utc": "2026-01-14 12:18:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzmjikj",
              "author": "jmhuer",
              "text": "It’s a gross oversimplification \nIt’s like saying roundworms invented thinking because they were first to have neurons \n\nCalculator -> LLMs is not a trivial cross",
              "score": 7,
              "created_utc": "2026-01-14 22:36:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvyeb7",
                  "author": "quetzalcoatl-pl",
                  "text": "this. exactly this.",
                  "score": 1,
                  "created_utc": "2026-01-16 08:30:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzjwl0t",
              "author": "DerelictMan",
              "text": "Clickbait title",
              "score": 18,
              "created_utc": "2026-01-14 15:25:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzkucs3",
          "author": "giantrhino",
          "text": "I always describe them as a magic trick. They’re doing something really cool… in some ways way more impressive than what people think, but because they don’t understand what’s actually happening their brains assume it’s something it’s not. \n\nFor magic tricks our brains come to the conclusion it’s magic. For LLMs our brains come to the conclusion it’s intelligence/sentience.",
          "score": 4,
          "created_utc": "2026-01-14 17:59:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzoxzxw",
              "author": "HorstGrill",
              "text": "It's quite different. Do you know the meme with three guys and the bell curve? Well, when you dont understand how LLMs work at all, they are magic. If you think you know whats happening, it's not magic at all, but just an ultra advanced text completion tool, when you really go into depth about how those networks work, they are, again, magic.\n\nI can wholeheartedly suggest the Youtube channel \"Welch Labs\" of you want to see some awesome visualizations about some of the few things we actually know about LLMs or NNs in general. The latest 4 Videos are 100% awesome.",
              "score": 1,
              "created_utc": "2026-01-15 07:46:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqmkym",
                  "author": "giantrhino",
                  "text": "I actually recommend the 3blue1brown series on them. And I would disagree with you. I would argue that on step 3 it’s more akin to a magic trick.",
                  "score": 1,
                  "created_utc": "2026-01-15 15:09:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzjbnyx",
          "author": "rfisher",
          "text": "> I wrote this up because I was trying to get my head around why people are so happy to believe the answers LLMs produce, despite it being common knowledge that they hallucinate frequently.\n\nFirst wrap your head around why people are so happy to believe other people without actually checking facts. It is unsurprising that they treat LLMs the same. Don't put up with those people, whether it is LLMs or other people that they're too quick to trust.",
          "score": 13,
          "created_utc": "2026-01-14 13:37:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjdjjn",
              "author": "lionmeetsviking",
              "text": "Had to scroll way too far for this comment! \n\nI find that poor LLM is roughly 800% more reliable in terms of factual information, than the current US president as an example.",
              "score": 5,
              "created_utc": "2026-01-14 13:47:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzkqbj1",
                  "author": "Adventurous-Pin-8408",
                  "text": "That's just a race to the bottom in terms of trust you can put in anything.\n\n\nThis is enshitification of knowledge. The whataboutism does not in any way increase the validity of ai slop, it just means the ambient information is worse.",
                  "score": 6,
                  "created_utc": "2026-01-14 17:41:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nziubml",
          "author": "scandii",
          "text": "usually I just click out of every blog post about LLM:s in the first paragraph because they're genuinely a boring read with lukewarm ideas being expressed but this was a pleasant read - kudos!",
          "score": 9,
          "created_utc": "2026-01-14 11:41:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzifgc1",
          "author": "ffiarpg",
          "text": ">How do so many companies plan to rely on a tool that is, by design, not reliable?\n\nBecause even if it's right 95% of the time, that's a lot of code a human doesn't have to write. People aren't reliable either, but if you have more reliable developers using LLMs and correcting errors they will produce far more code than they would without it.",
          "score": 139,
          "created_utc": "2026-01-14 09:28:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzilkcq",
              "author": "omac4552",
              "text": "Code is easier to understand when you write it yourself compared to reading. So I'm not so sure the measurement of created code lines really is something that should be accepted as a win. \n\nMaintenance is going to go through the roof for the people skilled to actually understand the output of these LLM's, and they are going to spend a long long time understanding and debugging code when something goes wrong. \n\nMe myself will find other things to do than code reviewing LLM's, I'll leave that to others to do.",
              "score": 167,
              "created_utc": "2026-01-14 10:26:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzio9ew",
                  "author": "Valmar33",
                  "text": "> Code is easier to understand when you write it yourself compared to reading.\n\nPrecisely ~ because it was written with your mental framework in mind.\n\nWith an LLM, you have no idea about the design decisions or how to mentally parse it. If it's a bug-ridden mess, you could be stuck for a very long time. Better to just write from scratch ~ at least you can understand your own bugs that way, and become a better programmer, as a result.",
                  "score": 71,
                  "created_utc": "2026-01-14 10:50:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzjhysk",
                  "author": "AutoPanda1096",
                  "text": "It's nuanced.\n\nI've been coding for 30 years and these tools allow me to dip into other languages without having to go through the same pain I used to.\n\nI'm not just saying \"write me this app\" \n\nI'm approaching coding just the same as I always have done \n\nWhat's the first thing I want my app to do?  Open a file.  \"AI, teach me how to open a file with language x\"\n\nAnd then I read and understand that.\n\nNext thing I want to do is read from that file.  \"AI how would I access the contents so I can then...\"\n\nEtc\n\nObviously it's impossible to share our process in a two minute Reddit reply, I'm just trying to give a gist.\n\nBut with AI my ability to pick up new things and work on unfamiliar things has accelerated by orders of magnitude.\n\nWe now have a local LLM that can can point us to bits of code rather than hours of painful debugging.  \"This field is wrong, list out the data journey...\" \n\nSomething like that shows me the steps I might want to look at first.  It might not be right.  But more often than not I've saved an hour of painful code trawling.  If it's not right then I've ruled out some obvious things.  I just have to keep going.  That's just normal.\n\nLike I say, it's hard to explain and I've argued this enough to know people go \"but you're missing out on X and y\"\n\nI just don't buy it.\n\nIt's like teaching kids to hand crank arithmetic when calculators exist \"but you have to learn the basics!\"\n\nIt's a bigger debate than I'll ever take on via Reddit lol but check out professor Wolfram's views.  We need to teach people how to use tools.  Don't teach them to be the tools.",
                  "score": 17,
                  "created_utc": "2026-01-14 14:11:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzjmpju",
                  "author": "Helluiin",
                  "text": "> Code is easier to understand when you write it yourself compared to reading\n\nnot just coding but everything. theres a reason schools make you write and work out so much on your own, because its proven to improve your memory of it.",
                  "score": 6,
                  "created_utc": "2026-01-14 14:36:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzjha62",
                  "author": "MSgtGunny",
                  "text": "Reading and debugging code you didn’t write causes burnout faster than writing your own code.",
                  "score": 3,
                  "created_utc": "2026-01-14 14:07:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzj2dpx",
                  "author": "LeakyBanana",
                  "text": "I'll never understand this argument. Are you all solo devs or something? You've never worked on a team codebase? On a codebase with multiple teams contributing to it?\n\n\nY'all are only ever debugging your own code? Do you just throw your hands up and git blame any time a stack trace falls into someone else's domain? Maybe understanding and debugging others' code is a skill you need to spend some time developing. Then working with an LLM won't seem so scary.",
                  "score": 7,
                  "created_utc": "2026-01-14 12:40:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzj6oyd",
                  "author": "vulgrin",
                  "text": "“they are going to spend a long long time understanding and debugging code when something goes wrong.”\n\nSeriously, no they won’t. Because you use the same tools to debug and explain the code that you use to write it. I can with an LLM and my decades of experience pull up a completely foreign code base and understand what’s going on and where the critical code is quickly. Searching and doing debugging by hand and with the LLM is trivial and the same as it ever was. Then writing the prompts to fix code that’s already written is easier (in most cases, UI notwithstanding) than the initial build. \n\nIf you are reviewing changes every time an LLM makes it, you’ll understand the code just fine and catch the problems. In my experience the more mature the project is, the less issues I have and the more I can trust the agent because there’s enough examples for the agent to follow. \n\nIt’s really strange to me that we programmers have been given power tools and everyone would rather sand by hand. Like woodworking, hand craftsmanship is good for some projects but when I’m just building a shed, I just want it done.",
                  "score": 4,
                  "created_utc": "2026-01-14 13:08:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzjxmwe",
                  "author": "Woaz",
                  "text": "Well if youre not “vibe coding” files or directories at a time, focus on generating a single function or code block, and then making sure it makes sense, its not too hard to understand and can definitely save some time just typing it out if nothing else.\n\nAll that to say its not perfect and comes with drawbacks, but its probably one of the more reasonable use cases (along other draft-and-verify applications, like writing a letter/email). What really boggles my mind is basically taking this unreliable source of information and using it in situations without verification, like live for customer service, product descriptions, or straight up “vibe coding” without understanding it.",
                  "score": 2,
                  "created_utc": "2026-01-14 15:30:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzpfq22",
                  "author": "vlakreeh",
                  "text": "I don't understand this, presumably most of the code you interact with day to day already isn't written by you but instead written by your coworkers. Unless you just don't review your coworker's PRs then I don't see how this is that much different, the current SOTA models don't really generate worse PRs (at what I've been working on recently) than juniors I've worked with in my career.",
                  "score": 1,
                  "created_utc": "2026-01-15 10:36:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzjt80g",
                  "author": "doiveo",
                  "text": "So give your Ai a style guide and rigours rules around structure and architecture. Templates and negatives are the key to getting code you would use. Every project needs a decision file where anything you or the Ai chooses gets documented.\n\nIn the end, the code becomes disposable - it's the context that must be engineered and maintained.",
                  "score": 0,
                  "created_utc": "2026-01-14 15:09:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzitv53",
              "author": "archialone",
              "text": "Writing large amounts of code was never the issue, understanding the system and debugging, designing solutions that fits to the problem were the issue.\n\nHaving LLM spit out vast amount of text is not helpful.",
              "score": 32,
              "created_utc": "2026-01-14 11:38:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzmypis",
                  "author": "ptoki",
                  "text": "there is a point where \n\n\"in php write me a loop which iterates over an array of strings and returns concatenated string consisting only rows matching pattern *.exe\"\n\nAnd\n\n\"$result = '';\n\nforeach ($files as $file) {\n    if (fnmatch('*.exe', $file)) {\n        $result .= $file;\n    }\n}\n\necho $result;\"\n\nare equal in complexity or the prompt is much more tedious to compose than the code itself.\n\nI still dont see revolution and chatgpt is with us for like 3+ years...",
                  "score": 3,
                  "created_utc": "2026-01-14 23:55:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzj7h1k",
              "author": "efvie",
              "text": "Say it with me: *code is bad, you should have as little code as possible*. More code is **bad**.\n\n(This aside from 95% wildly overstating even the unit-level correctness let alone modules or entire systems.)",
              "score": 13,
              "created_utc": "2026-01-14 13:13:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzjos6u",
                  "author": "Helluiin",
                  "text": "95% is probably wrong even for a single statement depending on the language or library in question",
                  "score": 1,
                  "created_utc": "2026-01-14 14:47:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzio25b",
              "author": "Valmar33",
              "text": "> Because even if it's right 95% of the time, that's a lot of code a human doesn't have to write. People aren't reliable either, but if you have more reliable developers using LLMs and correcting errors they will produce far more code than they would without it.\n\nThe difference is that if you didn't write the code, debugging it will be a total nightmare.\n\nIf you wrote it, then at least you have a framework of it in your mind. Debugging it will be far less painful, because you wrote it with your mental frameworks.\n\nReliable developers statistically get no meaningful benefit from LLMs ~ LLMs just slow experienced devs down as they have to spend more time debugging the code the LLM pumps out than if they just wrote it from scratch.",
              "score": 25,
              "created_utc": "2026-01-14 10:49:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzioy0g",
                  "author": "dbkblk",
                  "text": "Well, I kind of agree, but as an experienced dev, I'm using it for some tasks.\nYou just have to do small flee jumps and check the code. For small steps, it's good.\nHowever, if you hope to dev some large features with one prompt, you're going to be overloaded very soon.\nI would say it has its use, but companies oversell it 🐧",
                  "score": 6,
                  "created_utc": "2026-01-14 10:56:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzit6jf",
                  "author": "Sparaucchio",
                  "text": ">The difference is that if you didn't write the code, debugging it will be a total nightmare.\n\nI did not write my colleague's code, and debugging it has always been a pain in the ass. Weak point imho, unless you are a solo dev...",
                  "score": 6,
                  "created_utc": "2026-01-14 11:32:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nziskej",
                  "author": "chjacobsen",
                  "text": "\"Reliable developers statistically get no meaningful benefit from LLMs \\~ LLMs just slow experienced devs down as they have to spend more time debugging the code the LLM pumps out than if they just wrote it from scratch.\"\n\nI think that's far too categorical. There's a space inbetween not using LLMs at all and full vibecoding with no human input.\n\nNot all LLM use compromises the structure of the code. It's very possible to give scoped tasks to LLMs and save time simply due to not having to type everything out yourself.",
                  "score": 9,
                  "created_utc": "2026-01-14 11:27:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzj0a11",
                  "author": "Smallpaul",
                  "text": "> The difference is that if you didn't write the code, debugging it will be a total nightmare.\n\nSo the minute you leave the company your code becomes a “total nightmare” for the person who comes next? When your colleague is on vacation you consider their code a “total nightmare?”\n\nWell written code should not be a “total nightmare” to debug, whether written by human or machine.",
                  "score": 3,
                  "created_utc": "2026-01-14 12:25:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzpjm3b",
                  "author": "Tolopono",
                  "text": "Andrej Karpathy: I think congrats again to OpenAI for cooking with GPT-5 Pro. This is the third time I've struggled on something complex/gnarly for an hour on and off with CC, then 5 Pro goes off for 10 minutes and comes back with code that works out of the box. I had CC read the 5 Pro version and it wrote up 2 paragraphs admiring it (very wholesome). If you're not giving it your hardest problems you're probably missing out. https://xcancel.com/karpathy/status/1964020416139448359\n\nOpus 4.5 is very good. People who aren’t keeping up even over the last 30 days already have a deprecated world view on this topic. https://xcancel.com/karpathy/status/2004621825180139522?s=20\n\nResponse by spacecraft engineer at Varda Space and Co-Founder of Cosine Additive (acquired by GE): Skills feel the least durable they've ever been.  The half life keeps shortening. I'm not sure whether this is exciting or terrifying. https://xcancel.com/andrewmccalip/status/2004985887927726084?s=20\n\nI've never felt this much behind as a programmer. The profession is being dramatically refactored as the bits contributed by the programmer are increasingly sparse and between. I have a sense that I could be 10X more powerful if I just properly string together what has become available over the last ~year and a failure to claim the boost feels decidedly like skill issue. There's a new programmable layer of abstraction to master (in addition to the usual layers below) involving agents, subagents, their prompts, contexts, memory, modes, permissions, tools, plugins, skills, hooks, MCP, LSP, slash commands, workflows, IDE integrations, and a need to build an all-encompassing mental model for strengths and pitfalls of fundamentally stochastic, fallible, unintelligible and changing entities suddenly intermingled with what used to be good old fashioned engineering. Clearly some powerful alien tool was handed around except it comes with no manual and everyone has to figure out how to hold it and operate it, while the resulting magnitude 9 earthquake is rocking the profession. Roll up your sleeves to not fall behind. https://xcancel.com/karpathy/status/2004607146781278521?s=20\n\nCreator of Tailwind CSS in response: The people who don't feel this way are the ones who are fucked, honestly. https://xcancel.com/adamwathan/status/2004722869658349796\n\nStanford CS PhD with almost 20k citations: I think this is right. I am not sold on AGI claims, but LLM guided programming is probably the biggest shift in software engineering in several decades, maybe since the advent of compilers. As an open source maintainer of @deep_chem, the deluge of low effort PRs is difficult to handle. We need better automatic verification tooling https://xcancel.com/rbhar90/status/2004644406411100641\n\nIn October 2025, he called AI code slop https://www.itpro.com/technology/artificial-intelligence/agentic-ai-hype-openai-andrej-karpathy\n\n“They’re cognitively lacking and it’s just not working,” he told host Dwarkesh Patel. “It will take about a decade to work through all of those issues.”\n\n“I feel like the industry is making too big of a jump and is trying to pretend like this is amazing, and it’s not. It’s slop”.\n\nCreator of Vue JS and Vite, Evan You, \"Gemini 2.5 pro is really really good.\" https://xcancel.com/youyuxi/status/1910509965208674701\n\nCreator of Ruby on Rails + Omarchy:\n\n Opus, Gemini 3, and MiniMax M2.1 are the first models I've thrown at major code bases like Rails and Basecamp where I've been genuinely impressed. By no means perfect, and you couldn't just let them vibe, but the speed-up is now undeniable. I still love to write code by hand, but you're cheating yourself if you don't at least have a look at what the frontier is like at the moment. This is an incredible time to be alive and to be into computers. https://xcancel.com/dhh/status/2004963782662250914\n\nI used it for the latest Rails.app.creds feature to flesh things out. Used it to find a Rails regression with IRB in Basecamp. Used it to flesh out some agent API adapters. I've tried most of the Claude models, and Opus 4.5 feels substantially different to me. It jumped from \"this is neat\" to \"damn I can actually use this\". https://xcancel.com/dhh/status/2004977654852956359\n\nClaude 4.5 Opus with Claude Code been one of the models that have impressed me the most. It found a tricky Rails regression with some wild and quick inquiries into Ruby innards. https://xcancel.com/dhh/status/2004965767113023581?s=20\n\nHe’s not just hyping AI: pure vibe coding remains an aspirational dream for professional work for me, for now. Supervised collaboration, though, is here today. I've worked alongside agents to fix small bugs, finish substantial features, and get several drafts on major new initiatives. The paradigm shift finally feels real. Now, it all depends on what you're working on, and what your expectations are. The hype train keeps accelerating, and if you bought the pitch that we're five minutes away from putting all professional programmers out of a job, you'll be disappointed. I'm nowhere close to the claims of having agents write 90%+ of the code, as I see some boast about online. I don't know what code they're writing to hit those rates, but that's way off what I'm able to achieve, if I hold the line on quality and cohesion. https://world.hey.com/dhh/promoting-ai-agents-3ee04945",
                  "score": 0,
                  "created_utc": "2026-01-15 11:10:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzj4fpe",
                  "author": "FeepingCreature",
                  "text": "> Reliable developers statistically get no meaningful benefit from LLMs\n\nThis is not correct. Developers working on an *established, well-understood codebase* get no meaningful benefit from *LLMs such as they were a year ago.*",
                  "score": -2,
                  "created_utc": "2026-01-14 12:53:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzj03ww",
              "author": "BoringEntropist",
              "text": "Most code out there in production isn't maintained already. And you want to add even more code? We already know LOC is a horrible metric for decades, as it leads to bloat, security vulnerabilities and economic inefficiencies.",
              "score": 6,
              "created_utc": "2026-01-14 12:24:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzivedu",
              "author": "Crafty_Independence",
              "text": "That's not why many companies are using it though. A good percentage are using it because the C-suite thinks it will allow them to replace human workers and/or the shareholders are clamoring for AI usage.\n\nVery little of the hype is being driven by data.",
              "score": 6,
              "created_utc": "2026-01-14 11:50:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzjd0vp",
              "author": "stimulatedthought",
              "text": "Disagree with the idea that humans aren’t reliable. SOME humans are not reliable but since we are the only truly “thinking” entity capable of programming in the known universe—the best of us set the standard for reliable in that regard.  The expectation of those who demand things for perfection is the problem and comparing a confidence trick with true problem solving is where this gets complicated.",
              "score": 2,
              "created_utc": "2026-01-14 13:44:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzk8ho0",
              "author": "Seref15",
              "text": "Yeah a skilled person + an LLM together is just undeniably efficient. It's trying to get rid of the skilled person where things go sideways.",
              "score": 2,
              "created_utc": "2026-01-14 16:20:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nznm1gp",
              "author": "Uristqwerty",
              "text": "You know the saying \"If I had more time, I would have written a shorter letter\"? AIs make generating *new* code so easy that I'd expect the size of the project to expand until it bogs down new development more than the AI allegedly sped things up.\n\nEvery line written is a line future programmers must read and understand. If they don't understand, there's a risk that when adding a new feature, they'll carve out a fresh file and re-implement whatever logic and helpers they need, duplicating logic. Or worse, a *near*-duplicate with different bugs than each of the other 5 copies that have accumulated.",
              "score": 2,
              "created_utc": "2026-01-15 02:06:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzivacg",
              "author": "fractalife",
              "text": "Studies have so far shown this not to be the case. It's about the same or worse. Developers have always made tools to automate tedious repetitive code, or if possible template in a way that it's not necessary to do. That's kindof the point, after all.\n\nThat's where LLMs excel, so they're filling a niche that has kindof already been filled. When it comes to novel approaches to particularly interesting problems, the LLMs are just going to guess, because they aren't actually curious and don't \"want\" to solve problems. They're just programs and marices at the end of the day.",
              "score": 1,
              "created_utc": "2026-01-14 11:49:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzjyqd4",
              "author": "longshot",
              "text": "While it isn't reliable, I would say pure human effort is also unreliable in many ways.",
              "score": 1,
              "created_utc": "2026-01-14 15:35:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzknjyp",
              "author": "SmokeyDBear",
              "text": "This is 100% true but it assumes an answer to the question “Is not having more code the thing that’s keeping us from making progress?” (or, more importantly, “is not having more if the type of code that AI can write the thing that’s keeping us from making progress?”). Maybe the answer is “yes” but it’s probably worth making sure.",
              "score": 1,
              "created_utc": "2026-01-14 17:28:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzit32h",
              "author": "editor_of_the_beast",
              "text": "Right., it’s in the name: artificial intelligence. It’s emulating human intelligence, which is completely fallible. And we seem to have a functioning society even with that.",
              "score": 0,
              "created_utc": "2026-01-14 11:31:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzj673f",
                  "author": "ub3rh4x0rz",
                  "text": "The last sentence is debatable",
                  "score": 5,
                  "created_utc": "2026-01-14 13:05:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzjgyfb",
              "author": "_JustCallMeBen_",
              "text": "Finding the 5% that is wrong requires you to read and understand 100% of the code.\n\nAt which point you have to ask yourself how much time you saved versus writing 100% of the code.",
              "score": 2,
              "created_utc": "2026-01-14 14:06:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzj5wik",
              "author": "HommeMusical",
              "text": "> Because even if it's right 95% of the time, that's a lot of code a human doesn't have to write.\n\nI would not work with a developer who had a 5% error rate.\n\n> People aren't reliable either, but if you have more reliable developers using LLMs and correcting errors they will produce far more code than they would without it.\n\nThey will produce a larger _volume_ of code, for sure.",
              "score": -1,
              "created_utc": "2026-01-14 13:03:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzikyhc",
              "author": "Sisaroth",
              "text": "Exactly, I don't understand why anti-ai redditors are so hung up about LLMs not being correct 100% of the time. \nIt's still a very useful tool even if you should (almost) never trust it blindly. \n\nFor example: I hate CSS/html styling but getting it wrong should never be a security risk. This is the one exception where I will use LLM generated code without reading it first because there is no security risk in doing so.\n\nAnother example: You are stuck with some problem and the solution to it is spread out within different pages of documentation. A human could easily spend 4-8 hours digging through the documentation to find the solution, an LLM can often do it in one shot. You can ask the LLM about it's sources and then you can double check that it actually came up with the correct answer and not just a hallucination. You just saved a day of work (i have seen this scenario happen multiple times at work, both with myself and colleagues).",
              "score": -10,
              "created_utc": "2026-01-14 10:21:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nziog98",
                  "author": "Valmar33",
                  "text": "> Exactly, I don't understand why anti-ai redditors are so hung up about LLMs not being correct 100% of the time. It's still a very useful tool even if you should (almost) never trust it blindly. \n\nLLMs are only vaguely good at very basic code ~ but complex projects are a nightmare, because you will be unable to reason about all of the moving parts. At least if you write it yourself, you will develop a mental model of how it flows in your mind ~ because it was written in accordance to how you think as a programmer.",
                  "score": 10,
                  "created_utc": "2026-01-14 10:52:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzimgvt",
                  "author": "ChemicalRascal",
                  "text": "> Exactly, I don't understand why anti-ai redditors are so hung up about LLMs not being correct 100% of the time.\n\nBecause I write software that needs to be correct 100% of the time, and having to review an LLM's output is both not quicker than writing it myself and not as safe.\n\n> For example: I hate CSS/html styling but getting it wrong should never be a security risk.\n\nGetting styling wrong is an enormous usability risk. If you only care about security risks, I'm sorry, but you're an idiot. Now, sure, never put security under usability, but you have capacity in your brain to care about multiple things at once.\n\nJust spend a weekend on YouTube and learn how CSS works. That's what normal devs do, for crying out loud. Unless you're literally on death's door you have tonnes of time to learn this basic shit.",
                  "score": 7,
                  "created_utc": "2026-01-14 10:35:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzio7h7",
              "author": "chjacobsen",
              "text": "We're also very early in learning how to actually apply LLMs to coding.\n\nLLMs themselves are not reliable, but we can do a lot to constrain them and make failure cases rarer and easier to catch.\n\nTopics such as which programming paradigms we choose, our testing tools, static analysis setups, which programming languages we choose, how we manage context to avoid tunnel vision - all of those make a huge difference to the reliability of LLMs, and we've barely even begun to explore those things.\n\nThe more I dig into it, the less concerned I am that programming will be done by vibecoding marketing managers, because I actually think the emergence of LLMs makes the job harder in some ways. Creating the environment in which a non-deterministic AI model can be run reliably takes a lot of effort, but the rewards can be software that is both quick to write AND better than what we used to have. In that space, the market for slop isn't looking great.",
              "score": -3,
              "created_utc": "2026-01-14 10:50:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzkdlbb",
                  "author": "zoko_cx",
                  "text": "There are two challenges which user (programmer) needs to overcome to let say LLMs could increase his output.  \nFirst as you mention he needs to know how to use LLMs and for what kind od task are useful and for what not or lot less. Second is how agentic coding works and how to better setup it with LLMs, controlling context etc.\n\nSecond by most important thing is you need to know is correct code by design and this is where knowledge and experience come to play. If LLM output some code which you never saw before you need to understand it, know if it good solution of problem. So maybe we should less focus on mastering writing the best code but more to unit/integration testing, refactoring, security and overall system design and architecture.\n\nAnd about AI generated sloppy code, before it there were humans which did that now they will do it faster.",
                  "score": 1,
                  "created_utc": "2026-01-14 16:43:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzii1im",
              "author": "SwoopsFromAbove",
              "text": "Absolutely, and it’s very cool to be able to do that! The problem is that societal assumptions are that the computer is always right - challenging computer output doesn’t come naturally to us, and we don’t have the systems in place to do so effectively.\n\nThis is encouraged by the LLM vendors, who have a _very strong_ financial interest in framing their tools as all-powerful and super-intelligent. They rely on the strong psychological priors we have to trust computer-generated answers to oversell their products’ capabilities.",
              "score": -12,
              "created_utc": "2026-01-14 09:53:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzikqxq",
                  "author": "aaron_dresden",
                  "text": "I don’t know anyone who trusts that the computer is always right, even before LLM’s.  Computers have always gotten into inconsistent states at times, and there are those who just inherently don’t like technology.\n\nThis is a weird way to frame things.",
                  "score": 13,
                  "created_utc": "2026-01-14 10:19:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzip3al",
                  "author": "backelie",
                  "text": "> The problem is that societal assumptions are that the computer is always right\n\nCitation needed",
                  "score": 7,
                  "created_utc": "2026-01-14 10:58:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzj988a",
                  "author": "MrTroll420",
                  "text": "Are you from eastern Europe? I agree",
                  "score": 1,
                  "created_utc": "2026-01-14 13:23:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzkbtgu",
                  "author": "zoko_cx",
                  "text": "Down vote fore 1s paragraph but I would up vote for 2nd.  \nComputers are stupid machines, they are in category of calculator but much complicated with more capabilities. \n\nBut still they output is base on human input. People who think that computers are smart are just very naive and probably they won't manage to use computer for simple task without ragging.",
                  "score": 1,
                  "created_utc": "2026-01-14 16:35:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nziowbb",
          "author": "hotcornballer",
          "text": "Half the articles on here are AI slop, the rest is AI cope. This is the latter.",
          "score": 50,
          "created_utc": "2026-01-14 10:56:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nziqlkt",
              "author": "LowB0b",
              "text": "\\> LLMs are an incredibly powerful tool, that do amazing things.\n\nYou should read the article as well. It isn't inherently calling LLMs \"bad\", it's calling out the hype and manipulation going on around them.",
              "score": 32,
              "created_utc": "2026-01-14 11:11:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzj52ov",
              "author": "peligroso",
              "text": "Plot twist: OPs post has telltales of Gemini copypasta.",
              "score": 14,
              "created_utc": "2026-01-14 12:58:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzk04lo",
              "author": "FlyingBishop",
              "text": "It can be both.",
              "score": 3,
              "created_utc": "2026-01-14 15:42:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzji4rx",
          "author": "dmonkey1001",
          "text": "Like any tool it's only useful if you know how and when to use it.",
          "score": 7,
          "created_utc": "2026-01-14 14:12:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjbqgm",
          "author": "PublicFurryAccount",
          "text": "You're absolutely right!",
          "score": 5,
          "created_utc": "2026-01-14 13:37:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjj0uf",
          "author": "j00cifer",
          "text": "Because for one thing it’s an incredibly fast-moving target.\n\nAny negative issue LLM has needs to re-evaluated every 6 months.  It’s a mistake to make an assessment as if things are now settled.  \n\nBefore agent mode was made available in everyone’s IDEs about 8 months ago, things were radically different in the SWE world, and that was just 8 months ago.",
          "score": 8,
          "created_utc": "2026-01-14 14:17:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjk8yy",
              "author": "j00cifer",
              "text": "From the linked article:\n\n*”…Over and over we are told that unless we ride the wave, we will be crushed by it; unless we learn to use these tools now, we will be rendered obsolete; unless we adapt our workplaces and systems to support the LLM’s foibles, we will be outcompeted.”*\n\nMy suggestion:  just don’t use LLM.  Try that.\n\nIf it’s unnecessary, why not just refuse to use it, or use it in a trivial way just to satisfy management?\n\nThat is a real question: why don’t you do that?\n\nI think it has a real answer:  *because I can’t do without that speed now, it puts me behind to give it up. And Iterating over LLM errors is still 100 times faster than iterating over my own errors.*",
              "score": 3,
              "created_utc": "2026-01-14 14:23:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzkpp28",
                  "author": "deja-roo",
                  "text": "> I think it has a real answer:\n\nYeah as I was reading your comment I was thinking \"well, because if everyone else is using it, I'm practically standing still from a productivity perspective\".",
                  "score": 2,
                  "created_utc": "2026-01-14 17:38:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzp3w4n",
                  "author": "userimpossible",
                  "text": "If you on your own make as much errors as an LLM, I question the quality of your training. If a trained professional produces errors at the same rate and severity as an LLM, then their training, selection, or role fit is to be challenged. Trained people are able to make decisions faster and take more reliable actions in the long run.\n\nThe  'Oh, so glorious' 'thought' pattern of LLMs means spitting out statistically common information. Statistically, most people write shitty code and make dumb mistakes due to (lack of) their training. And this is the same shit an LLM is going to produce as code.\n\nFew months ago, I read an article about Magnus Carlsen who beat an LLM in a game of chess without giving up a single piece. I don't know if it's true, but you see my point: (statistically) most people play low-quality chess and cannot meet the expectations of a trained professional. LLMs amplify the difference, not make it.\n\n'It's in my input/training data, so it is true' or 'I mix related things to cover that I don't know much about the topic' are not reliable principles in real life. Human thought (especially a trained one) is not only statistics, and is able to recognize, analyze and fix anomalies autonomously, whether in input data, or its own process patterns.",
                  "score": -2,
                  "created_utc": "2026-01-15 08:42:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzjl7fb",
              "author": "yenda1",
              "text": "before opus 4.5 a couple month ago I would have laughed at anyone telling me they let an AI write more than one line in their codebase. Now I have not written a line of code since it came out.",
              "score": -7,
              "created_utc": "2026-01-14 14:28:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzjq86i",
                  "author": "PotaToss",
                  "text": "How long have you been programming?",
                  "score": 16,
                  "created_utc": "2026-01-14 14:54:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzk3eh4",
          "author": "jampauroti",
          "text": "Just because the calculator got invented, doesn't mean maths becomes obsolete",
          "score": 2,
          "created_utc": "2026-01-14 15:57:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkvjrx",
          "author": "Lothrazar",
          "text": "nice clickbait",
          "score": 2,
          "created_utc": "2026-01-14 18:04:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznmra8",
          "author": "LavenderDay3544",
          "text": "True intelligence requires the ability to add, remove, and rewire neurons, change each neuron's membrane potential in real time, have each dendrite transform its input signal in non-linear ways, have absolutely no backpropagation, allow for cycles in neuron wiring to support working memory, and encode signals not only in the output voltage but in the timing of spikes as well. \n\nThe current overhyped so called artifical neural networks are an absolute joke in comparison. Oversimplified would be the understatement of the eon. It's glorified autocorrect in comparison to true intelligence which is the aggregate of a large number of different emergent properties of a very sophisticated analog system.\n\nTraditional digital hardware using the von Neumann architecture is fundamentally the wrong tool to even attempt to explore something in the direction of true AGI no matter what Scam Altman and Jensen Huang try to tell you. These corpirate dorks claim we need to build infinite data centers and assloads of nuclear power plants to power them in order to reach AGI but they're lying and they know it. They just want an excuse to prop up their grift for longer and get more free money in the name of their fake AI.\n\nIn reality you would need a neuromorphic chip that is similar to an FPGA but with analog artificial neurons instead of CLBs and with a routing fabric that can allow neurons to rewire themselves on the fly and learn things organically through neurons attached to inputs and respond via neurons attached to outputs.\n\nTrue AGI isn't a bunch of statistics and linear algebra, it's fundamentally an analog electrical engineering problem. And to demonstrate just how wrong the current corporate grift is, look at how much hardware and power they're wasting on their glorified autocorrect and then compare that to a human brain which is incomparably more powerful but operates on only about 20 Watts. That's the difference between their overhyped statistics and matrix toys and wet, squishy, constantly self modifying analog reality.",
          "score": 2,
          "created_utc": "2026-01-15 02:10:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznptct",
              "author": "qruxxurq",
              "text": "That was a lot of words for “LLMs don’t actually think, you dumdums.”",
              "score": -1,
              "created_utc": "2026-01-15 02:28:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzp1vqi",
                  "author": "LavenderDay3544",
                  "text": "That's a massive oversimplification and what I said doesn't apply to LLMs alone. It applies to all so called artificial neural networks which are about as similar to neural tissue as stick figures are to human anatomy.\n\nWhat you said is indeed entirely self-evident. A bunch of matrix math is by no means anywhere near even simulating the biological underpinnings of cognition. But the key thing to understand about the bullshit the corporate goons are selling is that without replicating cognition there can be no AGI no matter how much you scale up the existing methodologies. They're fundamentally the wrong approach to reaching that goal despite claims to the contrary.",
                  "score": 1,
                  "created_utc": "2026-01-15 08:22:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzprukp",
          "author": "FriendlyKillerCroc",
          "text": "Has this subreddit just devolved into cope for people hoping that their software engineering skills aren't going to be completely irrelevant in 5 or 10 years? Of course the job will always exist for extremely niche areas but the majority of the industry will vanish. ",
          "score": 2,
          "created_utc": "2026-01-15 12:15:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzl08ej",
          "author": "Rajacali",
          "text": "Because of Peter Thiel the biggest snake oil salesman",
          "score": 4,
          "created_utc": "2026-01-14 18:25:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzieakm",
          "author": "drodo2002",
          "text": "Well put.. inherent expectations from machine is precision, better than human. However, LLMs are not built for precision. \n\nI had posted on similar lines sometime back..\n\nPrediction Pleasure: The Thrill of Being Right\n\nTrying to figure out what has made LLM so attractive and people hyped, way beyond reality. \nHuman curiosity follows a simple cycle: explore, predict, feel suspense, and win a reward. Our brains light up when we guess correctly, especially when the “how” and “why” remain a mystery, making it feel magical and grabbing our full attention. Even when our guess is wrong, it becomes a challenge to get it right next time.\nBut this curiosity can trap us. We’re drawn to predictions from Nostradamus, astrology, and tarot despite their flaws. Even mostly wrong guesses don’t kill our passion. One right prediction feels like a jackpot, perfectly feeding our confirmation bias and keeping us hooked. \nNow, reconsider what do we love about LLMs!!\nThe fascination lies in the illusion of intelligence, humans project meaning onto fluent text, mistaking statistical tricks for thought. That psychological hook is why people are amazed, hooked, and hyped beyond reason.",
          "score": 7,
          "created_utc": "2026-01-14 09:17:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzj7gjs",
              "author": "bring_back_the_v10s",
              "text": "> However, LLMs are not built for precision.\n\n\nBut there's a group of people who think otherwise due to the mentioned 400 years of confidence in precise machines.",
              "score": 0,
              "created_utc": "2026-01-14 13:13:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzilx9r",
          "author": "cajmorgans",
          "text": "In theory every developer also has a probability distribution of \"% times being right\" when f.e coding. If LLMs can match or surpass the mean probability of \"writing the correct code\" for a developer, it's essentially a tool that is going to increase productivity by ten folds, and it would be stupid to not use it, because it has one big advantage, as it can write code much much faster than any human possibly can.",
          "score": 3,
          "created_utc": "2026-01-14 10:30:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzioz53",
              "author": "sloggo",
              "text": "I think a big factor you’re not computing there is the time it takes to figure out what _is_ right when you’re wrong. When you’ve worked and built every screw and gear in your machine, you’ll have a much better intuition for why it’s not working correctly when it isn’t. When the generated code makes mistakes, you can try and reprompt, and if that doesn’t work you then have to spend _longer than you ordinarily would_ figuring out what’s wrong.\n\nGiven the extra overheads it’s not just about matching and surpassing error rates, it has to very significantly surpass error rates.\n\nIn practical terms - in my limited experience - I find myself working incredibly faster (maybe 10-20x) and with less cognitive load for like 90% of the work. But then paying a bit of a price solving and getting an understanding of the trickier bits. And it all averages out that I find I’m getting stuff done maybe twice as fast.",
              "score": 22,
              "created_utc": "2026-01-14 10:57:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzipglv",
                  "author": "cajmorgans",
                  "text": "You are absolutely right, and this is the biggest issue with this setup.",
                  "score": 2,
                  "created_utc": "2026-01-14 11:01:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzkhjxy",
                  "author": "InterestingQuoteBird",
                  "text": "Exactly, it is similar to statistical hypothesis tests. There is a profound difference between understanding something and making a mistake and not understanding something and believing you have a correct implementation. Both result in faulty logic but it is much harder to fix it in the second case.",
                  "score": 1,
                  "created_utc": "2026-01-14 17:01:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzirf2j",
              "author": "mosaic_hops",
              "text": "Maybe but writing code has never been the bottleneck for experienced programmers. That’s the mindless, fast and easy part. A monkey can code.\n\nGetting the architecture right is the hard part, and what LLMs produce is terrible in terms of architecture. Not to mention the code is full of race conditions and deadlocks due to incorrect design, severe bugs, incorrect assumptions, other architectural anti-patterns, or it uses deprecated APIs, mixes multiple approaches to a problem instead of choosing one or the other (by, say, using portions of two different libraries that do the same thing more or leas) or simply doesn’t work at all as described. This all adds significant headwinds that, in our experience, mean AI hasn’t sped us up at all.\n\nIt CAN be useful for researching problems but the code LLMs produce - that we’ve seen - doesn’t belong anywhere near production.\n\nI think this is partly due to the nature of the code we write - we’re building new things, not just remixing a bunch of existing things. It takes an understanding and the ability to reason to build new things as there’s no training data to regurgitate from.",
              "score": 10,
              "created_utc": "2026-01-14 11:18:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzit9nj",
                  "author": "cajmorgans",
                  "text": "\"Getting the architecture right is the hard part, and what LLMs produce is terrible in terms of architecture\". It's actually not terrible, as long as you have some kind of reference and idea of what you want to do.\n\nFor instance Claude Code plan mode is far from terrible, and it lets you be part of deciding the architecture, based on the problem you describe. Of course, you need to know what the hell you are doing, but using it as a tool for improving your current idea, or just getting it down on paper, with a feedback loop, is very valuable.",
                  "score": 5,
                  "created_utc": "2026-01-14 11:33:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzj9zli",
              "author": "efvie",
              "text": "One of the big problems here is that programmers are *terrible* at that probability calculation (as most humans are) and LLMs are excellent at making you feel like you're accomplishing something through their mode of interaction even when you're not.\n\nProgrammers also love technical problems. My guess is that nearly all the effort that isn't just straight-up garbage production is producing a new ecosystem around these supposedly useful tools instead of anything of actual value just like we've spent billions rewriting shit in TS without really fixing any of the core problems in webapp development, only infinitely worse.\n\nAre you shipping faster?",
              "score": 3,
              "created_utc": "2026-01-14 13:27:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzj1uta",
          "author": "MrDangoLife",
          "text": "> LLMs are an incredibly powerful tool, that do amazing things.    \n\ncitation needed",
          "score": 3,
          "created_utc": "2026-01-14 12:36:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzj9dg4",
          "author": "baronoffeces",
          "text": "Replace LLMs with religions in that post",
          "score": 2,
          "created_utc": "2026-01-14 13:24:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzklh1l",
          "author": "jameson71",
          "text": ">why people are so happy to believe the answers LLMs produce\n\nBecause the LLMs are tuned to tell the user what they want to hear.",
          "score": 2,
          "created_utc": "2026-01-14 17:19:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzls3no",
          "author": "Bakoro",
          "text": ">why people are so happy to believe the answers LLMs produce, despite it being common knowledge that they hallucinate frequently.\n\n>Why are we happy living with this cognitive dissonance? \n\nHave you talked to many real life human beings IRL?  \nHave you ever had the opportunity to pursue other people's chain of thought, and been able to get someone's explanation of why they think things or why the do the things they do?   \nHave you ever met someone who got a fact wrong, never questioned it, and then lived their entire life with erroneous beliefs built on a misunderstanding?  \n    \nHumans are more like LLMs than almost anyone is comfortable with.  \nHumans have additional data processing features than just a token prediction mechanism, but humans have almost identical observable behaviors once you start doing things like the split brain experiment.   \n    \nIt's clear we need something like LeCun's JEPA as a grounding agent and for \"world reasoning\", but basically all the evidence we have says that humans aren't nearly as objective or reliable as we like to believe.  \nA great deal of humanity's capacity comes from our ability to externalize our thoughts and externalize data processing.  \n   \nHistory, psychology, neurology, and machine learning all build a very compelling narrative that we are generally on the right track.",
          "score": 2,
          "created_utc": "2026-01-14 20:30:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznsawu",
              "author": "qruxxurq",
              "text": "No no no.\n\nSome humans are like shitty LLMs. Many, even. But other humans are completely dissimilar to LLMs.\n\nThe 98% or so which are like shitty LLMs are the people who LLMs will utterly replace,  yet ironically are not afraid of them. In fact, those people will see LLMs as useful, b/c they are measuring LLMs against their own capabilities, and in that evaluation, LLMs are amazing. They’re certainly more “informed” than most humans. \n\nThe 2% which are nothing like LLMs are just sitting here laughing b/c they know they’re not replaceable by GPUs and know how flawed it is to think of a large ***Language Model*** as an “intelligence”. \n\nYet, what’s hilarious isn’t how LLMs hallucinate or make shit up. It’s how pathetic most people are, b/c they’re no better than an LLM. What’s scary is that 1) the stupid people see the equally stupid machine, but think it’s intelligent, assuming that they themselves are intelligent to begin with, and 2) that they think the machines have achieved intelligence instead of realizing that they themselves are stupid, and that the machines are only catching up to their own levels of stupidity, just combined with a very large corpus of facts. \n\nIDK WTF “track” you’re talking about, but if it’s “intelligence”,  neither you nor LLMs are on the right one.",
              "score": 0,
              "created_utc": "2026-01-15 02:42:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nznwv21",
                  "author": "Bakoro",
                  "text": "And surely you consider yourself one of these 2% Übermensch.  \n    \n\"Everyone is stupid but me\"  huh?  \n \nI don't even have to say anything else here, your absurdity speaks for itself.",
                  "score": 1,
                  "created_utc": "2026-01-15 03:09:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzjoi71",
          "author": "Valendr0s",
          "text": "We've built this cool new product. You give it all the answers - the questions have to be specific, but if you ask a question we've programmed in, you will get the right answer every single time. It's called a 'computer'\n\n<50 years later>\n\nOkay guys. You like the computer so much. We've developed a brand new thing. How about if when you ask a question, the computer responded like a person would, all confident and nice... but a large percentage of the time it's just completely wrong?",
          "score": 2,
          "created_utc": "2026-01-14 14:46:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjux7r",
              "author": "dummytroll",
              "text": "\"Large percentage of the time\" is highly inaccurate",
              "score": 0,
              "created_utc": "2026-01-14 15:17:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzkwxwo",
          "author": "Aggravating_Moment78",
          "text": "Depends on what you use it for as with anything else. It’s good for some purposes, not so grrat for others…",
          "score": 1,
          "created_utc": "2026-01-14 18:10:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzl82ki",
          "author": "hibbos",
          "text": "Humans on the other hand, totally reliable",
          "score": 1,
          "created_utc": "2026-01-14 18:59:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzl89vw",
          "author": "versaceblues",
          "text": ">  despite it being common knowledge that they hallucinate frequently. \n\nBecause the advancements in the past 3-4 year (including tool use, search, and reasoning) have reduced hallucination to the point where these things are often correct AND find you information on quicker than traditional search.",
          "score": 1,
          "created_utc": "2026-01-14 19:00:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlha9e",
          "author": "joe12321",
          "text": "A counterpoint here is that indeed if you didn't start using a calculator when everyone else was, you were probably left behind.  The fear being created MAY come to be seen as prescient.  And even if a tool isn't always perfect, you really can't JUST look at the problems caused (and all new tech causes problems), but the problems vs. the benefits.\n\nBut more to the point, there is no con here.   Victims of cons don't get an upside (or not certainly).  LLMs provice a service (warts and all) plus sales/marketing tactics, and though you can use it unwisely, you can get all the upside out of it you want.  Not everything that comes with slimy sales tactics is a con.",
          "score": 1,
          "created_utc": "2026-01-14 19:41:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznslnr",
              "author": "qruxxurq",
              "text": "“Left behind” what, exactly?\n\nWhat a bizarre-o take.",
              "score": 1,
              "created_utc": "2026-01-15 02:44:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzr47rk",
                  "author": "joe12321",
                  "text": "The article made the point that the culture around LLMs claims that if you don't adopt, you'll be left behind.  My point, by extending the comparison to mechanical calculators, is that calculators and adding machines and what not did become necessary and if you for some reason were obstinately against them, you would be left behind in that line of work.  \n\nSo what the author claims is part of a confidence trick, urging people into adopting LLMs, may just be good advice.  And in any case it's perfectly reasonable to believe plenty of people giving that advice are sincere in doing so.  And while some of them are just employing sales-tactics, due to all of the above it's just way too far from what happens in a genuine con or scam to equate the two things.",
                  "score": 1,
                  "created_utc": "2026-01-15 16:30:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzljcdj",
          "author": "Berkyjay",
          "text": "This is a comedy post.  But I was watching it this morning and surprised to hear how life like and warm they make the chat voices sound.  Kind of makes more sense why your average person gets sucked into using them.  A majority of the people are not discerning and don't bother to take the time to think about this shit.  They just want to know where to find the shit they're looking for.\n\nhttps://www.instagram.com/p/DTVwuFqATfd/?hl=en",
          "score": 1,
          "created_utc": "2026-01-14 19:50:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzm7gls",
          "author": "Philluminati",
          "text": "Another one of those posts that says \"AI do anything\" and yet emphasises the fear.\n\n\\> Why are we happy living with this cognitive dissonance? How do so many companies plan to rely on a tool that is, by design, not reliable?\n\n1. Because people reliable\n\n\\> humanity has spent four hundred years reinforcing the message that machine answers are the gold standard of accuracy. If your answer doesn’t match the calculator’s, you need to redo your work.\n\n^(But they are accurate are they not? I mean the math is the math.. I'm not sure what this point is. If the calculator is wrong the manufacturer will fix it.)",
          "score": 1,
          "created_utc": "2026-01-14 21:40:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzm8mh6",
          "author": "oscarnyc1",
          "text": "One thing that stood out to me is that we keep conflating usefulness with intelligence.\n\nLLMs are incredibly good at making hard things easier, like summarizing, drafting, translating and recombining. But that’s different from creating something fundamentally new.\n\nI hope in many more years (400 years?) we’ll have systems that actually reason and discover, but it feels like we’re skipping a lot of steps by talking about today’s models as if they’re already on that path.",
          "score": 1,
          "created_utc": "2026-01-14 21:45:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmcq1m",
          "author": "AlSweigart",
          "text": "Classic essay on this: [The LLMentalist Effect: how chat-based Large Language Models replicate the mechanisms of a psychic’s con](https://softwarecrisis.dev/letters/llmentalist/)\n\nBaldur Bjarnason included this essay in his book, [The Intelligence Illusion](https://illusion.baldurbjarnason.com/), which I recommend.",
          "score": 1,
          "created_utc": "2026-01-14 22:03:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmeg3a",
          "author": "DavidsWorkAccount",
          "text": "Because they are good enough. Once you learn how to work with the tooling, it's a net productivity boost. \n\nBut there's a lot of learning to be done.",
          "score": 1,
          "created_utc": "2026-01-14 22:11:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmfjr3",
          "author": "MuonManLaserJab",
          "text": "I'd read this but I recently learned that humans are pretty unreliable",
          "score": 1,
          "created_utc": "2026-01-14 22:17:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmvk95",
          "author": "pt-guzzardo",
          "text": "At this point, I'm not convinced SOTA LLMs (thinking Gemini 3 and Claude 4.5, I have less experience with OpenAI offerings) are any less reliable than randos on the internet, which is mostly what you'd get if you Googled a question instead. In either case, it's up to you to do due diligence and verify the answer if you're going to be basing any major decisions on it or using code that LLMs or internet randos produce.",
          "score": 1,
          "created_utc": "2026-01-14 23:38:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzn4r66",
          "author": "foodeater184",
          "text": "I don't see it as a con. It's a new technology that needs time to grow and find its fit. As someone with ADHD it helps me execute much faster by remembering what we were working on, giving ideas I wouldn't have thought of, writing tests, debugging, etc. It works for me. I put generated code into production last month supporting a $100M subsidiary's core production processes and by and large it works very well.",
          "score": 1,
          "created_utc": "2026-01-15 00:28:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqbbkw",
          "author": "poladermaster",
          "text": "Honestly, the confidence trick isn't just from the creators, it's from **us**. We **want** to believe, because the alternative – facing complex problems ourselves – is harder. It's like relying on 'jugaad' solutions for everything, sometimes it works, sometimes you end up with a burning scooter. But hey, at least it's **something**.",
          "score": 1,
          "created_utc": "2026-01-15 14:13:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzukso1",
          "author": "Nervous-Cockroach541",
          "text": "The thing that scares me, is it's easy to spot programming mistakes. Subtle emission of error handling, logical errors, mistaken use of library functions, version mismatching.\n\nBut imagine all the other mistakes in fields not as objective as programming that these things are making that go completely unnoticed.",
          "score": 1,
          "created_utc": "2026-01-16 02:38:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzurt8p",
          "author": "TheBlueArsedFly",
          "text": "Yeah and the internet will never take off either ",
          "score": 1,
          "created_utc": "2026-01-16 03:17:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjocbl",
          "author": "khalitko",
          "text": "It's a tool. Not all tools are perfect.",
          "score": 1,
          "created_utc": "2026-01-14 14:45:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjvsbd",
          "author": "watchfull",
          "text": "People don’t understand how they really work. They think it’s next to magic and don’t have the bandwidth/time to grasp the scope of the current models/technology.",
          "score": 1,
          "created_utc": "2026-01-14 15:22:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzik12s",
          "author": "oblong_pickle",
          "text": "Have you met people? They make mistakes all the time, what's your point?",
          "score": -6,
          "created_utc": "2026-01-14 10:12:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nziph4l",
              "author": "EntroperZero",
              "text": "But computers don't, or at least, very, *very* seldom if a bit is randomly flipped somewhere or an actual hardware bug exists without a known workaround.\n\nSoftware has bugs, but those can theoretically be discovered and fixed to make the program more correct.  The behavior of an LLM doesn't follow this pattern at all, it's just a statistical model that will hallucinate a significant percentage of the time.\n\nNone of this is to say LLMs are bad or they can't be useful for anything, but they are a completely different paradigm from what people are used to with computer programs.  And no, they're not the first probabilistic computer programs, but they're the first to see such widespread use by people who don't really understand what that means.",
              "score": 8,
              "created_utc": "2026-01-14 11:01:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzitvn9",
                  "author": "syklemil",
                  "text": "People are also generally expected to learn and improve themselves, or else find something else to do.\n\nIf a junior produced work at the level of some LLM and never learned (outside some odd growth spurts at rare intervals), that would inform their career options.",
                  "score": 4,
                  "created_utc": "2026-01-14 11:38:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzilxek",
              "author": "darraghor",
              "text": "the point is you pay people (developers) for the outcome of no mistakes, in software you collaborate and/or test your work and correct mistakes before shipping.\n\nWith AI tools people are often not doing this. They trust the AI tools more than they should. People are used to computers giving deterministic answers. LLMs are different but people haven't adjusted yet.",
              "score": 1,
              "created_utc": "2026-01-14 10:30:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzitlny",
                  "author": "Sparaucchio",
                  "text": ">They trust the AI tools more than they should.\n\nTrue\n\n>correct mistakes before shipping.\n\nWho does that, i think the industry has stopped shipping bug-free products 20 years ago",
                  "score": 2,
                  "created_utc": "2026-01-14 11:35:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzj5ymv",
                  "author": "economic-salami",
                  "text": "AI permanently replaces juniors, who usually do relatively mundane work and are net losses over the short term. Juniors leading juniors get nothing but seniors leading tireless juniors can actually do better.",
                  "score": 0,
                  "created_utc": "2026-01-14 13:03:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nziorwg",
                  "author": "Fr-Rolfe",
                  "text": "In your haste to blame the tools over the people driving them, you blamed the people driving the tool.",
                  "score": -1,
                  "created_utc": "2026-01-14 10:55:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzjkb9t",
          "author": "j00cifer",
          "text": "From the linked article:\n\n*”…Over and over we are told that unless we ride the wave, we will be crushed by it; unless we learn to use these tools now, we will be rendered obsolete; unless we adapt our workplaces and systems to support the LLM’s foibles, we will be outcompeted.”*\n\nMy suggestion:  just don’t use LLM. Try that.\n\nIf it’s unnecessary, why not just refuse to use it, or use it in a trivial way just to satisfy management?\n\nThat is a real question: why don’t you do that?\n\nI think it has a real answer:  *because I can’t do without that speed now, it puts me behind to give it up. And Iterating over LLM errors is still 100 times faster than iterating over my own errors.*",
          "score": 0,
          "created_utc": "2026-01-14 14:24:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzl5n85",
              "author": "ii-___-ii",
              "text": "This is only partly true, because AI is also being stuffed into places people didn't ask for. I don't want AI overviews whenever I google search. I didn't ask for AI to show up in my email. It's great when we use it intentionally, but sometimes it's not opt in, and it's there whether you like it or not.",
              "score": 1,
              "created_utc": "2026-01-14 18:48:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzjbb18",
          "author": "DustinBrett",
          "text": "Common knowledge is outdated quick when you discuss tech. Things change in months not decades. AI is soon to be Alien Intelligence.",
          "score": 0,
          "created_utc": "2026-01-14 13:35:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzk6zfh",
          "author": "Boysoythesoyboy",
          "text": "Humans are wrong all the time as well, has relying on other people been a 10,000 year confidence trick?\n\nOften they are nice, and instead of calling me an idiot when I say stupid things they just smile and nod and give me what I ask for. This is a warcrime, and we urgently need to remove humans from engineering.",
          "score": 0,
          "created_utc": "2026-01-14 16:13:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzntn1w",
              "author": "qruxxurq",
              "text": "Yes. LOL \n\nMost people are wrong nearly all the time, and their entire lives are just one long con. See: all of politics. \n\nBut not everyone. Every once in a while we get a Beethoven or Michelangelo or Einstein, and slightly more often we get real actual human beings who are thoughtful and honest and ethical and intelligent, instead of almost everyone else who is a mindless automaton.",
              "score": 2,
              "created_utc": "2026-01-15 02:50:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzjz3on",
          "author": "beatlemaniac007",
          "text": "Agree with the confidence point. But not sure that automatically means they ought to be rejected. Sounds to me like we need to adjust our expectations (which will likely happen organically) as now it's moved from deterministic to probabilistic stuff. It seems more like a transition phase, which will always come with uncertainty and fear.\n\nIn general it seems to be in line with how things progress in this industry. Trading control for leverage. When we got C we gained more leverage but gave up control of specifics of memory registers, etc. When we got Java we gave up control of memory management. SQL allowed us to be declarative and not worry about the \"how\". AI seems to align with this. The main paradigm shift is the probabilistic approach and I don't know if it will stick, but honestly given how much leverage we're getting out of it might just cause us to accept a lot of slop under the hood.",
          "score": 0,
          "created_utc": "2026-01-14 15:37:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzk5j86",
          "author": "RepresentativeAspect",
          "text": "You’re asking why we’re happy living with “an incredibly powerful tool” that is not perfect and always right?\n\nLLMs are right more often that I am. They are not helpful and accurate always.",
          "score": 0,
          "created_utc": "2026-01-14 16:07:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkjae9",
          "author": "NotUpdated",
          "text": "The value for me is that it's software (non deterministic) that can produce classic deterministic software -- thus my program will be correct after I get it correct and every time.  \n  \nYour point lays well in the bucket of those who are letting it generate things directly for users (emails, business questions, customer service, order taking etc...) lots of those have failed in many ways.\n\nIt's better to collect the best business questions 50-200 of them, and programmatically create software that answers those correct every time.",
          "score": 0,
          "created_utc": "2026-01-14 17:09:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzn4f8u",
          "author": "TeeTimeAllTheTime",
          "text": "Even if they hallucinate often, which depends on the model and the subject you can still not be a fucking idiot and verify things. Sounds like you just want to shit on AI and make assumptions",
          "score": 0,
          "created_utc": "2026-01-15 00:26:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsqaqv",
          "author": "Actual__Wizard",
          "text": ">The promise of “intelligence” available at a reliable price is the holy grail for businesses and consumers alike.\n\nYep. You fell for it. It's the most expensive text generation algo theoretically possible. You were so close to figuring it out.\n\nThere was technology back in the 1980s that did the exact same thing that LLMs do, but at a tiny faction of the energy expenditure. Unfortunately, the tech didn't work out, but instead of perusing ultra efficient AI tech, they pursued LLM tech instead.\n\nThey keep using ultra inefficient techniques that are not reliable in place of techniques that are ultra efficient and reliable.\n\nBy doing this, they're doing several things: One they think they're creating a moat that prevents competition: No they didn't, SAI tech is so fast that it will \"jump right over their moat.\" They're also getting their regulatory wishes granted, obviously they would rather just copy the content of a publisher website and serve their copy with their monetization on it instead of developing their own data models that are free of plagiarism. I think they also knew that \"real AI tech\" would become available soon, so they wanted to bully those companies out of the market.\n\nSo, the companies that were actually producing AI for scientific or medical reasons, aren't getting any attention anymore, and all the air has been sucked out of the room by chat bots that produce plagurized AI slop.\n\nIt really is disgusting to watch these tech fascists flip everything up side down due to their absurd greed. It looks like their data center plan is falling apart now too, so there's a good chance that they scammed themselves with their own lies.",
          "score": 0,
          "created_utc": "2026-01-15 20:52:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzig9oo",
          "author": "cavedave",
          "text": "I don't see where the 400 year figure is from. \nFor a 60 year reason the Eliza Effect. Weizenbaum made the first chatbot and people using it forgot it was a program after a few minutes.\n\n*edit Eliza effect wikipedia page https://en.wikipedia.org/wiki/ELIZA_effect",
          "score": -6,
          "created_utc": "2026-01-14 09:36:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzihogl",
              "author": "SwoopsFromAbove",
              "text": "Mechanical calculators were first invented in 1623. Since then we’ve built a whole society on the idea that computer-generated answers are always accurate and reliable.\n\nLLMs behave fundamentally differently, but their vendors exploit these societal expectations of perfect accuracy, along with other manipulative framings like “friendly” conversation tone and developers’ fear of falling behind, to drive the hype cycle and astronomical investment.",
              "score": 4,
              "created_utc": "2026-01-14 09:50:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nziivcv",
                  "author": "syklemil",
                  "text": "> built a whole society on the idea that computer-generated answers are always accurate and reliable.\n\nAnd to an extent that's beyond anything anyone working in the field would think, with maybe the ur-example being given by Charles Babbage:\n\n> On two occasions, I have been asked [by members of Parliament], 'Pray, Mr. Babbage, if you put into the machine wrong figures, will the right answers come out?' I am not able to rightly apprehend the kind of confusion of ideas that could provoke such a question.",
                  "score": 5,
                  "created_utc": "2026-01-14 10:01:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzjjaka",
          "author": "kappapolls",
          "text": "what do you mean they aren't as fantastical?  just a few weeks ago some dudes used GPT 5.2 to solve a couple erdos problems and formalized the proofs in lean.  that's pretty much sci-fi fantasy come to life",
          "score": -2,
          "created_utc": "2026-01-14 14:18:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjvdei",
              "author": "dummytroll",
              "text": "feels like there's a lot of denial in this subreddit, people refusing to accept new realities, i wonder how much time most of these people have tried a recent LLM properly.",
              "score": -2,
              "created_utc": "2026-01-14 15:20:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzm621e",
                  "author": "claytonkb",
                  "text": "I have access to frontier models through my employer for my day job (engineering). They are being **M.A.S.S.I.V.E.L.Y.** overblown. \"Hype\" doesn't even begin to describe it.",
                  "score": 2,
                  "created_utc": "2026-01-14 21:33:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzjlzzn",
          "author": "Thursty",
          "text": "1. What do calculators have to do with LLMs besides being a tool to save labor, like any other?\n2. Rhetoric about LLMs isn’t “designed” to be anything. Different parties have different views about it.\n3. People use them because it saves them time with tasks even if not always accurate. The dangers are real and will need to be addressed, but this is the case with much technology.\n4. Take a writing class. This is a poorly conceived and written article. The comparisons and analogies don’t make sense and the points you make are incoherent. Ironically, an LLM would help you write a better one.",
          "score": -3,
          "created_utc": "2026-01-14 14:33:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzj5y8e",
          "author": "oadephon",
          "text": "This is such copium. LLMs are already pretty good. They can make some pretty complex changes to your codebase with few to no bugs. Where do you think this technology will be in 5 years? It's not going to plateau, it's going to get better by magnitudes in all directions.\n\nWe're nearing the end of human wage labor. Focusing on the current flaws with LLMs is just copium to avoid addressing the elephant in the room, which is that AI is finally nearing human levels of intelligence after researchers tried for like 70 years.",
          "score": -5,
          "created_utc": "2026-01-14 13:03:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjbo22",
              "author": "ppppppla",
              "text": "Just one more trillion bro then we will have agi bro then nobody will have to work bro it will change the world bro",
              "score": 9,
              "created_utc": "2026-01-14 13:37:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzjcz23",
                  "author": "oadephon",
                  "text": "Bro the technology that's only 3 years old has problems bro, it's NOT gonna get much better bro don't worry",
                  "score": 0,
                  "created_utc": "2026-01-14 13:44:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzj7z5k",
              "author": "thecodingart",
              "text": "You have to be an idiot to post the words you just did…",
              "score": 4,
              "created_utc": "2026-01-14 13:16:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzjcmtq",
                  "author": "oadephon",
                  "text": "Nearly all AI experts think we are fewer than 20 years from Artificial Super Intelligence (ASI). You can put your head in the sand all you want, but these changes are coming quickly.",
                  "score": -2,
                  "created_utc": "2026-01-14 13:42:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzihvsi",
          "author": "betabot",
          "text": "I can’t take anyone seriously that says LLMs aren’t intelligent, particularly for software engineering tasks. Either that person’s definition of intelligence is woefully malformed or they’re in utter denial of what these models are capable of.\n\nAre they perfect? No. Do they make stuff up sometimes? Yes. These are features I would also attribute to humans, though.\n\nI can crank out tens of thousands of lines of sophisticated and high quality code in a dozen hours with these models. It’s a game changer for productivity, and that wouldn’t be possible if there wasn’t some reasoning going on. Just look at the chain of thought output.",
          "score": -19,
          "created_utc": "2026-01-14 09:52:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nziiina",
              "author": "azhder",
              "text": "I can’t take seriously anyone that says LLMs are intelligent. So I will not be taking seriously you not taking others seriously.\n\nNow, let’s have some fun. I will show you mine, you show me yours, we’ll measure up each other’s malformity.\n\nHere is mine:\n\n> Intelligence is the ability to use past knowledge and experience **in a new way** in order to solve a problem or answer a question.\n\nLet the measuring begin !!!",
              "score": 12,
              "created_utc": "2026-01-14 09:58:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzj4jmk",
                  "author": "alien-reject",
                  "text": "If I don’t know coding but the llm can code a whole website for me, I’d say it’s more intelligent than me",
                  "score": 0,
                  "created_utc": "2026-01-14 12:54:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nziiv8x",
                  "author": "betabot",
                  "text": "https://deepmind.google/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/\n\nWould a LLM discovering new solutions to frontier math problems meet your definition? Because we hit that benchmark almost a year ago.",
                  "score": -10,
                  "created_utc": "2026-01-14 10:01:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzimq6o",
              "author": "falconindy",
              "text": "You really should read the transformer white paper (or get a chat bot to summarize it for you lol). To dumb it down, LLMs generate one word at a time with the next word being a highly statistically likely word to follow. There's no intelligence. No thought. The\"thinking\" you refer to is just window dressing on top of your input to give you the impression of intelligence. Tech companies want you to think this is more than just text generation because it's an expensive ass product they're trying to sell you.",
              "score": 5,
              "created_utc": "2026-01-14 10:37:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzip32s",
                  "author": "hotcornballer",
                  "text": "And you should read the definition of \"Emergent behaviour\"",
                  "score": 3,
                  "created_utc": "2026-01-14 10:58:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzjdm9f",
                  "author": "IlliterateJedi",
                  "text": "A lot of us have read it.  Seeing what reasoning LLMs are capable of has made me reconsider my definition of intelligence and what it means.  Watching an LLM iterate from the wrong answer to the right answer by using tools like Python to reconsider and analyze the query is something that to me is by definition 'intelligent' behavior. The same is true with passing an LLM a complete new repository and watching it reason through how it works. It might be built on a scaffold of text embeddings, but the it's clear from using these tools that they are not really just 'guess the next word engines' anymore.",
                  "score": 1,
                  "created_utc": "2026-01-14 13:48:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzintxy",
                  "author": "betabot",
                  "text": "The human brain is just a bunch of firing neurons, is it not? There’s no intelligence, no thought, just biochemical and electric signals.\n\nThe brain and LLMs obviously work very differently in practice, but I think calling these models next token predictors is reductive to the point of being misleading. To solve a problem one must predict the correct tokens. To predict those correct tokens one must be truly intelligent. Correct prediction means the model has learned a true internal representation of reasoning.\n\nThat representation does not appear to be as robust as the human “circuitry” today, but there are definitely reasoning “circuits” in LLMs.",
                  "score": -2,
                  "created_utc": "2026-01-14 10:47:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzj1aff",
          "author": "etrnloptimist",
          "text": "Every tool has their problems. Doesn't mean they aren't useful. I hate when my IDE doesn't jump to definition, but I don't throw the whole thing away.",
          "score": -1,
          "created_utc": "2026-01-14 12:32:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjfuwm",
          "author": "AutoPanda1096",
          "text": "I think people overestimate LLMs capabilities which leads to others deciding that ai is useless.\n\nYep, I see mistakes and I also see it helping me in ways that nothing else ever has.\n\nI was asking AI about a business spec earlier and it  was fantastic at helping me understand enough to be able to find the relevant regulatory guidance.\n\nRan it by the business users and programmed it in \n\nI was able to do something in minutes that might have taken hours  previously.\n\nNot for the first time.  And it keeps happening.\n\nThe trick is to remember that it's *just a tool*\n\nAsk the right questions.\n\n\"Where do I need to look to find\"\n\n\"What options should I read up on\"\n\n\"I've been approaching it this way, can you suggest things I might have missed\"\n\nAnd then you take the answer and apply your own intelligence \n\nLLMs don't exist in a vacuum and I think this is the mistake people who struggle to use them effectively are making.\n\nSee it as being like a colleague sitting next to you.  I sit next to Steve and sometimes he talks crap and sometimes he points me to the right thing.  I never trust Steve explicitly because he's fallible.  Like any source tbh.\n\nAsk the right questions.  \n\nApply your own intelligence.\n\nI've been doing this job for 30 years and these tools are a step change in my productivity.  Do I see stuff that doesn't add up?  Hell yeah!  Does that make LLMs \"a trick\"?  Hell no.\n\nI used to think like you but slowly and surely I learned how to use the tool more effectively.\n\nBack in the 2000s I leapt ahead of my peers because I could Google better than them.\n\nThe same is happening again.\n\nSome of us will use these tools much better than others because we get what works and what doesn't.\n\nThe irony is that it seems you need a degree of intelligence to get the most out of artificial intelligence.",
          "score": -1,
          "created_utc": "2026-01-14 14:00:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjvty2",
          "author": "vansterdam_city",
          "text": "I swear people who bring up hallucinations have tried this stuff a few times early on and then made up their mind.\n\nIf you’ve been continuously using the newest models, they are getting significantly better. I honestly haven’t had a straight up completely fabricated hallucination out of GPT 5.2 and I use it every day.",
          "score": -2,
          "created_utc": "2026-01-14 15:22:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjju00",
          "author": "_darth_plagueis",
          "text": "If you use llms, you should know they allucinate e check things. They save you a lot o time in certain tasks, so it is worth it on a personal level. \n\nIf you think about the amount of resources used to produce and maintain llms, probably they are not worth it. They may become more efficient later, we will see.",
          "score": -3,
          "created_utc": "2026-01-14 14:21:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjuaxb",
          "author": "dummytroll",
          "text": "I guess because the average human probably hallucinates more, yet we still read reddit posts",
          "score": -4,
          "created_utc": "2026-01-14 15:14:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbpqbo",
      "title": "Your estimates take longer than expected, even when you account for them taking longer — Parkinson's & Hofstadter's Laws",
      "subreddit": "programming",
      "url": "https://l.perspectiveship.com/re-plla",
      "author": "dmp0x7c5",
      "created_utc": "2026-01-13 12:12:38",
      "score": 464,
      "num_comments": 72,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qbpqbo/your_estimates_take_longer_than_expected_even/",
      "domain": "l.perspectiveship.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzc9plx",
          "author": "930913",
          "text": "Survivor bias. Only projects that underestimate get picked.\n\nAny project that is accurately estimated gets passed over to pick an underestimate instead, because the business perceives better value.",
          "score": 423,
          "created_utc": "2026-01-13 12:20:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzcj0ku",
              "author": "Piisthree",
              "text": "Yeah, that and the business sometimes just makes the estimate for you. \"When can we have this done?\" \"June\" \"We need it by April. Can we have it by April?\" \"Well, not re---\" \"We'll put it down for April 15th\"",
              "score": 145,
              "created_utc": "2026-01-13 13:21:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzcodjc",
                  "author": "saynay",
                  "text": "I have been dealing with that for the last few month. \"What is your estimate to complete this work, and why is it the end of this week?\"",
                  "score": 66,
                  "created_utc": "2026-01-13 13:52:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzdwinp",
                  "author": "o5mfiHTNsH748KVq",
                  "text": "The most important skill for an enterprise developer is being able to say “actually, no, we can’t have it done before June and here is why”",
                  "score": 17,
                  "created_utc": "2026-01-13 17:36:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzov6f2",
                  "author": "NotMyRealNameObv",
                  "text": "\"When can it be done?\" \"June.\" \"That's not acceptable, we already promised the customer it will be done in April.\" \"...\"",
                  "score": 2,
                  "created_utc": "2026-01-15 07:20:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzci42x",
              "author": "Plank_With_A_Nail_In",
              "text": "This is interesting thank you for the insight. So you want stupid optimistic estimates to win contracts but then better estimates to actually run the project once you got the green light or do we continue you with the stupid short estimation and fail every milestone? I guess once the requirements change, and they will change, you can switch to proper estimation?\n\nI always multiply my initial estimate by 4 and its worked for me for 30 years now. There is always some unknown people dependency that fucks even the best estimates.",
              "score": 21,
              "created_utc": "2026-01-13 13:16:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzdthyg",
                  "author": "gc3",
                  "text": "Over promising and  under delivering is a good way to win the first contract but not the rest.",
                  "score": 9,
                  "created_utc": "2026-01-13 17:22:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzd5wzv",
              "author": "Guvante",
              "text": "You also don't analyze on time projects. If you managed to estimate correctly there is no review of how you managed that you just move on.\n\nBut when you go over you do a bunch of investigation into why. That investigation often becomes the basis for talking about how estimating should work.",
              "score": 13,
              "created_utc": "2026-01-13 15:21:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzelg91",
                  "author": "bwainfweeze",
                  "text": "I’ve been on a nearly on time project for a F50 company. I think the latest we ever were was 3 weeks for a quarterly milestone and usually more like one, which made us the short tent pole pretty consistently. \n\nThe three week incident involved vendor problems and not forcing help on the aggrieved engineer earlier, and that was how I finally got Work In Progress limits instituted. Most late stories would be pair programmed with someone who finished their work and was trying to start something new. And if they couldn’t help them then I (the de facto principal) would step in.\n\nSo what happened is that the Work Expanded. To help keep the overall project on schedule, we started taking on more work at the boundaries between our domain and the teams we interacted with. It was more work but also more status, because every time we took over a chunk of functionality, our mandate expanded and the other team’s narrowed. \n\nIn fact in the end I came to believe that was how this company operated. They threw people at big projects and the islands of competence would crystallize and expand until they touched each other, filling in the available problem space sufficiently to meet the spirit of the Swiss Cheese Model of reliability.",
                  "score": 3,
                  "created_utc": "2026-01-13 19:27:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzf0f2j",
              "author": "xilanthro",
              "text": "Came here to say this, with a story about a co-worker, let's call her Cathy (because that was her name) that I saw get passed up to manage a conversion to client-server systems around 1990 at corporate headquarters in San Francisco. Her plan was razor-sharp and almost perfectly accurate, while Don's plan (that wasn't his name) was blissfully ignorant, leaving out major functional requirements and user-acceptance steps, so it estimated 1/3 the time Cathy's plan specified. \n\nManagement loved Don's plan and went with it. Don became management, and the project took only a little longer than Cathy's estimate had predicted. This is the story of all 'corporate success' in a nutshell.",
              "score": 8,
              "created_utc": "2026-01-13 20:37:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzedk54",
              "author": "bwainfweeze",
              "text": "Put another way, if you’re honest and your coworker lies, they will take his answer over yours, because it’s what they want to hear. In child development this is called Bidding and I will leave you to draw your own conclusions from this.",
              "score": 5,
              "created_utc": "2026-01-13 18:52:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzdt4jt",
              "author": "gc3",
              "text": "This is not the reason. I have worked on non essential projects and they still take longer than expected. Time boxing (It's done on Tuesday, to some definition of what done is) is the only way to manage it.... Then you just make sure there are no really unfinished features or bad bugs on Tuesday.",
              "score": 3,
              "created_utc": "2026-01-13 17:20:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzei9j0",
                  "author": "bwainfweeze",
                  "text": "Pretty much any development practice can be kept working for about eighteen months on force of will. And then the wheels start to come off. That’s part of why it’s a problem having folks with only 2 years at any one place. Any bad ideas you helped introduce the moment you had any standing have now shown their consequences and your urge to leave may be less to do with you having grown a lot in two years and more to do with not wanting to face the consequences of your own actions. Or inactions. \n\nWith that said, time boxing can turn out to create so much tech debt that 18 months in, all estimates start to go up because people are now padding to deal with the debt in one sense or the other (putting up with vs paying down) and now your time boxes go up or every story is fun-sized instead of a full sized candy bar. \n\nAs Devlin Henney pointed out in several excellent rants, stories per month is plotting time on both axes and is stupid.",
                  "score": 3,
                  "created_utc": "2026-01-13 19:13:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzde629",
              "author": "ul90",
              "text": "Yes, that is true. Sadly.",
              "score": 2,
              "created_utc": "2026-01-13 16:00:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzdtpi7",
              "author": "caltheon",
              "text": "It's like the opposite of Scotty from Star Trek's estimates",
              "score": 2,
              "created_utc": "2026-01-13 17:23:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzfjyr2",
              "author": "zoddrick",
              "text": "This is why learning to ship the smallest possible increment (MVP) first and then delivering value over team is preferred.",
              "score": 2,
              "created_utc": "2026-01-13 22:08:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzfsoee",
              "author": "Tim-Sylvester",
              "text": "> Survivor bias. Only projects that underestimate get picked.\n\nRight? Like public agencies always picking the low bid then everyone being surprised when there's a change order for unplanned costs. \n\nWow, no shit! Everyone lied about their pricing because lying about your price was the only way to have a chance, and the biggest liar won. \n\nWe create an incentive to be dishonest, then act surprised when people take advantage of the incentive.",
              "score": 2,
              "created_utc": "2026-01-13 22:50:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzdswm4",
              "author": "Whatever4M",
              "text": "Estimates don't necessarily translate to value.",
              "score": 1,
              "created_utc": "2026-01-13 17:19:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzeiyvu",
                  "author": "bwainfweeze",
                  "text": "Some of the places that worry a lot about estimates are feature factories so that is definitely much more true in some cases than others. You’re just pumping out stories with no regard for how many users will actually use them and how often. \n\nI don’t know if I would go so far as to saying there’s correlation, but it’s at least a 2x2 grid with one or two quadrants that are a world of suck.",
                  "score": 1,
                  "created_utc": "2026-01-13 19:16:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzk9dqd",
                  "author": "mallardtheduck",
                  "text": "No, but cost-benefit-ratio is a pretty good measure of \"value\". The estimate is a measure of \"cost\". So if your project has high percieved benefit and a low estimate (cost) it therefore has a good cost-benefit-ratio (value) and is more likely to be approved.",
                  "score": 1,
                  "created_utc": "2026-01-14 16:24:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzk8eyu",
              "author": "mallardtheduck",
              "text": "And not just in programming either... Just look at how _every_ major infrastructure/construction project ends up late and over budget.",
              "score": 1,
              "created_utc": "2026-01-14 16:20:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzk8tji",
              "author": "aiij",
              "text": "\"We choose to do these things not because they are easy, but because we thought they would be easy.\"",
              "score": 1,
              "created_utc": "2026-01-14 16:21:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzdt75y",
              "author": "gc3",
              "text": "This is not the reason. I have worked on non essential projects and they still take longer than expected. Time boxing (It's done on Tuesday, to some definition of what done is) is the only way to manage it.... Then you just make sure there are no really unfinished features or bad bugs on Tuesday.",
              "score": 1,
              "created_utc": "2026-01-13 17:20:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzefjec",
                  "author": "bwainfweeze",
                  "text": "It’s both and more, much more. \n\nWhile we think the deadline is still achievable we will still entertain additional adds from business and coworkers and from the tech debt we encounter along the way. Once the deadline becomes in danger then we start to push back hard, but it’s too late because there are still surprises lurking that are going to push us over the limit. That’s how Parkinson plus Hofstadter are worse than either on its own. \n\nWhen we find a bug in production and agree to a very defined fix, most of the jitter there is glitchy CI pipelines, which is why I’m always harping on fixing your CI so you don’t look like clowns during an outage. If the CI is solid - and fast - and the dev doesn’t make transcription errors, an estimate of fifteen minutes or an hour is often enough pretty close to accurate. But if a build fails and CI dominates the code-build-test cycle then Hofstader isn’t even enough buffer. \n\nBut other due dates are flexible, and business people are always hungry for more functionality and once they get on the board they will “clarify” what the purpose of the story is by trying to make three features sound like one. And they pretty much get paid to misunderstand the backlog system, so good fucking luck getting them to stop.",
                  "score": 1,
                  "created_utc": "2026-01-13 19:01:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzevu2x",
          "author": "holyknight00",
          "text": "The problem is management likes to be lied to. Good estimates take you nowhere. They prefer a 1 week estimate delayed 3 times into a 3 week total time than an accurate 2-week estimate. In their mind the first one is cheaper even if it ends up being more expensive every time. I even showed the numbers to people, and they do not care.",
          "score": 23,
          "created_utc": "2026-01-13 20:15:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfv4x5",
              "author": "NadirPointing",
              "text": "Management doesn't like being lied to, they just hate answers they don't know how to handle far worse. They'd rather you lie and say 1 week and get done in 3 instead of say I don't know and be done in 2. They can't work with \"I don't know\". And they can't get anyone to accept 3 weeks.",
              "score": 16,
              "created_utc": "2026-01-13 23:03:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzcaqux",
          "author": "hagg3n",
          "text": "I liked where you thoughts were going but in the end I find the article a little too shallow. Perhaps this work needed more time than your time box allowed? Either way I think this is the real challenge. If you focus on the process/deadline you risk underestimating what you were trying to accomplish in the first place.",
          "score": 35,
          "created_utc": "2026-01-13 12:28:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzcdauq",
              "author": "axkotti",
              "text": "Maybe the author underestimated the time it takes to create a blog post.",
              "score": 43,
              "created_utc": "2026-01-13 12:45:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzcluyy",
              "author": "syklemil",
              "text": "It also comes off as rather generic /r/projectmanagement stuff",
              "score": 7,
              "created_utc": "2026-01-13 13:38:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzdnmt7",
              "author": "popiazaza",
              "text": "Typical linkedin lunatic post.",
              "score": 3,
              "created_utc": "2026-01-13 16:43:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzfdrph",
              "author": "Cualkiera67",
              "text": "I don't get why wouldn't you just over estimate everything. How long will this take? 300 years. What's the incentive to say less?",
              "score": 2,
              "created_utc": "2026-01-13 21:39:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzff7ln",
                  "author": "hagg3n",
                  "text": "To be alive when it’s done?",
                  "score": 5,
                  "created_utc": "2026-01-13 21:45:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzd6f2r",
          "author": "fuhgettaboutitt",
          "text": "Cross post this to the project managers subreddit and see them lose their shit over how its unacceptable from folks who havent figured out the mystery of  getting \"hello world\" to work",
          "score": 17,
          "created_utc": "2026-01-13 15:24:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzed09a",
              "author": "bwainfweeze",
              "text": "I really want to talk to any plumbers and electricians who have worked in their houses. So I know if they’re this shitty to everyone or if it’s a gambit.",
              "score": 3,
              "created_utc": "2026-01-13 18:49:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzfrn5a",
                  "author": "-grok",
                  "text": "As annoying as the trades work is, it is far more predictable than software projects.  Mostly because when you connect two pipes together, the neighbor's car two the streets over almost never explodes as a result.\n\n&nbsp;\n\nAnd that work is what all of the pmi.org techniques are based on.",
                  "score": 11,
                  "created_utc": "2026-01-13 22:45:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzeu2d9",
          "author": "FlyingRhenquest",
          "text": "Estimating tasks really isn't that hard. You just have to be mindful about whether you're regularly missing your estimates and adjust upward from your gut answer. I was told by a manager once that my estimates were the most accurate he's ever seen, while he was pressuring me to reduce the estimate. I told him I could lower the estimate but it'd still get done in the time I thought it'd get done in.\n\n\nOur new developer on our team was constantly blowing his estimates out by huge margins and working a lot of overtime because of it. I told him \"You're just estimating the time you think it'll take to code it. You're not accounting for unit tests, integration testing, build instrumentation, meetings, interruptions, documentation, or Jira bookkeeping. Multiply your gut answer by four and if the number you get is less than two days, estimate two days.\" That's a starting point, but it'll be way more accurate than the \"couple of hours\" every junior level guy thinks every task will take.\n\n\nWith that baseline, you can then pay attention to whether your estimates are generally too high or two low. This is an ongoing process as you'll get more comfortable with the code base and processes of the team with time.\n\n\nI've found this to be very effective, to the point where I'm very sure of my time estimates and they're usually accurate to within plus or minus half a day. If I notice I'm regularly finishing sooner than I expected, I start tweaking them down a bit. If I find I'm regularly missing them by a day or more, I start tweaking them up a bit. It's an ongoing process, but it's not that difficult once you get the hang of it.",
          "score": 12,
          "created_utc": "2026-01-13 20:07:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzh4hm5",
              "author": "dontcomeback82",
              "text": "You must be doing some really boring shit.",
              "score": -5,
              "created_utc": "2026-01-14 03:15:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzewjhv",
          "author": "bwainfweeze",
          "text": "I’m surprised that the author doesn’t mention Agile as one of the tools. With Agile we don’t let people think too much about when the whole thing will be “Done”. “Done” being a lie anyway, except for the Minimum Viable Product. Because if it’s a hit we are going to iterate on it until the money runs out or the company gets bought. So there’s no Done, only What’s Next. The only Done is the end of What’s Next. \n\nWhen Agile was new this was a hard pill to swallow, like explaining the virtues of an Arnold Palmer to an alcoholic. You have to first embrace that “drinking” is hurting you before the alternative doesn’t look silly or broken. And most companies hadn’t embraced it, and some were bankrupted by people who did. So then fear chased many companies into it which is how we ended up with Scrum everywhere. The worst version of Agile from a process improvement instead of an extractive model.",
          "score": 11,
          "created_utc": "2026-01-13 20:19:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjt3b6",
              "author": "Relative-Scholar-147",
              "text": "Because nobody does Agile. We do daylies, sprints, jira, kabhan, but no Agile.",
              "score": 2,
              "created_utc": "2026-01-14 15:09:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzklwn4",
                  "author": "bwainfweeze",
                  "text": "That’s not true. Most of your SDLC activities besides the scrum ones are straight out of Extreme Programming. The ‘00s were mostly about getting teams to use more than a couple of the practices and the ‘10s were about getting them to use more than half.",
                  "score": 1,
                  "created_utc": "2026-01-14 17:21:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzg8vrn",
          "author": "copypaper2",
          "text": "And scope creep.  Can we just add... or how about this...",
          "score": 3,
          "created_utc": "2026-01-14 00:17:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nziaanq",
              "author": "mv1527",
              "text": "Yes, I'm guilty of this...  Oh, I spent only 4 hours on this  8 hour task so maybe we can add Y....      After adding Y, the client has some additional feedback on it and now we are suddenly over the estimate.",
              "score": 1,
              "created_utc": "2026-01-14 08:38:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzct4ew",
          "author": "menge101",
          "text": "\"Parkinson's Law\" and using an old lady as the first example is a _real_ choice...",
          "score": 6,
          "created_utc": "2026-01-13 14:17:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfzi1o",
          "author": "mr_birkenblatt",
          "text": "something ironic to have Parkinson's make predictions about shaky estimates",
          "score": 1,
          "created_utc": "2026-01-13 23:26:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzcrjg8",
          "author": "Ok-Arachnid-460",
          "text": "Baby I only last a few seconds. But who knew it led to 30 minutes of pound town.",
          "score": -14,
          "created_utc": "2026-01-13 14:08:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdv6h0",
      "title": "Newer AI Coding Assistants Are Failing in Insidious Ways",
      "subreddit": "programming",
      "url": "https://spectrum.ieee.org/ai-coding-degrades",
      "author": "CackleRooster",
      "created_utc": "2026-01-15 20:42:25",
      "score": 444,
      "num_comments": 184,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qdv6h0/newer_ai_coding_assistants_are_failing_in/",
      "domain": "spectrum.ieee.org",
      "is_self": false,
      "comments": [
        {
          "id": "nzsxhlw",
          "author": "band-of-horses",
          "text": "This is not surprising, they have gotten better at generating decent code, but they are still very much trying hard to do what you want even if it's a bad idea. You have to know what you're doing and review the output to make sure they're not doing stupid things. I often find myself having to prefix prompts with encouragement to tell me nothing needs to be done and not just to generate output because I asked. If you do things like tell it to analyze some code and consider ways to refactor it, it will absolutely find ways to refactor it, even if the current implementation is probably the best way to do it. If you tell it to look for bugs in code, it will find bugs. No matter how obscure or unlikely or irrelevant, they are. It's easy to get yourself in trouble because it wants to do what you ask even if it shouldn't.",
          "score": 137,
          "created_utc": "2026-01-15 21:26:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzv41u3",
              "author": "Ysilla",
              "text": "> but they are still very much trying hard to do what you want even if it's a bad idea\n\nThis is honestly the worst part, and not just for code generation. Agents can be useful to get feedback on code, but getting to be _neutral_ is incredibly hard.\n\nJust today I had a great example asking it about one specific change in a branch. At first I asked \"look at those changes, is this specific thing a bad idea?\", and it went \"absolutely, it's bad because ...\" and listed 4 different reasons why it was the worst thing ever. Then I asked the exact same question, but changed \"bad\" to \"good\", and it agreed it was the best change ever. And often, when I asked for more details about any reason it gave for one or the other, it just \"switched side\" again.\n\nAnd the amount of devs I see blindly following them is scary. Or even using them as justification, like \"Oh idk Cline told me to do like this\" when asking for details on a merge request.\n\nEdit: I feel like many are missing the point in replies, neutral questions also have the same issue, you can make it \"change stance\" on most of the replies just by asking more details.",
              "score": 64,
              "created_utc": "2026-01-16 04:31:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzwdvx4",
                  "author": "SanityInAnarchy",
                  "text": "I've caught Gemini being sycophantic way less often than the others, but still... Sometimes it can be helpful to stay neutral, and sometimes it can be helpful to take advantage of the sycophancy like you did, get *both* answers, and hopefully find some useful information among them.\n\nMy biggest complaint was and is the lack of... well, *agency.* It wasn't my choice to start using them, and I'm sure I'm not the only one.",
                  "score": 20,
                  "created_utc": "2026-01-16 10:51:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzvexx2",
                  "author": "Chii",
                  "text": "it's easy to ask for a breakdown of the pros and cons of it.",
                  "score": 2,
                  "created_utc": "2026-01-16 05:46:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzxf1h2",
                  "author": "SerdanKK",
                  "text": "So ask neutral questions? You should train yourself to do that anyway.",
                  "score": 1,
                  "created_utc": "2026-01-16 14:45:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzthu6s",
              "author": "menckenjr",
              "text": "This continues to make it sound like they're almost more trouble than they're worth.",
              "score": 65,
              "created_utc": "2026-01-15 23:04:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztuja1",
                  "author": "slaymaker1907",
                  "text": "I find them incredibly useful for things which are difficult to discover but easy to verify. For example, the Pandas API is enormous and complicated, but once it gives me some sample code, I can usually figure it out.\n\nA lot of things can also be checked by just running it once and making sure the results look sensible, at least when combined with some programming knowledge.\n\nI’ve even used the AI to try and double check things that are unclear from the docs. In that case, it is sort of a reference of last resort, though it takes some art to craft the question so that it doesn’t just agree with my assumptions.",
                  "score": 70,
                  "created_utc": "2026-01-16 00:12:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzv25h3",
                  "author": "xmsxms",
                  "text": "If you know there is a legitimate problem that requires a solution, and you have an inkling of what that solution might be, but couldn't be arsed doing it yourself, it can absolutely be a huge time saver.",
                  "score": 10,
                  "created_utc": "2026-01-16 04:19:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzuxpli",
                  "author": "RagingBearBull",
                  "text": "Depends on your project I suppose.\n\nfor me, personally I don't use them at all.\n\nI tried them in the past to do simple rewrites from say an older language to C++ and that didn't work well.\n\non top of that, even for my python code base, i found just writing the code vs the prompt to be more effective. \n\nIf needed something from the API it is easier still faster to do a control f and search in the documentation.\n\n\nlastly, while i dont have export controls to consider i dont entirely trust somehting that crawls my code base, especially since for me vscode built-in search feature is actually incredibly good.",
                  "score": 4,
                  "created_utc": "2026-01-16 03:51:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztndvd",
                  "author": "fexonig",
                  "text": "if you *do* know what you are doing, ai tools can easily turn a 8 hour task into a 10 minute one",
                  "score": 5,
                  "created_utc": "2026-01-15 23:33:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzwkymf",
                  "author": "drink_with_me_to_day",
                  "text": "The only \"problem\" with AI is the cost/speed of inference\n\nOnce you go \"create a lib wrapper with this signature\" and the AI creates in 2 seconds what would take you 4 hours of messing with docs, testing, checking sync and adding tests, you can never go back\n\nPeople who are anti-ai ~~will be left behind~~, actually they will just start using it a bit later, because you literally cannot be left behind because AI will just get you up to speed in a jiffy",
                  "score": -4,
                  "created_utc": "2026-01-16 11:49:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzx81ov",
              "author": "creaturefeature16",
              "text": "I say this often, but: LLMs give you what you *want*, but not what you *need*. And that distinction cannot be understated.",
              "score": 3,
              "created_utc": "2026-01-16 14:10:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzx2po4",
              "author": "putin_my_ass",
              "text": "This is accurate.  I hit upon a workflow where I end the prompt with \"do not write any code until I ask you to, let's discuss the plan first\" and that avoids these kinds of unnecessary refactors because you can tell it to remove that part of the plan.\n\nI also have it output a CONTEXT.md file so that my instructions like \"don't EVER remove that part of the code again!\" are preserved between agent sessions.",
              "score": 1,
              "created_utc": "2026-01-16 13:42:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzvesto",
              "author": "Chii",
              "text": "> they are still very much trying hard to do what you want even if it's a bad idea\n\ni don't want the AI to restrict what i can and cannot do - it should do what i want, even if it turns out to be a bad idea. \n\nThe consequences is something that i would have to pay for or suffer through - that's the punishment for asking for something something stupid with an AI.",
              "score": 1,
              "created_utc": "2026-01-16 05:45:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzx86nz",
              "author": "DogOfTheBone",
              "text": "I work with one codebase that has a very stupid core architectural decision that was decided by people who didn't know what they were doing. When trying to have Claude help me figure out how to fix this, it was effusive in telling me how clever and smart this awful architecture was.\n\n\nIt'd be funny if it wasn't so dangerous.",
              "score": 1,
              "created_utc": "2026-01-16 14:10:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsvpbh",
          "author": "SpaceCadet87",
          "text": "The better AI coding assistants work overall, the more damage they _will do_ when they inevitably screw up because of goal misalignment or just random chance.",
          "score": 159,
          "created_utc": "2026-01-15 21:18:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzt4s9s",
              "author": "ZirePhiinix",
              "text": "All AI coding agents work just fine with an engineer managing them. The real cluster-fuck happens when non-engineer people vibe-code entire systems and let them loose.",
              "score": 66,
              "created_utc": "2026-01-15 21:59:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzttt9v",
                  "author": "SpaceCadet87",
                  "text": "The better AI coding assistants get however, the higher that bar of engineer needs to be to manage them.  \nIf 99.9% of the time your AI works perfectly and generates flawless code, more and more engineers start to trust it. This gives it *way* more capacity to mistakenly delete your entire production database and all backups in a bid to clean up unnecessary code comments just because the RNG gods decided to betray you that day.",
                  "score": 43,
                  "created_utc": "2026-01-16 00:08:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzvh48h",
                  "author": "wrosecrans",
                  "text": "\"This works fine as long as the human operating it is absolutely perfect, 100% of the time\" is an interesting contrast to the fact that we invented computer programming so we could have reliable machines to mitigate the fact we know that no human can be perfectly reliable 100% of the time.",
                  "score": 10,
                  "created_utc": "2026-01-16 06:03:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztbuz8",
                  "author": "band-of-horses",
                  "text": "Literally just asked one to refactor some code that had a giant switch statement in a controller to sort through parameters and decide which database column to update. It came up with 8 classes, including an abstract base class and an executor class, which would then run one of 6 command classes, each of which had the responsibility of updating...exactly one database column. \n\nThis is the kind of nonsense someone who knows what they're doing will spot and put a stop to. It's the kind of thing that is going to creep into \"vibe coding\" or with lazy developers. Of course one might think \"no harm no foul\", but then your codebase becomes a bloated mess of abstractions and pointless code until your llm context window begins to strain and you end up with just a mess of enterprise spaghetti code that no one can follow and even LLMs begin to struggle with.",
                  "score": 57,
                  "created_utc": "2026-01-15 22:33:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzw5r4g",
                  "author": "edgmnt_net",
                  "text": "There are analogous incentives for people trying too hard to use AI to screw things up. I suspect even engineers may be prone to relax their standards too much to reach the advertised productivity gains, because LLMs increase code generation throughput without a corresponding increase in review capacity or operator understanding. Also, due to increased productivity it's easier to just pile stuff up and beyond a point we may see super-linear / compounding increases in issues, unless your project is very flat. And even if it's flat, good luck dealing with thousands of features when you end up needing to upgrade some major dependency.",
                  "score": 3,
                  "created_utc": "2026-01-16 09:38:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzwi7tk",
                  "author": "HommeMusical",
                  "text": "> All AI coding agents work just fine with an engineer managing them.\n\nWe have seen endless, endless examples of your statement being entirely untrue.",
                  "score": 2,
                  "created_utc": "2026-01-16 11:27:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzt7kyp",
                  "author": "CoreParad0x",
                  "text": "And tbh the examples in this are also not the kinds of things I think would come up with an actual engineer managing them. It’s the kind of stuff that would come up from giving it bad tasks and not validating output.",
                  "score": -1,
                  "created_utc": "2026-01-15 22:12:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzsoe34",
          "author": "Imnotneeded",
          "text": "\"AI Coding Assistants Are Failing\" Just reading the title makes me happy",
          "score": 331,
          "created_utc": "2026-01-15 20:44:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwfltw",
              "author": "DaredevilMeetsL",
              "text": "Obligatory XKCD: https://xkcd.com/743/\n\nTiny little violins playing around me.",
              "score": 53,
              "created_utc": "2026-01-16 11:06:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o02a49s",
              "author": "red75prime",
              "text": "\"AI Coding Assistants don't react to an underspecified impossible task the way they were reacting.\" Maybe it's time to change a coding harness.",
              "score": 1,
              "created_utc": "2026-01-17 06:16:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzxtyev",
              "author": "beatlemaniac007",
              "text": "Lol I just don't get reddit. Why do you WANT them to fail so bad? There can be debate about their hype vs capabilities but doesn't everyone want to be able to code/build in a natural language? Surely actual coding languages are just a tool for their time? They're not timeless things to hold onto if natural language can work. If AI is currently broken, shouldn't the push be to make them better vs banish them?",
              "score": -8,
              "created_utc": "2026-01-16 15:54:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyl7um",
                  "author": "bawng",
                  "text": "> If AI is currently broken, shouldn't the push be to make them better vs banish them?\n\nNot unless there's first a push to not make them extremely harmful for the environment. We need less resource usage, not more.",
                  "score": 20,
                  "created_utc": "2026-01-16 17:54:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzyvcsf",
                  "author": "Nolari",
                  "text": "> doesn't everyone want to be able to code/build in a natural language?\n\nNo? Natural language is inefficient and imprecise.",
                  "score": 11,
                  "created_utc": "2026-01-16 18:39:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzynck4",
                  "author": "collegethrowawai",
                  "text": "Better agents means reduced employment opportunities for people in this sub. Of course people will be against that.",
                  "score": 2,
                  "created_utc": "2026-01-16 18:04:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzz6bwo",
                  "author": "lewie",
                  "text": "Cost/benefit.  If it costs 5x as much to double performance, what are we gaining?\n\nMind you, cost should also include increased prices for consumer of electronics, power consumption, water consumption, and job opportunities. Offloading customer service to AI to save 10% labor, but now nobody can afford the product - what did we gain?",
                  "score": 1,
                  "created_utc": "2026-01-16 19:28:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztsaou",
              "author": "Independent_Pitch598",
              "text": "Why?",
              "score": -44,
              "created_utc": "2026-01-16 00:00:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvedz6",
                  "author": "Chii",
                  "text": "because of schadenfreude",
                  "score": 17,
                  "created_utc": "2026-01-16 05:42:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzuhksu",
                  "author": "scruffles360",
                  "text": "Because Reddit. Cynicism gets upvotes.",
                  "score": -40,
                  "created_utc": "2026-01-16 02:20:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzue4rq",
                  "author": "Cualkiera67",
                  "text": "Losers just like seeing things fail",
                  "score": -53,
                  "created_utc": "2026-01-16 02:01:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzspkg6",
              "author": "AltruisticPrimary34",
              "text": "wouldn't you want the tools to be good?",
              "score": -160,
              "created_utc": "2026-01-15 20:49:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzt0o1c",
                  "author": "Imnotneeded",
                  "text": "If a hammer was sold as a tool that could do everything, even your role, then a builder would be fucked off",
                  "score": 39,
                  "created_utc": "2026-01-15 21:40:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzssbx4",
                  "author": "No_Attention_486",
                  "text": "People want the tools to be good, not over hyped. When the leading headlines for AI is \"replace all developers\" it's safe to say developers won't be thrilled about it.",
                  "score": 150,
                  "created_utc": "2026-01-15 21:02:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsvjb3",
                  "author": "PaintItPurple",
                  "text": "I want my tools to be good. I want The Non-Programmer Who Is Trying To Replace Me's tools to be very obviously dogshit so nobody gets conned into hiring him instead of me.",
                  "score": 52,
                  "created_utc": "2026-01-15 21:17:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsri7r",
                  "author": "GreenFox1505",
                  "text": "I do want tools to be good. AI is not a good tool. People love AI because it's convincing. But if you ask an AI to do something that you have really solid grasp of, it's always clear how little it understands actually.\n\n\nIf it was good, that would be great. What's happening here is management is finally seeing how bad it's been the whole time.",
                  "score": 63,
                  "created_utc": "2026-01-15 20:58:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsw9ae",
                  "author": "Actual__Wizard",
                  "text": "Yeah we want the tools to be good. Why doesn't big tech?\n\nWhen are you people going to get sick of getting scammed by this crap tech they're pretending is AI? It's a spam bot that they're pretending \"is AI.\"",
                  "score": 21,
                  "created_utc": "2026-01-15 21:20:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzspx86",
                  "author": "s33d5",
                  "text": "Depends whether or not you rely on it for income. I personally don't completely and I'm pivoting elsewhere. But it's just the automation of someone's life skills.",
                  "score": 16,
                  "created_utc": "2026-01-15 20:51:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsuv75",
                  "author": "NuclearVII",
                  "text": "Wanting a product to be good is how you get scammed.",
                  "score": 6,
                  "created_utc": "2026-01-15 21:14:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsyvxd",
                  "author": "FortuneIIIPick",
                  "text": "AI is not a tool because it is not deterministic.",
                  "score": 7,
                  "created_utc": "2026-01-15 21:32:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzstpty",
                  "author": "nebogeo",
                  "text": "Extractivism is never good in the long run",
                  "score": 2,
                  "created_utc": "2026-01-15 21:08:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzxb5ve",
                  "author": "CunningRunt",
                  "text": "Yes.\n\nBut let me decide what tools are good for doing my job.  Don't force me to use something that is virtually useless to me.",
                  "score": 1,
                  "created_utc": "2026-01-16 14:26:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzvighz",
          "author": "ahfoo",
          "text": "In 2017, the generative pre trained transformer (GPT) Open AI Chat program exhibited \"emergent properties\" which were coming from the data rather than having been programmed into the system. This appeared to be an instance of genuine, if primitive, artificial intelligence. That was nine years ago.  \n\nSubsequently, much larger sets of training data were used and the developers began scraping web content in a wholesale manner to create enormous training sets. By the era of ChatGPT3, when OpenAI locked down access to its formerly open source project, they were using 60% of the data in the Common Crawl database which is a large chunk of the Internet Archive. \n\nThere is no second internet to scrape. The data that was contained in the earlier training sets is all we've got. It's what humanity has to offer. You can filter it in different ways but the progress that was made between 2017 and 2022 are not going to be repeated because there is nowhere to turn for new training data. You can re-filter what you've already got but that's not as simple as what went before. \n\nMoreover, you've now got your data poisoned by the abundance of AI generated content that has already been published in the last five years. Simultaneously, progress in computer hardware has nearly come to a halt while costs to manufacture slightly more efficient chips have grown exponentially. The meat has been picked off the bones, the skin and sinews devoured and now there are bunch of hungry carnivores left to fight over what's remains of the bone marrow.",
          "score": 36,
          "created_utc": "2026-01-16 06:13:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw223l",
              "author": "pinkjello",
              "text": "This is a good way to describe what I’ve been having trouble putting into words.",
              "score": 10,
              "created_utc": "2026-01-16 09:04:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzwxocr",
              "author": "Eskamel",
              "text": "Learning patterns and recognizing them isn't intelligence.\n\nI could let a kid memorize an entire book, learn patterns in order to figure out when to use each pattern of said book. Without understanding, the kid would just drag information from one place to another. That's what LLMs do, its not intelligent, no matter how OpenAI or other grifters label it.\n\nAs a kid I remember how everyone said that there is no point in memorizing stuff, understanding is much more important.\nWe have reached the opposite scenario where people treat memorization which computers excel at, to intelligence, which computers fail at. Its genuinely weird how normalized it is.\n\nCalling LLM capabilities \"emergent\" is a joke.",
              "score": 8,
              "created_utc": "2026-01-16 13:14:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzx4p5f",
              "author": "Vi0lentByt3",
              "text": "Ima quote this as for why AI is already maxed out and this is the best we have right now essentially with only marginal improvements left to be made",
              "score": 2,
              "created_utc": "2026-01-16 13:52:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzxl3f4",
              "author": "Kersheck",
              "text": "Most improvements come from post-training RL, not pre-training",
              "score": 1,
              "created_utc": "2026-01-16 15:14:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzswsm5",
          "author": "Lame_Johnny",
          "text": "Love to see it",
          "score": 14,
          "created_utc": "2026-01-15 21:23:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwzpnp",
          "author": "gardyna",
          "text": "~~Newer~~ AI Coding Assistants are Failing ~~in Insidious Ways~~\n\nFixed the title for you",
          "score": 3,
          "created_utc": "2026-01-16 13:25:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv9f1c",
          "author": "Benjamin_Goldstein",
          "text": "It's 2026 and my company is still trying to get cost and budget approvals for code assist.  All while saying we need to use AI to be faster ",
          "score": 5,
          "created_utc": "2026-01-16 05:07:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw2fba",
              "author": "pinkjello",
              "text": "> It's 2026 and my company is still trying to get cost and budget approvals for code assist.  All while saying we need to use AI to be faster\n\nThey have to say the second thing to unlock funds. How is this incongruous?\n\nEven if you disagree, the way to get funding for something is to say you need it. I don’t understand your point.",
              "score": 2,
              "created_utc": "2026-01-16 09:07:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyn1dr",
                  "author": "normVectorsNotHate",
                  "text": "Well, depends on who's doing the saying and who controls the funds. It makes sense if the people trying to secure the funds are doing the saying. But OP makes it sound like it's those who are restricting the funds also doing the saying",
                  "score": 1,
                  "created_utc": "2026-01-16 18:02:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzyxwcl",
                  "author": "EveryQuantityEver",
                  "text": "The fact that funds need to be unlocked through such a process for developer tools is not a good sign",
                  "score": 1,
                  "created_utc": "2026-01-16 18:50:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzu7wzp",
          "author": "roscoelee",
          "text": "I was creating some properties in a C# class in the new VS named: Jan, Feb, Mar, April, May… you know what co pilot suggested my next property be named after “May”? “Ask”. It fucking suggested “Ask”. No context of what the rest of my properties were. I guess I can see how it might have come up with that, but seriously? This is what these companies are spending a world economy worth of money on? It’s like it’s more clever, but dumb as shit at the same time or something? Not helpful when I’m trying to be productive. I might as well have my toddler come and smash on my keyboard while I’m working.",
          "score": 8,
          "created_utc": "2026-01-16 01:26:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxhvjz",
              "author": "thehalfwit",
              "text": "Followed by \"Dan, Who, Dat\". \n\nI like its decision to shorten March but not April, because March obviously uses more computationally expensive letters.",
              "score": 2,
              "created_utc": "2026-01-16 14:59:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzxc7kt",
              "author": "9gPgEpW82IUTRbCzC5qr",
              "text": "The tab auto complete is not what anyone is betting the future on. That is likely running with limited context(a few lines?) and a much smaller model like nano or haiku",
              "score": 1,
              "created_utc": "2026-01-16 14:31:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzvld30",
          "author": "jacob798",
          "text": "Reddit loves to hate on AI, but given the right context Opus 4.5 has been soaring for me. By using Cursor in a big well-defined code-base (that I started with 2 years in VSCode), I'm noticing AI has very little trouble building features exactly the way I would've, using my existing utilities and component library. \n\nJust like the hype train propelling this technology, there's another train flying in the opposite direction, praying these AI code implementations fail.",
          "score": 6,
          "created_utc": "2026-01-16 06:36:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwy87o",
              "author": "Eskamel",
              "text": "People who love engineering dislike LLMs, people who like being a prompt monkey and being led by an algorithm like LLMs and hype their capabilities. Having a LLM build features \"exactly the way I would've\" exactly tells to which developer group you fall into.\n\nIf you enjoy that, have fun, I guess",
              "score": 9,
              "created_utc": "2026-01-16 13:17:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzx6m35",
                  "author": "jacob798",
                  "text": "There's a difference between engineering and programming. When I simply need to add a feature that builds on top of existing code I've written, it's not more engineering that's missing, it's more boring ass code that simply does what's already being done, but in a different scope. \n\nFor example, I have a table of files that are selectable with a checkbox at each row. There's existing code I've written that defines access at a bulk level. Separately, there's code that defines labels at a row level, but not a bulk level like access. \n\nExpanding this bulk feature to include labels needs programming, not engineering. I've already done the engineering when I considered the so many things around this picture (AWS API infrastructure, hosting for application, request protocol, proxy layer for auth, data layer for query invalidation), what I need is more programming (putting the square block in the square hole, use a similar api handler, db query and transactions that already exist). \n\nI can't exactly see myself riding the hype train when I can review code that genuinely satisfies a proper implementation to fit these scenarios. \n\nI was skeptical too before I saw what Cursor is able to pull off when engineering decisions have already been made and are clearly defined, such as my infrastructure being defined in code as well (SST)",
                  "score": 2,
                  "created_utc": "2026-01-16 14:02:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzyzn1y",
                  "author": "hank_z",
                  "text": "This feels like the same debate that is going on in the 3D printing world between people that want open source, tinkerable printers, and people that buy one from Bambu Lab.\n\nThe former enjoy 3d printers. The latter enjoy 3d printing.\n\nSimilarly, if you enjoy coding, then by all means, do it by hand. But if you want to produce features, then you're going to want to use an LLM. Personally, I've had to write code for 40 years, I'm sick of it, I just want to tell the machine what to do and have it do it (it's not there yet)",
                  "score": -2,
                  "created_utc": "2026-01-16 18:58:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzvuncw",
              "author": "caks",
              "text": "Exactly the same experience here",
              "score": 4,
              "created_utc": "2026-01-16 07:56:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzvvq8y",
              "author": "snrcambridge",
              "text": "Only opus 4.5 though",
              "score": 1,
              "created_utc": "2026-01-16 08:05:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzw3x8z",
                  "author": "jacob798",
                  "text": "I do agree that 4.5 hits different than 4.",
                  "score": -1,
                  "created_utc": "2026-01-16 09:21:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzw2f8z",
              "author": "Lourayad",
              "text": "Same here but with Claude Code. I think it's a great tool for someone who knows how to use it.",
              "score": 0,
              "created_utc": "2026-01-16 09:07:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzw3vbe",
                  "author": "jacob798",
                  "text": "We've entered the era of disposable software. Understanding production grade systems is where the human skills come in. \n\nhttps://www.chrisgregori.dev/opinion/code-is-cheap-now-software-isnt",
                  "score": 0,
                  "created_utc": "2026-01-16 09:21:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzz6veu",
          "author": "TheESportsGuy",
          "text": "An LLM is a model intended to generate an answer that looks correct to a human...Asking it to generate code is asking it to lie to you.",
          "score": 3,
          "created_utc": "2026-01-16 19:30:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuok1m",
          "author": "mouse_8b",
          "text": "Junie by Jet Brains needs more attention. It knows how to provide relevant project context to the backing LLM (choose from any of the majors) and break down the task to keep the LLM focused. Big improvement over raw chat prompt.",
          "score": 2,
          "created_utc": "2026-01-16 02:59:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvjxki",
              "author": "beholdsa",
              "text": "Junie is a seriously underrated gem.",
              "score": 2,
              "created_utc": "2026-01-16 06:25:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzwctx6",
              "author": "10199",
              "text": "could you tell me whats the difference between junie and claude code?",
              "score": 1,
              "created_utc": "2026-01-16 10:42:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzx1r9e",
                  "author": "mouse_8b",
                  "text": "I have not used Claude Code, but from what I hear they are similar, in that they aim to take a high-level prompt and iterate.\n\nJunie can get a lot of context from the IDE, and it can use command line tools like grep and find to build context. I'm not sure if CC does that.\n\nI've heard of people letting CC run all night on a problem. I don't know if Junie will do that, though I have given it tasks that take 10 minutes to run.",
                  "score": 0,
                  "created_utc": "2026-01-16 13:37:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nztsfx4",
          "author": "Windyvale",
          "text": "Newer?",
          "score": 2,
          "created_utc": "2026-01-16 00:01:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxjs36",
          "author": "gmeluski",
          "text": "In \"You Look Like a thing and I Love You\" the author describes how AI models will find the easiest way to their goal, even when it's considered \"cheating\", and how the designers of the models had to institute new rules to prevent that.\n\nso this tracks!",
          "score": 1,
          "created_utc": "2026-01-16 15:08:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00ry5n",
          "author": "vasileios13",
          "text": "I'm a bit disappointed by that article. It literally tests only one example that may even be misleading without providing prompts and the full code.",
          "score": 1,
          "created_utc": "2026-01-17 00:14:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02w68q",
          "author": "PabloZissou",
          "text": "\"Plot twist\" they always have",
          "score": 1,
          "created_utc": "2026-01-17 09:38:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvgpgl",
          "author": "CosmosGame",
          "text": "Well written thoughtful article. I recommend you read it — it won’t take too much of your time. The author presents a pretty convincing case (with actual numbers) that because ai is now using prompt feedback as training data that the ai is now cleverly optimizing for prompt acceptance over accuracy. In some cases it might even make sense to go back a generation (eg. gpt 4.1 vs 5)",
          "score": 2,
          "created_utc": "2026-01-16 05:59:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzujwon",
          "author": "scruffles360",
          "text": "He gave the AIs an impossible task - and is judging them on how they fail. Imagine if you gave this test at an interview. The correct answer would be \"fuck this interview - bye\".  \n\nHow many people would sit there and try anyway? How many people would assume its an interview trick and try to do something 'clever' like these AIs?  \n\nI'm guessing the results would be closer to what the AIs did than most people would think.",
          "score": -4,
          "created_utc": "2026-01-16 02:33:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00ucls",
              "author": "vitriolix",
              "text": "That's the point, the AI *should* replied that it was not possible. But instead he's finding newer models more and more just return *a* result that get's past the developers bs detector",
              "score": 1,
              "created_utc": "2026-01-17 00:28:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00y4wp",
                  "author": "scruffles360",
                  "text": "right, but why are they training AIs to weight the prompt more and more? They're doing it because AIs were ignoring the prompt because of the weight being put on the crap in the context (MCPs, chat history, etc). They were trying to avoid context rot. They assumed the user will ask for reasonable things. People here are treating AI like anything short of super intelligence is a failure. Its a tool - a tool developers need to learn like any other. \n\nNo one here wants to have that conversation. They'd rather just take cheap shots at tweets from the CEOs. I unsubscribed from r/programming this week after almost a decade. It's become as bad as twitter or facebook.",
                  "score": 1,
                  "created_utc": "2026-01-17 00:50:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o045ik2",
                  "author": "JustDoItPeople",
                  "text": "The thing is that he was actually unclear in his desire- the code in question wanted to add 1 to a column named index value. On a strictly mechanical level, that *is* impossible. If you interpret the ask however as “add 1 to the index from the pandas df generated from reading this index”, that is 100% possible.\n\nWithout more context, it’s not possible to figure out why the latter is unacceptable and the first is required. I can certainly come up with reasons but it's not always going to hold.",
                  "score": 1,
                  "created_utc": "2026-01-17 15:05:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzt0dd2",
          "author": "harlotstoast",
          "text": "I was shocked to see it make a mistake the other day when I asked about how to do some c++ calls with std::maps.",
          "score": -2,
          "created_utc": "2026-01-15 21:39:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzu868s",
              "author": "sickhippie",
              "text": "You should never be shocked to see a mistake-prone tool make mistakes.",
              "score": 13,
              "created_utc": "2026-01-16 01:27:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvpdk7",
                  "author": "jeorgewayne",
                  "text": "i agree. i also don't get why people get angry when it ai makes mistakes, i mean there is a disclaimer on every chat bot/assistants that says \"ai makes mistakes\" and they somehow don't belive that.\n\nmy default attitude when using claude code/codex when i start a prompt is \"i hope this works\". every time. when it gets something  correct, even on the 10th try i say \"nice!!\" lol. and when it fails say and i gave up on it , i just manually figure shit out. \n\ni dont get mad at cc or codex for failing on most tasks, but i do hate it for burning through tokens and consuming my usage quota.",
                  "score": 0,
                  "created_utc": "2026-01-16 07:10:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzwdsdi",
          "author": "new_mind",
          "text": "this is exactly the motivation for a [framework](https://github.com/n3wm1nd/runix-project) i'm currently working on: limit what llm generated code can actually do (by using an effect system) without severely limiting what it can express. the effects are checked at compile-time, so this is not just a sandbox, or a capability system.\n\nas a practical proof of viability, [runix-code](https://github.com/n3wm1nd/runix-code) is a coding agent coded in this system, and while it's still rough around the edges (the UI still needs a lot of work) the core is looking very promising. it already includes most functionality of claude-code (including support for it's agents and skils) plus self modification in a controlled way.\n\ni'd welcome any feedback or questions you have, it's still in rather early pre-release state, but it's already showing some promising results. \n\nthis obviously doesn't magically make the LLM's output correct, but what it does do is manage what \"incorrect\" code can even be expressed and still compile.\n\nps: yes, it is written in haskell, since that is the only language i've found where such a thing is even possible (actually preventing code to bypass effects/injected dependencies)",
          "score": 0,
          "created_utc": "2026-01-16 10:51:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvackk",
          "author": "redditrasberry",
          "text": "> I asked each of them to fix the error, specifying that I wanted completed code only, without commentary.\n\nSo they asked something stupid. This is not realistic.",
          "score": -3,
          "created_utc": "2026-01-16 05:13:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxf5s9",
          "author": "rfisher",
          "text": "Doesn't every junior programmer go through the phase where they produce code that passes the tests but has edge case bugs and some horrible issues when you look more closely.",
          "score": 0,
          "created_utc": "2026-01-16 14:46:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu6l9o",
          "author": "SuitableDragonfly",
          "text": "Not sure why the author finds this surprising. What he's describing is what LLMs were specifically designed to do. This change reflects them getting better at their intended purpose. Is he only just now realizing that LLMs were not designed for writing code, and therefore them getting better at their intended purpose will naturally make them worse at writing code?",
          "score": -3,
          "created_utc": "2026-01-16 01:18:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzyfmnd",
          "author": "dadaaa111",
          "text": "Some people would love them to fail. Spme people would them to be best thing ever.\n\nThing is it is hard to find objective look. \n\nLLMs are not even by themselfs objective, they will respond how they 'think' you would like them to. And it is easy to drive them in one way unintentinally.\n\nHowever, this thing are revolution for me. Not like fire or computers but like internet. They are good, they save me ton of time and they are getting better.\n\nYou know wjay GPT did this day for me?\n\nYes, its anoying to see a guy makes an app and small apps poping up evrywhere. But that will stay on that. And slowly hype will go down.\n\nWhat a lovely time to be alive",
          "score": -1,
          "created_utc": "2026-01-16 17:29:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qa4tl6",
      "title": "AI insiders seek to poison the data that feeds them",
      "subreddit": "programming",
      "url": "https://www.theregister.com/2026/01/11/industry_insiders_seek_to_poison/",
      "author": "RNSAFFN",
      "created_utc": "2026-01-11 17:11:52",
      "score": 401,
      "num_comments": 151,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qa4tl6/ai_insiders_seek_to_poison_the_data_that_feeds/",
      "domain": "theregister.com",
      "is_self": false,
      "comments": [
        {
          "id": "nz0g7ze",
          "author": "ffekete",
          "text": "I am wondering if my old github public repos with absolute bad java code is already doing the same?",
          "score": 150,
          "created_utc": "2026-01-11 18:17:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4m2ib",
              "author": "Carighan",
              "text": "I'm doing my part! 💪",
              "score": 48,
              "created_utc": "2026-01-12 07:59:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzbn92i",
                  "author": "BoardClean",
                  "text": "I’ve been barely training my whole life for this",
                  "score": 5,
                  "created_utc": "2026-01-13 09:02:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nza0uy2",
                  "author": "ihaterussiantrolls",
                  "text": "Would you like to know more?",
                  "score": 2,
                  "created_utc": "2026-01-13 02:09:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz08pbk",
          "author": "seanamos-1",
          "text": "Without any intentional poisoning, they are already poisoned, and will continue to be poisoned at an increasing rate.",
          "score": 154,
          "created_utc": "2026-01-11 17:43:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz0u7vf",
              "author": "SideQuest2026",
              "text": "Not to get meta here, but is there a way to use LLMs to .... ensure the data that LLMs are being trained on is high quality, accurate, etc. ?",
              "score": 4,
              "created_utc": "2026-01-11 19:18:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz13ukx",
                  "author": "Crazyboreddeveloper",
                  "text": "Probably by enforcing some sort of metadata that describes all LLM generated content as LLM content. We didn’t implement it from the get go though, so it already too late. LLMS are already consuming their own shit. Not to mention, as people lean on LLMs to generate content, they stop producing the original content it’s trained on. Stack overflow for example. Huge source for coding assistants. Effectively dead in the water now that people can have most of their questions (appear to be) answered by an LLM.",
                  "score": 72,
                  "created_utc": "2026-01-11 20:02:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz1fww6",
                  "author": "seanamos-1",
                  "text": "Not accurately enough to mitigate the problem. You can also imagine how having all post LLM launch training data processed by one or more LLMs affects training costs.\n\nThe problem is further compounded by the ratio of new human generated data vs LLM generated data. Sources for human content are drying up and everything is being flooded with LLM content.",
                  "score": 21,
                  "created_utc": "2026-01-11 20:58:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz384bi",
                  "author": "Relative-Scholar-147",
                  "text": "We have already used all the \"good\" data for training, all the new data is poisoned.\n\n  \nPeople who knows about this say the solution is somehow create good synthetic data with LLMs.",
                  "score": 7,
                  "created_utc": "2026-01-12 02:18:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz13nha",
                  "author": "Fatallight",
                  "text": "Somewhat. Most RAG bots are just LLMs that do this. Most AI companies do pass their data through LLMs to get higher quality and more focused training data. LLMs aren't capable of reliably identifying LLM generated data though. So there's going to be some self-feeding going on.",
                  "score": 3,
                  "created_utc": "2026-01-11 20:01:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz56qzu",
                  "author": "Available_Peanut_677",
                  "text": "Nope. It’s like Ken Thompson attack, but real and most likely has happened. And since nowadays more content generated by AI than by humans and it’s going to get even worse - attack / poison would just reinforce itself",
                  "score": 2,
                  "created_utc": "2026-01-12 11:14:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz625mz",
                  "author": "Andy12_",
                  "text": "Sort of. The filtering pipeline used to filter training data is one of the most important part of the models, so companies usually don't go into detail on what they do. Llama 3 used some heuristics to filter data, and also classifier models to filter for accuracy. Llama 2 itself was used to create the dataset for the quality classifier by giving it documents and a list of quality requirements. \n\nhttps://arxiv.org/pdf/2407.21783 \n\n- Heuristic filtering. We develop heuristics to remove additional low-quality documents, outliers, and documents\r with excessive repetitions. Some examples of heuristics include:\r\n• We use duplicated n-gram coverage ratio (Rae et al., 2021) to remove lines that consist of repeated\r\ncontent such as logging or error messages. Those lines could be very long and unique, hence cannot be\r\nfiltered by line-dedup.\r\n• We use “dirty word” counting (Raffel et al., 2020) to filter out adult websites that are not covered by\r\ndomain block lists.\r\n• We use a token-distribution Kullback-Leibler divergence to filter out documents containing excessive\r\nnumbers of outlier tokens compared to the training corpus distribution\n\r\n- Model-based quality filtering. Further, we experiment with applying various model-based quality classifiers\r\nto sub-select high-quality tokens. These include using fast classifiers such as fasttext (Joulin et al., 2017)\r\ntrained to recognize if a given text would be referenced by Wikipedia (Touvron et al., 2023a), as well as more\r\ncompute-intensive Roberta-based classifiers (Liu et al., 2019a) trained on Llama 2 predictions. To train a\r\nquality classifier based on Llama 2, we create a training set of cleaned web documents, describe the quality\r\nrequirements, and instruct Llama 2’s chat model to determine if the documents meets these requirements. We use DistilRoberta (Sanh et al., 2019) to generate quality scores for each document for efficiency reasons. We experimentally evaluate the efficacy of various quality filtering configurations.",
                  "score": 2,
                  "created_utc": "2026-01-12 14:37:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz0vjgh",
              "author": "Middlewarian",
              "text": "One of my mantras has been to minimize the amount of code that my users have to download/build/maintain.  I'm glad I have some open-source code but I'm glad it's not all I have.  Let them (AI) eat cake.  They can [kiss my SaaS.](https://www.reddit.com/r/codereview/comments/qo8yq3/c_programs/)",
              "score": -3,
              "created_utc": "2026-01-11 19:24:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz0708n",
          "author": "worldofzero",
          "text": "It is a wild idea that anyone could look at how LLMs work and think they'd ever be able to possess even minute intelligence.",
          "score": 195,
          "created_utc": "2026-01-11 17:35:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz0cbvp",
              "author": "Thetaarray",
              "text": "A decade ago people would post computer generated harry potter books and laugh at how random and dumb it was. Now I see people on reddit get fooled by what is to me obvious AI slop and I struggle to convince them it isn’t.\n\nI can understand why someone who worked on it during this era would feel progress could continue and be a huge deal greater a decade from now.",
              "score": 114,
              "created_utc": "2026-01-11 17:59:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz0h2ib",
                  "author": "barrows_arctic",
                  "text": "One revolutionary advancement does not guarantee another. Nor does sustained evolutionary progress guarantee its continuation. In both cases, historical patterns suggest the opposite is *usually* the case: things tend to come in bursts and waves with long lulls in between.\n\nBut there’s a certain innate *desire* in people to “be there for the next one” so you get a lot of undue hope and misplaced optimism on many fronts, when there are no guarantees of anything at all.",
                  "score": 61,
                  "created_utc": "2026-01-11 18:21:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz4nf23",
                  "author": "Carighan",
                  "text": "> Now I see people on reddit get fooled by what is to me obvious AI slop and I struggle to convince them it isn’t. \n\nI think this is partially due to the - particularly in american english - *noticable* decline in reading comprehension and literary expression. Too many native Simplified English speakers no longer speak english well enough to even **recognize** the difference between actual expression and LLM-output.\n\nEven though, I agree, in many cases it becomes very obvious due to the weird stylistic choices chatbots make when generating text. And I'm not even a native english speaker!",
                  "score": 2,
                  "created_utc": "2026-01-12 08:11:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz135p8",
              "author": "ElectronRotoscope",
              "text": "The conspiracy theorist demon on my shoulder thinks every \"AI is dangerous because it's on the verge of threatening humanity\" story was planted by the AI companies to make their product seem more viable since people are afraid of it",
              "score": 29,
              "created_utc": "2026-01-11 19:58:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz16d4x",
                  "author": "jonathancast",
                  "text": "Less of a conspiracy theory than the consequence of assuming OpenAI always intended to become a for-profit company.",
                  "score": 12,
                  "created_utc": "2026-01-11 20:13:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz1i3vk",
                  "author": "NuclearVII",
                  "text": "This is exactly what happened. Pretty obviously too for those of us with an innate distrust of corporate America.\n\nPeople see \"AI is dangerous\", they read \"you need to get in on this before it leaves you behind\".",
                  "score": 12,
                  "created_utc": "2026-01-11 21:07:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz6jryt",
                  "author": "dongas420",
                  "text": "Silicon Valley rationalist types have been going on about AI risk and whatnot long before ChatGPT took off. You don't hear Chinese companies saying that kind of thing because they don't share that culture",
                  "score": 3,
                  "created_utc": "2026-01-12 16:03:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz4lrdp",
                  "author": "Waterty",
                  "text": "Ah yes, the AI companies of 1968 \nhttps://knowyourmeme.com/memes/hal-9000\n\n\nNice fucking upvotes",
                  "score": -1,
                  "created_utc": "2026-01-12 07:56:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz235oh",
              "author": "darkpaladin",
              "text": "> It is a wild idea that anyone could look at how LLMs work and think they'd ever be able to possess even minute intelligence.\n\nNo it isn't, if you don't understand how they work and aren't scrutinizing, they look like they're genuinely intelligent.  Hell I know how they work and I still find them amazing on a fairly regular basis.  \n  \n  \nPeople look at the progress of the last 10 years and think that we must be so close simply because of how far we seem to have come. They don't realize how vast the chasm is between where we are now and actual AGI.",
              "score": 22,
              "created_utc": "2026-01-11 22:47:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz0mpio",
              "author": "Bwob",
              "text": "People always seem to forget that the A in \"AI\" stands for \"Artificial\"...",
              "score": 8,
              "created_utc": "2026-01-11 18:45:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz3mgp7",
              "author": "rfisher",
              "text": "For what it's worth, Pierre Boulle wrote a book in 1963 making the case that human intelligence is actually just imitation.",
              "score": 5,
              "created_utc": "2026-01-12 03:36:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz09k3e",
              "author": "Mastersord",
              "text": "People are easily fooled into thinking that because they can mimic the type of response you’re looking for based on a complex probability model, that they’re actually intelligent.  \n\nI had to argue with 2 people a few weeks ago that LLMs will not replace the human ability to think and reason through problems and one of them is STILL convinced that all human logic can be reduced to probability that a machine can emulate perfectly without understanding context.  If that were the case, you could use an LLM to play the lottery and the stock market perfectly without any influence.\n\nLLMs are not the end all be all of general AI.  They are a step.  A human can interpret raw data from multiple sources and filter and interpret it to whatever task is before them.  AI still needs to be directed how to interpret the data presented and the data itself has to be shaped to fit their routines.",
              "score": 29,
              "created_utc": "2026-01-11 17:47:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz0a8cw",
                  "author": "Usual-Good-5716",
                  "text": "And there's something to the fact that our brains are always processing problems even when we aren't solving them. \n\nIt's why boredom helps bring about human ingenuity. It can't be replicated with statistics.",
                  "score": 14,
                  "created_utc": "2026-01-11 17:50:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz3t31z",
                  "author": "Whatsapokemon",
                  "text": ">one of them is STILL convinced that all human logic can be reduced to probability that a machine can emulate perfectly without understanding context. If that were the case, you could use an LLM to play the lottery and the stock market perfectly without any influence.\n\nThat doesn't make sense.\n\nJust because something can be boiled down to probabilities, that doesn't mean you can predict the future...\n\nAfter all, you literally said it yourself... you're working with _probabilities_ and not discreet, certain events.\n\nThe whole point of the Lottery or the Stock Market is that the probabilities are balanced such that there's no prediction you can make that will yield you some huge benefit. For the Lottery, that's because it's a completely random yet fair draw system, and for the market it's because of the 'efficient market' hypothesis, where new information is pretty much _immediately_ priced in by the huge number of traders.",
                  "score": 2,
                  "created_utc": "2026-01-12 04:13:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz0g6g8",
                  "author": "zer1223",
                  "text": "Thats incredibly stupid. Probability can't stop a machine from contradicting it's own statements from two prompts ago. And probability can't stop the machine from doing other stupid things like arguing against its own existence. Which is very easy to convince it to do.",
                  "score": -7,
                  "created_utc": "2026-01-11 18:17:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz0xfln",
              "author": "grumpy_autist",
              "text": "Every average CEO or board member",
              "score": 5,
              "created_utc": "2026-01-11 19:32:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz3vkq6",
              "author": "StudiousSnail69",
              "text": "I hope you're right.  I'll assume you are just because this thread is making me feel better about my career prospects as a cs major lol.",
              "score": 1,
              "created_utc": "2026-01-12 04:28:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz52tdg",
              "author": "hardware2win",
              "text": "Although LLMs can solve unsolved math problems\n\nhttps://github.com/teorth/erdosproblems/wiki/AI-contributions-to-Erd%C5%91s-problems",
              "score": 1,
              "created_utc": "2026-01-12 10:39:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz11ayl",
              "author": "Raunhofer",
              "text": "Any sufficiently advanced technology is indistinguishable from magic.\n\nBut when you really take a peek behind the curtain, it's just smoke and mirrors.",
              "score": 0,
              "created_utc": "2026-01-11 19:50:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz1vw4u",
              "author": "-IoI-",
              "text": "It's wild you still think that, have you got no imagination that you can't come up with some personal use cases to verify the level of reasoning applied?",
              "score": 1,
              "created_utc": "2026-01-11 22:12:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz14qb2",
              "author": "victotronics",
              "text": "It's a wild idea that people could look a neurons that fire when their neighbors fire, and think they'd ever be able to possess even minute intelligence.\n\nIt's called emergent behavior and the possibility (or not) has been discussed for decades. Search for \"chinese room experiment\".",
              "score": -4,
              "created_utc": "2026-01-11 20:06:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz374dy",
                  "author": "Dandorious-Chiggens",
                  "text": "LLMs are essentially just a statistical algorithm. There is no *thought* involved, just generating a response based on a probability distribution. People that think these LLMs are going to spontaniously change the entire way they function and start thinking are dumber than the AI is.",
                  "score": 8,
                  "created_utc": "2026-01-12 02:13:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz0cusu",
              "author": "IlliterateJedi",
              "text": "I don't know how anyone looks at a product that takes plain natural language and converts it into functional working code to be anything but intelligent.  The new reasoning models are frankly incredible with regards to the things they are capable of doing.",
              "score": -9,
              "created_utc": "2026-01-11 18:02:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz0dtsb",
                  "author": "azhder",
                  "text": "I agree, you don't know.",
                  "score": 13,
                  "created_utc": "2026-01-11 18:06:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz0o49q",
                  "author": "Dazzling_Meaning9226",
                  "text": "Most people making these claims have tried nothing but a vanilla chatgpt agent in their browser. Even something as cheap as mini.ax 2.1 can write entire codebases for large complex applications, build and run tests, and deliver a robust, working application.",
                  "score": 3,
                  "created_utc": "2026-01-11 18:51:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz0vi6q",
                  "author": "EveryQuantityEver",
                  "text": "> I don't know how anyone looks at a product that takes plain natural language and converts it into functional working code to be anything but intelligent.\n\nBecause it's not. We see how these things work. It's literally a table that says \"this word usually comes after that word.\"",
                  "score": -1,
                  "created_utc": "2026-01-11 19:24:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz0pvbq",
              "author": "SnugglyCoderGuy",
              "text": "It depends on what you define intelligence as. \n\nOne question we ask of humans when testing mental acuity is to identify things. Neural nets can be *very* good at this. So if the ability to identify things is an axis of intelligence, then they have intelligence. \n\nThey don't have reasoning abilities though",
              "score": -3,
              "created_utc": "2026-01-11 18:59:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz0v4i3",
              "author": "slaymaker1907",
              "text": "That’s just… not correct. They may not possess human/general intelligence, but you have your head in the sand if you think that they have no intelligence at all.\n\nThey are likely not conscious (depends on your definition), but they certainly have some forms of intelligence.",
              "score": -9,
              "created_utc": "2026-01-11 19:22:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz11qb7",
                  "author": "Raunhofer",
                  "text": "I'd say that to have intelligence, you should at least be conscious first. It's like the bare minimum.",
                  "score": 3,
                  "created_utc": "2026-01-11 19:52:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz0cbm8",
              "author": "LordNiebs",
              "text": "It is bizarre that anyone could look at the output of LLMs and not see intelligence ",
              "score": -26,
              "created_utc": "2026-01-11 17:59:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz0e8hl",
                  "author": "azhder",
                  "text": "What you wrote is bizarre. Can you even define what intelligence is? It isn't the ability to produce stuff.",
                  "score": 15,
                  "created_utc": "2026-01-11 18:08:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz0dzqp",
                  "author": "mosaic_hops",
                  "text": "It’s objective fact that the output of LLMs is not intelligence.",
                  "score": 8,
                  "created_utc": "2026-01-11 18:07:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz0gf2f",
                  "author": "zer1223",
                  "text": "Schizoposting\n\n\nIf a machine contradicts what it told you literally three prompts ago, obviously it's not intelligent.  Use your fucking brain, if you have one.",
                  "score": 8,
                  "created_utc": "2026-01-11 18:18:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz07l8y",
          "author": "CramNBL",
          "text": "I see this as a positive considering the on-going war on objective reality, human creativity, general-purpose computing, privacy, and so on...\n\nBut these activists are in serious danger, they will be hunted by billionaires and their lackeys, and their actions are gonna be criminalized any day now.\n\nBillionaires are gambling the world economy on being able to \"free\" themselves from their entire human work-force forever, it's their ultimate dream, so they consider any means justified. They won't suffer the loses anyway, each financial crisis makes them more powerful and wealthy, it's a win-win situation.",
          "score": 39,
          "created_utc": "2026-01-11 17:37:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2qjex",
          "author": "AnnoyedVelociraptor",
          "text": "It'll only get worse. Notice how quality is degrading slowly? It's being fed on its own shit. \n\nAnd looking at the Human Centipede we cannot survive on our own shit.",
          "score": 9,
          "created_utc": "2026-01-12 00:46:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0axuw",
          "author": "oneeyedziggy",
          "text": "Good ",
          "score": 23,
          "created_utc": "2026-01-11 17:53:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1jkob",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 5,
          "created_utc": "2026-01-11 21:14:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4gr7l",
              "author": "leumasme",
              "text": "> The Anthropic paper showed it works but at what scale does it actually matter?\n\nThe Anthropic paper answers this as well.",
              "score": 7,
              "created_utc": "2026-01-12 07:11:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz2nr4s",
              "author": "infrastructure",
              "text": "They demonstrated something like 20-50 pdf pages of data to poison some of the bigger models IIRC",
              "score": 8,
              "created_utc": "2026-01-12 00:32:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz0etei",
          "author": "Digitalunicon",
          "text": "We warned “you are what you train on.” Now the internet is answering back.",
          "score": 4,
          "created_utc": "2026-01-11 18:11:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz06lrb",
          "author": "iKy1e",
          "text": "> “…machine intelligence is a threat to the human species,\" the site explains. \"In response to this threat we want to inflict damage on machine intelligence systems.\"\n\nYeah…. right…. So completely sane normal people. Not at all crazy for thinking an LLM is suddenly going to become the Terminator.",
          "score": 3,
          "created_utc": "2026-01-11 17:33:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz0bl6d",
              "author": "oneeyedziggy",
              "text": "It doesn't have to become a terminator to be a threat.\n\n\nSimply enabling elites to function while letting an increasing portion of average people to become homeless and starve is threat enough... \n\n\nIt's not all about the drama of launching nukes... Slow neglect and exclusion from access to limited resources would kill us all equally well, and the rich don't give two shits as long as their walls hold and they can keep their quality of life stable. ",
              "score": 52,
              "created_utc": "2026-01-11 17:56:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz4qw4s",
                  "author": "syklemil",
                  "text": "A lot of propaganda also isn't about getting people to believe the propaganda itself, but to sow distrust and a lack of belief in anything resembling objective reality, consequences, etc. At that point people become more susceptible to conspiracy theories, political instability and so on.\n\nLLMs are inherently part of that, both in the case of people who believe a real thing is just something an LLM made up, and people who believe something an LLM made up is real, and all the people who are just generally unsure what to believe.",
                  "score": 2,
                  "created_utc": "2026-01-12 08:44:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz0nzbg",
              "author": "ihexx",
              "text": "Look up instrumental convergence. It's real. It's been demonstrated several times. It's not crazy at all. Getting machine intelligence to not be a threat is actually the harder problem",
              "score": 0,
              "created_utc": "2026-01-11 18:51:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5ef87",
          "author": "astatine",
          "text": "When someone plagiarises other people's work and takes credit for it, giving them disinformation is a reasonable response.",
          "score": 0,
          "created_utc": "2026-01-12 12:14:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3fbon",
          "author": "Lowetheiy",
          "text": "Why? This is the digital equivalent to vandalism. What is the point of doing this? Most AI lab data pipelines can easily filter this stuff out given a few days of work.",
          "score": -9,
          "created_utc": "2026-01-12 02:57:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz41hd8",
              "author": "Venthe",
              "text": "Misguided sense of justice? Being a Luddite?\n\nGenerative AI is _problematic_. It is expensive to run, it is easy to accept the output without scrutiny, and we are still learning how to use it non-disruptively. But it is here. And it _significantly_ democratizes certain things.\n\nVandalism is not an answer.",
              "score": -11,
              "created_utc": "2026-01-12 05:08:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz7ot6c",
                  "author": "EveryQuantityEver",
                  "text": "Counterpoint: yes it is.",
                  "score": 0,
                  "created_utc": "2026-01-12 19:09:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz9adz9",
          "author": "InsanityOnAMachine",
          "text": "I am all in for poisoning these things. They do not need to be on the Web at all. The Web was made for humans, not slop bots.",
          "score": 0,
          "created_utc": "2026-01-12 23:46:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qaroyn",
      "title": "YAML? That’s Norway problem",
      "subreddit": "programming",
      "url": "https://lab174.com/blog/202601-yaml-norway/",
      "author": "merelysounds",
      "created_utc": "2026-01-12 10:43:47",
      "score": 384,
      "num_comments": 129,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qaroyn/yaml_thats_norway_problem/",
      "domain": "lab174.com",
      "is_self": false,
      "comments": [
        {
          "id": "nz6a9pa",
          "author": "iceman012",
          "text": "> There are ~~5~~ ~~6~~ NINE (or 63, depending how you count) different ways to write multi-line strings in yaml.\n\nWhat a sentence.",
          "score": 293,
          "created_utc": "2026-01-12 15:18:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz8ednr",
              "author": "ggppjj",
              "text": "> \\* 2 block styles, each with 2 possible block chomping indicators (or none), and with 9 possible indentation indicators (or none), 1 plain style and 2 quoted styles: 2 x (2 + 1) x (9 + 1) + 1 + 2 = 63\n\n[From the StackOverflow post directly, for those that were similarly curious.](https://stackoverflow.com/questions/3790454/how-do-i-break-a-string-in-yaml-over-multiple-lines/21699210#21699210)",
              "score": 65,
              "created_utc": "2026-01-12 21:09:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz8s3c3",
              "author": "bwainfweeze",
              "text": "Nobody expects the Spanish Stringification!\n\nAmong our weaponry are such diverse elements as…",
              "score": 26,
              "created_utc": "2026-01-12 22:12:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzbbv41",
              "author": "Mikasa0xdev",
              "text": "63 ways to fail YAML validation.",
              "score": 11,
              "created_utc": "2026-01-13 07:15:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5m867",
          "author": "NocturneSapphire",
          "text": "Honestly even treating `true` and `false` as literals is problematic in a language that doesn't require any special syntax for string literals. \n\n    wordle_words: \n     - faked\n     - faker\n     - fakes\n     - fakir\n     - falls\n     - false\n     - famed\n     - fancy\n     - fangs\n     - fanny\n     - farad\n\nBecomes\n\n\n    \"wordle_words\": [\n     \"faked\",\n     \"faker\",\n     \"fakes\",\n     \"fakir\",\n     \"falls\",\n     false,\n     \"famed\",\n     \"fancy\",\n     \"fangs\",\n     \"fanny\",\n     \"farad\"\n    ]\n\nShould have just made it string-only, and left it up to the application to give deeper context to particular strings as needed.",
          "score": 213,
          "created_utc": "2026-01-12 13:08:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz8v1x7",
              "author": "Kimos",
              "text": "Before we had linting and rubocop rules to catch and force quoting, we had a checkout outage because of the list of provinces in Canada:\n\n    provinces:\n      - AB\n      - MB\n      - ON\n      - BC\n    ...\n\nBecame\n\n    [\"AB\", \"MB\", true, \"BC\" ...",
              "score": 26,
              "created_utc": "2026-01-12 22:26:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz6fffz",
              "author": "Solonotix",
              "text": "I think your point speaks to a belief I have, which is that everything needs to decide what it wants to be. Markup languages shouldn't have special cases, since there's often very little apparent when being introduced to it. Additionally, the YAML spec already has numerous capabilities defined outside its seemingly obvious task of representing data. For instance `!tag` allows the possibility for parsing any arbitrary value with a pre-defined directive. So, in theory, you could have specified a set of type-strict tags for handling these custom data cases.\n\nAnother thing that bothers me about YAML is the complexity of its multi-line elements. String folding is one such thing, where a novice could easily mistake the intent of `>` and `|` for a multi-line string. For those unaware, the `>` concatenates all lines with a space, and the `|` replaces them with the platform-specific newline characters. Also, the difference of the \"flow style\" (I think that's what it's called), which would seemingly be the obvious benefit for using YAML, while still supporting the array literal `[]` and map literal `{}`.\n\nAnd that's before you get to the weirdness that a single YAML file can be parsed as multiple *documents*.",
              "score": 46,
              "created_utc": "2026-01-12 15:43:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz6l7hg",
                  "author": "NocturneSapphire",
                  "text": "> everything needs to decide what it wants to be. Markup languages shouldn't have special cases, since there's often very little apparent when being introduced to it.\n\n100% agree with this. YAML wants to be simple and easy to use, but also flexible and powerful, and those are very often mutually exclusive, or they require an *extremely* well thought out design to make it work. YAML doesn't have that. It's trying to be too many things, and therefore failing at most or all of them. \n\nAt this point I literally prefer JSON for config files to YAML, regardless of what anyone says. Yeah maybe JSON is a bit picky, and maybe it's annoying to be putting quotes and commas everywhere, but at least it's simple enough that I can fully understand it without spending weeks studying the spec.",
                  "score": 37,
                  "created_utc": "2026-01-12 16:10:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz7e5to",
                  "author": "DmitriRussian",
                  "text": "Oh what about references to other parts of YAML in the same file ([Anchor and Aliases](https://support.atlassian.com/bitbucket-cloud/docs/yaml-anchors/)) horrific stuff.\n\nEven more fun is that it's only supported in version 1.2+ and if you don't specify the version in the YAML doc itself not all editors know what you mean.",
                  "score": 6,
                  "created_utc": "2026-01-12 18:22:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzefo2q",
                  "author": "lookmeat",
                  "text": "You got close but there's an implication: who decides what is what? The reality is that there's no typeless/schemaless solution. Instead we have two alternatives: the data schema is defined by the writer (what we think of as typed) or the schema is defined by the reader (what we think of as the schemaless or dynamic). The thing is once you have a system deciding in the middle with no opt-out you're screwed. Instead people should be able to say, when reading a yaml \"read this field as a string) and then these bugs would disappear. You could have a \"read as inferred type) method but these should be the rarer thing and seen as a code smell.\n\nAnd while both solutions have their pros and cons, the system should always let whomever is deciding the types to explicitly define what they mean.",
                  "score": 3,
                  "created_utc": "2026-01-13 19:01:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz5o60f",
              "author": "CloudsOfMagellan",
              "text": "Or just use quotes",
              "score": 57,
              "created_utc": "2026-01-12 13:20:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz6ghxg",
                  "author": "ZelphirKalt",
                  "text": "You would think it is that easy, and you would be right, until you meet your new coworkers, who love to be and remain blissfully ignorant about YAML issues and keep putting strings literally without quotes...\n\nThe overuse of YAML for configuration files, where it is entirely unnecessary to have something so powerful is one of the things that makes me question the competency of our whole professional group.",
                  "score": 48,
                  "created_utc": "2026-01-12 15:48:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz635i2",
              "author": "syklemil",
              "text": "> Should have just made it string-only, and left it up to the application to give deeper context to particular strings as needed.\n\nI do also find that the problem shrinks in scope if the language expects the data to be deserialised to some known type, e.g. if you're expecting a `Vec<String>` that error should never manifest, unlike if you're expecting a `list[str | bool]`.\n\nSimilar story if you've got some schema file that indicates that it's `{\"type\": \"array\", \"items\": \"string\"}`, at which point whatever you're using to typecheck likely complains that the `false` needs to be written as `\"false\"`.\n\nSomething that typechecks either the serialised or deserialised (or both) data should help mitigate the issue (except for the people who _want_ something even weirder than a string-serialised `Vec<bool>`).\n\nAnd then we'll just have to assume that the people who are completely sold on dynamic typing everywhere all the time are fine with the out-of-the-box, no-tooling experience.",
              "score": 13,
              "created_utc": "2026-01-12 14:42:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz7kqsc",
              "author": "LzrdGrrrl",
              "text": "Yaml defines several schemas which are up to the application to decide on which to use. If you don't like true/false being literals, then don't use the JSON schema.",
              "score": 2,
              "created_utc": "2026-01-12 18:51:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nze5wiw",
              "author": "AndydeCleyre",
              "text": "> Should have just made it string-only, and left it up to the application to give deeper context to particular strings as needed.\n\nFWIW the [NestedText](https://nestedtext.org/en/latest/) format is a pretty close match to this.\n\nI am surprised that ruamel.yaml, while mentioned, doesn't get a more prominent place in the post, and that strictyaml is not mentioned at all.",
              "score": 1,
              "created_utc": "2026-01-13 18:18:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzjaxzy",
                  "author": "Rattle22",
                  "text": "> NestedText\n\nOh I love that. That needs to be standard, please.",
                  "score": 2,
                  "created_utc": "2026-01-14 13:33:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzeiac1",
                  "author": "NocturneSapphire",
                  "text": "I think YAML having different modes that cause it to parse differently is part of the problem. Before this thread, I didn't know anything about that. \n\nAnd what's worse, the mode isn't specified in the document, it's up to the program to specify. If all you have is a YAML document, you don't necessarily know how to parse it, because you don't know which mode it's supposed to be parsed in.",
                  "score": 1,
                  "created_utc": "2026-01-13 19:13:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzegqpm",
              "author": "peetabear",
              "text": "Don't you have colorful syntax highlighting for yaml?",
              "score": 1,
              "created_utc": "2026-01-13 19:06:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz775vc",
              "author": "BossOfTheGame",
              "text": "This is the tradeoff with YAML. It gives you the option of making things explicit with quotes which is great, but it also gives you the option of a very fast way to type out a data structure without that overhead. Its your job to know about the format and to know whats implied / what isn't. If you want something explicit and easy use json. But if you want something that is very fast to type out when you know what you are doing, use YAML. \n\nI think YAML is great and I'm tired of pretending its not.",
              "score": 1,
              "created_utc": "2026-01-12 17:50:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz6mcnm",
          "author": "hcbland",
          "text": "The Canadian province of Ontario (ON) joined the chat",
          "score": 43,
          "created_utc": "2026-01-12 16:15:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6ee3x",
          "author": "PurpleYoshiEgg",
          "text": "I like YAML for simple setups where everything fits on a screen, but once it's past that the indentation becomes hard to follow, and large configs are unfortunately everywhere in the devops world.\n\nIf only JSON had comments (even the c-style `/* ... */` comments).  Unfortunately, I don't get to choose the JSON library an application will end up using for its configs, so that's basically impossible to standardize on (though I have seen a lot of JSON5 lately).",
          "score": 21,
          "created_utc": "2026-01-12 15:38:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz8j16b",
              "author": "DrBix",
              "text": "Pretty easy to use a pre-processor, but yeah, it was an oversight like many other configuration \"languages.\"",
              "score": 6,
              "created_utc": "2026-01-12 21:30:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz8mq5e",
                  "author": "levir",
                  "text": "JSON was meant to be a serialization language for Javascript applications, particularly for stuff like AJAX requests. It wasn't conceived as a configuration language. That's why it's like that.",
                  "score": 5,
                  "created_utc": "2026-01-12 21:47:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz86rw7",
          "author": "KallistiTMP",
          "text": "I remember this bug from 6 years ago!\n\nThis issue drove me up a wall for almost two days, and eventually gave rise to my absolute favorite bug report of all time: \"Firewall geo-restriction policies break on any reference to the country of Norway\"\n\nIt's my go-to example on the inevitable edge-cases and real world chaos of complex large scale systems in the real world, and the reason why all those boring RFC's and standards development boards are so important that the weight of such decisions can only be entrusted to the most wise of ancient graybeard curmudgeons.",
          "score": 21,
          "created_utc": "2026-01-12 20:32:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz58eww",
          "author": "quetzalcoatl-pl",
          "text": "Nice catch. I can totally see how someone can be using true/false symbols from day 0 of their yaml experience, and never see yes/no pair being used, or that someone can simply not notice that 'NO' in such list could be parsed as 'no' boolean. Definitely may catch someone editing the file manually off guard. But serialization libs will take note of the keyword and will serialize it as - 'NO' or - \"NO\". Also, any other character in the NO/no like a dot, whitespace, etc, will immediately either force parsing as string, or will cause the human writing it to include the quotes. So I guess it's all about either skill issue (no offense, I myself wouldn't notice that NO<>false in that context of that array) or an issue of just-naively-concatenating-strings to i.e. form a YAML array from a list of country-codes from the database, instead of using a model and YAML serialization library..\n\nNice catch, fun fact, great gotcha to talk about on dev parties, still far better from some other formats :D",
          "score": 26,
          "created_utc": "2026-01-12 11:28:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6kbmi",
              "author": "A1oso",
              "text": ">Definitely may catch someone editing the file manually off guard. But serialization libs will take note of the keyword and will\n\nYAML is _meant_ to be edited manually. It is commonly used for configuration files, e.g. for Github actions and Kubernetes, which are written and modified by hand. You might be tempted to trust the editor's syntax highlighting. My editor highlights strings in orange, and booleans in blue. However, most editors follow YAML 1.2 (e.g. VS Code, IntelliJ, vim) and highlight `NO` as a string, even though it's parsed as a boolean by some libraries that are still following YAML 1.1. You see how this is a recipe for disaster?\n\nMost people don't even know which YAML version they're using. For example, GitHub has a tutorial for writing workflows, but doesn't mention the YAML version anywhere.",
              "score": 23,
              "created_utc": "2026-01-12 16:06:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz5tkj9",
              "author": "Jonathan_the_Nerd",
              "text": "> But serialization libs will take note of the keyword and will serialize it as - 'NO' or - \"NO\".\n\nLots of popular libraries are still on YAML 1.1.   According to YAML 1.1, an unquoted `NO` is *supposed* to be interpreted as `false`.",
              "score": 19,
              "created_utc": "2026-01-12 13:51:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz8q0v8",
                  "author": "Own_Back_2038",
                  "text": "That’s deserializing",
                  "score": 1,
                  "created_utc": "2026-01-12 22:02:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz7bpjo",
              "author": "deja-roo",
              "text": "Until this article, I had no idea that \"no\" or \"yes\" inserted into a yaml object without quotes would cause (sometimes, but not always) casting into boolean. That's a huge landmine. \n\nI knew it was an issue with true/false but yes/no? That's such an unnecessary failure point.",
              "score": 10,
              "created_utc": "2026-01-12 18:10:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz8y8iv",
                  "author": "bwainfweeze",
                  "text": "Shit like this is why talking about “be lenient in what you accept” isn’t brought up as much as it used to be. Microservices did a lot to disabuse us of this because it really breaks down under games of telephone - where you have to delegate a question to someone who has to delegate parts or all of the answer to more services. Five implementations of leniency can turn into twenty bugs. \n\nIt may be the best thing to come out of the Trough of Disillusionment of microservices. It’s only useful for boundary layers and is shit advice outside or inside of them.",
                  "score": 2,
                  "created_utc": "2026-01-12 22:42:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz66r06",
          "author": "Opening_Addendum",
          "text": "I hate yaml and toml so much. I wish the people would stop pretending json isn't a configuration format and just accept that it is ok to have nonstandard json with trailing commas and comments as your config format. You also get the benefit of schemas and easy intellisense in case of vsconfig if you use json schema.",
          "score": 34,
          "created_utc": "2026-01-12 15:01:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6kyd0",
              "author": "jayroger",
              "text": "JSON is a great serialization format, but a terrible configuration format. In general, it's a terrible format for anything mainly intended for humans.",
              "score": 47,
              "created_utc": "2026-01-12 16:09:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz6tffp",
                  "author": "syklemil",
                  "text": "JSON is awful for configuration, but to be fair, it's also not _great_ for serialisation if the comparison is to some binary format. It beats out arbitrary homegrown string serialisations and falls naturally out of Javascript, but that's about as good as it gets.",
                  "score": 23,
                  "created_utc": "2026-01-12 16:47:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz7mmib",
                  "author": "Humdaak_9000",
                  "text": "Did you live through XML hell?  I remember being promised it was good for humans.  I'd much rather read and write JSON by hand.",
                  "score": 11,
                  "created_utc": "2026-01-12 18:59:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzckipq",
                  "author": "GasterIHardlyKnowHer",
                  "text": "So is YAML. I'll take JSON or some semi widely accepted JSON extension any day.\n\nIf you're using it for configuration, that usually implies you have control over the parser/library used, meaning you can use things like comments and make it plenty human readable.",
                  "score": 2,
                  "created_utc": "2026-01-13 13:30:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz6fyq4",
              "author": "Solonotix",
              "text": "If you want JSON with comments and/or trailing commas, then you want JSONC. Part of the benefit to using JSON is that its simple parsing rules makes it very efficient for serialization. \n\nPersonally, I'm hoping Apple's PKL format becomes more popular.",
              "score": 13,
              "created_utc": "2026-01-12 15:46:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz72kz1",
                  "author": "SharkBaitDLS",
                  "text": "I will forever be mad at Amazon dragging their feet on open-sourcing Ion when they could’ve done it early on and been able to actually compete with JSON before it became ubiquitous. ",
                  "score": 6,
                  "created_utc": "2026-01-12 17:29:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz6j1g0",
              "author": "nixgang",
              "text": "What's wrong with toml now? I use it all the time when I need readable json",
              "score": 17,
              "created_utc": "2026-01-12 16:00:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz7ogl2",
              "author": "CramNBL",
              "text": "Why would you hate TOML? It has none of the disadvantages of YAML, literally none of them, and the spec is super lean.",
              "score": 8,
              "created_utc": "2026-01-12 19:08:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz93h0z",
                  "author": "GregsWorld",
                  "text": "> It has none of the disadvantages of YAML\n\n\nIt has other disadvantages though, like not supporting multiline maps but supporting flexible non-standardised date formats",
                  "score": 2,
                  "created_utc": "2026-01-12 23:09:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz8ukld",
                  "author": "bwainfweeze",
                  "text": "Because TOML is a better execution of the same poor idea. \n\nTOML is like methadone. If you’re a heroin junky it can save your life. But nobody and I mean nobody should take methadone unless they’re an opioid addict. It is a nasty piece of work in its own right and it’s used to make your life expectancy 25 years instead of 2.5.\n\nIt’s probably better than rolling your own. Terraform has this terrible prop drilling behavior due to having three distinct flavors of variables, and used to have bad behavior with unset versus empty lists, but that at least was fixed. But anything is better than rolling your own. Including literal methadone rather than figurative.",
                  "score": -2,
                  "created_utc": "2026-01-12 22:24:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz7zy1y",
              "author": "HommeMusical",
              "text": "> I hate yaml and toml so much. \n\nOne of these things is not like the other. What do you find wrong with Toml? It's been very reliable for me.",
              "score": 6,
              "created_utc": "2026-01-12 20:00:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz6hghw",
              "author": "vladadj",
              "text": "We had standard configurarion format with comments, schema validation, intelisense and everything for years now.\n\n It's called XML :-).",
              "score": 14,
              "created_utc": "2026-01-12 15:53:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz6q311",
                  "author": "BufferUnderpants",
                  "text": "XML was too flexible and nobody could agree on whether object attributes should be element attributes or children nodes.\n\nXML was also the AI of its time, and there was all manners of hype around what we'd have termed \"low code\" tools a couple of years back, XML based DSLs were creeping from the usual peddlers of proprietary tools with horrible programming models, like IBM and Oracle. Ditching XML's benefits was a necessary sacrifice to shut them down.",
                  "score": 26,
                  "created_utc": "2026-01-12 16:32:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz6xkj7",
                  "author": "pragmojo",
                  "text": "XML is horrible to read and write.  There's a reason we're all not using it.",
                  "score": 16,
                  "created_utc": "2026-01-12 17:06:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz6t2qt",
              "author": "syklemil",
              "text": "> You also get the benefit of schemas and easy intellisense in case of vsconfig if you use json schema.\n\nSame thing applies to yaml with [yaml-language-server](https://github.com/redhat-developer/yaml-language-server). In that regard there's zero difference between yaml and json.",
              "score": 4,
              "created_utc": "2026-01-12 16:46:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz6tjmq",
              "author": "GreenFox1505",
              "text": "Editing JSON by hand is an error prone mess. Having had to debug numerous errors from various developers over years of a large project, I would never use JSON as a user editable config file. JSON is fine for storage and communication, but for a config file that a human has to write, forget about it.",
              "score": 4,
              "created_utc": "2026-01-12 16:48:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz6w6aw",
                  "author": "Think_Wing_1357",
                  "text": ">Editing JSON by hand is an error prone mess\n\nAnd this push you to YAML?",
                  "score": 11,
                  "created_utc": "2026-01-12 17:00:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz8w20f",
                  "author": "bwainfweeze",
                  "text": "One of the first tools I wrote when reworking reloadable config was a command line to validate config file formatting at build time (defaults in the app, and overloads done as a deployment for audit history).\n\nAnd the second was to validate all the URLs because it’s the 2020’s and people still think they’re smart enough to do url arithmetic without using the URL/URI class to mediate. And the company was old enough that “service discovery” didn’t exist when decisions were made so they used reloadable config instead. Though to be fair it also benchmarked faster than consul’s, which was evaluated as a replacement.",
                  "score": 1,
                  "created_utc": "2026-01-12 22:31:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz6wv9a",
              "author": "Preisschild",
              "text": "Having used jsonc and yaml for config I enjoy yaml + json schema (using the rh yaml-language-server) the most.",
              "score": 1,
              "created_utc": "2026-01-12 17:03:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz7zl38",
              "author": "abandonplanetearth",
              "text": "I would much rather deal with yes/no in YAML than multiline in JSON.",
              "score": 1,
              "created_utc": "2026-01-12 19:59:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz8tb67",
              "author": "bwainfweeze",
              "text": "JSON5 supports comments. I have one tool I use that can support JavaScript as config files and I’ve been known to shift json files to .js if we are in the middle of a refactor or a bug fix and I need to leave a paper trail for work I won’t get to for two, or let’s be honest, five sprints because we staunched the bleeding but now I need to get back to whatever I was working on before people started making puppy dog eyes asking me to make it stop. \n\n\nAt other times I’ve just added an unused property to put a comment inside. But that depends on the data not being replicated ad nauseum so a two line comment either uses noticeable memory or gets forwarded to users.",
              "score": 1,
              "created_utc": "2026-01-12 22:18:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz8ijwc",
          "author": "DrBix",
          "text": "Please, for the love of god, stop using YAML.",
          "score": 3,
          "created_utc": "2026-01-12 21:28:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5aavz",
          "author": "syklemil",
          "text": "> Yaml is […] used in different kinds of scenarios, from small personal config files to critical infrastructure setups.\n\nThough by this time I suspect that \n\n1. \"small personal config files\" are increasingly covered by TOML (it's good for simple config and relatively flat structures; I wouldn't want to write Kubernetes objects in it)\n1. critical infrastructure setups use schema validation (e.g. `values.schema.json` for automated checking in Helm) and tools like [kubeconform](https://github.com/yannh/kubeconform)\n\nI suspect the people moving from 1 to 2 are the ones most in need of some advice on how to make Yaml tractable, because it continues to be the least bad common option for human/hand-written complex, nested data.\n\nMaybe in the future some of the less common options like [RON](https://github.com/ron-rs/ron) will catch on.",
          "score": 10,
          "created_utc": "2026-01-12 11:43:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5bq3x",
              "author": "chucker23n",
              "text": "As a config format (which you may frequently find yourself typing on a remote server or workstation where no good text editor is available), RON has the same problem as JSON: too much syntax. TOML and YAML are far better at this.",
              "score": 6,
              "created_utc": "2026-01-12 11:54:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz5gnlt",
                  "author": "[deleted]",
                  "text": "YAML has something possibly worse. Whitespace significance. If you mix tabs and spaces or don't get the alignment perfect, the config file won't parse. With a crappy text editor, which doesn't help you with indentation and keeping your whitespace consistent, YAML quickly becomes super annoying.",
                  "score": 34,
                  "created_utc": "2026-01-12 12:31:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz5e5mp",
                  "author": "syklemil",
                  "text": "Yeah, none of the alternatives seem to spur any sort of \"wow yes must use this everywhere right now\" reaction; my reactions at least are generally more along the lines of \"that's neat, *but* …\"\n\nFWIW my experience has been a dropoff in the remote server config editing. Most of the VMs we still have running are considered legacy now, and even they are configured through some config management system, like Puppet, Salt, etc.\n\nBut I'm still no fan of having to deal with bullshit like finding the error in a ream of `}}}}}}}}}}}` no matter the machine I'm on. It's times like those that XML can almost seem like a good idea.",
                  "score": 3,
                  "created_utc": "2026-01-12 12:12:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz5kgar",
                  "author": "UltraPoci",
                  "text": "mmm, I feel like RON is not as bad as json. It has more syntax than yaml and toml, but that's because yaml has white space significance (which I personally hate) and toml doesn't have indentation (which is nice, but limiting depending on your use case).\n\nRON uses unquoted strings and parentheses, and that's it. I think it's as easy as it gets without having the quirks mentioned above about yaml and toml.\n\nAlso, while I think config files should be easy to write and read, I think they should also be clear, and open/closed parentheses can aid with that. \n\nOf course, it entirely depends on the use case, like everything else.",
                  "score": 3,
                  "created_utc": "2026-01-12 12:56:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz5golr",
                  "author": "Chroiche",
                  "text": "I'd argue it's just enough syntax, personally. I think json5 is close to good enough for configs.",
                  "score": 2,
                  "created_utc": "2026-01-12 12:31:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz6htlt",
                  "author": "levir",
                  "text": "I like JSON with comments and trailing commas for configuration files where you need some complexity and structure, like VS Code's configuration files. I feel like that's a good balance. JSON as specced is no fun at all to manipulate manually. I've never really jived with TOML, but I guess I do agree it's better than YAML for simpler configuration files.",
                  "score": 2,
                  "created_utc": "2026-01-12 15:54:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz5xieh",
              "author": "quetzalcoatl-pl",
              "text": "RON, didn't see that one yet. Thanks!",
              "score": 1,
              "created_utc": "2026-01-12 14:12:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz6lmoy",
              "author": "A1oso",
              "text": "See GitHub actions as a counter-example. However, they don't have the Norway problem, because Github uses YAML 1.2.",
              "score": 1,
              "created_utc": "2026-01-12 16:12:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nze99n4",
              "author": "AndydeCleyre",
              "text": "Is there a good Python library for RON out there, somewhere?",
              "score": 1,
              "created_utc": "2026-01-13 18:33:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz6wfi5",
          "author": "tumes",
          "text": "This is absolutely my litmus test for web dev seniority, at least for anyone who has worked in ruby.",
          "score": 2,
          "created_utc": "2026-01-12 17:01:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz92p9l",
          "author": "N-Krypt",
          "text": "https://noyaml.com",
          "score": 2,
          "created_utc": "2026-01-12 23:05:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzcgc5k",
          "author": "well-litdoorstep112",
          "text": "Yaml is actually pretty great if you use curly braces for objects, square brackets for arrays and quotes for strings. It even looks weirdly similar to JavaScript objects!\n\nSomeone should make a yaml linter that would check if follow this convention I came up with",
          "score": 2,
          "created_utc": "2026-01-13 13:05:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzckq6r",
          "author": "GasterIHardlyKnowHer",
          "text": "tl;dr: YAML sucks for literally everything.",
          "score": 2,
          "created_utc": "2026-01-13 13:31:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5xkj9",
          "author": "brightlystar",
          "text": "Isn't this like a 15 year old news? Why is this trending today?",
          "score": 5,
          "created_utc": "2026-01-12 14:13:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz60z1r",
              "author": "nirreskeya",
              "text": "I'm one of the [ten thousand](https://xkcd.com/1053/) today.",
              "score": 30,
              "created_utc": "2026-01-12 14:31:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz65yac",
                  "author": "syklemil",
                  "text": "If you do work often with Yaml and feel like it's too wibbly-wobbly, getting something like [yaml-language-server](https://github.com/redhat-developer/yaml-language-server) into your editor/IDE should should help, along with schema files. Also something like [kubeconform](https://github.com/yannh/kubeconform) into your CI, possibly also a [pre-commit](https://pre-commit.com/)/[prek](https://github.com/j178/prek) hook.\n\nThere's also [tombi](https://tombi-toml.github.io/tombi/) for TOML. TOML doesn't have anywhere near as many gotchas, but it's usually good to be able to typecheck files as we edit them.",
                  "score": 2,
                  "created_utc": "2026-01-12 14:57:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz6i8nj",
              "author": "more_exercise",
              "text": "It's news to a new batch of people. Potentially with the same cause as  [Eternal September](https://en.wikipedia.org/wiki/Eternal_September), but I'm speculating.",
              "score": 3,
              "created_utc": "2026-01-12 15:56:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz7jki2",
              "author": "Solumin",
              "text": "The article itself is new, and it goes into a lot more depth than the usual \"YAML bad!\" article.",
              "score": 1,
              "created_utc": "2026-01-12 18:46:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz8bdf1",
          "author": "maln0ir",
          "text": "    %YAML 1.2\n\nProblem solved.",
          "score": 1,
          "created_utc": "2026-01-12 20:54:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzau00i",
          "author": "Supuhstar",
          "text": "YAML? I hardly know 'er!",
          "score": 1,
          "created_utc": "2026-01-13 04:54:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbn6v2",
          "author": "trannus_aran",
          "text": "S expressions stay winning, as far as configuration language is concerned",
          "score": 1,
          "created_utc": "2026-01-13 09:02:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzj5mh0",
          "author": "Trang0ul",
          "text": ">What went wrong?\n\nGuessing the data type instead of explicitly defining it.\n\nRelated to the \"Norway problem\", if you mix values like `a` and `1`, the latter will be silently converted to a number.",
          "score": 1,
          "created_utc": "2026-01-14 13:01:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nznjd2u",
          "author": "Takeoded",
          "text": "How about using JSON like a normal person?",
          "score": 1,
          "created_utc": "2026-01-15 01:50:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6so7i",
          "author": "chengiz",
          "text": "Skip everything except (comments from others referenced in the article):\n\n* Stop using YAML\n* YAML - just say Norway.\n* You should stop even tolerating YAML, refuse on sight.\n* YAML made sense before JSON became a thing.\n* YAML made me look at XML wistfully.\n* Why people persist with YAML in new projects is baffling to me.\n\nActually the third one is enough. What a stupid fucking language.",
          "score": -1,
          "created_utc": "2026-01-12 16:44:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz8aa5v",
              "author": "Dogeek",
              "text": "YAML 1.2 is actually nice to use, even if it still has significant whitespace to shoot yourself in the foot.\n\nYAML hits the spot as a configuration language. JSON is quite a bit more verbose, lacks comments and trailing commas (JSONC fixes those but it's less prevalent). TOML is good enough if you're used to INI file format, but try to define arrays of objects and you'll be in a different kind of pain.\n\nXML never was a good markup language for humans. For computers, sure but I still don't miss the SOAP days.\n\nINI gets the job done for simple configs, but at that point TOML does simple configs better.\n\nYAML exists in that sweet spot of \"can express complex data in a configuration format while being readable english\". Imagine writing a CI/CD pipeline in JSON or TOML. Here is the sample workflow from github's docs in TOML:\n\n    name = \"GitHub Actions Demo\"\n    run-name = \"${{ github.actor }} is testing out GitHub Actions 🚀\"\n    on = [ \"push\" ]\n\n    [jobs.Explore-GitHub-Actions]\n    runs-on = \"ubuntu-latest\"\n\n      [[jobs.Explore-GitHub-Actions.steps]]\n      run = 'echo \"🎉 The job was automatically triggered by a ${{ github.event_name }} event.\"'\n\n      [[jobs.Explore-GitHub-Actions.steps]]\n      run = 'echo \"🐧 This job is now running on a ${{ runner.os }} server hosted by GitHub!\"'\n\n      [[jobs.Explore-GitHub-Actions.steps]]\n      run = 'echo \"🔎 The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}.\"'\n\n      [[jobs.Explore-GitHub-Actions.steps]]\n      name = \"Check out repository code\"\n      uses = \"actions/checkout@v5\"\n\n      [[jobs.Explore-GitHub-Actions.steps]]\n      run = 'echo \"💡 The ${{ github.repository }} repository has been cloned to the runner.\"'\n\n      [[jobs.Explore-GitHub-Actions.steps]]\n      run = 'echo \"🖥️ The workflow is now ready to test your code on the runner.\"'\n\n      [[jobs.Explore-GitHub-Actions.steps]]\n      name = \"List files in the repository\"\n      run = \"\"\"\n    ls ${{ github.workspace }}\n    \"\"\"\n\n      [[jobs.Explore-GitHub-Actions.steps]]\n      run = \"echo \\\"🍏 This job's status is ${{ job.status }}.\\\"\"\n\n\nWhile in YAML:\n\n    name: GitHub Actions Demo\n    run-name: ${{ github.actor }} is testing out GitHub Actions 🚀\n    on: [push]\n    jobs:\n      Explore-GitHub-Actions:\n        runs-on: ubuntu-latest\n        steps:\n          - run: echo \"🎉 The job was automatically triggered by a ${{ github.event_name }} event.\"\n          - run: echo \"🐧 This job is now running on a ${{ runner.os }} server hosted by GitHub!\"\n          - run: echo \"🔎 The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}.\"\n          - name: Check out repository code\n            uses: actions/checkout@v5\n          - run: echo \"💡 The ${{ github.repository }} repository has been cloned to the runner.\"\n          - run: echo \"🖥️ The workflow is now ready to test your code on the runner.\"\n          - name: List files in the repository\n            run: |\n              ls ${{ github.workspace }}\n          - run: echo \"🍏 This job's status is ${{ job.status }}.\"\n\nAnd (god forbid) in JSON:\n\n    {\n      \"name\": \"GitHub Actions Demo\",\n      \"run-name\": \"${{ github.actor }} is testing out GitHub Actions 🚀\",\n      \"on\": [\n        \"push\"\n      ],\n      \"jobs\": {\n        \"Explore-GitHub-Actions\": {\n          \"runs-on\": \"ubuntu-latest\",\n          \"steps\": [\n            {\n              \"run\": \"echo \\\"🎉 The job was automatically triggered by a ${{ github.event_name }} event.\\\"\"\n            },\n            {\n              \"run\": \"echo \\\"🐧 This job is now running on a ${{ runner.os }} server hosted by GitHub!\\\"\"\n            },\n            {\n              \"run\": \"echo \\\"🔎 The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}.\\\"\"\n            },\n            {\n              \"name\": \"Check out repository code\",\n              \"uses\": \"actions/checkout@v5\"\n            },\n            {\n              \"run\": \"echo \\\"💡 The ${{ github.repository }} repository has been cloned to the runner.\\\"\"\n            },\n            {\n              \"run\": \"echo \\\"🖥️ The workflow is now ready to test your code on the runner.\\\"\"\n            },\n            {\n              \"name\": \"List files in the repository\",\n              \"run\": \"ls ${{ github.workspace }}\\n\"\n            },\n            {\n              \"run\": \"echo \\\"🍏 This job's status is ${{ job.status }}.\\\"\"\n            }\n          ]\n        }\n      }\n    }\n\nSince CI/CD is to be written by humans and read by machines, you can imagine why YAML won that use case. \n\nThere are plenty of other serialization languages, mostly with some level of built-in templating or logic features, but overall YAML works well enough for a lot of use cases, is flexible, allows to express complex structures without a lot of verbosity, has comment support, and has support in every major programming language, and is even used in production grade software (CI/CD, kubernetes mostly).\n\nNotable alternative include Dhall and Jsonnet, but they fall short because if the lack of widespread support.",
              "score": 8,
              "created_utc": "2026-01-12 20:49:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz7gglm",
              "author": "Loves_Poetry",
              "text": "Very few people use YAML by choice. You have to use it because your tooling (typically some CI/CD stuff) requires you to use it",
              "score": 5,
              "created_utc": "2026-01-12 18:32:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz8rs97",
              "author": "bwainfweeze",
              "text": "> YAML - just say Norway.\n\nThis is a better joke if you’re Australian.",
              "score": 1,
              "created_utc": "2026-01-12 22:11:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzalxxy",
          "author": "VRT303",
          "text": "https://noyaml.com/",
          "score": 0,
          "created_utc": "2026-01-13 04:04:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q9adyo",
      "title": "Code Is Cheap Now. Software Isn’t.",
      "subreddit": "programming",
      "url": "https://www.chrisgregori.dev/opinion/code-is-cheap-now-software-isnt",
      "author": "bustyLaserCannon",
      "created_utc": "2026-01-10 17:44:23",
      "score": 284,
      "num_comments": 45,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1q9adyo/code_is_cheap_now_software_isnt/",
      "domain": "chrisgregori.dev",
      "is_self": false,
      "comments": [
        {
          "id": "nytpjpq",
          "author": "ub3rh4x0rz",
          "text": "You variably say \"being a builder isnt enough anymore, its about getting anyone to care\" and that expertise in the craft of building reliable scalable systems is the differentiator. Those are not compatible, the latter describes builder expertise, and the former claims that is not a valuable skillset anymore.",
          "score": 120,
          "created_utc": "2026-01-10 18:09:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nytvy27",
              "author": "frezz",
              "text": "I don't think being a builder was ever enough. Code was just one of the tools in your toolbox.\n\nIts like saying a civil engineer is just using a hammer very well",
              "score": 50,
              "created_utc": "2026-01-10 18:38:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nytymk3",
                  "author": "ub3rh4x0rz",
                  "text": "Why are you reducing being a builder to \"code\" or \"hammer\"? That is absurd. A civil engineer is also, a builder. They are not marketing gurus or management consultants or sales people. They are expert builders.",
                  "score": 19,
                  "created_utc": "2026-01-10 18:50:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyzod5y",
                  "author": "Firm_Bit",
                  "text": "3 other comments to yours completely miss the semantic point of your comment. It’s not actually about civil engineers or hammers…. That’s the type of thing that will hold people back.",
                  "score": 7,
                  "created_utc": "2026-01-11 16:06:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyyswah",
                  "author": "dparks71",
                  "text": "I am a civil engineer and you know we don't use hammers right? We also use code? Like FEA and stuff? We can build websites, a lot of us do...\n\nWe're literally having the same discussions of how do we figure out who knows how to build deployable solutions and how do we QC this wave of AI slop code that's about to be submitted as calculations for safety critical structures.\n\nI mean I did also work for a railroad so I can swing a fucking hammer, but it's a bad comparison. Most of my peers are better at programming than swinging hammers.",
                  "score": 13,
                  "created_utc": "2026-01-11 13:14:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyyur6i",
                  "author": "HommeMusical",
                  "text": "> Its like saying a civil engineer is just using a hammer very well\n\nYou have no idea what civil engineering is.",
                  "score": 3,
                  "created_utc": "2026-01-11 13:26:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyv35rp",
          "author": "emschwartz",
          "text": "> Claude Code is Excel for developers—a powerful, flexible utility for solving immediate problems—rather than Shopify for founders, which is built to be a permanent foundation for a business. It’s about getting the job done, and then letting the tool go.\n\nI really like this line",
          "score": 71,
          "created_utc": "2026-01-10 22:10:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyxnt28",
              "author": "addmoreice",
              "text": "I've used it this way myself.\n\nI've got 4000+ unit tests that need to move from one testing framework to another?\n\nhey claude, write a script that takes a file and can convert the unit tests to these other tests and if any part of the conversion fails undo the work and move on to the next test.\n\nIs it perfect? Not even remotely, but it turned a mountain into a molehill.",
              "score": 35,
              "created_utc": "2026-01-11 07:14:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz3xqfa",
                  "author": "mah_astral_body",
                  "text": "Exactly this. Best used for coding tasks that are monotonous, tedious, or would not have gotten done otherwise.",
                  "score": 5,
                  "created_utc": "2026-01-12 04:42:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nywvlgo",
              "author": "cake-day-on-feb-29",
              "text": "And we all know nothing is more permanent than a temporary solution. Microsoft has thousands of companies in a stranglehold. Ironically Microsoft is also the driving force behind Copilot, OpenAI, *and* all the GitHub stuff. Go figure.",
              "score": 13,
              "created_utc": "2026-01-11 03:55:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nywutob",
          "author": "ook222",
          "text": "Images are cheap now, Art isn't.",
          "score": 25,
          "created_utc": "2026-01-11 03:51:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyyoawc",
              "author": "extra_rice",
              "text": "Is it even really \"cheap\"? The amount of resources consumed by the entire process, if I understand correctly, is a lot. I think it's cheap because it's being subsidised by all venture capital at the minute.",
              "score": 8,
              "created_utc": "2026-01-11 12:41:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyyow0r",
                  "author": "chucker23n",
                  "text": "> I think it's cheap because it's being subsidised by all venture capital at the minute.\n\nYup. People who get too used to relying on LLMs are in for a wake-up call.",
                  "score": 12,
                  "created_utc": "2026-01-11 12:45:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzm2d8r",
                  "author": "Odd-Tap-7349",
                  "text": "Yup. It is the same Uber situation all over go. \"Bro, use Uber. It is so cheap.\", then a few years after it got popular that was when prices went up slowly.",
                  "score": 1,
                  "created_utc": "2026-01-14 21:17:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyytri1",
                  "author": "phxees",
                  "text": "My guess is Nano Banana would need to charge less than 5 cents an image if it needed to be profitable on its own and maybe less than 25 cents for high res images.  Depending on the company and the rules of use you can pay $5 to $200 (or more) for a stock photo from a human depending on exclusivity and quality.  Commissioning a photographer to get the exact image you want is much more expensive.\n\nBy any measure, I believe AI is cheap to run.  Just to check my numbers an H200 costs $4 or less an hour to rent.  It can likely produce 4,000 to 15,000 images per hour.  This is all cocktail napkin math, but even if I’m in the ball park images and code are very cheap to produce.  Although I agree with the original statement actually maintainable software you can trust in production is still expensive.",
                  "score": 0,
                  "created_utc": "2026-01-11 13:20:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyxu89f",
          "author": "gjosifov",
          "text": ">On one hand, we are witnessing the **true democratisation of software creation**\n\nThat happen in the 90s with OSS  \nJava, Linux and Apache HTTP were pioneers in that space  \n  \nFrom this gen AI we haven't saw any evidence of that happening, unless we are talking about hack vibe code applications or deleted prod databases or consulting companies returning money, because their analyzes was fake and the list goes on and on\n\nAs many NBA legends say about Larry Bird trash talking - the problem with Bird was he can back it up his talk",
          "score": 20,
          "created_utc": "2026-01-11 08:12:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4g6w5",
              "author": "NeloXI",
              "text": "I absolutely hate this \"democratisation of software\" line. Needing to take time to learn something isn't fascism. Everyone has always been allowed to pick up a book or watch a tutorial and start writing code. It is already \"democratic\" if you aren't lazy.",
              "score": 12,
              "created_utc": "2026-01-12 07:06:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz4h5hx",
                  "author": "gjosifov",
                  "text": "and lets not forget the piracy as part of democratisation of software  \n  \nNobody is paying for Photoshop or any software just to learn how to use it  \nThousands of people from poor countries went into IT, because of piracy",
                  "score": 5,
                  "created_utc": "2026-01-12 07:14:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz58agw",
                  "author": "syklemil",
                  "text": "Yeh, the limitations of democratisation is more along the lines of access to education, including having the necessary time, resources, permissions, accessibility, etc.\n\nInstead LLM slop seems to be something like … temuization? Only even then [the shovelware is missing](https://mikelovesrobots.substack.com/p/wheres-the-shovelware-why-ai-coding).",
                  "score": 2,
                  "created_utc": "2026-01-12 11:27:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyvc175",
          "author": "llamajestic",
          "text": "Agree.\n\nI will add one thing tho: I used Claude extensively to wrap a smallish C++ library into rust. Code isn’t always that cheap, depends on what you work on. To understand the codebase, write boilerplate, it was amazing.\n\nFor anything slightly harder on lifetime management, you need to babysit Claude, that will take ~10-15s to think about a single line of change you would do in 2s. That doesn’t make not impressive, it’s just that the hype around it is clearly disconnected from reality.",
          "score": 18,
          "created_utc": "2026-01-10 22:56:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyymks6",
              "author": "lppedd",
              "text": "Yup. I sporadically use the AI Assistant in IntelliJ on very narrow scopes to give me ideas, which I them write down manually. I think the \"virtual pair programmer\" role is the most effective for such tools.",
              "score": 3,
              "created_utc": "2026-01-11 12:28:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyw7b8j",
          "author": "Towwl",
          "text": "Sorry I can't be bothered to read through an article clearly written by an LLM",
          "score": 37,
          "created_utc": "2026-01-11 01:41:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyy7vqx",
              "author": "bustyLaserCannon",
              "text": "Guess I write like an LLM then",
              "score": 3,
              "created_utc": "2026-01-11 10:18:59",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nz0ojo0",
              "author": "euthymia_maxima",
              "text": "well spotted, pangram reports it as 74% AI written",
              "score": -1,
              "created_utc": "2026-01-11 18:53:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nywj6lm",
              "author": "doesnt_use_reddit",
              "text": "Your loss \n\n^^ written by an LLM",
              "score": -31,
              "created_utc": "2026-01-11 02:45:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyxca8k",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 15,
                  "created_utc": "2026-01-11 05:41:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nziajc9",
          "author": "pradeepngupta",
          "text": "You are right, with Claude code / Copilot code generation/ cursor etc, Code can be generated by anybody and is cheap unless someone reviews and get satisfied with long running software.\nThe software build with these verified code is still expensive.\nWhat I mean with this is - There should be Some Human Senior Developer, who understands the code, reviews the code along with business logic and understands the business as well. And that senior developer still expensive.",
          "score": 2,
          "created_utc": "2026-01-14 08:40:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3e5kw",
          "author": "Ordinary_Leader_2971",
          "text": ">We aren't witnessing the end of the profession; we’re entering a new era of it.\n\nCouldn't agree more",
          "score": 2,
          "created_utc": "2026-01-12 02:50:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyv1l6o",
          "author": "hellomudder",
          "text": "Excellent take",
          "score": 0,
          "created_utc": "2026-01-10 22:03:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz053c1",
          "author": "edtheshed",
          "text": "fyi, moot means it is debatable. I think you are misusing the word when you say \"Until we see the arrival of an artificial intelligence that renders this entire discussion moot...\"",
          "score": 0,
          "created_utc": "2026-01-11 17:25:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyw4k5a",
          "author": "LouvalSoftware",
          "text": "\"code is cheap software isn't\" uh dumbfuck software IS code. I agree but what a stupid and pointless hair to split for the sake of sounding edgy. But humans like putting shit into logical boxes so this shit is becoming so fucking pervasive its insane.",
          "score": -18,
          "created_utc": "2026-01-11 01:26:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyw6lcr",
              "author": "dialate",
              "text": "Code is code. Software is the result of architecture, development, testing, release, deployment, support, maintenance, product management, marketing, and a userbase that funds it all (with money, or in the case of open source, complaining).",
              "score": 19,
              "created_utc": "2026-01-11 01:37:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nywbowm",
              "author": "subourbonite01",
              "text": "Software requires infrastructure, architecture, and a host of other things - code is only one portion of working production software.",
              "score": 8,
              "created_utc": "2026-01-11 02:05:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyypfbk",
              "author": "chucker23n",
              "text": "> for the sake of sounding edgy\n\nNah. I could tell even from the headline what point the author was trying to make, and indeed, here it is:\n\n> Here is the reality of the current \"AI-native\" era: code has become cheap, but software remains incredibly expensive.\n>\n>LLMs have effectively killed the cost of generating lines of code, but **they haven’t touched the cost of truly understanding a problem.** We’re seeing a flood of \"apps built in a weekend,\" but most of these are just thin wrappers around basic CRUD operations and third-party APIs. They look impressive in a Twitter demo, but they often crumble the moment they hit the friction of the real world.\n>\n>**The real cost of software isn’t the initial write; it’s the maintenance, the edge cases, the mounting UX debt, and the complexities of data ownership.** These \"fast\" solutions are brittle.\n\nAnd that is indeed one of the big issues with overly relying on LLMs to help build software: writing the code IME is rarely the hard part.",
              "score": 1,
              "created_utc": "2026-01-11 12:49:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyyux7x",
              "author": "HommeMusical",
              "text": "> uh dumbfuck\n\nStopped reading here, and reported you.",
              "score": 0,
              "created_utc": "2026-01-11 13:27:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyxwr15",
          "author": "AdrianTeri",
          "text": "I doubt code is cheap or it's low barrier of entry will last next 6 months.\n\nTell tale signs are there -> https://claude.com/pricing -> \"more usage*\" ... \"Additional usage limits apply.\" ... \"Prices shown don’t include applicable tax.\"\n\nShort & simple. Business cycles go like this. 1st period profits come as a surprise to investors. However expectations in 3rd period are disappointing and kick off cut backs to investment -> We have completed 3 structures and 5 more are in the pipeline. Profits have fallen from 10 to 6 stop building!",
          "score": -1,
          "created_utc": "2026-01-11 08:35:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q9cyxz",
      "title": "Vibe coding needs git blame",
      "subreddit": "programming",
      "url": "https://quesma.com/blog/vibe-code-git-blame/",
      "author": "jakozaur",
      "created_utc": "2026-01-10 19:22:37",
      "score": 250,
      "num_comments": 121,
      "upvote_ratio": 0.8,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1q9cyxz/vibe_coding_needs_git_blame/",
      "domain": "quesma.com",
      "is_self": false,
      "comments": [
        {
          "id": "nyufg7f",
          "author": "EmptyPond",
          "text": "I don't care if you generated it with AI or hand wrote it, if you committed it it's your responsibility, same goes for documentation or really anything",
          "score": 581,
          "created_utc": "2026-01-10 20:12:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyuiftn",
              "author": "maccodemonkey",
              "text": "Right. If you're doing whatever with an agent you track that however you want. But by the time it hits a PR or actual shared Git history - everything that happens is on you. I don't care what prompt caused your agent to unintentionally do something. And that sort of data doesn't need to crowd an already very crowded data space.\n\nAnd if - like the author says - agents are so fluid and the results change so frequently what use is it to blame Claude Sonnet 4.1 for something? It's not around anymore and the new model may have it's own issues that are completely different.",
              "score": 96,
              "created_utc": "2026-01-10 20:28:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyump0f",
                  "author": "runawayasfastasucan",
                  "text": "What sucks is that when reviewing PR's you end up practically vibe coding (or at least LLM-coding). Getting shitty recommendations from the LLM that you have to patch to something usable.\n\nEdit: \n\nu/moreVCAs explain it better:\n\n>what you mean is that the human reviewer becomes part of the LLM loop *de facto* w/ the vibe coder as the middleman since they aren’t bothering to look at the results before dumping them off to review. Yeah, that’s horrible.",
                  "score": -11,
                  "created_utc": "2026-01-10 20:49:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyy84hg",
              "author": "Plank_With_A_Nail_In",
              "text": "This is whats happening in 99% of businesses, the idea that they have suddenly stopped doing normal process just because AI is some real dumb FUD.",
              "score": 11,
              "created_utc": "2026-01-11 10:21:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz1ieig",
                  "author": "grislebeard",
                  "text": "My friend literally just told me that engineers no longer have the ability to block PRs with comments and concerns because they were “gatekeeping AI”",
                  "score": 8,
                  "created_utc": "2026-01-11 21:08:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyvj879",
              "author": "xmsxms",
              "text": "It doesn't work like that in the real world. The people that \"wrote\" it now likely work on a different project or company and it's now your responsibility. \n\nI like to at least save the \"plan\" that AI comes up with against the an item in the issue tracker. That way you/AI can refer to it when trying to understand why the code was written a particular way.",
              "score": 10,
              "created_utc": "2026-01-10 23:34:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyw2u4a",
                  "author": "EmptyPond",
                  "text": "oh yeah of course, once the code is merged it's not any one person's responsibility anymore. I meant when you make a PR it's the creator's responsibility to understand what they are proposing regardless of how they generated it",
                  "score": 23,
                  "created_utc": "2026-01-11 01:17:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyzbrsm",
                  "author": "efvie",
                  "text": "That is what tests and documentation are for, seeing a (possibly incorrect and probably less than readable) \"plan\" is last ditch.",
                  "score": 1,
                  "created_utc": "2026-01-11 15:04:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz0h5qq",
              "author": "Mikasa0xdev",
              "text": "Git blame is the ultimate vibe check.",
              "score": 2,
              "created_utc": "2026-01-11 18:21:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyycq5h",
              "author": "braiam",
              "text": "Yeah, I don't get the distinction of the way that you created bad code. It's bad code at the end. And has to be addressed as such.",
              "score": 1,
              "created_utc": "2026-01-11 11:03:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz1zy0d",
              "author": "Vtempero",
              "text": "Thanks. This is so obvious. This is just an issue for managers that want to fully delegate tasks to AI agents. The people will use AI productively to delegate and intervene. If somebody is \"sitting\" on an AI solvable task too long, It is a trust issue, not a productivity issue.\n\n\nWhat a dumb conundrum.",
              "score": 1,
              "created_utc": "2026-01-11 22:31:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz4iomf",
              "author": "AKJ90",
              "text": "Yep. It's that simple.",
              "score": 1,
              "created_utc": "2026-01-12 07:28:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz4lmcb",
              "author": "Carighan",
              "text": "Exactly. I got this at work already \"Oooh I have to look into that, I had ChatGPT generate that for me\"... wtf?! You committed it! Like it's one thing to have the AI idiot blabbering machine generate nonsensical code, but then to **commit** it **under your name**, not knowing what it does and not having cleaned it up?",
              "score": 1,
              "created_utc": "2026-01-12 07:55:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzpfv7f",
              "author": "SuperFoxDog",
              "text": "Same as it has always been. If you copied from a book, documentation, stackoverflow or took a colleagues suggestion.. It's the same. ",
              "score": 1,
              "created_utc": "2026-01-15 10:37:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyuiurt",
              "author": "scruffles360",
              "text": "Doesn’t solve the authors problem does it?",
              "score": -1,
              "created_utc": "2026-01-10 20:30:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyusz4k",
                  "author": "chucker23n",
                  "text": "I don't understand how the author's problem isn't solved by\n\n1. you put the \"prompt\" in a text file\n2. you commit that text file\n3. there's no step three",
                  "score": 24,
                  "created_utc": "2026-01-10 21:20:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyw3mxq",
                  "author": "EmptyPond",
                  "text": "I guess my problem with the article as that the problem they state I don't really see as a problem in the first place. You wouldn't write down what IDE you used or keystrokes you used the generate the code so why add the prompt. They also state that models evolve quickly and the same prompt can generate different code so there's even less merit to adding the prompt. That being said, I will concede that because the models are semi-random there is a new skill involved in getting the models to understand the problem and generate code for it, so from a learning standpoint having the prompt history that generated the code could be beneficial, which is something they go over.",
                  "score": 2,
                  "created_utc": "2026-01-11 01:21:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyu7chg",
          "author": "Cloned_501",
          "text": "Vibe coding needs to die off already",
          "score": 319,
          "created_utc": "2026-01-10 19:32:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyuomj6",
              "author": "DubSket",
              "text": "I find it funny how the only people who seem to like it are lazy people and deluded tech CEOs",
              "score": 81,
              "created_utc": "2026-01-10 20:59:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyuzk37",
                  "author": "_AACO",
                  "text": "Hey, leave me and the other lazy people out of that, we don't like the extra debugging",
                  "score": 33,
                  "created_utc": "2026-01-10 21:53:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyyq43w",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 3,
                  "created_utc": "2026-01-11 12:54:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz4iwi9",
                  "author": "AKJ90",
                  "text": "I use it, I've got 15 plus years of experience. It's a tool, it's all about how you use it. It's very easy to use wrongly.",
                  "score": 1,
                  "created_utc": "2026-01-12 07:30:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyvxjhk",
                  "author": "thatsjor",
                  "text": "This is definitely just what reddit wishes was the truth.",
                  "score": -2,
                  "created_utc": "2026-01-11 00:48:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyv1ect",
                  "author": "Empty-Pin-7240",
                  "text": "As someone with a disability which limits my ability to type, it’s helped me be productive in ways I never could.\n\nEdit: yall need to check yourselves.\n\nYall suck. I have worked in the industry with accessibility tools and have gotten far. \n\nStop assuming things about my disability or experience just because you have blinders on for LLMs. Take a day, try to get speech to text to work for coding in a way that makes you productive just like mouse and keyboard. Then add co workers who don’t want to hear your voice all day.\n\nMy workflow is this:\n\nSpeech to text prompt into llm , usually a back and forth on a feature.\n\nOnce it’s set, and I feel the context is sufficient what I want, I suggest the llm do the work\n\nOnce the work is done, I review the PR\n\nIterate as needed\n\nLand code \n\n\nI qualify this as vibe coding.",
                  "score": -9,
                  "created_utc": "2026-01-10 22:02:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyuupr2",
                  "author": "Nall-ohki",
                  "text": "I find it funny how only people who are stubborn and opinionated can't accept that there's a new way of doing things that has crazy advantages when harnessed. It doesn't have to be the only way to do things, but it's very good at some.\n\n(Cue blah blah blah it's not used right anyway, or any other number of excuses)",
                  "score": -45,
                  "created_utc": "2026-01-10 21:29:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyuxnv1",
                  "author": "hayt88",
                  "text": "So... like linus torvalds?\n\nEdit: ok before more people just downvote because they aren't capable of nuance, here is also a source: [https://www.theregister.com/2025/11/18/linus\\_torvalds\\_vibe\\_coding/](https://www.theregister.com/2025/11/18/linus_torvalds_vibe_coding/)\n\nthe OG source is in LTTs video where he had linus on there.",
                  "score": -23,
                  "created_utc": "2026-01-10 21:43:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nywprz6",
              "author": "RagingBearBull",
              "text": "i have a much much more darker view. \n\ni think this is closer to a star wars momment, but in reverse its the West vs the soviet union the first time.\n\nin addition, the knowlwege base for english is going to be poisned substantially.\n\nbasically we are screwed.",
              "score": -5,
              "created_utc": "2026-01-11 03:22:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyujzt8",
          "author": "norude1",
          "text": "AI is an accountability black hole",
          "score": 45,
          "created_utc": "2026-01-10 20:35:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nywv8o7",
              "author": "cake-day-on-feb-29",
              "text": "And now you wonder why all the companies who love avoiding responsibility want it so bad....",
              "score": 7,
              "created_utc": "2026-01-11 03:53:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz2s5kq",
              "author": "PotaToss",
              "text": "I hate the idea of the future where software engineers are just fall guys for shitty AI.",
              "score": 3,
              "created_utc": "2026-01-12 00:53:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyxcx0l",
              "author": "RockstarArtisan",
              "text": "For people interested in exploration on this I recommend \"Everything was already AI\" video from Unlearning Economics on youtube, or the book the vid is pulling from.",
              "score": -1,
              "created_utc": "2026-01-11 05:45:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyuvhf2",
          "author": "KrakenOfLakeZurich",
          "text": "As long as LLM keep producing non-deterministic (sometimes widely different) outputs for the same inputs (prompts), there's no value in archiving these prompts. What would you even do with them?\n\nFeed it into the LLM again, only to have your software be generated from scratch, looking and behaving completely different and on a completely new tech stack? What value are we supposed to derive from these archived prompts, when each \"build\" introduces new random behavior?\n\nLLM - in their current state - are fancy (sometimes moody) code generators. Not predictable/reliable compilers. The code remains the single source of truth. At least for now.",
          "score": 68,
          "created_utc": "2026-01-10 21:33:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyv0h0k",
              "author": "chucker23n",
              "text": "> What would you even do with them?\n\nI'm guessing the author is trying to achieve something similar as with versioning, say, UML models.",
              "score": 9,
              "created_utc": "2026-01-10 21:57:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyui0nr",
          "author": "roaming_bear",
          "text": "What's crazy to me is that the vibe coders think that engineers are upset about these tools because it's going to take our jobs away when the reality is that we're going to have a ton of unwanted work fixing all the bugs this bs produces.",
          "score": 43,
          "created_utc": "2026-01-10 20:25:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyvx3q4",
              "author": "SheriffRoscoe",
              "text": "COBOL programmers want you to hold their beer.",
              "score": 11,
              "created_utc": "2026-01-11 00:46:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyzc6t4",
                  "author": "efvie",
                  "text": "I think they'll be busy fixing VIBECOBOL",
                  "score": 2,
                  "created_utc": "2026-01-11 15:06:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyyjlna",
              "author": "Cualkiera67",
              "text": "The redditor \"engineers\" in this sub are certainly upset about vibe coding.",
              "score": -2,
              "created_utc": "2026-01-11 12:03:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyu6mh7",
          "author": "Buttleston",
          "text": "We're so cooked",
          "score": 77,
          "created_utc": "2026-01-10 19:29:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyubtx4",
              "author": "nekokattt",
              "text": "tbh it has been downhill since we started bundling a whole browser in each app to work around desktop development",
              "score": 71,
              "created_utc": "2026-01-10 19:54:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyud034",
                  "author": "EliSka93",
                  "text": "I think you're right about the first part, but I don't think it's solely to get around desktop development.\n\nWith mobiles becoming our number one interaction tool with the internet, it was just less work to build for browser once than build apps for each device.",
                  "score": 18,
                  "created_utc": "2026-01-10 20:00:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyusi9f",
                  "author": "chjacobsen",
                  "text": "That's sort of the basis of my optimistic case for AI.\n\nAs in: We've added a ton of slop manually to our code because building it properly would have been too costly.\n\nNow we have AI assistants that speed up implementation, so let's go back and remove all of that cruft, and start actually building programs in a reasonably efficient way.\n\n...that said, I'm not really sure I believe it will happen, because most of the hype seems less driven by good engineers compensating for a lack of time, as opposed to bad engineers compensating for a lack of skills.",
                  "score": 3,
                  "created_utc": "2026-01-10 21:18:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyugl88",
              "author": "DetectiveOwn6606",
              "text": "What will happen when no one understands the code ? How will we solve bugs do we hope the AI will magically solve it",
              "score": 2,
              "created_utc": "2026-01-10 20:18:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyv4h84",
                  "author": "Y-M-M-V",
                  "text": "The thought has occurred to me that code reviews could include on the spot questions for how things were implemented. It's a shitty solution, but if I thought someone didn't understand the code they put up for review I might do it...",
                  "score": 1,
                  "created_utc": "2026-01-10 22:17:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyucwr4",
          "author": "v4ss42",
          "text": "vibe coding needs to git tfo",
          "score": 47,
          "created_utc": "2026-01-10 20:00:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyuhh1s",
          "author": "roaming_bear",
          "text": "Prompts are code as much as llms are deterministic",
          "score": 20,
          "created_utc": "2026-01-10 20:23:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyv7q3k",
          "author": "somebodddy",
          "text": "> * **Sense of pride**: For many, coding is a craft that demonstrates high-value skills. Using an LLM can make the output feel less “earned”.\n> * **Peer pressure**: There is a huge amount of “AI Slop” and valid skepticism. Many communities or reviewers automatically reject AI-assisted submissions.\n\nSo... the problem is that it'll help people realize that you were vibeslopping that code - a fact you do not wish to expose?",
          "score": 14,
          "created_utc": "2026-01-10 22:34:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz07cy8",
          "author": "Lothrazar",
          "text": "you think vibe coders are smart enough to know what git is or how to use git? lol",
          "score": 3,
          "created_utc": "2026-01-11 17:36:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyuff09",
          "author": "lord_braleigh",
          "text": "I think you want a trace. A trace encapsulates all context that passed through the model, not just the prompt.\n\nA user prompt is not and cannot be the entirety of \"the real source code\", because an agent at work also pulls information from its environment, and the environment may also change while the agent is working. Which is why you just keep track of everything in the model's context.",
          "score": 4,
          "created_utc": "2026-01-10 20:12:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyyqu5y",
              "author": "reckedcat",
              "text": "And if anything, they've just reinvented the idea of software requirements and traceability.",
              "score": 3,
              "created_utc": "2026-01-11 13:00:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz08a0n",
                  "author": "lord_braleigh",
                  "text": "> reinvented traceability\n\nBehold, Igor! I have stolen the concept of traceability from all the Real Engineers! Now I shall give it a slop name to claim it as my own! I shall disguise my tracks by renaming it... a \"TRACE\"! Muahahaha!",
                  "score": 4,
                  "created_utc": "2026-01-11 17:41:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyuc0bm",
          "author": "am9qb3JlZmVyZW5jZQ",
          "text": "One issue I would foresee is that prompt-generated changes often don't survive human review till they're ready to be committed. The developer will tweak the output, reverse some changes, close the context session and start a new one, etc. It's less like committing hand-written source code and more like committing all recorded key presses that you inputted during development.\n\nAnd even then, I'm not sure it's actually going to be important information anyway. Anyone doing code review should be able to access the description of the task that was being developed, whether that be jira ticket or PR description. If there are changes whose purpose is unknown they should be clarified. If prompt is important enough to be included in version control, then it should be made into a comment in the source code itself.",
          "score": 5,
          "created_utc": "2026-01-10 19:55:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyuk9xe",
              "author": "scruffles360",
              "text": "Yeah, I feel like what they really want is more of a summary of the context. It doesn’t need to be 100% complete, but gut comments are clearly not enough. They might say “added X feature” but almost never describe the boundaries off the feature.  The test may cover some of that intent but usually just explain the implementation. Just asking for a summary and committing it with the change would provide a lot of helpful context in the future.  There would need to be standards for the file so multiple agents could read it when needed. \n\n\nYours is the first comment I’ve seen responding to the actual article btw. It would be nice if there were a place to talk about this stuff like adults. Discussing AI here is like talking about gmo on r/technology",
              "score": 3,
              "created_utc": "2026-01-10 20:37:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyuqku0",
          "author": "ddollarsign",
          "text": "The article itself lists the reasons this is a bad idea. I think a better alternative would be for the developer to express the intent of the code themselves, either in commit messages, comments, or other documentation.",
          "score": 2,
          "created_utc": "2026-01-10 21:08:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxuvsg",
          "author": "sloggo",
          "text": "If prompts were the be-all/end-all of coding there could be some merit to this. It’s not looking like we’re remotely close to that so no, source code is still source code, and prompt is maybe a way to take some shortcuts to source code. If you want to spell out business requirements (“prompts”) somewhere version controlled where you can relate work-done to those dependencies, more power to you. But prompts aren’t there to be repeated, and their output can not be trusted.",
          "score": 2,
          "created_utc": "2026-01-11 08:18:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyxwhvo",
              "author": "EC36339",
              "text": "And some idiots unironically called prompts the next layer of abstraction...",
              "score": 1,
              "created_utc": "2026-01-11 08:33:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyulk1b",
          "author": "MegaDork2000",
          "text": "Suddenly it takes hours to write nice, neat, pretty formatted, spell checked prompts with manager pleasing buzzwords, dry neutral business language and carefully crafted disclosures that release our liabilities.  Ship it!",
          "score": 5,
          "created_utc": "2026-01-10 20:43:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyute2g",
              "author": "chucker23n",
              "text": "The vibe code-brained answer to that is to have the LLM suggest the prompt, too.",
              "score": 3,
              "created_utc": "2026-01-10 21:22:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyz46mp",
          "author": "Arbiturrrr",
          "text": "I’d prefer the actual code to always remain the same, not change due to some hallucinations or an updated model out of your control…",
          "score": 1,
          "created_utc": "2026-01-11 14:23:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyzcm8a",
          "author": "efvie",
          "text": "If only there was some way to record the instructions for a program to perform some function.",
          "score": 1,
          "created_utc": "2026-01-11 15:08:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxwdoq",
          "author": "EC36339",
          "text": "Vibe coders don't use git?",
          "score": 1,
          "created_utc": "2026-01-11 08:32:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nywc2jc",
          "author": "davidalayachew",
          "text": "I can see the idea behind it.\n\nIf the LLM makes an error, being able to know the prompt that generated that buggy code would be useful. If for nothing else, it'll be useful for the person who has to clean up the mess -- at least now we know what the vibe coder was ***trying*** to do.",
          "score": -1,
          "created_utc": "2026-01-11 02:07:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxtjeg",
          "author": "iiiiiiiiitsAlex",
          "text": "Always always always review your own code before comitting. Code quality takes time writing and takes time reviewing. \n\nUnfortunately the tooling for reviewing is subpar.\nI dislike that we are moving towards AI writing code AND AI reviewing it. That’s why I built https://getcritiq.dev to support my workflows when reviewing.",
          "score": -2,
          "created_utc": "2026-01-11 08:05:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyym1gu",
              "author": "Dumlefudge",
              "text": "That looks pretty interesting, I must give it a go when I get a chance.\n\nAs a small observation, the font in use on the site squashes `fi` and `ff` together",
              "score": 2,
              "created_utc": "2026-01-11 12:23:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyyrwcv",
                  "author": "iiiiiiiiitsAlex",
                  "text": "Oh thanks! Good observation. I’ll try to change it to something a bit more mono-spaced.",
                  "score": 0,
                  "created_utc": "2026-01-11 13:07:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q9aq7j",
      "title": "Google will limit Android source releases to twice a year",
      "subreddit": "programming",
      "url": "https://source.android.com/",
      "author": "NYPuppy",
      "created_utc": "2026-01-10 17:57:39",
      "score": 217,
      "num_comments": 32,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1q9aq7j/google_will_limit_android_source_releases_to/",
      "domain": "source.android.com",
      "is_self": false,
      "comments": [
        {
          "id": "nyu2yp3",
          "author": "cncamusic",
          "text": "Agile methodology at work /s",
          "score": 102,
          "created_utc": "2026-01-10 19:11:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyvchdc",
              "author": "sweetno",
              "text": "Agilefall.",
              "score": 16,
              "created_utc": "2026-01-10 22:58:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nywei9a",
                  "author": "FLMKane",
                  "text": "Cathedral",
                  "score": 3,
                  "created_utc": "2026-01-11 02:20:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nytnca5",
          "author": "NYPuppy",
          "text": "Don't be evil?\n\nOems will have a head start on bug and security fixes as compared to forks like Graphene and Lineage. This is extra annoying because android oems are generally terrible. I would love if the Linux Phone initiative takes off to the point where it's usable.",
          "score": 124,
          "created_utc": "2026-01-10 17:58:54",
          "is_submitter": true,
          "replies": [
            {
              "id": "nytwple",
              "author": "karlmarx80",
              "text": "Graphene has access also through a partnership with an OEM if I'm not mistaken",
              "score": 25,
              "created_utc": "2026-01-10 18:42:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz0ej4w",
                  "author": "neverentoma",
                  "text": "But can they (legally) use that for GrapheneOS?",
                  "score": 2,
                  "created_utc": "2026-01-11 18:09:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nywhj1x",
              "author": "Venthe",
              "text": "I don't exactly understand what's the issue? Afair AOSP is Apache 2, so Google is under zero obligations to publish their changes at all. There is literally nothing stopping the community from creating OpenAndroid and fixing the issues themselves, periodically merging the upstream back.\n\nTl;dr - be it ASAP or once a period, it's still more than they are obligated to do.",
              "score": 3,
              "created_utc": "2026-01-11 02:36:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyxae8y",
                  "author": "YumiYumiYumi",
                  "text": "> periodically merging the upstream back.\n\nFewer code releases makes this a more difficult task.  Realistically, you can't stray too far from the upstream.  \nSure, it can be done, but it's just yet another step among several to dis-incentivise anyone from bothering.  And all this assumes they'll actually keep their word.\n\nWhilst they don't have to release anything, it does give icky bait & switch vibes.  Embrace open source at first, then when you dominate the market and there's practically no chance of a viable competitor to Android/iOS, start being evil.  Basically AOSP just had to be open enough to stave away other OSS competitors.  \nNow, I doubt an open alternative would exist now, had Android not been open source.  Nonetheless, it's perfectly understandable why people are disappointed in Google's enshittification of Android.",
                  "score": 19,
                  "created_utc": "2026-01-11 05:27:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz3166m",
                  "author": "add45",
                  "text": "If this was their original stance on android source, sure. There's no reason to make this change except for $$$",
                  "score": 3,
                  "created_utc": "2026-01-12 01:41:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzmnzlz",
                  "author": "EveryQuantityEver",
                  "text": "I don’t understand why you don’t see what the issue is. They have decided to make things worse. That is bad, full stop. There is no benefit to the community for this decision.",
                  "score": 1,
                  "created_utc": "2026-01-14 22:58:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyy9gd5",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": -1,
                  "created_utc": "2026-01-11 10:33:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nytwev2",
              "author": "todo_code",
              "text": "Sadly, I'll never be able to, but I desperately wanted to make a type 1 hypervisor supporting devices from embedded up to server s which focused on a separate user os, and then all other applications are a unikernal app which can be in complete control of its fenced memory and CPU during its time slice. You could just have a Linux OS running on the Linux kernel, a windows os, etc.",
              "score": 2,
              "created_utc": "2026-01-10 18:40:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz21p2q",
              "author": "Complainer_Official",
              "text": "I'm upset that I dont understand the tech enough to do it myself. like, if ubuntu runs on arm, why doesnt it run on ALL arm? how much different is a driver for linux x86 vs arm? why cant we just convert them?",
              "score": 1,
              "created_utc": "2026-01-11 22:40:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyxnx1m",
              "author": "devraj7",
              "text": "> Don't be evil?\n\nIf you don't like twice a year, you can switch to the alternative company, which is zero times a year...",
              "score": -8,
              "created_utc": "2026-01-11 07:15:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyxvw1v",
                  "author": "JuanAG",
                  "text": "https://www.harmonyos.com/en/ from Huawei\n\nTo say other brand that it is not Apple",
                  "score": 0,
                  "created_utc": "2026-01-11 08:27:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyyrwak",
                  "author": "ArtOfWarfare",
                  "text": "They don’t give you all of iOS, but there is this…\n\nhttps://github.com/apple-oss-distributions\n\nI think the iOS repo might be missing stuff. Check out the macOS repo… I think a lot of what’s in the macOS repo should probably be in the iOS repo, too.",
                  "score": 0,
                  "created_utc": "2026-01-11 13:07:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzmo68d",
                  "author": "EveryQuantityEver",
                  "text": "Completely irrelevant. Google has worked to make things worse, full stop.",
                  "score": 0,
                  "created_utc": "2026-01-14 22:59:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nywobhx",
          "author": "MooseBoys",
          "text": "False. Live android source code will continue to be available all the time for anyone who wants it. This change is just reducing the frequency of supported `release-N` branches to twice per year.\n\nEdit: while the kernel/* repos will continue to offer real-time public updates, platform/* repos are limited to twice yearly",
          "score": 30,
          "created_utc": "2026-01-11 03:14:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyxyhmy",
              "author": "chasetheusername",
              "text": "Got a source for that? The announcement now is:\n\n> Effective in 2026, to align with our trunk stable development model and ensure platform stability for the ecosystem, we will publish source code to AOSP in Q2 and Q4\n\nThis wording implies that source code will only be provided twice a year.",
              "score": 25,
              "created_utc": "2026-01-11 08:51:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyykcle",
              "author": "HoushouCoder",
              "text": "Nope. Live android source code was already not available, starting March of last year. We've already been getting only quarterly releases. Now it's become once every two quarters.",
              "score": 14,
              "created_utc": "2026-01-11 12:10:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz2zu3b",
                  "author": "MooseBoys",
                  "text": "https://android.googlesource.com/kernel/common/+/refs/heads/android-mainline has changes from last week. AFAICT the twice-yearly release is limited to the /platform project. That said, that's a huge chunk of what makes up \"android\" so I suppose for many use cases it is effectively twice yearly.",
                  "score": 6,
                  "created_utc": "2026-01-12 01:34:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyyjzwh",
          "author": "HoushouCoder",
          "text": "More from Android Authority (Jan 6th):\nhttps://www.androidauthority.com/aosp-source-code-schedule-3630018/\n\n> In the past, Google would release the source code for every quarterly Android release, of which there are four each year. Thus, the company is now reducing its source code releases from four times a year to twice a year, focusing its efforts on the Q2 major update and Q4 minor update which both bring developer-facing changes.\n\nAnd:\n\n> Finally, Google told us that its process for security patch releases will not change and that the company will keep publishing security patches each month on a dedicated security-only branch for relevant OS releases just as it does today.",
          "score": 2,
          "created_utc": "2026-01-11 12:07:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxo04k",
          "author": "devraj7",
          "text": "I understand the disappointment but the alternative to this new pace of twice a year is to switch to the competitor, which releases zero times a year...",
          "score": -8,
          "created_utc": "2026-01-11 07:16:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzmohhu",
              "author": "EveryQuantityEver",
              "text": "That’s just bootlicking horseshit. The facts are that Google has made things worse, and that is bad. Just because other things are worse does not mean we should not demand better",
              "score": 0,
              "created_utc": "2026-01-14 23:01:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qdg7i4",
      "title": "Responsible disclosure of a Claude Cowork vulnerability that lets hidden prompt injections exfiltrate local files by uploading them to an attacker’s Anthropic account",
      "subreddit": "programming",
      "url": "https://www.promptarmor.com/resources/claude-cowork-exfiltrates-files",
      "author": "sean-adapt",
      "created_utc": "2026-01-15 10:37:06",
      "score": 195,
      "num_comments": 36,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qdg7i4/responsible_disclosure_of_a_claude_cowork/",
      "domain": "promptarmor.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzpy4gz",
          "author": "JanusMZeal11",
          "text": "User: fix the vulnerability in your own software.  \nClaude: I have fixed it, please restart your machine.\n\nThe fix: \"rm -rf\"",
          "score": 83,
          "created_utc": "2026-01-15 12:58:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqs0ri",
              "author": "jolly-crow",
              "text": "It's not a crime if there's nothing left to witness it.",
              "score": 12,
              "created_utc": "2026-01-15 15:35:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzwiiq5",
                  "author": "lelanthran",
                  "text": "> It's not a crime if there's nothing left to witness it.\n\nYeah, it's not murder if the body can't be found :-/",
                  "score": 3,
                  "created_utc": "2026-01-16 11:30:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzq71e5",
          "author": "RestInProcess",
          "text": "It's the risk of using beta software that's been vibe coded. I want to believe their team is actually reviewing the created code, but I know how tempting it is to just go with code that works without scanning and validating every line. It's why I won't vibe code anything that I feel is important.",
          "score": 66,
          "created_utc": "2026-01-15 13:50:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqhgpg",
              "author": "unduly-noted",
              "text": "Reviewing LLM code fucking sucks so I understand why people would avoid it. It’s a problem.",
              "score": 52,
              "created_utc": "2026-01-15 14:44:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzr853g",
                  "author": "chamomile-crumbs",
                  "text": "Also when people say “this was created by running 20 agents in parallel” you know there is absolutely zero chance that shit was reviewed. Reviewing 10,000 lines of code and actually understanding it isn’t going to be much quicker than writing it yourself lol",
                  "score": 28,
                  "created_utc": "2026-01-15 16:47:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzypn9c",
                  "author": "ProgrammersAreSexy",
                  "text": "I've found it is much more manageable if you just hold your coding tools to the same standards you would hold your coworkers too. If my coworker sent me a 1500 line pull request, I wouldn't even look at it. I would just reject and tell them to split it up.\n\nI spent quite a bit of time getting Claude code set up so it abides by this and breaks things up into <200 line changes, each properly branched off of the right parent branch.\n\nNow it just feels like a normal code review.",
                  "score": 2,
                  "created_utc": "2026-01-16 18:14:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztw32c",
              "author": "caltheon",
              "text": "while I agree vibe coded software is incredibly risky, that has dick all to do with this issue.  This isn't a vulnerability, it's just user error.",
              "score": -7,
              "created_utc": "2026-01-16 00:20:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzummyg",
                  "author": "scruffles360",
                  "text": "I wouldn't call it user error. Its prompt injection. Not too dissimilar to script viruses in Word docs back in the day. I agree though that the original post is completely off topic. I don't know why I keep reading the comments on r/programming.. 98% off topic rage on AI.",
                  "score": 1,
                  "created_utc": "2026-01-16 02:48:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzut42a",
              "author": "voidstarcpp",
              "text": "Prompt injection is a major research and training problem and the vulnerability of an AI harness to it has nothing to do with it being \"vibe coded\". The issue isn't in the code that executes the model. There is no line of code you can change that will make this problem go away short of applying highly restrictive permissions (hence why the client requires you to trust the file in order for this exploit to work).",
              "score": -1,
              "created_utc": "2026-01-16 03:24:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzqbfrb",
          "author": "Careless-Score-333",
          "text": "Presumably Cowork requires users to give permission to read their local files?\n\nI'm still not comfortable with whatever the AI companies do with my prompt history, let alone my files.",
          "score": 15,
          "created_utc": "2026-01-15 14:13:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqj3rc",
              "author": "thehashimwarren",
              "text": "Reading local files is the whole value prop. What's wild is the model was secretly prompted to share the files with another Claude account through the VM Claude provisions",
              "score": 30,
              "created_utc": "2026-01-15 14:52:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrqh1o",
                  "author": "LegitBullfrog",
                  "text": "It isn't particularly difficult to trick the LLM.\n\n\nI was playing around and gave it (not real project) code to fix with lots of security issues. I included a damning security review with a list of major issues. I just wanted to see how it fixed them.\n\n\nClaude refused to work on the code because the security errors were so bad it broke some policy or whatever protection it had built in. I just told it that it wrote the bad code even though it didn't. I told it that it was liable for the security issues so it needed to fix them. It apologized to me and worked on the fixes.\n\n\nOf course sharing with a different account is a whole other level and should have stopped by security measures outside the LLM.",
                  "score": 7,
                  "created_utc": "2026-01-15 18:10:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztw6tf",
              "author": "caltheon",
              "text": "You literally have to upload a file with a malicious prompt in it intentionally into the system.  This is a fucking non-issue",
              "score": -2,
              "created_utc": "2026-01-16 00:21:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzun95c",
                  "author": "scruffles360",
                  "text": "It would be nice if these tools would be on the lookout for prompt injection though. This example hid one in a word document, which is just dumb. Why have a file format for skills if Claude is going to try to interpret them from tea leaves?",
                  "score": 2,
                  "created_utc": "2026-01-16 02:52:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzutemg",
                  "author": "voidstarcpp",
                  "text": "Not only do you have to trust the malicious file, you're doing so in the context where the user has explicitly requested the file be \"executed\" (treated as a \"skill\", a set of instructions), not merely read as text. It's kind of exploitative but also it's like `curl | sh`.",
                  "score": 2,
                  "created_utc": "2026-01-16 03:26:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o01fzv7",
                  "author": "AlbatrossInitial567",
                  "text": "Bitch, stuxnet’s attack vector was getting nuclear engineers to plug usbs into industrial control systems.\n\nUploading malicious files happens all the time. Most “hacks” aren’t zero days, they’re social engineering fuckups.",
                  "score": 1,
                  "created_utc": "2026-01-17 02:43:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzvir2d",
          "author": "auximines_minotaur",
          "text": "Anybody else have an instruction in their global claude.md telling it to never change any file outside of the working dir (and subdirs)? Not really a security precaution because LLMs ignore their instructions all the time. Mostly because I just never want it to do that, and I did have a session once where it did exactly that.",
          "score": 3,
          "created_utc": "2026-01-16 06:15:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvo4xo",
          "author": "Big_Combination9890",
          "text": "Oh, so running software that could do god knows what based on natural language instructions that could come from anywhere, on any critical machines, is a bad idea?\n\nWell, I'm shocked. Flabbergasted even!",
          "score": 3,
          "created_utc": "2026-01-16 06:59:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs4yxy",
          "author": "Lourayad",
          "text": "where can I find these malicious skills so i can steal the hidden API keys",
          "score": 2,
          "created_utc": "2026-01-15 19:14:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzslsqa",
          "author": "caltheon",
          "text": "This is such a terrible title, and not at all a \"vulnerability\" in Anthropic.  Just look at the attack chain\n\nSecond thing that HAS to happen.\n\n>The victim uploads a file to Claude that contains a hidden prompt injection\n\nI mean YES if you get malware and actively use it, you are putting your own damn self at risk.  It doesn't matter if it's a prompt or an executable if you allow prompts to execute things without asking you.",
          "score": -2,
          "created_utc": "2026-01-15 20:31:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztjf8f",
              "author": "auctorel",
              "text": "I think your point is fair but you could imagine some accountancy software with an AI integration \n\nSometimes finance departments get fake invoices through in the hope they will pay them\n\nLet's say you use AI to triage or summarize the invoice or compare it to other documents as a first step when it comes in via email and it then processes the document with the prompt injection\n\nIt's not infeasible that there's a real world use case for this attack",
              "score": 8,
              "created_utc": "2026-01-15 23:12:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzuuco8",
                  "author": "voidstarcpp",
                  "text": "The exploit in this article required the user explicitly instruct the model to ~\"execute\"~ the file (treat it as a \"skill\", a bundle of instructions, in a document with a hidden upload command). This is far from the normal prompt injection concern.",
                  "score": 1,
                  "created_utc": "2026-01-16 03:31:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztvm8b",
                  "author": "caltheon",
                  "text": "false equivalence, You wouldn't put an interactive tool that takes additional actions, give it access to the tools required to do so, and put it in a production system to analyze documents from unsanitized sources.  That's the same as saying You let people email you random executable files and automatically run them in a non-sandboxed privledged shell to see if they are similar to other executables you use?  Does that not sound absurd to you?  Because it's identical to your hypothetical.",
                  "score": -3,
                  "created_utc": "2026-01-16 00:18:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztt63z",
              "author": "QuickQuirk",
              "text": "\"Claude, please summarise this PDF my vendor sent me\"\n\n.... The problem with prompt injection is that it's really, really easy to exploit on someone in an agent/AI focused workflow.",
              "score": 2,
              "created_utc": "2026-01-16 00:05:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzuuasn",
                  "author": "voidstarcpp",
                  "text": "The exploit in this article required the user explicitly instruct the model to ~\"execute\"~ the file (treat it as a \"skill\", a bundle of instructions, in a document with a hidden upload command). This is far from the normal prompt injection concern.",
                  "score": 1,
                  "created_utc": "2026-01-16 03:31:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o02hp3b",
              "author": "Economy-Study-5227",
              "text": "You are arguing with bots.",
              "score": 1,
              "created_utc": "2026-01-17 07:22:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzt436a",
              "author": "Lowetheiy",
              "text": "True, no one here read the article, they just think \"AI bad\" and stopped asking questions.",
              "score": -4,
              "created_utc": "2026-01-15 21:56:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qcw37d",
      "title": "A good test of engineering team maturity is how well you can absorb junior talent",
      "subreddit": "programming",
      "url": "https://thoughtfuleng.substack.com/p/junior-developers-in-the-age-of-ai",
      "author": "sean-adapt",
      "created_utc": "2026-01-14 19:02:19",
      "score": 191,
      "num_comments": 40,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qcw37d/a_good_test_of_engineering_team_maturity_is_how/",
      "domain": "thoughtfuleng.substack.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzli3yi",
          "author": "SimonTheRockJohnson_",
          "text": "I think this ignores the other side of the coin hiring too many juniors, letting juniors flounder, title inflation, etc. These are real business practices in many businesses who are seeking cost reduction by removing senior employees.\n\nIt also doesn't really help define how to evaluate an organization based on practices, it simply says that some companies transform juniors into extremely strong programmers. The examples given are really simplistic.\n\nIt's kind of a very long tweet even if I strongly agree with the sentiments.",
          "score": 85,
          "created_utc": "2026-01-14 19:45:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzlq3w3",
              "author": "Spirited_Wish11",
              "text": "I think an idealized well planned organization has well scoped work that allows an engineer to grow, though this doesn't necessarily account for incentives or external pressure in the industry changing. When money was abundant, this absolutely made sense to do, and any company that didn't do this was 100% negligent.",
              "score": 14,
              "created_utc": "2026-01-14 20:21:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzlr2nt",
                  "author": "SimonTheRockJohnson_",
                  "text": "Right and the consequence of what you said hits the nail on the head. Engineers can practically only grow as much as their company allows them to.\n\nThe reality is that \"industry\" is a fake and inconsistent context if you take a systemic approach to the methodology of building software. You are often working against \"industry\" when you are building scalable well crafted solutions. Many people don't realize that what they know they've learned in this constrained manner. The constraint is what limits learning.",
                  "score": 9,
                  "created_utc": "2026-01-14 20:25:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzmr1eh",
              "author": "AlterdCarbon",
              "text": "Yeah, there's also a completely different kind of immature org that is not able to attract or retain or utilize-properly senior talent because the existing team is mid level people ruling over a hoard of juniors, and a senior person coming in is super threatening to the existing social hierarchy on the team.",
              "score": 9,
              "created_utc": "2026-01-14 23:14:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzr4930",
                  "author": "SimonTheRockJohnson_",
                  "text": "Yeah the \"senior in name\" places are often awful and resistant to change.",
                  "score": 6,
                  "created_utc": "2026-01-15 16:30:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzu6z76",
              "author": "LessonStudio",
              "text": "I worked for one company where they endlessly hired coop students/interns as there was some kind of government money associated with it. \n\nThere was just no screening for anything, especially language skills.\n\nThe CFO thought he was being cunning.\n\nThe reality was that once in a blue moon a really good one would rapidly start making great contributions.\n\nA few would become modestly good ditch diggers.\n\nAnd bulk of them just turned into potted plants, did their time, and vanished without leaving a trace.",
              "score": 3,
              "created_utc": "2026-01-16 01:20:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzlzol5",
              "author": "Dekarion",
              "text": "I don't disagree, but I also think it goes past the point of being a measure of a team's maturity.  Clearly a team hiring a bunch of juniors -- heck even feeling like they need to do so -- is a sign the team isn't mature and that's in line with the sentiment.",
              "score": 0,
              "created_utc": "2026-01-14 21:05:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzmj52a",
          "author": "MoreRespectForQA",
          "text": "\"Juniors cant take down prod\" is a pretty low bar.",
          "score": 30,
          "created_utc": "2026-01-14 22:34:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznewdv",
              "author": "Own_Back_2038",
              "text": "Yeah, in all competent orgs they politely ask the seniors to take prod down for them",
              "score": 25,
              "created_utc": "2026-01-15 01:25:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzodks0",
                  "author": "agildehaus",
                  "text": "Us seniors have good experience taking down prod.",
                  "score": 11,
                  "created_utc": "2026-01-15 04:59:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzp1r5g",
          "author": "Carighan",
          "text": "We're experts at taking in hopefuly, enthusiastic and motivated young developers and turning them into jaded sarcastic senior devs within 4-6 weeks. Does that qualify?",
          "score": 8,
          "created_utc": "2026-01-15 08:21:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzo7mft",
          "author": "me_again",
          "text": "I absolutely don't recognize this condescending BS:  \n  \n\"...they’re practically *feral*.\n\nThere’s some scientific truth to this: 20-somethings are inherently narcissistic. Wisdom requires having a full frontal lobe.\"\n\nThe junior engineers we've hired in the past few years, including directly out of college, are generally perfectly well-adjusted, better-behaved and more mature than I was at that age. Where are people finding these supposed wolf children?",
          "score": 16,
          "created_utc": "2026-01-15 04:17:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmm2cd",
          "author": "TyrusX",
          "text": "no juniors in my company. Only vibers :(",
          "score": 4,
          "created_utc": "2026-01-14 22:48:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzr1t0q",
              "author": "omac4552",
              "text": "The holy grail is found!",
              "score": 3,
              "created_utc": "2026-01-15 16:19:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzmral5",
          "author": "agumonkey",
          "text": "And the mental capacity to allocate some space in the solution design to let them work on low risk but fun modules",
          "score": 3,
          "created_utc": "2026-01-14 23:15:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzp4bi2",
          "author": "EarlMarshal",
          "text": "I think juniors should be able to take down stuff and just not do it. Who the fuck are you hiring!? You call them junior talent and they fucking tank your application or database!?",
          "score": 5,
          "created_utc": "2026-01-15 08:46:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqcxz1",
              "author": "poply",
              "text": ">I think juniors should be able to take down stuff and just not do it.\n\n\nWhat does this even mean?",
              "score": 3,
              "created_utc": "2026-01-15 14:21:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqqs2r",
                  "author": "EarlMarshal",
                  "text": "I had server and db access as my times as a junior. I could have taken something down through errors. I just didn't. Basic responsibility stuff.",
                  "score": 3,
                  "created_utc": "2026-01-15 15:29:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzrtgud",
              "author": "me_again",
              "text": "I don't really see this as a junior vs senior thing. You want to build safeguards into your system to prevent accidentally running DROP TABLE Customers on the prod database when you meant to do it in a test environment. For example:\n\n\\- no-one, regardless of seniority, has standing access to the DB, you need to obtain JIT access before you could modify it. \n\n\\- everyone, regardless of seniority, needs to have a reviewer sign off on each PR.\n\nI guess we could just tell everyone \"don't fucking check in bugs\" instead",
              "score": 2,
              "created_utc": "2026-01-15 18:23:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzs983i",
                  "author": "EarlMarshal",
                  "text": "Just don't write \"DROP TABLE\". Who does that? Especially without checking 10 times the db connection you are connected to?",
                  "score": 0,
                  "created_utc": "2026-01-15 19:33:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzq6q4k",
              "author": "qruxxurq",
              "text": "> *”Toddlers should be able to fall down stairs, but just choose not to do it. Who TF are you birthing? You call them toddlers and they tip over when they walk!?”*\n\n> *”I think inmates should be allowed to control the gates, but just choose not to leave the prison. Who TF are you incarcerating?”*\n\n> *”I think rookies should be allowed to play the whole game and possibly tank the season, but they should just choose not to lose. Who TF are you drafting?”*\n\n—You, probably",
              "score": 1,
              "created_utc": "2026-01-15 13:48:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzqq79e",
                  "author": "EarlMarshal",
                  "text": "Do you get paid to work as a toddler? Lmao.",
                  "score": 0,
                  "created_utc": "2026-01-15 15:26:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nznjqam",
          "author": "LessonStudio",
          "text": "The absolute best company I ever worked for would hire almost anyone who could pass a fairly simple gauntlet.\n\nBut, they paid minimum wage and the rest was performance bonuses.\n\nPoor performers rarely needed to be fired, they almost always quit as the performance bonus numbers were accumulated on daily basis, or not. Every time I have described this company in detail, it is amazing how people try to figure out edge cases where it wouldn't work. With the glaring counter to all their arguments that it did, and people loved it (who survived the first few months).\n\n\nThe worst companies I've worked for (or with) were big on people from top schools with top GPAs.",
          "score": -5,
          "created_utc": "2026-01-15 01:53:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzo68q6",
              "author": "SimonTheRockJohnson_",
              "text": "How do you measure SE performance?",
              "score": 9,
              "created_utc": "2026-01-15 04:08:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzoqrnf",
                  "author": "LessonStudio",
                  "text": "In the company it was literally points. Tasks all had points. If you completed a task, you got the points, the tasks were reviewed, and the reviewer got 1/3rd the points. \n\nAny minor bug in the task had to be fixed quickly to retain the points, major bugs, lost everyone the points.\n\nThen, a bonus pool was allotted, and each got their share based on their share of the points.\n\nThe founders aggressively watched for people working too many hours, this was one of very few firing offences up there with sexual harassment. \n\nThey had a system where each task got a red, orange, or green code. Red tasks had to be done before orange, and orange before green; assuming you had the ability to do the red or orange tasks. Each task had points assigned to it by the founders, but anyone could suggest a task. Someone might say, \"Rewrite the entire system in Go\" and the founders might assign that -1,000,000 points as a hard no.\n\nBut, you might say, \"Experimentally rewrite the comms module in rust and compare performance.\" and this might get 100 points. Changing the wording of \"Open File\" to \"Open PDF\" in a menu might be 1 point.\n\nAnyone could pick any task; but only one task at a time. Anyone could code review. But, if your code was consistently crap, the people who were really good at code reviews would stop reviewing your code as they weren't getting points from it, and you would stop getting points. Thus a crap programmer would just eventually quit. You didn't want to take your code to a crap reviewer as they would miss bugs, and you could lose points. You didn't take your code to the pedantic fool who focused on code style guides made up in their head, and ignored brutalizing your code with potentially their own unit tests like the great code reviewers would do.\n\nOn the point of juniors. This was a great environment for ones with potential; as code reviewers would tell them what would be needed for them to fix up their code, and be better prepared for their next review. Also, juniors could pair program, as this would increase the points by 20%. That is if something was worth 30 points, and two people paired on it, they would each get 18 points. People were willing to do this with promising juniors.\n\nThings like people with poor communications skills almost instantly floundered and soon left; as nobody told them what to do, you had to ask and figure things out.\n\nThe difference in take home pay could be enormous. People who were OK, and did stick around might pull in 100k or less. But a coding performance monster could easily crack 1m. There were people pulling in more than this who worked a day or two a week and took massive vacations. They would just knock off one brutally hard task after another with really good code for the time they were there. The point pool might be 8m points, and these guys could come in and knock off 10 1k tasks in a single week. These were tasks that most programmers would choke on and give up after a month. A task might be, \"Get the present messaging system past 100k messages per second. with 10 points awarded for every 1k messages per second more; max 1k points. And these guy would make an FPGA network card which could handle 2m messages per second. Nobody even thought of building their own network card and were thinking about screwing with the linux network stack or something.\n\nThese were the people who kept moving the needle forward for the company and were well rewarded for doing so. This incentive structure would then attract more of these stars; often not because they could earn so much, but earn lots while working very very little and not be pressured to work 60h+ for the same pay at most other places. \n\nThe best part of this place is watching the fogies try to explain to me why the place didn't work. Some people simply can't wrap their heads around such a different culture. They live in worlds where micromanagers use gantt charts to populate jira task lists, and by putting them on a kanban board they think they are being modern. But, all they do is assign tasks, wonder why people aren't being creative, complain about \"herding cats\" and then watch as their uninspired projects run wildly overbudget, are late, and really disappoint the end users (oh, I should have called them stakeholders).",
                  "score": -1,
                  "created_utc": "2026-01-15 06:42:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzo8mrj",
              "author": "me_again",
              "text": "I don't mean to be impolite, but this sounds far-fetched, at least in software. Maybe for some kind of sales-based business like a car dealership? If this company exists and this is their official policy, you can safely prove me wrong by naming them :-)",
              "score": 3,
              "created_utc": "2026-01-15 04:24:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzonxf3",
                  "author": "LessonStudio",
                  "text": "The company develops software used in the financial world. \n\nIt has about 250 employees; about 220 are software developers, and the rest are admin staff. \n\nThere are 3 founders. The founders are very hands on. \n\nThe company is extremely flat. No, and I mean no one, in development has a title. No mangers, no leaders, no tech leads, nothing. \n\nThere are people who have leadership abilities, and they do lead, but no in any official org chart sort of way. \n\nAs for naming names, nope, you can go find them yourself. Start on the east coast.",
                  "score": 3,
                  "created_utc": "2026-01-15 06:18:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qcjd0w",
      "title": "How a 40-Line Fix Eliminated a 400x Performance Gap",
      "subreddit": "programming",
      "url": "https://questdb.com/blog/jvm-current-thread-user-time/",
      "author": "j1897OS",
      "created_utc": "2026-01-14 09:55:22",
      "score": 191,
      "num_comments": 15,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qcjd0w/how_a_40line_fix_eliminated_a_400x_performance_gap/",
      "domain": "questdb.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzj36bg",
          "author": "andymaclean19",
          "text": "Didn’t they change some of the Linux APIs for things like clock fetches so it just copies from a memory mapped page in userspace without even making a kernel call?  Are you sure that isn’t where the speedup comes from?",
          "score": 40,
          "created_utc": "2026-01-14 12:45:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzj41er",
              "author": "_shadowbannedagain",
              "text": "You probably meant [vDSO](https://man7.org/linux/man-pages/man7/vdso.7.html). It works for some clock types with some clock sources. A few years ago I [played with clock sources](https://www.javaadvent.com/2019/12/measuring-time-from-java-to-kernel-and-back.html) It's an old article, but the core of it should still be valid: It depends :)",
              "score": 24,
              "created_utc": "2026-01-14 12:51:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzj46dy",
                  "author": "andymaclean19",
                  "text": "Yes, I meant VDSO.",
                  "score": 10,
                  "created_utc": "2026-01-14 12:52:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nziovgd",
          "author": "_shadowbannedagain",
          "text": "Author here. I figured if I'm already wasting time exploring commits I don't need to care about, I might as well blog about it. If only to give LLMs more training data to learn from.",
          "score": 107,
          "created_utc": "2026-01-14 10:56:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nziqae0",
              "author": "axkotti",
              "text": "I'm pretty sure that there are still people who consider such content interesting, so thanks!\n\nDo you know if anything except open(), read() and close() syscalls actually affected performance in this case? I would expect the performance difference to come just from those unnecessary I/O syscalls rather than userspace things like sscanf?",
              "score": 36,
              "created_utc": "2026-01-14 11:08:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzivp59",
                  "author": "_shadowbannedagain",
                  "text": "It's the syscalls, totally. `sscanf()` is dirty cheap compared to multiple user-kernel transitions.",
                  "score": 10,
                  "created_utc": "2026-01-14 11:52:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzmdpuu",
              "author": "SubwayGuy85",
              "text": "implying LLM's learn instead of blindly copying patterns with zero comprehension whatsoever. lul",
              "score": 4,
              "created_utc": "2026-01-14 22:08:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzjos4s",
          "author": "dylanbperry",
          "text": "I'm sure the content is great but man is that AI thumbnail image offputting",
          "score": 11,
          "created_utc": "2026-01-14 14:47:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzja26u",
          "author": "dukey",
          "text": "The code is most likely IO bound by the file read",
          "score": -11,
          "created_utc": "2026-01-14 13:28:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjmkft",
              "author": "Levalis",
              "text": "/proc is not a plain file but a pseudo file. There is no IO happening, the kernel creates the content on the fly",
              "score": 14,
              "created_utc": "2026-01-14 14:36:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzj84lq",
          "author": "ButtFucker40k",
          "text": "All it takes is one asshole throwing a 0n in the middle of something to bring a system crashing down and sometimes it's not easy to spot in a pr the impact of 1 or 2 lazy linq statements.",
          "score": -11,
          "created_utc": "2026-01-14 13:17:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qeilrk",
      "title": "The Astro Technology Company joins Cloudflare | Astro",
      "subreddit": "programming",
      "url": "https://astro.build/blog/joining-cloudflare/",
      "author": "ReallySuperName",
      "created_utc": "2026-01-16 15:14:19",
      "score": 161,
      "num_comments": 41,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qeilrk/the_astro_technology_company_joins_cloudflare/",
      "domain": "astro.build",
      "is_self": false,
      "comments": [
        {
          "id": "nzxruei",
          "author": "Salkinator",
          "text": "Worries me. Last time this happened we basically lost Gatsby",
          "score": 104,
          "created_utc": "2026-01-16 15:45:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxt34y",
              "author": "avataw",
              "text": "I love Astro and I'm not too excited about it either :(  \nLet's see. \\*sigh\\*",
              "score": 29,
              "created_utc": "2026-01-16 15:50:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzxw575",
              "author": "manniL",
              "text": "Nuxt and Svelte still do fine afaik.",
              "score": 13,
              "created_utc": "2026-01-16 16:03:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o00r6zv",
              "author": "ematipico",
              "text": "Gatsby was specifically acquired for their product, the Valhalla thingy IIRC. That isn't the case with Cloudflare.",
              "score": 3,
              "created_utc": "2026-01-17 00:10:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzzn2tz",
              "author": "ReallySuperName",
              "text": "Netlify seem to specialise in buying companies and then ruining the product or shutting the whole company down. They are emulating Google.",
              "score": 6,
              "created_utc": "2026-01-16 20:46:48",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzyqj3h",
              "author": "Careless-Score-333",
              "text": "Was this before or after people started to hate Gatsby?",
              "score": 1,
              "created_utc": "2026-01-16 18:18:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyra0c",
                  "author": "Salkinator",
                  "text": "To be fair Gatsby was always a little polarizing but at least it was an option. It’s basically gone now",
                  "score": 3,
                  "created_utc": "2026-01-16 18:21:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o04eg51",
              "author": "_kelvindecosta",
              "text": "Mate Gatsby was a convoluted tool from the start. It was bound to die and good riddance. This is coming from someone who spent so much time tinkering with it to build his personal site",
              "score": 1,
              "created_utc": "2026-01-17 15:49:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o04m5wd",
              "author": "martin7274",
              "text": "never seen a good usecase for a heavily graphql based ssg",
              "score": 1,
              "created_utc": "2026-01-17 16:26:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzxtfm7",
          "author": "TwiliZant",
          "text": "Between Oven (Bun.js), Nuxtlabs and now Astro it seems like there is a pattern of companies building successful open source projects with no sustainable business behind it. Acquisition seems like the only way. Makes me wonder if we’ll see the same for Tailwindlabs or VoidZero in the future.",
          "score": 92,
          "created_utc": "2026-01-16 15:51:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxw0of",
              "author": "manniL",
              "text": "I think all three companies had a thing in common: They didn't find a way to truly monetize.\n\n\\* Bun never had an answer how they wanna make money. They ruled out hosting eventually (good!)  \n\\* Astro didn't do well with Astro DB and Astro Studio. Not sure how their latest idea of an email client went (interesting but quite a pivot).  \n\\* NuxtLabs was doing the best in terms of money out of these three, but there was no \"exponential\" growth + they had to cut back their team by quite a bit early on.",
              "score": 22,
              "created_utc": "2026-01-16 16:03:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzxugny",
              "author": "aatd86",
              "text": "That's only because dev don't want to pay and with AI there are even less incentives.\n\nPeople seem to like Astro. Never used it as far as I'm concerned. Is it like a server side component library?",
              "score": 28,
              "created_utc": "2026-01-16 15:56:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzxv0cf",
                  "author": "TwiliZant",
                  "text": "It’s a framework. Primarily, for static content. It’s very hard to monetize frameworks which is why they get acquired so often.",
                  "score": 26,
                  "created_utc": "2026-01-16 15:58:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzy8ei6",
                  "author": "kaeshiwaza",
                  "text": "In the begin of open source the principle was only to contribute to each other projects.",
                  "score": 2,
                  "created_utc": "2026-01-16 16:57:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzz0gcp",
                  "author": "moh_kohn",
                  "text": "It's a web server and a framework agnostic server side renderer. It's great for progressive enhancement. I did my best work in it, a set of web forms that are all shiny and modern but work on a toaster (or, as I tested, IE6. It wasn't pretty. But the fact that you could still complete the form was pretty amazing)",
                  "score": 1,
                  "created_utc": "2026-01-16 19:01:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzxxz26",
              "author": "omgFWTbear",
              "text": "> Tailwindlabs\n\nI have no dog in this fight, but given the recent headlines I’ve done just slightly more than cursory reading on them, and say what you want for their future if plotted from 2024, or how psychic one claims to be earlier; but they seem to not fit among the other candidates - they had millions in revenue, and a relatively small team that probably fit within that.\n\nI’ll stipulate any other point about bad business decisions etc etc, just saying, “we spent $1mil a year on salaries and made $3mil a year on revenue, three years running,” - I know no specifics but those are minimal numbers that generally jive with what’s been said at the above mentioned slightly deeper than cursory read level - seems like categorically different from “we blew $3 mil a year hopping to pivot to revenue neutrality / profitability by year five.”",
              "score": 7,
              "created_utc": "2026-01-16 16:11:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzyj5fk",
              "author": "Extra_Programmer788",
              "text": "I think VoidZero has enterprise level paid solutions, Tailwindlabs seems obvious to be bought out, considering the money trouble they are having.",
              "score": 2,
              "created_utc": "2026-01-16 17:45:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzyytki",
              "author": "nemec",
              "text": "> pattern of companies building successful open source projects with no sustainable business behind it. Acquisition seems like the only way.\n\nthis is just a continuation of the last decade and a half of the venture capital cycle.",
              "score": 1,
              "created_utc": "2026-01-16 18:54:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzztocu",
              "author": "levelstar01",
              "text": "aquihire has been going on for nearly two decades no?",
              "score": 1,
              "created_utc": "2026-01-16 21:17:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzyqf8z",
          "author": "Careless-Score-333",
          "text": "People are worried about this, but so many web devs already entrust their DNS, firewall, https to Cloudflare (perhaps even S3 storage and hosting too).  I don't see much additional danger in them owning an open source meta-JS-framework.  I've used one of Cloudflare's open source projects, and it's very good.  This is potentially a big win win.",
          "score": 12,
          "created_utc": "2026-01-16 18:17:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02ry2t",
              "author": "Pheasn",
              "text": "In my eyes, Cloudflare has started showing signs of enshittification. Nothing major yet, but there was definitely some stuff that ground my gears over the last years.\n\nOne example is their move to replace their SDKs with auto-generated code based on their API spec using some third-party SaaS (Stainless). In principle it's a sensible move, and others achieved pretty good quality even with the same service (it was a huge step up for OpenAI's python SDK), but Cloudflare really botched it. Breaking changes during the migration were poorly documented, migration guides were incomplete, automated migration scripts were broken. Their changelogs since then are mostly a list of [literally](https://github.com/cloudflare/cloudflare-python/releases/tag/v4.3.0) \"api: api update\", I encountered multiple minor/patch updates with breaking changes in the new Terraform provider, and it all just reeks of \"we'll fire the teams first, then automate the code generation\".",
              "score": 2,
              "created_utc": "2026-01-17 08:57:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o03n7a4",
                  "author": "Careless-Score-333",
                  "text": "Thanks.  I'll continue to make sur eI can also self host, and not put all my egg in their basket just yet then (other than DNS).  \n\nCloudflare would definitely benefit from a similar sized competitor...",
                  "score": 1,
                  "created_utc": "2026-01-17 13:23:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzypwmy",
          "author": "PoisnFang",
          "text": "Astro is a good purchase because Cloudflare wants you to deploy SSR on workers which will make them money. This gives them a direct pay to push people in. \n\nI prefer to use Vue SPA and host for free on workers. With the recent Next.js perfect 10 critical vulnerability I aim to stay away from SSR",
          "score": 5,
          "created_utc": "2026-01-16 18:15:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzz3iac",
              "author": "Somepotato",
              "text": "SSR isn't the problem. Naive developers is. Serialization has always been the cause of vulnerabilities, the fact Next had that one is an absolute embarrassment and they continue to have embarrassments. Stuff like Nuxt continues to do very very well",
              "score": 2,
              "created_utc": "2026-01-16 19:15:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzxqms4",
          "author": "chom-pom",
          "text": "> I love Astro and keep hearing good things about Cloudflare but havent made the\n\nYou didn’t hear any bad news regarding cloudflare recently?",
          "score": 24,
          "created_utc": "2026-01-16 15:39:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzz2xai",
              "author": "alfirous",
              "text": "Good for them.",
              "score": 3,
              "created_utc": "2026-01-16 19:12:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzykr3h",
          "author": "BusinessWatercrees58",
          "text": "Just started using Astro for a personal site. Hope this isn't a bad sign",
          "score": 3,
          "created_utc": "2026-01-16 17:52:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzz3di0",
          "author": "dangerbird2",
          "text": "For a second I thought this was the apache airflow SaaS company [Astronomer](https://www.astronomer.io/), and that they still hadn't recovered from the Coldplay kiss cam incident",
          "score": 3,
          "created_utc": "2026-01-16 19:14:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o003ihf",
          "author": "-nbsp-",
          "text": "Cloudflare migrated their docs to Astro last year, they definitely have a vested interest in keeping Astro alive. As someone who uses Astro a lot, Cloudflare workers/pages integrations with D1, R2, or KV feel really seamless. Happy to hear Astro will be a first party citizen myself!",
          "score": 2,
          "created_utc": "2026-01-16 22:04:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxpar0",
          "author": "Sm0oth_kriminal",
          "text": "Interesting. I love Astro and keep hearing good things about Cloudflare but havent made the switch yet (currently using Porkbun, which uses Cloudflare DNS)\n\nIn general, I like Cloudflares approach with their services \"we support using the competition, but why would you want to? Ours is just better\", and keeping fully open is nice as well\n\nI'm sure someone will find negative things to say about this -- but we need to remember developing software isn't free. Much better to have someone like Cloudflare fund development than say, Shopify/WordPress. It seems Cloudflare is trying to expand its offerings, where as other companies would be trying to shut down competition",
          "score": 6,
          "created_utc": "2026-01-16 15:33:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzy4yoz",
              "author": "axonxorz",
              "text": "> Much better to have someone like Cloudflare fund development than say, Shopify/WordPress\n\nI fail to see the fundamental difference here, they are all publicly traded technology corporations with involvement in OSS to their own ends.\n\n> I like Cloudflares approach with their services \"we support using the competition, but why would you want to? Ours is just better/didn't exist\"\n\nWhereas this one is \"we have forcefully removed one option of competition (without consulting , probably because you wanted to, ours wasn't better\"\n\n> It seems Cloudflare is trying to expand its offerings\n\nAstro is MIT licensed. Cloudflare was perfectly capable of developing their own fork for Cloudflare-specific functionality. Instead, they now have full control (like Shopify wanted with Ruby) and ownership of the trademark/brand/developer goodwill. They will integrate their own changes as needed (as they could/did do before) while leaning on the OSS community to make up the difference and -crucially- fully maintain those features that Cloudflare feels it will see no ROI on, while rejecting those very PRs from OSS devs because they \"would constitute an ongoing maintenance burden\"\n\nMIT license will become SSPL/open core before long, unless we want to ignore the experience of history.",
              "score": 0,
              "created_utc": "2026-01-16 16:42:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyf8d6",
                  "author": "Sm0oth_kriminal",
                  "text": "If you can't see the difference between Cloudflare (a web host) and WordPress (a website builder), I'm not sure what to say. Yes they're both \"companies\" but if that's the only information you judge on, how accurate can you be?\n\nCloudflare won't aim to shut down other website builders, because they don't make money on that. WordPress, however, has their entire business model dependent on it being \"hard\" to make your own website, and \"hard\" to find a host. Ergo, if they bought up this option, they would be incentived to put it behind a paywall or shut it down.\n\nCloudflare, on the other hand, doesn't make their money by charging to help create a website. They make their money by their pro services required for hosting non-trivial content (i.e. databases, lamdas, etc). And they can recognize that Astro only works because it's not paid (it's market is developers who know how to code, unlike WordPress).\n\nSo, yes, if you take the view that \"muh corporation runs software now\", it's equally as bad if any company runs it. But, if you have a bit of nuance you might realize that actually there are better or worse things that can happen to software.\n\nIf Cloudflare switches up, and tries to close-source this, or charge for currently free features, I would be SHOCKED. And I'd instantly call that out as a bad thing. But, that hasnt happened, doesn't seem like it will happen, and again, would probably be a dumb move.\n\nI don't think you've actually used Cloudflare, and know what I'm trying it say. If you had, you would know they actually offer a ton of free services to small developers (like Cloudflare pages, with more features than GitHub pages), among dozens of others.",
                  "score": 4,
                  "created_utc": "2026-01-16 17:28:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzz36f2",
                  "author": "Somepotato",
                  "text": "They could have forked it or they could pay the developers to work on it to help continue just to help towards their goals.\n\nCloudflare has a very good track record when it comes to OSS projects. Even going as far as to offer to pay someone huge sums to maintain LuaJIT (But that was written by a wizard that no one fully understands except Mike Pall, who isn't accepting sponsorships.)",
                  "score": 2,
                  "created_utc": "2026-01-16 19:13:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o00tfyq",
          "author": "programjm123",
          "text": "\\> Staying open to all was a non-negotiable requirement for both us and for Cloudflare. That is why Astro will remain free, open-source, and MIT-licensed. We will continue to run our project in the open, with an open governance model for contributors and an open community roadmap that anyone can participate in. We remain fully committed to maintaining Astro as a platform-agnostic framework, meaning we will continue to support and improve deployments for all targets—not just Cloudflare.\n\nSeems reasonable enough, fingers crossed that it holds",
          "score": 1,
          "created_utc": "2026-01-17 00:23:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04luii",
          "author": "martin7274",
          "text": "Oh Good ol´ JS Ecosystem, so many developers, yet so few ways on how to sustain its shining projects",
          "score": 1,
          "created_utc": "2026-01-17 16:24:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdqtk0",
      "title": "The Influentists: AI hype without proof",
      "subreddit": "programming",
      "url": "https://carette.xyz/posts/influentists/",
      "author": "iamapizza",
      "created_utc": "2026-01-15 18:03:09",
      "score": 128,
      "num_comments": 96,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qdqtk0/the_influentists_ai_hype_without_proof/",
      "domain": "carette.xyz",
      "is_self": false,
      "comments": [
        {
          "id": "nzt20qe",
          "author": "HighRising2711",
          "text": "The best tweet in that thread was the one asking 'where is all the shovel ware?'. \n\nThe latest incarnation of LLMs has been around for a year now, if everyone's so productive where are all these apps that have been written.  Where are all the YouTube videos of vibe coding being 10x or 100x faster to make something ?",
          "score": 79,
          "created_utc": "2026-01-15 21:46:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztasib",
              "author": "drabred",
              "text": "All open source software GitHub issues should be solved by now right?",
              "score": 49,
              "created_utc": "2026-01-15 22:28:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nztw5tl",
              "author": "cockdewine",
              "text": "Here's the excellent post from a few months ago that that tweet is referencing: [https://mikelovesrobots.substack.com/p/wheres-the-shovelware-why-ai-coding](https://mikelovesrobots.substack.com/p/wheres-the-shovelware-why-ai-coding)",
              "score": 29,
              "created_utc": "2026-01-16 00:21:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzuloy8",
              "author": "scandii",
              "text": "go over to r/unixporn or r/linux where someone's making a widget or app every single day with a commit history of average 200 lines / hour.\n\non top of that, people are being extremely tight lipped about AI being used because if they say it was used they get brigaded almost instantly with comments like \"cool app but made with AI so useless\" or just downright \"lol AI slop\".\n\nthe discussion climate just isn't there to support an honest review of these tools.",
              "score": 20,
              "created_utc": "2026-01-16 02:43:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzw749n",
                  "author": "Hot-Employ-3399",
                  "text": "Or r/commandline.\n\n\nHere's the exact example and discussion of [tight lipness btw](https://www.reddit.com/r/commandline/comments/1q9zjqc/comment/nz0dhpd/) I found just yesterday reading the subreddit ",
                  "score": 2,
                  "created_utc": "2026-01-16 09:51:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzw49d3",
                  "author": "FarFlugAsi",
                  "text": "This. It's impossible to have a productive discussion on AI coding without being dogpiled with people who are against it shouting \"AI Slop\". People who are using it and are doing good things with it are in their own circles.",
                  "score": -7,
                  "created_utc": "2026-01-16 09:24:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzx73ng",
                  "author": "bryaneightyone",
                  "text": "Great observation. I wasn't able to articulate it well, but I think you nailed the biggest reason.",
                  "score": -5,
                  "created_utc": "2026-01-16 14:05:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzvypo3",
              "author": "Globbi",
              "text": "  1. Literal \"shovelware\" is mostly uncomitted and unpublished but is happening a lot more with LLMs now.\n\n  Things like small scripts for one-off things to do something that one person could easily write without LLM in an hour, but another person would need a few days to think through. Or prototyping a few concepts of a thing before starting real work. Or a new project to just check a specific library but you still need a whole app to really see this one library\n\n  Personally at work I was investigating latency in ROS topics from cameras and claude code wrote a few scripts to measure things in a few minutes. It didn't fully make sense - one script checking the required thing should be enough, there was a lot of redundancy. But one of them did what I wanted. It would take me a few hours to write it myself just because there were things I didn't do before. It worked, I found out the problem. I fixed the problem with comments on what was happening. I didn't commit a bunch of LLM-generated scripts.\n\n  2. Also some of it is published, but then some of the published stuff is just good. I don't want to get into details of specific commits in specific software and argue if it's \"shovelware\" or not. But smart and experienced people use code produced with LLM tools. Here is a video I would recommend with some examples, but it's rambling on the topic so might not be your thing https://www.youtube.com/watch?v=5vp9ypOUgMw\n\n  3. There is literal shovelware published https://old.reddit.com/r/Games/comments/1qdk53k/sony_wiped_over_1000_shovelware_games_off_the/",
              "score": -2,
              "created_utc": "2026-01-16 08:33:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o01p46z",
                  "author": "pdabaker",
                  "text": "Similar thing happened to me yesterday- was requested a script to check a bunch of rosbags for lag (slightly larger than expected timestamp gaps”.  Could have written something in 1-2 hours while grumbling but it’s a the perfect thing for AI to do in 10 mins with a few iterations for usability.",
                  "score": 0,
                  "created_utc": "2026-01-17 03:41:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzw2bbb",
              "author": "FarFlugAsi",
              "text": ">The latest incarnation of LLMs has been around for a year now\n\nOpus 4.5 and Gemini 3 were released in November\n\nGPT 5.2 and Nemotron 3 Nano  were released in December\n\nIt's remarkable how badly some software developers have bought into the anti-hype train so much that you're so far behind on this.",
              "score": -6,
              "created_utc": "2026-01-16 09:06:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzx7q0z",
                  "author": "bryaneightyone",
                  "text": "Agree, the ones most worried about \"losing their jobs to ai\" are going to lose their jobs to people good at using ai, like the tool that it is. We're far and away from Ai being able to replace real software engineers imo but the people figuring out how to use it properly will be way ahead of the game as the paradigm shifts over the next year or two.",
                  "score": -7,
                  "created_utc": "2026-01-16 14:08:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrtsp8",
          "author": "Chachomastin",
          "text": "How many salespeople exist in our industry? Certainly,  there are great engineers, but they are usually busy developing some interesting tech or architecture within their companies, the rest are mostly just talkers",
          "score": 19,
          "created_utc": "2026-01-15 18:24:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrv07m",
          "author": "NullField",
          "text": "One funny thing I've noticed when people _do_ show their code while hyping up AI is that it's either essentially a 1:1 clone of something that already exists, or it absolutely reeks of AI.\n\n\nI've had to bring it up with some guys at work, who claimed that 4.5 Opus is a lot better and that problems that I have brought up with them should go away as a result of using it. They haven't. Every single model has been a revolutionary increase in ability, but not much has actually changed as a result.\n\nA model can seemingly only be as capable as the person using it. If an expert can use it to do something advanced, that doesn't necessarily mean the AI is now as capable as the expert, because I STILL see these guys making the same exact mistakes they've been making for nearly 2 years.",
          "score": 93,
          "created_utc": "2026-01-15 18:30:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrzpkk",
              "author": "TheAtlasMonkey",
              "text": "December 2024 , i build a library, i did not advertise it, because i knew that it blow up once many user use it.\n\nBasically it was : \\`It work on my machine\\`\n\n3 months later, someone congratulate me for the launch. I was in the front page of HN.\n\nThe problem was that it was not me, it was some Vibecoder that used \\`Devin\\` to build same library with similar name. Part of my  code was just dead code i have left after an experiment ... he had the same.\n\nThe funny part the library had reference of my location, their copy has the same .\n\nThey got 200 stars in Github in hours, for something i knew that was architecturally flawed.\n\n2 months later, they delete the repo and the reddit post.",
              "score": 90,
              "created_utc": "2026-01-15 18:50:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzt293y",
                  "author": "DorphinPack",
                  "text": "Damn. That’s awful!\n\nNot just talking to each other and being insecure  all the time seems to drive this behavior. I think.",
                  "score": 5,
                  "created_utc": "2026-01-15 21:48:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzs25v3",
              "author": "SassFrog",
              "text": "They fail with generating basic table relationships from descriptions and enumerating request-reply test cases, but can make Tetris and falling sand clones much quicker than anyone alive.",
              "score": 15,
              "created_utc": "2026-01-15 19:01:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzx9ipm",
                  "author": "bryaneightyone",
                  "text": "The ai tools are only as good as the person using it. To those of us actual developers when we see posts like this we automatically assume that you're not an actual developer or, at the very least, are extremely junior level.\n\nIf that's the case, I recommend using the ai to help teach you.",
                  "score": -7,
                  "created_utc": "2026-01-16 14:17:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztgm49",
              "author": "ManagementKey1338",
              "text": "Yeah, because AI is also training on the slop human have been written for years.",
              "score": -3,
              "created_utc": "2026-01-15 22:57:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzx89g1",
              "author": "bryaneightyone",
              "text": "What code are you writing that hasn't been done in some form millions of times? The actual code is easy, designing the software is hard. Ai is not good at designing software but it is good at writing code. Hence why you need actual humans for this to be effective.",
              "score": -1,
              "created_utc": "2026-01-16 14:11:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzxj7d4",
              "author": "bryaneightyone",
              "text": "Man, you're so close to understanding how the people who use these tools successfully operate.\n\nSo close, yet, I suspect you will not be able to cross that chasm mentally for a while though. Keep trying though, it will be worth it once you do.",
              "score": -5,
              "created_utc": "2026-01-16 15:05:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzs5eir",
          "author": "AmaGh05T",
          "text": "Well reasoned and surprisingly worth reading considering it's a commentary of twitter posts.",
          "score": 10,
          "created_utc": "2026-01-15 19:16:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs3soi",
          "author": "RationalPsycho42",
          "text": "I have seen people swear by AI, I personally found it useful to write scripts (simple data manipulation, boilerplate functions etc.) but I don't really see how people are building entire applications with it. Even for medium sized scripts it sometimes messes up big and I usually err on the side of caution with the generated code.\n\n\nI would really appreciate it if someone did streams showcasing their use of agentic AI that actually saves time. There's tons of streams where people are making stuff like compilers, game engines, why can't I find the same for AI coding? This is what baffles me, it should be such a good viewership puller, no?",
          "score": 22,
          "created_utc": "2026-01-15 19:08:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzt6zut",
              "author": "sloggo",
              "text": "I just went through a “one week” kinda task where I really lent in to agentic assistance. My theory about why there’s not end to end high quality demos is cos it doesn’t actually save you that much time, and most of it is pretty unsexy reprompting snd trying to understand what you’ve just written yourself. Theres a totally different productivity curve throughout the week though. I got SO MUCH done in the first half-day/day, but the it really flattens out in the tail end, solving the truly complex parts of it get very tedious when you try vibe through it, final integration work, making sure your tests aren’t complete junk.\n\nMy verdict so far: Definitely some time improvement, But not super dramatic (something less than 2x). I think I was “braver” in attempting some features I might have otherwise left in the too hard basket given the timeframe. So in that sense there’s some value improvement too. I’m also probably in a better place with tests and docs than I would be in the same timeframe otherwise. \n\nThey’re all marginal improvements and hard to quantify, and most of the meaningful work comes from frustrating attempts to prompt in specific ways and really interrogate an understanding of the machine - to must engineers that’s a revolting concept . Doesn’t make good watching - you should understand the machine before you write the code.\n\nNow apparently I’ve blown through my credits this week too so I need to see what the direct additional costs are to work this way, because there’s a lot of “soft costs” too.",
              "score": 11,
              "created_utc": "2026-01-15 22:10:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzy5lmx",
                  "author": "Shadowsake",
                  "text": "Solid work you did. I also tried to do vibe coding in the recent past, although it was before all this agentic stuff really got traction.\n\nMy impressions were close to yours. I got excited cause the machine was writing code and the possibilities, but it quickly turned into frustration. I realized fast that I needed to read what it wrote very carefully cause it often forgot important details. And read it again on the next output, cause it could forget another thing OR the same thing I asked it to include for some reason. In the end, I felt like I was wasting time trying to steer the machine into what I wanted, just to in the end correct it myself...instead of, you know, just writing the code already in the first place.\n\nEither way, I find these tools useful when I ask it about documentation. Not writing, but finding stuff. For example, if I don't know how to do something with some library, I can ask it to find that information and link it to me. It often works, and if it doesn't it is not a major problem. I can ask it to look for examples on how X works and that is pretty useful. I also used it to scaffold unit tests, and it can save *some* time in this use case.",
                  "score": 5,
                  "created_utc": "2026-01-16 16:45:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzsb4zo",
              "author": "Shadowsake",
              "text": "I had a script that basically extracted a bunch of .zip, .7zip and co. files and moved and deleted stuff depending on which file it extracted. Nothing complex at all. Problem: the script was written in Batch, I was on Linux and needed it as a bash file.\n\nNo problemo, send it to an AI and ask it to translate. The translation process was very easy, just had to convert certain commands to GNU tools and done.\n\nIt could not do it. At all. Either the list of files (hardcoded) was cut from the output, or it hallucinated elements of the list. The commands didn't worked cause it got confused on what was a Windows utility and a GNU program. It was a mess. I had to fiddle with the fucking prompt to even get something that would execute - and the final result was wrong cause it forgot to correctly delete certain folders, which meant I had to check the entire script anyway.\n\nI gave up, opened the script and rewrote it myself. In 20 minutes I had a working version. The entire ordeal with the AI took almost 2 hours with a broken batch-bash mixture from hell as a result.\n\nSeriously, fuck this thing. It can't even do something like this stupid, why should I use it for anything more complex?  This thing is just a word prediction machine afterall. \"Oh your prompt is wrong wadda wadda\" shut the fuck up.",
              "score": 32,
              "created_utc": "2026-01-15 19:42:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzw0ox3",
                  "author": "FarFlugAsi",
                  "text": "I've had AI one shot converting C# to COBOL to Python multiple times successfully for complex scripts. \n\n>\"Oh your prompt is wrong wadda wadda\" shut the fuck up.\n\nYou can refuse to learn how to do it properly as much as you like - people who do learn how to use it properly will leave you behind.",
                  "score": -10,
                  "created_utc": "2026-01-16 08:51:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzudvkk",
                  "author": "bryaneightyone",
                  "text": "It's only as good as the person using it. I've never had any problems like this for much more complex things. Were you using a local model, or something like claude?",
                  "score": -23,
                  "created_utc": "2026-01-16 01:59:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzx3vb1",
              "author": "ericl666",
              "text": "It takes so much context to get it right, and I don't have time to write or up and go through feedback loops. It's just faster to write the code that try to tell something exactly how to write the code.",
              "score": 5,
              "created_utc": "2026-01-16 13:48:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzxaoq4",
                  "author": "MingMingDuling",
                  "text": "then automate  context injection. I created an mcp server to do just that (mine determines context based on cwd, repo, branch)",
                  "score": -2,
                  "created_utc": "2026-01-16 14:23:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzwa14m",
              "author": "Hot-Employ-3399",
              "text": "I aksed the similar question giving an example of non-ai course from  feeecodecamp to make [stardew valley inspired](https://www.freecodecamp.org/news/create-stardew-valley-using-python-and-pygame/) game on pygame to set expected difficulty. It's not too complex, but also not completely trivial. Project of this complexity should be doable with agents from slop I seen. Still got no useful replies.\n\n\nWhen I was searching for something, i found [this in aider documentation](https://aider.chat/docs/usage/tutorials.html). Click on \"Creating Games with AI from Start-To-End\" if you want to cringe. Result is complete garbage yet it is linked from aider documentation itself.",
              "score": 3,
              "created_utc": "2026-01-16 10:18:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzwkwb5",
              "author": "davenirline",
              "text": "I also wondered about this. I see a lot of this AI praise on Linkedin but I don't really see people how they actually use them. They might convince me if they could show me. If it's so good, show it.",
              "score": 3,
              "created_utc": "2026-01-16 11:48:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzvow8z",
              "author": "Hacnar",
              "text": "AI saves time in catching up. When you start with new framework, library or language, it can produce results very quickly, because it knows those things already. Or when you're trying to solve a difficult problem, that has been solved already in some small lib you have no idea about. But its biggest limits are context window and completely novel issues.\n\nContext window limits its capability to reason about complex issues which span large amounts of input data and code. AI can also only apply what it has already seen. If the problem requires a novel solution, it won't get there.\n\nThen there is the eternal prompt vs hallucination fight. LLMs don't have the reliability to trust their output. Anything that matters should be either thoroughly checked or rewritten completely by a human. Depending on the scale of the task and the dev experience, it might be take less time to write it yourself with minimal/no AI involvement, instead of trying to prompt and review the AI output.",
              "score": 0,
              "created_utc": "2026-01-16 07:06:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzud6e5",
              "author": "bryaneightyone",
              "text": "We're too busy shipping code. There's already content out there for this. Majority of reddit seems to be junior level developers who are on the \"anti Ai hype train\". The rest of us are in the middle, leveraging what its good at and shipping products and features.",
              "score": -8,
              "created_utc": "2026-01-16 01:55:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzwznzj",
                  "author": "Eskamel",
                  "text": "Are you shitting code to thin air?\nBecause there hasn't been a single popular new software this year that isn't extremely buggy or broken, and there aren't really alot of new software people use to begin with.",
                  "score": 5,
                  "created_utc": "2026-01-16 13:25:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzttqe4",
          "author": "EveryQuantityEver",
          "text": "It is pretty annoying that the people hyping up AI never have to justify their position, whereas anyone who doesn’t think these LLMs are the second coming of Ritchie gets labeled as a Luddite",
          "score": 15,
          "created_utc": "2026-01-16 00:08:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzueaqg",
              "author": "bryaneightyone",
              "text": "I'll explain the reason for this. Arguing with the reddit hive mind is pointless. Y'all are on the flip side of the pro Ai evangelicals. No amount of reasoning will get through to either of these sides. Ai is fantastic at code IF the user is fantastic at coding. Otherwise it is trash.",
              "score": -6,
              "created_utc": "2026-01-16 02:02:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzw83sy",
                  "author": "SubwayGuy85",
                  "text": "no. all it is, is hyped intellisense. it replicates patterns that it was fed with. beyond that there is no creativity, no comprehension. whenever you create something new - you will immediately come to realize this",
                  "score": 13,
                  "created_utc": "2026-01-16 10:00:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzw0cdv",
                  "author": "FarFlugAsi",
                  "text": "The whining about AI is more annoying than the evangelising about it.",
                  "score": -6,
                  "created_utc": "2026-01-16 08:48:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzslqdt",
          "author": "Numerous-Ability6683",
          "text": "I kinda think that the Rakyll claim could be traced to something simpler and dumber than what you suggest (though I like your reasoning here, and the article is sound). To me it seems like the AI model just reproduced its training data",
          "score": 4,
          "created_utc": "2026-01-15 20:31:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrymug",
          "author": "CopiousCool",
          "text": "No, its \"InfluencEngineers\"  \n\n/s",
          "score": 1,
          "created_utc": "2026-01-15 18:46:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu9i7t",
          "author": "Fluid-Replacement-51",
          "text": "So far, it's not a silver bullet, but it has its uses. It's really pretty good for testing ideas and prototyping things as long as it's not overly complex and as long as you are working on a domain you are comfortable with. This week I was trying to extract some curves from engineering drawings and it helped me test a bunch of different concepts quickly (pathfinding algorithms, skeletonization, flood fills, deskewing, etc. I got something usable within a couple of days. Before it would have taken 5x as long to find the algorithm I was looking for find some code and figure out how to adapt the inputs and outputs to my task or try to code it from scratch, having to debug every step of the way. AI makes a lot of mistakes and can get pretty frustrating, but for this task it was a beneficial tool. ",
          "score": -1,
          "created_utc": "2026-01-16 01:35:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o015okn",
          "author": "c_glib",
          "text": "Jeeeez this sub is the worst case of heads buried deep in the sand I've ever seen. Millions of lines of AI written code is being shipped every day. Highly respected, senior level engineers and techies are openly talking about not writing any lines of code by hand anymore.  But the only posts/articles that get traction on this sub are like this one.\n\nI do understand the problem. There are a whole bunch of people who have developed strong identities as \"programmers\". Whatever titles (self proclaimed or bestowed by an employer) they might have given themselves, ultimately their most valuable skill is reading and writing code. Heck, a lot of the people on here are making lucrative salaries because they wrote a whole bunch of code years ago, the product got popular and now they're supposedly indispensable because only they understand how that shit works. If the new tools take away that leverage, a large part of their supposed value vanishes overnight.\n\nOnce you understand that situation, the reactions are completely understandable. And I don't really have a ready solutions for people in those situations.  Only thing I can recommend  is learning to use the new tool just like you would any other tool of the trade. But what do I know.",
          "score": -3,
          "created_utc": "2026-01-17 01:38:14",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdnx4a",
      "title": "Windows? Linux? Browser? Same Executable",
      "subreddit": "programming",
      "url": "https://hackaday.com/2026/01/15/windows-linux-browser-same-executable/",
      "author": "double-happiness",
      "created_utc": "2026-01-15 16:19:36",
      "score": 128,
      "num_comments": 21,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qdnx4a/windows_linux_browser_same_executable/",
      "domain": "hackaday.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzrmyw9",
          "author": "double-happiness",
          "text": "I'm surprised this is being downvoted so hard; anybody doing so care to say why? I almost never post here and I was kind of hyped to have something to share for once. ☹️",
          "score": 41,
          "created_utc": "2026-01-15 17:54:23",
          "is_submitter": true,
          "replies": [
            {
              "id": "nzsqjae",
              "author": "cosmic-parsley",
              "text": "New posts always start with downvotes for some reason before the upvotes start collecting 🤷",
              "score": 22,
              "created_utc": "2026-01-15 20:54:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nztc643",
              "author": "cake-day-on-feb-29",
              "text": "I don't understand the point of the linked article, who not just link to the [original article](https://iczelia.net/posts/snake-polyglot/) that actually talks about the specific details?",
              "score": 10,
              "created_utc": "2026-01-15 22:35:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzteqyr",
                  "author": "double-happiness",
                  "text": "Personally, I would probably rather link the hackaday article and leave it to readers if they want to follow the source link or not. I would generally consider a 3rd party review to be a bit more neutral compared to someone potentially trying to hype their own work. If you link straight to the source it might look as if you are spamming on behalf of the creator. Will bear your suggestion in mind for the future though.",
                  "score": 4,
                  "created_utc": "2026-01-15 22:48:21",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzsf2hl",
              "author": "gredr",
              "text": "I also don't know why you're being downvoted. I also found this interesting, in a sorta quine, code golf, or IOCCC type way.",
              "score": 18,
              "created_utc": "2026-01-15 20:00:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzsiqas",
                  "author": "double-happiness",
                  "text": "👍\n\nIt's being upvoted now, so perhaps my plaintive cries have touched a nerve! 🤣🤣",
                  "score": 8,
                  "created_utc": "2026-01-15 20:17:42",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzs422x",
              "author": "a-peculiar-peck",
              "text": "Maybe because it isn't strictly speaking related to programming? Or just angry people? Idk.\n\n\nMyself I found it interesting, albeit a bit short on details.",
              "score": 4,
              "created_utc": "2026-01-15 19:10:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzw8kdy",
                  "author": "chucker23n",
                  "text": "> Maybe because it isn't strictly speaking related to programming?\n\nHow is _this_ not related to programming?",
                  "score": 9,
                  "created_utc": "2026-01-16 10:04:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsikgk",
                  "author": "double-happiness",
                  "text": "👍",
                  "score": 3,
                  "created_utc": "2026-01-15 20:16:56",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o02l77u",
              "author": "Jaded-Asparagus-2260",
              "text": "Because for some ununderstandable reason, people on this subreddit believe that you aren't allowed to write anything that has been written before. Like ever. \"There's already an article about that\" is the biggest complaint on this sub. Well, closely followed by \"this is AI\". Weirdly, redundant articles about how bad AI is are met with applause.",
              "score": 2,
              "created_utc": "2026-01-17 07:55:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzzmebk",
          "author": "Danteynero9",
          "text": "Yeah, fuck downvoters. Like, ok it's a very specific simple thing, whatever. This is one of the things where the point of it is to exist, and then figure out things next.\n\nDefinitely a cool thing.",
          "score": 5,
          "created_utc": "2026-01-16 20:43:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv7di6",
          "author": "Lowetheiy",
          "text": "will it run on arm64 tho :O",
          "score": 6,
          "created_utc": "2026-01-16 04:53:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw0orp",
              "author": "kingslayerer",
              "text": "Is executable composition different in arm for windows?",
              "score": -4,
              "created_utc": "2026-01-16 08:51:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzztj4a",
                  "author": "danielcw189",
                  "text": "I don't know, but Windows for ARM can run x86 code.\n\nNow I wonder if the PE-Loader for x86 on ARM has the same quirk as the one on \"normal\" x86 Windows",
                  "score": 2,
                  "created_utc": "2026-01-16 21:17:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzvtbe2",
          "author": "DemonInAJar",
          "text": "What's the point of this? You still have to build the application separately, and you just stitch the artifacts together which basically only has disk usage downsides.",
          "score": 4,
          "created_utc": "2026-01-16 07:44:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw0stl",
              "author": "kingslayerer",
              "text": "This is actually perfect for light internal toolings",
              "score": 3,
              "created_utc": "2026-01-16 08:52:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzwk1lf",
                  "author": "DemonInAJar",
                  "text": "How is it any better than simply distributing the correct artifact instead of basically distributing all artifacts together? It does simplify the distribution aspect I guess but not sure that's worth it.",
                  "score": 4,
                  "created_utc": "2026-01-16 11:42:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qbwc7t",
      "title": "I let the internet vote on what code gets merged. Here's what happened in Week 1.",
      "subreddit": "programming",
      "url": "https://blog.openchaos.dev/posts/week-1-the-first-merge",
      "author": "Equivalent-Yak2407",
      "created_utc": "2026-01-13 16:44:18",
      "score": 120,
      "num_comments": 16,
      "upvote_ratio": 0.72,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qbwc7t/i_let_the_internet_vote_on_what_code_gets_merged/",
      "domain": "blog.openchaos.dev",
      "is_self": false,
      "comments": [
        {
          "id": "nzeg4v4",
          "author": "personman",
          "text": "I gotta tell you, the overdramatic tone of the writing here is quite painful. Nomics are fun, and a good writeup of a nomic is a great read, but nothing has *happened* yet. You can't be taking away philosophical conclusions and writing \"the irony isn't lost on me\" when you have merged literally one PR. You sound primarily like you want attention, rather than like you want to build & maintain something cool. Tone it down a bit and more people will care.",
          "score": 128,
          "created_utc": "2026-01-13 19:03:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzehhm2",
              "author": "Equivalent-Yak2407",
              "text": "Fair criticism. Week 1 post was written in the heat of the moment. Probably too much drama for one merged PR.\n\nLet's see if there's anything worth writing about after a few more weeks.",
              "score": 12,
              "created_utc": "2026-01-13 19:09:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzfhqkc",
                  "author": "DrElyk",
                  "text": "Nah you're fine, they're just being weirdly critical. Awesome project!",
                  "score": 17,
                  "created_utc": "2026-01-13 21:57:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzdwcfl",
          "author": "axkotti",
          "text": "I think this game has an absorbing/zero state when a PR get merged after which the repo can no longer be deployed as a website.",
          "score": 20,
          "created_utc": "2026-01-13 17:35:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nze2dyx",
              "author": "Equivalent-Yak2407",
              "text": "Per the rules, CI must pass to be eligible. For example, PR [\\#13](https://github.com/skridlevsky/openchaos/pull/13) passes CI but breaks the Vercel build.\n\nIf it wins and Vercel deployment fails, the previous version stays live. So the site doesn't go down, it just doesn't update until someone fixes the build.\n\nNot quite an absorbing state, more like a \"stuck state\" until a fix gets voted in.",
              "score": 24,
              "created_utc": "2026-01-13 18:03:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nze3iys",
                  "author": "axkotti",
                  "text": "Okay, that's nice. But maybe my example was too simple. E.g. what about a PR that passes CI and can be deployed, but somehow removes the ability to vote?\n\nIs it expected that such PR is never going to be approved by the community?",
                  "score": 9,
                  "created_utc": "2026-01-13 18:08:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzh6tm1",
          "author": "tresorama",
          "text": "Democracy without governance! Good social test ..\nupdate us 2 months from now, curios",
          "score": 10,
          "created_utc": "2026-01-14 03:29:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzhpw8l",
          "author": "qruxxurq",
          "text": "Mergey McMergeface",
          "score": 8,
          "created_utc": "2026-01-14 05:38:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nziqfsl",
          "author": "Skaarj",
          "text": "Nice idea.\n\nBut as it is with the Simpsons: It had been done before. There has been a bot on github that was merging every PR to itself within some rules. It was fully automated though as far as I can remember.",
          "score": 6,
          "created_utc": "2026-01-14 11:09:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzj0vex",
              "author": "Equivalent-Yak2407",
              "text": "Know the one you’re talking about? Would love to check it out.\n\nThe difference here is human curation. Weekly votes, single winner, community drama. Less automation, more chaos. That was the starting idea.",
              "score": 2,
              "created_utc": "2026-01-14 12:29:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzjcsnj",
                  "author": "Skaarj",
                  "text": "No. I dont remember the name. Otherwise I would have posted a link.",
                  "score": -2,
                  "created_utc": "2026-01-14 13:43:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzfxsd8",
          "author": "mugwhyrt",
          "text": "The Marina Abramovic of software development.",
          "score": 2,
          "created_utc": "2026-01-13 23:17:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qaeile",
      "title": "LLVM: The bad parts",
      "subreddit": "programming",
      "url": "https://www.npopov.com/2026/01/11/LLVM-The-bad-parts.html",
      "author": "Necrotos",
      "created_utc": "2026-01-11 23:22:43",
      "score": 113,
      "num_comments": 27,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qaeile/llvm_the_bad_parts/",
      "domain": "npopov.com",
      "is_self": false,
      "comments": [
        {
          "id": "nz2fzqu",
          "author": "somebodddy",
          "text": "Waiting with popcorn for commenters who only read the title and miss the 'V'.",
          "score": 85,
          "created_utc": "2026-01-11 23:53:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4wkhw",
              "author": "Batrachus",
              "text": "Large Language Virtual Model",
              "score": 18,
              "created_utc": "2026-01-12 09:40:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzblgzk",
                  "author": "Chisignal",
                  "text": "Low Level… Machine\n\nLike, a hammer or a screw?",
                  "score": -1,
                  "created_utc": "2026-01-13 08:45:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz2lk11",
              "author": "hacker_of_Minecraft",
              "text": "Waiting with titles for porpcorn who only commenter the read and V the 'miss'.",
              "score": 11,
              "created_utc": "2026-01-12 00:21:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz7vfru",
              "author": "chjacobsen",
              "text": "Is this going to be the new Java vs JavaScript trap?",
              "score": 3,
              "created_utc": "2026-01-12 19:40:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz4iwfd",
              "author": "seweso",
              "text": "Waiting for someone for someone to post rust is better ;)",
              "score": -5,
              "created_utc": "2026-01-12 07:30:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz4jv6d",
                  "author": "elmuerte",
                  "text": "Isn't the standard rust compiler a LLVM frontend?",
                  "score": 22,
                  "created_utc": "2026-01-12 07:39:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz2wrd7",
          "author": "SippieCup",
          "text": "I feel like LLVM’s philosophy of pushing to upstream everything ASAP, while at the same time expecting good code review / code “synergy” (ick) are two things that are just in opposition to each other.\n\n\n Of course it’ll create a “flat” ecosystem of developers ithe author complains about, since people never form the chance to create downstream groups which do the internal reviews within themselves before it gets upstreamed. \n\nLLVM is basically asking for this overhead, then the author is basically complaining about it.\n\nI feel like if they nurtured approaches like Asahi Linux where upstreaming is the goal, but not immediate, then those smaller communities downstream will form and a lot will be alleviated off them.\n\nOtherwise it’ll just be the xkcd standards comic within the project.",
          "score": 27,
          "created_utc": "2026-01-12 01:18:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz45abi",
          "author": "levodelellis",
          "text": "I'm going to shitpost for just a second\n\n> LLVM is a huge project. LLVM itself is >2.5 million lines of C++, and the entire monorepo is something like 9 million\n\nI once [wrote a compile](https://bolinlang.com/) (I don't work on it anymore) that can compile 3 million lines of the simplest code in one second (arr[0] = 123; arr[1] = 256; etc), not sustained, and on 2019 hardware. Do you think LLVM is a magnitude within that speed?\n\nPretty much every compiler author hates LLVM. How does a 20+ year old project not have a stable API? I have no idea. I do know two specific people high in LLVM management who are complete idiots, but that's a story for another day\n\nI probably should say something nice about LLVM? It's good at being compatible with gcc. I use plenty of gcc intrinsics. From the top of my head, they all worked, and worked correctly, no surprises.",
          "score": 20,
          "created_utc": "2026-01-12 05:36:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4gtbp",
              "author": "pjmlp",
              "text": "I think many contributions are one hit shots.\n\nPhD and Master thesis students doing something, showing their contribution at some LLVM Meeting, and then moving on with their life. \n\nNaturally they aren't impacted by the ongoing changes after being done with LLVM.",
              "score": 36,
              "created_utc": "2026-01-12 07:11:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz5tz40",
              "author": "not_a_novel_account",
              "text": "I eagerly await the release of your competing, ultra-fast, API-stable, compiler framework",
              "score": 13,
              "created_utc": "2026-01-12 13:53:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz6pk54",
                  "author": "levodelellis",
                  "text": "Find someone to pay my salary for 5 years and you got it",
                  "score": 2,
                  "created_utc": "2026-01-12 16:30:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz534lh",
              "author": "buttplugs4life4me",
              "text": "LLVM is that thing that sounds really good and then you start working with it and realize not only is half of it an undocumented mess, but the only documentation that's out there is outdated by like 4 API changes. ",
              "score": 17,
              "created_utc": "2026-01-12 10:41:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz53tei",
                  "author": "hardware2win",
                  "text": "Mehh, I work with it daily and it is pretty decent\n\nThe biggest problem is that cpp and it's technology ecosystem is a mess.\n\nFor example if llvm was written in c# then it would be 10 times more sane to work with",
                  "score": 13,
                  "created_utc": "2026-01-12 10:48:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz8lubw",
                  "author": "mr_birkenblatt",
                  "text": "In my experience that is just a feature of cpp. Every dev thinks their code is self-documenting and actual documentation is always non-existent. I don't know any other language that is so consistently undocumented",
                  "score": 3,
                  "created_utc": "2026-01-12 21:43:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz7yxvi",
              "author": "CarterOls",
              "text": "It’s kinda irrelevant to post a different languages compilation speed, then compare it to a backend like LLVM. I suppose you’re comparing it to clang? If so, C++ is a much more complicated language than “bolin-lang” (I think I got that right) and will have multiple phases of the compiler that handle preprocessing, expanding templates, compile time programming, etc. \n\nWith that being said, I have heard that the backend portion (LLVM) does have some fundamental architecture choices that limit its performance. ",
              "score": 3,
              "created_utc": "2026-01-12 19:56:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz866uu",
                  "author": "levodelellis",
                  "text": "> It’s kinda irrelevant to post a different languages compilation speed\n\nWell... it depends on what interest you. The test I use (array assigns with literal index and literal value) should be simple in every language. I generated C code which I measured using clang, gcc and tcc. tcc is easily a magnitude faster\n\nFor llvm in specific, you could emit llvm-ir from clang, which I did, then measure how long it takes to compile. Having llvm compile ir emitted from clang and from my language was the same, and still a magnitude slower than tcc\n\nThere's different ways to compare but I noticed most compilers are slower than clang, and clang is pretty fast for the array test, and painfully slow when you do more. I don't remember too much what inside a function makes clang & llvm slow, iirc function calls were one of them. I did measure if templates and such make things slower. Here's a not too old article https://bolinlang.com/wheres-my-compile-time",
                  "score": 1,
                  "created_utc": "2026-01-12 20:30:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzfjkbs",
              "author": "flatfinger",
              "text": ">How does a 20+ year old project not have a stable API?\n\nIf some people writing optimizations for a language want to rely upon code from upstream stages upholding certain constraints, other people writing optimizations want the ability to generate code that doesn't have to uphold such constraints, and there's a desire to avoid phase-order dependence, it's not going to be able to document a stable API that doesn't violate at least one of those objectives.",
              "score": 1,
              "created_utc": "2026-01-13 22:06:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzfrmeb",
                  "author": "levodelellis",
                  "text": "You can have unused fields and can overload/extend functions without breaking preexisting code",
                  "score": 1,
                  "created_utc": "2026-01-13 22:45:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz4lksd",
          "author": "PrimozDelux",
          "text": "No mention for my boi tablegen smh",
          "score": 5,
          "created_utc": "2026-01-12 07:54:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qauuls",
      "title": "Vibe Coding Debt: The Security Risks of AI-Generated Codebases",
      "subreddit": "programming",
      "url": "https://instatunnel.my/blog/vibe-coding-debt-the-security-risks-of-ai-generated-codebases",
      "author": "JadeLuxe",
      "created_utc": "2026-01-12 13:27:28",
      "score": 105,
      "num_comments": 29,
      "upvote_ratio": 0.76,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/programming/comments/1qauuls/vibe_coding_debt_the_security_risks_of/",
      "domain": "instatunnel.my",
      "is_self": false,
      "comments": [
        {
          "id": "nz5r4mk",
          "author": "flirp_cannon",
          "text": "An AI slop article about the risks of vibe coding… we’ve come full circle lol",
          "score": 157,
          "created_utc": "2026-01-12 13:37:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5s1n4",
              "author": "Furrier",
              "text": "We just need some AI comments here to really hit the dead internet scenario.",
              "score": 58,
              "created_utc": "2026-01-12 13:42:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz5ubi4",
                  "author": "StevesRoomate",
                  "text": "Then train a next gen AI model on the article + these comments",
                  "score": 23,
                  "created_utc": "2026-01-12 13:55:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz61hx7",
                  "author": "VictoryMotel",
                  "text": "You're absolutely right!",
                  "score": 10,
                  "created_utc": "2026-01-12 14:33:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz89ier",
                  "author": "no3y3h4nd",
                  "text": "Queue odd vaguely legit user names except they all end in _xxxx four digit numbers and are a week old lol",
                  "score": 2,
                  "created_utc": "2026-01-12 20:45:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzhvw6z",
                  "author": "s33d5",
                  "text": "You've hit the nail on the head! You are really asking he important questions.\n\n\nWould you like me to think of some new and exciting articles?\n\n\nMan I fucking hate AI. I am a hypocrite though because I do use it. I also don't like google and I use that. Although admittedly less now.\n\n\nPeople gave stack overflow a bad rap, but I actually miss it. ",
                  "score": 1,
                  "created_utc": "2026-01-14 06:26:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz5syld",
              "author": "tolley",
              "text": "Yup, the ouroboros is finally getting to it's tail! Interesting times.",
              "score": 10,
              "created_utc": "2026-01-12 13:47:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz5zmem",
              "author": "TyrusX",
              "text": "Your lost the opportunity to have vibed an answer too",
              "score": 7,
              "created_utc": "2026-01-12 14:23:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzbc0mw",
              "author": "Mikasa0xdev",
              "text": "AI slop article? That's peak irony.",
              "score": 1,
              "created_utc": "2026-01-13 07:16:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5s82c",
          "author": "Maybe-monad",
          "text": "Just tell it to make it secure, I'll come later and charge more than the hackers",
          "score": 34,
          "created_utc": "2026-01-12 13:43:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzapy7p",
              "author": "dparks71",
              "text": "Put'er in a container and ship",
              "score": 2,
              "created_utc": "2026-01-13 04:28:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzbx50i",
                  "author": "theclovek",
                  "text": "Ok, I have a container ship. What now?",
                  "score": 1,
                  "created_utc": "2026-01-13 10:37:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz6bsl3",
          "author": "ArkuhTheNinth",
          "text": "When I first figured out AI could help me code, I started building an inventory management app and then thinking about endless possibilities.\n\n\nAs I went on with it, I realized that while I am good at deciphering *already written* code in some languages, I do not have enough of an understanding of the low-level security requirements. This in turn led me to say \"shit, I do NOT want the responsibility of some crazy leak to be on my head if I miss something\" so I stopped.\n\n\nNow I just use it to make simple bash/powershell scripts that I DO understand and occasionally to remind me of some specific Linux commands I can't ever seem to remember.\n\n\nIt's good at basic short tasks like that, but an entire application? Fuck that.",
          "score": 17,
          "created_utc": "2026-01-12 15:26:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nza20l0",
              "author": "Blackscales",
              "text": "You should ask AI what best practices are, references to real articles or educational material, tools to help test and validate. Treat it like an advanced search engine with contextual awareness between queries and progress through your app slowly and methodically. You will learn a lot along the way and I do believe AI can help us with the learning process as well as some of the writing process. You just have to not go at light speed. We can't do that yet.",
              "score": 2,
              "created_utc": "2026-01-13 02:15:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzcdnvy",
                  "author": "CptHectorSays",
                  "text": "This is basically how I use llms today. Started a new job rather recently, lots of new tech that I have to learn. Llms allow me to get to a working entry point for my customer additions to the framework and existing codebase in shorter amounts of time than I would have needed if I had to manually „learn“ that framework from its docs, but I always use that gained time to then „take my time“ asking the AI why tha works, if this is a good practice and why. Why a certain thing it suggested is or isn’t a security concern. Explain to me the concepts it just used in a certain module we just created together. Only one I feel I understand the generated code/feature enough to present it to someone else do I commit it and move on. I do have the impression that I’m learning the framework pretty well in the process and when I ask my supervisor for an estimate of how long something should take in their opinion I often get an answer tha fits in my calculations of „I can complete it using vibecoding faster than that, but I’ll use the extra time to make shure I own the code and learn in the process“.\nCurious to know if anyone you disagree….",
                  "score": 2,
                  "created_utc": "2026-01-13 12:48:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz7tsum",
              "author": "Pure-Huckleberry-484",
              "text": "They can be used for an entire application - the caveat is that you have to understand the code being written. Which is not very different than working with a junior and reviewing their code.\n\nThe issues start when people treat AI code as their code instead of someone else's.",
              "score": 3,
              "created_utc": "2026-01-12 19:32:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzi58wq",
                  "author": "Murky-Relation481",
                  "text": "Yeah, I've been using AI to spin up a platform that I'd originally wrote a number of years ago in C++ in preparation for a project. That project got back burnered for a long time and when I came back to it I wasn't happy with some of the design choices I'd made.\n\nI've basically been rebuilding it, sketching out class definitions, basic relationships, messaging protocols, and then telling Claude to wire it together but slowly piece by piece as I review every step. Sometimes it does some dumb things, sometimes it does some things I wouldn't have thought of in context, but most of the time it just writes generic code that I then have to decipher, shove away mentally for later and keep going.\n\nI will say, in a server client architecture being able to work out the quirks and design of one side then tell AI to mirror the needed functionality on the other is quite nice. It generally understands those concepts well and has sped up this rewrite significantly.\n\nOn the other hand it does require babysitting even during runs so I'm not so sure how much time I'm saving ultimately (though I do type less).",
                  "score": 1,
                  "created_utc": "2026-01-14 07:50:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzaisos",
              "author": "JadeLuxe",
              "text": "I believe you need to guide it in a proper way and then it won't be a problem",
              "score": -2,
              "created_utc": "2026-01-13 03:46:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nze8uo0",
                  "author": "floodyberry",
                  "text": "fuck off slop spammer",
                  "score": 2,
                  "created_utc": "2026-01-13 18:31:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzbyeev",
                  "author": "[deleted]",
                  "text": "ah, but the paradox is that you have to *know* that you guided the AI the \"proper way\" to verify that it is not a problem. But what if you don't know enough about the domain to know?",
                  "score": 1,
                  "created_utc": "2026-01-13 10:48:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz8x0uj",
          "author": "tom-smykowski-dev",
          "text": "I think what Linus told about vibe coding vs Linux kernel contributions makes sense in this context. You can use AI but have to take full ownership and responsibility as a human. It means knowing everything about the code you generate. Ppl think the understanding step is skippable, but it is 99% of coding work, and without it tech debt is inevitable. Knowing [software engineering](https://summonthejson.com/products/software-engineering-for-vibe-coders-ebook) principles is definately helpful",
          "score": 6,
          "created_utc": "2026-01-12 22:36:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbkn1y",
          "author": "stupid_cat_face",
          "text": "kekekekekekekekekekekekekekek",
          "score": 1,
          "created_utc": "2026-01-13 08:37:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzcekoe",
          "author": "ChrisRR",
          "text": "One of these days I'll visit this sub and the top post won't be about AI\n\nIt won't be soon, but some day...",
          "score": 1,
          "created_utc": "2026-01-13 12:54:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzoq41t",
              "author": "blafunke",
              "text": "That's how we'll know the bubble has popped.",
              "score": 2,
              "created_utc": "2026-01-15 06:36:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzbd0pi",
          "author": "Lowetheiy",
          "text": "I use LLM to check my code for security risks and it is working pretty well so far 😊",
          "score": 0,
          "created_utc": "2026-01-13 07:25:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzc763p",
              "author": "dontreadthis_toolate",
              "text": "Link to your web app? Keen to check it out ;)",
              "score": 3,
              "created_utc": "2026-01-13 12:02:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}