{
  "metadata": {
    "last_updated": "2026-02-24 09:09:57",
    "time_filter": "week",
    "subreddit": "fintech",
    "total_items": 20,
    "total_comments": 91,
    "file_size_bytes": 112681
  },
  "items": [
    {
      "id": "1r99t2p",
      "title": "Is AI the real edge or just faster iteration?",
      "subreddit": "fintech",
      "url": "https://www.reddit.com/r/fintech/comments/1r99t2p/is_ai_the_real_edge_or_just_faster_iteration/",
      "author": "Glittering_Jelly4177",
      "created_utc": "2026-02-19 20:06:19",
      "score": 64,
      "num_comments": 9,
      "upvote_ratio": 0.97,
      "text": "AI is becoming the default label for modern trading systems.\n\nBut after looking into different structured platforms; [atomichedge.com](http://atomichedge.com) being one example Istudied, I’m starting to think AI isn’t the edge itself.Maybe the edge is process discipline, risk allocation logic, and execution efficiency.Does machine learning create durable advantage or just accelerate adaptation?\n\nInterested in hearing technical takes.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1r99t2p/is_ai_the_real_edge_or_just_faster_iteration/",
      "domain": "self.fintech",
      "is_self": true,
      "comments": [
        {
          "id": "o6dybpg",
          "author": "Adventurous_Read_758",
          "text": "\nAI can make iteration faster, but at the end of the day the underlying math and logic are what really matter.",
          "score": 1,
          "created_utc": "2026-02-20 08:00:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dzd5z",
          "author": "kanchan1711",
          "text": "\n\nThis is a solid discussion. Too many people get lost in buzzwords without understanding the fundamentals.",
          "score": 1,
          "created_utc": "2026-02-20 08:10:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6efgbo",
          "author": "Any_Sleep1653",
          "text": "\nI’ve found that machine learning is most useful for optimizing parameters rather than actually forecasting outcomes.",
          "score": 1,
          "created_utc": "2026-02-20 10:41:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6eg9lw",
          "author": "Better_Chance_4492",
          "text": "Most alpha eventually fades, what really sticks is consistent process and risk management.",
          "score": 1,
          "created_utc": "2026-02-20 10:48:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6eghgz",
          "author": "skeleton012",
          "text": "A long-lasting edge usually comes from solid structure and disciplined process, not from trying to predict the next move.",
          "score": 1,
          "created_utc": "2026-02-20 10:50:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ehvt1",
          "author": "Traditional_Rock_451",
          "text": "A long-lasting edge usually comes from solid structure and disciplined process, not from trying to predict the next move",
          "score": 1,
          "created_utc": "2026-02-20 11:02:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6g8ilc",
          "author": "WhichMongoose5514",
          "text": "We need to be careful using AI in finance.   Mostly due to the predictive nature. Here accuracy is the key . Hence we need to exercise caution before using it\n\nWe must not forget it’s just another tool in the tool belt",
          "score": 1,
          "created_utc": "2026-02-20 16:53:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kv6s0",
          "author": "Stup2plending",
          "text": "In trading specifically, helping beginners in particular but even the more experienced traders once a in while leave their emotions aside is one of the big advantages of AI. Instead of chasing returns after a couple of losing trades, the AI, if set up correctly and with good logic will just stick to its plan. And it's that consistency that is so helpful. \n\nThere are great general fintech uses for it too as I use it to help with onboarding and retention issues.",
          "score": 1,
          "created_utc": "2026-02-21 10:09:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dogv4",
          "author": "TrioDeveloper",
          "text": "For me, AI isn't the edge but a multiplier. Without proprietary data, strong risk management, and solid execution, ML just helps you lose money faster. Most signals decay once they're crowded. Durable edge usually lives in data quality, capital allocation, and infrastructure. AI just accelerates the feedback loop. I think the real moat isn't that we use AI. It's what we have that others don't. Curious how others see it.",
          "score": 0,
          "created_utc": "2026-02-20 06:30:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8kk8u",
      "title": "Quick DLP Software reality check, what’s working for SaaS/cloud and source code?",
      "subreddit": "fintech",
      "url": "https://www.reddit.com/r/fintech/comments/1r8kk8u/quick_dlp_software_reality_check_whats_working/",
      "author": "herereallygone00",
      "created_utc": "2026-02-19 00:34:36",
      "score": 25,
      "num_comments": 7,
      "upvote_ratio": 1.0,
      "text": "Hey folks, I’m trying to get a reality check from practitioners who’ve evaluated or deployed DLP Software recently (endpoint, network, and especially cloud/SaaS).\n\nA few things I’m specifically curious about:\n\nSource code protection:\n\nWhich DLP Software approaches actually work for repos, CI/CD artifacts, and dev laptops?\n\nAre you relying more on classification + policies, or secrets scanning + repo controls, or both?\n\nCloud/SaaS coverage:\n\nFor Microsoft 365 / Google Workspace / Slack / Salesforce / Box, etc., what’s been the best path: CASB-style controls, native SaaS controls, API-based DLP, or endpoint-first?\n\nAny big gaps you didn’t expect until rollout?\n\nBypass reality (the stuff users do):\n\nHow do common bypasses shake out in practice: password-protected archives, client-side encryption, screenshots, copy/paste into personal accounts, “shadow” upload tools, etc.?\n\nDo you treat DLP as “detect + deter,” or do you successfully block a meaningful % without breaking workflows?\n\nOperational pain:\n\nWhere do you spend most of your time: tuning rules, classification, exceptions, false positives, policy drift, or incident triage?\n\nAny “must-have” features for reducing noise (workflows, incident enrichment, integrations)?\n\nAlso: in the broader cloud data security conversation, I keep seeing Cyera mentioned alongside DSPM / data discovery + classification. From what I’ve read, teams sometimes pair discovery/classification with DLP Software controls (since finding and labeling sensitive data is half the battle). If anyone’s evaluated that “DSPM + DLP” combo, I’d love to hear what the decision criteria looked like (even if you didn’t pick Cyera).\n\nWhat vendors or patterns have you worked with, and what are the honest tradeoffs?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1r8kk8u/quick_dlp_software_reality_check_whats_working/",
      "domain": "self.fintech",
      "is_self": true,
      "comments": [
        {
          "id": "o683qc7",
          "author": "Iron-Horde",
          "text": "We use Cyberhaven. Covers source code tracking from repos to wherever devs paste it, catches AI tools, personal accounts, etc.\n\nEndpoint approach works better than trying to integrate with every SaaS tool separately. Gets screenshots and copy/paste too.\n\nTuning took time upfront but investigations are way faster now you see the full story instead of digging through logs.",
          "score": 1,
          "created_utc": "2026-02-19 11:29:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6a97a6",
          "author": "whatwilly0ubuild",
          "text": "Source code protection is where traditional DLP falls apart fastest. The tools built for detecting credit card numbers in emails don't understand code context at all. A function named `get_secret_key()` isn't sensitive, but the actual AWS credentials hardcoded three lines below it are. Most teams end up splitting this into two separate problems. Secrets scanning with tools like GitLeaks, TruffleHog, or GitHub's native scanning handles the credentials and API keys. Repo access controls and audit logging handle the \"who can see what code\" problem. Trying to force endpoint DLP to understand source code sensitivity is painful and generates endless false positives.\n\nFor cloud and SaaS coverage the honest answer is that no single approach covers everything well. Native controls in M365 and Google Workspace work reasonably for their own ecosystems but the policies don't translate across platforms. CASB-style inline inspection catches uploads but struggles with API-based access and sanctioned app usage. API-based DLP can scan content at rest but can't block in real-time. Most production deployments end up layering multiple approaches and accepting gaps. The big surprise for teams at rollout is usually how much sensitive data already exists in places they didn't know about, so discovery has to happen before enforcement or you're flying blind.\n\nThe bypass reality is humbling. Password-protected archives defeat most inspection. Client-side encryption before upload works if users are motivated. Screenshots and photos of screens are basically undetectable. Copy-paste into personal browser sessions or webmail is hard to block without aggressive endpoint lockdown that kills productivity. Our clients running DLP programs have generally landed on \"detect and deter\" rather than \"block everything\" because the blocking approach creates so much friction that users find workarounds or productivity tanks. The deterrence value comes from users knowing their actions are logged even if not blocked.\n\nOperational time distribution in my experience is roughly 40% false positive tuning and exception handling, 30% policy drift as business processes change and new tools get adopted, 20% incident triage, 10% actual new policy development. The classification problem dominates everything because if you can't accurately identify what's sensitive, your policies are either too broad and noisy or too narrow and miss things.\n\nOn the DSPM plus DLP combination, the logic is sound. You can't protect data you don't know exists. Discovery and classification tools like Cyera, Varonis, or BigID find where sensitive data actually lives, then DLP policies enforce controls based on those classifications. The decision criteria usually come down to whether your primary gap is visibility or enforcement. If you don't know where your sensitive data is, DSPM first. If you know but can't control it, DLP first. Most teams that try to deploy DLP without good discovery end up drowning in false positives or missing their actual high-risk data.",
          "score": 1,
          "created_utc": "2026-02-19 18:31:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6aaf8s",
          "author": "NewZealandTemp",
          "text": "One thing I keep seeing in comparisons is that “DLP Software” can mean totally different things depending on where enforcement happens:\n\nEndpoint DLP (agents controlling copy/paste, printing, uploads, removable media)\n\nNetwork DLP (egress inspection, proxies)\n\nSaaS/API DLP (scanning content inside apps like M365/Drive/Slack)\n\nCloud data security / DSPM (discovery/classification across cloud data stores)\n\nFrom what I’ve read in vendor bakeoffs and analyst-style writeups, a lot of misses come from assuming one category covers all. Curious how people here map “what we’re trying to stop” → “where we enforce,” especially for dev workflows and SaaS sprawl.",
          "score": 1,
          "created_utc": "2026-02-19 18:36:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ce0px",
          "author": "Ok_Interaction_7267",
          "text": "We went through this recently in a SaaS-heavy environment.\n\nBig takeaway: DLP without good data context is rough. On its own it turned into regex tuning + false positives. Once we had continuous data discovery/classification in place (we use Sentra for cloud/SaaS), DLP got more precise because policies were tied to actual sensitivity and exposure, not just content patterns.\n\nFor source code, traditional DLP wasn’t the main control. It’s mostly secrets scanning in repos/CI, tight repo permissions, and monitoring obvious exfil paths on endpoints.\n\nFor M365/Google Workspace, API-level visibility into the data was key. Endpoint-only didn’t cut it. AI assistants just amplify whatever permission mess already exists.\n\nYou’re never going to block every bypass without breaking workflows. We block clear high-risk cases, detect/escalate the gray area, and focus heavily on reducing overexposed sensitive data upstream.",
          "score": 1,
          "created_utc": "2026-02-20 01:10:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6d5na4",
          "author": "Papito24",
          "text": "On bypasses: password-protected archives + client-side encryption seem like the classic “limits of content inspection” problem. The discussions I’ve seen tend to frame it as: if you can’t inspect content, you end up leaning on context signals (destination domain/app, user risk, device posture, unusual volumes, labels, etc.) and process controls (repo permissions, secrets management, least privilege, monitoring).\n\nIf your program is mature, do you treat encrypted exfil as “always block to unknown destinations,” or do you allow it with stricter controls (like only to approved storage/workflows)? I’m trying to understand what’s realistic without causing constant business exceptions.",
          "score": 1,
          "created_utc": "2026-02-20 04:03:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qj5rx",
          "author": "Mormegil1971",
          "text": "I’m also curious how many teams are pairing data discovery/classification tools with DLP Software. The argument I keep seeing is: “DLP policies get way easier when you actually know where sensitive data lives and it’s labeled.” Cyera comes up in that context as a DSPM/data discovery option people compare, but I’m not sure how common the pairing is in practice versus trying to do everything inside one suite.\n\nIf you’ve evaluated “DSPM + DLP,” what were the deal-breakers or success factors? (Coverage of data stores, accuracy of classification, integration into enforcement, incident workflow, etc.)",
          "score": 1,
          "created_utc": "2026-02-22 07:30:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vo4lv",
          "author": "Spawn_75_3311",
          "text": "Cyberhaven is the way to go.",
          "score": 1,
          "created_utc": "2026-02-23 01:47:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7mr46",
      "title": "The hidden problem with AI agents in finance: making them audit-ready",
      "subreddit": "fintech",
      "url": "https://www.reddit.com/r/fintech/comments/1r7mr46/the_hidden_problem_with_ai_agents_in_finance/",
      "author": "InspectionWrong4177",
      "created_utc": "2026-02-17 23:40:59",
      "score": 16,
      "num_comments": 23,
      "upvote_ratio": 0.88,
      "text": "The hidden problem with AI agents in finance: making them audit-ready...\n\n\n\nI've been knee-deep in AI agent deployments in fintech, and I've hit a wall that many others might be facing, too. Building the agents themselves? Challenging, but doable. The real headache, though, is making them audit-ready.\n\n\n\nThe core issue is that AI models are inherently probabilistic. They can spit out different answers for the same input based on a bunch of variables – model version, temperature, token limits, even API response times. But financial regulators demand determinism. They want to replay a transaction approval from months ago and get the exact same reasoning path every single time.\n\n\n\nThis creates a huge compliance gap. Simply logging AI outputs isn't enough. Auditors will inevitably ask, 'Why did your agent approve this loan?' and 'Can you prove it would make the same decision today?' If you can't answer with certainty and a clear, repeatable process, you're not going to pass muster.\n\n\n\nMy approach has been to build a validation layer that sits between the AI agent and the production environment. It's designed to capture the agent's reasoning chain, validate it against a set of deterministic rules, and then create an immutable audit trail. This way, the agent can still be probabilistic during development and exploration, but any decision pushed to production has a deterministic, auditable validation behind it.\n\n\n\nThis layer needs to ensure:\n\n\\- Reproducibility: The same input always yields the same validation outcome.\n\n\\- Explainability: A clear, step-by-step reasoning path for every decision.\n\n\\- Auditability: Immutable logs that regulators can easily review.\n\n\\- Version control: Tracking exactly which model version was involved in each decision.\n\n\n\nIs anyone else in r/fintech grappling with this challenge of making probabilistic AI compliant with deterministic financial regulations? How are you bridging this gap?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1r7mr46/the_hidden_problem_with_ai_agents_in_finance/",
      "domain": "self.fintech",
      "is_self": true,
      "comments": [
        {
          "id": "o5yybc3",
          "author": "KimchiCuresEbola",
          "text": "Why would you ever have a loan validation done by an LLM?!\n\n\\*If\\* you want to implement ML (which tbh I'm not sure most people should), you should be doing decision trees or at most some SVM model...\n\nLLM can perhaps do some automation, but it should have \\*absolutely\\* nothing to do with the actual approval model!",
          "score": 3,
          "created_utc": "2026-02-18 01:10:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6y0fmm",
              "author": "onlyforyouiam",
              "text": "That is where most teams end up after experimenting. The LLM is useful for document parsing, extracting intent, or highlighting risk signals, but the approval logic usually has to fall back to something testable and fixed. Otherwise you cannot prove consistency across time.",
              "score": 2,
              "created_utc": "2026-02-23 13:00:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5zozm1",
              "author": "InspectionWrong4177",
              "text": "I completely agree with your skepticism about handing over loan approvals to LLMs. This caution is exactly why we've produced such a value-added service in finance! Machine Learning is a very specialized process that most likely could be applicable if training private-client frontier models. LLMs are inherently stochastic. Finance requires reproducible outcomes for audits, backtesting, and regulatory sign-off. Our emphasis on deterministic environments for the agent layer (i.e., exact replay, seeded randomness, fixed tool mocks) is key.",
              "score": 0,
              "created_utc": "2026-02-18 03:35:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5zt3tl",
          "author": "Plus_Cat6736",
          "text": "Honestly, this is a tough issue. We've been trying to tackle similar concerns with AI in our audits. The challenge of reproducibility and explainability is real. \n\nLast year, we faced some pushback on our automated processes because they weren't transparent enough for the auditors. We started logging decision-making processes more meticulously, and it helped a lot. Instead of just recording outputs, we captured the reasoning as well. It cut down on audit queries, probably by 30% since we could clearly show how decisions were made. \n\nThat said, it's still a work in progress. We're looking into more robust solutions for version control and immutable logging. Have you considered implementing any auditing frameworks or tools that help with this? It'd be great to hear what others are doing to bridge the gap between AI and compliance.",
          "score": 2,
          "created_utc": "2026-02-18 04:01:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6y0gb7",
              "author": "onlyforyouiam",
              "text": "We saw the same shift when teams started logging not just outputs but inputs, prompts, model version, and the transformation pipeline as one chain. It turns the question from “why did the AI decide this” into “here is the exact evaluated rule set with the AI derived features attached.” Some groups are borrowing ideas from data lineage tooling and treating model interactions like regulated data transformations instead of black box inference.",
              "score": 1,
              "created_utc": "2026-02-23 13:00:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5yk3hb",
          "author": "kubrador",
          "text": "the real problem is you've built a system that requires you to explain your black box to regulators who also don't understand black boxes, so you're essentially creating a fake deterministic layer that's just theater for compliance. might work until it doesn't.",
          "score": 1,
          "created_utc": "2026-02-17 23:52:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60gvph",
          "author": "Plus_Cat6736",
          "text": "This is such an interesting topic, and I can see how tricky it gets with AI being so probabilistic. Not sure how much I can help, but have you looked into some tools that help with audit trails in general? It sounds like you’re already on a solid path with that validation layer, but I wonder if there are industry standards or frameworks that can support your process. What kind of regulations are you primarily dealing with? It’d be cool to hear what others in the community are doing about this!",
          "score": 1,
          "created_utc": "2026-02-18 07:00:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63zrub",
              "author": "InspectionWrong4177",
              "text": "There is so much competition! I could give you more info in a technical demo. For now, check out this research paper on a new Financial industry AI Agent benchmark: [https://arxiv.org/pdf/2507.17186](https://arxiv.org/pdf/2507.17186)\n\nOur strategy so far has been to codify various financial industry ontologies (like FinGAIA) into \"programmable logic gates\" executed during simulation and production runtimes, depending on business requirements.",
              "score": 1,
              "created_utc": "2026-02-18 19:38:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o60k6bv",
          "author": "KarinaOpelan",
          "text": "I think the key distinction is this: regulators don’t need the model to be deterministic, they need the decision process to be controlled and reviewable. The safer pattern in fintech is letting the LLM produce analysis, while a deterministic policy engine and/or human sign-off makes the binding decision. Then your audit surface becomes clear: immutable input snapshots, model/version pinning, fixed inference configs, full tool logs, and explicit rule triggers. Most failures happen when generative reasoning gets mixed directly with financial approvals without that structural separation.",
          "score": 1,
          "created_utc": "2026-02-18 07:30:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o613t30",
          "author": "xaic",
          "text": "In highly regulated financial environments, LLM agents should function as advisory systems within deterministic governance frameworks, not as autonomous decision makers. The compliance problem you’re describing may actually be a signal that we’re assigning the wrong role to the technology.",
          "score": 1,
          "created_utc": "2026-02-18 10:31:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o635vny",
          "author": "whatwilly0ubuild",
          "text": "The problem is real but I'd push back slightly on the framing. Regulators don't actually demand perfect reproducibility in most cases, they demand explainability and defensibility. Those are related but not identical.\n\nThe distinction matters because chasing perfect determinism from LLM-based systems is often the wrong goal. You can pin model versions, set temperature to zero, fix seeds where possible, and still get slight variations due to batching, hardware differences, or API provider changes. Building compliance architecture around the assumption of perfect reproducibility sets you up for failure when it inevitably drifts.\n\nWhat actually satisfies auditors in practice. Comprehensive input/output logging with timestamps and model version metadata. The reasoning chain captured at decision time, not reconstructed later. Clear documentation of what the AI recommended versus what was actually actioned, since many compliant systems have human approval gates that make the AI advisory rather than decisioning. Validation rules that are themselves versioned and logged so you can show what checks were applied.\n\nThe validation layer approach you're describing is solid but the framing should be \"we validated this decision against these deterministic rules at this time\" rather than \"the AI would make the same decision today.\" The first is provable and sufficient, the second is a promise you can't keep.\n\nOur clients deploying AI in regulated finance have found that the architectural pattern that works is treating AI outputs as proposals that pass through deterministic policy gates. The AI is explicitly non-deterministic and that's fine. The policy layer is deterministic and auditable. The decision record captures both.\n\nThe version control point is often underestimated. Model version, prompt version, validation rule version, and any retrieval corpus version if you're doing RAG, all need to be captured together.",
          "score": 1,
          "created_utc": "2026-02-18 17:24:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63o6du",
          "author": "GitPushGoogly",
          "text": "I’m aware that there are software platforms that help with this, such as:\n\n Arize AI – https://arize.com/llm-evaluation/\n\n Corridor Platforms (GenguardX) – https://ggx.corridorplatforms.com/",
          "score": 1,
          "created_utc": "2026-02-18 18:45:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64s4hx",
          "author": "dennisthetennis404",
          "text": "The AI can be unpredictable under the hood and that's fine. What matters is that every decision it makes in production has a clear, traceable explanation attached to it. That's what auditors actually need.",
          "score": 1,
          "created_utc": "2026-02-18 21:49:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o655p0e",
          "author": "into_fiction",
          "text": "If you're dealing with global tax compliance challenges, you might want to look into Getsphere. It automates a lot of the tedious parts of sales tax, VAT, and GST, integrating directly with your systems. It's been quite efficient for my team.",
          "score": 1,
          "created_utc": "2026-02-18 22:54:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65mgow",
          "author": "skinnydill",
          "text": "So a rules engine? Why use ai other than write the rules?",
          "score": 1,
          "created_utc": "2026-02-19 00:25:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o680u62",
          "author": "ItinerantFella",
          "text": "Give the same loan application to 1000 people and you wouldn't get 100% consistency. Why do regulators expect AI to be 100% consistent?\n\n\nObservable, explainable, trainable? Yes yes yes.",
          "score": 1,
          "created_utc": "2026-02-19 11:05:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e41dz",
          "author": "ETP_Queen",
          "text": "100% agree with this. The hard part isn’t “agents,” it’s making them replayable months later under audit. If you can’t reproduce the decision with the same inputs + versioning + immutable logs, it’s basically un-auditable.\n\nA validation layer is the right pattern: let the model propose, but only deterministic rules can approve, with strict schema, test gates, and a full trace. Otherwise you’re just accumulating regulatory debt.",
          "score": 1,
          "created_utc": "2026-02-20 08:54:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gp63e",
          "author": "Necessary-Company-38",
          "text": "Good framing, and the validation layer approach makes sense. I'd push the model a bit further though, because in practice the determinism problem is IMO only one of several places the accountability chain breaks.\n\nYour four points (reproducibility, explainability, auditability, version control) are necessary. I'd argue they may not be quite sufficient though. Here's what we've run into on top of those:\n\n1. Evidence objects, besides your \"step-by-step reasoning path\". This means to ensure claims are tied to discrete evidence records (source, retrieval timestamp, URL/ID). Auditors don't just want to see that a decision was made, they want to verify each factual premise independently. If a claim exists in the output but can't be traced to a captured source, it can't survive examination.\n\n2. Policy enforcement, besides policy awareness. The agent should not be making the final call. Approvals, escalations and closures should be governed by a separate set of rules, sitting outside the model, that are fixed and independently auditable. The agent reasons and proposes. A deterministic rule set makes the actual decision. Critically, those rules need to be versioned, meaning you can always go back and show exactly which rules were in force at the time of any given decision, not just what the rules say today.\n\n3. Entity resolution and context (the misattribution problem). In my experience, most hallucinations in compliance contexts aren't confabulation but misattribution, e.g. wrong entity, wrong subsidiary etc. The AI confidently attributes something to the right name but the wrong legal person. Standard audit logging typically doesn't catch this because the reasoning chain looks clean. I think you need to embed identity confidence scoring and escalation below resolution threshold. \n\n4. Reproducibility via evidence bundle vs token determinism. I think the OP's reproducibility point is the right goal, but the mechanism matters. In a compliance context, reproducibility doesn't mean the model produces identical tokens, rather you can reconstruct why the decision was made at any point in the future. That requires capturing the full evidence bundle active at decision time, e.g. inputs, sources with timestamps, entity resolution decisions, policy version, outputs, reviewer overrides with reason codes. With that, you can replay any decision credibly in front of a regulator without depending on model determinism, which as the OP correctly notes is not something you can reliably guarantee.\n\nBottom line, I believe the real problem is less \"AI is unpredictable while regulators want certainty\", and rather that agents should be built with the paper trail around them. The validation layer in the OP solves part of that, while the evidence and entity resolution pieces are the rest.\n\nCurious whether others are hitting the entity resolution piece specifically, as it tends to be the one that in my eyes typically surprises teams who think they've solved the audit problem. \n\nDisclosure: I work at CleverChain, where we build agentic AI for compliance and due diligence. Not pitching, just sharing a control pattern we've stress-tested in practice and shaped by engagement with regulators. Happy to be challenged in thread.",
          "score": 1,
          "created_utc": "2026-02-20 18:09:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ugdbf",
          "author": "Fun-Hat6813",
          "text": "yeah this hits so close to home it's not even funny. I've been building AI systems for lenders for years now and the audit trail problem is probably the biggest technical challenge we face. The regulatory side doesn't care how smart your AI is if you can't explain exactly why it made each decision, and \"the neural network said so\" doesn't fly when you're in front of examiners.\n\n\n\nYour validation layer approach is solid but I'd add one thing that's been crucial for us at Starter Stack AI - we actually maintain dual decision paths. The AI does its probabilistic magic to surface insights and flag issues, but then we have deterministic rule engines that make the actual decisions based on those insights. So when an examiner asks \"why did you approve this deal\" we can point to specific rules that fired, specific data points that were extracted, and specific thresholds that were met. The AI becomes more like a really smart research assistant rather than the decision maker itself.\n\n\n\nThe other nightmare scenario we learned about the hard way is model drift over time. Even if you lock down your validation layer, the underlying AI models change behavior as they get retrained or updated. We started versioning everything obsessively and running regression tests on historical decisions whenever we update anything. It's a pain but beats having to explain to regulators why the same loan application would get different results six months apart. The compliance overhead is real but it's the price of admission if you want to deploy this stuff in regulated industries.",
          "score": 1,
          "created_utc": "2026-02-22 21:41:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6y0ejc",
          "author": "onlyforyouiam",
          "text": "What you are describing is basically separating “decision support” from the actual decision engine. Let the AI explore, summarize, flag anomalies, or structure unstructured data, but freeze the final approval inside a deterministic rules layer that can be replayed exactly. Think of the LLM as a preprocessing or interpretation component, not the authority. Once you treat it like a probabilistic sensor feeding a deterministic system, auditors get more comfortable because the regulated outcome is still traceable code.",
          "score": 1,
          "created_utc": "2026-02-23 13:00:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ylshp",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 0,
          "created_utc": "2026-02-18 00:01:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ythzf",
              "author": "InspectionWrong4177",
              "text": "Small team here, thinking about going open source. I can say we've implemented a low-level execution tracing of Agent-related tasks in context, for later replay verification.   \n  \nWe've discovered that different agents produce different results even when using the same model! Thus, our platform is more agentic-focused to address this obvious trust gap in the market.  \n\n\nWhat tools or frameworks do you use?",
              "score": 0,
              "created_utc": "2026-02-18 00:44:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r8bof7",
      "title": "Fintech history timeline",
      "subreddit": "fintech",
      "url": "https://i.imgur.com/1aEdLPp.jpeg",
      "author": "boppyblice25",
      "created_utc": "2026-02-18 18:51:23",
      "score": 15,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1r8bof7/fintech_history_timeline/",
      "domain": "i.imgur.com",
      "is_self": false,
      "comments": [
        {
          "id": "o67ag1y",
          "author": "PassionImpossible326",
          "text": "This is very much detail graph. And I dint know world's first ATM was launched by Barclys bank",
          "score": 1,
          "created_utc": "2026-02-19 06:56:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69lcj8",
          "author": "rain_malanix",
          "text": "Neat, but I feel like Ethereum is notable and relevant enough to make the timeline too",
          "score": 1,
          "created_utc": "2026-02-19 16:37:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o658kgu",
          "author": "ploesdrupl",
          "text": "I dont think Google Wallet is significant enough to be on that timeline",
          "score": 0,
          "created_utc": "2026-02-18 23:09:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rc3tac",
      "title": "Expense platform PayEM astroturfing finance subreddits with a single account",
      "subreddit": "fintech",
      "url": "https://i.redd.it/a3v8dups23lg1.png",
      "author": "partyxpat",
      "created_utc": "2026-02-23 01:20:34",
      "score": 12,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1rc3tac/expense_platform_payem_astroturfing_finance/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r7b6hv",
      "title": "Fintech security architectures: where they break and why",
      "subreddit": "fintech",
      "url": "https://www.cerbos.dev/blog/fintech-security-architectures-where-they-break-and-why",
      "author": "West-Chard-1474",
      "created_utc": "2026-02-17 16:41:38",
      "score": 12,
      "num_comments": 1,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1r7b6hv/fintech_security_architectures_where_they_break/",
      "domain": "cerbos.dev",
      "is_self": false,
      "comments": [
        {
          "id": "o5xlxy5",
          "author": "quovest",
          "text": "Great breakdown. From building in the investment analytics space, the two biggest security gaps I've seen in early-stage fintech are:\n\n1. **Over-relying on API gateway auth without per-service authorization.** When you have a single gateway but multiple internal services, a compromised service can access other services' data. Zero-trust between services matters even at small scale.\n2. **Treating compliance as a post-hoc layer instead of a design constraint.** If you're operating under any regulatory framework (publisher's exclusion, RIA, etc.), your security architecture needs to enforce those constraints automatically. We built automated guardrails that prevent our AI from crossing from \"general research\" into \"personalized advice\" territory but this should be in the architecture, not in a manual review process.\n\nAlso: secrets management. The number of fintech startups I've seen with API keys hardcoded or in .env files that get committed to git is terrifying.",
          "score": 1,
          "created_utc": "2026-02-17 21:00:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rc9dn9",
      "title": "Prototyping real use cases is way harder than designing “Happy Path” screens",
      "subreddit": "fintech",
      "url": "https://www.reddit.com/r/fintech/comments/1rc9dn9/prototyping_real_use_cases_is_way_harder_than/",
      "author": "Curious-Session4119",
      "created_utc": "2026-02-23 05:53:38",
      "score": 8,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "I’m building prototypes for a fintech product, and I realized something: designing the main flow is easy. Designing real behavior is not. What happens when a user skips a step?  \nwhat happens when data is missing?, what happens when they come back after 3 months? My prototypes look great when everything goes right. The second I try to map real-world use cases, my design files explode into duplicates and disconnected screens. I want a way to visually organize use cases, branches, and logic before everything becomes high-fidelity. Some place where wireframes, notes, and flows can live together, so im not guessing how the product should behave.\n\nAt the moment, my prototypes show UI but not product thinking.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1rc9dn9/prototyping_real_use_cases_is_way_harder_than/",
      "domain": "self.fintech",
      "is_self": true,
      "comments": [
        {
          "id": "o6wp40b",
          "author": "Careless_Passage8487",
          "text": "For a particularly messy fintech project, we moved the early flow mapping into Miro. Instead of trying to represent everything in Figma from the start, we created a shared board where each path happy, skipped, or exception had its own branch. Screens, notes, and edge cases lived together visually. Stakeholders could explore scenarios without breaking the design file, and developers could see exactly how logic connected to screens.",
          "score": 3,
          "created_utc": "2026-02-23 05:58:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6wpwz0",
          "author": "Economy_Passenger296",
          "text": "For me, the first mistake is trying to force everything into a single high-fidelity prototype too early. ive started keeping a “logic-first” layer a visual diagram of every user path, edge case, and failure scenario, separate from polished screens. once that layer is clear, creating wireframes or prototypes is much faster, and you don’t lose context when things inevitably change.",
          "score": 1,
          "created_utc": "2026-02-23 06:05:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6wslh1",
          "author": "Firm-Goose447",
          "text": "We were building a subscription management feature, the happy path sign up, add card, confirm email was easy. but when we mapped real-world behaviors like paused accounts, expired cards, skipped verification, or users returning after months, our figma file quickly became a tangled mess of 50+ screens. developers couldn’t tell which screens were authoritative, and product managers were constantly asking for clarifications. It really made.",
          "score": 1,
          "created_utc": "2026-02-23 06:28:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6x5tl9",
          "author": "ETP_Queen",
          "text": "missing data, retries, stale sessions, regulatory flags, reconciliation breaks. If those aren’t mapped first, the prototype is just a demo, not a system. I’ve found it helps to model states and transitions (almost like a mini state machine) before touching high-fidelity screens. Flows break less when the logic is explicit.",
          "score": 1,
          "created_utc": "2026-02-23 08:32:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9gdla",
      "title": "QA here — uneasy about AI being pushed toward production in lending systems. Am I overthinking this?",
      "subreddit": "fintech",
      "url": "https://www.reddit.com/r/fintech/comments/1r9gdla/qa_here_uneasy_about_ai_being_pushed_toward/",
      "author": "c0rza1r_12",
      "created_utc": "2026-02-20 00:23:05",
      "score": 7,
      "num_comments": 18,
      "upvote_ratio": 0.89,
      "text": "I work in fintech (mortgage / loan origination systems), mainly on the QA / validation side. I’m not an AI expert — I was pulled into an internal AI project because of my domain and testing background.\n\nThe goal was to use AI to generate business rules for mortgages and consumer loans. On paper it sounds great — faster rule writing, less manual effort, more efficiency.\n\nIn practice… it’s been messy.\n\nWe tested multiple baseline models. Refined prompts. Added structured output constraints. Wrapped guardrails around it. Tried narrowing scope. And still:\n\n\t•\tLogical inconsistencies\n\n\t•\tEdge cases breaking\n\n\t•\tConfident-but-wrong outputs\n\n\t•\tStrange eligibility conditions\n\n\t•\tFormatting issues that could affect downstream systems\n\nFrom a QA perspective, this isn’t minor. In lending, small logic errors can mean incorrect approvals or declines. That’s compliance exposure, audit findings, and real customer impact.\n\nWhat’s honestly making me uneasy is that there’s still momentum to move it closer to production. I get the innovation pressure. AI is the buzzword. Nobody wants to look like they’re lagging behind.\n\nBut there’s a difference between using AI as a drafting assistant that a human fully owns and validates… and letting it influence decision logic in heavily regulated systems.\n\nAgain, I’m not anti-AI. I actually find the tech interesting and I’m not trying to block innovation. I just feel like the reliability and determinism gap is being underestimated.\n\nAm I overreacting?\n\nIs anyone else in fintech seeing this “ship it and harden it later” mindset around LLMs?\n\nHow are you drawing the line between assistive tooling and production decision logic?\n\nTrying to figure out if this is just internal pressure where I am or if this is where the industry is heading.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1r9gdla/qa_here_uneasy_about_ai_being_pushed_toward/",
      "domain": "self.fintech",
      "is_self": true,
      "comments": [
        {
          "id": "o6c8m63",
          "author": "amg-rx7",
          "text": "Not over reacting. You do need to cover your ass and inform the stakeholders of your observations of the results and state your concerns. Stakeholders being informed should include compliance leaders.\n\nYou should probably try and mitigate risk with a soft launch where ai makes the decision but needs human review before anything goes out to customers. Probably other risk mitigation steps as well…",
          "score": 4,
          "created_utc": "2026-02-20 00:37:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6cvsq2",
              "author": "c0rza1r_12",
              "text": "I did inform PO and CPO about the issues, it didn’t end up well, unfortunately. I quit because it was going against my professional standards. Thankfully I kept good contacts at the company, so people I know will show up for quality. I’ll use your advice earlier - before it becomes reactive. Thank you.",
              "score": 3,
              "created_utc": "2026-02-20 02:59:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6h5ds6",
                  "author": "RocheleAveruiz",
                  "text": "How did you make the decision to quit? A lot of people in these spaces will stay despite knowing fully well what they're doing and the implications, so seeing someone make the choice and have it be based on that is pretty rare.",
                  "score": 1,
                  "created_utc": "2026-02-20 19:23:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6jrh2x",
                  "author": "amg-rx7",
                  "text": "Pretty harsh but I understand",
                  "score": 1,
                  "created_utc": "2026-02-21 04:14:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6dhb3k",
          "author": "rhizome-compliance",
          "text": "I think it should work as you say: these systems can inform human decisions on loans, but not make them directly. Does your company have a legal department? An ally there might help to pump the breaks on this a bit.",
          "score": 3,
          "created_utc": "2026-02-20 05:29:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e3vvx",
          "author": "ETP_Queen",
          "text": "You’re not overthinking it at all. In lending, small logic errors aren’t “bugs,” they’re real customer and compliance issues. If you’re already seeing inconsistencies and edge cases breaking, that’s a signal.\n\nAI can be great as a drafting or support tool, but decision logic in regulated systems needs to be deterministic and fully auditable. “Ship and harden later” doesn’t really work when approvals and declines are involved.",
          "score": 3,
          "created_utc": "2026-02-20 08:53:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dd4oo",
          "author": "opinionsnotmine",
          "text": "In the US, consumer lenders most provide the specific reasons for denial of an application for credit. I would be equally worried about \"disparate impact\" liability if the models have discriminatory effects of a protected basis - while the CFPB has been clear that they won't bring actions under the disparate impact their, many states' AG will absolutely continue to do so.  Also note that, even absent any disparate impact, there could be fair lending liability for using data are \"proxies\" for membership in a protected class.  AI use is definitely risky, but there are absolutely ways to use AI responsibly and with minimal added regulatory risk.  ",
          "score": 2,
          "created_utc": "2026-02-20 04:57:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6eq1b3",
          "author": "Professional_Mix2418",
          "text": "Also pending your jurisdiction consumer have the right not to have automated decision making. The AI Act also identifies high risk businesses and this seems to fall into that category. This may help your case to frame it constructively. And even if the EU AI Act isn’t applicable in your jurisdiction you can still use it as a best practice test and conscious decision point to do or not do. \n\nThat way you aren’t making it about you, you are pointing to recognised standards.",
          "score": 2,
          "created_utc": "2026-02-20 12:06:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fo2ha",
              "author": "c0rza1r_12",
              "text": "\nWe’re operating in NL, Germany and now the UK, how would you bring this up if you were me? Would you directly reference the EU AI Act + automated decision-making / high-risk stuff, or just position it more as “this is where regulation is heading / recognised best practice”?",
              "score": 1,
              "created_utc": "2026-02-20 15:18:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6fr0bg",
                  "author": "Professional_Mix2418",
                  "text": "The AI was enacted last year februari. In the NL and DE it is the law. I wouldn’t bring it that hard as many organisations aren’t aware of it. And the regulators I. NL it’s with the AP are toothless. \n\nBut as part of the project you have both GDPR and the AI Act that give the guard rails on how this can be used. So as you have the concerns already from your experience and as a human being, familiarise yourself with those pieces and bring it in as a positive constructive feedback with regulatory implications. The fintech sector is already in the high risk category so this isn’t an option for them. \n\nBut yes too often management has got no clue, sales people find compliance and regulations annoying. But it’s a fiduciary duty to the organisation to protect it.",
                  "score": 2,
                  "created_utc": "2026-02-20 15:32:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6c6q16",
          "author": "venturepulse",
          "text": "you forgot to say which model you used",
          "score": 1,
          "created_utc": "2026-02-20 00:26:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c8t15",
          "author": "c0rza1r_12",
          "text": "We used GPT-4 Turbo and Claude 3 Opus. Both were prompted with the same inputs for consistency.",
          "score": 1,
          "created_utc": "2026-02-20 00:38:59",
          "is_submitter": true,
          "replies": [
            {
              "id": "o6df4b6",
              "author": "cxavierc21",
              "text": "Why such out of date models?",
              "score": 1,
              "created_utc": "2026-02-20 05:12:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6dvl8z",
                  "author": "c0rza1r_12",
                  "text": "Those were the models we used when I was actively on the project a year ago.",
                  "score": 1,
                  "created_utc": "2026-02-20 07:35:17",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6con0c",
          "author": "PuzzleheadedPeace360",
          "text": "Isn’t it illegal in your state/jurisdiction to deny loans without explaining the exact reasons? If the AI model hallucinates it can expose the company to a big liability. ",
          "score": 1,
          "created_utc": "2026-02-20 02:15:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gzaal",
          "author": "sgart25",
          "text": "Vendor here in the space assisting with real-time querying of account info for support purposes. We are strongly against the approach of “hardening it later.” Our philosophy is to master 1-2 use cases, demonstrate success with customers, and build on use cases from there.",
          "score": 1,
          "created_utc": "2026-02-20 18:55:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6h580h",
          "author": "whatwilly0ubuild",
          "text": "You're not overthinking this. Your instincts are correct and the concerns you're raising are exactly what a good QA person should be surfacing.\n\nThe core problem is that LLMs are probabilistic systems being asked to produce deterministic logic. Business rules in lending need to be exactly right every time. An LLM producing a rule that's correct 95% of the time is a compliance nightmare because you don't know which 5% is wrong until it's already made bad decisions. The \"confident but wrong\" pattern you're observing isn't a bug you can fix with better prompts, it's fundamental to how these models work.\n\nThe distinction you drew is the right one. AI as drafting assistant where humans fully validate every output is reasonable. AI influencing production decision logic in regulated lending is a different risk category entirely. The problem with the second scenario isn't that AI is involved, it's that the validation burden doesn't actually decrease. If you have to fully verify every rule the AI generates, you haven't saved effort, you've added a step while creating false confidence that the AI output is a reasonable starting point.\n\nThe \"ship it and harden it later\" mindset around LLMs is absolutely happening across fintech. Our clients see it constantly. The pressure comes from leadership reading headlines about AI transformation and not wanting to fall behind. The problem is that \"harden it later\" doesn't work for compliance. You can't un-approve a loan that shouldn't have been approved, and regulators don't accept \"we were iterating\" as an explanation for fair lending violations.\n\nWhere to draw the line practically. If the AI output goes directly into a system that affects customer outcomes without expert human review of every single output, it's not ready. If the failure mode is \"customer gets wrong decision\" rather than \"employee has to redo some work,\" the bar for reliability is regulatory, not just operational.\n\nDocument your findings thoroughly. When this becomes an audit issue later, you want a clear record that QA raised concerns.",
          "score": 1,
          "created_utc": "2026-02-20 19:22:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8j1q8",
      "title": "Saw these guys promising to replace compliance teams. How many times are we going to fall for this?",
      "subreddit": "fintech",
      "url": "https://www.linkedin.com/posts/alexandreberkovic_yesterday-we-announced-our-71m-seed-round-activity-7430027952643432449-2nU4?utm_source=share&utm_medium=member_desktop&rcm=ACoAACc5Fz0BOlOIh6vul9nrOfEyyFXnpwIoNjs",
      "author": "AinaPapaya",
      "created_utc": "2026-02-18 23:30:00",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1r8j1q8/saw_these_guys_promising_to_replace_compliance/",
      "domain": "linkedin.com",
      "is_self": false,
      "comments": [
        {
          "id": "o65u7nc",
          "author": "meninblck9",
          "text": "This all breaks down when you have complicated names. NICE has been around forever and not cracked the code. Uipath just acquired Workfusion who uses AI agents for AML / KYC sanction screening. The space is a mess still.",
          "score": 2,
          "created_utc": "2026-02-19 01:08:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65z92z",
          "author": "13Morton",
          "text": "I’ve been in identity / AML long enough to have seen a few “this replaces compliance” waves come and go.\n\nThe pattern is usually the same: we treat AML like a detection or pattern-matching problem when in reality it’s a judgment, defensibility, and governance problem.\n\nTransaction monitoring? Sure; models can (and should) improve signal quality. Screening? Automate it. Triage? Optimize it.\n\nBut a SAR narrative isn’t just an output. It’s a position. It’s something you may have to defend to regulators months later with documented rationale, policy alignment, and an audit trail that holds up under scrutiny.\n\nRegulators don’t examine “model confidence scores.” They examine controls, governance, explainability, escalation paths, and documented human accountability.\n\nAI can absolutely make compliance teams more effective.\n“Your last compliance hire” is a very different claim.\n\nIf anything, the vendors who win long-term are the ones who understand they’re augmenting risk judgment, not replacing it.",
          "score": 2,
          "created_utc": "2026-02-19 01:38:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65yug1",
          "author": "lodavo",
          "text": "There are some things that humans should be behind. Security is one of them. Either the AI is too stupid to do it properly or you have a super intellectual black box whose reasoning/intention isn't fully understood controlling your security system.",
          "score": 1,
          "created_utc": "2026-02-19 01:36:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66pvbb",
          "author": "PassionImpossible326",
          "text": "Those all are flashy demos created by Cloude , kids of age 16-17 trying to take on messy fintech problems , c'mon NICE,ACTIMIZE and player like them been here more than your age and still not able to Crack that.\nSuch demos kicked out of the room when compliance team start reviewing them.",
          "score": 1,
          "created_utc": "2026-02-19 04:18:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8vlsk",
      "title": "NEW AML AI-POWERED",
      "subreddit": "fintech",
      "url": "https://www.reddit.com/r/fintech/comments/1r8vlsk/new_aml_aipowered/",
      "author": "Organic_Act7411",
      "created_utc": "2026-02-19 10:18:56",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I'm founder and dev of an AI-powered platform designed to automate Anti-Money Laundering (AML) investigations for compliance teams, particularly in EU fintechs\n\nI get good feedback from fintech people and I wanna know what possible feature if you are in (neobanks, exchanges crypto, payments, would add to make it more complete, now the plataform has: AI agent investigator with deep reasoning, generating structured narratives, compliant STR/SAR drafts, and full explainability in minutes. Enable end-to-end investigations in 60 seconds, and adapt via human feedback loops for MiCA/5AMLD auditability.\n\nwhat feature you would remove/add for make it more stand out in the crowded AML IA space\n\nthanks folks",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1r8vlsk/new_aml_aipowered/",
      "domain": "self.fintech",
      "is_self": true,
      "comments": [
        {
          "id": "o67wq2r",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-19 10:28:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67xmc0",
              "author": "Organic_Act7411",
              "text": "Totally agree. those 4 features we have it already, just the 4th one is on dev mode but for got to market is fine not have it for now, I'll take look to Agentix Labs ref. cheers",
              "score": 1,
              "created_utc": "2026-02-19 10:36:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rbwh56",
      "title": "Everyone is talking about Voice AI in BFSI. Why is no one talking about in-app AI agents?",
      "subreddit": "fintech",
      "url": "https://www.reddit.com/r/fintech/comments/1rbwh56/everyone_is_talking_about_voice_ai_in_bfsi_why_is/",
      "author": "DizzyGold6618",
      "created_utc": "2026-02-22 20:23:41",
      "score": 5,
      "num_comments": 3,
      "upvote_ratio": 0.78,
      "text": "Scroll through any fintech or BFSI thread right now and it’s all Voice AI.\n\nVoice automation.\nVoice agents.\nVoice collections.\nVoice compliance.\n\nBut almost no one is talking about what’s happening inside the app itself.\nMost drop-offs in BFSI don’t happen on calls.\n\nThey happen inside:\n\nKYC flows\nLoan applications\nDispute forms\nPayment journeys\nOnboarding steps\n\nUsers abandon mid-journey because the app cannot resolve friction in real time.\n\nIt shows information.\nIt explains policy.\nIt redirects to support.\nBut it does not act.\n\nVoice AI is powerful for outbound, reminders, and support automation.\n\nBut if the in-app experience is still static, context-blind, and escalation-heavy, are we really solving the biggest leakage points?\nWhy are we optimizing the channel\ninstead of optimizing the journey?\n\nSerious question for product teams in BFSI:\n\nWould reducing in-app drop-offs by even 10 to 15 percent have a bigger revenue impact than automating more call volume?\nCurious if others are seeing the same gap.\nIs in-app intelligence the quieter, bigger opportunity right now?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1rbwh56/everyone_is_talking_about_voice_ai_in_bfsi_why_is/",
      "domain": "self.fintech",
      "is_self": true,
      "comments": [
        {
          "id": "o6ue5tq",
          "author": "Fun-Hat6813",
          "text": "This hits so close to home it's almost painful. I spent years watching financial services companies pour millions into voice automation while their users were literally bleeding out through broken application flows. The obsession with voice AI feels like we're polishing the doorknob while the house is on fire - sure, it's shiny and impressive, but people are still walking away frustrated before they even need to make a call.\n\n\n\nI've been neck deep in this exact problem, especially working with alternative lenders who were losing deals left and right because their KYC and application processes were these nightmarish document upload marathons. Users would get halfway through uploading bank statements or tax returns, hit some validation error or unclear instruction, and just... leave. No phone call, no complaint, just gone. We built intelligent agents at Starter Stack AI that actually understand what users are trying to accomplish in real time and can guide them through these complex flows, fix data issues on the spot, and eliminate those friction points that cause abandonment. The difference in completion rates is honestly staggering.\n\n\n\nThe revenue math on this is pretty brutal when you actually run the numbers. A 10-15% reduction in drop-offs during loan applications or onboarding can literally translate to millions in additional originations for mid-sized lenders, way more impact than automating another hundred collection calls. But voice AI gets all the buzz because it's easier to demo and sounds more futuristic than \"we made the form filling experience not suck.\" The real opportunity is building apps that can actually think and problem-solve alongside users instead of just displaying static information and hoping for the best.",
          "score": 2,
          "created_utc": "2026-02-22 21:30:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6wp7bd",
              "author": "DizzyGold6618",
              "text": "This is exactly the blind spot most teams underestimate.\n\nVoice automation gets budget because it is visible. In-app abandonment is silent.\n\nThe painful part is that users do not complain. They just drop.\n\nCompletely agree that fixing document upload loops, validation ambiguity, and unclear next steps can move revenue far more than optimizing call volume.\n\nWhere I think the next layer evolves is beyond guided assistance toward true in-app orchestration. Not just guiding users, but coordinating backend systems in real time so issues are resolved instead of just explained.\n\nWe are building Revrag around that premise. Intelligence that sits inside the application layer and works with backend state, not around it.\n\nWould love to compare notes on completion rate impact across different segments.",
              "score": 1,
              "created_utc": "2026-02-23 05:59:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o71pqw7",
          "author": "kubrador",
          "text": "you're right that in-app friction is the bigger leak, but voice ai gets funding because it's shinier and easier to demo to executives than \"our kyc form now has better context awareness.\" \n\nalso voice agents print money on collections calls in ways smooth ux never will, so venture capital votes accordingly.",
          "score": 1,
          "created_utc": "2026-02-24 00:05:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9204y",
      "title": "Looking for a technical cofounder (AI + FinTech / RegTech)",
      "subreddit": "fintech",
      "url": "https://www.reddit.com/r/fintech/comments/1r9204y/looking_for_a_technical_cofounder_ai_fintech/",
      "author": "Motor_Advertising193",
      "created_utc": "2026-02-19 15:22:35",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 0.86,
      "text": "Hi all, slightly different post to the usual “idea looking for dev”.\n\nI work in financial crime / compliance in the UK and have been deep in the intersection of regulation and AI over the past year. I’m now building an AI-native RegTech platform aimed at becoming a “Stripe for compliance” — starting with automated AML and AI Act readiness for financial institutions.\n\nThis isn’t a napkin idea. I’ve already mapped:\n\n• MVP architecture\n\n• Regulatory model (UK/EU)\n\n• Product thesis\n\n• Early positioning\n\nWhat I don’t have (yet) is the right technical partner.\n\nI’m looking for a backend-leaning builder (Python/Node, AI API familiarity, cloud infra) who’s interested in building something meaningful in a space that’s about to get very real very quickly.\n\nNot looking for freelancers or agencies — I’m looking for a true cofounder. Equity-based, long-term thinking.\n\nIf you’ve worked in fintech, regtech, or enterprise SaaS and have been itching to build something serious, I’d genuinely love to connect.\n\nHappy to share the blueprint and thinking openly.\n\nJohn",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1r9204y/looking_for_a_technical_cofounder_ai_fintech/",
      "domain": "self.fintech",
      "is_self": true,
      "comments": [
        {
          "id": "o6c0vxt",
          "author": "465di",
          "text": "Have dm'd",
          "score": 1,
          "created_utc": "2026-02-19 23:53:14",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rab4yw",
      "title": "How long does it take to get a Neobank live these days?",
      "subreddit": "fintech",
      "url": "https://www.reddit.com/r/fintech/comments/1rab4yw/how_long_does_it_take_to_get_a_neobank_live_these/",
      "author": "No-Bad-3624",
      "created_utc": "2026-02-20 23:28:02",
      "score": 5,
      "num_comments": 18,
      "upvote_ratio": 0.86,
      "text": "If I wanted to launch a barebones Neobank how long would it take to launch with a Baas platform and how much would I be looking at cost wise in the US? ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1rab4yw/how_long_does_it_take_to_get_a_neobank_live_these/",
      "domain": "self.fintech",
      "is_self": true,
      "comments": [
        {
          "id": "o6mymv5",
          "author": "barbsbaloney",
          "text": "Probably 3-12 months of biz dev. \n\nDepending on who your law firm is and what compliance model you develop could be faster. \n\nYou’d want to budge $20k/month for a bank deal and $100k in legal fees. Again could be less if you’re not working with a bank and have a different compliance model.",
          "score": 3,
          "created_utc": "2026-02-21 18:06:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ldzvj",
          "author": "ji_b",
          "text": "Need funding, and, consequently, a revenue model. Not every baas provider/issuer will share interest on deposits, and those that do will take a cut. Interchange also ain’t what it used to be, and, without a team/consultant (FSV et al.) in place to build said team, it’s a long shot. \n\n6-12 months with funding + team + bank in place.",
          "score": 2,
          "created_utc": "2026-02-21 12:56:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vckjv",
          "author": "looch_app",
          "text": "We built a fully-functional neobank. In the US, neobank = no banking charter. BaaS platforms are happy to sell you their service, but then you need to pitch the partner bank and sometimes even Visa or Mastercard depending on what card you’re issuing. If interchange is your sole source of income, you’re not going to make it. Dev work depends on your team and the kind of UX you’re after. 6-12 months.",
          "score": 2,
          "created_utc": "2026-02-23 00:38:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6x7iwl",
          "author": "ETP_Queen",
          "text": "tbh people always underestimate this. “just plug into a baas and ship” sounds easy but the sponsor bank, compliance model, card network approvals, kyc flows, ops playbooks… that’s where the real time goes. even a lean setup can drift into 6–12 months pretty fast.\n\ncost wise it’s rarely just dev. you’ve got platform minimums, bank/issuer fees, legal, compliance consultants, ongoing monitoring. the stack is doable, but the governance layer is what makes it real.",
          "score": 2,
          "created_utc": "2026-02-23 08:48:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ij6x7",
          "author": "monkey6",
          "text": "Ask us to write your business plan for you and to find investors for you as well",
          "score": 4,
          "created_utc": "2026-02-20 23:37:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6q27qa",
              "author": "houseofn1njas",
              "text": "For US banks only? What about UK?",
              "score": 1,
              "created_utc": "2026-02-22 05:02:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6mx00j",
          "author": "mightymouse1906",
          "text": "Why do we need yet another neo-bank? ",
          "score": 3,
          "created_utc": "2026-02-21 17:58:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ildry",
          "author": "comrace",
          "text": "Depends on your approach anything from 6-24 mths. License not included. I talk from experience",
          "score": 1,
          "created_utc": "2026-02-20 23:50:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6isp7x",
          "author": "ImTheDeveloper",
          "text": "Been through the process fully twice and now going into my 3rd. It 100% depends on your funding and the path the regulator puts you down. In the UK to go from 0 to live id say you're in 18 months territory but I'm the US you can shave a minimal amount off",
          "score": 1,
          "created_utc": "2026-02-21 00:32:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6q2da1",
              "author": "houseofn1njas",
              "text": "It takes a lot longer than 18 months in UK.  And substantial funding to get the right team in place.  Just to get the invite to apply, let alone apply and get the licence.",
              "score": 1,
              "created_utc": "2026-02-22 05:04:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6r07le",
                  "author": "ImTheDeveloper",
                  "text": "As I said it depends on your funding and whether you go into this with a predefined team. My 1st time round we were 2 years and one of the new banks going through at the time (think monzo/atom/starling era). 2nd time we were in alongside bank north, recognise, allica, gb bank, monument etc. This time round we are funded ahead of time due to parent company structures, team pre-assembled and knowledge of the process (see above) and a bank in the box rather than full build out.\n\nIt also depends on your goal posts for start and end of the process as well as the timeframe from the regulator to keep up with responses and feedback. The COVID era startup banks struggled massively and it did take 3+ years due to funding, regulatory feedback slowdown due to staff shortages etc. That's not the case right now they are sticking to the timelines and can be pushed along",
                  "score": 1,
                  "created_utc": "2026-02-22 10:13:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6jlt2d",
          "author": "fuggleruxpin",
          "text": "Doesn't it matter on what the bank does?  Custody/ lending / trading trust etc....",
          "score": 1,
          "created_utc": "2026-02-21 03:35:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6jouzk",
              "author": "No-Bad-3624",
              "text": "Just looking to offer checking accounts",
              "score": 1,
              "created_utc": "2026-02-21 03:56:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6mx5iy",
                  "author": "mightymouse1906",
                  "text": "why? ",
                  "score": 1,
                  "created_utc": "2026-02-21 17:59:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6nqsgk",
          "author": "Johnstake123",
          "text": "I have one for sale if you are interested. Send me dm. You will save a lot of time and money",
          "score": 1,
          "created_utc": "2026-02-21 20:29:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pojpz",
          "author": "chrispedini",
          "text": "Please tell us what marginalized segment of society it is you want to save! Or will you plant a tree? Release a trout into a river? \n\nNeobanks are, by and large, just a branch of a legacy bank / system. I have more NDAs than I can remember but if you can DM me I’d love to help.",
          "score": 1,
          "created_utc": "2026-02-22 03:25:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ra9cjz",
      "title": "Director-level work without title/comp — normal?",
      "subreddit": "fintech",
      "url": "https://www.reddit.com/r/fintech/comments/1ra9cjz/directorlevel_work_without_titlecomp_normal/",
      "author": "Pbjamking1212",
      "created_utc": "2026-02-20 22:16:36",
      "score": 4,
      "num_comments": 5,
      "upvote_ratio": 0.75,
      "text": "Looking for perspective.\n\nI’ve been at a 15-year-old fintech (\\~25 employees) for almost 4 years. I’m a Senior AE (70k base / 150k OTE) and consistently hit quota.\n\nFor the past 6+ months, I’ve also been:\n\n* Hiring and interviewing new AEs\n* Training and coaching\n* Letting an underperformer go\n* Building sales processes\n* Representing sales in product meetings\n* Supporting enterprise deals\n* All while still carrying my own number\n\nWe have two AEs total (including me). I hired the other rep, and he’s still ramping and requires support.\n\nI asked the President about formalizing a Director of Sales role and adjusting comp. He said he’s “not sure we need a manager” yet, but expects me to build the sales team.\n\nAt this point, it feels like I’m being asked to do leadership work without authority or compensation — basically doing it for free.\n\nIs this a normal “prove it first” situation in small companies? Or is this a misalignment I should push harder on?\n\nTrying to handle this strategically, not emotionally. Appreciate any honest thoughts.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1ra9cjz/directorlevel_work_without_titlecomp_normal/",
      "domain": "self.fintech",
      "is_self": true,
      "comments": [
        {
          "id": "o6i6uh0",
          "author": "cxavierc21",
          "text": "Push harder. Be ready to walk, though.",
          "score": 2,
          "created_utc": "2026-02-20 22:29:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6iaps6",
          "author": "Murdles14u",
          "text": "Ya, they’re taking advantage of the situation. \n\nNow you’re stuck, if you pull back and focus on sales then you’re not a team player.\n\nLike the other comment above, push harder and be ready to walk. \n\nYou could prepare for your next conversation with an ask of an extra $15-$20k of base to bridge the gap. Usually a Director should carry a base of $125-$150k depending on the company size. So if you approach it as a middle ground that rewards you for your extra care and attention, but still saves him on a new hire at a higher comp plan then he should see the logic and give you the bump up. \n\nIf you go a bit deeper and do some market research to see what the Director level roles are like in your region and industry then share that info while you’re asking for more money, that shows you’re aware of your value in the marketplace and it also shows the value of your smaller ask of 15-20k. \n\nAlso, ask yourself if you want to grow into a director role fully? If yes, then the conversation is about setting you on a path and the comp is the motivator for that. If that’s the case, then in that same conversation position the bump as a stepping stone to when you become a director and will grow the sales team and take on the target of your whole team. But that would also be another raise and restructuring of your comp plan to give you a variable that’s brings your OTE close to $200k.\n\nI caution you against actually interviewing/accepting another role and telling him about it. I used to work for a VP who would counter offer the role, then fire the person after 6 months because they weren’t loyal enough.",
          "score": 1,
          "created_utc": "2026-02-20 22:50:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lzsnf",
          "author": "just-dg",
          "text": "It’s unfortunately normal, even in larger companies.\n\nThere’s a description people use called “founding AE” (or founding + whatever the role is) which implies selling, building process, probably helping build a team, etc. That’s more common in new startups, probably with a similar FTE count to your company. There’s typically some meaningful equity (of course only really matters when the company successfully exits) to align incentives.\n\n^^ This is what your actual role sounds like - could be wrong. You can use this if you look for a role elsewhere and it should resonate.\n\nWhich do you care about more - authority or compensation?\n\nYou could open up a conversation about comp - equity, higher commission with higher targets, etc. It doesn’t need to be dependent on becoming a director or manager.\n\nYou could also ask for more details on when they see the need coming. If you’re involved in hiring, you will probably have a decent idea. 3-5 direct reports is a reasonable point to need it.\n\nYou could ask for more explicit authority but I wouldn’t do that without having the pay behind it. They are incentivized to do this. It’s a business, and the objective is to get the most ROI out of their capital as possible - you are human capital.\n",
          "score": 1,
          "created_utc": "2026-02-21 15:10:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pgr31",
          "author": "kubrador",
          "text": "you're doing the job for free, they're just not calling it that yet. the \"prove it first\" thing works when there's actual growth to show. if you're hiring your second rep and he's still ramping, you haven't proven the model scales yet, which is probably their (dumb) logic.\n\n\n\npush harder, but frame it differently: \"here's what director-level work costs in the market, here's what i'm already doing, pick a number or i'm job searching\". vague timelines get you nowhere.",
          "score": 1,
          "created_utc": "2026-02-22 02:32:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o72tu9a",
          "author": "itsdrmario515",
          "text": "You need to be director with manager / contributor roles",
          "score": 1,
          "created_utc": "2026-02-24 03:59:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rc73h2",
      "title": "Built a UK app for private money pools (ROSCAs) but I am getting lost!",
      "subreddit": "fintech",
      "url": "https://i.redd.it/npou6o1ow5lg1.png",
      "author": "EMPTY-BOX-044",
      "created_utc": "2026-02-23 03:55:05",
      "score": 4,
      "num_comments": 5,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1rc73h2/built_a_uk_app_for_private_money_pools_roscas_but/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6xknai",
          "author": "schepter",
          "text": "Here's some harsh truths you asked for at the bottom.\n\nHow did you get so far into your app development before validating the core idea of holding funds into an escrow account. This should have been done as part of your MVP or discovery phase. It would've saved you weeks or months making the app and backend infrastructure.\n\nHow are you handling building their credit score and have you made the appropriate connections for reporting it? Usually in finance there's a lot of regulatory requirements for local regions so I'm hoping you've done that at least (worried you haven't since you didn't validate your escrow issue).",
          "score": 2,
          "created_utc": "2026-02-23 10:56:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6yf994",
              "author": "njbmartin",
              "text": "Ultimately, this. You can pour your heart and soul into building something that solves a real problem, but doing the research first would have saved you the heartache. Finance is heavily regulated in the UK, and what you’re essentially trying to build is a “savings account” and would require partnering with an existing Electronic Money Institution partner.\n\nFor the “credit building” aspect, you’re probably looking at something similar to Loqbox, which would require you to be a credit broker and have appropriate regulations in place or require you to partner with. You would have to provide “credit” in order for you to report payments to credit reference agencies.\n\nWithout serious funding behind you, it will be impossible to get the support you need to make this work.",
              "score": 2,
              "created_utc": "2026-02-23 14:27:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7116j0",
                  "author": "EMPTY-BOX-044",
                  "text": "Thank you both for the honesty and the reality check. You are 100% right.\n\nI fully admit my mistake🤷‍♂️  \nI didn't do enough deep research on the compliance side before I started building. My motivation blinded me a bit 🙃. I genuinely believed this would be a massive, legal, and highly convenient solution for people. Seeing that Stripe provided almost everything out of the box (Payment Gateway + seamless KYC via Connect Express) made me rush into development, assuming they would naturally support the escrow-like flow for this use case.\n\nThat being said, I have absolutely zero regrets. Catching this critical flaw *before* launching and touching real user money is a huge win for me.\n\nThis roadblock definitely isn't going to stop me. Right now, I am waiting on replies from a few BaaS providers to see if I can partner with them and legally operate under their regulatory umbrella for the safeguarding piece. If I find the right provider, I have absolutely no problem rewriting the backend and adjusting the code to integrate their system, as long as it guarantees user funds are safe and makes the platform a true success.\n\nAs for the credit score feature, you're entirely right about the regulatory headache. Since I'm doing all that alone, I will push that to future updates once the core safeguarding is fully secured with the right provider.\n\nThanks again for the insights, it saved me from a massive disaster!",
                  "score": 1,
                  "created_utc": "2026-02-23 21:54:30",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o71ys5j",
          "author": "swemming",
          "text": "Would you be interested in doing this for the US?",
          "score": 2,
          "created_utc": "2026-02-24 00:55:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o72cyne",
              "author": "EMPTY-BOX-044",
              "text": "100% yes! In fact, the US was a massive part of the roadmap from day one.\n\nMy original plan was to launch in the UK first to establish a really strong PoC and validate the model, and then immediately flip the switch to open it up in the US right after.\n\nThat’s actually the main reason I fell into the Stripe trap in the first place. I built the entire backend around Stripe Connect because I thought it would give me a seamless, out-of-the-box way to scale across both the UK and the US simultaneously without having to rebuild the infrastructure. It was a huge letdown when I realised their TOS strictly prohibits holding funds in escrow for this type of flow in both regions.\n\nBut launching in the US is still an absolute top priority for me once I secure the right BaaS/safeguarding partner",
              "score": 1,
              "created_utc": "2026-02-24 02:17:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r9ojs5",
      "title": "ION group LDP superday advice",
      "subreddit": "fintech",
      "url": "https://www.reddit.com/r/fintech/comments/1r9ojs5/ion_group_ldp_superday_advice/",
      "author": "Former-Screen8870",
      "created_utc": "2026-02-20 07:04:57",
      "score": 3,
      "num_comments": 8,
      "upvote_ratio": 0.81,
      "text": "Hey!! Has anyone attended the ion group rotational analyst ldp superday in the past? Got shortlisted for it but have no idea what to expect or how to prepare, any help would be greatt!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1r9ojs5/ion_group_ldp_superday_advice/",
      "domain": "self.fintech",
      "is_self": true,
      "comments": [
        {
          "id": "o6yiejv",
          "author": "Chemical_Anybody9772",
          "text": "Which regional superday are you attending? \n\n",
          "score": 1,
          "created_utc": "2026-02-23 14:44:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ypt8v",
              "author": "Former-Screen8870",
              "text": "In hong kong",
              "score": 1,
              "created_utc": "2026-02-23 15:22:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6yqate",
                  "author": "Chemical_Anybody9772",
                  "text": "ah good luck... I also applied in hk but I didn't get any email... seems like I am ghosted :(",
                  "score": 1,
                  "created_utc": "2026-02-23 15:24:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o714x7d",
          "author": "bakhshish10",
          "text": "hey congrats!! how close to the superday did they send invites, like 2-3 weeks?",
          "score": 1,
          "created_utc": "2026-02-23 22:12:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o71t6zq",
              "author": "Former-Screen8870",
              "text": "Thanks! Also around 4 weeks",
              "score": 1,
              "created_utc": "2026-02-24 00:24:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r9iywy",
      "title": "Does anyone experience long (business) customer onboarding?",
      "subreddit": "fintech",
      "url": "https://www.reddit.com/r/fintech/comments/1r9iywy/does_anyone_experience_long_business_customer/",
      "author": "Icy_Tour6309",
      "created_utc": "2026-02-20 02:19:15",
      "score": 3,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "I’m curious to hear if anyone is facing this problem. If not, how are you currently handling business customer onboarding? What tools are you using?\n\nWe’re building AI agents for AML and are looking for fintech startups struggling with KYB. We’re offering a free partnership to help streamline onboarding in exchange for feedback.\n\nCriteria to qualify:\n\n* You have at least 2 AML or compliance analysts\n* You primarily onboard businesses, not individuals\n* You struggle with manual document reviews\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1r9iywy/does_anyone_experience_long_business_customer/",
      "domain": "self.fintech",
      "is_self": true,
      "comments": [
        {
          "id": "o6cqho0",
          "author": "Smooth_Wishbone1755",
          "text": "Yeah our KYB process is a nightmare - takes us like 3-4 weeks minimum for complex corporate structures and our compliance team is drowning in docs",
          "score": 3,
          "created_utc": "2026-02-20 02:27:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6cqwdm",
              "author": "Icy_Tour6309",
              "text": "I'll DM you",
              "score": 2,
              "created_utc": "2026-02-20 02:29:31",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6dqkf8",
              "author": "Flimsy-Ball2017",
              "text": "Just curious, any AI tool involved in this KYB process? ",
              "score": 2,
              "created_utc": "2026-02-20 06:49:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6kvdon",
          "author": "Stup2plending",
          "text": "It's long for everyone. I work a little down the funnel from you in retention strategies like why a business onboards but then does not transact or takes 6 weeks to make their first transaction.\n\nLet's talk.",
          "score": 2,
          "created_utc": "2026-02-21 10:11:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6v3e7y",
              "author": "Icy_Tour6309",
              "text": "Thanks for sharing this. I just sent you a message!",
              "score": 1,
              "created_utc": "2026-02-22 23:46:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r844re",
      "title": "Vibe-coded tools in financial advisor ops: what guardrails are non-negotiable?",
      "subreddit": "fintech",
      "url": "https://www.reddit.com/r/fintech/comments/1r844re/vibecoded_tools_in_financial_advisor_ops_what/",
      "author": "obchillkenobi",
      "created_utc": "2026-02-18 14:16:00",
      "score": 3,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "I’m seeing more teams vibe code  internal tools with AI (Replit/Cursor/ChatGPT-style), the kind that usually work well in a demo.   \n  \nFrom conversations with a few advisor-ops teams, a pattern I see is  that drafts + pre-flight checks are fine, but anything that starts behaving like a system of record (or complex workflows) is where things get messy.\n\nExamples  (from advisor/RIA ops POV):  \n\\- billing/fee checks (“does billed rate match the signed schedule/discounts?”)  \n\\- marketing/comms pre-checks (flag promissory language / missing disclosures  \n\\- onboarding/paperwork preflight \n\nFor anyone who has shipped similar tools in production:  \n\\- what’s safe to build this way vs a hard no?  \n\\- what guardrails actually mattered (approvals, evidence/logging, tests/goldens, access control, monitoring/rollback)?  \n  \nLooking for real patterns and any lessons you can share.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1r844re/vibecoded_tools_in_financial_advisor_ops_what/",
      "domain": "self.fintech",
      "is_self": true,
      "comments": [
        {
          "id": "o62dimm",
          "author": "kubrador",
          "text": "the honest answer is \"all of it breaks the second a client calls their lawyer.\" you're basically asking which parts of compliance can be handled by vibes and the answer is none of them.\n\nthat said, the actual pattern i've seen work: treat ai-assisted tools like a really good intern who needs to get everything initialed. drafts and flags are fine because humans still decide. the moment it starts \\*deciding\\* (auto-billing adjustments, regulatory sign-offs, document finalization) you've moved from \"helpful\" to \"liability with a gpu.\"\n\nthe guardrails that mattered in practice were dumber than they sound. audit trails matter way more than you think because regulators don't care if your claude instance was right 99% of the time, they care that you can prove what happened. version control for prompts. separate staging/prod entirely. and honestly, the access control piece is underrated; not letting the tool touch prod databases",
          "score": 3,
          "created_utc": "2026-02-18 15:15:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6314g0",
              "author": "KimchiCuresEbola",
              "text": "Using AI to build proper system much more quickly with good engineers and domain experts = OK\n\nThrowing everything into AI and having it be \"the system\" != OK",
              "score": 1,
              "created_utc": "2026-02-18 17:03:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o62bgqz",
          "author": "oedividoe",
          "text": "Partner with teams/startups who are willing to co-build and co-evolve in AI ",
          "score": 2,
          "created_utc": "2026-02-18 15:06:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6a9hh1",
          "author": "whatwilly0ubuild",
          "text": "The \"works in demo\" to \"works in production\" gap is exactly where vibe-coded tools fall apart in regulated contexts. The pattern you're seeing is correct, and the line you drew around system of record behavior is roughly the right place.\n\nWhat's generally safe to build this way. Read-only checks and flagging are the sweet spot. Fee schedule validation that surfaces discrepancies for human review, marketing copy scanners that flag potential compliance issues, document completeness checklists before submission. These tools can be wrong without catastrophic consequences because a human makes the final call. The AI is doing triage, not decisions.\n\nWhat's a hard no. Anything that writes to a system of record without human approval. Anything that generates client-facing content that goes out without review. Anything that calculates fees or billing amounts that flow directly into invoices. The moment the tool's output becomes the source of truth rather than an input to human judgment, you've crossed into territory where vibe-coded quality isn't acceptable.\n\nThe guardrails that actually mattered for our clients shipping similar tools. Logging everything with immutable audit trail was non-negotiable. Not just what the tool output, but what inputs it received, which version of the logic ran, and what the human did with the recommendation. When a regulator asks why a disclosure was missing, \"the AI said it was fine\" isn't an answer. Evidence that a human reviewed and approved is what matters.\n\nApproval gates with explicit sign-off are essential for anything beyond pure advisory output. The tool flags, a human reviews, the human clicks approve, that approval is logged. This sounds obvious but teams skip it because it adds friction, then regret it when something goes wrong.\n\nGolden test suites covering known edge cases saved teams from embarrassing failures. Vibe-coded tools break in weird ways when inputs drift from what the developer tested against. A set of regression cases that must pass before any deployment catches the obvious stuff.\n\nAccess control scoped tightly from day one. Internal tools tend to accumulate permissions over time. Start restrictive.\n\nRollback capability that's actually tested. When the tool starts producing garbage, can you revert in minutes or does it require an engineer to debug and redeploy?\n\nThe monitoring question is underrated. Most teams don't instrument internal tools well, so they don't notice degradation until someone complains. Even basic metrics like \"flagging rate over time\" catch model drift or logic bugs before they become incidents.\n\nThe honest pattern is that vibe-coded tools work fine for the 80% case but regulated environments are defined by the 20% edge cases that matter disproportionately.",
          "score": 2,
          "created_utc": "2026-02-19 18:32:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6h7s2m",
          "author": "Ok-Office-6564",
          "text": "Hey u/obchillkenobi , we are using this guy [https://github.com/LerianStudio/ring](https://github.com/LerianStudio/ring) to set all the guard rails we believe we need. ",
          "score": 1,
          "created_utc": "2026-02-20 19:35:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7x65y",
      "title": "What actually slows down a fintech MVP the most?",
      "subreddit": "fintech",
      "url": "https://www.reddit.com/r/fintech/comments/1r7x65y/what_actually_slows_down_a_fintech_mvp_the_most/",
      "author": "Sarah_Shephard",
      "created_utc": "2026-02-18 08:05:57",
      "score": 3,
      "num_comments": 9,
      "upvote_ratio": 1.0,
      "text": "From what I’ve been seeing across different fintech product builds, the biggest delays aren’t caused by feature development they usually come from things that aren’t visible in the initial product plan.\n\nThe most common ones:\n\n• KYC & AML flow complexity  \n• compliance requirements changing mid-build  \n• payment/banking API limitations  \n• handling real-time transaction states  \n• security architecture decisions made too late\n\nA lot of teams plan timelines based on UI + core features, but in fintech, the non-visible layers take equal (or more) effort.\n\nFor people here who’ve worked on fintech products\n\n  \nWhat ended up impacting your launch timeline the most?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1r7x65y/what_actually_slows_down_a_fintech_mvp_the_most/",
      "domain": "self.fintech",
      "is_self": true,
      "comments": [
        {
          "id": "o61159m",
          "author": "KimchiCuresEbola",
          "text": "It's always lack of domain knowledge that hinders fintech startups from what I've seen.",
          "score": 3,
          "created_utc": "2026-02-18 10:07:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6168od",
          "author": "kubrador",
          "text": "banking integrations will humble you faster than any feature ever could. we planned 6 weeks, the bank's api docs were \"call us\", we launched 4 months later wondering why we didn't just build a sandwich shop instead.",
          "score": 2,
          "created_utc": "2026-02-18 10:52:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63eak3",
              "author": "kayandrae",
              "text": "I've been part of an integration that took 1 year 3 months.\nThe docs said one thing, the apis did another thing. Took many many months to properly edge case this particular company",
              "score": 1,
              "created_utc": "2026-02-18 18:02:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o61bbf1",
          "author": "Patelsiddhi",
          "text": "Most fintech MVPs get slowed by compliance + integrations: KYB/KYC, bank/payment rails, vendor contracts, and edge-case testing . Building UI is rarely the bottleneck.",
          "score": 2,
          "created_utc": "2026-02-18 11:34:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o680fb9",
          "author": "Organic_Act7411",
          "text": "Compliance requirements changing mid-build  this one absolutely wrecked my timeline. Thought I had MiCA figured out, started building, then realized halfway through that regulators don't just want \"the AI flagged it\" they want the exact article of law cited. Had to rebuild the entire decision layer. The domain expert comment is real. I came from financial crime investigations and still underestimated how different \"technically works\" is from \"passes an audit. Biggest lesson: whatever time you budget for compliance infrastructure, triple it. It's invisible work that nobody sees but if you skip it early, you're retrofitting later which is 10x worse. Also learned the hard way that \"we'll make it compliant later\" is basically choosing pain.",
          "score": 1,
          "created_utc": "2026-02-19 11:01:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dmvbf",
              "author": "crazylipid",
              "text": "In our case incompetence of Lithuanian Product Owners, business decided to keep them close where they have license with BoL. CEO approves sadly and defends but since 4 years it is all the same, because they don’t have a clue what they do and as colleague in earlier post provided there are multiple areas and regulations to consider properly.",
              "score": 1,
              "created_utc": "2026-02-20 06:16:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6dryg8",
                  "author": "Organic_Act7411",
                  "text": "That's brutal. 4 years of technical debt because product owners didn't understand the regulatory landscape.The \"we'll figure it out later\" mentality in fintech is what kills most projects. By the time you realize the gap, you're either rebuilding everything or operating with a Frankenstein system that barely passes audits.\n\nThe CEO defending them is the worst part means the problem won't get fixed until something breaks publicly.Out of curiosity: are they at least working with external compliance consultants or completely winging it internally?",
                  "score": 1,
                  "created_utc": "2026-02-20 07:01:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o692hqe",
          "author": "SellSideShort",
          "text": "This is why I hate the word *Fintech.*   \n  \nDifferent areas of finance are regulated in different ways, by different entities, finance isnt the same across the board.\n\nLets say you get all the regulatory and legal aspects sorted, you'll have a hell of a time getting real customers.",
          "score": 1,
          "created_utc": "2026-02-19 15:05:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rd27g4",
      "title": "Are corporate cards legit / worth it?",
      "subreddit": "fintech",
      "url": "https://www.reddit.com/r/fintech/comments/1rd27g4/are_corporate_cards_legit_worth_it/",
      "author": "RocheleAveruiz",
      "created_utc": "2026-02-24 02:22:23",
      "score": 3,
      "num_comments": 1,
      "upvote_ratio": 0.72,
      "text": "I'm not a fintech savant but I know my way around API's and tools. One topic that's come up a lot this year with other early stage founders raising post seed has been corporate cards. I know there are huge players in this space like ramp, etc. that offer corporate cards with expense management features built in, which I can see how it facilitates spend tracking. Any founders here using corporate cards who wouldn't mind sharing insights? When did you start looking into them and what made it the right time. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/fintech/comments/1rd27g4/are_corporate_cards_legit_worth_it/",
      "domain": "self.fintech",
      "is_self": true,
      "comments": [
        {
          "id": "o72n9nj",
          "author": "alicantetocomo",
          "text": "You want to build one or just use one?",
          "score": 2,
          "created_utc": "2026-02-24 03:18:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}