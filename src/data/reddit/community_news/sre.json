{
  "metadata": {
    "last_updated": "2026-02-26 03:06:08",
    "time_filter": "week",
    "subreddit": "sre",
    "total_items": 10,
    "total_comments": 72,
    "file_size_bytes": 75905
  },
  "items": [
    {
      "id": "1r9uw96",
      "title": "Multi cloud was supposed to save us from vendor lock in but now we're just locked into two vendors",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1r9uw96/multi_cloud_was_supposed_to_save_us_from_vendor/",
      "author": "NoBet3129",
      "created_utc": "2026-02-20 13:07:57",
      "score": 128,
      "num_comments": 24,
      "upvote_ratio": 0.98,
      "text": "CTO convinced leadership we needed multi cloud because aws would \"definitely raise prices\" or something. Nobody really thought through what this meant for the team managing it.\nHalf our stuff runs on aws api gateway, half on gcp api gateway and they work completely differently, aws does resource policies, gcp does iam, keeping security consistent across both is genuinely impossible. When something breaks we're checking cloudwatch and cloud monitoring separately trying to figure out which platform is the problem and our devs are pissed because they had to learn two completely different systems that do the exact same thing.\nWe've probably spent more time dealing with this mess than we ever would've spent migrating off aws if we actually needed to. The ironic part is now we're stuck with both platforms instead of one so... mission accomplished I guess?\nDid anyone else do this and actually make it work or did we just completely botch the implementation?",
      "is_original_content": false,
      "link_flair_text": "DISCUSSION",
      "permalink": "https://reddit.com/r/sre/comments/1r9uw96/multi_cloud_was_supposed_to_save_us_from_vendor/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o6f12iq",
          "author": "taleodor",
          "text": "The idea to avoid vendor lock in is to only use things between clouds that are essentially the same (sort of largest common denominator). So yes, your implementation seems botched and you should get back to drawing board.",
          "score": 41,
          "created_utc": "2026-02-20 13:18:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6grxx3",
              "author": "pokomokop",
              "text": "k8s, DNS/Load Balancing, blob storage(with the proper abstractions written in code), and (somewhat) managed databases are the services I feel are quite easy to migrate between CSP's. Access Policies and security are a bit tricky as they're definitely not one to one, but if you're already in multiple clouds those sort themselves out. Your serverless technologies is where you start to see tight coupling, at least in my experience.\n\nEDIT: Just seeing OP specifically talking about CloudWatch and what not. Disclaimer as I work at Grafana Labs, this is where having a centralized tool helps. You're not going to bridge the gap between monitoring solutions between the hyperscalers.",
              "score": 14,
              "created_utc": "2026-02-20 18:22:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6f0cn0",
          "author": "AmazingHand9603",
          "text": "Multi cloud sort of works if you have super strict abstraction layers and your ops team is big enough to handle the extra complexity. Most places, even big ones, end up with duplicated effort and everyone slightly irritated all the time. The theory is nice, but unless you’re at a scale where you can throw a separate team at each provider, it ends up being more pain than it’s worth. We ended up quietly letting one cloud become the main one over time, and honestly nobody cared except leadership, who eventually forgot why we did it in the first place.",
          "score": 51,
          "created_utc": "2026-02-20 13:14:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7b1qyu",
              "author": "kverma02",
              "text": "This is spot on. Multi-cloud works if you have strict abstraction, but most teams end up with 'double the operational overhead, half the expertise.'\n\nWe've seen this pattern repeatedly - teams think they're avoiding vendor lock-in but end up with operational lock-in instead. Different monitoring tools, different IAM models, context-switching during incidents.\n\nThe breakthrough we're seeing is treating observability as the abstraction layer - unified view across both clouds, correlate signals regardless of where workloads run, while keeping data local in each environment. \n\nSuddenly multi-cloud becomes manageable because you aren't managing each cloud separately.",
              "score": 2,
              "created_utc": "2026-02-25 11:03:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6f2s6c",
          "author": "ufukty",
          "text": "mobility makes more sense than multi cloud to me. having configurations written down as terraform, ansible or bash scripts is enough of documentation to ease future migration",
          "score": 14,
          "created_utc": "2026-02-20 13:28:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f7v9f",
              "author": "Creative-Dentist-383",
              "text": "Additionaly, use as many “common services” as possibles. Migrating from EC2 to Azure VMs is a lot easier than some very specialized service. ",
              "score": 11,
              "created_utc": "2026-02-20 13:55:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6fcq3e",
          "author": "MordecaiOShea",
          "text": "Building to open standards rather than multicloud is the solution you need. It is why we use EKS, not ECS. And managed Kafka, not SQS. And Postgres Aurora, not DynamoDb.",
          "score": 11,
          "created_utc": "2026-02-20 14:21:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f3f9x",
          "author": "ninjaluvr",
          "text": "Multi-cloud without thought and intention is a disaster as you've witnessed first hand. Multi-cloud with abstraction can be beautiful. But if you don't have the expertise to design, build, and manage it, you should stick with one vendor.",
          "score": 8,
          "created_utc": "2026-02-20 13:31:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gjypf",
          "author": "kellven",
          "text": "AWS is one of the few vendors I can think of in recent time that hasn’t really jacked up prices. Unless your org is absolutely massive , or you directly compete with Amazon, I think the lock-in cost of AWS is worth the benefit. \n\nIt’s a bit wild to me that your CTO could sell that large of a project purely on the ghosts of prices future. He either made the coffee is for closers speech or your leadership has no back bone.",
          "score": 5,
          "created_utc": "2026-02-20 17:46:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f8v5z",
          "author": "faajzor",
          "text": "Honestly that is an issue of poor planning on the engineering side.\n\nUse common tools (k8s?) or try to abstract some of the services. Centralize logging and monitoring, invest in tooling, etc.",
          "score": 5,
          "created_utc": "2026-02-20 14:01:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f4gz9",
          "author": "borg286",
          "text": "Would you mind sharing what you mean by the API gateways working differently?",
          "score": 4,
          "created_utc": "2026-02-20 13:37:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6htkl7",
          "author": "manauwar1212",
          "text": "The only way this works is if you stop trying to manage each cloud separately. Put everything behind one api layer that handles the routing and policies. We use gravitee with aws and azure backends, and gateway stays consistent, cloud providers just become dumb compute and at least devs only learn one system.",
          "score": 2,
          "created_utc": "2026-02-20 21:22:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fqe21",
          "author": "amarao_san",
          "text": "Multicloud is hard. I would say, the best way for multicloud is to have baremetal option. If you can rebuild your production with some baremetal servers with some bgp, you are multicloud by definition, because you can run on any infra.\n\nnext, you can cut some clumsy implemented functions into vendor provided, with baremetal fallback. In this case you get best for reasonable price, because unreasonable price just been replaced with baremetal.\n\nBut it's hard, as you need to integrate something as replacement for all fancy services providers gives you, or give up on them entirely.\n",
          "score": 3,
          "created_utc": "2026-02-20 15:29:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hkukl",
          "author": "LongjumpingGuava5656",
          "text": "Best title ever",
          "score": 1,
          "created_utc": "2026-02-20 20:38:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hu6w3",
          "author": "[deleted]",
          "text": "multi cloud only makes sense if you have a dedicated team for it. for most companies it just doubles the work with no real benefit.",
          "score": 1,
          "created_utc": "2026-02-20 21:25:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6i79um",
          "author": "curious_maxim",
          "text": "Multi-cloud is good in three cases: 1) you actually need to abandon one and switch to another. That’s typically related to competition concerns (Amazon, Microsoft and Google do own bunch of companies who might be competing with some), or significant savings (think tens of millions of dollars a year scale); 2) you use them complimentary as some services can be better at one vendor and others - at second; 3) same as 2) but from price perspective - think mid-size company with plenty of network traffic.\n\nMaintaining multi-cloud redundancy is a huge time-waster in other cases.",
          "score": 1,
          "created_utc": "2026-02-20 22:31:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ktx3c",
          "author": "Its_Sunaina_",
          "text": "Your leadership read some consultant presentation about vendor lockin without thinking it through. Multi cloud makes sense for compliance or geo stuff but not just because you're scared of price increases.",
          "score": 1,
          "created_utc": "2026-02-21 09:57:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lfztn",
          "author": "Ordinary-Role-4456",
          "text": "Honestly, the only folks I’ve seen pull off multi-cloud well are the massive companies with specialized teams for each platform, so no one is having to become a universal expert. Most of the time, though, it just turns into twice the pain for no real gain.   \n  \nUnless you’re building for some serious redundancy needs or have regulatory reasons, a single cloud keeps things way simpler. ",
          "score": 1,
          "created_utc": "2026-02-21 13:11:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6q0jn4",
          "author": "surpremebeing",
          "text": "Kubernetes and VMware are the only two technologies today that avoid cloud lock. As soon as you adopt specific cloud native features, they have you locked.",
          "score": 1,
          "created_utc": "2026-02-22 04:50:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70nxco",
          "author": "Mundane_Discipline28",
          "text": "i get why most people here are saying multi-cloud is a mistake. and honestly when you're managing each provider separately it is. two IAM configs, two monitoring stacks, two deploy pipelines. that's not multi-cloud, that's just double the work.\n\nmy experience was different tho. we use a platform that abstracts the cloud layer into one interface (Quave ONE). deploy to AWS or GCP from the same place, same workflow. when we needed to move some workloads to GCP for pricing it wasn't a migration project, just a config change.\n\nthe thing is we're not \"managing two clouds.\" we're managing one platform that runs on multiple providers. if we decided to go all in on AWS tomorrow we could do that without changing anything.\n\nnot saying multi-cloud is for everyone. but OP's case sounds more like bad implementation than bad strategy",
          "score": 1,
          "created_utc": "2026-02-23 20:49:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o794ufr",
          "author": "KiritoCyberSword",
          "text": "Just make it a container, regardless if its k8s, or other containers platforms, you can migrate it easily",
          "score": 1,
          "created_utc": "2026-02-25 02:14:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jrq74",
          "author": "kennetheops",
          "text": "I'm actively working on a platform to help with a lot of this type of stuff. I don't know if you will ever be interested in collaborating with early tools, but I ran into this scenario a couple of years back and started working on an AI tool to cross-collaborate across clouds for both cost or just having a better understanding, honestly. I absolutely despise Terraform anything once you start getting pretty large deployments.",
          "score": 0,
          "created_utc": "2026-02-21 04:16:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rayuwn",
      "title": "What metrics actually matter? Lessons shared after a recent 47-minute outage",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1rayuwn/what_metrics_actually_matter_lessons_shared_after/",
      "author": "Agitated-Alfalfa9225",
      "created_utc": "2026-02-21 18:39:18",
      "score": 41,
      "num_comments": 20,
      "upvote_ratio": 0.89,
      "text": "Saw a team recently share a breakdown of a 47-minute checkout outage that could have been caught much earlier. Thought it was worth summarizing because a lot of people here ask what application monitoring metrics actually matter. The issue started with checkout services returning 500s around 2am. Initial investigation focused on CPU and memory at the pod level. Everything looked healthy from an infrastructure perspective, which ended up being a distraction. Once traces were reviewed, it became clear that payment gateway calls were timing out at the default 30s. The root cause turned out to be an expired certificate on an upstream dependency.\n\n\n\nWhat reportedly helped identify the issue:\n\n\\- A service map that immediately showed the payment gateway dependency in a degraded or red state\n\n\\- A p99 latency dashboard that spiked from about 200ms to 30s\n\n\\- Distributed traces showing the exact span where requests were hanging\n\n\n\nWhat did not help:\n\n\\- Basic infra metrics. CPU and memory looked fine throughout\n\n\\- Alerting configured only around error rates crossing 5%\n\n\n\nOne takeaway from the discussion was that infrastructure level health can look completely normal while user-facing latency is collapsing because of a dependency. The team is now adding dependency-specific health checks, defining SLOs for upstream services, and lowering error rate alert thresholds. Curious what others keep on their war room dashboards during incidents. Are you prioritizing latency percentiles, dependency maps, synthetic checks, something else? It seems like a lot of monitoring setups still focus heavily on infrastructure signals rather than service-to-service behavior.\n\n",
      "is_original_content": false,
      "link_flair_text": "DISCUSSION",
      "permalink": "https://reddit.com/r/sre/comments/1rayuwn/what_metrics_actually_matter_lessons_shared_after/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o6nhfoo",
          "author": "calibrono",
          "text": "Alerting on P95/99 (and even P50) + alerting on dependency metrics (error rate of requests to a dependency service) is very helpful.",
          "score": 13,
          "created_utc": "2026-02-21 19:40:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ninhg",
          "author": "Mysterious_Salt395",
          "text": "Tools like Datadog often come up in these conversations because they correlate traces, logs, and metrics in one place. From what I’ve seen discussed, having that cross-signal visibility can make a big difference during incidents like this. Service maps in particular get mentioned a lot as helpful for spotting failing dependencies quickly.",
          "score": 9,
          "created_utc": "2026-02-21 19:46:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6nmxmp",
              "author": "FormerFastCat",
              "text": "Careful, any mention of Datadog or Dynatrace on this sub gets insta down voted because building an observability platform from scratch with OTEL and log parsing is 100% the way to go and obviously best practice. /S",
              "score": 7,
              "created_utc": "2026-02-21 20:08:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6qfkha",
                  "author": "kabrandon",
                  "text": "You’re not really building a platform from scratch though are you. It’s a stack of FOSS tools, you run them, and once you’ve done it once you can do it a hundred times if your deploy manifests are in git.",
                  "score": 3,
                  "created_utc": "2026-02-22 06:56:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6o462m",
                  "author": "GrogRedLub4242",
                  "text": "FOSS ideal, not necessarily OTEL, the latter has anti-patterns and risks and is relatively young. I see the argument to avoid DataDog, Splunk and similar when you can",
                  "score": 1,
                  "created_utc": "2026-02-21 21:40:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ptwch",
          "author": "Hi_Im_Ken_Adams",
          "text": "Why didnt you start with traces?    Infrastructure performance is what you drill down into, not what you start looking at first.  \n\n\nTraces tell you where the problems is.  Simple as that.",
          "score": 3,
          "created_utc": "2026-02-22 04:02:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x75wh",
              "author": "SWEETJUICYWALRUS",
              "text": "Scaling policies usually aren't set up right in the first place or drift out of the requirements with time. So people tend to head there first out of gut reaction. \n\nJust happened to us. Everyone was panicking about ensuring ECS scaled up. Meanwhile I'm the only one that saw 8000 500 errors due to max db connections because someone set the scaling to 10% max cpu utilization and max tasks to 999",
              "score": 1,
              "created_utc": "2026-02-23 08:45:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6nk87j",
          "author": "SudoZenWizz",
          "text": "From my experience you should map all dependencies of the app. Cpu/ram/disk are not sufficient and having other services and metrics will give some insight.\nFor some web/mobile apps we have in checkmk monitoring all requests to api’s or external website that the application does mapped in health checks with additional http active checks.\nLastly, we map the overall service as BI and when something is not working properly we know what’s the culprit.\nAdd log monitoring for specific keywords and this can improve source of the issue.\nFor full service monitoring and performance you can also add syntethic montoring woth robotmk.",
          "score": 1,
          "created_utc": "2026-02-21 19:54:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6o3tuy",
          "author": "GrogRedLub4242",
          "text": "all signal helps. the more the merrier. because any signal helps paint the space of potential contributing causes. in the case you described either it was a young/immature monitoring setup or young/novice crew\n\nin the next incident it might be a diff mix of signals which identify the root/prox cause.",
          "score": 1,
          "created_utc": "2026-02-21 21:38:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ol8ob",
              "author": "baezizbae",
              "text": "> all signal helps. the more the merrier.\n\nBe *very* careful with this. \n\nI understand this *in spirit* but *in practice* it is how you end up paying an arm and a leg for observability (either to a vendor or to work-hours spent building and operating your observability moat). It's been a consistent and repeat experience of mine that when you start yanking more and more signals from a system, people will begin to want those signals to tell them more and more \"just in case\" something goes wrong, not when something has *actually* gone wrong and you end up with a bunch of people suffering from alert fatigue",
              "score": 2,
              "created_utc": "2026-02-21 23:15:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6o50u7",
          "author": "curious_maxim",
          "text": "Do you monitor  key integrations with logical smoke tests? - to alert on them even before customer executes full flow.",
          "score": 1,
          "created_utc": "2026-02-21 21:44:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6o8nkl",
          "author": "borg286",
          "text": "Incoming error ratio and latency and outgoing error ratio and latency are the big ones.",
          "score": 1,
          "created_utc": "2026-02-21 22:03:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pknrj",
          "author": "rnjn",
          "text": "depends on issues really, it would be ill advised to use a cookie cutter approach. as usage grows, and deployment volume grows, one sees many different type of problems. you could create a summary view one way, and an issue will break assumptions. what i have seen work is to ensure each issue/incident as feedback and do postmortems well. build a summary and drill-down approach, build very few summary views that can help anyone understand what's happening. and then they can drill down thru multiple dimensions (including infra) to understand why its happening. keep these two categories separate, and guard summaries well.   \n  \nthe outcome could be latency profiles coupled with an infra map and a service map, or it could be a tabular view - depends on the software being monitored and the team responsible for the SLOs.  I even have SSL cert expiry as part of mine (because of what i am responsible for), you should share this with the owner of your upstream dependency (https://docs.base14.io/blog/make-certificate-expiry-boring)",
          "score": 1,
          "created_utc": "2026-02-22 02:58:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qa5nd",
          "author": "raymond_reddington77",
          "text": "- A p99 latency dashboard that spiked from about 200ms to 30s\n\nWhat type of latency?",
          "score": 1,
          "created_utc": "2026-02-22 06:07:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70q1w2",
          "author": "Muthakkir",
          "text": "I hate to say it but synthetic checks are helpful in this case specially if it's combined with distributed traces ",
          "score": 1,
          "created_utc": "2026-02-23 20:59:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bp74a",
          "author": "MonadEndofactor",
          "text": "Part of the problem here is assuming that an issue like that will be visible in CPU/memory usage, which it may not at all. Using dashboards with full metrics is something that helps, but is often ignored. The other thing is that you need a dashboard for application metrics (not infra metrics) and APM. These will quickly show latency spikes and will allow you to determine where. What NOT to do: don't avoid dashboards and rely on team members manually checking metric by metric (i've seen this under the excuse of \"you need to know which metric to check, dashboards are for the n00bs and then missing shit for several days). ",
          "score": 1,
          "created_utc": "2026-02-25 13:44:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1re6wm5",
      "title": "My SRE track for kubecon eu ‘26 (one ft. DOOM agents destroying clusters lol)",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1re6wm5/my_sre_track_for_kubecon_eu_26_one_ft_doom_agents/",
      "author": "cloudsommelier",
      "created_utc": "2026-02-25 07:39:10",
      "score": 32,
      "num_comments": 1,
      "upvote_ratio": 0.93,
      "text": "Hi hi,\n\nThere are 350+ talks in the KubeCon schedule, and I went through it looking for interesting/cool stories about reliability. I've been doing this for 4 editions, people seem to like it (and I def do lol)\n\nThese are my 6 favorite talks:\n\n**Airbnb: 1000 Services, 1 Year, 0 Downtime**  \nAfter a series of major outages in summer 2023, a five-person team migrated 1,000+ production services from regional to zonal Kubernetes clusters across a 3,000-engineer org with zero user-visible downtime.\n\n**What Survived Production: Operating Game Backends at Million-Player Scale** Futureplay Games, three engineers, millions of players. Talk is specifically about what failed, what stayed, and what proved essential. I like this format because it's honest about tradeoffs rather than presenting a perfect architecture.\n\n**Banking on Reliability: Cloud Native SRE Practices in Financial Services** Five years of SRE at a major Swiss bank, covering how SLOs drove cascading improvements and ending with a live debug session tracking down six 502s per million requests.\n\n**From Alert Fatigue to Self-Healing**  \nI'm skeptical of most \"AI for SRE\" talks but this one is, allegedly, running in production so I’m curious: one of Portugal's largest banks had bad alert fatigue and long MTTR across a multi-cloud platform. They built Crossplane control planes where LLM-powered composition functions automatically triage and remediate Kubernetes alerts. In a regulated banking environment. \n\n**Observing Chaos: Real-Time Monitoring of AI-Driven Kubernetes Destruction**  \nJosh Halley (Cisco) and Ricardo Aravena (CNCF) integrated ViZDoom and KubeDoom so reinforcement learning agents play **DOOM** (!!) *(*yes, the videogame lol*)* against live Kubernetes workloads. As the agents get better, the chaos gets more sophisticated: pods killed, services disrupted, infrastructure stressed. I have no idea what expect but I NEED to see it.\n\n**Kubernetes Autopsy: Live Debugging a Cluster Meltdown** Three engineers reconstruct a real cascading failure live: memory leak triggers OOMKill, destabilizes etcd, corrupts state, triggers a controller storm, brings down the control plane. Minute by minute, using actual logs, metrics, and traces.\n\nI wrote a bit more about each and added times/rooms/links to each in my full list in case you’re interested: [https://rootly.com/blog/the-unofficial-kubecon-eu-26-sre-track](https://rootly.com/blog/the-unofficial-kubecon-eu-26-sre-track)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1re6wm5/my_sre_track_for_kubecon_eu_26_one_ft_doom_agents/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o7ajzeb",
          "author": "WeekSubstantial6065",
          "text": "Great curation — that Kubernetes autopsy talk is basically my nightmare from last spring. We had a nearly identical cascade: memory leak in a sidecar → OOMKills → etcd getting hammered → API server timeouts → controller reconciliation storm. Took us 90 minutes to piece together what happened because we were SSH-ing into nodes one at a time pulling logs.  \n  \nThe thing that killed us wasn't the initial failure, it was the sequential debugging. By the time we'd checked three nodes manually, the problem had already propagated to twenty more. We ended up building a quick script to pull diagnostics from all nodes in parallel (journalctl, kubectl describe, process inspection) and that's when we finally saw the pattern.  \n  \nThat DOOM talk sounds absolutely unhinged in the best way. If the agents learn to target stateful workloads first I'm gonna lose it.",
          "score": 2,
          "created_utc": "2026-02-25 08:19:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9jrrk",
      "title": "Does any one deploy AI agents in prod.",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1r9jrrk/does_any_one_deploy_ai_agents_in_prod/",
      "author": "masterluke19",
      "created_utc": "2026-02-20 02:56:10",
      "score": 7,
      "num_comments": 16,
      "upvote_ratio": 0.69,
      "text": "With all Agent based discussion I have seen that there is major trust issue with AI Agents in prod. How do you ensure that the agents are secure. TBH I can’t imaging how they adapt in prod unless it’s different tools plugged in together. Multi model makes it more complex. How do you track those.",
      "is_original_content": false,
      "link_flair_text": "DISCUSSION",
      "permalink": "https://reddit.com/r/sre/comments/1r9jrrk/does_any_one_deploy_ai_agents_in_prod/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o6cw0oi",
          "author": "c0LdFir3",
          "text": "Fuck no, I have self respect.",
          "score": 17,
          "created_utc": "2026-02-20 03:00:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6cw7dm",
              "author": "masterluke19",
              "text": "Legend!",
              "score": 2,
              "created_utc": "2026-02-20 03:02:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6d4ggi",
          "author": "slashedback",
          "text": "Are developer’s laptops prod? If so yes tons of dangerous agents are now in prod lmao. IYKYK",
          "score": 11,
          "created_utc": "2026-02-20 03:55:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dip1n",
              "author": "masterluke19",
              "text": "If it’s serving anything public then yes",
              "score": 2,
              "created_utc": "2026-02-20 05:41:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6epbuj",
                  "author": "imdevin567",
                  "text": "I don't think that's what they meant. Developer laptops are usually considered prod-adjacent, because they can reach prod. Developers are almost certainly running agents locally, often with their own personal API keys, and often with little-to-no guardrails. You're probably already \"running agents in prod\" and don't even realize it. It's the wild wild west out there right now.",
                  "score": 4,
                  "created_utc": "2026-02-20 12:01:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ee9wv",
          "author": "glowandgo_",
          "text": "yeah, in my experience most teams don’t really deploy agents in prod the way marketing hype suggests. usually it’s workflows where the agent is orchestrating fixed tools, not making autonomous decisions.......the hard part is observability and guardrails. you need logging, validation layers, and clear rollback paths. multi-model setups just amplify that complexity, so a lot of prod deployments end up being more like supervised automation than true agents.",
          "score": 5,
          "created_utc": "2026-02-20 10:30:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f8l73",
              "author": "masterluke19",
              "text": "Finally someone validated what I felt. But do you thing the multi model system will be widely adopted for prod systems. I don’t mean the multi tool or multi workflow integration, actual prod servers.",
              "score": 1,
              "created_utc": "2026-02-20 13:59:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6refh3",
                  "author": "glowandgo_",
                  "text": "heyy wazuup! think multi model setups will grow, but mostly for routing and cost control. Small model for simple tasks, stronger one for deeper reasoning. That’s practical... Fully autonomous multi model systems in prod feel unlikely for most teams right now. The ops overhead and eval complexity is still pretty high.",
                  "score": 1,
                  "created_utc": "2026-02-22 12:22:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6dqokd",
          "author": "Federal_Ad7921",
          "text": "The trust concern is valid. Instead of layering more tools, focus on unified zero-trust runtime control. We’ve used AccuKnox’s agentless eBPF approach to monitor what AI agents actually read, write, and call, reducing data leakage risk significantly. It’s not a management fix, but strong runtime visibility is essential.",
          "score": 2,
          "created_utc": "2026-02-20 06:50:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lc5s1",
          "author": "JustAnAverageGuy",
          "text": "The shit people are just throwing over the fence into prod without realizing what those agents are actually capable of, and the glaring security holes, scares the fuck out of me.\n\nWhen you make the “software engineering” barrier as low as it is today, you enable people to build ridiculously dangerous things without them even understanding that’s dangerous, let alone why it’s dangerous or what the concerns are.\n\nThe newest astroturf bullshit I’m seeing in places like r/smallbusiness are these non-US folks coming in and trying to convince business owners that they can build them a website that will replace QuickBooks their CRM their job hosting software everything with just a simple website at half the cost of what they’re spending every year.\n\nSo now we suddenly have somebody who doesn’t know how to build a secure solution selling solution solutions to people who don’t know the right questions to ask to make sure that it’s a good secure solution…\n\nI really think this is gonna be really bad for a lot of organizations, post mom and pop businesses where they’re gonna get completely wiped out the first security breach. They have all the way up to the big enterprise organizations that just don’t understand what they’re doing with AI and they don’t have the right talent in place to help them do it in a safe way.\n\n",
          "score": 1,
          "created_utc": "2026-02-21 12:43:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70qzhr",
          "author": "Party-Major1956",
          "text": "Si yo despliego agente de IA muy confiables. Por  insultas infi@newinsurtechia/WhatsApp 11.2675.7243",
          "score": 1,
          "created_utc": "2026-02-23 21:04:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o71o9fe",
          "author": "vartheo",
          "text": "Limited AI Chat bot LLM's are the most that I see deployed when it comes to AI. I don't see free-will agents anywhere in prod for any real company",
          "score": 1,
          "created_utc": "2026-02-23 23:57:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gouht",
          "author": "Useful-Process9033",
          "text": "We deploy one in production for incident investigation. The key constraint: it's read-only. It can query your monitoring, pull logs, check deploy history, read runbooks, but it can't take any action. That single decision eliminates most of the trust problems people worry about.\n\nThe other thing that helps is scoping it tightly. It's not a general-purpose agent roaming your infra. It gets triggered by an alert or ticket, investigates that specific thing, and produces a summary. Fixed input, fixed output, predictable token budget.\n\nWe open sourced it if you want to poke at the approach: https://github.com/incidentfox/incidentfox",
          "score": 0,
          "created_utc": "2026-02-20 18:08:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rc9l84",
      "title": "RAG usage in SRE",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1rc9l84/rag_usage_in_sre/",
      "author": "CosmicKheerTornado",
      "created_utc": "2026-02-23 06:04:51",
      "score": 7,
      "num_comments": 11,
      "upvote_ratio": 0.69,
      "text": "Anyone using or any idea folks utilising RAGs in their SRE work. I am thinking of working on any but confused.\n\nLike : Postmortem Intelligence or Log & Monitoring Analysis.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1rc9l84/rag_usage_in_sre/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o6wtq3f",
          "author": "slayem26",
          "text": "We tried implementing these ideas. Problem happens when you can't tell hallucinations from facts.\n\nDeveloping a model and validations was a lot of effort, so for now it is shelved.",
          "score": 13,
          "created_utc": "2026-02-23 06:38:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o775wwg",
          "author": "WeekSubstantial6065",
          "text": "the biggest breakthrough for us was getting structured diagnostic data feeding into the RAG system rather than just dumping raw logs at it. We set up tooling that pulls metrics, traces, and events without needing to SSH into boxes directly (which our security team loves), and that structured context makes the RAG outputs way more actionable. Like instead of \"here's 10000 lines of logs,\" it's more \"here's the correlated anomalies across these three services at 2:14am.\"  \n  \nFor postmortems specifically, having that kind of organized timeline data means the RAG can actually surface relevant patterns from past incidents instead of just keyword matching. We've caught a few recurring issues that way that would've taken forever to spot manually.  \n  \nAnyway, thought I'd share since you're exploring this space. Happy to chat more about what's worked (and what hasn't) if you're interested.  \n  \nCheers",
          "score": 4,
          "created_utc": "2026-02-24 20:10:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xe38j",
          "author": "roy_malcolm",
          "text": "Have gotten great use out of hooking up Claude code to our logs & metrics (observe) via CLI. It can iterate on queries 30x faster than I can, much easier to find things",
          "score": 2,
          "created_utc": "2026-02-23 09:53:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o73z5pw",
              "author": "mr_sharmas",
              "text": "How do you limit the number to tokens processed by LLM? I mean.. to process logs of last 3 hours to know something is overwhelming.",
              "score": 1,
              "created_utc": "2026-02-24 09:48:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o78l8up",
                  "author": "roy_malcolm",
                  "text": "It hasn't been an issue. You can instruct agents to write efficient queries, like limit=50 arguments or selecting only error logs or whatnot. You're not going to get any signal dumping 100,000 lines at a time, same reason we don't design dashboards for humans like that",
                  "score": 1,
                  "created_utc": "2026-02-25 00:24:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6yqww5",
          "author": "TheDevauto",
          "text": "You might try rag+knowledge graph. You need someone to develop and maintain the kg, but that will help ground the responses by showing relationships between network topology and application configurations. Might help point out root causes faster with event streams.",
          "score": 1,
          "created_utc": "2026-02-23 15:27:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74ggne",
          "author": "IndiBuilder",
          "text": "I have been working in this space for some time.\nIf you are intreated for a demo slide in to my dm.\nWe can discuss this further.",
          "score": 1,
          "created_utc": "2026-02-24 12:14:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76asgh",
          "author": "kennetheops",
          "text": "This tech is the basis of what the company i started. Would gladly share any insights you want. It’s pretty cool but as other stated its a full time thing",
          "score": 1,
          "created_utc": "2026-02-24 17:50:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o716k6o",
          "author": "SmallSeaworthiness95",
          "text": "I’m an SRE co‑founder working on this space (at ewake.ai), and the RAG stuff I’ve seen actually works is pretty boring:  \n– “Have we seen this before?” search over incidents/postmortems/runbooks",
          "score": -1,
          "created_utc": "2026-02-23 22:20:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o72ydzs",
              "author": "krvnb",
              "text": "Great",
              "score": 0,
              "created_utc": "2026-02-24 04:30:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1ray8lg",
      "title": "How is SRE organized in your company and why that way?",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1ray8lg/how_is_sre_organized_in_your_company_and_why_that/",
      "author": "ray_pb",
      "created_utc": "2026-02-21 18:15:40",
      "score": 7,
      "num_comments": 7,
      "upvote_ratio": 0.9,
      "text": "I guess there are various ways to implement SRE as a discipline in an organization. Google speaks of (I think) at least 6 different ways of embedding SRE in an organization. Let’s for clarity sake limit this to software development companies only.\n\nDo you have a single product development team and do your SREs sit next to that team as a separate team dedicated to maintaining the reliability of that product ? Or is there a different setup?\n\nAlso, how did you start (organization wise)?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1ray8lg/how_is_sre_organized_in_your_company_and_why_that/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o6n1dwk",
          "author": "thecal714",
          "text": "The guy who created the SRE program at my company actually did a talk at [DASH](https://dash.datadoghq.com/) about this: https://www.youtube.com/watch?v=-ResKgP2WbI",
          "score": 5,
          "created_utc": "2026-02-21 18:20:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o70lnlp",
              "author": "ray_pb",
              "text": "Thanks, I watched it and sounds a bit like my current journey, but it doesn’t quite discuss the team topology topic.",
              "score": 1,
              "created_utc": "2026-02-23 20:38:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o70nl4y",
                  "author": "thecal714",
                  "text": "He talks a bit about how we do partial embeddings: 50% of our time is spent with a feature team and the other 50% is spent working with \"home base\" (or the rest of the SRE team).",
                  "score": 2,
                  "created_utc": "2026-02-23 20:47:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o71mxhi",
          "author": "baezizbae",
          "text": "At my company SRE’s are thrown at problems the same way people throw bug spray at whatever crevice they *think* the bugs are coming from. All the while having a sink full of last week’s dirty dishes and a floor that hasn’t been swept in a month. \n\nIOW: Poorly organized, but that’s probably familiar to too many of us, right?",
          "score": 5,
          "created_utc": "2026-02-23 23:49:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7f156o",
          "author": "hawtdawtz",
          "text": "At Robinhood we literally got rid of reliability for years because our leadership disagreed with the embedded model. Now we just rebuilt reliability and we’re having to justify our existence all over again, fun times. Mostly build tooling to automate stuff, own our incident response from a high level, and act as boots on the ground for many initiatives. Mainly grabbing scope wherever we can while we build up again.",
          "score": 1,
          "created_utc": "2026-02-25 23:11:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rd8ks1",
      "title": "How do you handle weekly client reporting and RCA docs?",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1rd8ks1/how_do_you_handle_weekly_client_reporting_and_rca/",
      "author": "Pristine-Ocelot8746",
      "created_utc": "2026-02-24 06:17:40",
      "score": 6,
      "num_comments": 5,
      "upvote_ratio": 0.87,
      "text": "*Been a DevOps engineer for a while now and honestly the part I hate most about my job is the reporting side.*\n\n*Every week I'm manually going through Grafana and CloudWatch, taking screenshots, deciding which ones matter, then copy pasting everything into a Confluence template to write up the weekly infra summary and any RCA docs.*\n\n*Takes me 4-5 hours per client. Feels like there should be a better way.*\n\n*How are you guys handling this? Any tools or workflows that actually help? Or is everyone just doing this manually too?*",
      "is_original_content": false,
      "link_flair_text": "DISCUSSION",
      "permalink": "https://reddit.com/r/sre/comments/1rd8ks1/how_do_you_handle_weekly_client_reporting_and_rca/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o74n7h0",
          "author": "SmallSeaworthiness95",
          "text": "You can build a simple agentic workflow internally: Slack bot that auto‑tags incidents by type, fetches RCA patterns from postmortems using RAG, and then drafts the summary.   \nYou can also feed it with your runbooks or logs for example.",
          "score": 1,
          "created_utc": "2026-02-24 12:59:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75jio8",
          "author": "maxfields2000",
          "text": "Agree with the other poster, this sounds like a perfect use case to teach yourself some modern agentic AI usage to gather that data. Grafana has a pretty good MCP server and AWS definitely has one for cloudwatch.  There's an agent for Confluence as well, so you can automate a lot of this.\n\nThe weekly infra summary sounds like a great idea. We do something similar on a few product teams here and we're trying to get that to be a common discourse, some teams do it during their weekly on-call rotation hand-off (recap the week).\n\nAs for RCA doc's, that's more interesting. Our failures are diverse enough that I couldn't really template a standard set of graphs, but I could still use an agent to go after what we already know or summarize what was captured during the incident in the incident ticket.  Only a few teams have any kind of \"weekly\" failures, most it's more monthly or quarterly though.\n\nThe other thing we're looking at for mostly stable teams is \"release\" analysis, especially if they've created SLO's, you can do an automated report of burn rates before/after releases pretty easily.",
          "score": 1,
          "created_utc": "2026-02-24 15:47:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o764fvd",
          "author": "glowandgo_",
          "text": "been there. what changed for me was treating reporting as a system problem, not a docs problem.\n\nat scale we stopped doing manual screenshots and defined a fixed kpi layer per client. once that contract was clear, most of it came from apis and templated markdown, then i’d just add context on anomalies + decisions. cut the 4-5h down a lot.\n\nthe trade off people dont mention is clients say they want detail, but usually care about risk, impact, and what’s next. are yours actually reading the graphs or just scanning for narrative + accountability?",
          "score": 1,
          "created_utc": "2026-02-24 17:21:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76n08d",
          "author": "ninjaluvr",
          "text": "We automate toil away. Grafana has an API, confluence has an API...",
          "score": 1,
          "created_utc": "2026-02-24 18:44:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o773l5b",
          "author": "Useful-Process9033",
          "text": "4-5 hours per client is rough but pretty common from what I've seen. The thing that cut the most time for us was templating the RCA structure with pre-populated fields pulled from our alerting system, so instead of starting from scratch you already have timeline, affected services, and detection method filled in. Then the human part is just the analysis and action items. For the weekly reporting, we set up a cron job that pulls key metrics from our monitoring APIs and dumps them into a markdown template, then review and annotate. Still manual but went from hours to maybe 45 minutes per client.",
          "score": 1,
          "created_utc": "2026-02-24 19:59:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1revgil",
      "title": "I’m burned out.",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1revgil/im_burned_out/",
      "author": "BoringTone2932",
      "created_utc": "2026-02-26 00:40:12",
      "score": 6,
      "num_comments": 7,
      "upvote_ratio": 0.88,
      "text": "I’m burned out and I realize it. I used to love my job, loved the technical challenge and loved automation, self healing, loved tackling the hard systemic issues. Finding the bug in the code from 3 years ago that’s impacting our clients. There’s things even today, that I truly love doing, but have come to hate it. The seconds of satisfaction are just blown away. \n\nAbout 8 months ago, I took my first SRE role after YEARS in operations and development. Our product is absolute garbage. At first it was fun, I spent weeks optimizing SQL maintenance, built observably from the ground up, ran with FinOps to save millions, optimized autoscaling policies. It was fun. But about 3 months ago we hit a wall. Specifically around November. We had optimized everything around our constraint, and now had reached critical mass whereas the next step was to resolve the critical constraint. There’s no way around it. Without fixing this, there’s no improvement we can do, and, the issue MUST be fixed by development or we are left manually changing and manipulating our scaling policies to avoid user impact, manually recycling clusters, manually responding. And,  dev has been trying to fix it, they are spinning their wheels. The update has been stuck in QA, and here I am for months working late, writing RCAs, snuffing fires all day. \n\nI’m tired of it. I’ve spent months working late, weekends, holidays, just to continue to spend nights away from my family, mentally exhausted. We get a new JIRA that hits the board, and my first thought is, “this isn’t my job, this needs to go away, it’s cleaning up someone else’s screw up.” \n\nI told my manager the other day to kick rocks, it’s an insane amount of effort not to tell people “well that’s stupid” in Trams chats. \n\nI’m the sole dedicated SRE for this product, and it seems like that means “manually run prod while we prioritize new features”\n\nHow do I get out of the SRE burnout? ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1revgil/im_burned_out/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o7fn2rj",
          "author": "DandyPandy",
          "text": "> How do I get out of <snip> burnout\n\nFor starters, set some boundaries around your work hours. If it can’t be done in your normal workday, it doesn’t get done.\n\nThen you take a break. Minimum of a week or two. You don’t check email, Teams/Slack, no alerts, nothing work related at all.\n\nHopefully you have a manager you can be honest with about being burned out and they will support you.\n\nIf they aren’t empathetic or you worry they might hold it against you, start looking for a new job. Put in absolutely minimum effort at work and focus on interview prep and interviews. When you get that new job lined up, you give your notice and set your start date so you have a couple of weeks off.",
          "score": 3,
          "created_utc": "2026-02-26 01:13:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7frtv9",
          "author": "TheDevauto",
          "text": "One way is to consider what its like to be searching for a job for 2 years. 5000+ applications, interviews with 8 companies, 2 to the final and still nothing. I dont think ill ever complain about burnout again.",
          "score": 2,
          "created_utc": "2026-02-26 01:40:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7fsawl",
          "author": "AccordingAnswer5031",
          "text": "You are burned out because you are not getting paid good enough",
          "score": 2,
          "created_utc": "2026-02-26 01:43:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7g3u84",
              "author": "Relevant_Interests",
              "text": "This.",
              "score": 1,
              "created_utc": "2026-02-26 02:48:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ftd3i",
          "author": "tr14l",
          "text": "You remember that you are there for the shareholders and you just push through because ultimately they are the job creators and you just poke computer keys. How you feel doesn't matter when they need to exceed their fiduciary responsibilities. Do you even consider them? I bet if you had you wouldn't be feeling like this",
          "score": 1,
          "created_utc": "2026-02-26 01:49:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7fv9ay",
          "author": "kellven",
          "text": "Option one, take of time off and get some rest. Honestly do this either way, it’s just a job , if you died they would continue on fine. \n\nOption two, get fucking spicy and burn some political capital. Maybe they fire you but that’s half the fun. Start throwing verbal rocks in meetings, some times you gota be the bad guy to get real shit done. \n\nOption 3 find a new job. \n\nSide note if this bugs cost can be translated into a direct cost to the biz , that can really get the ball moving cause now it’s not you pushing but leadership who wants to claim the cost savings. I pitched everything from OS updates to cluster rebuilds in terms of cost savings , and most of my shit don’t just get approved but got direct support from C levels.",
          "score": 1,
          "created_utc": "2026-02-26 02:00:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7fvpxb",
          "author": "Grandpabart",
          "text": "“this isn’t my job, this needs to go away, it’s cleaning up someone else’s screw up.” This describes burnout PERFECTLY. It happens because your powerless fixing the same problems over and over.",
          "score": 1,
          "created_utc": "2026-02-26 02:02:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rd618g",
      "title": "SRE Career Path Guidance",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1rd618g/sre_career_path_guidance/",
      "author": "Efficient-Branch539",
      "created_utc": "2026-02-24 04:40:21",
      "score": 3,
      "num_comments": 7,
      "upvote_ratio": 0.67,
      "text": "I have been working as a DevOps engineer for 2.5 years in Germany, and in this time I have worked with tools like Terraform, Jenkins, Ansible, Docker, Kubernetes, Prometheus etc. My responsibilities include creating/improving CI/CD workflows and helping devs build their code faster, adding prometheus targets, keeping Kubernetes cluster up (its Rancher on premise), use Vault, I have not worked on database side of things, like with Postgres cluster, that’s managed by another team.\n\nI have an underlying feeling that I am not doing an actual SRE related work, like scaling a service, setting SLI/SLOs or monitoring the specific metrics or writing code very often.\n\nMy question is how can I level up my skills to feel confident when applying for a SRE role. Should I get any specific certification? Will my experience be considered as a useful experience in big tech companies.\n\nThank you",
      "is_original_content": false,
      "link_flair_text": "CAREER",
      "permalink": "https://reddit.com/r/sre/comments/1rd618g/sre_career_path_guidance/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o731dms",
          "author": "ohlaph",
          "text": "I would always start where you are at. Ask to do more SRE tasks to get experience under your belt. ",
          "score": 2,
          "created_utc": "2026-02-24 04:52:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7acy94",
          "author": "ProtectionBrief4078",
          "text": "This is actually a very common place to be, especially for DevOps engineers who grew into platform work first. What you are doing now is still highly relevant to SRE, even if it does not feel like the textbook version. Keeping CI/CD reliable, clusters healthy, observability working, and secrets secure are all core building blocks of SRE work.\n\nThe gap you are sensing is usually around service ownership and reliability thinking rather than tools. You can level up by practicing SRE concepts deliberately, like defining SLIs and SLOs for one service, improving alert quality, or doing basic load and failure testing, even if it is on a side project or a non critical service.\n\nCertifications can help with structure, but they are rarely a deciding factor in big tech. Your experience will be considered useful if you frame it in terms of reliability, automation, incident prevention, and tradeoffs instead of just listing tools.\n\nDo you have access to any production services where you could start proposing SLOs or improving alerting, even in a small scoped way?",
          "score": 2,
          "created_utc": "2026-02-25 07:15:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7bav5o",
              "author": "Efficient-Branch539",
              "text": "As far as I can think there are some gaps where I can propose alerts especially on Jenkins, but that’s a good point to start. For SLOs, I am not sure as no one talks about it.\nAlso from your answer I understand that one should be thinking in SRE terms and rephrasing is needed.",
              "score": 1,
              "created_utc": "2026-02-25 12:15:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7bcjkk",
                  "author": "ProtectionBrief4078",
                  "text": "That makes sense, and honestly you’re already on the right track. The SLO part being unclear is super common, so you’re not alone there. A lot of this really clicks once you start thinking more in SRE terms and tying it back to user impact. Would you be open to a quick DM to compare setups and talk through this a bit more?",
                  "score": 1,
                  "created_utc": "2026-02-25 12:27:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rdsbwl",
      "title": "Need help landing SRE roles [1.5 YOE currently at F500 Resume Review]",
      "subreddit": "sre",
      "url": "https://i.redd.it/wu0bfdzl2ilg1.png",
      "author": "d0lfun",
      "created_utc": "2026-02-24 20:52:13",
      "score": 3,
      "num_comments": 17,
      "upvote_ratio": 0.55,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1rdsbwl/need_help_landing_sre_roles_15_yoe_currently_at/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o77hy1z",
          "author": "MichaelMach",
          "text": ">Is \\~2 years of experience too little for the roles I’m targeting?\n\nWhat roles *are* you targeting? I'm surprised you aren't a junior without at least 2 YoE at your current job.\n\nThe data science master program is sending mixed signals, too. Sure, SREs deal with some graphs for monitoring and alerting, but what you're doing in that program is so far removed from the day-to-day of an SRE that I'd be suspicious as a hiring manager that you don't really care to be an SRE at all.",
          "score": 22,
          "created_utc": "2026-02-24 21:06:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o78raxi",
              "author": "d0lfun",
              "text": "My job has a very niche, company-specific title so I wasn’t sure what to label it as. Maybe application support is better suited?",
              "score": 1,
              "created_utc": "2026-02-25 00:57:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ab6gy",
          "author": "tushkanM",
          "text": "1. You better remove the numbers - audit of 35 alerts + 10 pipes  in 2 years raises questions what did you do during the other 1 year and 6 months  \n2. Bring up more \"SRE-heavy\" language-  what SLOs/SLI is did you set up to observe, how many RCAs you conducted, how exactly MTTR was improved by %. You can fake it - nobody will check ",
          "score": 6,
          "created_utc": "2026-02-25 06:59:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77mlnd",
          "author": "Sea_Refrigerator5622",
          "text": "I really dislike how your resume is formatted. Especially the centerered roles with right side dates. \n\nI’d look for a more conventional template. \n\nAs a manager I would give it some small weight as it’s relevant to how you can communicate and document.  Its a huge deal for some and no big deal for others.",
          "score": 5,
          "created_utc": "2026-02-24 21:27:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7bgnik",
              "author": "PercussiveScruf",
              "text": "I think they’re left aligned, just with white space used to redact the company names",
              "score": 3,
              "created_utc": "2026-02-25 12:54:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7e2iqe",
                  "author": "thecal714",
                  "text": "I think you're right. I see a bit of what might be a serif that didn't get redacted.",
                  "score": 1,
                  "created_utc": "2026-02-25 20:25:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o78mhlo",
          "author": "Prox_The_Dank",
          "text": "You got python listed twice in your technologies section just fyi",
          "score": 3,
          "created_utc": "2026-02-25 00:31:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7atadw",
          "author": "Unlucky_You6904",
          "text": " tighten it to 1–2 pages, rename your current role to something market‑legible (e.g. ‘Application Support / Production Support’) and rewrite your bullets around SRE language: incidents handled, on‑call scope, SLIs/SLOs, MTTR/uptime, automation you built, and the scale of systems you touched. Pull your most relevant tools (Linux, cloud, containers, CI/CD, infra‑as‑code, observability stack) into a clear skills block and then echo them inside your experience bullets so it’s obvious you’re doing more than ticket chasing. An Observability / Platform / SRE I title might be an easier wedge than mid‑level SRE right now, but with sharper SRE‑style bullets and less noise, you should at least start getting interviews; if you revise in that direction and want another opinion, feel free to ping me.",
          "score": 3,
          "created_utc": "2026-02-25 09:47:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77iphn",
          "author": "poolpog",
          "text": "FWIW, I am an SRE manager who hires SREs. Though my experience as a manager is limited (i.e. I haven't been in this role very long).\n\n* *Is \\~2 years of experience too little for the roles I’m targeting?*\n\nProbably\n\n* *Should I remove certain things from my resume?*\n\nProbably not -- there's not a lot on there to begin with\n\n* *Do I need stronger/more relevant projects?*\n\nPersonally I don't give 2 shits about your personal projects being listed on your resume. Some hiring managers might. I do find them interesting to talk about during an interview. But on your resume? I mostly don't care.\n\n* *Should I be elaborating more on impact and metrics?*\n\nMaybe? Maybe not? This is probably fine as is. I personally truly hate resume bullet items in the format of \"Did <thing> by <implementation method> which resulted in <X %> <reduction of|increase in> <Some ohter thing>\" e.g.  \"Reduced Flarbnoz alerts by automating the deployment of Sparzel Nobbins, resulting in a 73% reduction in Alert Fatigue to the SRE Org\"\n\nGreat, good for you. You measured your Flarbnoz alerts. Or did you just make these numbers up? Who the fuck knows?\n\nOTOH, that's how resumes work, so :shrug:\n\n* *Am I aiming too high?*\n\nDefinitely not; Aim as high as you possibly can, imo. You'll probably get there eventually, but you also will probably only will get as high as you aim. (tbf I've seem some real lucky dunces get pretty far just by being pretty to look at and nice to be around)",
          "score": 9,
          "created_utc": "2026-02-24 21:09:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77rc6o",
              "author": "User342349",
              "text": ">I personally truly hate resume bullet items in the format of \"Did <thing> by <implementation method> which resulted in <X %> <reduction of|increase in> <Some ohter thing>\"\n\nWhat *do* you like to see on a resume?",
              "score": 3,
              "created_utc": "2026-02-24 21:49:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o77yv65",
                  "author": "poolpog",
                  "text": "I get it -- how else can one declare one's efforts and successes other than in this format. Also, HR resume scan bots are definitely a thing.\n\nI just hate the format, it is so trite. Someone who can write their achievements out in a novel, interesting, or simply well written, way, will definitely pop to to the top of my list.\n\nEdit: Let me clarify -- I do like seeing achievments and successes. I just like them written more like actual human sentences than as HR-Scan-Bot-friendly templates.",
                  "score": 1,
                  "created_utc": "2026-02-24 22:25:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o77w3tl",
              "author": "Tryin2Dev",
              "text": "What measurements are you going by? Do ask questions to find out if they made the numbers up?",
              "score": 1,
              "created_utc": "2026-02-24 22:12:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7a2zcn",
              "author": "enby_them",
              "text": "Which is funny because I think many of us have been explicitly trained to make those numbers up if we don’t have them because hiring managers/recruiters expect them. I’ve also never once been asked about how I got the numbers on my resume.",
              "score": 1,
              "created_utc": "2026-02-25 05:51:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o77lv35",
          "author": "paulv7",
          "text": "Here’s my take as a Director of SRE:\n\nWith your resume as is looking for an Observability Engineer role maybe easier than SRE.\n\nFor an SRE 1 role here are some things I’d want to see on your resume: \n\nYou need to find ways to learn and mention how you used AI to achieve business goals or save money. Ai is just another tool to move faster… How are you using/learning it.\n\nI would move your projects up just below your work experience. As I glossed over your resume and hardly read your projects. Which have some good tooling mentions in them. As I wrote this then went back to look at your resume and noticed you had a few of these::: What automation tooling have you used? Anything from Argo CD, Salt, Puppet, Ansible, Jenkins, gitlab ci/cd, github actions, terraform. Which as you see from other comments some people don’t care about home projects. Personally for an SRE 1 role that is a big factor for me in does this person really like playing  with technology or are they just looking to collect a pay check. In an SRE 1 interview I probably ask as many questions about someone’s home lab as work experience. Are they going to push themselves to get better or just be a button smasher.\n\nAnother item you could try to work on is if you have any oncall experience. At a high level what those responsibilities are and for how large of a platform. \n\nYour resume is very literal with the number of alerts you helped fix. Just saying “Worked with multiple dev teams to improve alerting and close observability gaps would cover it for me vs. giving exact numbers of alerts you touched. Then dive into the details in an interview.",
          "score": 7,
          "created_utc": "2026-02-24 21:24:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79quo3",
          "author": "poop-in-my-ramen",
          "text": "Fix the indentations. Why is role middle aligned instead of left? also some blue texts in education section. keep it black and white. ",
          "score": 2,
          "created_utc": "2026-02-25 04:24:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7fwzss",
          "author": "smuzzu",
          "text": "Use AI to fix your resume, you'll get much better results. Then come again and recheck here for further suggestions.",
          "score": 2,
          "created_utc": "2026-02-26 02:09:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77ji8b",
          "author": "hijinks",
          "text": "all you did is like 1/3 of a page?\n\nmake it at least 75% of the page.. the resume needs to be one page is so outdated. ",
          "score": -1,
          "created_utc": "2026-02-24 21:13:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}