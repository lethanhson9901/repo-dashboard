{
  "metadata": {
    "last_updated": "2026-02-25 03:09:26",
    "time_filter": "week",
    "subreddit": "sre",
    "total_items": 8,
    "total_comments": 57,
    "file_size_bytes": 55811
  },
  "items": [
    {
      "id": "1r9uw96",
      "title": "Multi cloud was supposed to save us from vendor lock in but now we're just locked into two vendors",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1r9uw96/multi_cloud_was_supposed_to_save_us_from_vendor/",
      "author": "NoBet3129",
      "created_utc": "2026-02-20 13:07:57",
      "score": 129,
      "num_comments": 23,
      "upvote_ratio": 0.98,
      "text": "CTO convinced leadership we needed multi cloud because aws would \"definitely raise prices\" or something. Nobody really thought through what this meant for the team managing it.\nHalf our stuff runs on aws api gateway, half on gcp api gateway and they work completely differently, aws does resource policies, gcp does iam, keeping security consistent across both is genuinely impossible. When something breaks we're checking cloudwatch and cloud monitoring separately trying to figure out which platform is the problem and our devs are pissed because they had to learn two completely different systems that do the exact same thing.\nWe've probably spent more time dealing with this mess than we ever would've spent migrating off aws if we actually needed to. The ironic part is now we're stuck with both platforms instead of one so... mission accomplished I guess?\nDid anyone else do this and actually make it work or did we just completely botch the implementation?",
      "is_original_content": false,
      "link_flair_text": "DISCUSSION",
      "permalink": "https://reddit.com/r/sre/comments/1r9uw96/multi_cloud_was_supposed_to_save_us_from_vendor/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o6f12iq",
          "author": "taleodor",
          "text": "The idea to avoid vendor lock in is to only use things between clouds that are essentially the same (sort of largest common denominator). So yes, your implementation seems botched and you should get back to drawing board.",
          "score": 41,
          "created_utc": "2026-02-20 13:18:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6grxx3",
              "author": "pokomokop",
              "text": "k8s, DNS/Load Balancing, blob storage(with the proper abstractions written in code), and (somewhat) managed databases are the services I feel are quite easy to migrate between CSP's. Access Policies and security are a bit tricky as they're definitely not one to one, but if you're already in multiple clouds those sort themselves out. Your serverless technologies is where you start to see tight coupling, at least in my experience.\n\nEDIT: Just seeing OP specifically talking about CloudWatch and what not. Disclaimer as I work at Grafana Labs, this is where having a centralized tool helps. You're not going to bridge the gap between monitoring solutions between the hyperscalers.",
              "score": 13,
              "created_utc": "2026-02-20 18:22:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6f0cn0",
          "author": "AmazingHand9603",
          "text": "Multi cloud sort of works if you have super strict abstraction layers and your ops team is big enough to handle the extra complexity. Most places, even big ones, end up with duplicated effort and everyone slightly irritated all the time. The theory is nice, but unless you’re at a scale where you can throw a separate team at each provider, it ends up being more pain than it’s worth. We ended up quietly letting one cloud become the main one over time, and honestly nobody cared except leadership, who eventually forgot why we did it in the first place.",
          "score": 47,
          "created_utc": "2026-02-20 13:14:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f2s6c",
          "author": "ufukty",
          "text": "mobility makes more sense than multi cloud to me. having configurations written down as terraform, ansible or bash scripts is enough of documentation to ease future migration",
          "score": 16,
          "created_utc": "2026-02-20 13:28:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f7v9f",
              "author": "Creative-Dentist-383",
              "text": "Additionaly, use as many “common services” as possibles. Migrating from EC2 to Azure VMs is a lot easier than some very specialized service. ",
              "score": 12,
              "created_utc": "2026-02-20 13:55:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6fcq3e",
          "author": "MordecaiOShea",
          "text": "Building to open standards rather than multicloud is the solution you need. It is why we use EKS, not ECS. And managed Kafka, not SQS. And Postgres Aurora, not DynamoDb.",
          "score": 11,
          "created_utc": "2026-02-20 14:21:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f3f9x",
          "author": "ninjaluvr",
          "text": "Multi-cloud without thought and intention is a disaster as you've witnessed first hand. Multi-cloud with abstraction can be beautiful. But if you don't have the expertise to design, build, and manage it, you should stick with one vendor.",
          "score": 8,
          "created_utc": "2026-02-20 13:31:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gjypf",
          "author": "kellven",
          "text": "AWS is one of the few vendors I can think of in recent time that hasn’t really jacked up prices. Unless your org is absolutely massive , or you directly compete with Amazon, I think the lock-in cost of AWS is worth the benefit. \n\nIt’s a bit wild to me that your CTO could sell that large of a project purely on the ghosts of prices future. He either made the coffee is for closers speech or your leadership has no back bone.",
          "score": 7,
          "created_utc": "2026-02-20 17:46:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f8v5z",
          "author": "faajzor",
          "text": "Honestly that is an issue of poor planning on the engineering side.\n\nUse common tools (k8s?) or try to abstract some of the services. Centralize logging and monitoring, invest in tooling, etc.",
          "score": 5,
          "created_utc": "2026-02-20 14:01:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f4gz9",
          "author": "borg286",
          "text": "Would you mind sharing what you mean by the API gateways working differently?",
          "score": 4,
          "created_utc": "2026-02-20 13:37:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6htkl7",
          "author": "manauwar1212",
          "text": "The only way this works is if you stop trying to manage each cloud separately. Put everything behind one api layer that handles the routing and policies. We use gravitee with aws and azure backends, and gateway stays consistent, cloud providers just become dumb compute and at least devs only learn one system.",
          "score": 2,
          "created_utc": "2026-02-20 21:22:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fqe21",
          "author": "amarao_san",
          "text": "Multicloud is hard. I would say, the best way for multicloud is to have baremetal option. If you can rebuild your production with some baremetal servers with some bgp, you are multicloud by definition, because you can run on any infra.\n\nnext, you can cut some clumsy implemented functions into vendor provided, with baremetal fallback. In this case you get best for reasonable price, because unreasonable price just been replaced with baremetal.\n\nBut it's hard, as you need to integrate something as replacement for all fancy services providers gives you, or give up on them entirely.\n",
          "score": 3,
          "created_utc": "2026-02-20 15:29:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hkukl",
          "author": "LongjumpingGuava5656",
          "text": "Best title ever",
          "score": 1,
          "created_utc": "2026-02-20 20:38:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hu6w3",
          "author": "[deleted]",
          "text": "multi cloud only makes sense if you have a dedicated team for it. for most companies it just doubles the work with no real benefit.",
          "score": 1,
          "created_utc": "2026-02-20 21:25:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6i79um",
          "author": "curious_maxim",
          "text": "Multi-cloud is good in three cases: 1) you actually need to abandon one and switch to another. That’s typically related to competition concerns (Amazon, Microsoft and Google do own bunch of companies who might be competing with some), or significant savings (think tens of millions of dollars a year scale); 2) you use them complimentary as some services can be better at one vendor and others - at second; 3) same as 2) but from price perspective - think mid-size company with plenty of network traffic.\n\nMaintaining multi-cloud redundancy is a huge time-waster in other cases.",
          "score": 1,
          "created_utc": "2026-02-20 22:31:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ktx3c",
          "author": "Its_Sunaina_",
          "text": "Your leadership read some consultant presentation about vendor lockin without thinking it through. Multi cloud makes sense for compliance or geo stuff but not just because you're scared of price increases.",
          "score": 1,
          "created_utc": "2026-02-21 09:57:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lfztn",
          "author": "Ordinary-Role-4456",
          "text": "Honestly, the only folks I’ve seen pull off multi-cloud well are the massive companies with specialized teams for each platform, so no one is having to become a universal expert. Most of the time, though, it just turns into twice the pain for no real gain.   \n  \nUnless you’re building for some serious redundancy needs or have regulatory reasons, a single cloud keeps things way simpler. ",
          "score": 1,
          "created_utc": "2026-02-21 13:11:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6q0jn4",
          "author": "surpremebeing",
          "text": "Kubernetes and VMware are the only two technologies today that avoid cloud lock. As soon as you adopt specific cloud native features, they have you locked.",
          "score": 1,
          "created_utc": "2026-02-22 04:50:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70nxco",
          "author": "Mundane_Discipline28",
          "text": "i get why most people here are saying multi-cloud is a mistake. and honestly when you're managing each provider separately it is. two IAM configs, two monitoring stacks, two deploy pipelines. that's not multi-cloud, that's just double the work.\n\nmy experience was different tho. we use a platform that abstracts the cloud layer into one interface (Quave ONE). deploy to AWS or GCP from the same place, same workflow. when we needed to move some workloads to GCP for pricing it wasn't a migration project, just a config change.\n\nthe thing is we're not \"managing two clouds.\" we're managing one platform that runs on multiple providers. if we decided to go all in on AWS tomorrow we could do that without changing anything.\n\nnot saying multi-cloud is for everyone. but OP's case sounds more like bad implementation than bad strategy",
          "score": 1,
          "created_utc": "2026-02-23 20:49:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o794ufr",
          "author": "KiritoCyberSword",
          "text": "Just make it a container, regardless if its k8s, or other containers platforms, you can migrate it easily",
          "score": 1,
          "created_utc": "2026-02-25 02:14:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jrq74",
          "author": "kennetheops",
          "text": "I'm actively working on a platform to help with a lot of this type of stuff. I don't know if you will ever be interested in collaborating with early tools, but I ran into this scenario a couple of years back and started working on an AI tool to cross-collaborate across clouds for both cost or just having a better understanding, honestly. I absolutely despise Terraform anything once you start getting pretty large deployments.",
          "score": 0,
          "created_utc": "2026-02-21 04:16:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rayuwn",
      "title": "What metrics actually matter? Lessons shared after a recent 47-minute outage",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1rayuwn/what_metrics_actually_matter_lessons_shared_after/",
      "author": "Agitated-Alfalfa9225",
      "created_utc": "2026-02-21 18:39:18",
      "score": 42,
      "num_comments": 19,
      "upvote_ratio": 0.89,
      "text": "Saw a team recently share a breakdown of a 47-minute checkout outage that could have been caught much earlier. Thought it was worth summarizing because a lot of people here ask what application monitoring metrics actually matter. The issue started with checkout services returning 500s around 2am. Initial investigation focused on CPU and memory at the pod level. Everything looked healthy from an infrastructure perspective, which ended up being a distraction. Once traces were reviewed, it became clear that payment gateway calls were timing out at the default 30s. The root cause turned out to be an expired certificate on an upstream dependency.\n\n\n\nWhat reportedly helped identify the issue:\n\n\\- A service map that immediately showed the payment gateway dependency in a degraded or red state\n\n\\- A p99 latency dashboard that spiked from about 200ms to 30s\n\n\\- Distributed traces showing the exact span where requests were hanging\n\n\n\nWhat did not help:\n\n\\- Basic infra metrics. CPU and memory looked fine throughout\n\n\\- Alerting configured only around error rates crossing 5%\n\n\n\nOne takeaway from the discussion was that infrastructure level health can look completely normal while user-facing latency is collapsing because of a dependency. The team is now adding dependency-specific health checks, defining SLOs for upstream services, and lowering error rate alert thresholds. Curious what others keep on their war room dashboards during incidents. Are you prioritizing latency percentiles, dependency maps, synthetic checks, something else? It seems like a lot of monitoring setups still focus heavily on infrastructure signals rather than service-to-service behavior.\n\n",
      "is_original_content": false,
      "link_flair_text": "DISCUSSION",
      "permalink": "https://reddit.com/r/sre/comments/1rayuwn/what_metrics_actually_matter_lessons_shared_after/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o6nhfoo",
          "author": "calibrono",
          "text": "Alerting on P95/99 (and even P50) + alerting on dependency metrics (error rate of requests to a dependency service) is very helpful.",
          "score": 13,
          "created_utc": "2026-02-21 19:40:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ninhg",
          "author": "Mysterious_Salt395",
          "text": "Tools like Datadog often come up in these conversations because they correlate traces, logs, and metrics in one place. From what I’ve seen discussed, having that cross-signal visibility can make a big difference during incidents like this. Service maps in particular get mentioned a lot as helpful for spotting failing dependencies quickly.",
          "score": 8,
          "created_utc": "2026-02-21 19:46:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6nmxmp",
              "author": "FormerFastCat",
              "text": "Careful, any mention of Datadog or Dynatrace on this sub gets insta down voted because building an observability platform from scratch with OTEL and log parsing is 100% the way to go and obviously best practice. /S",
              "score": 8,
              "created_utc": "2026-02-21 20:08:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6qfkha",
                  "author": "kabrandon",
                  "text": "You’re not really building a platform from scratch though are you. It’s a stack of FOSS tools, you run them, and once you’ve done it once you can do it a hundred times if your deploy manifests are in git.",
                  "score": 3,
                  "created_utc": "2026-02-22 06:56:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6o462m",
                  "author": "GrogRedLub4242",
                  "text": "FOSS ideal, not necessarily OTEL, the latter has anti-patterns and risks and is relatively young. I see the argument to avoid DataDog, Splunk and similar when you can",
                  "score": 1,
                  "created_utc": "2026-02-21 21:40:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ptwch",
          "author": "Hi_Im_Ken_Adams",
          "text": "Why didnt you start with traces?    Infrastructure performance is what you drill down into, not what you start looking at first.  \n\n\nTraces tell you where the problems is.  Simple as that.",
          "score": 3,
          "created_utc": "2026-02-22 04:02:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x75wh",
              "author": "SWEETJUICYWALRUS",
              "text": "Scaling policies usually aren't set up right in the first place or drift out of the requirements with time. So people tend to head there first out of gut reaction. \n\nJust happened to us. Everyone was panicking about ensuring ECS scaled up. Meanwhile I'm the only one that saw 8000 500 errors due to max db connections because someone set the scaling to 10% max cpu utilization and max tasks to 999",
              "score": 1,
              "created_utc": "2026-02-23 08:45:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6nk87j",
          "author": "SudoZenWizz",
          "text": "From my experience you should map all dependencies of the app. Cpu/ram/disk are not sufficient and having other services and metrics will give some insight.\nFor some web/mobile apps we have in checkmk monitoring all requests to api’s or external website that the application does mapped in health checks with additional http active checks.\nLastly, we map the overall service as BI and when something is not working properly we know what’s the culprit.\nAdd log monitoring for specific keywords and this can improve source of the issue.\nFor full service monitoring and performance you can also add syntethic montoring woth robotmk.",
          "score": 1,
          "created_utc": "2026-02-21 19:54:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6o3tuy",
          "author": "GrogRedLub4242",
          "text": "all signal helps. the more the merrier. because any signal helps paint the space of potential contributing causes. in the case you described either it was a young/immature monitoring setup or young/novice crew\n\nin the next incident it might be a diff mix of signals which identify the root/prox cause.",
          "score": 1,
          "created_utc": "2026-02-21 21:38:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ol8ob",
              "author": "baezizbae",
              "text": "> all signal helps. the more the merrier.\n\nBe *very* careful with this. \n\nI understand this *in spirit* but *in practice* it is how you end up paying an arm and a leg for observability (either to a vendor or to work-hours spent building and operating your observability moat). It's been a consistent and repeat experience of mine that when you start yanking more and more signals from a system, people will begin to want those signals to tell them more and more \"just in case\" something goes wrong, not when something has *actually* gone wrong and you end up with a bunch of people suffering from alert fatigue",
              "score": 2,
              "created_utc": "2026-02-21 23:15:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6o50u7",
          "author": "curious_maxim",
          "text": "Do you monitor  key integrations with logical smoke tests? - to alert on them even before customer executes full flow.",
          "score": 1,
          "created_utc": "2026-02-21 21:44:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6o8nkl",
          "author": "borg286",
          "text": "Incoming error ratio and latency and outgoing error ratio and latency are the big ones.",
          "score": 1,
          "created_utc": "2026-02-21 22:03:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pknrj",
          "author": "rnjn",
          "text": "depends on issues really, it would be ill advised to use a cookie cutter approach. as usage grows, and deployment volume grows, one sees many different type of problems. you could create a summary view one way, and an issue will break assumptions. what i have seen work is to ensure each issue/incident as feedback and do postmortems well. build a summary and drill-down approach, build very few summary views that can help anyone understand what's happening. and then they can drill down thru multiple dimensions (including infra) to understand why its happening. keep these two categories separate, and guard summaries well.   \n  \nthe outcome could be latency profiles coupled with an infra map and a service map, or it could be a tabular view - depends on the software being monitored and the team responsible for the SLOs.  I even have SSL cert expiry as part of mine (because of what i am responsible for), you should share this with the owner of your upstream dependency (https://docs.base14.io/blog/make-certificate-expiry-boring)",
          "score": 1,
          "created_utc": "2026-02-22 02:58:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qa5nd",
          "author": "raymond_reddington77",
          "text": "- A p99 latency dashboard that spiked from about 200ms to 30s\n\nWhat type of latency?",
          "score": 1,
          "created_utc": "2026-02-22 06:07:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70q1w2",
          "author": "Muthakkir",
          "text": "I hate to say it but synthetic checks are helpful in this case specially if it's combined with distributed traces ",
          "score": 1,
          "created_utc": "2026-02-23 20:59:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8jo96",
      "title": "SRE on a black-box SaaS (Shopify): using synthetic transactions to catch checkout breakages and silent telemetry failures",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1r8jo96/sre_on_a_blackbox_saas_shopify_using_synthetic/",
      "author": "Silver-Geologist8926",
      "created_utc": "2026-02-18 23:56:57",
      "score": 11,
      "num_comments": 13,
      "upvote_ratio": 0.8,
      "text": "Hi all,\n\nIn e-commerce platforms like Shopify, we don’t control infra and we don’t get server logs, but reliability problems still show up in the places the business cares about most: add-to-cart / checkout-start and telemetry (ads/analytics events) silently failing after app/theme changes.\n\nWe’ve been treating the storefront as a black-box system and using synthetic transactions (Playwright) as the primary signal:\n\n* execute a real user journey on an interval (home → PDP → ATC → cart → checkout-start)\n* capture evidence: console errors, blocked/failed network calls (401/403), browser security policy blocks that prevent embedding/redirect flows, and perf deltas\n* diff against a baseline so “something changed” is machine-detectable even without server logs\n\nQuestion for folks who’ve had to do SRE on third-party platforms:\n\nDo you treat synthetics as the source of truth for SLOs in no-log environments, or have you found higher-fidelity signals (RUM, edge logs, support APIs, etc.)? Also curious how you define error budgets when the platform owner controls most dependencies.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1r8jo96/sre_on_a_blackbox_saas_shopify_using_synthetic/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o65plmr",
          "author": "BlessedSRE",
          "text": "What’s the point of an error budget on a managed service if you can’t do anything to stop burn? Are you just trying to audit their SLA attainment?",
          "score": 14,
          "created_utc": "2026-02-19 00:42:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o662bze",
              "author": "Silver-Geologist8926",
              "text": "Totally fair question. For a managed platform, the error budget isn’t about “fixing Shopify infra” - it’s about controlling what we can burn (theme/app deploys, 3rd-party scripts, headless edge/API deps, telemetry/pixel regressions) and having a trigger for freeze/rollback + vendor escalation when it’s not us. Auditing the provider SLA is a side benefit, but the main value is change management and fast attribution",
              "score": 8,
              "created_utc": "2026-02-19 01:56:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o69d76i",
                  "author": "BlessedSRE",
                  "text": "If you're doing app deploys, then orchestrate telemetry in your app so you can distinguish between errors coming from your code vs errors from Shopify APIs",
                  "score": 1,
                  "created_utc": "2026-02-19 15:58:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6dh19p",
              "author": "Useful-Process9033",
              "text": "Error budgets on managed platforms still make sense because most outages on Shopify storefronts are caused by your own theme/app deploys, not Shopify infra. The budget gives you a freeze trigger for your own changes and a paper trail for vendor escalation when it actually is their fault.",
              "score": 1,
              "created_utc": "2026-02-20 05:27:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o66lq5n",
          "author": "pharcide",
          "text": "I had the same challenges running SF Commerce Cloud and yes we used synthetics but really should only be used for reachability.   One approach I've seen is have all the component teams own their own health sensors and have the synthetic load that page and execute those tests which should be indicative of the health of services.\n\nCan you clarify, are you running a storefront on Shopify or are YOU Shopify?  that would clarify the approach here",
          "score": 1,
          "created_utc": "2026-02-19 03:51:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68svax",
              "author": "Silver-Geologist8926",
              "text": "We’re not Shopify - we’re a third-party team operating merchant storefronts on Shopify (sometimes headless, sometimes themes/apps)",
              "score": 1,
              "created_utc": "2026-02-19 14:13:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6aire8",
          "author": "lazyant",
          "text": "One of my pet theories is that people use or mention error budgets because that Google SRE book but I have yet to find a good answer for a non-google scale company of  what do you do (really actionable) when you go under / over budget. Variations of “Be more/less careful” don’t make a lot of sense to me.",
          "score": 1,
          "created_utc": "2026-02-19 19:16:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dh1vt",
              "author": "Useful-Process9033",
              "text": "The actionable part is deploy freezes. When you burn through budget you stop shipping changes until it recovers. At non-Google scale the value is less about the math and more about having an objective trigger that stops the \"just one more deploy\" mentality during fragile periods.",
              "score": 2,
              "created_utc": "2026-02-20 05:27:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6h1vwc",
                  "author": "lazyant",
                  "text": "Upvoted but I’ve seen this theory in more than one company and didn’t work , at the end the freezing is again “be more careful”",
                  "score": 1,
                  "created_utc": "2026-02-20 19:07:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6byxav",
          "author": "ResponsibleBlock_man",
          "text": "I literally just wrote a post about it just now on sre. Can you please DM. I am doing something similar.",
          "score": 1,
          "created_utc": "2026-02-19 23:41:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gid0a",
          "author": "Silver-Geologist8926",
          "text": "Update: OSS implementation here - [https://github.com/Shop-Integrations/shopify-nano-sre](https://github.com/Shop-Integrations/shopify-nano-sre)\n\nIt’s basically scheduled Playwright journeys + evidence capture (trace/screenshots/console/network/CSP) so failures are reproducible. Feedback welcome.",
          "score": 1,
          "created_utc": "2026-02-20 17:38:45",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9jrrk",
      "title": "Does any one deploy AI agents in prod.",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1r9jrrk/does_any_one_deploy_ai_agents_in_prod/",
      "author": "masterluke19",
      "created_utc": "2026-02-20 02:56:10",
      "score": 7,
      "num_comments": 16,
      "upvote_ratio": 0.71,
      "text": "With all Agent based discussion I have seen that there is major trust issue with AI Agents in prod. How do you ensure that the agents are secure. TBH I can’t imaging how they adapt in prod unless it’s different tools plugged in together. Multi model makes it more complex. How do you track those.",
      "is_original_content": false,
      "link_flair_text": "DISCUSSION",
      "permalink": "https://reddit.com/r/sre/comments/1r9jrrk/does_any_one_deploy_ai_agents_in_prod/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o6cw0oi",
          "author": "c0LdFir3",
          "text": "Fuck no, I have self respect.",
          "score": 18,
          "created_utc": "2026-02-20 03:00:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6cw7dm",
              "author": "masterluke19",
              "text": "Legend!",
              "score": 2,
              "created_utc": "2026-02-20 03:02:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6d4ggi",
          "author": "slashedback",
          "text": "Are developer’s laptops prod? If so yes tons of dangerous agents are now in prod lmao. IYKYK",
          "score": 11,
          "created_utc": "2026-02-20 03:55:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dip1n",
              "author": "masterluke19",
              "text": "If it’s serving anything public then yes",
              "score": 2,
              "created_utc": "2026-02-20 05:41:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6epbuj",
                  "author": "imdevin567",
                  "text": "I don't think that's what they meant. Developer laptops are usually considered prod-adjacent, because they can reach prod. Developers are almost certainly running agents locally, often with their own personal API keys, and often with little-to-no guardrails. You're probably already \"running agents in prod\" and don't even realize it. It's the wild wild west out there right now.",
                  "score": 4,
                  "created_utc": "2026-02-20 12:01:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ee9wv",
          "author": "glowandgo_",
          "text": "yeah, in my experience most teams don’t really deploy agents in prod the way marketing hype suggests. usually it’s workflows where the agent is orchestrating fixed tools, not making autonomous decisions.......the hard part is observability and guardrails. you need logging, validation layers, and clear rollback paths. multi-model setups just amplify that complexity, so a lot of prod deployments end up being more like supervised automation than true agents.",
          "score": 6,
          "created_utc": "2026-02-20 10:30:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f8l73",
              "author": "masterluke19",
              "text": "Finally someone validated what I felt. But do you thing the multi model system will be widely adopted for prod systems. I don’t mean the multi tool or multi workflow integration, actual prod servers.",
              "score": 1,
              "created_utc": "2026-02-20 13:59:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6refh3",
                  "author": "glowandgo_",
                  "text": "heyy wazuup! think multi model setups will grow, but mostly for routing and cost control. Small model for simple tasks, stronger one for deeper reasoning. That’s practical... Fully autonomous multi model systems in prod feel unlikely for most teams right now. The ops overhead and eval complexity is still pretty high.",
                  "score": 1,
                  "created_utc": "2026-02-22 12:22:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6dqokd",
          "author": "Federal_Ad7921",
          "text": "The trust concern is valid. Instead of layering more tools, focus on unified zero-trust runtime control. We’ve used AccuKnox’s agentless eBPF approach to monitor what AI agents actually read, write, and call, reducing data leakage risk significantly. It’s not a management fix, but strong runtime visibility is essential.",
          "score": 2,
          "created_utc": "2026-02-20 06:50:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lc5s1",
          "author": "JustAnAverageGuy",
          "text": "The shit people are just throwing over the fence into prod without realizing what those agents are actually capable of, and the glaring security holes, scares the fuck out of me.\n\nWhen you make the “software engineering” barrier as low as it is today, you enable people to build ridiculously dangerous things without them even understanding that’s dangerous, let alone why it’s dangerous or what the concerns are.\n\nThe newest astroturf bullshit I’m seeing in places like r/smallbusiness are these non-US folks coming in and trying to convince business owners that they can build them a website that will replace QuickBooks their CRM their job hosting software everything with just a simple website at half the cost of what they’re spending every year.\n\nSo now we suddenly have somebody who doesn’t know how to build a secure solution selling solution solutions to people who don’t know the right questions to ask to make sure that it’s a good secure solution…\n\nI really think this is gonna be really bad for a lot of organizations, post mom and pop businesses where they’re gonna get completely wiped out the first security breach. They have all the way up to the big enterprise organizations that just don’t understand what they’re doing with AI and they don’t have the right talent in place to help them do it in a safe way.\n\n",
          "score": 1,
          "created_utc": "2026-02-21 12:43:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o70qzhr",
          "author": "Party-Major1956",
          "text": "Si yo despliego agente de IA muy confiables. Por  insultas infi@newinsurtechia/WhatsApp 11.2675.7243",
          "score": 1,
          "created_utc": "2026-02-23 21:04:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o71o9fe",
          "author": "vartheo",
          "text": "Limited AI Chat bot LLM's are the most that I see deployed when it comes to AI. I don't see free-will agents anywhere in prod for any real company",
          "score": 1,
          "created_utc": "2026-02-23 23:57:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6gouht",
          "author": "Useful-Process9033",
          "text": "We deploy one in production for incident investigation. The key constraint: it's read-only. It can query your monitoring, pull logs, check deploy history, read runbooks, but it can't take any action. That single decision eliminates most of the trust problems people worry about.\n\nThe other thing that helps is scoping it tightly. It's not a general-purpose agent roaming your infra. It gets triggered by an alert or ticket, investigates that specific thing, and produces a summary. Fixed input, fixed output, predictable token budget.\n\nWe open sourced it if you want to poke at the approach: https://github.com/incidentfox/incidentfox",
          "score": 0,
          "created_utc": "2026-02-20 18:08:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ray8lg",
      "title": "How is SRE organized in your company and why that way?",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1ray8lg/how_is_sre_organized_in_your_company_and_why_that/",
      "author": "ray_pb",
      "created_utc": "2026-02-21 18:15:40",
      "score": 7,
      "num_comments": 6,
      "upvote_ratio": 0.9,
      "text": "I guess there are various ways to implement SRE as a discipline in an organization. Google speaks of (I think) at least 6 different ways of embedding SRE in an organization. Let’s for clarity sake limit this to software development companies only.\n\nDo you have a single product development team and do your SREs sit next to that team as a separate team dedicated to maintaining the reliability of that product ? Or is there a different setup?\n\nAlso, how did you start (organization wise)?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1ray8lg/how_is_sre_organized_in_your_company_and_why_that/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o71mxhi",
          "author": "baezizbae",
          "text": "At my company SRE’s are thrown at problems the same way people throw bug spray at whatever crevice they *think* the bugs are coming from. All the while having a sink full of last week’s dirty dishes and a floor that hasn’t been swept in a month. \n\nIOW: Poorly organized, but that’s probably familiar to too many of us, right?",
          "score": 6,
          "created_utc": "2026-02-23 23:49:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6n1dwk",
          "author": "thecal714",
          "text": "The guy who created the SRE program at my company actually did a talk at [DASH](https://dash.datadoghq.com/) about this: https://www.youtube.com/watch?v=-ResKgP2WbI",
          "score": 4,
          "created_utc": "2026-02-21 18:20:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o70lnlp",
              "author": "ray_pb",
              "text": "Thanks, I watched it and sounds a bit like my current journey, but it doesn’t quite discuss the team topology topic.",
              "score": 1,
              "created_utc": "2026-02-23 20:38:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o70nl4y",
                  "author": "thecal714",
                  "text": "He talks a bit about how we do partial embeddings: 50% of our time is spent with a feature team and the other 50% is spent working with \"home base\" (or the rest of the SRE team).",
                  "score": 2,
                  "created_utc": "2026-02-23 20:47:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rc9l84",
      "title": "RAG usage in SRE",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1rc9l84/rag_usage_in_sre/",
      "author": "CosmicKheerTornado",
      "created_utc": "2026-02-23 06:04:51",
      "score": 6,
      "num_comments": 11,
      "upvote_ratio": 0.69,
      "text": "Anyone using or any idea folks utilising RAGs in their SRE work. I am thinking of working on any but confused.\n\nLike : Postmortem Intelligence or Log & Monitoring Analysis.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1rc9l84/rag_usage_in_sre/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o6wtq3f",
          "author": "slayem26",
          "text": "We tried implementing these ideas. Problem happens when you can't tell hallucinations from facts.\n\nDeveloping a model and validations was a lot of effort, so for now it is shelved.",
          "score": 13,
          "created_utc": "2026-02-23 06:38:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o775wwg",
          "author": "WeekSubstantial6065",
          "text": "the biggest breakthrough for us was getting structured diagnostic data feeding into the RAG system rather than just dumping raw logs at it. We set up tooling that pulls metrics, traces, and events without needing to SSH into boxes directly (which our security team loves), and that structured context makes the RAG outputs way more actionable. Like instead of \"here's 10000 lines of logs,\" it's more \"here's the correlated anomalies across these three services at 2:14am.\"  \n  \nFor postmortems specifically, having that kind of organized timeline data means the RAG can actually surface relevant patterns from past incidents instead of just keyword matching. We've caught a few recurring issues that way that would've taken forever to spot manually.  \n  \nAnyway, thought I'd share since you're exploring this space. Happy to chat more about what's worked (and what hasn't) if you're interested.  \n  \nCheers",
          "score": 2,
          "created_utc": "2026-02-24 20:10:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xe38j",
          "author": "roy_malcolm",
          "text": "Have gotten great use out of hooking up Claude code to our logs & metrics (observe) via CLI. It can iterate on queries 30x faster than I can, much easier to find things",
          "score": 2,
          "created_utc": "2026-02-23 09:53:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o73z5pw",
              "author": "mr_sharmas",
              "text": "How do you limit the number to tokens processed by LLM? I mean.. to process logs of last 3 hours to know something is overwhelming.",
              "score": 1,
              "created_utc": "2026-02-24 09:48:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o78l8up",
                  "author": "roy_malcolm",
                  "text": "It hasn't been an issue. You can instruct agents to write efficient queries, like limit=50 arguments or selecting only error logs or whatnot. You're not going to get any signal dumping 100,000 lines at a time, same reason we don't design dashboards for humans like that",
                  "score": 1,
                  "created_utc": "2026-02-25 00:24:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6yqww5",
          "author": "TheDevauto",
          "text": "You might try rag+knowledge graph. You need someone to develop and maintain the kg, but that will help ground the responses by showing relationships between network topology and application configurations. Might help point out root causes faster with event streams.",
          "score": 1,
          "created_utc": "2026-02-23 15:27:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74ggne",
          "author": "IndiBuilder",
          "text": "I have been working in this space for some time.\nIf you are intreated for a demo slide in to my dm.\nWe can discuss this further.",
          "score": 1,
          "created_utc": "2026-02-24 12:14:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76asgh",
          "author": "kennetheops",
          "text": "This tech is the basis of what the company i started. Would gladly share any insights you want. It’s pretty cool but as other stated its a full time thing",
          "score": 1,
          "created_utc": "2026-02-24 17:50:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o716k6o",
          "author": "SmallSeaworthiness95",
          "text": "I’m an SRE co‑founder working on this space (at ewake.ai), and the RAG stuff I’ve seen actually works is pretty boring:  \n– “Have we seen this before?” search over incidents/postmortems/runbooks",
          "score": 0,
          "created_utc": "2026-02-23 22:20:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o72ydzs",
              "author": "krvnb",
              "text": "Great",
              "score": 1,
              "created_utc": "2026-02-24 04:30:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rd8ks1",
      "title": "How do you handle weekly client reporting and RCA docs?",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1rd8ks1/how_do_you_handle_weekly_client_reporting_and_rca/",
      "author": "Pristine-Ocelot8746",
      "created_utc": "2026-02-24 06:17:40",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 0.86,
      "text": "*Been a DevOps engineer for a while now and honestly the part I hate most about my job is the reporting side.*\n\n*Every week I'm manually going through Grafana and CloudWatch, taking screenshots, deciding which ones matter, then copy pasting everything into a Confluence template to write up the weekly infra summary and any RCA docs.*\n\n*Takes me 4-5 hours per client. Feels like there should be a better way.*\n\n*How are you guys handling this? Any tools or workflows that actually help? Or is everyone just doing this manually too?*",
      "is_original_content": false,
      "link_flair_text": "DISCUSSION",
      "permalink": "https://reddit.com/r/sre/comments/1rd8ks1/how_do_you_handle_weekly_client_reporting_and_rca/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o74n7h0",
          "author": "SmallSeaworthiness95",
          "text": "You can build a simple agentic workflow internally: Slack bot that auto‑tags incidents by type, fetches RCA patterns from postmortems using RAG, and then drafts the summary.   \nYou can also feed it with your runbooks or logs for example.",
          "score": 1,
          "created_utc": "2026-02-24 12:59:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75jio8",
          "author": "maxfields2000",
          "text": "Agree with the other poster, this sounds like a perfect use case to teach yourself some modern agentic AI usage to gather that data. Grafana has a pretty good MCP server and AWS definitely has one for cloudwatch.  There's an agent for Confluence as well, so you can automate a lot of this.\n\nThe weekly infra summary sounds like a great idea. We do something similar on a few product teams here and we're trying to get that to be a common discourse, some teams do it during their weekly on-call rotation hand-off (recap the week).\n\nAs for RCA doc's, that's more interesting. Our failures are diverse enough that I couldn't really template a standard set of graphs, but I could still use an agent to go after what we already know or summarize what was captured during the incident in the incident ticket.  Only a few teams have any kind of \"weekly\" failures, most it's more monthly or quarterly though.\n\nThe other thing we're looking at for mostly stable teams is \"release\" analysis, especially if they've created SLO's, you can do an automated report of burn rates before/after releases pretty easily.",
          "score": 1,
          "created_utc": "2026-02-24 15:47:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o764fvd",
          "author": "glowandgo_",
          "text": "been there. what changed for me was treating reporting as a system problem, not a docs problem.\n\nat scale we stopped doing manual screenshots and defined a fixed kpi layer per client. once that contract was clear, most of it came from apis and templated markdown, then i’d just add context on anomalies + decisions. cut the 4-5h down a lot.\n\nthe trade off people dont mention is clients say they want detail, but usually care about risk, impact, and what’s next. are yours actually reading the graphs or just scanning for narrative + accountability?",
          "score": 1,
          "created_utc": "2026-02-24 17:21:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o76n08d",
          "author": "ninjaluvr",
          "text": "We automate toil away. Grafana has an API, confluence has an API...",
          "score": 1,
          "created_utc": "2026-02-24 18:44:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o773l5b",
          "author": "Useful-Process9033",
          "text": "4-5 hours per client is rough but pretty common from what I've seen. The thing that cut the most time for us was templating the RCA structure with pre-populated fields pulled from our alerting system, so instead of starting from scratch you already have timeline, affected services, and detection method filled in. Then the human part is just the analysis and action items. For the weekly reporting, we set up a cron job that pulls key metrics from our monitoring APIs and dumps them into a markdown template, then review and annotate. Still manual but went from hours to maybe 45 minutes per client.",
          "score": 1,
          "created_utc": "2026-02-24 19:59:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rd618g",
      "title": "SRE Career Path Guidance",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1rd618g/sre_career_path_guidance/",
      "author": "Efficient-Branch539",
      "created_utc": "2026-02-24 04:40:21",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "I have been working as a DevOps engineer for 2.5 years in Germany, and in this time I have worked with tools like Terraform, Jenkins, Ansible, Docker, Kubernetes, Prometheus etc. My responsibilities include creating/improving CI/CD workflows and helping devs build their code faster, adding prometheus targets, keeping Kubernetes cluster up (its Rancher on premise), use Vault, I have not worked on database side of things, like with Postgres cluster, that’s managed by another team.\n\nI have an underlying feeling that I am not doing an actual SRE related work, like scaling a service, setting SLI/SLOs or monitoring the specific metrics or writing code very often.\n\nMy question is how can I level up my skills to feel confident when applying for a SRE role. Should I get any specific certification? Will my experience be considered as a useful experience in big tech companies.\n\nThank you",
      "is_original_content": false,
      "link_flair_text": "CAREER",
      "permalink": "https://reddit.com/r/sre/comments/1rd618g/sre_career_path_guidance/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o731dms",
          "author": "ohlaph",
          "text": "I would always start where you are at. Ask to do more SRE tasks to get experience under your belt. ",
          "score": 1,
          "created_utc": "2026-02-24 04:52:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}