{
  "metadata": {
    "last_updated": "2026-01-25 08:55:26",
    "time_filter": "week",
    "subreddit": "sre",
    "total_items": 13,
    "total_comments": 54,
    "file_size_bytes": 83999
  },
  "items": [
    {
      "id": "1qj4eei",
      "title": "Upskiling for SRE",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1qj4eei/upskiling_for_sre/",
      "author": "Firm_Friend_7572",
      "created_utc": "2026-01-21 17:34:17",
      "score": 57,
      "num_comments": 14,
      "upvote_ratio": 0.91,
      "text": "I’ve been working as an SRE for 3 years now. My current role has become quite stagnant and I feel my learning has slowed down.\n\nI’ve found tons of resources online (blogs, courses, YouTube, etc.), but I’m struggling to find a clear learning path or roadmap to follow. Everything feels a bit scattered.\n\nAreas I’m particularly interested in strengthening:\n\n* Linux (internals, troubleshooting, performance)\n* Kubernetes\n* Networking\n\nThanks in advance!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1qj4eei/upskiling_for_sre/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o0zdrrr",
          "author": "jldugger",
          "text": "> My current role has become quite stagnant and I feel my learning has slowed down.\n\nFascinating perspective. Normally I feel great when I've stopped learning on the job because it means I can finally feel productive and not stressed out about delivering on time, resolving incidents faster, etc. Strongly recommend talking with your boss about performance criteria and expected annual review ratings.\n\nThat said, I keep a a deliberate backlog of training material. Various themes of mine over the years:\n\n2014: puppet & chef  \n2015: PostgreSQL perf  \n2016: git internals  \n2017: terraform & GCP  \n2018: new job, panic! (studied FAANG comp stuff? SRE book?)  \n2019: Time Series Forecasting  \n2020: Statistics & causal inference  \n2021: HBase and t-digests  \n2022: Classic CS papers  \n2023: Prometheus & PromQL  \n2024: MLOps  \n2025: FinOps  \n2026: GPUs & \"Staff Engineering\"  \n\n> but I’m struggling to find a clear learning path or roadmap to follow. Everything feels a bit scattered.\n\nTextbooks are best for this -- their mix of pedagogy and practice helps make things stick. But they're rare, esp for tech stacks. For standard O'Reilly tech books, usually I just commit to reading 10 pages a day to help pace myself.\n\nSelf-paced courses work but avoid any optional \"corporate trainings.\" Spending 6h+ in a classroom for 2 or 3 days isn't the right format to really learn or remember anything, it just ends up being a waste of time. Theres a reason college courses are 3 hours a week. You need a chance to practice recalling this stuff from \"long term storage\" if you want it to stick.\n\nVideo wise, I have a calendar with various conferences that typically publish videos. Kubecon, re:invent, USENIX, etc. I have reminders to check for uploads a few weeks after the event and when they do publish, I'll skim the sessions for presentations to add to my YT Watch Later queue. Just finished KubeCon a few weeks ago, and decided to put every nvidia GTC keynote into the backlog. Doing one a day, and should be done by Monday! It's a fun way to pick up on industry trends and evolutions. (Did something similar with Werner Vogels reinvent keynotes a few years ago).\n\nFor a while there I was even doing Anki, making cards from papers and textbooks, but fitting it into my daily schedule became harder after lock downs ended and I had to commute 3 days a week.\n\n> Linux (internals, troubleshooting, performance)\n\nThe best [Linux internals book is sadly 15 years old now](https://man7.org/tlpi/). It's hard to really wish the author would update it knowing how unrewarding books are financially, but reality is it doesn't mention containers at all and that limits its usefulness in the cloud compute era. The [UNIX Sysadmin handbook](https://www.reddit.com/r/linuxadmin/comments/1mvuw99/unix_and_linux_system_administration_handbook_6th/) is pretty good but I'm not sure how relevant it is for similar reasons.",
          "score": 25,
          "created_utc": "2026-01-22 03:23:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0zggi2",
              "author": "Firm_Friend_7572",
              "text": "This helps a lot thank you",
              "score": 1,
              "created_utc": "2026-01-22 03:39:10",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0zh4gq",
              "author": "Firm_Friend_7572",
              "text": "| Fascinating perspective. Normally I feel great when I've stopped learning on the job because it means I can finally feel productive and not stressed out about delivering on time, resolving incidents faster, etc. Strongly recommend talking with your boss about performance criteria and expected annual review ratings.\n\nMy reviews are good like exceeds performance for annual ratings. But there are no new projects coming and just maintenance work on k8s. So looking for a way to learn new things on my own. ",
              "score": 1,
              "created_utc": "2026-01-22 03:43:13",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0zwghl",
              "author": "banhyou",
              "text": "Curious about staff engineering — what resources are you using to dive deeper into it?",
              "score": 1,
              "created_utc": "2026-01-22 05:25:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1048xh",
                  "author": "jldugger",
                  "text": "Mostly just reading Staff Engineer's Path and some slack channels. And so far, it's mostly not enlightening. I already know how to run projects and write proposals; the way that book frames it Staff+ engineers paper over deficiencies in engineering managers and PMs.\n\nAnd I've posted in other threads how unlikely I am to actually get said promotion; due in part to a variety of factors including several high profile departures to the competition, and some career ending missteps in the executive suite leading our department no longer existing.",
                  "score": 3,
                  "created_utc": "2026-01-22 06:25:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0wfk4a",
          "author": "jobswithgptcom",
          "text": "To be a top notch SRE, I'd recommend you get a solid understanding of basics (linux kernel subsystems and how to measure / troubleshoot, user space, tcp/ip) Once you have that you build a small  subset of container management system like podman, some utilities to help troubleshoot using BPF (mebbe a little tcpdump), and some of user space utilities like free. You can use chatgpt etc to guide but make sure you understand. Books I recommend are linux kernel by Robert love, Richard Stevens. tcp/ip and of course you can ask chatgpt to come up with a summary for more recent topics. I been sharing some of notes @ [https://kaamvaam.com/categories/infrastructure/](https://kaamvaam.com/categories/infrastructure/)",
          "score": 15,
          "created_utc": "2026-01-21 18:29:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wraik",
          "author": "StevieP_",
          "text": "Build an K3s cluster, hits all of theses points with practical experience",
          "score": 6,
          "created_utc": "2026-01-21 19:21:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0w9vj4",
          "author": "GrogRedLub4242",
          "text": "read about them. learn. theres no one perfect only path. we are awash in a sea of learning material now like never before.",
          "score": 5,
          "created_utc": "2026-01-21 18:04:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0w61vv",
          "author": "Jolly-Mushroom-7512",
          "text": "Try kodekloud",
          "score": 3,
          "created_utc": "2026-01-21 17:48:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11hdyf",
          "author": "General-Conclusion13",
          "text": "Preparing for the same, we can connect for side projects and stuff!",
          "score": 1,
          "created_utc": "2026-01-22 13:13:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11l0lu",
          "author": "Alternative_Bill_754",
          "text": "Pick few certifications from golden kube astronaut or AWS or Azure or GCP. ArgoCd certification will also help.",
          "score": 1,
          "created_utc": "2026-01-22 13:34:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1awe7n",
          "author": "SadServers_com",
          "text": "Since you mentioned Linux troubleshooting, I suggest SadServers :-)",
          "score": 1,
          "created_utc": "2026-01-23 20:22:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi2ian",
      "title": "SRE: Past, Present, and Future - what changed and where is it going?",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1qi2ian/sre_past_present_and_future_what_changed_and/",
      "author": "Pippa_the_second",
      "created_utc": "2026-01-20 14:27:29",
      "score": 47,
      "num_comments": 25,
      "upvote_ratio": 0.9,
      "text": "In the 2010s, SRE was a hot field. Companies wanted SREs and many were even willing to pay a premium, relative to their SWE counterparts. Which made sense considering the on-call and after hours work.\n\nIt stopped being a hot field after a few years. I cannot pinpoint an actual event to cause this, but with the rise of AWS and Kubernetes, my sense is that SRE was not as critical as before.\n\nThe overall brand also faced dilution. To some, SRE was a SWE who could not code. This was reflected in hiring. In one FAANG, I remember there was a brouhaha when a SRE recruiter asked his SWE counterparts to send him candidates who performed strongly but did not pass the coding bar. The SREs were livid. I hope I am not doxxing myself now.\n\nAs we come to the recent few years, there was a trend towards Platform Engineers. To me, they were SREs at the core. Now that trend feels like it is disappearing. I see fewer discussions about Platform Engineers AND SREs.\n\nAs I look to the future, I sense that SRE has been stripped out of so many core functions that it has lost its meaning. SRE means so little that other vendors now sell AI SRE and companies are willing to try it out. You do not hear about companies selling AI SWE even though Claude can write code.\n\nWhat do you think the future holds for SRE?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1qi2ian/sre_past_present_and_future_what_changed_and/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o0omqgs",
          "author": "Electronic-Work-311",
          "text": "I’ve been working as an SRE for the past 10 years, and I’ve come to realize that the title itself can be quite ambiguous, often varying significantly from one company to another. Some organizations even brand traditional Application or Production Support roles as “SRE” to make the position sound more appealing. \nIn my case, I primarily work with AWS, Terraform, architecture design, GitOps, Kubernetes, and some Python - building and operating infrastructure platforms. I developed internal workflows integrating Amazon Bedrock (AI) with the monitoring alerts. This has made me reflect on how I should actually define my role: Platform Engineer, DevOps Engineer, SRE, or Cloud Engineer.\nUltimately, though, I’ve learned that titles matter far less than the underlying skill set. Across companies, there’s a common core of skills that companies look for, and that’s what truly makes the difference. Again SWE are not SREs and vice versa, so the expectations shouldn't be same at all.",
          "score": 15,
          "created_utc": "2026-01-20 15:48:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oydag",
              "author": "hawtdawtz",
              "text": "While I agree this is the case for some companies, once you hit “big-tech” almost every SRE is a previous SWE or has substantial SWE skill sets. I feel like what you describe is a bit more platformy and devops like, which most bigger companies will have dedicated teams for.\n\nSincerely,\n\nA guy who’s done both and seen lots of flavors of SRE",
              "score": 9,
              "created_utc": "2026-01-20 16:41:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0tci6v",
              "author": "Useful-Process9033",
              "text": "I feel like the tooling layer has evolved but the underlying core skill sets hold true.\n\nSounds like you built an ai sre for your team internally, curious how that played out.\n\nBtw how did you find aws bedrock? I was at aws reinvent last year, went to a iHeartMedia talk, they also used it to develop their internal ai sre.",
              "score": 1,
              "created_utc": "2026-01-21 06:58:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0od8rt",
          "author": "Remote_Succotash",
          "text": "Out of curiosity, who sells \"AI SRE\"?",
          "score": 8,
          "created_utc": "2026-01-20 15:02:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ogtvk",
              "author": "Useful-Process9033",
              "text": "There’s plenty discussion on them in this sub and there’s like 100s of companies building them.\n\nThey more or less do the same thing, connecting to your logs, metrics, runbooks etc and tells you root cause when alerts fire/ draft postmortems, etc.",
              "score": 6,
              "created_utc": "2026-01-20 15:19:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0oyc77",
                  "author": "ambitiousGuru",
                  "text": "These are cool and all but if you don’t know what it is saying(assuming that it is correct) do you expect a SWE to be able to solve it? Especially if it is infra related. \n\nAI is good at gathering data points for you like these SRE agents but that’s one part of the job. \n\nIMO the SWE are going to hurt more because a business major can now come do their job for them. SWE at the core was architecting code and being in the weeds of the code. If now all you’re doing is prompting a LLM “create a function that does X”, how hard is the job really? Then it’s made a huge PR that a human cannot mentally take on so you need an agent to PR review. Seriously what is your job lol?\n\nUnless something that I haven’t come across yet that can view the full context(doesn’t exceed the context window) of the environment and you give it write access to do it then we will be the last to go. Even then do you trust a indeterministic solution to replace a human? Time will tell",
                  "score": 1,
                  "created_utc": "2026-01-20 16:41:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0p74sw",
              "author": "blitzkrieg4",
              "text": "Incident.io",
              "score": 4,
              "created_utc": "2026-01-20 17:22:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0pl5cs",
              "author": "emery-glottis",
              "text": "[Resolve.ai](http://Resolve.ai), [Rootly.com](http://Rootly.com), DataDog Bit AI, [incident.io](http://incident.io), [Traversal.com](http://Traversal.com), [Cleric.ai](http://Cleric.ai), [Neubird.ai](http://Neubird.ai) there's got to be 30 or more advertising AI SRE at this point. Also, [https://www.reddit.com/r/devops/comments/1m4egqq/a\\_growing\\_wave\\_of\\_ai\\_sre\\_tools\\_are\\_they/](https://www.reddit.com/r/devops/comments/1m4egqq/a_growing_wave_of_ai_sre_tools_are_they/) come up but even that list isn't complete at the time and has grown since. Resolve is dedicated and quite hype at the moment, incident has shown capability live on stage, i've spoken 3 different people who use Rootly say good things. I would advise, like any other tool, you find a baseline test and compare the top choices. If you're a DataDog shop that's prob an easy test for you.",
              "score": 2,
              "created_utc": "2026-01-20 18:26:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0puun7",
                  "author": "Disastrous-Glass-916",
                  "text": "And [Anyshift.io](http://Anyshift.io) :)",
                  "score": 1,
                  "created_utc": "2026-01-20 19:09:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0tbz1l",
                  "author": "Useful-Process9033",
                  "text": "And incidentfox! https://github.com/incidentfox/incidentfox/",
                  "score": 1,
                  "created_utc": "2026-01-21 06:53:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0omf6z",
              "author": "neeltom92",
              "text": "built an opensource one here : [https://github.com/neeltom92/sre-copilot](https://github.com/neeltom92/sre-copilot)  \n  \ninspired by : [https://clickhouse.com/blog/llm-observability-challenge](https://clickhouse.com/blog/llm-observability-challenge)",
              "score": 1,
              "created_utc": "2026-01-20 15:46:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0rj21w",
              "author": "NefariousnessOk5165",
              "text": "Ai Sre agents only helps you remove L1 , L2 layer … Sre in itself is quite huge !",
              "score": 1,
              "created_utc": "2026-01-21 00:02:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0st4a4",
              "author": "Ok_Housing7981",
              "text": "Ever heard of the company called “Harness”\n, they are taking a lot of funding and their entire goal is to replace Testing and devops/sre roles with AI",
              "score": 1,
              "created_utc": "2026-01-21 04:30:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0ofy24",
              "author": "Pippa_the_second",
              "text": "You can find plenty through a google search. This question will attract sales reps like flies to honey.",
              "score": -1,
              "created_utc": "2026-01-20 15:15:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ohnru",
          "author": "Useful-Process9033",
          "text": "Honestly I think the established engineers working in a company for a long time will never get replaced. I worked at a consumer big tech company and we had a team of people who’ve worked at the company for 10+ years that’s knows the infra inside and out. The tribal knowledge they have is crazy and all serious incidents/ outages get routed to them.",
          "score": 8,
          "created_utc": "2026-01-20 15:23:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0q7ck2",
              "author": "interrupt_hdlr",
              "text": "exactly. people saying AI will replace SREs completely in X years have no idea about what running a complex environment is like. \n\nAI can do a lot of things but it currently doesn't have all the information/signals to decide and if it did, 1M context windows would not even begin to scratch the surface. You need a dozen subagents , all sorts of MCPs and integrations... and you will still miss a lot of necessary context.",
              "score": 2,
              "created_utc": "2026-01-20 20:07:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0ta3is",
                  "author": "Useful-Process9033",
                  "text": "Haha I’m taking a stab at this with the dozen sub agents + tons of MCP approach you mentioned.\n\nI made another post in this sub about the open source ai sre agent that I’m building. Didn’t seem to get much attention yet.\n\nBut yea I think one of the hardest problem to solve is you need to have all these integrations since all the context is spread everywhere across different tools & every environment is different. I’m just sucking it up and building all these integrations one by one for now.\n\nThe context window problem is still very much true. I think they can be cracked with smart enough engineering.\n\nThough at the end of the day I’d think of AI as copilot and can’t be trusted to do write actions without human approval, since you still need human accountability in incident management.",
                  "score": 1,
                  "created_utc": "2026-01-21 06:37:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0owu21",
          "author": "red_flock",
          "text": "Anybody can code, but not everyone can stare at a million line code base and solve a performance issue at 3am. Is that SRE? I dont know, but that's what I think an ideal \"real\" SRE ought to be. But then again, is this a senior dev or an SRE?\n\nMeanwhile, there are SREs who code, but they dont touch the business code. Their coding is restricted to their tooling or Infrastructure. Is this SRE? Or Platform Engineers?\n\nThen there is people like me. I can write a little python, read a little bit of other people's code, but I mostly dont have to code, because there is always enough things on fire for me to put out. Most of you will say this is not SRE work, but even though I cannot check in a bug fix at 3am, I most certainly can get stuff back to a working state by hook or crook. If I am not an SRE, what am I?",
          "score": 14,
          "created_utc": "2026-01-20 16:34:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qf6v1",
          "author": "HiddenWithChrist",
          "text": "When some companies say SRE, they really mean Unicorn. At other Orgs, people are given the SRE title for their role, but in reality only do one particular thing (e.g. managing infra) and rely more heavily on Senior Engineering roles for more complex issues. At my workplace I'm whatever the Org needs me to be and wear the hats of SWE - identifying and troubleshooting bugs, Network Engineer- setting up VLANs, routing, Internal/External DNS, etc., DevOps- ci/cd pipeline creation/troubleshooting, K8s deployments, Terraform, Ansible, Argo, etc., Cloud Engineer, Platform Engineer- infrastructure deployment management and observability, Systems Performance, InfoSec, the list goes on and on. It's been great for me, since I enjoy challenging tasks and learning. SRE has kind of always been a vague title, IMO- same as \"DevOps\".",
          "score": 5,
          "created_utc": "2026-01-20 20:44:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11xukf",
          "author": "gerrowadat",
          "text": "SRE has always been a misunderstood term, even internally at G back in the day.\n\n  \nTwo things have moved the needle here IMHO:\n\n1. The tooling available. Making a database go, or doing monitoring at scale, or doing service orchestration used to be a lot harder and involved a lot more capital-E engineering. Now you can just buy stuff and have a team of essentially systems integrators. This has been fairly linear, but I think it's on the cusp of a number of companies \"ingrowing\" certain key tech. The SaaS/PaaS providers have gotten lazy (incumbents like Pagerduty, and a couple of other examples of places that feel they can't just do-one-thing-well) - so a lot of the Engineering happening these days is in de-productising core functions - you can build your own monitoring or orchestration pretty easily with the building blocks available if you're willing to put some folks' time into it, and this starts being cheaper pretty quickly given the ballooning saas/paas prices.\n\n  \n2. What people are actually looking for when they hire SREs. This has been more of a bell-curve. SRE (or production engineering, or whatever) used to be a very hardcore disciple/specialisation of SWE -- then the industry convinced itself that DevOps was a thing, and that regular devs can moonlight as their operations groups and everything would be fine. This turned out to not actually be true in effect, so I thnk we're now seeing things rolling back to a sort of hybrid systems architect/integrator thing, given (1). The interesting parts anyway. It mostly gets masked by a trend throughout the whole timeline of people hiring SRE/DevOps/PlatEng that are just operations or maybe occasionally operations++.",
          "score": 2,
          "created_utc": "2026-01-22 14:41:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p1hoq",
          "author": "one-alexander",
          "text": "I like your discussion, but there are of course AI SWE in the market.",
          "score": 0,
          "created_utc": "2026-01-20 16:56:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0std7d",
              "author": "Ok_Housing7981",
              "text": "Tell me one company , which has its business only on AI SWE , there is no company like that\n\nBut as far as testing and sre/ devops is concerned , search about “Harness” , you will get to know",
              "score": 1,
              "created_utc": "2026-01-21 04:31:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qlqm8j",
      "title": "Honeycomb EU outage write-up is a good reminder that humans are still the bottleneck",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1qlqm8j/honeycomb_eu_outage_writeup_is_a_good_reminder/",
      "author": "TellersTech",
      "created_utc": "2026-01-24 15:58:02",
      "score": 44,
      "num_comments": 4,
      "upvote_ratio": 0.94,
      "text": "Just read it and yeah… it hit a nerve.\n\nLong incidents aren’t just “fix the thing.” It’s handoffs, fatigue, context getting dropped, people accidentally doing the same work twice, status updates eating cycles, and everyone getting a little more cooked as the hours pile up.\n\nIt also made me think about the curl bug bounty thing this week. Different domain, same failure mode. Once the input stream turns into noise (AI slop reports, alert spam, ticket spam), you don’t just lose time. You lose trust in the channel. Then the real signal shows up and gets missed.\n\nHow are you all handling this lately? Not just outages, but the “too much inbound” problem in general.\n\nHoneycomb report:  [ https://status.honeycomb.io/incidents/pjzh0mtqw3vt ](https://status.honeycomb.io/incidents/pjzh0mtqw3vt)\n\ncurl context: [https://github.com/curl/curl/pull/20312](https://github.com/curl/curl/pull/20312)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1qlqm8j/honeycomb_eu_outage_writeup_is_a_good_reminder/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o1g4oje",
          "author": "jdizzle4",
          "text": "my palms are sweaty after reading that. Those poor SREs, what a battle. So much respect for the transparency in writing up and publishing this much detail. Having been in similar long incidents where it feels like defeat after defeat... my heart rate was elevated while reading it.",
          "score": 16,
          "created_utc": "2026-01-24 16:21:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1gtgbf",
          "author": "TellersTech",
          "text": "Quick follow-up: I talked about this same ‘inbound noise kills trust’ thing on Ship It Weekly this week, using curl + the Honeycomb outage as examples. \n\nIf anyone wants the audio version: https://www.tellerstech.com/ship-it-weekly/curl-shuts-down-bug-bounties-due-to-ai-slop-aws-rds-blue-green-cuts-switchover-downtime-to-5-seconds-and-amazon-ecr-adds-cross-repository-layer-sharing/\n\nBut I’m more interested in what patterns actually work for teams here.",
          "score": 11,
          "created_utc": "2026-01-24 18:10:44",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o1iuekp",
          "author": "wfrced_bot",
          "text": "> Long incidents aren’t just “fix the thing.” It’s handoffs, fatigue, context getting dropped, people accidentally doing the same work twice, status updates eating cycles, and everyone getting a little more cooked as the hours pile up.\n\nI'm not following. The report was about the issue with restoring distributed self-managed metadata on a broken cluster. There is no mention of humans being a bottleneck anywhere.\n\n> It also made me think about the curl bug bounty thing this week. Different domain, same failure mode.\n\nWhat failure mode?",
          "score": 3,
          "created_utc": "2026-01-24 23:53:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ixvot",
              "author": "TellersTech",
              "text": "Yeah that’s fair. The write-up is basically all technical details, not “humans are the bottleneck” explicitly.\n\nWhat I meant was more the *pattern* you see in any long incident. Even when the root cause is 100% technical, after a few hours the limiting factor becomes people… handoffs, context loss, duplicate work, comms/status updates, fatigue. From what I’ve seen multi-region recovery stuff like this is where that really shows up.\n\nAnd the curl thing was the same vibe from a different angle. Once the input stream turns into noise, triage stops scaling and the channel loses trust.",
              "score": -1,
              "created_utc": "2026-01-25 00:11:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qicfdh",
      "title": "RCA: Why our H100 training cluster ran at 35% efficiency (and why \"Multi-AZ\" was the root cause)",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1qicfdh/rca_why_our_h100_training_cluster_ran_at_35/",
      "author": "NTCTech",
      "created_utc": "2026-01-20 20:25:43",
      "score": 40,
      "num_comments": 10,
      "upvote_ratio": 0.92,
      "text": "Hey everyone,\n\nI wanted to share a painful lesson we learned recently while architecting a distributed training environment for a client. I figure some of you might be dealing with similar \"AI infrastructure\" requests landing on your ops boards.\n\nThe Incident: We finally secured a reservation for a cluster of H100s after a massive wait. The Ops team (us) did what we always do for critical web apps: we spread the compute across three Availability Zones (AZs) for maximum redundancy.\n\nThe Failure Mode: Training efficiency tanked. We were seeing massive idle times on the GPUs. After digging through the logs and network telemetry, we realized we were treating AI training like a stateless microservice. It’s not.\n\nIt turns out that in distributed training (using NCCL collectives), the cluster is only as fast as the slowest packet. Spanning AZs introduced a \\~2ms latency floor. For a web app, 2ms is invisible. For gradient synchronization, it was a disaster. It caused \"Straggler GPUs\" basically, 127 GPUs were sitting idle burning power while waiting for the 128th GPU to receive a packet across that cross-AZ link.\n\nThe Fix (and the headache):\n\n1. Physics > Availability: We had to violate our standard \"survivability\" protocols and condense the cluster into a single placement group to get the interconnect latency down to microseconds.\n2. The \"Egress Trap\": We looked at moving to a Neocloud (like CoreWeave) to save on compute, but the SRE team modeled the egress costs of moving the checkpoints back to our S3 lake. It wiped out the savings. We ended up building a \"Just-in-Time\" hydration script to move only active shards to local NVMe, rather than mirroring the whole lake.\n\nThe Takeaway for SREs: If your leadership is pushing for \"AI Cloud,\" stop looking at CPU/RAM metrics. Look at Jitter and East-West throughput. The bottleneck has shifted from \"can we get the chips?\" to \"can we feed them fast enough?\"\n\nI wrote up a deeper dive on the architecture (specifically the \"Hub and Spoke\" data pattern we used to fix the gravity issue) if anyone is interested in the diagrams:\n\n[https://www.rack2cloud.com/designing-ai-cloud-architectures-2026-gpu-neoclouds/](https://www.rack2cloud.com/designing-ai-cloud-architectures-2026-gpu-neoclouds/)\n\n*Has anyone else had to explain to management why \"High Availability\" architecture is actually bad for LLM training performance?*",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1qicfdh/rca_why_our_h100_training_cluster_ran_at_35/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o0qj456",
          "author": "maccam94",
          "text": "Neoclouds mostly make sense if you run whole training jobs there, then send your completed runs back to your cloud storage. AI workloads must maximize data locality and minimize egress.",
          "score": 9,
          "created_utc": "2026-01-20 21:02:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0qtqtc",
              "author": "NTCTech",
              "text": "You are absolutely correct....the math only works if the compute savings significantly outweigh that initial data ingress and the final model egress.\n\nWhere we ran into trouble and why we ended up building that \"Just-in-Time\" hydration script was dealing with datasets in the multi-petabyte range. Moving the \"whole\" dataset over to the Neocloud before starting training was taking days and killing our iteration speed.\n\nWe've found that for the really big jobs, we have to stop treating data as a monolith and start streaming only the active shards to local NVMe. \"Maximize data locality\" is definitely the golden rule of '26.",
              "score": 5,
              "created_utc": "2026-01-20 21:50:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0r48cq",
                  "author": "Stephonovich",
                  "text": "> Maximize data locality\n\nSome of us have been screaming this for years, and were called old-fashioned, anti-progress, etc.\n\n2 msec is only invisible in a web app if it’s only happening a few times. When you have to take that hit on every transit, it adds up. This is the part that the optimists fail to understand: *most* web apps are not well-written, do not have performance in mind, and use a million abstractions to hide the fact that what is happening under the hood is very complex (often unnecessarily so, but I digress). So even if you built a well-designed schema, your ORM is going to murder performance by doing things like lazy-loading, rewriting JOINs to do separate SELECTs, etc. And when that happens, the 2 msec starts to add up very, very quickly.",
                  "score": 2,
                  "created_utc": "2026-01-20 22:42:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0sym6x",
          "author": "Ordinary-Role-4456",
          "text": "Funny how everything we learned from classic app deployments kind of falls apart with ML clusters. Leaders are always asking about redundancy but very few grok that distributed training is its own beast.   \n  \nAt the end of the day, feeding GPUs fast enough is more important than surviving a zone failure. It took a few wasted days of watching the cluster idle to hammer that lesson in here.",
          "score": 5,
          "created_utc": "2026-01-21 05:07:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tzjmp",
              "author": "NTCTech",
              "text": "That \"wasted days watching the cluster idle\" hits home hard. It’s the most expensive screensaver in the world.\n\nYou nailed the core conflict here. The hardest part of this transition isn't the technology; it's de-programming leadership (and frankly, ourselves) from fifteen years of \"always-on,\" \"design for failure\" web architecture dogma.\n\nWe have to keep reminding them: Distributed training isn't a microservice; it's High-Performance Computing (HPC) with better marketing. If a node dies, you don't want graceful degradation; you want to crash fast, roll back to the last checkpoint, and restart with full bandwidth. Trying to survive a zone failure by sacrificing 40% performance is bad math.",
              "score": 3,
              "created_utc": "2026-01-21 10:34:15",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o178f4p",
              "author": "re-thc",
              "text": "Not true. It doesn’t fall apart. AZ affinity always applies. In terms of redundancy you can still have it, just with 3 clusters (1 per AZ) instead of 1 across 3 AZs.",
              "score": 1,
              "created_utc": "2026-01-23 07:35:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0t9hlj",
          "author": "granviaje",
          "text": "You forget one important thing: coreweave is muuuuuuuuch better at getting working hardware to you and handling gpu failures than AWS and Azure. \n\n But yes,  ML training is HPC not some web service. There are very different requirements. ",
          "score": 2,
          "created_utc": "2026-01-21 06:32:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0u1f0e",
              "author": "NTCTech",
              "text": "That is an incredibly valid point and a fair critique.\n\nWe are definitely seeing the hyperscalers struggle with the physical reality of running these dense H100 racks at scale. The GPU failure rates on standard AWS P5 instances have been... higher than we'd like. The specialists like CoreWeave do seem to have better physical ops for keeping the silicon running right now because that's *all* they do.\n\nIt always comes down to that trade-off: Do you want better raw hardware reliability (Neoclouds), or do you want the comfort of your existing IAM/Security perimeter and data gravity (Hyperscalers)?\n\nAnd totally agree with your summary: It’s just HPC hidden behind a cloud API. We forget that at our peril.",
              "score": 1,
              "created_utc": "2026-01-21 10:50:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o10h5qi",
          "author": "millionflame85",
          "text": "Good read and blog. It also is a disconnect from the underlying core Compsci fundamentals understanding from the 90s. Using EBPF tools like bisnoop, biolatency, bpftime would show it in no time ( to someone knowing the bedrock fundamentals). Now every job requires particular monitoring tool knowledge like grafana, Prometheus (and you need to know the exact tool they use) but not the expertise to analyze them.",
          "score": 1,
          "created_utc": "2026-01-22 08:18:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qk0rug",
      "title": "Built OTelBench to test fundamental SRE tasks.",
      "subreddit": "sre",
      "url": "https://quesma.com/blog/introducing-otel-bench/",
      "author": "quesmahq",
      "created_utc": "2026-01-22 17:27:40",
      "score": 21,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1qk0rug/built_otelbench_to_test_fundamental_sre_tasks/",
      "domain": "quesma.com",
      "is_self": false,
      "comments": [
        {
          "id": "o1300tr",
          "author": "hijinks",
          "text": "thank you for testing what I've been telling every \"founder\" who created some AI Slop app to end SRE that its great for what does this log mean but horrible at the big picture",
          "score": 6,
          "created_utc": "2026-01-22 17:37:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1i1i7d",
              "author": "thearctican",
              "text": "Never mind having to ship off all of your APM events and source code to a third party.",
              "score": 1,
              "created_utc": "2026-01-24 21:29:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o133w44",
          "author": "maxfields2000",
          "text": "We were just discussing this at work with some engineering leaders and having a hard time explaining the challenges to folks who have had success writing code with Claude/Various models.  This blog is both timely and does a waaay better job than I could at cutting the situation down to actual facts/realities rather than feelings and emotions.\n\nDeeply appreciate how this blog is not written to be overly hypey nor \"anti-ai\".  Just the realities of the situation.",
          "score": 5,
          "created_utc": "2026-01-22 17:54:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o181aas",
          "author": "kusanagiblade331",
          "text": "Very interesting results. Thanks for sharing. I learnt something new today - Pareto frontier!",
          "score": 4,
          "created_utc": "2026-01-23 11:51:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qk7h3w",
      "title": "Front end observability",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1qk7h3w/front_end_observability/",
      "author": "Eduarworld",
      "created_utc": "2026-01-22 21:32:19",
      "score": 13,
      "num_comments": 4,
      "upvote_ratio": 0.84,
      "text": "Hey folks\n\nI’m an SRE working mostly on backend/platform observability, and I recently got pulled into frontend observability, which is pretty new territory for me.\n\nSo far I’ve:\n\n\t•\tEnabled Grafana Faro on a React web app\n\n\t•\tStarted collecting frontend metrics\n\n\t•\tSet alerts on TTFB and error rate\n\n\t•\tIngested Kubernetes metrics into Grafana via Prometheus\n\n\t•\tEnabled distributed tracing in Grafana\n\nAll of that works, but now I’m stuck \n\nI’m not fully sure:\n\n\t•\tHow to mature frontend observability beyond the obvious metrics\n\n\t•\tWhat kinds of questions frontend observability is actually good at answering\n\n\t•\tWhat’s considered high signal vs noise on the frontend side\n\nRight now I’m asking myself things like:\n\n\t•\tWhat frontend metrics are actually worth alerting on (and which aren’t)?\n\n\t•\tHow do you meaningfully correlate frontend signals with backend/K8s/traces?\n\n\t•\tDo people use frontend traces seriously, or mostly for ad-hoc debugging?\n\n\t•\tWhat has actually paid off for you in production?\n\nIf you’ve built or evolved frontend observability in real systems:\n\n\t•\tWhat dashboards ended up being valuable?\n\n\t•\tWhat alerts did you keep vs delete?\n\n\t•\tAny “aha” moments where frontend observability caught something backend metrics never would?\n\nWould love to hear experiences, patterns, or even “don’t bother with X” advice.\n\nTrying to avoid building pretty dashboards that no one looks at ",
      "is_original_content": false,
      "link_flair_text": "HELP",
      "permalink": "https://reddit.com/r/sre/comments/1qk7h3w/front_end_observability/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o16y14x",
          "author": "_dantes",
          "text": "Basics\n\n* Web Vitals\n* Session Replay (if allowed)\n* Client-side console errors\n* Do not treat the frontend as a backend service. Unify data around sessions, not transactions.\n* OTEL for RUM was still in SIG a few months ago.\n* We currently use rrweb, linked with logs and traceId, to unify data at the session level.\n* User events (business events) to capture real business requirements that cannot be solved with backend data alone.\n\nTo your questions\n    What kinds of questions is frontend observability actually good at answering?\n\nIf a client executes an action and cannot reach the backend from their device, how do you see it?\nService observability assumes you can observe incoming transactions. Frontend observability covers what happens before a transaction ever reaches the backend.\n\n    How do you meaningfully correlate frontend signals with backend / Kubernetes / traces?\n\nThere is no real standard yet. You need a unifying concept. A session ID representing a browser instance is essential to track a user. \nA traditional traceId does not work well from a session point of view—it only helps at the level of a single fetch, request, or DOM render process. \n\n    What has actually paid off in production?\n\nDetecting availability issues that do not depend on backend responses. Example: An Azure outage impacted Android devices, while iOS handled timeouts differently. Even though the failing component wasn’t hosted in Azure, frontend data showed:\n\n    A drop in requests fron backend mostly 85% ish. since most users use android.\n    A spike in connection issues on Android devices\n\nThis was invisible from backend metrics alone. You could use the useragent of the header to represent the system makling the call. With luck is not removed. With RUM data, that info is there by default.\n\n    What dashboards ended up being valuable?\n\nDashboards that represent business value, such as:\n\n* Login success rate from the user’s point of view (not backend success)\n* Login retries\n* Client-side console errors\n* Timeout errors\n* Web Vitals\n* making Funnels for Business Process. (Ex onboarding). \n\n    Any “aha” moments where frontend observability caught something backend metrics never would?\n\nAnything that is frontend-only will never be captured by the backend. If the user cannot reach the backend:\n\n* The backend only sees fewer transactions\n* Frontend observability explains why",
          "score": 6,
          "created_utc": "2026-01-23 06:09:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14i64w",
          "author": "razler_zero",
          "text": "I would map user's journey end-to-end. You will get better picture which one is often the pain points of the customers in regards to the front-end.",
          "score": 5,
          "created_utc": "2026-01-22 21:45:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o165npc",
          "author": "No-Anxiety-6297",
          "text": "A good option is using OTEL SDK for your application / service. With that you can get end to end tracing for every new front end request generated.",
          "score": 2,
          "created_utc": "2026-01-23 03:04:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qk5ncm",
      "title": "Need suggestions and your pov",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1qk5ncm/need_suggestions_and_your_pov/",
      "author": "shru_2317",
      "created_utc": "2026-01-22 20:22:59",
      "score": 7,
      "num_comments": 28,
      "upvote_ratio": 0.64,
      "text": "24F this side, So for quite sometime  I am giving interviews for senior SRE roles . And there are instances when even after hiring manager round(i.e. last round) . I get rejected and they never gave me a reason . In interview the interviewer gives me feedback that I am doing great and hr will contact me in few days  and the only thing I hear from HR is they chose someone else over me.\n\nIs it because hiring manager thinks that certain gender would be available more oncalls instead of me ? \n\n\nAlso this assumption was confirmed by 1 HR that they thought someone else would be more available on night shifts and they think I won't be. Weird ",
      "is_original_content": false,
      "link_flair_text": "CAREER",
      "permalink": "https://reddit.com/r/sre/comments/1qk5ncm/need_suggestions_and_your_pov/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o141n6s",
          "author": "Derriaoe",
          "text": "No, that's not a gender thing. The current market is hell.",
          "score": 36,
          "created_utc": "2026-01-22 20:26:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o170jab",
              "author": "alik604",
              "text": "+1. I'm 27M and been interviewing for Senior 2+ years\n\nMarket is hell",
              "score": 4,
              "created_utc": "2026-01-23 06:29:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o141z4h",
          "author": "tamara_henson",
          "text": "48F.  Been working in Tech since 2002.  I get rejected all the time for roles.  You gotta just keep moving forward, keep applying and keep interviewing.",
          "score": 33,
          "created_utc": "2026-01-22 20:28:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1463zh",
              "author": "shru_2317",
              "text": "Comforting words , Thank you!",
              "score": 7,
              "created_utc": "2026-01-22 20:47:39",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o1acrun",
              "author": "OneMorePenguin",
              "text": "This.  You generally won't get a reason because that might open them up for some kind of legal issue.  Try not to take it personally.  But I am sure there is gender and age and other biases out there.",
              "score": 1,
              "created_utc": "2026-01-23 18:51:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o142kne",
          "author": "raymond_reddington77",
          "text": "Senior SRE at 24? You must be very smart. However it takes years to understand how systems work. I can’t speak to every sre role but in general, companies are looking for more experienced engineers who can speak to real world experience. But more power to you if you do get hired. Maybe the market has changed. I don’t think it’s a gender thing but everyone is different.",
          "score": 17,
          "created_utc": "2026-01-22 20:30:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o14617h",
              "author": "shru_2317",
              "text": "I finished my college early , So I now have 4.8 years of experience and I am working as one. \nThank you.",
              "score": -5,
              "created_utc": "2026-01-22 20:47:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o14xj4z",
                  "author": "TheBadgerKing1992",
                  "text": "Yeah in today's oversaturated market, 4 years is not senior material, sorry. Someone coming in with 10+ years will always be picked over you.",
                  "score": 13,
                  "created_utc": "2026-01-22 23:05:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o14el52",
                  "author": "ghostreport",
                  "text": "Nowadays, especially big tech, they rarely give out senior to folks with less than 8YOE.",
                  "score": 5,
                  "created_utc": "2026-01-22 21:27:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o14yego",
                  "author": "realitythreek",
                  "text": "As a hiring manager I’d find that to be suspect. Then again, that’s why I’m not allowed to even ask your age.\n\nIt’s dumb but by the time you’re interviewing face to face they’re looking for “culture fit” which could absolutely include gender/age (or the perception of). Not legally but they just wouldn’t give that as the reason. The only thing you can do is to keep interviewing until you get to a less toxic workplace.\n\nAnd it doesn’t help that hiring has been down for several years now.",
                  "score": 4,
                  "created_utc": "2026-01-22 23:09:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1cm7xr",
                  "author": "hawtdawtz",
                  "text": "Not sure why this is downvoted worthy",
                  "score": 1,
                  "created_utc": "2026-01-24 01:39:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1g8k74",
                  "author": "neuralspasticity",
                  "text": "That’s not very senior, my junior SREs have about that experience",
                  "score": 1,
                  "created_utc": "2026-01-24 16:38:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1h01cw",
                  "author": "shru_2317",
                  "text": "Why Am I getting downvoted for saying the truth about myself ? Weird",
                  "score": 1,
                  "created_utc": "2026-01-24 18:38:46",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o144mf3",
          "author": "engineered_academic",
          "text": "Honestly it has less to do with your gender and probably more to do with your inexperience. However you totally have a lawsuit against that 1 HR if you are in the US.",
          "score": 9,
          "created_utc": "2026-01-22 20:40:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o146bcv",
              "author": "shru_2317",
              "text": "I live in India but maybe they can give me the exact reason . I can do better in that area.",
              "score": 2,
              "created_utc": "2026-01-22 20:48:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1476un",
                  "author": "engineered_academic",
                  "text": "Oh yeah in India you are fucked. No offense.",
                  "score": 9,
                  "created_utc": "2026-01-22 20:52:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o148vss",
          "author": "Black_Dawn13",
          "text": "The market is very competitive at the moment so the best option is to just keep trying.",
          "score": 2,
          "created_utc": "2026-01-22 21:00:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14h6x0",
          "author": "Beginning-Can-1248",
          "text": "Hey there, I’m 26 with about 3.5 YOE and considering applying to Mid level, but how did you get to senior at 24??\n\nDid you work at FAANG or what’s your experience. I’m also kind of curious about the interview process nowdays? What are you seeing on the interviews and what kind of TC? Apply to Interview ratio? Leetcode or Cloud questions?",
          "score": 2,
          "created_utc": "2026-01-22 21:40:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o15y39f",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 6,
              "created_utc": "2026-01-23 02:22:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o15yql2",
                  "author": "Beginning-Can-1248",
                  "text": "Ahh that makes sense. A lot of contractors at my org are like that",
                  "score": 3,
                  "created_utc": "2026-01-23 02:26:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o14qmq1",
          "author": "smuzzu",
          "text": "If they don't hire you maybe that job is not for you, trust me.",
          "score": 2,
          "created_utc": "2026-01-22 22:27:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1cmfcj",
          "author": "hawtdawtz",
          "text": "Market is tight. The big fish still get interviews at least. Lots of ex FAANG able to land the open roles.",
          "score": 2,
          "created_utc": "2026-01-24 01:41:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17127k",
          "author": "Humble_Detective_656",
          "text": "Forget the titles. My team's hiring for an SRE, and with your experience, you'd be an L2 – our senior engineers are L4 with like 10-12 years of exp. I'd suggest you focus on responsibilities, scale, and the money offered.",
          "score": 1,
          "created_utc": "2026-01-23 06:33:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ea1wa",
          "author": "KiritoCyberSword",
          "text": "Maybe lack Years of exp requirement",
          "score": 1,
          "created_utc": "2026-01-24 08:48:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1krg52",
          "author": "SilverOrder1714",
          "text": "I do agree that the situation is incredibly frustrating when you don't get proper feedback. \n\nI will submit two perspectives for you to consider:\n\n1. Interviews (especially at senior levels) involve a lot of hidden variables - internal candidates, team balance, budgets etc. Don’t try to reverse engineer every ‘no’. A healthy approach would be to learn what you can and move on quickly. \n2. An interview isn’t just them interviewing you, it is also you evaluating them. If a team is actually making assumptions about your availability based on gender or personal factors, that is actually a red flag about their culture. You really don’t want to work in a place like that anyway.\n\nOne practical step you could take for the next interview is to be explicit about your comfort with on-call.\n\nI would expect the interviewer to bring this up but if they don’t, feel free to ask what their expectations are with on-call/availability during outages.\n\nKeep going. Hiring is competitive right now and it might take a while, but that just means it’s worth the wait!\n\n\n\nPS: Do check that you are applying for roles that match your YOE. Hopefully the JD is clear on this.",
          "score": 1,
          "created_utc": "2026-01-25 06:44:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14bajl",
          "author": "thearctican",
          "text": "I’m calling industry conditions.\n\nThere are pushes for residency to support data sovereignty.\n\nI’ve worked with great SRE women both in the United States and in India. Gender is never a consideration when picking candidates for my org.",
          "score": 1,
          "created_utc": "2026-01-22 21:12:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o15ig2z",
          "author": "GrogRedLub4242",
          "text": "We can't know all the particulars. We do know you are very young (ie. relatively very inexperienced compared to many competitors now) and you have poor English (ESL? India or Russia?). You might otherwise be the best SRE skill-wise but folks doing hiring look for any flaws/showstoppers to pass on someone, simply so they can filter their total inbound set down. This market now is hard for everyone, including folks with longer resumes and perfect native English.",
          "score": 1,
          "created_utc": "2026-01-23 00:55:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkyqxv",
      "title": "What do you use to manage on-call rotations + overrides (multi-team) with iCal/Google Calendar export?",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1qkyqxv/what_do_you_use_to_manage_oncall_rotations/",
      "author": "katsil_1",
      "created_utc": "2026-01-23 18:28:49",
      "score": 6,
      "num_comments": 8,
      "upvote_ratio": 0.75,
      "text": "Hi!  Currently we are implementing oncall duty/rotation in our company (around 10 teams on oncall and 30 users in rotation will be) and i wanted to ask: what are you using to rotate your duties? My goal is to find a solid \"Source of Truth\" for scheduling that supports overrides/swaps and can export the final schedule as an iCal feed or to Google Calendar\\*\\* natively, because we are using Workspace\n\n**The Context:**\n\n* In the future, we plan to use Grafana OnCall for calling/alerting escalation, utilizing its \"Import schedule from iCal URL\" feature. <<< \\*\\*\n* We need a way to manage the shifts now that is cleaner than manually dragging and dropping events in the Google Calendar UI (which becomes a nightmare with multiple teams and frequent overrides).\n\nHere is my thoughts and what i do not want for now:\n\n1. Manually maintaining everything in Google Calendar UI (too painful with multiple teams)\n2. linkedin/oncall ([https://github.com/linkedin/oncall](https://github.com/linkedin/oncall)) seems to be abandonware and doesn't appear to support iCal export/sync easily\n3. Grafana OnCall (OSS) I know I can do scheduling directly there, but I'm looking into options where I can import *into* it as well (but if you thing  using Grafana OnCall purely as a scheduler is the best way.... please give me an advice).\n4. *\\[What we are testing/researching now\\]* Bettershift ([https://github.com/panteLx/BetterShift](https://github.com/panteLx/BetterShift)) is an interesting option and it seems to be the best option for visually seeing rotations and updating them, but you can't set up a rotation like \"I want Ivan to be on duty every other week,\" you have to manually fill out the calendar (although this is actually a really good option because you can export everything to Google at once)\n\nSo i\\`ve spend already some time to research and right now asking you, community, for any advice or, in general, how do you organize shifts in your teams?\n\nWhat’s your current setup (tooling + process)? Anything you wish you’d done differently when scaling to multiple teams?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1qkyqxv/what_do_you_use_to_manage_oncall_rotations/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o1aaxgs",
          "author": "founders_keepers",
          "text": "here's my dilemma with these self hosted solutions.\n\nyou're literally adding yet anther failure point into the stack, who and how are you getting called about the on-call stack going down???  do you set up multiple layers of redundancy? when/where does it end? \n\nyeah.. so i just end up advising all my portcos to use Rootly.",
          "score": 9,
          "created_utc": "2026-01-23 18:43:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ac1s0",
              "author": "katsil_1",
              "text": "We definitely want and will use an external resource for oncall (e.g. grafana), and now I'm thinking about which resource to use to **create** **shifts** (namely, a convenient format for creating a calendar/assign of the current duty, etc....)\n\nThen this information will go to google calendar and grafana oncall will pick it up. I definitely do not want and will not create or use a self-hosted oncall solutions, for sure.",
              "score": 0,
              "created_utc": "2026-01-23 18:48:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1ae5h1",
                  "author": "founders_keepers",
                  "text": "gotcha. good stuff. then really what you should think about is alert volume and managing alert fatigue.\n\ngrafana don't give a hoot about how many alerts they're sending your team, how often, whether if it's useful or not. 10 teams of 30 users in rotation is not a small team, so it's not a trivial problem to solve.\n\nnot sure if you're aware but this is pretty big deprecation, i don't think there's long term vision behind Grafana oncall product at all.\n\nAs of March 24, 2026, Cloud Connection features for phone calls, SMS, and push notifications will no longer be supported in Grafana OnCall OSS. Refer to the documentation for [phone and SMS](https://grafana.com/docs/oncall/latest/manage/notify/phone-calls-sms/) and [push notifications](https://grafana.com/docs/oncall/latest/manage/notify/push-notifications/) for alternative setup options.",
                  "score": 1,
                  "created_utc": "2026-01-23 18:57:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1a8gpb",
          "author": "thecal714",
          "text": "Honestly, I've always done it the other way. FireHydrant and (IIRC) PagerDuty have ways to export to Google Calendar/iCal.",
          "score": 13,
          "created_utc": "2026-01-23 18:32:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ahqv1",
          "author": "Useful-Process9033",
          "text": "When I worked at a big company we used to just use PagerDuty and it doesn’t sync with Google Calendar etc at all. PagerDuty UI had always been confusing to me tbh but we had a lot of alert templates and teams etc set up to sync with it from GitHub config files, so I think the switching cost was too high.",
          "score": 3,
          "created_utc": "2026-01-23 19:14:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1jovpk",
              "author": "ccb621",
              "text": "PagerDuty definitely had an iCal export, and has had one for at least eight years. ",
              "score": 1,
              "created_utc": "2026-01-25 02:37:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1a9rek",
          "author": "Pethron",
          "text": "Go the other way around and use whichever platform you’re already using (pagerduty, jira on call, servicenow, and the likes). I personally like grafana oncall but using the jira one.",
          "score": 5,
          "created_utc": "2026-01-23 18:37:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1dk4dn",
          "author": "thatsnotnorml",
          "text": "We're using VictorOps (rebranded as Splunk On Call). It's an all in one so I'm not sure if it fits your use case, but it does have iCal link that I can pass to various stakeholders so they know who is on-call if needed. I actually imported it into my own Google calendar and I probably use that to check who's on call more than anything since I have a calendar widget on one of my home screens.",
          "score": 1,
          "created_utc": "2026-01-24 05:10:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qj7zzz",
      "title": "Anyone using logic monitor for observability?",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1qj7zzz/anyone_using_logic_monitor_for_observability/",
      "author": "Heisenberg_7089",
      "created_utc": "2026-01-21 19:42:54",
      "score": 5,
      "num_comments": 7,
      "upvote_ratio": 0.86,
      "text": "Basically what the title says. If you are using it or ever used it, would like to know about your experience. ",
      "is_original_content": false,
      "link_flair_text": "ASK SRE",
      "permalink": "https://reddit.com/r/sre/comments/1qj7zzz/anyone_using_logic_monitor_for_observability/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o0ylsci",
          "author": "Stephonovich",
          "text": "I used to be an SRE at LM. What questions do you have?",
          "score": 2,
          "created_utc": "2026-01-22 00:44:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10ebko",
              "author": "Heisenberg_7089",
              "text": "It's mostly for the customers of LM. I am using it for the first time, coming from AppD, Datadog, Dynatrace kind of background. I find LM quite amateur. I don't think it'll be able to help diagnose and troubleshoot production issues as efficiently as other tools I mentioned. So, I'm interested to find out if it's just me who feels that way about LM.",
              "score": 1,
              "created_utc": "2026-01-22 07:52:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o119ofh",
                  "author": "Stephonovich",
                  "text": "When I was there, they were pivoting from an explicit “we aren’t doing APM” to “we probably should have done APM,” so there’s that.\n\nThe platform, to me, is / was (haven’t used it in years) a power user tool, like how Windows applications were back in the 90s. It has immense capability and customization, but it isn’t going to hold your hand. I wouldn’t call it amateur, just designed with a different mindset.",
                  "score": 2,
                  "created_utc": "2026-01-22 12:25:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o10yh3l",
          "author": "SomeEndUser",
          "text": "Worked for a company that used LM and AppD. LM is good for devices and metrics but it’s not an APM. Great for fleet monitoring and data center ops.",
          "score": 1,
          "created_utc": "2026-01-22 10:58:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1679vy",
              "author": "No-Anxiety-6297",
              "text": "When you say devices and metrics - are you talking about network/sys devices? \nAnd what about logs? Is LM any good as a logs platform?",
              "score": 1,
              "created_utc": "2026-01-23 03:13:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1ql2tep",
      "title": "How do you make “production readiness” observable before the incident?",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1ql2tep/how_do_you_make_production_readiness_observable/",
      "author": "ImpossibleRule5605",
      "created_utc": "2026-01-23 21:00:12",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 0.67,
      "text": "In SRE work, I’ve often seen “not production ready” surface only after something breaks — during an incident, a postmortem, or a painful on-call rotation. The signals were usually there beforehand, but they were implicit: assumptions in config, missing observability, unclear failure modes, or operational responsibilities that weren’t encoded anywhere.\n\nI’ve been exploring whether production readiness can be treated as an explicit, deterministic signal rather than a subjective judgment or a single score. The approach I’m experimenting with is to codify common production risk patterns as explainable rules that can run against code or configuration in CI or review, purely to surface risk early, not to block deploys or auto-remediate.\n\nThe core idea is that production readiness is not a checklist or a score, but accumulated operational knowledge made explicit and reviewable.\n\nRepo: [https://github.com/chuanjin/production-readiness](https://github.com/chuanjin/production-readiness)  \nSite: [https://pr.atqta.com/](https://pr.atqta.com/)\n\nI’m curious how other SREs think about this. Where do you currently encode “this will page us later” knowledge? Is it policy-as-code, human review, conventions, or just experience and postmortems? And where do you feel automation genuinely helps versus creating false confidence?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1ql2tep/how_do_you_make_production_readiness_observable/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o1c5lrg",
          "author": "-ghostinthemachine-",
          "text": "Simple: you break it. Over and over again. There are fortunately many tools available now to do just that. Then you identify the gaps and do it all again next month. If something catches you by surprise you can add it to the suite of things you intentionally break, sometimes called a smoke test.",
          "score": 1,
          "created_utc": "2026-01-24 00:06:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1edq21",
              "author": "ImpossibleRule5605",
              "text": "I agree — intentionally breaking systems is one of the most effective ways to surface real gaps, and chaos-style testing is hard to replace. In practice though, I’ve seen a lot of the learnings from those exercises stay implicit: they show up in postmortems, runbooks, or people’s heads, but don’t always get encoded back into something that runs continuously.\n\nWhat I’m interested in is how some of those “we got surprised by X” lessons can be distilled into static or pre-deploy signals — things that don’t replace breaking systems, but reduce how often we rediscover the same class of problems the hard way. For me it’s less about avoiding failure and more about making past failures harder to forget.\n\nCurious how you’ve seen teams successfully close that loop over time.",
              "score": 1,
              "created_utc": "2026-01-24 09:22:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qitz0k",
      "title": "Anyone using datadog's Bits AI?",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1qitz0k/anyone_using_datadogs_bits_ai/",
      "author": "Secure-Print-2881",
      "created_utc": "2026-01-21 10:02:24",
      "score": 4,
      "num_comments": 4,
      "upvote_ratio": 0.7,
      "text": "It's demo looks beautiful! but facing real product enviroment, does it still works well?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1qitz0k/anyone_using_datadogs_bits_ai/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o0xqdjv",
          "author": "bikeidaho",
          "text": "The one time I demoed it, it gave me very generic advice that didn't really apply and charged me $32 bucks.",
          "score": 14,
          "created_utc": "2026-01-21 22:01:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1kkhd6",
              "author": "a_simple_fence",
              "text": "It’s crazy expensive for what it is",
              "score": 1,
              "created_utc": "2026-01-25 05:51:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o187x9w",
          "author": "jdizzle4",
          "text": "it was not good in my (few) experiences with it, and expensive",
          "score": 3,
          "created_utc": "2026-01-23 12:38:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1e70yw",
          "author": "andyr8939",
          "text": "We tried it and had some direct interactions with the Bits AI Product team to provide feedback.\n\nFor one of our customers that is very well invested with OTEL across everything, and very strict tagging/naming and logging standards, it worked really well.\n\nBut for other customers that didnt have as good coverage, it was hit and miss.  Some investigations would be very accurate but many just couldn't give more than any SRE would get in a 5 minute glance.  \n\nBut the kicker for everyone was the cost, its just not viable to have it billed the way it is.  We gave that feedback and were told bluntly that was very common, so should be pricing changes coming soon.",
          "score": 2,
          "created_utc": "2026-01-24 08:20:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi0m7n",
      "title": "Drafted a \"Ring 0\" safety checklist for kernel/sidecar deployments (Post-CrowdStrike)",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1qi0m7n/drafted_a_ring_0_safety_checklist_for/",
      "author": "Neat_Economics_3991",
      "created_utc": "2026-01-20 13:06:44",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.72,
      "text": "Hey all,\n\nBeen digging into the mechanics of the CrowdStrike outage recently and wanted to codify a strict \"Ring 0\" protocol for high-risk deployments. Basically trying to map out the hard gates that should exist before anything touches the kernel or root.\n\nThe goal is to catch the specific types of logic errors (like the null pointer in the channel file) that static analysis often misses.\n\nHere is the current working draft:\n\n* Build Artifact (Static Gates)\n   * Strict Schema Versioning: Config versions must match binary schema exactly. No \"forward compatibility\" guesses allowed.\n   * No Implicit Defaults: Ban null fallbacks for critical params. Everything must be explicit.\n   * Wildcard Sanitization: Grep for \\* in input validation logic.\n   * Deterministic Builds: SHA-256 has to match across independent build environments.\n* The Validator (Dynamic Gates)\n   * Negative Fuzzing: Inject garbage/malformed data. Success = graceful failure, not just \"error logged.\"\n   * Bounds Check: Explicit Array.Length checks before every memory access.\n   * Boot Loop Sim: Force reboot the VM 5x. Verify it actually comes back online.\n* Rollout Topology\n   * Ring 0 (Internal): 24h bake time.\n   * Ring 1 (Canary): 1% External. 48h bake time.\n   * Circuit Breaker: Auto-kill deployment if failure rate > 0.1%.\n* 4. Disaster Recovery\n   * Kill Switch: Non-cloud mechanism to revert changes (Safe Mode/Last Known Good).\n   * Key Availability: BitLocker keys accessible via API for recovery scripts.\n\nI threw the markdown file on GitHub if anyone wants to fork it or PR better checks: [https://github.com/systemdesignautopsy/system-resilience-protocols/blob/main/protocols/ring-0-deployment.md](https://github.com/systemdesignautopsy/system-resilience-protocols/blob/main/protocols/ring-0-deployment.md)\n\nI also recorded a breakdown of the specific failure path if you prefer visuals: [https://www.youtube.com/watch?v=D95UYR7Oo3Y](https://www.youtube.com/watch?v=D95UYR7Oo3Y)\n\nCurious what other \"hard gates\" you folks rely on for driver updates?",
      "is_original_content": false,
      "link_flair_text": "DISCUSSION",
      "permalink": "https://reddit.com/r/sre/comments/1qi0m7n/drafted_a_ring_0_safety_checklist_for/",
      "domain": "self.sre",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qkzbtp",
      "title": "Need a guidance",
      "subreddit": "sre",
      "url": "https://www.reddit.com/r/sre/comments/1qkzbtp/need_a_guidance/",
      "author": "Advanced_Collar5051",
      "created_utc": "2026-01-23 18:50:08",
      "score": 3,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "In your experience, what percentage of CI/CD failures are “we’ve seen this before” problems?\nDo teams have any system that remembers past fixes, or is it mostly human memory?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/sre/comments/1qkzbtp/need_a_guidance/",
      "domain": "self.sre",
      "is_self": true,
      "comments": [
        {
          "id": "o1ainge",
          "author": "xonxoff",
          "text": "Usually, the only failures I see are in code building.",
          "score": 2,
          "created_utc": "2026-01-23 19:18:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1aldji",
          "author": "hijinks",
          "text": "This is market research",
          "score": 2,
          "created_utc": "2026-01-23 19:31:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}