{
  "metadata": {
    "last_updated": "2026-01-21 02:39:59",
    "time_filter": "week",
    "subreddit": "softwarearchitecture",
    "total_items": 20,
    "total_comments": 109,
    "file_size_bytes": 172028
  },
  "items": [
    {
      "id": "1qdhlca",
      "title": "The U.S. Gov once threw a hacker in solitary because they thought he could WHISTLE nuclear launch codes. I wish I was joking.",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qdhlca/the_us_gov_once_threw_a_hacker_in_solitary/",
      "author": "Suspicious-Case1667",
      "created_utc": "2026-01-15 11:57:07",
      "score": 65,
      "num_comments": 14,
      "upvote_ratio": 0.83,
      "text": "Okay Reddit, gather around, because this is one of those stories where reality is so stupid it loops back into entertainment.\n\nSo, in the 90s, hacker Kevin Mitnick gets arrested. Fine. He did hack stuff. Cool.\nBut here‚Äôs where everything goes full WTF levels unknown to mankind:\n\nA federal judge was convinced genuinely, unironically convinced that Kevin could ‚Äústart a nuclear war by whistling into a phone.‚Äù\n\nLet me repeat that:\nA man was thrown in solitary confinement because someone thought he could blow up the world using dial-up noises.\nThis wasn‚Äôt satire.\nThis was the United States justice system.\nThey literally banned him from:\nUsing a phone\nTouching a computer\nBeing near anything with ‚Äútones‚Äù\nAnd kept him in solitary like he was a human rootkit about to self-replicate\nAll because they believed he was some kind of mythical techno-wizard who could whistle binary like a Final Boss NPC.\n\nMeanwhile, actual cybersecurity experts were like:\n\n‚ÄúUh‚Ä¶ that‚Äôs not‚Ä¶ how anything works.‚Äù\nAnd the court was like:\n‚ÄúShhhhh. He‚Äôs dangerous. He knows‚Ä¶ computers.‚Äù\n\nThe whole thing became one of the biggest controversies in cybercrime history because it showed just how hilariously clueless the system was about technology.\n\nImagine going to prison because a judge thinks you might be able to hack NORAD with your mouth.\n",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qdhlca/the_us_gov_once_threw_a_hacker_in_solitary/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nzppld9",
          "author": "jonathon8903",
          "text": "From my understanding of his story it was an unfortunate mix of an overzealous prosecutor and a judge who didn't understand technology to have any doubt. I'd like to hope that a similar situation couldn't happen today.",
          "score": 16,
          "created_utc": "2026-01-15 11:59:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpw4hy",
              "author": "Isogash",
              "text": "The system generally assumes that the defense is responsible for defending against stupid prosecutions, so this guy's lawyers were clearly not good enough. I don't necessarily agree but that's still how it works.\n\nI'd like to think that we've come a long way since and you are more likely to get lawyers who are tech-savvy enough to cut through the bullshit.",
              "score": 3,
              "created_utc": "2026-01-15 12:45:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzq3pbv",
                  "author": "caboosetp",
                  "text": "The lawyer doesn't even need to be tech savvy. They need to be smart enough to listen to their client and find an expert who can testify.¬†",
                  "score": 7,
                  "created_utc": "2026-01-15 13:31:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzq4b6o",
          "author": "Fine-Ad9168",
          "text": "Whistling into phones to hack was very much a thing.  I don't think think you could launch missiles, I think you could just get free long distance calls.",
          "score": 10,
          "created_utc": "2026-01-15 13:35:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpukx2",
          "author": "eduanlenine",
          "text": "And now we all have to watch boring videos from his security training company",
          "score": 7,
          "created_utc": "2026-01-15 12:35:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqf0tk",
          "author": "pandershrek",
          "text": "You can indeed hack an air gapped machine with tone injection. It was shown with a PoC less than 20 years ago, so this actually isn't far fetched because most scada systems are hilariously insecure.\n\nOn the tail of Stuxxnet they did a ton of work at kapersky to understand how so many exploits went into one attack. \n\nThough this might have been from a presentation at black hat before that",
          "score": 5,
          "created_utc": "2026-01-15 14:32:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqk2zj",
          "author": "Exotic_eminence",
          "text": "üÜì KEVIN\n\nTo be fair he did do a lot of hacking with his mouth \n\nüëÑ \n\nIt‚Äôs called social engineering",
          "score": 7,
          "created_utc": "2026-01-15 14:57:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpq3ig",
          "author": "Comprehensive-Art207",
          "text": "‚ÄùEverything is computer.‚Äù /DJT",
          "score": 4,
          "created_utc": "2026-01-15 12:03:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpuyks",
          "author": "GForce1975",
          "text": "Mitnick was a cocky guy and didn't do himself any favors..but that was pretty ridiculous.\n\nRemember all the \"free mitnick\" merch?",
          "score": 5,
          "created_utc": "2026-01-15 12:37:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o045q5d",
              "author": "pioo84",
              "text": "Man, I'm frickin old.",
              "score": 2,
              "created_utc": "2026-01-17 15:06:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzr4u8p",
          "author": "arnedh",
          "text": "There was both the possibility of changing the mode of a telephone call with 2600Hz and of submitting numbers as DTMF tones. https://en.wikipedia.org/wiki/Phreaking.\n\nWith DTMF tones, he might even have been capable of controlling equipment and hitting higher privileges with ABCD codes. https://en.wikipedia.org/wiki/DTMF_signaling, https://en.wikipedia.org/wiki/Precise_tone_plan\n\nWhat you could possibly achieve vs a government computer with those two techniques (and clicking/tapping the right rhythm) is not clear to me, but if I were the judge, I think I would err on the side of caution - the government wouldn't be likely to be forthcoming with specifics on what one could or couldn't hack, especially if security was below par  - imagine the headlines.",
          "score": 5,
          "created_utc": "2026-01-15 16:32:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzro69i",
          "author": "hxtk3",
          "text": "You say it's totally unreasonable like that should mean it's not true, but at one point in the development of the US ICBM-based nuclear deterrent, the design was such that a brown-out in rural Montana would've triggered a nuclear war. So I'm not surprised that someone unfamiliar with cybersecurity wouldn't immediately write off the possibility.",
          "score": 2,
          "created_utc": "2026-01-15 17:59:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztk4jc",
          "author": "bigbearandy",
          "text": "TBF, those of us who know how to whistle multi-frequency tones were able to drop a POTS line into maintenance mode and do a number of things you would otherwise need a blue box to achieve. However, hacking NORAD was not one of those things. At the time, the Defense Nuclear Agency access nodes were wide open, so you didn't need to whistle; you just social-engineered a login. \n\nDirect attacks weren't Mitnick's style; he usually collaborated with his partner, Roscoe, to physically penetrate a facility for intelligence and later used that information to hack it. \n\nAny sufficiently advanced methodology seems like magic, I guess. It was no fun for Mitnick when he was in prison, though, because he couldn't even call anybody to get money on his books.",
          "score": 2,
          "created_utc": "2026-01-15 23:16:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv9r4a",
          "author": "MattAtDoomsdayBrunch",
          "text": "hah! That's not how it works. The internet is a series of tubes.",
          "score": 1,
          "created_utc": "2026-01-16 05:09:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdjwx8",
      "title": "How to Make Architecture Decisions: RFCs, ADRs, and Getting Everyone Aligned",
      "subreddit": "softwarearchitecture",
      "url": "https://lukasniessen.medium.com/how-to-make-architecture-decisions-rfcs-adrs-and-getting-everyone-aligned-ab82e5384d2f",
      "author": "trolleid",
      "created_utc": "2026-01-15 13:45:44",
      "score": 46,
      "num_comments": 4,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qdjwx8/how_to_make_architecture_decisions_rfcs_adrs_and/",
      "domain": "lukasniessen.medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzqft3f",
          "author": "wampey",
          "text": "Thanks for this. Having listened to fundamentals of software architecture, I heard much of this but did not have it in paper form.",
          "score": 4,
          "created_utc": "2026-01-15 14:36:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrrib5",
              "author": "Frosty_Customer_9243",
              "text": "https://preview.redd.it/2fa1lc931kdg1.png?width=504&format=png&auto=webp&s=51bf9e4a0e76f12d88b39dd5c1cb8d561eadd279\n\nCheck out Andrew Harmel-Laws book \"Facilitating Software Architecture\"  \n[https://facilitatingsoftwarearchitecture.com/](https://facilitatingsoftwarearchitecture.com/)",
              "score": 7,
              "created_utc": "2026-01-15 18:14:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzscjyv",
          "author": "DeathByWater",
          "text": "I've been doing something similar lately, but with a few stages and a virtual/collaborative whiteboard. It goes a bit like this:\n\n\n- Introduce the problem/feature/proposed UX for addressing that problem (synchronous) - let people sit with it for a couple of days\n- Draw up a picture/diagram of the proposed technical implementation on a board and share with team (async)\n- Talk over in a shared meeting; make adjustments, add sticky notes (sync)\n- In that meeting - or a following one if it's bigger - ask the team to draw boxes around the various bits that might represent individual tasks (sync)\n\n\nBy the time backlog refinement/sprint planning/whatever you call it comes around, people are already familiar with the overall big picture (literally) and the scoping of an initial set of tasks. It's working fairly well; now just working on templating/scaling that process so other members of the team can drive it too.",
          "score": 4,
          "created_utc": "2026-01-15 19:49:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0e5t8u",
          "author": "Effective-Total-2312",
          "text": "This is interesting, thanks for sharing ! We have an architecture committee, and I've brought up some ideas to define new standards, so this information will definitely come in handy for me very soon !",
          "score": 1,
          "created_utc": "2026-01-19 00:57:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qgeg58",
      "title": "Regarding Modular Monolith , and Clean Architecture",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qgeg58/regarding_modular_monolith_and_clean_architecture/",
      "author": "Illustrious-Bass4357",
      "created_utc": "2026-01-18 17:22:20",
      "score": 18,
      "num_comments": 28,
      "upvote_ratio": 0.88,
      "text": "Should each module/bounded context have its own separate presentation layer (API controllers, DTOs, endpoints etc.), or is it better or more common to have one single presentation layer (like one big Web API project) that serves all modules?\n\nhttps://preview.redd.it/dwfujgxc65eg1.png?width=489&format=png&auto=webp&s=fc5658a49132abd3973113359f2cfe354f373421\n\n  \nthis is my current project setup and I think the controllers in the WebAPI are getting too overwhelming,",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qgeg58/regarding_modular_monolith_and_clean_architecture/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o0bt68l",
          "author": "Qinistral",
          "text": "It depends. If you have a ‚Äúmicroservoce‚Äù that handles say <5 entities, then you can probably do fine having them all together and packaging your classes by function. Otherwise, if you have a monolith with more entities, or multiple major subdomains, or just a LOT of business logic code (as opposed to simple CRUD) then it would be better to create sub-modules or libraries that encompass those sub domains end to end. This might also require you to have one or two common libraries that contain shared code, such as on one hand the server that wires up all the modules to the primary framework and server, and on the other hand a library that sets up the cross cutting shared code for all those individual modules, such as logging and database you know, utilities, and stuff like that. This later is how to do a ‚Äúmodular monolith‚Äù.\n\nYou‚Äôve expressed ‚Äúit‚Äôs overwhelming‚Äù so ya go for it. Split it up see how it feels. Doing that kinda refactor is how you learn and get a feel for it.",
          "score": 8,
          "created_utc": "2026-01-18 17:57:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0d3la9",
              "author": "kareesi",
              "text": "What you‚Äôve described is exactly what we do in my current org. We have a large modular monolith with common modules for the cross-cutting functionality. \n\nWe started with the shared presentation layer approach which made it hard to find anything and got unwieldy fast. Splitting it up helped draw clear boundaries of ownership for teams, and improved searchability/readability quite a bit.",
              "score": 2,
              "created_utc": "2026-01-18 21:45:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0hjdp6",
              "author": "Illustrious-Bass4357",
              "text": "thanks, I‚Äôll probably try to separate the presentation layer for some modules and see how it goes",
              "score": 1,
              "created_utc": "2026-01-19 15:09:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0dao94",
          "author": "gbrennon",
          "text": "Thats a hard decision with huge impacts! \n\nThis decision will involve:\n- size of the team\n- how team members interact\n- technical knowledge of the team\n\n\nMaybe for now it could make sense u choose something like:\n\nDefine bounded contexts with only domain and application layers(if u are going to use layers) and impl infrastructure and presentation as 2 packages. \n\n1 for the infrastructure one and 1 for presentation. \n\nIm suggesting this because if u the teams grow a lot team will just have to refactor 2 layers and u wont have friction with continuous integration and delivery  when all stay in the same project",
          "score": 2,
          "created_utc": "2026-01-18 22:18:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0hirti",
              "author": "Illustrious-Bass4357",
              "text": "I‚Äôm a solo dev right now, but I think it would be easier for people, or if I got other devs on the project ,if they decided to work on, say, the Menu module, they would just navigate through that bounded context.\n\nlike rn,  I have in each module the three basic layers (domain, application, and infra), and I thought maybe to make it more separated , or more complete as a whole I should include a presentation layer. that layer would have the controllers and presentation level DTOs, and then an IServiceCollection extension or something similar, and in the WebAPI app just do .AddFoodPresentation\n\nhttps://preview.redd.it/yzx94nrlmbeg1.png?width=361&format=png&auto=webp&s=916af3938583537f6ff6da6d06f1cfeb71b96015",
              "score": 2,
              "created_utc": "2026-01-19 15:06:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0kkfcd",
                  "author": "gbrennon",
                  "text": "that looks well structured bro! good job!\n\ni suggest u have a shared module or things like this to share base classes or interfaces that everyone can rely on like EventHandler and EventPublisher.\n\nfollowing thie approach each bounded context will be decoupled from each other BUT you will have also to have shared Event/Message/Command because  the bounded context that publishess a given integration message is not the same bounded context that will handle it.\n\nusually a domain message(event or commmand) can be kept in the same bounded context buut an integration one usually is across different bound contexts",
                  "score": 1,
                  "created_utc": "2026-01-19 23:41:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0czwa4",
          "author": "SolarNachoes",
          "text": "Each module can be represented in each layer in its own folder.\n\nPresentation\n /Todos\n /Users\n\nInfrastructure\n /Todos\n /Users\n\nEtc\n\nLater if you want to separate the entire module you just grab the appropriate folders.",
          "score": 1,
          "created_utc": "2026-01-18 21:25:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0g5xj1",
          "author": "jshalais_8637",
          "text": "Do you really need all of this? Most of the time it can be avoided, Don't over-engineer when it's not needed since this consumes much time on maintenance, explaining to new members and so on.",
          "score": 1,
          "created_utc": "2026-01-19 09:18:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0hj1et",
              "author": "Illustrious-Bass4357",
              "text": "It‚Äôs mainly for learning, tbh. \n\nand also if the app got bigger I think it would benefit me on the long run?",
              "score": 1,
              "created_utc": "2026-01-19 15:07:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ie3v5",
          "author": "codingfox7",
          "text": "The quick advice is: \"in most cases all elements of a module should be bundled together\".\n\nThe longer answer plus some remarks:\n\n* It's best to adhere to the High Cohesion pattern, because it is easier to maintain and understand code that is close together. Check out [https://codingfox.net.pl/posts/mim/#high-cohesion](https://codingfox.net.pl/posts/mim/#high-cohesion) (chapter \"8. Appendix - Introduction to Modular Design\", point \"High Cohesion\") for more explanation \n* Your design also breaks Low Coupling pattern (you coupled all modules in WebApi)\n* As a result, a simple change to e.g. Menus feature, will probably result with changes in 4 modules (in ideal world only one would be affected).\n\nYour question aside, I can tell you that your design is not really modular. It groups code into \"nouns\", so probably any \\_real\\_ business feature requires 2 or 3 modules to coordinate. That's will result in a big ball of mud sooner or later. Modules are self-contained, check out the \"A Module in the Modular Design\" subchapter (the same link as above).\n\nI also think that your modules are unnecessarily split by \"layers\", but is it really helpful?, or rather forces devs to constantly jump around? Instead split code by \"processes\" or \"features\" (and only extract \"infra\" code per module if you need to test it separately). You can see what I mean here: [https://codingfox.net.pl/posts/mim/#business-modules](https://codingfox.net.pl/posts/mim/#business-modules) (chapter \"Business-Modules\" of \"Simplify your Application Architecture with Modular Design and MIM\"). At the end of the article there's a long list of resources you can dig into to learn why I advised you to use these patterns.",
          "score": 1,
          "created_utc": "2026-01-19 17:29:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0imakc",
              "author": "Illustrious-Bass4357",
              "text": "I haven't read the resources yet, but you said that if I want to modify a real business feat I would require 2 or 3 modules and it will result in a big ball of mud sooner or later.  \n  \n(I don't know if I'm right or wrong), but in my design I'm using the contract layer to do exactly that, like, e.g., a Menu module needs to access some data from the Food module to get the ingredients, so the Menu Application layer depends on Food.Contract, which has, an interface and is acting like a contract. Right now I'm doing it synchronously and in memory.\n\nThe thing I think I'm doing wrong here is the fact that the Web API has all the presentation layers of the modules, and, honestly, I'm probably going to refactor them out.",
              "score": 1,
              "created_utc": "2026-01-19 18:06:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0iu6or",
                  "author": "codingfox7",
                  "text": "I meant these: \"Menu.Application\", \"Menu.Domain\", \"Menu.Infrastructure\", and \"WebApi\".\n\nYou wrote: \"so the Menu Application layer depends on Food.Contract\". But is just means that Menu depends on Food. What if you will need something from Menu in Food?\n\nThere's a heuristic that says \"a module should be ready to be extracted as a microservice\". In most cases it won't be ever extracted, but the point is it forces you to think about processes, not nouns.\n\nIf you have a large number or direct (method call) or indirect (messages) usages of one module in another, you would be better off merging them.\n\nInstead of thinking about \"Menu\" and \"Food\", make for instance an \"Ordering process\" module and separate \"Delivery process\" module. Arrange data so that each module has all data they need to fulfill it's responsibilities.\n\nI included a long list of resources that describe the modular design process. (Making a design based on nouns is so 1999 ;) )\n\nBTW: A case from just 2 weeks ago. In one of the services a big feature turned out to be unnecessary. I got rid of it in code by removing ONE module (and the registration from program.cs). In types of designs showed here, it should be shotgun surgery through many modules (csprojs) to remove a feature.",
                  "score": 1,
                  "created_utc": "2026-01-19 18:40:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0iugda",
                  "author": "steve-7890",
                  "text": "Extracting presentation layers into modules themselves is a good move.",
                  "score": 1,
                  "created_utc": "2026-01-19 18:42:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ckojh",
          "author": "Effective-Total-2312",
          "text": "That's just crazy. I am not a C# dev, but I would rather die than work in such a messy structure.\n\nLately, people are doing kinda the same thing with different names: vertical slices, package by feature, modular monolith, etc.\n\nIn all cases, the idea is that those setup are good when you start small, and once starting to get somewhat big, you should be able to easily separate each module/feature/slice into entirely different repositories/services.\n\nIf following those trends means having such a mess, I'd rather already go into different services, or use a hexagonal/clean/onion architecture which is much more easily navigable and understandable.",
          "score": -5,
          "created_utc": "2026-01-18 20:06:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0d01zr",
              "author": "Wiszcz",
              "text": "I think hexagonal/clean/onion is the same mess with more boilerplate :) They all try to do the same thing, and all look great on small/simple/crud applications. Add few queue sources, few db's, api versioning and you will always end up with mess.",
              "score": 4,
              "created_utc": "2026-01-18 21:26:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0d1xzk",
                  "author": "Effective-Total-2312",
                  "text": "I honestly don't see how could you end up with that.\n\n\\- Create a layer with your API code  \n\\- Create a layer with your domain logic, entities, and interfaces  \n\\- Create a layer with your infrastructure/external systems code\n\nJust use an IoC library (injects a concrete implementation/adapter for any port used throughout your code), and voil√°, you have your hexagonal/clean/onion architecture. What's simpler than that ?\n\nDependency management is ultra simple; API calls domain code, infrastructure leverages domain interfaces. That's just it.\n\nGranted, I put a services layer in-between my API and domain, handles some orchestration and transformations, as thin as possible. Still pretty easy and almost no boilerplate.",
                  "score": 1,
                  "created_utc": "2026-01-18 21:37:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0daxws",
              "author": "gbrennon",
              "text": "People are just naming things to sound new but its the same things as always üòÖ",
              "score": 1,
              "created_utc": "2026-01-18 22:20:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0hgkp6",
              "author": "Illustrious-Bass4357",
              "text": "can you elaborate more on how do you find it messy?? I literally went for this architecture because it‚Äôs very clean in terms of navigation and separation of concerns , like If you want to modify or update a **Menu-specific** use case, you go to the **Menu bounded context**, then the **Menu.Application** layer, and edit it there. You can‚Äôt really mess up anything in other modules\n\nAlso, I‚Äôm not trying to argue or claim that I‚Äôm right.  \nI‚Äôm still in college and haven‚Äôt worked on a real-world production app yet, so I assumed this structure or architecture would be better for production use.",
              "score": 1,
              "created_utc": "2026-01-19 14:55:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0i8t4m",
                  "author": "Effective-Total-2312",
                  "text": "I would surely bet you're going a very good direction, most developers working out there are really bad. Like really really bad. And again, have in mind I don't work in C#, but in Python, so my backends and applications look drastically different.\n\nI can't elaborate too much in a reddit thread, but there are a few things I care mostly when seeing a component level architecture:\n\n\\- Cohesiveness of each element/layer  \n\\- Efficiency of connections/dependencies\n\nThen, on a more \"mundane\" level, I want the file hierarchy to be easily navigable as well as cognitively easy; if I see more than 5-6 folders in a same directory, that sounds wrong. If I see more than 5-6 files in a directory, that sounds wrong. They're like code smells to me, it's similar to the Single Responsibilty principle, it sounds like there is too much going on there; either it isn't, and some things can be grouped, or it is, and some extraction or re-design can be made.\n\nSome times you may simply need those multiple dirs/files too. That's what happens with \"smells\".\n\nI don't know if my way of doing architecture works out in C#, so take my advice with a grain of salt, but I've had my good share of C# developers turning to Python and being a complete mess trying to understand what to do in a more free environment like Py.",
                  "score": 1,
                  "created_utc": "2026-01-19 17:05:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qhk69j",
      "title": "How to correctly implement intra-modules communication in a modular monolith?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qhk69j/how_to_correctly_implement_intramodules/",
      "author": "Tobi1311",
      "created_utc": "2026-01-19 23:16:51",
      "score": 18,
      "num_comments": 19,
      "upvote_ratio": 0.92,
      "text": "Hi, I'm currently designing an e-commerce system using a modular monolith architecture. I have decided to implement three different layers for each module: Router, to expose my endpoints; Service, for my business logic; and Repository, for CRUD operations. The flow is simple: Router gets a request, passes it to the Service, which interacts with Repository if necessary, and then the response follows the same path back. Additionally, I am using a single PostgreSQL database.\n\nThe problem I'm facing is that but when deciding how to communicate between modules, I have found several options:\n\n* **Dependency Injection (Service Layer):** Injecting, for example, `PaymentService` into `OrderService`. It's simple, but it seems to add coupling and gives `OrderService` unnecessary access to the entire `PaymentService` implementation when I only need a specific method.\n* **Expose modules endpoints:** Using internal HTTP calls. It‚Äôs an option, but it introduces latency and loses some of the \"monolith\" benefits.\n* **Event-bus communication:** Not an option. The application is being designing for a local shop, won't have much traffic so I consider implementing a queue message will be adding unnecesary complexity.\n* **Module Gateway:** Creating a gateway for each module as a single point of access. While it might seem like a single point of failure, I like that it delegates orchestration to a specific class and I think it will scale well. However, I‚Äôm concerned about it becoming a duplicate of the Service layer.\n\nI‚Äôm looking for your opinions, as I am new to system design and this decision is taking up a lot of my research time.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qhk69j/how_to_correctly_implement_intramodules/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o0knch0",
          "author": "rkaw92",
          "text": "If you have a procedure that spans several modules from start to finish, it's usually a sign that you need some form of orchestration. But it can be pretty minimal, like a function that calls different modules sequentially. Think about a Use-Case Controller. It would need access to several modules, of course - so inject them as dependencies.\n\nThe thing is, this is now your actual service layer. This is the crux of your application that clients will interact with. They don't really see the underlying modules anymore - they focus on the desired behavior or the \"what\", not the \"how\". You've now composed a rich process controller out of its constituent parts.\n\nTraditionally, this is called a mediator - an object that talks to many different objects to manage a complex process by passing data and calls back and forth. However, lately the word \"mediator\" has been hijacked (mostly by the .NET people, see MediatR) to mean \"a command dispatcher\". Keep this in mind when looking for code examples.",
          "score": 15,
          "created_utc": "2026-01-19 23:56:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0qm18r",
              "author": "Tobi1311",
              "text": "Very interesting, will read about that. Thank you!",
              "score": 1,
              "created_utc": "2026-01-20 21:15:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0kiloc",
          "author": "SolarNachoes",
          "text": "DI and move on. You can always refactor to other solutions as long as you access the payment method via DI‚Äôd interface.\n\nIf you don‚Äôt want to use the entire payment service, then you can write a small adapter class. But that‚Äôs getting a bit anal.",
          "score": 10,
          "created_utc": "2026-01-19 23:31:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0kqi3r",
              "author": "SmurphsLaw",
              "text": "Just be careful you don‚Äôt make circular dependencies.",
              "score": 4,
              "created_utc": "2026-01-20 00:14:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0qmbet",
              "author": "Tobi1311",
              "text": "Yeah, maybe I lost a lot of time trying to overengineering.",
              "score": 1,
              "created_utc": "2026-01-20 21:16:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mknnz",
          "author": "zlaval",
          "text": "I use in memory buses / application events for this (publishing events from a service and processing them elsewhere). It provides low coupling, high speed and if necessary it is easy to extract later into separate service.",
          "score": 2,
          "created_utc": "2026-01-20 06:59:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kqh1o",
          "author": "Effective-Total-2312",
          "text": "I don't see the benefit in doing \"modular monolith\". If your system is small enough, you should just use either of the traditional patterns: MVC, Layered, Pipe and Filter or Hex architecture. If your system is too big for those, split into two or three services (not microservices, just different and isolated services), each with one of the mentioned architectures.",
          "score": 2,
          "created_utc": "2026-01-20 00:13:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kvnd2",
          "author": "Character_Respect533",
          "text": "Im building another 'Manager' layer where its purpose is to call the operation in each service. For example, CreateUser in manager layer will call CreateUser in UserModule and also ScheduleSendEmail in NotificationModule.\n\nThe manager layer will call multiple operations in multiple modules so then I can keep the concerns separated",
          "score": 1,
          "created_utc": "2026-01-20 00:41:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kzvhf",
          "author": "theycanttell",
          "text": "Depends on injections",
          "score": 1,
          "created_utc": "2026-01-20 01:04:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mivat",
          "author": "flavius-as",
          "text": "This decision is not one you make now and never change it again.\n\nEach of your suggestions is valid and what you currently want to do depends on where you are on a Roadmap to transforming the modulith to microservices.\n\nIf you're far from it (or not even planned) then a simple method call should be enough.\n\nIf you're about to split it, some http mechanism or event store or whatever is maybe better to simulate and iron out any required guarantees in an inconsistent system.\n\nThis decision is not one you make now and never change it again. It's a decision you do now based on your current requirements and project planning.\n\nThe key part is to make it such that changing this decision later on the Roadmap to another strategy is easy.\n\nCircular dependencies and all other good design principles still apply, no matter what.",
          "score": 1,
          "created_utc": "2026-01-20 06:44:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mleo1",
          "author": "olivergierke",
          "text": "Depending on what stack you‚Äôre working in, event-based communication might not be as complicated as you think. I spoke about this at the jChampions Conference 2025:\n\nhttps://www.youtube.com/live/eiFnSevxAdk?si=U_N2xbozjntzW5Gf\n\nThe talk discusses the topic in a context of a Spring application, but the fundamentals should be understandable even outside that.",
          "score": 1,
          "created_utc": "2026-01-20 07:05:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0n0y22",
          "author": "codingfox7",
          "text": "You wrote \"(injecting)¬†PaymentService into OrderService. It's simple, but it seems to add coupling\". Yeah, it does, but all other methods do it too, but not so explicitly. Messaging also makes modules coupled.\n\n\nAdding async communication will bring you many problems inherent to Distributed Systems (e.g. eventual consistency inside a monolith or losing messages during reboot (with in-memory queue), etc.)\n\n\nCheck out my text for detailed explanation: https://codingfox.net.pl/posts/mim/#how-should-business-modules-communicate (subchapter \"How should Business-Modules communicate?\" from \"Simplify your Application Architecture with Modular Design and MIM\").",
          "score": 1,
          "created_utc": "2026-01-20 09:28:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0np38v",
              "author": "Tobi1311",
              "text": "Interesting article you wrote. You say that \"keeping Foreign Keys between modules should be avoided.\",  this made me think about my database design, where I do have foreign keys between modules (supplier in a purchase order, item in a sale\\_item table, item in a stock\\_movement table, etc.), wouldn't not having fk between modules introduce complex queries when information retrieval is needed?. Maybe this is great in a context where migrating to microservices is just about time, isn't it?\n\nAlso, this \"Public API\" you mentioned is like my gateway approach but with a great tech name, if I'm not wrong. I think I would take this way, it makes me feel that is a decision I will not change, because of the shop size, and it will scale well.\n\nWhat about when the communication is between entities from the same module? Let's say ItemService and CategoryService. Maybe this example is too simple, but what about when the intra-module communication gets complex? Is DI enough? Is the public API approach, in this context, a complex solution for a simple problem?",
              "score": 1,
              "created_utc": "2026-01-20 12:48:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0ojzp2",
                  "author": "codingfox7",
                  "text": ">wouldn't not having fk between modules introduce complex queries when information retrieval is needed?.¬†\n\nIt's a standard practice. Modules are self-contained, isolated, coherent \"processes\". If you need to make queries between modules and they constantly chat to do any flow, it means you have:\n\na) One big module  \nb) Or a big ball of mud antipattern.\n\nThere're many materials on that. One of the latest I've seen: [https://norbert.tech/blog/2025-10-18/dark-sides-of-modularization/](https://norbert.tech/blog/2025-10-18/dark-sides-of-modularization/) and there are more in \"Resources\" section on my MIM text. If you have FK between tables, any migration to microservice would be impossible (and that's one of heuristic for a well designed module),\n\nIf you need to do reports from data, you have to build a read-model. But that's a different topic.\n\n>Also, this \"Public API\" you mentioned is like my gateway approach but with a great tech name,\n\n\"Public API\" is like a facade. But it doesn't have to be Facade pattern per se or even an interface.\n\n>What about when the communication is between entities from the same module?¬†\n\nI've never seen an \"inter-module communication\" done differently than DI or direct method calls. Well, I have seen an inter (and intra) communication that used an external message queue, but there was a reason for that (time sync was required).\n\nTo be honest, inside one module I don't even create interfaces, because I test whole modules end-to-end (Chicago School of tests), so I don't have to mock anything.",
                  "score": 1,
                  "created_utc": "2026-01-20 15:35:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0q3i7o",
                  "author": "Wiszcz",
                  "text": "I'm not sure if I understand correctly, but if you have tables in db that belong to module in code, but that table have fk's to tables in other modules - you don't have modular monolith, you have just monolith.",
                  "score": 1,
                  "created_utc": "2026-01-20 19:49:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0npu8q",
          "author": "Tarnell2",
          "text": "If your primary goal is keeping the module in a good state for later removal into a microservice then you‚Äôll likely be looking to implement some sort of Adapter / Anti Corruption Layer and then write up a lot of dependency cruiser rules to enforce that very specific mode of integration. This is more of a Hexagonal approach, and annoying to enforce, so a lot of overhead for a small system\n\nFrom your description though, applying a use case layer to manage complex workflows (only layer able to have knowledge of multiple services being present) is typical of N-Tier architecture and commonly appropriate for smaller applications.",
          "score": 1,
          "created_utc": "2026-01-20 12:52:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi0jf2",
      "title": "Silent failures are worse than crashes",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qi0jf2/silent_failures_are_worse_than_crashes/",
      "author": "CompetitiveUnit7360",
      "created_utc": "2026-01-20 13:03:13",
      "score": 18,
      "num_comments": 5,
      "upvote_ratio": 0.91,
      "text": "Failures are unavoidable when you build real systems.  \nSilent failures are a choice.\n\nOne lesson that keeps repeating itself for me, it's not whether your system fails, it's how it fails.\n\nhttps://preview.redd.it/56rmp6uy5ieg1.png?width=2786&format=png&auto=webp&s=f89bd98b5d4aed94437ff2a4ba0fa8f682b28757\n\nWhile building a job ingestion pipeline, we designed everything around a simple rule:  \ndon‚Äôt block APIs, don't lose data, and never fail quietly.\n\nSo the flow is intentionally boring and predictable:\n\n* async API ‚Üí queue ‚Üí consumer\n* retries with exponential backoff\n* dead letter queue when things still go wrong\n\nIf processing fails, the system retries on its own.  \n\n\nIf it still can't recover, the message doesn't vanish it lands in a DLQ, waiting to be inspected, fixed, and replayed.\n\nNo heroics. No \"it should work\".  \nJust accepting that failures will happen and designing for them upfront.\n\nThis is how production systems should behave:  \nfail loudly, recover gracefully, and keep moving.\n\nWould love to hear how others here think about failures, retries, and DLQs in their systems.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qi0jf2/silent_failures_are_worse_than_crashes/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o0o2h3a",
          "author": "oweiler",
          "text": "The DLQ part can be problematic if order is important. It sometimes is better to block.",
          "score": 2,
          "created_utc": "2026-01-20 14:06:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0qhrnc",
              "author": "CompetitiveUnit7360",
              "text": "At the moment order is not that important. Main purpose is that making sure that data is there",
              "score": 1,
              "created_utc": "2026-01-20 20:55:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0p36fj",
          "author": "Shekher_05",
          "text": "Interesting",
          "score": 2,
          "created_utc": "2026-01-20 17:04:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qk9i6",
          "author": "madrida17f94d6-69e6",
          "text": "I‚Äôll bite. RabbitMQ likely writes/caches in memory before flushing to disk, what if the broker crashes before it does so?",
          "score": 1,
          "created_utc": "2026-01-20 21:07:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r8exj",
          "author": "Exirel",
          "text": "I agree with you, silent failure are a choice, and in my opinion, usually a bad one. When it comes to error, beside the \"never be silent\", I tend to follow these two guidelines:\n\n* **let it crash**: if something isn't suppose to work, just crash, most of the time the crash happens because there is a bug, and you don't fix bug with more code, you fix them with better code; and if you don't like crash reports... well, test more, use better types, get proof that it works!\n* **fail fast**: if you can check a fail condition, check it as early as possible to exit the process as soon as possible, I don't like when a program waste resources to end in a failure that was predictable; for example don't wait a query to the database to fail a data type check",
          "score": 0,
          "created_utc": "2026-01-20 23:04:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qeonrb",
      "title": "350PB, Millions of Events, One System: Inside Uber‚Äôs Cross-Region Data Lake and Disaster Recovery",
      "subreddit": "softwarearchitecture",
      "url": "https://www.infoq.com/news/2026/01/uber-hivesync-data-lake/",
      "author": "rgancarz",
      "created_utc": "2026-01-16 18:52:04",
      "score": 17,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qeonrb/350pb_millions_of_events_one_system_inside_ubers/",
      "domain": "infoq.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qif3i2",
      "title": "What math actually helped you reason about system design?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qif3i2/what_math_actually_helped_you_reason_about_system/",
      "author": "TrappedInLogic",
      "created_utc": "2026-01-20 22:03:46",
      "score": 17,
      "num_comments": 14,
      "upvote_ratio": 1.0,
      "text": "I‚Äôm a Master‚Äôs student specializing in Networks and Distributed Systems. I build and implement systems, but I want to move toward a more rigorous design process.\n\nI‚Äôm trying to reason about system architecture and components¬†**before writing code**. My goal is to move beyond ‚Äúreasonable assumptions‚Äù toward a framework that gives¬†**mathematical confidence**¬†in properties like soundness, convergence, and safety.\n\n**The Question:**¬†What is the¬†**ONE specific mathematical topic or theory**¬†that changed your design process?\n\nI‚Äôm not looking for general advice on ‚Äúlearning the fundamentals.‚Äù I want the specific ‚Äúclick‚Äù moment where a formal framework replaced an intuitive guess for you.\n\nSpecifically:\n\n* What was the topic/field?\n* How did it change your approach to designing systems or proving their properties?\n* Bonus: Any book or course that was foundational for you.\n\nI‚Äôve seen fields like Control Theory, Queueing Theory, Formal Methods, Game Theory mentioned, but I want to know which ones¬†**really transformed your approach to system design**. What was that turning point for you?",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qif3i2/what_math_actually_helped_you_reason_about_system/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o0qyovi",
          "author": "MoustacheApocalypse",
          "text": "Not exactly a math answer but learning the difference between centralized versus distributed paradigms. \n\nIt is more logic or philosophy than math but it covers everything from system architecture to organizational change management, Conway's Law included. \n\nOnce you start down the path of distributed teams and distributed microservices based architecture, it is helpful to keep in mind that you are not only designing the system but also designing how the system is built and maintained. Very important when working on large systems in large corporate environments.",
          "score": 12,
          "created_utc": "2026-01-20 22:14:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0r6rts",
              "author": "OneHumanBill",
              "text": "There's a mathy answer in here. \n\nA centralized system like a hub and spoke model or even a tree model have a communications complexity of O(N).  Simple.  But that model also lacks resilience.  In other words, it's too simple. \n\nA decentralized system like a web has a communications complexity of O(N^2).  It's more complex but much more resilient while still being tractable.\n\nI have a personal belief that there's something near magical about O(N^2) being the measurable complexity of a system.  For me that goes beyond system architecture and into things like social structures. \n\nIsn't it interesting for example that when humanity turned ownership of their personal relationships over to social media companies, that this is when society started forming echo chambers and really going nuts?  I think this in large regard has to do with the fact that your relationships with extended friends on Facebook aren't really yours anymore.  They're Facebook's, and we've moved human relationships from the web model that has existed since the time of chimpanzees to a simple hub-and-spoke model. \n\nO(N^2), I'm telling you, it's special.  It trends naturally toward resilience and self-healing.  Go elsewhere at your peril.",
              "score": 5,
              "created_utc": "2026-01-20 22:55:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0r1wrf",
          "author": "vplatt",
          "text": "I'm interested to see other answers here, but I feel like you're asking for theoretical math frameworks to apply to engineering in a way that would let you deterministically descend through a system design.  \n\nIn reality, that's not how it works.  It's just as much art as anything approaching real engineering; much less science or being provably correct.  For starters, you almost never know all the requirements up front and your design must adapt over time to accommodate new requirements as they are discovered or asserted.\n\nTo help guide a system design, one chooses as organizing architecture and follows design principles in order to ensure consistency, try ensure the necessary degree of resilience, scalability, and correctness - all custom to the specific situation.  \n\nA big help in doing this is to know what patterns have been followed before for the kind of work you're doing.  A patterns repository is a big help with that.  Of course, there are different types of patterns as well.  \n\n- Design patterns\n- Architectural patterns\n- Anti-patterns\n- Analysis patterns\n\nThese are simply languages that help you talk about your system.  You can have opinions all day long, but if you cannot communicate your ideas in a way that allows others to participate in the creation of your system, then it's not going to enjoy much success and patterns help communicate your approach in a clear way and give you some guidelines to use in creating it.  \n\nTo be clear, even if you don't believe a word of what I'm saying, you will use patterns anyway.  Everyone adopts the repeatable practices that form a path of least resistance.  But you can do that in a fully conscious way and avoid trying to reinvent the wheel at every turn.  \n\n\n| **Category**               | **URL**                                                                                                                                                           | **Description**                                                                                         |\n| -------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- |\n| **Design patterns**        | [https://refactoring.guru/design-patterns](https://refactoring.guru/design-patterns) ([Refactoring Guru][1])                                                      | A comprehensive and practical catalog of software design patterns with explanations and examples.       |\n| **Architectural patterns** | [https://architectural-patterns.net/](https://architectural-patterns.net/) ([architectural-patterns.net][2])                                                      | A site focused on patterns used in software system architecture with explanations and pattern catalogs. |\n| **Anti-patterns**          | [https://kb.segersian.com/software-architecture/topics/anti-patterns/](https://kb.segersian.com/software-architecture/topics/anti-patterns/) ([Knowledgebase][3]) | A general knowledge base listing common software anti-patterns and explanations.                        |\n| **Analysis patterns**      | [https://en.wikipedia.org/wiki/Software_analysis_pattern](https://en.wikipedia.org/wiki/Software_analysis_pattern) ([Wikipedia][4])                               | Wikipedia entry explaining analysis patterns in software engineering with definitions and context.      |\n\n[1]: https://refactoring.guru/design-patterns?utm_source=chatgpt.com \"Design Patterns\"\n[2]: https://architectural-patterns.net/?utm_source=chatgpt.com \"Home | Architectural Patterns\"\n[3]: https://kb.segersian.com/software-architecture/topics/anti-patterns/?utm_source=chatgpt.com \"Anti Patterns | Knowledgebase\"\n[4]: https://en.wikipedia.org/wiki/Software_analysis_pattern?utm_source=chatgpt.com \"Software analysis pattern\"",
          "score": 8,
          "created_utc": "2026-01-20 22:30:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rs7vk",
              "author": "midasgoldentouch",
              "text": "Love Refactoring Guru.  Going to spend my allowance this year on the book.",
              "score": 1,
              "created_utc": "2026-01-21 00:52:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0r1b07",
          "author": "therealkevinard",
          "text": "Maybe elementary, but Little‚Äôs Law is a priceless trinomial. I was always a sucker for a good polynomial, though lol. \n\nI‚Äôd seen it before, ofc, but it really fell into place during an incident response a few years ago. With LL, I could decisively dial-in application config to get the outcome I wanted (vs repeated dials to eventually hone in on the target)  \n\nI‚Äôve since used it in preliminary diagrams to gauge the impact of architectural changes on up- and down-stream components, and it shows up on at least a few of my grafana dashboards.",
          "score": 8,
          "created_utc": "2026-01-20 22:27:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0r770r",
              "author": "Effective-Total-2312",
              "text": "I hadn't heard about this one, very intuitive but nice !",
              "score": 2,
              "created_utc": "2026-01-20 22:57:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0qyq0t",
          "author": "justUseAnSvm",
          "text": "Look up the LSMT paper: [https://www.cs.umb.edu/\\~poneil/lsmtree.pdf](https://www.cs.umb.edu/~poneil/lsmtree.pdf) they make a very good argument for why a log structured DB would work using a disk model (3.1), which is just a heuristic calculated on access speed.\n\nI should say, soundness, convergence, and safety are difficult to prove, nigh impossible with pen and paper. That's when folks reach towards something like TLA+, Alloy, or even Lean3 or something like that.\n\nPersonally, I've been able to get away with just thinking about systems in terms of invariants (what must always be true), and show that progress will be made with the only tests being quickcheck or hedgehog. If you can encapsulate your system into a statemachine, or to a simple interface, generative testing gets you pretty far.",
          "score": 3,
          "created_utc": "2026-01-20 22:14:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rfey1",
              "author": "TrappedInLogic",
              "text": "I‚Äôve been eyeing TLA+ mainly for reasoning about safety properties.\n\nI‚Äôm still trying to understand its limits in practice: how much can formal methods like TLA+ actually tell you about performance characteristics (throughput, latency..), versus just functional correctness?\n\nIs it fair to think of TLA+ as closer to an *operational-semantics / state-transition specification* of a system, rather than a tool meant for performance analysis?",
              "score": 2,
              "created_utc": "2026-01-20 23:42:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0rnpd3",
          "author": "engx_ninja",
          "text": "Just read software architecture in practice. It gives you mathematical confidence in your architectural tactics and how they address your measurable quality attribute scenarios.",
          "score": 1,
          "created_utc": "2026-01-21 00:27:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rqf6z",
          "author": "MattAtDoomsdayBrunch",
          "text": "Two things that have influenced my thinking.\n\n[A Note On Distributed Computing](https://waldo.scholars.harvard.edu/sites/g/files/omnuum6261/files/waldo/files/waldo-94.pdf)\n\nand \n\n[The Unix Philosophy](https://en.wikipedia.org/wiki/Unix_philosophy)",
          "score": 1,
          "created_utc": "2026-01-21 00:41:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rze9p",
          "author": "chipstastegood",
          "text": "What helped me was not math but physics, specifically simulations and experiments in physics. Concept of simulations has helped me model software better. And experiments have helped me write better tests, especially black box tests because in physics you often have to look at externally visible behavior to infer something about what‚Äôs going on inside a system.",
          "score": 1,
          "created_utc": "2026-01-21 01:32:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rewzd",
          "author": "ElderberryNo6893",
          "text": "https://en.wikipedia.org/wiki/Graph_theory",
          "score": 1,
          "created_utc": "2026-01-20 23:39:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rinhv",
          "author": "asdfdelta",
          "text": "(Systems Theory)[https://en.wikipedia.org/wiki/Systems_theory] governs absolutely everything, and imho is one of the core parts of being an architect versus anything else. Architects that don't think with a Systems lens tend to struggle with larger problem sets.",
          "score": 1,
          "created_utc": "2026-01-20 23:59:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdnu1l",
      "title": "How do teams actually keep requirements stable once development starts?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qdnu1l/how_do_teams_actually_keep_requirements_stable/",
      "author": "TobyNartowski",
      "created_utc": "2026-01-15 16:16:27",
      "score": 16,
      "num_comments": 25,
      "upvote_ratio": 0.91,
      "text": "I‚Äôve run into this situation more than once and also hear similar stories from other developers, so I‚Äôm curious how common this is among more experienced teams. \n\nIn many Agile setups, it feels like work starts before things are truly nailed down. Requirements are good enough to begin, but not really complete, and then they keep evolving while implementation is already in progress. Late in the process, someone suddenly realizes there‚Äôs a missing dependency - a contract, an external system, some approval that wasn‚Äôt accounted for upfront. \n\nAt the same time, different phases blur together. Analysis isn‚Äôt really finished, but coding begins because of deadlines. Development isn‚Äôt fully reviewed yet, but testing has already started. Releases get planned while there are still known open risks. \n\nThere doesn‚Äôt seem to be a clear point where everyone agrees: ‚Äúthis is the current truth we‚Äôre working against.‚Äù \n\nWhat I‚Äôm trying to understand is how teams that work well avoid this turning into constant rework and frustration. Do you rely on explicit handoffs or contracts between roles, or some kind of commitment point before starting implementation? \n\nHow do you handle changes once work is already underway without everything becoming reactive? I‚Äôm less interested in theory or framework definitions and more in what actually works in practice.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qdnu1l/how_do_teams_actually_keep_requirements_stable/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nzr279o",
          "author": "RipProfessional3375",
          "text": "You don't. Requirements shift as understanding shifts and the situation changes over time.  \nThe question is not: how to keep requirements stable?  \nThe question is: how to keep the code flexible?",
          "score": 73,
          "created_utc": "2026-01-15 16:21:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrtajk",
              "author": "Electronic_Yam_6973",
              "text": "Typically the people giving the requirements barely know what they are doing and what the really want. Or at least don‚Äôt do a great job at communicating what they mean",
              "score": 9,
              "created_utc": "2026-01-15 18:22:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzuacmd",
                  "author": "Comfortable_Ask_102",
                  "text": "This is a known feature of software development. Users **will never** **know** what they want, it's up to you (the development team) to figure it out since you're the experts in all software things. Our elders noticed this and came up with the agile principles, the relevant one for this case is: \"responding to change over following a plan.\"\n\nI believe the pragmatic programmers came up with the analogy of *digging* for requirements, rather than *gathering* requirements. Gathering implies the requirements are there, perfectly clear in the user's mind for you to pick them with your hand and take them to your shop. The reality is that requirements are buried under layers of assumptions, incomplete information and cargo cult. Users will tell you what they *think they want*, it's up to you to figure what they *actually need*.",
                  "score": 7,
                  "created_utc": "2026-01-16 01:40:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzryntb",
                  "author": "RipProfessional3375",
                  "text": "Yep, and only as the project takes shape will they realize it more and more, this is normal.",
                  "score": 6,
                  "created_utc": "2026-01-15 18:46:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzs4se8",
              "author": "TobyNartowski",
              "text": "Totally agree that requirements will always change.  \nWhat I keep running into is a slightly different pain: assumptions change late, but there‚Äôs no clear trace that the delivery conditions actually changed. When the deadline slips, it just looks like the team didn‚Äôt deliver - even though they were working against a moving target. Or worse, people start hacking things together last-minute just to hit the date, fully aware that code quality is taking a hit.",
              "score": 2,
              "created_utc": "2026-01-15 19:13:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzsdzg9",
                  "author": "RipProfessional3375",
                  "text": "Then the problem is feedback cycle and scope of delivery.\n\nIn other words, show what you have once a week, and don't have more in a deployment than what you can show in 15-30 minutes.",
                  "score": 7,
                  "created_utc": "2026-01-15 19:55:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzs8zrd",
              "author": "One-History-1783",
              "text": "And anticipate the futurn shifting. ( In code and with the project )",
              "score": 1,
              "created_utc": "2026-01-15 19:32:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzr3iyw",
          "author": "NoForm5443",
          "text": "My cheat has always been to build \\*simple\\* software \\*fast\\*. Requirements don't usually change within a month.",
          "score": 8,
          "created_utc": "2026-01-15 16:26:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzr8ww7",
              "author": "cstopher89",
              "text": "Yep same here. Build the MVP based on what we know now and iterate as we learn more.",
              "score": 3,
              "created_utc": "2026-01-15 16:51:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzuozyn",
          "author": "Effective-Total-2312",
          "text": "Most companies \"adopted scrum\" or other \"agile frameworks\" but they still want the deadlines from waterfall. Models like scrum are not designed for rigid deadlines, they're designed for uncertainty, which means no specific date as to when development is complete.\n\nSo, what can you do ? My guess is to just surf the wave as best as you can, try to deliver the best possible software, don't allow management to harrass you, and try to negotiate deadlines if needed and possible. Otherwise, change companies.",
          "score": 4,
          "created_utc": "2026-01-16 03:01:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzr3asg",
          "author": "Masked_Solopreneur",
          "text": "The goal is to create value, not build software according to specs.¬†\nFind out where the risks are highest, be it technical or other product risks, and try to understand those parts first or make them flexible.¬†\nIf some parts require heavy lifting to change, communicate this to other parts of the org and seek ways to test things with low investments.¬†",
          "score": 6,
          "created_utc": "2026-01-15 16:25:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrkbre",
          "author": "SeriousDabbler",
          "text": "Yeah the design process asks us to immerse ourselves in thr problem domain and understand the interactions. It may be tempting to expect that you can get a group of passionate and clever individuals together to solve a problem and they'll agree on a solution. They won't.\n\nAt best your requirements will be a compromise between what the individual stakeholders want and what's practical given the technology choices\n\nDuring design, analysis, development, testing, and support after you ship you'll detect requirements that you couldn't have predicted. That's ok\n\nBy all means try to confirm your requirements ahead of time to reduce rework and costs but feedback is part of the process\n\nIt doesn't mean you're stupid or wrong. It's just the process.\n\nThis was something I've had to wrestle with as an architect. Many times the architecture is wrong in ways that we only detect later. I used to give myself a hard time about it but now I accept it as part of the discipline",
          "score": 3,
          "created_utc": "2026-01-15 17:42:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzr9wrm",
          "author": "Glove_Witty",
          "text": "You need good product management and you need to release as small units of features as possible. \n\nIf you have a set of big features that roll into a major version release then agile (in the way you guys seem to be practicing it) is going to have the exact problems that you are seeing.",
          "score": 3,
          "created_utc": "2026-01-15 16:55:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzri7ch",
          "author": "two-point-zero",
          "text": "Should Agile promote the deliverable of something valuable each iteration? If a task is worth to be done for the value it can give NOW, even if not spec complete, it could be started in the next Sprint, and refined later right?\n\nOf course it should be up to the product owner to give priorities and to decide that there are enough information to start develop a feature even if incomplete; and to the team to give higher story points to uncomplete/unclear features,so they can eventually be postponed to a better time in the future when more infos will be available.",
          "score": 2,
          "created_utc": "2026-01-15 17:33:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzri7ri",
          "author": "OhMyGodItsEverywhere",
          "text": "I develop agreements with whoever I am delivering to (PM, customer, etc.) on what it looks like and what it means to agree on requirements and deadlines.\n\nIn essence: \"These are the requirements for a given deadline. Changes to the requirements after sign-off will incur a cost: push the deadline, add a payment, remove other requirements, or stick to the agreement. If you agree, sign here.\"\n\nYou can only estimate based on the conditions that you're given. When new conditions come in, estimates have to change.\n\nThis isn't so much a software architecture thing, more of a contractual or organizational thing. But in terms of software architecture, you'll want to design your systems to be be quickly modifiable and verifiable in anticipation of regular requirement changes: good version control, small PRs, readable code, single-responsibility modules, automated tests and builds, smooth continuous integration, and reviews to stick to these principles.",
          "score": 1,
          "created_utc": "2026-01-15 17:33:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01u1e0",
              "author": "Mysterious-Rent7233",
              "text": "It's deeply harmful to the project when you are in that kind of adversarial relationship. It is better to both have no deadlines and also be flexible to changes in requirements. Rather than using one as a hostage to avoid changes to the other.",
              "score": 2,
              "created_utc": "2026-01-17 04:15:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrnd3k",
          "author": "aWesterner014",
          "text": "The trick is differentiating between an evolving understanding of requirements and scope creep.",
          "score": 1,
          "created_utc": "2026-01-15 17:56:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsz8gc",
          "author": "admiral_nivak",
          "text": "Have a good product team who understand what you need to build as the MVP or feature, build, enhance, rinse repeat.\n\nIf you are running out of time cut scope, long hours are only used as a last resort for prod issues or contractual deadlines.",
          "score": 1,
          "created_utc": "2026-01-15 21:34:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztdj6s",
          "author": "severoon",
          "text": "When you start a new project, the most important thing is to prioritize work on the **core** functionality.\n\n other words, don't try to choose the requirements you want to target and treat them as stable, no, that's the wrong way around. Instead, try to choose the most stable requirements, and cut, cut, cut the list down to the absolute, bare bones minimum. This is known as defining the MIP, the minimum implementable product.\n\nFor example, if you are a bank, you have customers and those customers have certain characteristics in your system: a name, an address, a username, a DOB, etc. They have that stuff today, they will have that stuff tomorrow, and they will have that stuff 50 years from now. These customers have checking and savings accounts. Those are products your bank offers today, tomorrow, and will likely offer 50 years from now. Etc.\n\nBuild the most stable and durable stuff first. The most stable aspects of a system are also the things that are the most solid foundation for your system. IOW, these things can support lots of incoming dependency. Conversely, you should be careful to not build dependency in the other direction, where highly stable things depend upon things you add later which are not so stable over time. Also, you should make sure the most stable and depended-upon elements of your system are the most *dependable*‚Äîthat is, they are the most well-tested, documented, etc.\n\nThe only way this can go wrong is if your org decides they want to be a completely different business. If you are a bank and you build a bunch of bank stuff and then the board of directors says, hey, we decided we're going to be a movie theater company instead, you're kind of screwed.\n\nAnother milestone of such a project is the MVP, the minimum viable product. This is the most stripped-down version of your system that actually does something useful for customers. This, again, should be defined by cutting requirements down as much as possible, meaning that it may only be useful to your friendliest alpha customers, whom you've reached out to and gotten on board to be early adopters willing to use and give feedback on your limited alpha release.\n\nWhen you first sit down to design your new project, you start by blue skying all of the cool stuff you want it to eventually do, then you ruthlessly cut it down to the smallest possible thing you can implement, then on top of that highly stable, highly dependable backbone you implement the requirements that is the smallest possible thing you can roll out to actual customers, and you do that.\n\nThe next step from here is to start adding requirements that will bring in the largest number of additional customers for the least amount of effort. If you add a few more reqs, maybe you can add another 10% of your customer base to your alpha. Great, do that. This is how you continue building milestones until you have a beta that serves 75‚Äí90% of your customer base. Once you've run the beta with a significant customer base long enough to know it's stable, you start migrating customers to the beta and stress test it, it passes, you bring it out of beta, and then at some point you EOL the existing product and force-migrate your customers to the new thing. Along the way you will undoubtedly find that the long tail of customers you were supporting before will never migrate because you can't meet their requirements, and they're just not worth it unless those are on your roadmap somehow anyway.\n\nYour approach to this in your questions isn't quite right:\n\n>In many Agile setups, it feels like work starts before things are truly nailed down. Requirements are good enough to begin, but not really complete, and then they keep evolving while implementation is already in progress.\n\nWhen you say \"requirements\" you are not being specific enough. The reqs for the MIP should *absolutely* be nailed down and carved in stone. The only way this isn't the case is if the org doesn't know what business it's in, because that's how you chose these requirements for the MIP. Either that or, much more likely, this isn't how those requirements were chosen and you're not working on an MIP.\n\nIn that case, yea, if you don't approach a large, complex project in a disciplined way, life sucks. (But, then again, what do you expect? Doing things wrong is unnecessarily hard and frustrating.)\n\nI think a lot of times management looks at processes like Agile or other methodologies as a substitution for doing all of the hard planning work I describe above. They are not. Whatever methodology you choose, that's just a set of tools for execution and tracking of the necessary planning work. But none of these are going to save you if you're just doing the wrong things in the wrong order. Perfect tracking of a requirement that was inserted way too early in the project plan as it whips everyone around isn't a solution to any kind of problem, it's an indicator that there *is* a problem that someone needs to step in and solve by moving planning around. (And this kind of stuff will happen, and the methodologies do help identify them.)\n\nThe point of these methodologies is communication. Once a bunch of smart people have gotten into a room and come up with a plan, how do you convey that plan and map it down to specific daily tasks that everyone can execute? That's the big where Agile or whatever can shine.\n\nI often see another mistake that orgs make along the same lines, which is not respecting [Conway's law](https://en.wikipedia.org/wiki/Conway%27s_law). I've been on teams where management is told about Conway's law and they respond by saying, oh, this is great, now that I know about it, I can break it and, because we're aware we're breaking it, we can navigate around the potential pitfalls. This way, I get the org chart I want to manage, and we can have the technical architecture we want to produce, and those two things can stay decoupled.\n\nThey all learn in the end that, no, they're not decoupled, and that doesn't doesn't. You either build your architecture around your team structure, or you structure your teams around your architecture, and you have to choose. There is no third path.",
          "score": 1,
          "created_utc": "2026-01-15 22:42:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztwmtf",
          "author": "PhaseMatch",
          "text": "The key concepts in agile software development are \n\n\\- make change cheap, easy, fast and safe (no new defects)  \n\\- get fast feedback on the (user) value that change created\n\nWe use valuable, working software as a probe to uncover what the user actually needs;  while this is less efficient (in terms of delivery) you don't create anything that is not valuable, and you create it in value order.\n\nThis was central to Extreme Programming (XP), which is broadly what \"agile\" meant prior to about 2010, when Scrum starts to take off as a (Google trends) term.\n\nThe XP \"planning game\" dealt with how to address this in terms of delivery, along with having an onsite customer who dynamically collaborated with the team in place of fixed, upfront requirements.\n\n\\- Jeff Patton's stuff (User Story Mapping) deals with this approach   \n\\- Alistair Cockburn's \"Elephant Carpaccio\" exercise for developers is an example\n\nWhat works in practice is XP;  it was created by developers, for developers, as an integrated approach.\n\nGetting your codebase to the point where you can do this is half the battle.",
          "score": 1,
          "created_utc": "2026-01-16 00:23:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzy2q16",
          "author": "Constant_Physics8504",
          "text": "Design for the system, then design for the subsystem, then design for the teams. Once that traceability is done, you can say oh when I change X this is what is impacted, and redesign if necessary",
          "score": 1,
          "created_utc": "2026-01-16 16:32:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzmvx3",
          "author": "steve-7890",
          "text": "The answer was already posted here, so I will just propose a good book that can help you understand why it's the way it is: *Rapid Development*, Steve McConnell",
          "score": 1,
          "created_utc": "2026-01-16 20:45:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01tmjc",
          "author": "Mysterious-Rent7233",
          "text": ">In many Agile setups, it feels like work starts before things are truly nailed down. Requirements are good enough to begin, but not really complete, and then they keep evolving while implementation is already in progress. Late in the process, someone suddenly realizes there‚Äôs a missing dependency - a contract, an external system, some approval that wasn‚Äôt accounted for upfront.\n\nWelcome to the real world. It's our job to deal with it, not to fight it. You can of course expend SOME effort to get requirements up front, but complaining that many arrive late is like complaining about rain on your beach day.\n\n>At the same time, different phases blur together. Analysis isn‚Äôt really finished, but coding begins because of deadlines. Development isn‚Äôt fully reviewed yet, but testing has already started. Releases get planned while there are still known open risks.\n\nYou mean that the [waterfall does not act as a proper waterfall](https://en.wikipedia.org/wiki/Waterfall_model)? This was first noted around 1970.",
          "score": 1,
          "created_utc": "2026-01-17 04:12:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04kyzm",
          "author": "reijndael",
          "text": "Since few comments here give any practical advice‚Ä¶ True skill is in finding code abstractions that don‚Äôt need to be rewritten or piled on top of every time there‚Äôs a request for a change. Use practices like modular code, TDD, small classes, SOLID, event sourcing. All of these and other practices exist precisely to mitigate the inherent chaotic nature of the job. The industry operates more like a research project with ups and downs rather than a factory where you have a clear pipeline of what needs to happen when.",
          "score": 1,
          "created_utc": "2026-01-17 16:20:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0odojp",
          "author": "the-fluent-developer",
          "text": "Successful development is about creating a short feedback loop. Ideally, you don't have to write software to figure out whether an assumption (aka \"requirement\") holds. You don't want to build software just to realize that you've built the wrong software.\n\nUnderstand the process. Visualize the process. A lot of clarification can happen on jointly looking at a process visualisation. Event Storming, Domain Storytelling, Architectural Roleplay come to mind, for example.",
          "score": 1,
          "created_utc": "2026-01-20 15:04:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qe60h4",
      "title": "How do big systems handle this?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qe60h4/how_do_big_systems_handle_this/",
      "author": "After_Ad139",
      "created_utc": "2026-01-16 04:16:25",
      "score": 15,
      "num_comments": 16,
      "upvote_ratio": 0.84,
      "text": "How you‚Äôd handle a traffic spike. You confidently say, ‚Äúrate limiting‚Äù and start sketching Redis and token buckets. ",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qe60h4/how_do_big_systems_handle_this/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nzv3ni2",
          "author": "markojov78",
          "text": "Horizontal scaling, load balancing.\n\nIt's a simple phrase but the whole system has to be designed to be able to do that...",
          "score": 16,
          "created_utc": "2026-01-16 04:29:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvqfyp",
          "author": "naedyr000",
          "text": "Big systems are complex, so there's no simple answer.\n\nBut you can only be sure it can handle load that you've actually seen. Anything else is just theoretical.\n\nSo you generate load or respond when there's a spike, and fix the issues that you see. Metrics and observability are key.\n\nThen use auto scaling etc to scale down from that high load state. I always think of it as scaling down to save money, rather than scaling up to handle load.",
          "score": 9,
          "created_utc": "2026-01-16 07:19:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv28ts",
          "author": "no1SomeGuy",
          "text": "Global CDN, Scale Out, Load Balancing, Elastic Services.",
          "score": 10,
          "created_utc": "2026-01-16 04:20:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwm6c2",
          "author": "dashingThroughSnow12",
          "text": "It depends the requirements.\n\nAre we talking 5% spikes? 20%? 100%? 10000% (ex we are running a Super Bowl ad)? Are we talking across the board (ex opening up a new feature) spike or some bad actors?",
          "score": 1,
          "created_utc": "2026-01-16 11:58:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzx7imo",
          "author": "Wh00ster",
          "text": "How fast does it need to respond?\n\nWould it take too long for autoscaling? Can you predict spikes and pre-allocate more servers?",
          "score": 1,
          "created_utc": "2026-01-16 14:07:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzydj9g",
          "author": "Mundane_Cell_6673",
          "text": "Systems have auto scaling based policies on CPU usage or other key indicators (request count, messages in queue)\n.if large traffic increase is instantaneous then you either reject requests (load shedding) or be slightly overprovisioned",
          "score": 1,
          "created_utc": "2026-01-16 17:20:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv3qm5",
          "author": "saravanasai1412",
          "text": "Just configure auto scale on your instance or just add load balancer.",
          "score": 0,
          "created_utc": "2026-01-16 04:29:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvm84x",
              "author": "Ok-Macaron-3844",
              "text": "‚Ä¶ only to find out app servers were not the bottleneck, but your database is ü´£",
              "score": 4,
              "created_utc": "2026-01-16 06:43:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvrvo8",
                  "author": "klekmek",
                  "text": "Time to shard",
                  "score": 3,
                  "created_utc": "2026-01-16 07:31:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzvq9zt",
                  "author": "saravanasai1412",
                  "text": "Do database base replication and setup read and right paths simple and straight forward.\n\nAdd proxy like pg bouncer which helps your with connection handling.",
                  "score": 2,
                  "created_utc": "2026-01-16 07:17:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzvi32b",
              "author": "symbiat0",
              "text": "This üëÜüèΩ",
              "score": 1,
              "created_utc": "2026-01-16 06:10:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzw6zom",
                  "author": "serverhorror",
                  "text": "Now your relational database becomes a bottleneck to the horizontally scaling Webservers \n\nWhat now?",
                  "score": 1,
                  "created_utc": "2026-01-16 09:50:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qhy94c",
      "title": "Every time I face legacy system modernization, the same thought comes back",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qhy94c/every_time_i_face_legacy_system_modernization_the/",
      "author": "Icy_Screen3576",
      "created_utc": "2026-01-20 11:05:35",
      "score": 14,
      "num_comments": 1,
      "upvote_ratio": 0.89,
      "text": "\"It would be much easier to start a next-gen system from scratch.\"\n\n[One worker process, one database.](https://preview.redd.it/3l58aw1cbheg1.png?width=3792&format=png&auto=webp&s=bde20bdd6ed7d95c51906784d90387dd76ac0ccb)\n\nThe problem is that the existing system already works. It carries years of edge cases, integrations, reporting, and revenue. I can‚Äôt simply ditch it and start on a greenfield, but I also can‚Äôt keep it as-is: complexity grows with every sprint, cognitive load increases, clear team ownership boundaries become impossible, and time to market slowing down.\n\n**What worked**\n\nLooking into design patterns, I found the Strangler Fig pattern that everyone mentions but in practice, it‚Äôs not enough. You also need an Anti-Corruption Layer (ACL). Without an ACL, you can‚Äôt keep the legacy system running without regression while new hosts run side by side.\n\nThey both allow you to incrementally replace specific pieces of functionality while the legacy system continues to run.\n\n[ The legacy system has no responsibilities left thus can be decommissioned.](https://preview.redd.it/k8xx43u7dheg1.png?width=3156&format=png&auto=webp&s=c7cc931bfe4880623f54e5a2366847d55d724244)\n\n**Important note** \n\nThis kind of service separation should only be done when justified. For example, when you need team ownership boundaries or different hardware requirements. The example here is meant to explain the approach, not to suggest that every monolith should be split.\n\n**One caveat**\n\nThis approach only works for systems where you *can* introduce a strangler. If you‚Äôre dealing with something like a background service ‚Äúbig ball of mud‚Äù with no interception point, then the next-gen is the way.\n\nThis is the [link](https://www.justifiedcode.com/modernizing-a-monolithic-application) where you can find all steps and diagrams, from the initial monolith to the final state, with an optional PDF download.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qhy94c/every_time_i_face_legacy_system_modernization_the/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o0rzw6l",
          "author": "HosseinKakavand",
          "text": "Thanks for posting this ‚Äî really insightful. Strangler Fig + ACL are the two patterns we use the most for modernization. You captured the reality well: you can't rewrite overnight, but you also can't keep bolting onto legacy debt forever.\n\nIn your example, how are you handling orchestration between these new services? I noticed the arrows in your diagram look like service-to-service choreography. At [Luther](https://reddit.com/r/luthersystems) we‚Äôve moved toward a \"distributed orchestrator\" model using what we call Common Operation Scripts (COS), with ACLs in front of each system. Have you found choreography enough or do you eventually hit a \"spaghetti\" wall where you need this kind of central coordination?",
          "score": 1,
          "created_utc": "2026-01-21 01:35:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdkpoi",
      "title": "I created a C4 model authoring tool using Python called buildzr",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qdkpoi/i_created_a_c4_model_authoring_tool_using_python/",
      "author": "scribe-kiddie",
      "created_utc": "2026-01-15 14:18:00",
      "score": 12,
      "num_comments": 0,
      "upvote_ratio": 0.94,
      "text": "Hello, fellow software architects!\n\nLast year, I started writing a Python C4 model authoring tool, and today it has come to a point where I feel good enough to share it with you guys so you can start playing around with it locally and render the C4 model views with PlantUML.\n\nUnder the hood, it follows Structurizr's schema (see [https://github.com/structurizr/json](https://github.com/structurizr/json) ) when storing the model in-memory and when writing it into a JSON file. So it is also compatible with any Structurizr-compatible rendering tool.\n\nYou can find out more about it in [https://buildzr.dev](https://buildzr.dev)\n\n# Quick Example\n\nHere's an example code straight from the README (I use image because Reddit doesn't support syntax highlighting -- if you want to copy, head out to [https://buildzr.dev](https://buildzr.dev) ).\n\n[Creating a workshop, and defining the models and their relationships.](https://preview.redd.it/q6u11qeipidg1.png?width=1600&format=png&auto=webp&s=59cd8c21adbf2dde5d212e95d782788ca3001bb5)\n\n[Next, we create two standard structurizr views: a SystemContextView and a ContainerView](https://preview.redd.it/oc2n9gnruidg1.png?width=1600&format=png&auto=webp&s=db276a5ecfb2cbc446e9c7ae201572c1dbfbab42)\n\n[You can \\`import\\` themes \\(icons and\\/or colors\\) and apply it to styles.](https://preview.redd.it/dya5hqe4widg1.png?width=1600&format=png&auto=webp&s=32418939a7983cf344334e0aca0dadae2f1f8732)\n\n[Finally, we can export the workspace to JSON; or, to PlantUML, or SVG to be rendered later.](https://preview.redd.it/nlybgr5eqidg1.png?width=1600&format=png&auto=webp&s=d6ff42dba15ea76995b93d667fd2e359c4fe8bc1)\n\n[Bonus: Mypy will complain about illegal relationships!](https://preview.redd.it/zhwxm1yrqidg1.png?width=1594&format=png&auto=webp&s=0f07772a5f82d0d857b2f385b3c7b268b87bc94d)\n\n# Works in Jupyter Notebook\n\nYou can also render the model in Jupyter Notebook, which I think will be useful for iteratively working on the models and views. Below is the screenshot from VS Code:\n\nhttps://preview.redd.it/1jetaw77tidg1.png?width=1600&format=png&auto=webp&s=a67d78cf6e80f06c4dc9512a81f375e89b285e0c\n\n# Features\n\n* ***Intuitive Pythonic Syntax***: Use Python's context managers (`with` statements) to create nested structures that naturally mirror your architecture's hierarchy.\n* ***Programmatic Creation***: Use buildzr's DSL APIs to programmatically create C4 model architecture diagrams. Great for automation!\n* ***Advanced Styling***: Style elements beyond just tags --- target by direct reference, type, group membership, or custom predicates for fine-grained visual control. Just take a look at [Styles](https://buildzr.dev/user-guide/styles/)!\n* ***Cloud Provider Themes***: Add AWS, Azure, Google Cloud, Kubernetes, and Oracle Cloud icons to your diagrams with IDE-discoverable constants. No more memorizing tag strings! See [Themes](https://buildzr.dev/user-guide/themes/).\n* ***Type Safety***: Write Structurizr diagrams more securely with extensive type hints and Mypy support.\n* ***Standards Compliant***: Stays true to the Structurizr JSON schema standards. buildzr uses datamodel-code-generator to automatically generate the low-level representation of the Workspace model.\n* ***Rich Toolchain***: Uses the familiar Python programming language and its rich toolchains to write software architecture models and diagrams!\n\n# Find out more\n\nThanks for reading this far!\n\nIf you're interested, feel free to ask me any questions about the project.\n\nGitHub repo: [https://github.com/amirulmenjeni/buildzr](https://github.com/amirulmenjeni/buildzr)\n\nDocumentation here: [https://buildzr.dev](https://buildzr.dev)",
      "is_original_content": false,
      "link_flair_text": "Tool/Product",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qdkpoi/i_created_a_c4_model_authoring_tool_using_python/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qgfr0w",
      "title": "How do you prevent design drift during PR reviews?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qgfr0w/how_do_you_prevent_design_drift_during_pr_reviews/",
      "author": "senthuinc",
      "created_utc": "2026-01-18 18:10:40",
      "score": 12,
      "num_comments": 8,
      "upvote_ratio": 0.93,
      "text": "Hey folks, looking for some honest feedback on a problem I keep running into during PR reviews.\n\nThe teams I worked and work with rely, at most on a single PR checklist. As systems grow, number of teams grow, org maturity mandates come into effect, we want more comprehensive checks (architecture, security, performance, conventions, etc.), but long checklists quickly get ignored because they slow reviews down - totally empathize with that.\n\nEspecially with LLM-assisted coding becoming more common, I‚Äôm also noticing more design drift - code that works, passes review, but slowly diverges from intended architecture and patterns accumulating technical debts in the blind if you will. This is getting harder to catch with today‚Äôs PR process.\n\nI‚Äôm exploring an idea around making PR checks more adaptive and context-aware, without overwhelming developers.\n\nCurious to hear:\n\nDo you use PR checklists today?\n\n1. Have you experienced checklist fatigue?\n2. Have you noticed increased design drift increasing with LLM-assisted coding?\n3. Would love to hear how others are dealing with this. ",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qgfr0w/how_do_you_prevent_design_drift_during_pr_reviews/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o0c1ekt",
          "author": "commanderdgr8",
          "text": "one idea is that as much of this checklist should be automated as possible. for example, linting and formatting as pre-commit hooks. See if any items from your checklist can be added as a rule in your linting and formatting. you might want to write a custom linting or formatting rule for your programming language.  This is possible and should be used.  \nSecond is automated test case which can run as part of CI/CD pipeline, particularly security and performance related checks, so even if they are missed in code review, they are caught in the pipeline.  \nWe also use LLM assisted code review, with tools like Code Rabbit and Claude which can catch many of the issues. You can ask teach CodeRabbit about your particular coding pattern, or any issues you want it to identify in future and next time onwards it can identify those issue. Same way you can ask Claude to review your code and find specific issues and in the system prompt you can ask it to find particular way a code is written the flag it.",
          "score": 4,
          "created_utc": "2026-01-18 18:34:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cg6pa",
              "author": "virtualstaticvoid",
              "text": "I agree that automation is key for things like static code analysis and linting, formatting, dependency checks for CVEs, etc, but I don't think there's anything that can easily detect something like architectural drift as such, or deviations from established patterns of the application, or more simply, where the code doesn't reuse helper classes which maybe the developer didn't know about.\n\nDo/can LLM based review tools detect these types of things?",
              "score": 1,
              "created_utc": "2026-01-18 19:44:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0cy1gu",
                  "author": "sansp00",
                  "text": "We use CoPilot at work and ended up building an instruction file derived from the Awesome CoPilot repository. It's been meh so far to be honest. What really worked well was the ArchUnit test suite I added. Even devs liked it since it prevented them from some 'design' pitfalls very early in their work.",
                  "score": 1,
                  "created_utc": "2026-01-18 21:14:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0bziyz",
          "author": "breek727",
          "text": "PR checklists imho are only useful for new engineers to know what to look out for, I.e got your indices right etc. \n\nAnything meaningful should have some level of none ai automation, like static analysis that stuff lives where it should be etc",
          "score": 2,
          "created_utc": "2026-01-18 18:26:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c1bub",
          "author": "Most_Double_3559",
          "text": "Most importantly here, PR checklists are a sign of something else: Clunky DevEx (usually in architecture or support).\n\nThe *correct* thing should be the *easy* thing. Then, you won't need to check for people \"doing it the wrong way\" because laziness (the same laziness that makes checklists not work) is now taking care of that for you.\n\nTo your examples:\n\n* Architecture drift / conventions: Ideally the designated architecture should be *easy to plug into.* Suppose you have a list of validators. You should be able to copy a class, add an object to a list somewhere, and done. If it's more complicated, you should be able to just @ inject a new module and still call it a day early. If your architecture / convention requires modifying 5 files to plumb in your new code nobody will ever do it. Don't make them do that, and they'll follow the pattern.\n* Security: Devops security checkers exist, or if you'd prefer, only require reviews if touching designated \"high risk\" files like password management code.\n* Performance: Have a canary environment. Block a release if performance decreases X% day-over-day. Done, no sense in hand wringing about whether some statement takes a bit longer in reviews.\n\nThat seems like a reasonable start to me, though of course this is something that has to evolve in-house over time :)",
          "score": 3,
          "created_utc": "2026-01-18 18:34:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0f5rmv",
          "author": "ryan_the_dev",
          "text": "I have been working on making my LLM very good at following PR checklists and now using multiple agents. \n\nNot gonna lie and say it‚Äôs perfect. Still testing it out at work. \n\nhttps://github.com/ryanthedev/code-foundations",
          "score": 1,
          "created_utc": "2026-01-19 04:21:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0h8p8o",
          "author": "Audzkan",
          "text": "For architecture drifts. You could write architecture tests which are executed in the CI/CD  on the commits to enforce specific architecture rules ti prevent drifts",
          "score": 1,
          "created_utc": "2026-01-19 14:14:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0i4fhc",
          "author": "alonsonetwork",
          "text": "If you establish standards and convention, AI can easily catch on this and you can add it to your pipeline. I setup a bunch of Claude files to steer agents on my code, and I have Haiku review my code for divergence from convention and standards. It does a good enough job.\n\nNow: design and logical correctness is YOUR job to catch. Your fatigue comes from the fact that you're doing everything: design, logic, standards, convention, and probably style and linting. Reduce it.\n\n- As others mentioned: static analysis on things that can be statically analyzed (lint, format, types, test, code coverage)\n- AI can catch standards and convention drift, based on git diffs. You must define your standards and conventions.\n- you focus purely on meaningful, non-robotic work that comes from the outside (requirements, external problems)",
          "score": 1,
          "created_utc": "2026-01-19 16:45:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qh1tzs",
      "title": "Are Transactional Middleware programs still used in backend?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qh1tzs/are_transactional_middleware_programs_still_used/",
      "author": "sexyman213",
      "created_utc": "2026-01-19 11:34:15",
      "score": 9,
      "num_comments": 13,
      "upvote_ratio": 0.85,
      "text": "I'm currently reading the 'Principles of Transaction Processing' book and I can see that a lot of technologies mentioned in the book are no longer used but serve as a good history lesson. The author namedrops several \"transactional\" middleware products/protocols/standards such as - HP‚Äôs ACMS, IBM Trivoli, CORBA, WCF, Java EE, EJB, JNDI, Oracle‚Äôs TimesTen etc. Are these and similar TP monitor tools used anymore or is it all web services and microservies now?\n\nA recurring theme throughout the book is the concept of \"transaction bracketing\" , i.e., handling business process requests as a transaction with ACID properties, not just at a database level but the entire request itself. What are the current technologies used to do this?\n\n  \nEdit: about transaction bracketing",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qh1tzs/are_transactional_middleware_programs_still_used/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o0glloz",
          "author": "KaleRevolutionary795",
          "text": "Transactional Middleware is still used. Either as ORM such as¬† Hibernate, EclipseLink or JPA or even an implementation of JTA. You could even reason that Mainframe architecture is a kind of transactional middle ware.\n\n\nSome specfic implementations of that: Corba, java EE (eg Tomcat/websphere), ejb, JNDI are all indead being phased out across most if not all organisations. These are implementations whose downsides have been resolved by evolutions.¬†\n\nYou can add SOAP to that but that's more an API , however the business transactionality is a part of that.¬†\n\n\nSo in effect the answer is yes and no: the statement is a little too broad, but correct in their examples of defunct technologies¬†",
          "score": 4,
          "created_utc": "2026-01-19 11:41:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0gr5ft",
              "author": "sexyman213",
              "text": "A recurring theme throughout the book is the concept of \"transaction bracketing\" , i.e., handling business process requests as a transaction with ACID properties, not just at a database level but the entire request itself. What are the current technologies used to do this?\n\n  \n(I have also editted the post to add this)",
              "score": 2,
              "created_utc": "2026-01-19 12:25:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0gu8pj",
                  "author": "OneHumanBill",
                  "text": "You're right and use of this whole concept has fallen off.  There are two main reasons. \n\nFirst and foremost, practically speaking when you need something to be transactional, it's not the whole process we care about.  It's just the storage part.  If you finish storing the result of a transaction including all in memory processing then really that means you've finished the storage end.  So we're down to a database ACID transaction, and usually a simple one that doesn't require even a multi-phase commit (though they're still out there if you really need them).  Even if you're doing something really old fashioned with a file operation, there's usually an rdbms status or something you need to mark as complete at the end.\n\nSecondly is the lessened need for ACID in many modern applications.  In a bank transaction, it is absolutely necessary to make sure that debits and credits balance, and this is the origin of ACID's necessity.  But if you need to deliver a social media notification then the need to ensure a correct transaction becomes a lot fuzzier.  If something fails, it's not the end of the world, and the notification can be delivered later when things are working better.  This is the world of no-sql where full ACID isn't considered necessary even in storage. \n\nI last saw a CORBA application in the wild about five years ago during a cloud migration.  Everybody was scared to touch the thing.  I spent weeks trying to figure out what it even did.  There didn't seem to be any way to move the stupid thing.  For all I know they left it running forever.",
                  "score": 5,
                  "created_utc": "2026-01-19 12:47:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0px2xc",
                  "author": "Wiszcz",
                  "text": "We used ‚Äútransaction bracketing‚Äù all the time in the monolith era, and we still use it very often. Basically, every local task is done within this transaction bracketing. The implementation is simple: you start a database transaction at the beginning of the request and end it when request processing finishes.\n\nThere are a few problems when a task involves an external service.  \n1 - Trying to do a multi-system transaction is very hard and costly. Because of that, many approaches exist to ensure that work is done fully or not at all, or that partially completed work can be mitigated.  \n2 - If you call one or more external systems during a transaction, it can take a lot of time. During that whole time the transaction stays open, which is very bad for database performance. As a result, we now try a similar approach as with multiple services: ensure that even if part of a task fails, the saved state is recoverable.\n\nIn my opinion, doing this well is much harder and more nuanced than the old transaction bracketing :)",
                  "score": 1,
                  "created_utc": "2026-01-20 19:19:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0gye1j",
          "author": "i_be_illin",
          "text": "Multisystem transactions are too hard. Very difficult to get right and get consistent behavior. Other patterns emerged that make the inevitable failures that occur in distributed systems easier to deal with.",
          "score": 3,
          "created_utc": "2026-01-19 13:15:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0he8a5",
          "author": "RipProfessional3375",
          "text": "Something similar to a distributed transaction system is the optimistic lock used in Event Sourcing. And the append condition in the new Dynamic Consistency Boundary specifications.\n\nThe lock and append condition are more a design and specification than a specific technology.\n\nThe general gist goes: application queries messages, makes a decision, attempts to write messages based on that decision, gets rejected if the query and result they used has become outdated in the meantime.",
          "score": 1,
          "created_utc": "2026-01-19 14:43:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0hyf8b",
          "author": "Middlewarian",
          "text": "I'm building a [C++ Middleware Writer.](https://www.reddit.com/r/codereview/comments/qo8yq3/c_programs/)  It's an on-line code generator that's implemented as a 3-tier system.  Each of the tiers is implemented using code that's been generated.   The back tier is closed, but the¬†[middle tier](https://github.com/Ebenezer-group/onwards/blob/master/src/tiers/cmwA.cc)¬†is open.  I'm the only user so far.",
          "score": 0,
          "created_utc": "2026-01-19 16:18:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0if39x",
              "author": "sexyman213",
              "text": "what's it used for? also what's a code generator?",
              "score": 1,
              "created_utc": "2026-01-19 17:33:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0it898",
                  "author": "Middlewarian",
                  "text": "It helps build distributed systems.  It writes messaging and serialization code.  This is the [generated code](https://github.com/Ebenezer-group/onwards/blob/master/src/tiers/cmwA.mdl.hh) that I use to build the middle tier of my code generator.",
                  "score": 1,
                  "created_utc": "2026-01-19 18:36:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qfhkdq",
      "title": "How solve business cyclic dependency between module ?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qfhkdq/how_solve_business_cyclic_dependency_between/",
      "author": "Ok-Professor-9441",
      "created_utc": "2026-01-17 16:25:57",
      "score": 9,
      "num_comments": 26,
      "upvote_ratio": 0.81,
      "text": "Hi\n\nWe want to decompose the app in severals domain, one domain will be transalted to a Java Module (Spring Modulith)\n\n**Business rules requiring cross-domain coordination**\n\n* When creating a new Order, we must update the related Article status to \"sell\".\n* When an Article price changes, we must update all Orders that are not validated yet with the new price.\n\n**Problem**\n\nThe domains Order and Article are both large and contain many business rules. Some rules must update state across modules, which seems to introduce a cycle:\n\n* Order needs to call/update Article\n* Article needs to call/update Order\n\nWith Spring Modulith module rules, this becomes:\n\n    order -> article\n    article -> order\n\n‚Ä¶which is a cyclic dependency and fails the *no cycle violation rule*.\n\n\n\n[Module Article depends on Order, module Order depends on Article](https://preview.redd.it/oenqt8ngrxdg1.png?width=1066&format=png&auto=webp&s=1b76d7607e15e3b72312fb9347634b6fc5400728)\n\n**Questions**\n\n* I s a cyclic dependency acceptable between module?\n* If cycles are discouraged, what is the recommended way to model this kind of cross-domain business logic while keeping modules independent?\n\n**What we considered**\n\n1. Allow cycles and disable Spring Modulith checks This works, but defeats the purpose of enforcing module boundaries.\n2. Put `Order` and `Article` in the same module Works, but we are afraid the result will become one big module, which we want to avoid.\n3. Add an orchestration module Example: `sales-orchestration` depends on both order and article But then we expect other domain pairs to have similar cross-domain rules (document <-> client, etc.), so we don‚Äôt know:\n   * how many orchestration modules are needed\n   * how to prevent orchestration from becoming a ‚Äúgod module‚Äù",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qfhkdq/how_solve_business_cyclic_dependency_between/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o04par6",
          "author": "never-starting-over",
          "text": "Hmm. I find it curious that an order can change the price of an article.\n\nNonetheless, perhaps you need an ephemeral representation of an Article that represents what the Article was at the time it was created. In a similar accounting/sales domain I worked we called this a Line Item, belonging to an Invoice (akin to your Order).\n\nThis would allow you to:\n\n1. Keep the actual billable separate from the billable reference used for other new Orders\n2. Have distinct logic for how updates cascade, or don't cascade, to and from Articles in Orders (line items). Maybe you can eliminate cascading from here to Articles altogether even, eliminating the cyclical dependency.\n  - On the topic of eliminating cyclical dependency with this, is it key that Orders really can change the original Article reference (price)? I'm interested to know more about the use-case if you don't think this approach works for your domain.\n\nI'd put this in the Order domain.\n\nThoughts?",
          "score": 3,
          "created_utc": "2026-01-17 16:40:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04x85m",
              "author": "Ok-Professor-9441",
              "text": "The order don't change the article price. I think UML diagram isn't clear.\nIt's `OrderProvider` that call `OrderUseCase.updateOrderWithNewPrice()`\n\nThe Business rules are :\n- When creating a new Order, we must update the related Article status to \"sell\".\n\n```\nOrderUseCase.createOrder() {\n    // 1. create the order and persist\n\n    // 2. Call article markSell\n    articleProvider.markSell()\n}\n```\n\n- When an Article price changes, we must update all Orders that are not validated yet with the new price.\n```\nArticleUseCase.updatePrice() {\n    // 1. findById(articleId), set the new price and persist\n\n    // 2. Call document to update all document not valedated yet\n    documentProvider.updateArticlePrice()\n}\n```",
              "score": 1,
              "created_utc": "2026-01-17 17:17:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o04tatn",
          "author": "Wesd1n",
          "text": "To me it sounds like orders update a status on the article.¬†\n\n\nI don't see why it is orders responsibility to update article.¬†\n\n\nOrders deals with orders and nothing else. Otherwise I might as well be one domain module.¬†\n\n\nIf they are truly distinct then the caller of orders should update the article.\n\n\nCould be via events or a two calls async calls that you can easily undo incase of failure.\n\n\n\n\nTo me the proposed thoughts do present a non negotiable cyclic coupling which I would try to avoid.\n\n\n\n\nOn the other hand article owns the product who has been ordered.¬†\nSo the order system could call for an updated price upon viewing or further action.\nThen we avoid having to update duplicate data.\nSure there will be a few calls but caching it for a moment based on what is written shouldn't be a problem.¬†\n\n\nThen orders will always know if there is an issue an you don't have to worry about the same stale data.",
          "score": 2,
          "created_utc": "2026-01-17 16:59:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04y1aw",
              "author": "Ok-Professor-9441",
              "text": "> Could be via events or a two calls async calls that you can easily undo incase of failure. \n\nAgree with you about event or async call but we want ACID transaction guaranted. So do it, in case of event or async call we must hendle distributed transaction and want to avoid it.\n\nIt's why we prefer synchronous calling and a \"simple modular architecture\".\n\n> I don't see why it is orders responsibility to update article.  \n\nSo, who is responsible to update it ?",
              "score": 2,
              "created_utc": "2026-01-17 17:21:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o05k383",
                  "author": "Freed4ever",
                  "text": "I don't understand all the domain logic (too lazy to think it all through üòä) but could be an inventory manager or something like that, after an order is placed, it places/delegates an event to a queue / async call and the inventory manager would update the article, fulfilment, notification to the customer, etc. - just off the top of my head, but you get the idea.",
                  "score": 2,
                  "created_utc": "2026-01-17 19:03:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o05kzvq",
                  "author": "Freed4ever",
                  "text": "Btw, why do you guys think Acid is required? Is it really true that failure to update the article would result in an order failure? If so, I would re-think the business process to be frank. Once a customer placed an order, and payment got processed, the order should be considered valid, what happen downstream (failure to update inventory, etc) shouldnt fail the order.",
                  "score": 2,
                  "created_utc": "2026-01-17 19:07:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o052eqf",
          "author": "thiem3",
          "text": "Didn't read all the way through, sorry, but when you mentioned something about an aggregate updatong across several modules, I was sceptical. This video might interest you, about how an aggregate is split and represented across modules.\n\nhttps://youtu.be/hev65ozmYPI?si=Ag5vno1lWEaszTIQ",
          "score": 2,
          "created_utc": "2026-01-17 17:41:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0679b8",
          "author": "ings0c",
          "text": "Can you give more context? What is an ‚Äúarticle‚Äù - it can have many meanings.\n\nWhat are users ordering?\n\nI think being less abstract will make it easier for everyone to understand.",
          "score": 2,
          "created_utc": "2026-01-17 20:58:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o06aoki",
          "author": "severoon",
          "text": ">Is a cyclic dependency acceptable between module?\n\nNo.\n\n>If cycles are discouraged, what is the recommended way to model this kind of cross-domain business logic while keeping modules independent?\n\nModule dependencies must form a DAG. The DAG can have one or more \"root\" modules which are completely independent, and these modules should define entities and possibly behaviors of the business that are the most stable, i.e., unlikely to change over versions and time.\n\nIn this case, it's possible to have articles in stock but no orders, whereas it is not possible to have orders if you have no articles for sale. The existence of orders depends upon the prior existence of articles, so the direction of dependency in your model should reflect that by having Order depend upon Article.\n\nThe simple way to do this is to invert the reverse dependency (Article -> Order). There are several ways to do this.\n\nThe simplest and most straightforward way is to define the Order interface in the Article module. In this approach, since Order interface belongs to the Article module, when the Article class depends upon that interface there's no issue. Then in the Order module, OrderImpl depends on the Order interface, which is the Order -> Article module dependency.\n\nHowever, you may not want the Order interface to belong to the Article module because this means that Article is responsible for defining what an Order is, and when that definition changes you have to deploy the Article module (and, of course, all dependent modules). This may or may not make sense for your app.\n\nMore likely, nothing in the Article module needs to know or care about anything to do with orders, and so the Order interface shouldn't live in that module. In this case, you need to understand what information they both share. For example, when an article changes price, orders need that updated info, which implies that there needs to be a shared price map.\n\nOne way to do this is to simply have something in the Article module update the price map and then notify listeners of the change. When an order is created, it registers a listener and will receive the updated price map whenever it changes, once the order is validated, it deregisters its listener. Maybe the price map is large and that's a lot of data flying around when only one price changes. In that case, you can publish just the articles that are updated instead of the entire price map.\n\nThis approach can be fragile, though, depending on what your deployment looks like. If these modules are guaranteed to be deployed in the same runtime, it's probably not a big deal, but one point of modularizing is being able to scale different parts of the system independently, so you shouldn't assume these will always and forever be deployed together. Better would be to assume they could be placed on different servers someday, but that means you now need something durable like a reliable database queue. You need monitoring that will notify and page when the queue gets backed up, etc.\n\nAnother solution is to simply update the price map in the DB. When an order is created, it reads all of the prices and treats them as provisional, and then if there are any price changes at validation, it processes those however it needs to. This could be simple, just updating the number, or complicated, like splitting the order into two and validating the sub-order with items that didn't change, then round tripping the sub-order containing updated prices with the customer. The customer might want to put through the sub-order with unchanged prices right away, or hold off and deal with the updated items so the system can merge the two back together into a single order or whatever.\n\nIf this happened here, though, it seems likely that a proper solution is going to necessitate fixing a bunch of other issues that come up. Such is the nature of spaghetti dependencies. If you run into that situation trying to fix this problem, that would be a red flag that you need to step back and treat this as a separate project unto itself. You will likely need to get your arms around the current out-of-control dependency structure before you can even contemplate fixing individual use cases because they will continue to pivot through the current dependency structure. (That is the problem with losing control of deps in the first place.)",
          "score": 2,
          "created_utc": "2026-01-17 21:16:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o06k89f",
              "author": "Ok-Professor-9441",
              "text": "You have summarised all the assumptions perfectly. Thank you for taking the time to explain everything in detail!\n\n**Solution 1 : Dependency Inversion** \n\nAgree with you and you identify the problem correctly\n\n>you may not want the Order interface to belong to the Article module because this means that Article is responsible for defining what an Order is\n\n**Solution 2 ‚Äî Shared pricing data / contract** \n\nThen, when you say\n\n>For example, when an article changes price, orders need that updated info, which implies that there needs to be a shared price map.\n\nI‚Äôm trying to understand whether you recommend:\n\n* a small shared ‚Äúpricing contracts‚Äù module (pure interfaces / DTOs),\n* or an event-driven approach (publish price updates / subscribe),\n* or something closer to an orchestration module.\n\n>  If these modules are guaranteed to be deployed in the same runtime, it's probably not a big deal,\n\nYes, modular monolithic application\n\n**Solution 3 : Use DB directly** \nI'll think about it.",
              "score": 1,
              "created_utc": "2026-01-17 22:04:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0757xb",
                  "author": "severoon",
                  "text": "Which of the approaches I would recommend from your bulleted list depends upon the architecture, scaling considerations, infrastructure you already have (or could have) available to you, and many other things.\n\nWhen I step back and think about this, it makes sense to me that the price list of articles already has to exist in the database anyway. That being the case, the Order module could simply look it up as I explain in the last bit of my post above. However, you are not jumping at this solution, which leads me to think that these modules currently use different databases. IOW, this is a microservice architecture.\n\nIf that's so, there's your problem. The microservice architecture is based on the notion that each team gets to own one or more small stovepipes that sit atop their own little data store, and the one and only dependency each of these microservices ever has to worry about is its own API at the top of its stack. The point of this approach is to adhere to Conway's law, giving each team total control over its own little slice of the universe and the ability to entirely and explicitly define the contract they agree to support. When one team needs something from another team, there's no choice but to negotiate and settle the requested API, so nothing flies under the radar.\n\nMost orgs that try this approach don't fully commit to it, though. At some point, instead of hitting the User service every time you want user data, other microservices just start caching that user info in their own data source. This works well enough until users get removed and the cached services continue serving that user's data. This is inconvenient, and then because of GDPR, it becomes illegal. Oops!\n\nBut they still don't want to hit the User service API, so instead why not just put a pub/sub queue at the bottom of the User service so when users are removed, anyone who cares gets notified? Sounds good, except there's no way to control who subscribes to this queue, and for what purpose. So now the queue needs to become a fully fledged queue service with access controls, etc, etc. And BTW, oops, now the User service is supporting the API at the top of its stack as well as the format of the User object it puts on the queue, and since it has no idea why others are consuming that data and what they're using it for, it can only grow in backwards compatible ways over time but nothing can be removed.\n\nBefore this got out of control, though, this queue solved this problem so well why not do the same thing in other places? So queues proliferate, and now all services are supporting APIs at the top and bottom of their stacks. (It's easier to get data from a queue rather than via an API, so that's how a lot of functionality gets implemented. So much for explicit contracts and negotiations!) No one really knows what clients are consuming what data for what purpose, so this microservices architecture has basically just become a mechanism for uncontrolled dependency to proliferate through the entire system. At this point, many orgs give up and just start giving services direct access to each other's data sources, or worse, they start allowing mid-stack cross-talk, and things have effectively become a poorly architected monolith at this point.\n\nThis is why most orgs find that adopting a microservice architecture turns out to be nothing more than a years-long way to accumulate tech debt.",
                  "score": 2,
                  "created_utc": "2026-01-17 23:51:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o089zj8",
          "author": "Isogash",
          "text": "You're probably splitting things up wrong if you're having to do a lot of cross system updating like that.\n\nFor a sales and order service, you want the service to hold a representation of the items it's selling e.g. an SKU, price and either stock counters or access to a stock-keeping service that it can reserve stock from. The service then produces events when anything of interest happens. These events can be both specific to an order, but also to an item, in which case the Article service can listen for orders of that item being fulfilled.\n\nThe key here is that the service has some abstract concept of the current things it can sell and what price it can sell them at, it's not *just* order entities, it's all of the order-relevant components and behaviours of all of your entities.",
          "score": 2,
          "created_utc": "2026-01-18 03:30:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09no8m",
          "author": "Infeligo",
          "text": "This can be handled using event. Direct dependencies between modules should form a DAG. I use \"who should know about whom\" mental model. In your case, Orders know about Articles (direct dependency), but Article don't know they are being sold by Orders. Articles can also emit events, e.g. when the price changes. Order module listens to price changes and reacts accordingly. This can all be done using Spring Modulith, which has dedicated facilities for domain events.",
          "score": 2,
          "created_utc": "2026-01-18 10:05:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05lkeh",
          "author": "GrogRedLub4242",
          "text": "bad English makes this painful to read and harder to understand",
          "score": 1,
          "created_utc": "2026-01-17 19:10:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09gy1y",
          "author": "flavius-as",
          "text": "You don't split by aggregate root, but by use case.\n\nThen aggregate roots will emerge within each module.\n\nYou might end up with duplicate Article classes, which vary wildly (because very different use cases).\n\nYour real dependency is a data dependency: only one module must be allowed to modify a data field.\n\nAlternate methodology: you map all use cases to all fields and characterize the relationship with: read, write, decision (use case uses data field as a decision variable), then you cut through this dependency graph in subgraphs in order to minimize dependencies.",
          "score": 1,
          "created_utc": "2026-01-18 09:02:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09s6p9",
              "author": "Ok-Professor-9441",
              "text": ">  Your real dependency is a data dependency: only one module must be allowed to modify a data field. \n\nWe want module specialized by business logic. I think in case of microservices having Order microservices and Article microservices is good. To manage relationship\n- When creating a new Order, we must update the related Article status to \"sell\".\n- When an Article price changes, we must update all Orders that are not validated yet with the new price.\n\nWe must implements SAGA or something else. To avoid this complexity we want keep business module but in monolith application\n\n**In this case do you think duplicated classes could be the solution ?**",
              "score": 1,
              "created_utc": "2026-01-18 10:47:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o09wg2g",
                  "author": "flavius-as",
                  "text": "Of course. That's what I just said.\n\nThe thinking for modulith is similar to microservices.\n\nIn fact, modulith is nothing but microservices but restricted to the logical view of the system, as opposed to the physical view of the system (which would be microservices).\n\nYou should restrict with database permissions the access to tables and columns in isolated cases to specific usernames and give each module a separate username and password and connection. This way you can ensure via governance that no module does \"creative\" things.",
                  "score": 2,
                  "created_utc": "2026-01-18 11:25:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o09pyyy",
          "author": "Jealous-Implement-51",
          "text": "If you only looking for solution, you can use getRequiredSerivice method. Better to revise your implementation, it shouldn't have this kind of problem.",
          "score": 1,
          "created_utc": "2026-01-18 10:26:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09sb61",
              "author": "Ok-Professor-9441",
              "text": "Could be explain the purpose of `getRequiredSerivice` and how it solve cyclic dependencies ?",
              "score": 1,
              "created_utc": "2026-01-18 10:48:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o09tt3b",
                  "author": "Jealous-Implement-51",
                  "text": "It‚Äôs the method from `IServiceProvider`. It essentially hides dependencies during startup, and only resolves when needed, however it will still fail if both service try to use each other during construction. Best way is to refactor the project, this might be something you need. https://learn.microsoft.com/en-us/azure/architecture/guide/architecture-styles/n-tier",
                  "score": 1,
                  "created_utc": "2026-01-18 11:01:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qi5xzv",
      "title": "A feature used by only approximately 6% of users was responsible for 41% of our database load",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qi5xzv/a_feature_used_by_only_approximately_6_of_users/",
      "author": "supreme_tech",
      "created_utc": "2026-01-20 16:36:01",
      "score": 9,
      "num_comments": 12,
      "upvote_ratio": 0.59,
      "text": "We recently encountered a performance issue that did not align with what our system-level metrics initially suggested.\n\nFrom an architectural standpoint, everything appeared healthy. CPU utilization was stable, memory had sufficient headroom, error rates were low, and most endpoints behaved as expected. However, the system was becoming increasingly difficult to stabilize following traffic spikes, and tail latency was gradually worsening. The database, in particular, remained under sustained pressure.\n\nRather than analyzing the issue by endpoint or request volume, we chose to examine the system through a different lens: resource ownership at the feature level.\n\nThat shift revealed an unexpected result. A feature used by only approximately 6% of users was responsible for nearly 41% of our total database load.\n\nThe reason this remained undetected for so long was that the feature was not frequently invoked. However, when it was, it triggered a cascade of activity. A single action resulted in multiple dependent queries, several wide scans, and background jobs that repeatedly re-fetched overlapping data. The issue was not any single expensive operation; rather, it stemmed from the interaction patterns between components.\n\nFrom an architectural perspective, the underlying issues included aggregates being recomputed synchronously, poor index selectivity along high-fanout paths, the absence of explicit upper bounds on the amount of data touched per request, repeated reads across both request and background execution layers, and a lack of clearly defined ownership of load between components.\n\nNone of these issues were visible in median latency metrics. Instead, they surfaced in tail behavior, prolonged recovery times following traffic spikes, and sustained database saturation.\n\nWe did not redesign the system. Instead, we made targeted architectural adjustments to better reflect real usage patterns. Heavy computations were precomputed. A short TTL cache was introduced. Fan-out was reduced. Hard limits were placed on how much data a single request could touch. Certain operations were shifted off the synchronous path.\n\nThe impact was immediate. Database load dropped by \\~38%. P95 latency stabilized. Queue oscillations ceased. Most importantly, the system became predictable again under mild stress.\n\nThe most important lesson for us was this: user share is not a reliable proxy for architectural impact. A relatively small subset of users can dominate system behavior if their workflows are computationally intensive.\n\nWe now ask:   \n  \n‚ÄúWhat percentage of total system load does this feature own?‚Äù Rather than: ‚ÄúHow many users interact with it?‚Äù\n\nI would be interested to hear how others reason about load ownership at the architectural level. Is this something you track explicitly, or does it typically surface only after issues begin to appear?",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qi5xzv/a_feature_used_by_only_approximately_6_of_users/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o0qd00n",
          "author": "UnreasonableEconomy",
          "text": "> We stopped doing X, now we do Eks. Instead of asking y, we ask why.\n\nI wish people stopped posting AI slop.\n\n> Rather than analyzing the issue by endpoint or request volume, we chose to examine the system through a different lens: resource ownership at the feature level.\n\nWhat does that even mean?\n\n>  CPU utilization was stable, memory had sufficient headroom [but] The database, in particular, remained under sustained pressure.\n\n???\n\n> We did not redesign the system. Instead, we made targeted architectural adjustments\n\nwe did not redesign the system, instead we redesigned parts of the system\n\nThis is 100% certified nonsense...\n\nYou can't even tell me that english is your second language and you're just using AI for translation, because then there'd at least be substance...",
          "score": 16,
          "created_utc": "2026-01-20 20:34:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0qqvms",
              "author": "nedal8",
              "text": "Pretty much all of reddit is this slop now. We're cooked",
              "score": 2,
              "created_utc": "2026-01-20 21:37:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0s5f7s",
              "author": "who_am_i_to_say_so",
              "text": "It means something but ain‚Äôt nobody talk this way.",
              "score": 1,
              "created_utc": "2026-01-21 02:07:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0s81g5",
                  "author": "UnreasonableEconomy",
                  "text": "i mean asking tarot cards how to debug your stuff also 'means' something",
                  "score": 2,
                  "created_utc": "2026-01-21 02:22:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0p2al7",
          "author": "MoustacheApocalypse",
          "text": "Curious: were you the architect for this system, dev manager, something else?\n\nWondering how you engaged the team to do this deep dive instead of someone looking to you to change the architecture or male a similar high-impact change.",
          "score": 7,
          "created_utc": "2026-01-20 17:00:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pehii",
          "author": "bigabig",
          "text": "How do you monitor this? Which tools do you use?",
          "score": 4,
          "created_utc": "2026-01-20 17:56:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p04f1",
          "author": "Aggressive_Ad_5454",
          "text": "I handle this by doing some monitoring at peak times. It helps a lot if all statements are prepared. The monitoring tries to identify the statements that take the most total time , either because they run often or because they‚Äôre just wicked slow. \n\nThen the slow ones can be examined for remediation. App changes? Indexes? \n\nIt‚Äôs my experience that this needs to be done continually for production systems. It‚Äôs, practically, impossible to predict what the bottleneck will be next month. That‚Äôs because tables grow and because user requirements change.",
          "score": 3,
          "created_utc": "2026-01-20 16:50:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qdcg9",
          "author": "LoveThemMegaSeeds",
          "text": "Feels like a bunch of AI bullshit",
          "score": 4,
          "created_utc": "2026-01-20 20:35:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p2ywo",
          "author": "the-fluent-developer",
          "text": "I try to make it part of the quality goals, and as such it should be tracked in order to be quantifiable.",
          "score": 2,
          "created_utc": "2026-01-20 17:03:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rh3th",
          "author": "baolongrex",
          "text": "Imagine taking time out of your day to prompt an AI generated Reddit post.¬†\n\n\n\"But MOOOOM, I need my updoots!!!\"¬†",
          "score": 2,
          "created_utc": "2026-01-20 23:51:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rllf5",
          "author": "jeffbell",
          "text": "Sometimes it‚Äôs fun to take a look at the 95th and 99th percentile transactions¬†",
          "score": 1,
          "created_utc": "2026-01-21 00:15:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s7jue",
          "author": "HosseinKakavand",
          "text": "\nThis tracks. One app faced something similar where long-tail requests triggered massive read queries that slowed down traffic. Luther [platform](https://www.reddit.com/r/luthersystems/) made it easier to spin up separate read replica pool for these slower queries identified pre-execution, freeing up CPU for the fast queries. The platform already has native Prometheus metrics, so we also added alerts within the DB layer to flag transactions reading/writing a large number of keys, to improve the router. With these changes, things have stabilized as prod continues to scale.",
          "score": 1,
          "created_utc": "2026-01-21 02:19:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcxc4n",
      "title": "Help regarding a production-ready security architecture for a Java microservices application using Keycloak",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qcxc4n/help_regarding_a_productionready_security/",
      "author": "Gold_Opportunity8042",
      "created_utc": "2026-01-14 19:47:53",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 0.84,
      "text": "I am building a microservices-based application that consists of multiple services (service-1, service-2, service-3, etc.), an API Gateway, and a Service Registry. For security, I am using¬†**Keycloak**.\n\nHowever, I am currently a bit confused about the overall security architecture. I have listed my questions below, and I would really appreciate it if you could share your expertise.\n\n1. From my understanding of the Keycloak architecture: when a client hits our signup or login endpoint, the request should be redirected to Keycloak. After that, everything is handled by Keycloak, which then returns a JWT token that is used to access all protected endpoints. Does this mean that we do¬†**not**¬†need to implement our own signup/login endpoints in our system at all?\n2. If my understanding of Keycloak is correct, how can I manage different roles for different user types (for example, Customer and Admin)? I ll have two different endpoints for registering customers and admins, but I am unable to figure out how role assignment and role mapping should work in this case.\n3. Should I use the API Gateway as a single point where¬†**authentication, authorization, and routing**¬†are all handled, leaving the downstream services without any security checks? Or should the API Gateway handle authentication and authorization, while each individual service still has its own security layer to validate the JWT token? what is the standard way for this?\n4. Are there any other important aspects I should consider while designing the security architecture that I might be missing right now?\n\nThank you!",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qcxc4n/help_regarding_a_productionready_security/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nzlroen",
          "author": "Embarrassed-Chain265",
          "text": "0. Maintaining your own keycloak instance is a PITA, you may be better off with a cloud provider in terms of $ and time wasted keeping your keycloak install up to date\n1. Yep, although you will need your own frontend sign up/login pages potentially if you don't use the keycloak defaults\n2. Just add the roles in the keycloak management app (that you will have to host yourself). Or you can add them via API calls from your own services\n3. Authorization should be based on the roles in the JWT inside your app and services, routing in the gateway, and authentication could happen in either\n4. See 0",
          "score": 2,
          "created_utc": "2026-01-14 20:28:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrgqnn",
          "author": "Glove_Witty",
          "text": "1. There is an extra step in the standard authentication flow. Keycloak gives you an id token and you go back to keycloak for an access token. I forget now how much of this the keycloak api hides but it is important to know there are 2 tokens. The access token lets you access resources. \n\nRegarding the actual question - in the standard oicd flow the idp (keycloak) displays the login an captures the clients credentials - you never see them. You can style the keycloak login box. You want this because it is how single sign in federation works. On a mobile device it is a little ugly but most people use an embedded web page. \n\n2. Your access token has claims that represent what the user can do. You can add your own claims and have keycloak add them to the tokens. How you use the claims depends on how you have designed authorization in your app. \n\n3. Yes. Best practice is to check authorization at every layer. Have an api gateway and authorize there. This is good because you can reject illegitimate traffic there and not let it inside the system. Also check the jwt and claims in your services. Checking the token is lightweight - just a signature check and it is built into the web frameworks of most stacks. \n\n4. If you haven‚Äôt look up the Google beyond prod document. This has a lot of security architecture guidance. Also, get a thorough understanding of oicd flows.",
          "score": 1,
          "created_utc": "2026-01-15 17:26:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qh59uv",
      "title": "How did NeetCode make AI hints? Feature",
      "subreddit": "softwarearchitecture",
      "url": "https://i.redd.it/kqk7qq74ebeg1.png",
      "author": "Big_Building_3650",
      "created_utc": "2026-01-19 14:15:59",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tool/Product",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qh59uv/how_did_neetcode_make_ai_hints_feature/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0hj950",
          "author": "xAmorphous",
          "text": "Without him commenting I doubt anyone knows for sure. My guess is that it's just either a simple prompt or a langchain graph that has known approaches for a problem.",
          "score": 4,
          "created_utc": "2026-01-19 15:08:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lj25a",
          "author": "Effective-Total-2312",
          "text": "This doesn't look complex. No need for fine-tuning.  \n  \nMost likely, there is a system prompt explaining the LLM its role, environment, and expected structured output with three hints.  \n  \nThen there is probably a specific prompt for each problem, which explains the LLM one or multiple possibilities of solving a problem (most likely in some kind of pseudo code). Finally, this should include your code snippet for tailored hints.",
          "score": 2,
          "created_utc": "2026-01-20 02:49:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhc4p5",
      "title": "Is my uml diagrams acceptable?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/gallery/1qhc4p5",
      "author": "Aware-Somewhere2086",
      "created_utc": "2026-01-19 18:22:00",
      "score": 8,
      "num_comments": 11,
      "upvote_ratio": 0.67,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qhc4p5/is_my_uml_diagrams_acceptable/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0iu37m",
          "author": "n00bz",
          "text": "Everyone does things a little different when it comes to UML modeling. For me, I tend to break up the models into particular features and not show the UML model for the full system as it is too complicated for anyone to read and accurately understand.\n\nPlus the granularity for the level you want to capture is difficult because for a large system you can just say authenticate user and not have to worry about the password reset or other related features when making other diagrams.\n\nIn short I would split this out to multiple use cases to better show the flow and not capture the whole system at once.",
          "score": 24,
          "created_utc": "2026-01-19 18:40:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0iws4u",
              "author": "Aware-Somewhere2086",
              "text": "Thanks I'll work on that",
              "score": 1,
              "created_utc": "2026-01-19 18:52:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0iyho8",
          "author": "Separate_Earth3725",
          "text": "Minor details that might make your life a little easier\n\nSystem Design:\nIt might be easier to turn member class into a base user class as an abstract parent class and create Moderator, Admin, Member, and Visitor. That way you can more easily manage permissions between the different user types ie ‚ÄòAdmin().CreateEvent()‚Äô, ‚ÄòModerator().ApproveNewsStory()‚Äô, etc. \n\nIn the reset password flow, in my experience I don‚Äôt check if the email exists and tell give the user feedback. I just tell the user ‚Äúa recovery email will be sent to that email if it exists‚Äù. If you give specific feedback like that, it can create a security gap where a threat actor is effectively querying your database for user emails.\n\nIn your event registration block, it kinda looks like you‚Äôre storing the users event registration before you confirm their payment and available space. If any of the payment and confirmation process fails or the user quits out of the flow, you‚Äôll need to undo that operation. I would do something like [user requests registration -> check available tickets/space* -> if space, request payment from user -> if payment confirmed, save user registration and inform user]\n*Ideally, you‚Äôre only displaying available events to the user at the very beginning of this workflow but theres always the edge case of there being 1 seat available and another user takes it while the current user is looking at this page\n\n\nNitpicks/Personal Preference:\nI like to add colors to my diagrams :) you‚Äôll be staring at them a lot and it helps when there‚Äôs another layer of visual depth\n\nIn your sequence diagrams, the [alt] and [opt] conditions should be placed at the left most edge of those visual containers so it‚Äôs easier for others to quickly read and process what you‚Äôre doing. Don‚Äôt want to have people looking for ‚Äúif‚Ä¶.what?‚Äù. Sequence diagrams should be read left-to-right AND top-to-bottom\n\nYou‚Äôll get mixed opinions on whether you should number your requests in a sequence. I personally don‚Äôt since the nature of the sequence is already sequential. If I need to draw attention to specific flows, I create separate diagrams or I create separate sections with their own titles on the diagram if their actors and entities are the same. \n\nIn your final sequence diagram that covers event registration, the actors/entities that are only used in the [alt] blocks (payment and participation) should still be defined at the very top of your diagram with the other entities/actors of your system. \n\nThe use case diagrams have a lot of visual noise. It might be better to break them up per user type. Sure, you‚Äôll get some duplicate scenarios but the few seconds spent duplicating the diagrams will be worth making it easier to read.",
          "score": 5,
          "created_utc": "2026-01-19 18:59:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0j2o90",
              "author": "Aware-Somewhere2086",
              "text": "Thanks for ur help , i really try to do all it of in great way but this diagrams kinda melting my brain to do as the first time",
              "score": 2,
              "created_utc": "2026-01-19 19:18:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0j3koo",
                  "author": "Separate_Earth3725",
                  "text": "Yeah, for a first time it‚Äôs better than what I could‚Äôve produced at that time. Overtime, you start getting better and faster especially as you get more comfortable with the idea of how the think of technical communication and get better at the tools you‚Äôre using to generate the diagrams.",
                  "score": 1,
                  "created_utc": "2026-01-19 19:22:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ixqpl",
          "author": "FuckItImLoggingIn",
          "text": "Here is my take: You only need to ask yourself one question - \"does whatever this diagrams tries to convey, manage to convey it?\".   \n  \nEasiest way to find the answer would be to see if the people this targets find it useful.\n\nSo then the question becomes - \"do the people that read this diagram find it useful?\".",
          "score": 3,
          "created_utc": "2026-01-19 18:56:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0j0bvu",
              "author": "Euphoric-Usual-5169",
              "text": "\"\"does whatever this diagrams tries to convey, manage to convey it?\".\n\n  \nThis question led me away from UML. I once read a book about UML and then did a lot of UML diagrams. Turns out nobody really got them. Simple block diagrams and flow charts are way better.",
              "score": 4,
              "created_utc": "2026-01-19 19:07:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0jbpmy",
          "author": "GrogRedLub4242",
          "text": "order of learning: English then programming then UML",
          "score": 3,
          "created_utc": "2026-01-19 20:00:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0j2bt1",
          "author": "Spare-Builder-355",
          "text": "very nice diagrams, you'll get nice grades for them in your school and never come back to uml again.",
          "score": 8,
          "created_utc": "2026-01-19 19:16:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0iy0ax",
          "author": "mr_mark_headroom",
          "text": "Yes it's a good diagram. How will you decompose it?",
          "score": 1,
          "created_utc": "2026-01-19 18:57:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qgcb7j",
      "title": "Retrofitted Legitimacy and Gaining Expertise from Ugliness",
      "subreddit": "softwarearchitecture",
      "url": "https://open.substack.com/pub/doriankeene/p/retrofitted-legitimacy-expertise?utm_source=share&utm_medium=android&r=78vb1g",
      "author": "No-Location8878",
      "created_utc": "2026-01-18 16:01:52",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qgcb7j/retrofitted_legitimacy_and_gaining_expertise_from/",
      "domain": "open.substack.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0lc2fn",
          "author": "RealHuman_",
          "text": "Nice post, with an interesting message!\n\nIn hindsight the idea is pretty \"obvious\" ‚Äî you literally can watch such trends progress over the years, but reading it as a completely formulated post makes you think about it more.  \n\nI especially like the thought of the following lines:\n\n>Rewriting lets you restate what you already know in nicer syntax.  \nRefactoring ugly code forces you to learn what you don‚Äôt know.",
          "score": 1,
          "created_utc": "2026-01-20 02:11:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhdak5",
      "title": "Google and Retail Leaders Launch Universal Commerce Protocol to Power Next‚ÄëGeneration AI Shopping",
      "subreddit": "softwarearchitecture",
      "url": "https://www.infoq.com/news/2026/01/google-agentic-commerce-ucp/",
      "author": "rgancarz",
      "created_utc": "2026-01-19 19:02:21",
      "score": 6,
      "num_comments": 3,
      "upvote_ratio": 0.8,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qhdak5/google_and_retail_leaders_launch_universal/",
      "domain": "infoq.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0jes7w",
          "author": "asdfdelta",
          "text": "I work in retail, this is an existential threat to the way ecommerce is done. We haven't seen an impact this big since Web 2.0.\n\nEveryone is scrambling. It's not fun.",
          "score": 2,
          "created_utc": "2026-01-19 20:14:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mthpm",
              "author": "GrootyProoty",
              "text": "Mind explaining why ?",
              "score": 1,
              "created_utc": "2026-01-20 08:18:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0nv4mu",
                  "author": "asdfdelta",
                  "text": "Sure.\n\nEvery metric we have to track behavior, what works and what doesn't isn't possible with Agentic Commerce. We have zero levers of influence in realtime, no personalization, and all of our data to form personalized profiles (ethically) are worthless.\n\nThe evolution of retail for the past 20 years is about to go extinct if this totally takes over. There'll always be a small population still doing traditional ecomm, but they alone can't support the value of all these tools. Enshittification will happen because there isn't an economy to support the quality, everything is based on scale.",
                  "score": 2,
                  "created_utc": "2026-01-20 13:25:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}