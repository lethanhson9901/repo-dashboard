{
  "metadata": {
    "last_updated": "2026-02-20 09:08:33",
    "time_filter": "week",
    "subreddit": "softwarearchitecture",
    "total_items": 20,
    "total_comments": 120,
    "file_size_bytes": 199124
  },
  "items": [
    {
      "id": "1r6aglp",
      "title": "SOLID confused me until i found out the truth",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1r6aglp/solid_confused_me_until_i_found_out_the_truth/",
      "author": "Icy_Screen3576",
      "created_utc": "2026-02-16 14:04:12",
      "score": 231,
      "num_comments": 64,
      "upvote_ratio": 0.82,
      "text": "Originally, Uncle Bob did not teach these principles in the order people know today. His friend Michael Feathers, the author of Working Effectively with Legacy Code, pointed out that if you arrange them in a certain sequence, you get the word SOLID. That sequence is what we ended up learning.\n\n# The problem is the order itself\n\nThe idea should start withÂ **D**. Inverting the dependencies or, the dependency rule. High-level policy must not depend on low-level details.\n\n[The interface inside the business rules layer](https://preview.redd.it/kmkoyik4xujg1.png?width=2323&format=png&auto=webp&s=3042b2a2a91fdb2299eecc50c8b31750c6758245)\n\nHigh-level policy is the business rules, the reason the system exists. Low-level details are the database, message broker, third-party frameworks, and delivery channels like Web APIs or desktop UIs.\n\nOnce D is set correctly, **O** and **L** are consequences. The system becomes open for extension and closed for modification because you can swap a message broker without modifying the core. As such, you can replace a concrete implementation at runtime without changing the code. Thatâ€™s Liskov substitution.\n\nThese principles emerge when dependencies point in the right direction.\n\n[Code dependencies point against the flow of control](https://preview.redd.it/lpn76srnxujg1.png?width=2542&format=png&auto=webp&s=6e358ce67c427d364e61035b4db3060fb6abf5c4)\n\nThe **I** principle often drives systems toward shallow modules. Instead of one deep abstraction, you get fragmented contracts that push responsibility back to the caller. The shallow modules is taken from A Philosophy of Software Design book.\n\n[Deep modules & shallow modules](https://preview.redd.it/1d0drzbwxujg1.jpg?width=1536&format=pjpg&auto=webp&s=f8f69e7e76432049cc77819b6089f8ac057c0858)\n\nWhen interface segregation is applied mechanically, it creates coordination code. Over time, especially in large teams, this leads to brittle designs where complexity is spread everywhere instead of being contained.\n\nThe most ambiguous part is **S**. Most people think it means a class should do one thing. This confusion is reinforced by Clean Code, where the same author says code should do one thing and do it well. What becomes clear when reading Clean Architecture book is that S is not a code-level thing.\n\n[Design by volatility](https://preview.redd.it/3b15znw8yujg1.jpg?width=960&format=pjpg&auto=webp&s=266cfd9ac9a4b4bd5a02620ba95574ad6d6391df)\n\nWhen decomposing a system into components, the idea is to look for sources of change. A source of change can be an admin, a retail user, a support agent, or an HR role.\n\n[Components separation](https://preview.redd.it/gq4m3iimyujg1.png?width=1162&format=png&auto=webp&s=3c5933e8af112491dfaf94ac56bc7f299f73dedc)\n\nA component should have a single reason to change, which means aligning it with one source of change. This is about deciding what assemblies your system should have so work does not get intermingled across teams.\n\n# The takeaway\n\nThe main idea is the dependency rule, not a trendy word like SOLID. Thatâ€™s how i see it today. It took me years to get here, and I'm open to change my mind.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r6aglp/solid_confused_me_until_i_found_out_the_truth/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o5ouy1k",
          "author": "aroras",
          "text": "> Once D is set correctly, O and L are consequences\n\nLiskov has nothing to do with dependency inversion. Also, DI cannot guarantee the module is open for extension. In fact, in many cases, open/closed can be achieved _without_ DI. DI is about coupling. Open closed is about axes of variation.\n\n> As such, you can replace a concrete implementation at runtime without changing the code. Thatâ€™s Liskov substitution\n\nNo. Itâ€™s literally not.\n\n> The I principle often drives systems toward shallow modules. Instead of one deep abstraction, you get fragmented contracts that push responsibility back to the caller. The shallow modules is taken from A Philosophy of Software Design book.\n\nOutsterhout's concept of deep modules is not incompatible with the interface segregation principle.\n\nPeople need to study this stuff on their own. Posts like this just spread misinformation",
          "score": 98,
          "created_utc": "2026-02-16 14:45:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5oxzaq",
              "author": "aroras",
              "text": "Also, Uncle Bobâ€™s â€œsingle source of changeâ€ way of thinking about single responsibility has been soundly criticized (and I think rightly so). Everything has multiple sources of change. \n\nAccounting wants a new value in the report. The CEO prefers last name first. The report is too slow to generate and must be performance tuned. \n\nShould there really be a 1:1 relationship between change requests and modules? No itâ€™s naive. Itâ€™s better to consider the underlying principle at play: cohesion.  \n\nModules should be designed with high cohesion in mind; once understood, you donâ€™t need a pithy rule of thumb like â€œone reason to changeâ€",
              "score": 30,
              "created_utc": "2026-02-16 15:01:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5ppk81",
              "author": "mackstann",
              "text": "> In his book, outsterhout argues against shallow modules. Instead he argues for deep modules.\n\nPretty sure you're in agreement with OP here.",
              "score": 3,
              "created_utc": "2026-02-16 17:11:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5pv9c0",
                  "author": "aroras",
                  "text": "I should have been more clear. I'm not in agreement with him that the interface segregation principle leads to a design that is incompatible with deep modules as described in *A Philosophy of Software Design*.  Outserhout argued for deep modules with simple, stable, intuitive interfaces. I updated my comment for clarity",
                  "score": 2,
                  "created_utc": "2026-02-16 17:38:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5pkpqp",
              "author": "confusing-world",
              "text": "If OP is wrong about Liskov, why don't you tell us what is it? Only affirming \"No. It's literally not\" is even more toxic for the community than the \"misinformation\" provided by OP. Argue about it!\n\nAt least OP brought some discussion about the topic and you are expecting us to just believe in your assertion? Your behavior is more close to misinformation spreading than OP post.\n\nWhat ridiculous affirmation: \"people need to study this stuff on their own\". So let's close this subreddit because it is useless if people can't share their knowledge.",
              "score": 15,
              "created_utc": "2026-02-16 16:49:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5pt4w7",
                  "author": "aroras",
                  "text": "My objective is only to point out to this community that OP had positioned himself as an authority on this topic, but was, in fact, teaching completely incorrect lessons.  A road sign warning of hazards ahead has value *even if* you don't know whether its because the road is icy or there's a rock-slide.  I may not have time to write a thorough explanation, but you've benefited from situational awareness.  Before I wrote the comment, people were praising him for the quality of his post.\n\n\\> What ridiculous affirmation: \"people need to study this stuff on their own\".\n\nThis just makes me sad. I feel strongly that self study is an important part of self-growth and improvement.  Not all lessons fit in blog post or a reddit post.  Sometimes you do just have to buy the book and read it.",
                  "score": 11,
                  "created_utc": "2026-02-16 17:28:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5tdaua",
                  "author": "glehkol",
                  "text": "Sad state of things these days. People more interested in telling others theyâ€™re ackchyually wrong than helping. Not surprising considering the demographic of people attracted to this field.",
                  "score": 1,
                  "created_utc": "2026-02-17 05:04:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5pjnf7",
              "author": "Tubthumper8",
              "text": "Adding onto this to explain more about LSP. The Liskov substitution principle is:\n\n\n> Subtype Requirement: Let â  Ï• (x) be a property provable about objects â  x of type T. Then â  Ï• (y) should be true for objects â  y of type S where S is a subtype of T.\n\n\nIt's a requirement for designing a correct type hierarchy. Notably this principle has a different perspective than type theory requirements for subtypes (contravariance of parameters & Co variance of returns), it's getting into the notion of **behavioural subtyping**. This is undecidable in general but the point of the principle is that you, the programmer, have to uphold the behavioural contract when creating a subtype.Â \n\n\nA general example is a subtype that overrides a method to have an infinite loop randomly. It type checks fine, the behaviour is undecidable statically at compile time, and you the programmer have violated the principle by introducing that behavioural incompatibility with the super type.Â \n\n\nThis is specifically about subtyping and has nothing to do with dynamically calling an implementation of a trait/typeclass/interface at runtime. That's just dynamic dispatch which is a built-in feature of most languages today",
              "score": 4,
              "created_utc": "2026-02-16 16:44:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5r0bxl",
              "author": "KaleAshamed9702",
              "text": "I would like to understand where op is wrong about LSP, as Iâ€™ve also read the design patterns book front to back and clean code, and that was my takeaway.",
              "score": 2,
              "created_utc": "2026-02-16 20:52:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5orotw",
          "author": "RickJWagner",
          "text": "Iâ€™ve retired after 35 years in programming.  In that time, I had complete design decision over several ( but not many ) applications.\n\nI wish my career had offered more work like that, I think you get a little better every time you do one.  Maybe consultants could have a career like that, I never saw anyone working in a regular job that got to do many large scale designs.",
          "score": 15,
          "created_utc": "2026-02-16 14:28:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5oxszf",
              "author": "Icy_Screen3576",
              "text": "you reminded me of the japanese word kaizen, continuous improvement.",
              "score": 0,
              "created_utc": "2026-02-16 15:00:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5rb0vn",
                  "author": "RickJWagner",
                  "text": "I have no idea why this is being downvoted.\n\nKaizen is completely appropriate.  You design your first system, then immediately learn of the flaws when you go to production.  You make changes in the next app, but learn new lessons there too.  The third one is a little better againâ€¦.",
                  "score": 7,
                  "created_utc": "2026-02-16 21:44:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5qpm5l",
          "author": "SiegeAe",
          "text": "I would say the order only matters when one is more a problem for you and I think the purposes of each are much simpler and mor general than this.\n\n\nWhat I've found each idea has been most useful for:\n\n- Single Responsibility, if a single piece of code is handling logic for many aspects of a system, when you change it you have a higher risk of breaking more aspects of the system so may be better if its broken up, it is also useful as a counterpoint to DRY meaning if code looks the same but it serves different purposes then it may be better to just have the code repeated, an indicator you haven't followed it when it might've been useful is if you start adding if-else logic to a method to make it behave differently for one stream of data than the others that use it, like the opposite of shotgun surgery.\n\n- Open/Closed, this is about designing things to have less of a need to change for existing consumers, so if you want to add more behaviour or more options you don't break how the existing consumers of your work, e.g. instead of an internal switch statement just take anyone who implements a certain interface, like the visitor and strategy patterns, or instead of taking unique arguments that get acted on you might consider taking a list that gets iterated on so the list can be added to. This is especially important for libraries and other forms of public APIs, if you follow this principle well then the API consumers will have much less issues.\n\n- Liskov Substitution - This is just about making sure child classes handle the contract of their parents predictably, a common way this gets broken is that people will override a parent classes method just to throw an exception saying its not allowed on the child, this means that consumers of those classes may be surprised if accept the parent and cater for the parent but someone provides this outlier child, you'll likely end up with more errors in your app.\n\n- Interface Segregation - This is more about not having god interfaces, this happens when interfaces aren't serving a specific enough purpose, a good example is xunit's IAsyncLifetime, because it is the only owner of InitializeAsync, but it also has DisposeAsync there are many instances of people having a DisposeAsync method in their test classes that is just a passthrough, if however there were an IAsyncInitializable interface this problem wouldn't occur (obviously it encourages some people to dispose what they create as many forget this so it does serve some purpose but that's a different debate)\n\n- Dependency Inversion - This is really just about passing in what you use instead of both creating it and using it in the same space, and is especially useful for external dependencies, its primarily to reduce coupling, meaning you can use different dependencies for the same service/utility more easily and you can use a service/utility in more different places if you want, also I find most people use it these days for testing, in that for your test you can just pass in a mock or fake instead of the real thing and your test can potentially be much faster and simpler (though many people use this to make their test more complex, but that goes to my final point below)\n\n\nThe problem I notice more often these days is, people applying these princples just because they were told it's \"best practice\" and you end up with the old enterprise fizzbuzz pattern. I think its more important to try and understand when and where these are beneficial and apply them only where the benefit is clear or it's simpler to apply than not, if applying a princple adds complexity without clear benefit then it might not be a good option.",
          "score": 8,
          "created_utc": "2026-02-16 20:00:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tjngk",
              "author": "Icy_Screen3576",
              "text": "Complexity must be justified.",
              "score": 3,
              "created_utc": "2026-02-17 05:53:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5wyrf7",
                  "author": "SiegeAe",
                  "text": "Also sometimes simplicity is harder but the upfront effort usually pays that back quickly.\n\nI really liked a point I saw recently that complexity is often not a case of overengineering but rather underengineering.",
                  "score": 1,
                  "created_utc": "2026-02-17 19:10:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5qzo0v",
          "author": "PaulPhxAz",
          "text": "I wish they would stop teaching this.",
          "score": 4,
          "created_utc": "2026-02-16 20:49:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tipf1",
              "author": "Icy_Screen3576",
              "text": "https://preview.redd.it/fvo9l9j7tzjg1.jpeg?width=4032&format=pjpg&auto=webp&s=29f64e8d334f37bf1918046a374319176c1a58e3\n\nI read this twice to understand that the key is the dependency rule.",
              "score": 2,
              "created_utc": "2026-02-17 05:45:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5vre3q",
                  "author": "Jarocool",
                  "text": "The key is coupling and cohesion. All of those â€œprinciplesâ€ are leading to lowering coupling and increasing cohesion in one way or another. Once you understand that you donâ€™t need the solid training wheels anymore.",
                  "score": 2,
                  "created_utc": "2026-02-17 15:41:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5sfzfo",
              "author": "RicketyRekt69",
              "text": "Why? The concepts themselves are useful when applied correctly.  Iâ€™ve seen what kind of code people write when ignoring all of this, and itâ€™s atrocious.  Iâ€™ll take vague design principles over poor code hygiene any day of the week.",
              "score": 1,
              "created_utc": "2026-02-17 01:30:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5tt8u6",
                  "author": "PaulPhxAz",
                  "text": "\"Clean\" is a brand.  Robert M has said himself that he doesn't have research of case studies on if it's actually helpful, but there is a load of papers, research, rigorous academic investigation in general on the subject. \n\nYou can't say \"I don't want to do 'Clean' coding\", because who wouldn't want it to be clean, what, you want \"dirty\" code?  It's harder to explain Locality of Behavior or Righting or Pragmatic or Residuality or whatever else you might have in mind.  \n\nSo, yes, interfaces, all that jazz.  Lots of good ideas.  I've also seen absolutely horrible code that is \"Clean\".  And the worst part is \"It's Clean Standard, it must be good\" ideology.",
                  "score": 2,
                  "created_utc": "2026-02-17 07:15:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ox5zz",
          "author": "atika",
          "text": "Sorry but thatâ€™s not Liskov.",
          "score": 13,
          "created_utc": "2026-02-16 14:56:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5oyrfc",
              "author": "Icy_Screen3576",
              "text": "what is it? ",
              "score": 3,
              "created_utc": "2026-02-16 15:05:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5papyq",
                  "author": "RipProfessional3375",
                  "text": "child classes should have the same behaviour as their parent class + their own.\n\nWeird rule to have among the other more abstract ones.",
                  "score": 16,
                  "created_utc": "2026-02-16 16:03:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5pqmc9",
                  "author": "atika",
                  "text": "If you want to understand it fully, look up an explanation in terms of variance / covariance.",
                  "score": 1,
                  "created_utc": "2026-02-16 17:16:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5swiq0",
                  "author": "ikeif",
                  "text": "Only in this sub is everyone expected to not ask questions and insist answers are clear and known.",
                  "score": 1,
                  "created_utc": "2026-02-17 03:10:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5opzvn",
          "author": "confusing-world",
          "text": "This post has high quality content, something difficult to find nowadays. Thanks for sharing the insights, OP, it was valuable for me.",
          "score": 22,
          "created_utc": "2026-02-16 14:19:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5orrug",
              "author": "Icy_Screen3576",
              "text": "Appreciate that, glad it was useful",
              "score": 3,
              "created_utc": "2026-02-16 14:28:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5otso8",
                  "author": "lelleepop",
                  "text": "great write up!! have u considered doing a technical blog or something? Iâ€™m v interested in following it and learning more from u",
                  "score": -8,
                  "created_utc": "2026-02-16 14:39:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5rjljb",
          "author": "sennalen",
          "text": "It's just pimpl. The whole consultant-industrial complex can DIAF.",
          "score": 2,
          "created_utc": "2026-02-16 22:27:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5u81n4",
          "author": "severoon",
          "text": ">you get the word SOLID. That sequence is what we ended up learning.\n\n>The problem is the order itself\n\nI'm a bit confused about the assertion that the order of SOLID is somehow significant. It's just meant to be a mnemonic, it doesn't intend to order the principles in any useful way.\n\nI think the most fundamental of these principles is LSP. I'm sure there are arguments to be had about the relative importance of the SOLID principles, but LSP is the one that the others depend upon getting right. If you don't know how to properly implement the behavioral contract of an interface, then inverting dependencies by introducing interfaces isn't going to get you too far.\n\n>As such, you can replace a concrete implementation at runtime without changing the code. Thatâ€™s Liskov substitution.\n\nI think you're conflating LSP with a thing that proper use of LSP enables, but it's not the only purpose of LSP.\n\nLSP basically says that the behavioral contract specified by a type must not be violated by a subtype. The canonical example of violating LSP is letting Square extend Rectangle. In math, a \"square is a rectangle,\" but in OOD, a square does not behave the same way a rectangle does:\n\n    @Test\n    void testArea() {\n      Rectangle r = new Rectangle();\n      r.setWidth(3);\n      r.setLength(4);\n      assertThat(r.getArea()).isEqualTo(12);\n    }\n\nIf you try to treat a Square instance polymorphically as type Rectangle, this test will never pass because a square is behaviorally not a rectangle.\n\nBasically, LSP says that whatever behavior that's specified by an interface, the subtype must conform. It can play within a more restricted area allowed by the contract, but it may not stray outside those bounds.\n\n>Once D is set correctly,Â **O**Â andÂ **L**Â are consequences. The system becomes open for extension and closed for modification because you can swap a message broker without modifying the core.\n\nI don't think this really gets at that core of what the Open-Closed Principle is all about. I think folks approach it as a kind of \"practice,\" like when new requirements come in, you should try to figure out a way to extend the existing code rather than modify it, but the principle itself doesn't give much guidance on how to design a system that actually makes this possible. It just leaves it to the architect to consult your crystal ball.\n\nWhat OCP is really saying is this: A design should define the roots of your dependency DAG around the most stable business entities and concepts.\n\nIn other words, if you're writing banking software, then there are certain things about the banking business that were true yesterday, they're true today, and they'll be true fifty years from now. Your system has customers, and those customers have accounts, and those accounts have balances. This means that the bank software should define a customer entity that *only* specifies the core, stable properties of a customer, the same goes for accounts. Can a customer exist that doesn't yet have accounts, does that make sense? Yes. Can an account exist that doesn't belong to any customer? No, that doesn't really make sense. So the system should be able to represent a customer without the concept of an account existing, and the account entity can depend on the customer entity. An intrinsic property of an account is a balance, so this core concept of account can declare balance as a property.\n\nNow let's say someone comes along and wants to add a bunch of user preference columns to the Customer DB table, users can specify dark mode on the bank UI, and they like the date formatted this way, etc, etc. By putting these things that might change into the core Customer entity, you're now allowing everything that depends on that entity to also become aware and form dependencies on all this new stuff that might or might not exist ten versions from now. That's bad. Instead, create a UserPreferences table and put all that stuff there, and let it depend upon the Customer table. Now only things that care about UserPreferences will bother depending on it, and everything else that doesn't care about that info doesn't need to be aware of it. This is an example of OCP, extend by adding, not modifying.\n\nThe exception to OCP is when your design doesn't mirror the actual problem domain correctly. Maybe one of the core aspects of a Customer didn't make it into your design, but should have. In that case, you shouldn't try to extend the current design, you should modify the Customer entity so it reflects reality. It's difficult to understand the problem domain, so this will happen, and a good architect is constantly learning and incorporating what they learn into the system. The architect should understand the problem domain well enough to understand where the joints are, and the system should carve the problem domain at its joints, so to speak.\n\n>TheÂ **I**Â principle often drives systems toward shallow modules. Instead of one deep abstraction, you get fragmented contracts that push responsibility back to the caller. The shallow modules is taken from A Philosophy of Software Design book.\n\nI don't agree with this at all. If you look at Ousterhout's diagram, the \"deep\" module has a smaller, more focused interface than the \"shallow\" module. This is exactly in line with the ISP, which says to separate interfaces into smaller, more focused contracts. What Ousterhout is objecting to is abstractions that specify overly simple contracts, basically the overuse of abstraction.\n\nOne of the problems I have with his book is that it hasn't really crystallized a philosophy. It does do a good job talking about his personal philosophy of software design, but I think many of the principles in there are not defined sharply enough to be applicable and they rely too much on the reader's judgment to be an \"objective\" kind of philosophy, if that makes sense. Also, I think he muddies the waters a bit by setting up some of his principles in opposition to other ways of doing things when I feel like he hasn't really deeply understood the thing he's trying to refute, such as the shallow/deep vs. ISP â€¦ these are not really opposed.\n\nThe last one is dependency inversion and I'll discuss that in a [separate comment below](https://www.reddit.com/r/softwarearchitecture/comments/1r6aglp/comment/o5uaq37/).",
          "score": 2,
          "created_utc": "2026-02-17 09:36:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uaq37",
              "author": "severoon",
              "text": "I do think that DIP is one of the most critical principles for a great OO architecture, but I feel like it's often misunderstood.\n\nIn the diagram you present where the Data subsystem depends upon the Business subsystem, that gestures in the right direction but leaves out some critical details.\n\nThe first thing that's often misunderstood about DIP is that people think Martin is talking about the n-tier architecture when he talks about the \"layers\" of the system. He's not. In your diagram, you've depicted a business logic layer and a data access layer, and you're probably imagining a presentation layer above the business logic layer, and the web client above that, right? This is the wrong picture.\n\nIf you read his white paper closely, you'll see that he's dividing up the system not according to these tiers, but rather he's talking about policy layers, mechanism layers, and utility layer. If you conflate these \"layers\" with the n-tier architecture of most web apps, you're getting it wrong. Think about the business logic tier, if you parse a string into a URL. That code uses a string utility. If you authenticate a user in order to service the request, you're using the auth module and that's probably a mechanism or utility, and it's also code in that same tier. Maybe you get a request and use a promise pattern to kick off async processing for different things that need to happenâ€¦that code managing that async processing isn't \"policy\" stuff, it's infrastructure you're using.\n\nThe way he's viewing a system for the purpose of presenting DIP is completely orthogonal to the n-tier architecture most people think he's talking about. He's not saying that, though. He's saying that when your business logic layer gets a user request and the first thing it does is authenticate that user, it should not call directly into the auth system you wrote and have all that auth stuff on its classpath. It should call into an interface, and the compilation dependency of this subsystem on auth should end there, at that auth API.\n\nThe other big thing people get wrong about DIP is how the abstractions that enable inversion are packaged. If you consider this subsystem that processes user requests, which needs to authenticate the user before servicing the request, it depends on the Auth interface, right? If that auth interface is packaged with its implementation, then a dependency on the interface is a dependency on the deployment unit (a jar, say) that contains all of that implementation code. This means that entire auth jar needs to build as a compilation dependency of this subsystem anyway.\n\nSo you cannot package the abstraction with the implementation, because in order to build and deploy that abstraction in a form for clients to use, the entire auth subsystem has to be built. So instead you package it with the subsystem that uses it, as you have depicted in your diagram. Problem solved, right?\n\nNope. Now the auth subsystem implements an interface in the deployment jar of this other subsystem, and in order to build the auth subsystem, this client of the auth subsystem needs to be built first.\n\nThe takeaway is that you cannot package the abstractions with the implementations nor with the clients. They must be packaged separately. This way, the build system builds those, packages them up, and makes them available to dependencies, which include *both* clients of the interface as well as implementations of it. This is harder than it seems, because that means all dependencies in that API package need to be included in it, and those cannot depend on anything outside either.\n\nIf you haven't set up a system where you can compile the interface independently, then the client and implementations independent of each other, you've inverted the dependency in a hypothetical sense, but you're not getting any benefit from having created these abstractions. You haven't shortened your classpath, you haven't sped up your compiles, you haven't done much of anything. This is something Ousterhout talks about in his book, explaining that he hasn't yet seen a system that really benefits much from DI. That's true, but it's not because DI is bad, it's because people don't actually invert dependency correctly.",
              "score": 4,
              "created_utc": "2026-02-17 10:01:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ug7tu",
                  "author": "Icy_Screen3576",
                  "text": "Man, i learned a lot.   \n  \ni am convinced about the OCP because you gave me an example from the field, having core customer entity that can be extended with user preferences, i assume you prefer composition over inheritance.    \n  \nFor Barbara liskov, i dont like the rectangle and square examples, yet i got your point about me focusing on what applying the principle is enabling, which is normal for an avg IQ person like me.\n\nOn ISP, i am leaning towards having one database port interface recently instead of having several interfaces, unlike the typical per entity or per root entity abstraction. I had recently worked with a team on a worker service that consume a kafka topic and writes the records to several db tables. The team thinking of segregating the interfaces, created an interface for each entity, and i have done that for long. Having a single database port made things simpler, the port implementation acted as a usb port, you know following the hexagonal architecture pattern.\n\nOn dependency inversion, i think it is the most important one and vote for focusing on the dependency rule instead. Most engineers i talk to, mention dependency injection which is the framework that should be a detail. Your point about having the interface in its own assembly and not having it inside the business rules is well taken sir. \n\nThe order SOLID is the problem since most of education starts with the S, which is very ambiguous.   \nIf we can all invert the dependency properly and isolate the core, we would be in a better place.",
                  "score": 1,
                  "created_utc": "2026-02-17 10:51:11",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o60h5r8",
          "author": "trolleid",
          "text": "He originally arranged them as SOLDI",
          "score": 2,
          "created_utc": "2026-02-18 07:03:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60tinb",
              "author": "Icy_Screen3576",
              "text": "I wasnt aware of that. I heard him once saying they were 8 principles before coming to the trendy SOLID.",
              "score": 2,
              "created_utc": "2026-02-18 08:56:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5vkwix",
          "author": "Imaginary_Treat9752",
          "text": "No, you got it all wrong. E.g. once D is set correctly, O does not necessarily follow. ",
          "score": 1,
          "created_utc": "2026-02-17 15:10:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vn9q2",
              "author": "Icy_Screen3576",
              "text": "dont you think swapping a database adapter without touching the core an extension without modification? ",
              "score": 2,
              "created_utc": "2026-02-17 15:21:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5vtnuv",
                  "author": "Imaginary_Treat9752",
                  "text": "Look. It is dead simple. You can have a system that comply to D and one that doesnt. The system that comply to D can have places that are open-for-extension, and it can have places that are closed modification. If we are talking java this is concretely using strategy places some places in your code (open-for-extension), and other places you just use a plan if else statement (closed for modification). That's it. This system is now a proof that what you are saying is false because it comply to D and O is not satisfied 100% (some places are closed for modification). You follow? ",
                  "score": 1,
                  "created_utc": "2026-02-17 15:53:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6don6x",
          "author": "Natural_Tea484",
          "text": "If D is setup correctly, Iâ€™m not sure O and L are implicitly satisfied. These are all complementary, even if they seem to overlap sometimes.",
          "score": 1,
          "created_utc": "2026-02-20 06:32:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dx664",
              "author": "Icy_Screen3576",
              "text": "It may not be direct from definition standpoint. Still its tangible. Swapping a payment gateway adapter without touching the core is extension without modification. Sure extending a core entity through inheritence or composition is the norm. As such, substituting an executing operation on rutime is something liskov enables when implemented properly.",
              "score": 1,
              "created_utc": "2026-02-20 07:49:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6e4687",
                  "author": "Natural_Tea484",
                  "text": "You can easily come up with very trivial examples for both.   \n  \nFor this reason, I think it's important not to mix them up, and not try to get to (dangerous) conclusions like \"If you do X you automatically do Y\".\n\nD without O:\n\n    public interface IDiscountCalculator\n    {\n        decimal Calculate(string customerType);\n    }\n    \n    public class DiscountCalculator : IDiscountCalculator\n    {\n        public decimal Calculate(string customerType)\n        {\n            if (customerType == \"Regular\") return 0.05m;\n            if (customerType == \"Premium\") return 0.10m;\n            if (customerType == \"VIP\") return 0.20m;\n            return 0m;\n        }\n    }\n\nD without L:\n\n    public interface IFileStorage\n    {\n        void Save(string content);\n    }\n    \n    public class DocumentService\n    {\n        private readonly IFileStorage _storage;\n    \n        public DocumentService(IFileStorage storage)\n        {\n            _storage = storage;\n        }\n    \n        public void Publish(string content)\n        {\n            _storage.Save(content);\n        }\n    }\n    \n    public class LocalFileStorage : IFileStorage\n    {\n        public void Save(string content)\n        {\n            File.WriteAllText(\"file.txt\", content);\n        }\n    }\n    \n    public class ReadOnlyStorage : IFileStorage\n    {\n        public void Save(string content)\n        {\n            throw new InvalidOperationException(\"Storage is read-only.\");\n        }\n    }",
                  "score": 1,
                  "created_utc": "2026-02-20 08:55:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5pq5q5",
          "author": "Independent_Sign_395",
          "text": "What's the name of book?",
          "score": 1,
          "created_utc": "2026-02-16 17:14:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tgn7z",
              "author": "Icy_Screen3576",
              "text": "https://preview.redd.it/dt04ud5bqzjg1.jpeg?width=4032&format=pjpg&auto=webp&s=5729ac28b7180a0f7385e901f6e4da2081565f7c\n\nBoth authors do not agree on stuff, a good way to see our blindspots.",
              "score": 3,
              "created_utc": "2026-02-17 05:29:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5pc60i",
          "author": "RipProfessional3375",
          "text": "Very good analysis. You will consider most of this at least somewhat wrong in a few years.  \nThis reminds me a lot of my own thoughts when the deeper concepts and principles that are hidden by the awful interface of SOLIDâ„¢ were starting to sink in.   \n  \nKeep thinking about it, keep making things and seeing how they confirm or conflict with the principles, and make your own adjustments and conclusions. Eventually you will get it on a level that is more intuitive than rational.",
          "score": -1,
          "created_utc": "2026-02-16 16:09:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tha47",
              "author": "Icy_Screen3576",
              "text": "Intuitive yes. Looking for opposing ideas to find our blindspots lies at the heart of science.",
              "score": 1,
              "created_utc": "2026-02-17 05:34:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5oxwuz",
          "author": "FriedGangsta55",
          "text": "Very high quality content OP, thank you",
          "score": -7,
          "created_utc": "2026-02-16 15:00:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5thcr0",
              "author": "Icy_Screen3576",
              "text": "Appreciate that",
              "score": 1,
              "created_utc": "2026-02-17 05:34:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5pahol",
          "author": "AIterEg00",
          "text": "Very well written, researched, and articulated.  I will definitely be applying this going forward!  Thank you for this write up!",
          "score": -7,
          "created_utc": "2026-02-16 16:01:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ti28e",
              "author": "Icy_Screen3576",
              "text": "Good call.",
              "score": 1,
              "created_utc": "2026-02-17 05:40:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r77eyp",
      "title": "I built an open architecture diagramming tool with layered 3D views - looking for early feedback from people who actually draw system diagrams",
      "subreddit": "softwarearchitecture",
      "url": "https://v.redd.it/aj72v1qj92kg1",
      "author": "hexploitsgroup",
      "created_utc": "2026-02-17 14:26:33",
      "score": 58,
      "num_comments": 40,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tool/Product",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r77eyp/i_built_an_open_architecture_diagramming_tool/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5viay2",
          "author": "andrerav",
          "text": "It's a UNIX system! I know this!",
          "score": 17,
          "created_utc": "2026-02-17 14:57:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vjddj",
              "author": "hexploitsgroup",
              "text": "Life, uh, finds a way ðŸ¦–",
              "score": 7,
              "created_utc": "2026-02-17 15:02:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5vlacf",
          "author": "i_be_illin",
          "text": "Why? Itâ€™s hard enough to get people to understand 2D architecture views. Is it just for a wow factor?",
          "score": 13,
          "created_utc": "2026-02-17 15:11:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vmf3n",
              "author": "bikeram",
              "text": "Diagrams are for the intended audience. I keep more complex diagrams for myself as a brain dump.",
              "score": 3,
              "created_utc": "2026-02-17 15:17:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5w1jfr",
          "author": "atika",
          "text": "Why do architects feel like EVERYTHING needs to fit on one diagram? Even for one small slice of the system, you can create several diagrams for different aspects.",
          "score": 7,
          "created_utc": "2026-02-17 16:32:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vfg0q",
          "author": "bikeram",
          "text": "This is cool. Can you drag components around in 3d view?\n\nI agree with u/asdfdelta. This matches my mental model. \n\n~~Would it be possible to take it one step further? Could we drill down into services and add more detail? Kind of like a Russian doll.~~\n\n~~Depending on the design, sometimes I know exactly how I want a core service to work. So I'll do a bottom-up approach. Sometimes it's more abstract and top-down makes more sense.~~\n\n  \nEdit: Sub-module exist. Looks like I'm porting everything from [draw.io](http://draw.io) today.",
          "score": 6,
          "created_utc": "2026-02-17 14:42:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vfx55",
              "author": "hexploitsgroup",
              "text": "You move the components around in the 2D view (it's a top down representation of the architecture), this is then reflected in the 3D view. I tried to allow direct component movement in 3D but it didn't feel very good from a UI/UX perspective, something I'll definetely re-visit if it's an indemand feature!\n\n  \nPS - Does the link work for you, I know [u/asdfdelta](https://www.reddit.com/user/asdfdelta/) is having some issues.",
              "score": 4,
              "created_utc": "2026-02-17 14:44:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5vgi8w",
                  "author": "bikeram",
                  "text": "Works fine on desktop. The top down is really intuitive, but I don't think I would have figured that out. Maybe when you switch to 3D the first time it does a top down view, then pans to perspective.",
                  "score": 3,
                  "created_utc": "2026-02-17 14:47:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5vmozw",
          "author": "SolarNachoes",
          "text": "Ok now add data flow links with animated gremlins.",
          "score": 3,
          "created_utc": "2026-02-17 15:18:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ve4lz",
          "author": "asdfdelta",
          "text": "The links don't work, btw.\n\nFINALLY someone sees what I see! I have been thinking about building this exact thing for years.",
          "score": 6,
          "created_utc": "2026-02-17 14:35:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5veclq",
              "author": "hexploitsgroup",
              "text": "The links don't work?! Curious to know what you're seeing when you try to goto 'https://layerd.cloud'.\n\nThat's great to hear - means I'm not the only one who's been frustrated by this! Would love to hear what you think once you've had a chance to play around with it. If anything feels off or you hit a wall, don't hesitate to let me know - early feedback like yours is shaping what I build next.",
              "score": 4,
              "created_utc": "2026-02-17 14:36:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5vey3i",
                  "author": "asdfdelta",
                  "text": "The links lead to a 404, btw. I tried on multiple devices",
                  "score": 2,
                  "created_utc": "2026-02-17 14:39:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5vzbne",
          "author": "Bayonett87",
          "text": "Helpful for flows. Showing what's happening in one layer, then another, then we can see \"jumps\" between them.  \nGonna try it out! I just learned how to use mermaidjs, I will definitely have my fun with this too :D",
          "score": 2,
          "created_utc": "2026-02-17 16:20:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vzxvs",
              "author": "hexploitsgroup",
              "text": "Please let me know if you have any feedback or feature requests! Let me know how you find it!",
              "score": 2,
              "created_utc": "2026-02-17 16:24:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5w57lw",
                  "author": "vplatt",
                  "text": "Cool, but my classic issue with diagramming tools is in showing boundaries and boundaries within boundaries.  \n\nFor example:  How do I show resources in a subnet?  \n\nIn AWS: How would I show servers within a cluster within a security group within a subnet within an availability zone within a region within an account?\n\nYou get the point.  There are boundaries within boundaries, recursively.  Your concept of layers handles only one part of that hierarchy, it assumes a linear stacking, and it's non-recursive.  \n\nCurrently I use Lucid.app for customers.  They have the same problem, but they let me put boundaries on the page in the form of shapes and then let me know stuff inside that boundary.  They also let me group the boundary and its contents and make it manipulable as a unit.  But even Lucid has problems because it doesn't handle multiple levels of boundary properly.\n\nEdit:  \n\nOh, and lines need endpoint symbols like arrow heads to imply inbound/outbound directionality at a minimum.\n\nA description for a shape should be a tooltip that pops up when I hover over the shape in the diagram; at least in 2D view.",
                  "score": 2,
                  "created_utc": "2026-02-17 16:51:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o62bc93",
          "author": "ryguycompsci",
          "text": "Had a co-worker point me to this today. I really like it as a quick prototyping tool, and the 3D view scratches and itch I have to see actual depth in our architecture diagrams across layers.  \n  \nA few suggestions/observations/bug reports in no particular order:  \n1. (Suggestion) I would love to have the ability to upload custom icons for blocks or support icon packs like draw.io has for AWS/Azure/GCP resources.  \n2. (Observation/Suggestion) The alignment and distribute tools work great, but the alignment behavior was a little unexpected for me. Granted, my expectations are coming from draw.io's behavior. When I took a few vertical items and try to align them along their horizontal center, I expected them to align based on the center of the *first* item I selected (this is the default behavior in draw.io). It looks like by default that alignment finds the middle of *all* selected elements. I noticed similar behavior with the left-and right-align, where it chose the left/right-most edge of all the selected blocks as the anchor point for alignment. It doesn't ruin the experience, but as someone who is quite particular about alignment and distribution, thinking about every selected block being relative to *each other* is more difficult than thinking about every selected block being relative to the *first* block selected. Not a problem for quick prototyping, but more important for higher-impact diagrams  \n3. (Suggestion) A light mode would be nice. I often show high-level architecture diagrams to our product team and many of them don't do dark mode UI's. I think the colored-coded borders on the left side of the blocks would show up well in a lighter theme. I did some mediocre inline style editing with my browser devtools to change the workspace background and the background/color of one of the blocks and it looked pretty good.  \n4. (Suggestion) I like the nested layers. I would be interested in seeing \"cross\" layers which could contain blocks across other layers. This would be great for representing-for example-VPC's in AWS which can contain back-end and data resources.\n5. (Bug?) I'm not sure the \"Toggle Interactivity\" button is working. I put it in the \"lock closed\" state, but everything in the diagram could still be interacted with. I may be misunderstanding this feature, too.\n6. (Bug/Suggestion) I colored one of my layers black, and in the 3D view the label and label text were both black. Might want to do a check on the layer color and dynamically use an appropriately contrasting label/text color for accessibility/user error.",
          "score": 2,
          "created_utc": "2026-02-18 15:05:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6b5328",
              "author": "hexploitsgroup",
              "text": "1. AWS, GCloud and Azure icons added natively! No need to upload :D!\n\n2. Before: Alignment used bounding-box logic across all selected nodes (e.g., \"align left\" moved everything to the leftmost node's edge), with measured built in layer order. After: The first-selected node (selectedNodeIds\\[0\\]) acts as the anchor - all other nodes align to it, matching draw.io-style behavior.\n\n3. Added - you can now choose this at the top right of the page. If it's too bright please do let me know!\n\n4. Added via the layer context menu (...), you can now choose layout as horizontal or vertical (test it out in 3D mode!)\n\n5. Fixed!\n\n6. Also fixed!\n\nMuch appreciated, thanks again! Let me know if these all align!",
              "score": 1,
              "created_utc": "2026-02-19 21:04:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5vl3ii",
          "author": "ubermuda",
          "text": "My first reaction was \"this is deliciously useless\" but then I tried it and you know what I might actually use this? A bit concerned with the potential for spaghettification of the diagram though, do you have an example of a complex architecture?",
          "score": 1,
          "created_utc": "2026-02-17 15:10:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vlu72",
              "author": "hexploitsgroup",
              "text": "Something slightly more complicated as an example (PS - the lines move in 2D view, if it's confusing to know what's networking to what):\n\nhttps://preview.redd.it/45fhthlrm2kg1.png?width=3005&format=png&auto=webp&s=2c9042e58dfb630d8bc6f739b4072de8974e5b89\n\nRelated 3D view:\n\n[https://media1.giphy.com/media/v1.Y2lkPTc5MGI3NjExMTh4bThvNHNwMTY5YWlsN2c1bnB2Z2M2dThoamo0cjA4cWZnMzl4aiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/GRADAvAuctqdWpH3Wi/giphy.gif](https://media1.giphy.com/media/v1.Y2lkPTc5MGI3NjExMTh4bThvNHNwMTY5YWlsN2c1bnB2Z2M2dThoamo0cjA4cWZnMzl4aiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/GRADAvAuctqdWpH3Wi/giphy.gif)\n\nPlease do let me know your thoughts!",
              "score": 1,
              "created_utc": "2026-02-17 15:14:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5w3ug0",
          "author": "hurley_chisholm",
          "text": "This looks promising, thank you for sharing! Layerd addresses some of my frustrations with C4 and the various editors that support it.\n\nDo you have a link to the diagramâ€™s data model schema or are you expanding on an existing diagram visualization standard?\n\nAlso, what are your thoughts about open-sourcing the code (even if the web app is freemium)?",
          "score": 1,
          "created_utc": "2026-02-17 16:44:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5w4d7t",
              "author": "hexploitsgroup",
              "text": "Hey! The data model schema is indirectly exposed when you click the 'Export JSON' button at the top left - if it's valuable for users to have an actual spec, I can make one! Open sourcing is 100% on our roadmap, just trying to get some confirmation bias before we take this any further!",
              "score": 3,
              "created_utc": "2026-02-17 16:47:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5yex8u",
                  "author": "hurley_chisholm",
                  "text": "A â€œproperâ€ schema would be interesting to see, but I certainly donâ€™t want to make more work than is needed at this stage.\n\nLooking forward to seeing more from this project!",
                  "score": 2,
                  "created_utc": "2026-02-17 23:23:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5wgh1i",
          "author": "Low_Satisfaction_819",
          "text": "Navigating the 3d layer is hard - I am used to clicking to recenter the view. If you havent already try out sketchup or other cad tools and model their interaction behaviour.",
          "score": 1,
          "created_utc": "2026-02-17 17:46:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62sd1d",
          "author": "vyrmz",
          "text": "Will only complicate things. Unneccary.\n\nGood if you need to sell stuff to non-engineers, bad for engineers.",
          "score": 1,
          "created_utc": "2026-02-18 16:23:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ynogi",
          "author": "GrogRedLub4242",
          "text": "3D adds no useful signal over 2D",
          "score": 0,
          "created_utc": "2026-02-18 00:12:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r594du",
      "title": "How would you design a Distributed Cache for a High-Traffic System?",
      "subreddit": "softwarearchitecture",
      "url": "https://javarevisited.substack.com/p/how-would-you-design-a-distributed",
      "author": "javinpaul",
      "created_utc": "2026-02-15 08:06:47",
      "score": 36,
      "num_comments": 1,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r594du/how_would_you_design_a_distributed_cache_for_a/",
      "domain": "javarevisited.substack.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5i075c",
          "author": "worksfinelocally",
          "text": "Nice post, really clear explanation. The breakdown between local, centralized, and hybrid cache is easy to follow. Maybe itâ€™s also worth mentioning a replicated cache variant, which can be useful in some cases. https://youtu.be/Ov2q8VdyrM0",
          "score": 1,
          "created_utc": "2026-02-15 12:52:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8ak3f",
      "title": "After you've mastered K8s, have any of you found yourselves wanting to avoid it for certain projects?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1r8ak3f/after_youve_mastered_k8s_have_any_of_you_found/",
      "author": "kingswordmaster",
      "created_utc": "2026-02-18 18:11:20",
      "score": 31,
      "num_comments": 20,
      "upvote_ratio": 0.83,
      "text": "I've been diving deep into Kubernetes, and once you get past the learning curve, it feels like a game-changer for building scalable apps without getting locked into a specific vendor. But I'm genuinely curious, after you've mastered K8s, have any of you found yourselves wanting to avoid it for certain projects? Maybe due to complexity, overhead, or better alternatives like Docker Swarm, Nomad, or serverless options?\n\nWhat were the scenarios where you opted out, and why? Sharing your experiences would be super helpful for those of us still evaluating it long-term.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r8ak3f/after_youve_mastered_k8s_have_any_of_you_found/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o63l5fr",
          "author": "Adorable-Fault-5116",
          "text": "I think people underestimate just how fast a single instance is. You probably don't need any cluster-like orchestration at all. You can handle 10k req per sec without putting any effort in.",
          "score": 54,
          "created_utc": "2026-02-18 18:32:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63q7qb",
              "author": "liyayaya",
              "text": "No no! We can't have this in our state of the art enterprise architectureâ„¢.  \nWe absolutely need a multi az autoscaling cluster for our crud app that serves 100 something users daily :\\^)\n\nGod i hate resume driven architecture.",
              "score": 32,
              "created_utc": "2026-02-18 18:54:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o640qyz",
                  "author": "Salfiiii",
                  "text": "There are certainly other ways as well to achieve this but fault tolerance, standardization and ci/cd with docker and helm are certainly almost as important for k8s adoption as scaling your apps.",
                  "score": 5,
                  "created_utc": "2026-02-18 19:42:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o65bjx7",
              "author": "ShumpEvenwood",
              "text": "Usually the argument I hear is that we still need multiple instances for availability.",
              "score": 5,
              "created_utc": "2026-02-18 23:25:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o67rs7h",
                  "author": "Adorable-Fault-5116",
                  "text": "Sure, but then you can have two instances. You still doing need k8s.Â \n\n\nThe point I'm making is that it's generally a devx issue not a scaling one. If k8s makes sense for your business because it just makes managing what is and isn't running, deployments without downtime, etc easier, then go for it.Â \n\n\nBut most people don't need to have 500 independent nodes or whatever, just to hit scale, you just need to not write utterly terrible software.",
                  "score": 3,
                  "created_utc": "2026-02-19 09:41:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o63hl40",
          "author": "hurricaneseason",
          "text": "It's typically a goal to avoid *all* complexity when it's not necessary. So yes, avoid K8s, avoid Kafka, avoid blockchain, avoid LLMs, avoid anything that's not actually related to the low-throughput calendar/scheduling/crud app that's actually in play. Shit, maybe don't even bring a programming language into it. ",
          "score": 38,
          "created_utc": "2026-02-18 18:16:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o663yfx",
              "author": "Downtown_Isopod_9287",
              "text": "excel spreadsheet in a Google doc",
              "score": 3,
              "created_utc": "2026-02-19 02:05:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o67rv93",
                  "author": "Adorable-Fault-5116",
                  "text": "At work we call that \"grey tech\", and you wouldn't believe how much value flows through it lol",
                  "score": 1,
                  "created_utc": "2026-02-19 09:41:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o63s029",
          "author": "who_am_i_to_say_so",
          "text": "For personal, yes absolutely avoid. It is way too expensive for my tastes, although it would be a joyous system to scale up.Â \n\nShop around and youâ€™ll see. Vultr offers the cheapest, last time I checked. and itâ€™s still over a $100 a month just to start off on the right foot with it.\n\nOther peopleâ€™s money, though, sure less gooo.",
          "score": 7,
          "created_utc": "2026-02-18 19:02:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64kkb6",
          "author": "hcboi232",
          "text": "your bottleneck is usually the data layer (i.e. db) not compute. better think about that and consistency/availability issues.",
          "score": 6,
          "created_utc": "2026-02-18 21:15:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63ndcj",
          "author": "gruyere_to_go",
          "text": "I think a lot of teams over-split apps into microservices because \"best practices\", which forces Kubernetes in the picture. For many use cases, a well-structured monolith is totally sufficient.\n\nIf youâ€™re running only a few services on a system, systemd is more than enough. K8s is great, but itâ€™s not free.",
          "score": 8,
          "created_utc": "2026-02-18 18:41:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o64ksh6",
              "author": "hcboi232",
              "text": "itâ€™s really conwayâ€™s law tbh. there is no need to break the system down if 2-3 folks maintain the whole things.",
              "score": 1,
              "created_utc": "2026-02-18 21:16:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o69ylc6",
                  "author": "coltzero",
                  "text": "It doesn't depend on the number of maintainers, you can also work well with multiple people in parallel on a well structured componentized (is that a word?) monolith.",
                  "score": 1,
                  "created_utc": "2026-02-19 17:41:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o64noef",
          "author": "Comprehensive-Art207",
          "text": "I am building https://github.com/jhsware/nix-infra for this. Currently finalising a server setup for a research team. Test servers on Hetzner, production on a VMware cluster.",
          "score": 2,
          "created_utc": "2026-02-18 21:29:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o64vsu2",
          "author": "sessamekesh",
          "text": "Low scale deployments. K8s brings great things that you simply don't need for a surprisingly long time.\n\n\nK8 clusters bring a bit of cost overhead, and if I'm operating at \"low\" scale (fewer than a few dozen QPS for _sure_) I practically get the same benefits with systemd and nginx on a box or two.\n\n\nI still really like K8s and reach for it pretty often.",
          "score": 2,
          "created_utc": "2026-02-18 22:06:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o666q3c",
          "author": "hxtk3",
          "text": "Honestly no. Kubernetes is like ansible to me. Anything big enough to involve a fleet of computers (even if itâ€™s just three for N+2 high availability purposes) I probably want kubernetes.\n\nThe main reason I avoid it is in a regulated enterprise environment where it is not yet standard and would be yet another thing to get approved and I can simplify the paperwork by more than a trivial amount.\n\nIâ€™ll also avoid it if Iâ€™m building something small that can run basically for free on serverless infrastructure, or if Iâ€™m building something with loose enough availability requirements that I can run it all on a single instance.\n\nFor personal stuff I use kubernetes for literally everything and have rewritten tools to make them more kubernetes native in some cases because my main homelab project is a kubernetes cluster that basically maintains itself, but my homelab is a real hack shop that suffers badly from â€œnot invented hereâ€ syndrome.",
          "score": 2,
          "created_utc": "2026-02-19 02:22:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65z1bt",
          "author": "ducki666",
          "text": "99% of all enterprise apps don't need k8s.\nSo why then use it?",
          "score": 1,
          "created_utc": "2026-02-19 01:37:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66vts1",
          "author": "tankerdudeucsc",
          "text": "Oh heck yeah.  For low volume stuff, I make it as simple as possible with the cheapest way to run it.\n\nIt may sound crazy but I run an API server hosted in AWS Lambda via serverless framework.\n\nMake it easy, make it simple, and move on.\n\nTakes nearly zero time to hook it up.  Just make sure youâ€™ve got the right security on your AWS roles and you should be good.",
          "score": 1,
          "created_utc": "2026-02-19 04:59:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67y7im",
          "author": "TheLastofGremlins",
          "text": "Mastered is a strong word, but I've been around enough K8s clusters to have opinions. If it's a short-lived prototype or internal tool, I'll grab something lighter every time like Render, Fly, even a single VM with docker-compose. Kubernetes is fantastic at what it does. You're not just running the app, you're running the thing that runs the app.The red flag is team size. If you've got 5 engineers, spending one of them on cluster upkeep is a bad way.\n\n",
          "score": 1,
          "created_utc": "2026-02-19 10:41:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3ycmu",
      "title": "I just shipped v1.0 of EDA Visuals â€“ a free collection of visuals explaining event-driven architecture",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1r3ycmu/i_just_shipped_v10_of_eda_visuals_a_free/",
      "author": "boyneyy123",
      "created_utc": "2026-02-13 19:18:52",
      "score": 31,
      "num_comments": 5,
      "upvote_ratio": 0.94,
      "text": "Hey folks,\n\nToday I released v1.0 of EDA Visuals, a collection of over 100 visuals to help you learn about event-driven architecture.\n\n2 years ago I followed the Zettelkasten method to learn more about event-driven architecture and dive deep. I started to collect notes, references, and my own thoughts into designs, and I've been sharing them online since.\n\n  \nIf you want to learn more about event-driven architecture and dive deeper you can find them here:\n\nWebsite: [https://eda-visuals.boyney.io/](https://eda-visuals.boyney.io/)\n\nDirect download: [https://eda-visuals.boyney.io/visuals/eda-visuals.pdf](https://eda-visuals.boyney.io/visuals/eda-visuals.pdf)\n\nI enjoy creating these, and hope they help anyone else wanting to learn.\n\nCheers",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r3ycmu/i_just_shipped_v10_of_eda_visuals_a_free/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o58m8oe",
          "author": "bunsenhoneydew007",
          "text": "Just wanted to say thank you for releasing these and for giving them away for free! Iâ€™ve used them on serverlessland before but itâ€™s great to see youâ€™ve kept going with them. Thanks also for EventCatalog, itâ€™s become the hub of our documentation!",
          "score": 3,
          "created_utc": "2026-02-13 21:51:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o590c92",
              "author": "boyneyy123",
              "text": "ðŸ™Œ, that's awesome to hear. Glad you like them. Would love to hear how you are getting on with EventCatalog too, if you ever have the chance, feel free to reach out to me!",
              "score": 2,
              "created_utc": "2026-02-13 23:05:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5a0a3o",
                  "author": "bunsenhoneydew007",
                  "text": "I will do! In the meantime, briefly we're currently upgrading our use significantly (just gone from open source to a scale licence) and are looking to build it into our CI/CD pipeline for automated schema validation along with EventBridge integration. Among a bunch of other things we're thinking of.",
                  "score": 1,
                  "created_utc": "2026-02-14 02:47:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o59w92a",
          "author": "ProfessionalMajor904",
          "text": "Thank you sir for this. In my opinion, EDA is a natural way  to architect systems.",
          "score": 1,
          "created_utc": "2026-02-14 02:21:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5abxv3",
          "author": "GrogRedLub4242",
          "text": "ahhhh, the Zetelkasttensplitschema method. now thats a name I have not heard since, well, since before you were born! almost as classic as Heiny von Richtensplern's Reverse Bid Double-Flank Maneuver, or Spleeble's Sonata in D Minor.",
          "score": 1,
          "created_utc": "2026-02-14 04:06:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9f14n",
      "title": "Building an opensource Living Context Engine",
      "subreddit": "softwarearchitecture",
      "url": "https://v.redd.it/u97n00qobjkg1",
      "author": "DeathShot7777",
      "created_utc": "2026-02-19 23:27:02",
      "score": 28,
      "num_comments": 8,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tool/Product",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r9f14n/building_an_opensource_living_context_engine/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6d1xtt",
          "author": "hcboi232",
          "text": "most of those operations are deterministic right? If thatâ€™s the case, I like where this is going.",
          "score": 1,
          "created_utc": "2026-02-20 03:38:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dfz69",
              "author": "DeathShot7777",
              "text": "Yes that's the intuition here",
              "score": 1,
              "created_utc": "2026-02-20 05:19:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6dm0fh",
          "author": "vojtah",
          "text": "great idea. i always thought that codebase indexing was one of the most underrated areas in agentic coding. so many tokens spent just by analyzing code over and over. also different tasks need different interpretations of the code. good job, will give it a try.",
          "score": 1,
          "created_utc": "2026-02-20 06:09:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dmugr",
              "author": "DeathShot7777",
              "text": "Thanks. Would appreciate a brutally honest feedback",
              "score": 1,
              "created_utc": "2026-02-20 06:16:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6e2b2f",
          "author": "HeathersZen",
          "text": "Does it export the code to an external website? My boss would be unhappy if it did.\n\nIf the code stays private, how do you generate that graph image?",
          "score": 1,
          "created_utc": "2026-02-20 08:38:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6e37x3",
              "author": "DeathShot7777",
              "text": "Nope its local. The cli command is i guess obvious that it uses local compute. The webapp is zero server it runs tree sitters, embeddings model and even the DB engine locally inside the browser ( through webassembly ). \n\nIf u use the zip file drop its totally no data nothing goes out. If u use github url, the data comes through gitnexus proxy since git clone command cant be run on browser and public proxies might be risky and github api has bad ratelimit. So everything is local, code is opensource so u can audit it yourself too",
              "score": 1,
              "created_utc": "2026-02-20 08:46:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6c9eby",
          "author": "Karlo_Mlinar",
          "text": "I will definitely try this out and star it. Good shit",
          "score": 1,
          "created_utc": "2026-02-20 00:42:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6c9xne",
              "author": "DeathShot7777",
              "text": "Thanks a lot, and DAAAAM it got to 600 stars ðŸ˜­ðŸ˜­. I started it as my college project lmaoo",
              "score": 1,
              "created_utc": "2026-02-20 00:45:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r9bhqq",
      "title": "The 3 most common invisible scaling killers I saw at AWS (and how to fix them)",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1r9bhqq/the_3_most_common_invisible_scaling_killers_i_saw/",
      "author": "Busy_Weather_7064",
      "created_utc": "2026-02-19 21:09:23",
      "score": 24,
      "num_comments": 11,
      "upvote_ratio": 0.7,
      "text": "After 8 years of reviewing backend architectures at scale, I noticed the same patterns breaking systems over and over. They aren't usually \"bad code\" : they are \"bad architecture decisions.\"\n\n1. **Ignoring Idempotency:**Â Assuming a network call happens exactly once. (It doesn't).\n   * *Fix:*Â Always design assuming the clientÂ *will*Â retry. Use idempotency keys on every mutating request.\n2. **The Distributed Monolith:**Â Breaking a monolith into microservices but requiring synchronous HTTP calls between them for every request.\n   * *Fix:*Â Move to event-driven architectures (SNS/SQS) for anything that doesn't need an immediate response. Decouple your services.\n3. **Database as a Queue:**Â Polling your primary SQL database for \"jobs to do.\"\n   * *Fix:*Â Redis or SQS. Your primary DB is for state, not for workflow management.\n\n**Iâ€™m looking to do a few deep-dive architecture reviews this week for teams facing these kinds of issues.**\n\nIf you are currently designing a complex feature or suspect you have one of these bottlenecks,Â **DM me or comment below.**Â Iâ€™m happy to look at your high-level design doc or diagram and give you a structured review of where it might break.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r9bhqq/the_3_most_common_invisible_scaling_killers_i_saw/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o6bajsa",
          "author": "FuckYourFavoriteSub",
          "text": "I donâ€™t know why.. but I feel like this is trying to sell something at the end of the day. \n\nLike, â€œDM me, Iâ€™d love to look over your docs and look for where the thing Iâ€™m trying to sell can absolutely be sold to you.â€ \n\nMaybe you are, maybe you arenâ€™t. But I feel a grift coming at the end of that review lol.",
          "score": 36,
          "created_utc": "2026-02-19 21:30:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6bek0a",
              "author": "IlliterateJedi",
              "text": ">They aren't usually \"bad code\" : they are \"bad architecture decisions.\"\n\nIt's probably because it reads like an AI post where someone find and replaced the em dashes with colons.",
              "score": 13,
              "created_utc": "2026-02-19 21:50:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6bbdfa",
              "author": "Busy_Weather_7064",
              "text": "Lol ðŸ˜‚. I don't know what people believe and what not anymore in this era. Well sometimes enthusiastic folks love to talk about things they're passionate about :) ",
              "score": -8,
              "created_utc": "2026-02-19 21:34:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6bca7w",
                  "author": "FuckYourFavoriteSub",
                  "text": "Nice then man. Just saying I distrust everything so donâ€™t take it too personal.",
                  "score": 3,
                  "created_utc": "2026-02-19 21:39:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6bcibj",
          "author": "Effective-Total-2312",
          "text": "I have a very big problem with calling \"synchronous HTTP calls\" to a \"blocking HTTP call\". Those are two different things. Also, there is nothing wrong with having non-blocking asynchronous HTTP requests; communication is easy, simple, unilateral.\n\nEvent-driven, on the other hand, is an illusion of decoupling. Not everything needs to be \"lightly coupled\". Specially important communications. If I need to talk to you, I don't want a middle man. It wouldn't decouple us, just hide away the communication errors.\n\nThe same happens in software, unless you have very specific constraints like requiring multiple services listening to the same event, or something else. If your response will take too much time, there are lots of other patterns to use.",
          "score": 20,
          "created_utc": "2026-02-19 21:40:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6cubge",
              "author": "sharpcoder29",
              "text": "He means making an http request to another service and waiting for a response. Just using async doesn't get around the issues it creates.\n\nTypically this is the first thing I see when inexperienced engineers start doing \"microservices\". They don't truly understand domain boundaries or tight vs loose coupling",
              "score": 4,
              "created_utc": "2026-02-20 02:50:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6bo4yb",
          "author": "TheMightyTywin",
          "text": "1. Does *everything* have to have an idempotency id? Like, adding an item to user favorites? \n\n3. Iâ€™m using SQS + Lambda for jobs. But putting the work id itself into the primary db. I had considered redis but since Iâ€™m using aurora postgres v2 I was thinking that it was basically the same scaling wise. Bad idea?",
          "score": 3,
          "created_utc": "2026-02-19 22:40:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6btxhv",
              "author": "BillBumface",
              "text": "I think idempotency can be achieved multiple ways. Things like \"Add $5 to the user's balance\" absolutely benefit from an idempotency key. Your example is a great one though, the call to add an item to favourites doesn't need this. Deduplication can be handled within the system owning the favourites.",
              "score": 6,
              "created_utc": "2026-02-19 23:12:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6c4nh8",
              "author": "Far_Office3680",
              "text": "If your request is idempotent then it doesn't need a dedicated idempotency key. It's okay to retry it and even process the same  request multiple times.",
              "score": 5,
              "created_utc": "2026-02-20 00:14:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6csi8w",
              "author": "LordWecker",
              "text": "I'd revise #1 to: Everything should be able to gracefully handle repeated attempts.\n\nFor the same reason OP excluded reads (repeated attempts don't have side effects), if \"adding an item to a users favorites\" uses get_or_create logic and unique constraints to prevent duplicates: repeated attempts are \"safe\".",
              "score": 3,
              "created_utc": "2026-02-20 02:39:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6cxxjs",
          "author": "snarkformiles",
          "text": "ðŸ‘ðŸ‘ðŸ‘",
          "score": 1,
          "created_utc": "2026-02-20 03:12:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7czgt",
      "title": "The Interest Rate on Your Codebase: A Financial Framework for Technical Debt",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1r7czgt/the_interest_rate_on_your_codebase_a_financial/",
      "author": "misterchiply",
      "created_utc": "2026-02-17 17:42:46",
      "score": 23,
      "num_comments": 14,
      "upvote_ratio": 0.87,
      "text": "[https://www.chiply.dev/post-technical-debt](https://www.chiply.dev/post-technical-debt)\n\nhttps://preview.redd.it/j6daylwnd3kg1.jpg?width=3438&format=pjpg&auto=webp&s=1337fe3a15ba89130a238a79aa6036c7490b749f\n\n",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r7czgt/the_interest_rate_on_your_codebase_a_financial/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o5x1n4j",
          "author": "FRELNCER",
          "text": "Formatting is way too chaotic for me to take the time to parse without some proof it will benefit me. Can you give me a tl;dr summary to better determine if I should bother? ",
          "score": 8,
          "created_utc": "2026-02-17 19:23:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5x98pe",
              "author": "misterchiply",
              "text": "And there is a TLDR built into the document.  This links to internal sections so you can jump to specific parts of the post if only those details matter to you!\n\nhttps://preview.redd.it/gwkgt5gr14kg1.png?width=2828&format=png&auto=webp&s=78cc26944a2506f4db43ba4bcbb07dc92159a36f\n\n",
              "score": 6,
              "created_utc": "2026-02-17 19:59:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5xu7fk",
                  "author": "asdfdelta",
                  "text": "On mobile it looks great, btw.",
                  "score": 2,
                  "created_utc": "2026-02-17 21:38:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5x8xho",
              "author": "misterchiply",
              "text": "you can toggle off all the sidebar components with this button at the top.  Maybe some other part of the format is chaotic, is that the case?  I can fix if so! \n\nhttps://preview.redd.it/8l61nc6l14kg1.png?width=2828&format=png&auto=webp&s=a96ea1e9f4b9d94ed2bc334ca34d4f901f18645c",
              "score": 3,
              "created_utc": "2026-02-17 19:58:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o60u4nf",
          "author": "imihnevich",
          "text": "For those like me: you can click \"Hide all panels\" and it becomes readable. \n\nThe text itself is great, I like it. I maybe disagree with LOC/Complexity and similar being useless. I like the concept of hotspots, which is a combination of complexity of the module and the frequency of change (you need both to be high for a module being a hotspot). I found it useful in my work. I do agree that complexity itself is not enough to refactor",
          "score": 2,
          "created_utc": "2026-02-18 09:02:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60x4y3",
              "author": "misterchiply",
              "text": "Thank you for this insight!  I might update the article to soften the language around lines of code and complexity, because your comments have me thinking about whether these could be useful signals, maybe not as strong as others, that tech debt exists.  It makes me think about both the human and AI problems where there could be inexperienced devs or sloppy LLMs writing code that is confusing to read and therefore difficult to maintain/change.\n\nI just took a look at \"charlie\", the tech debt analysis tool you published, and it's awesome.  I feel like you have really put into practice what so many organizations are afraid to, which is to mine for and expose tech debt.  The coupled pairs feature is particularly exciting as I considered writing a section on coupling, but couldn't precipitate a good a idea on what that implementation would look like.  The viz you chose for that is perfect, I really appreciate that!\n\nWould you mind if I link to your tool in a section of my blog, of course giving you attribution as an author?  I do a lot of soap-boxing in my article, but I don't have a lot of material recommendations on tools to use that implement my advice.  I think \"charlie\" would be a great call out in my blog.  If so, let me know the best way to link to your project, whether it's the reddit post, the github, the npm package, or something else.\n\nFunnily enough, my name is Charlie lol, so this was a bit of a [Baaderâ€“Meinhof phenomenon](https://en.wikipedia.org/wiki/Frequency_illusion) for multiple reasons.",
              "score": 1,
              "created_utc": "2026-02-18 09:31:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o61a4i1",
                  "author": "imihnevich",
                  "text": "Those ideas aren't mine; I took them from the book Your Code as a Crime Scene, which I highly recommend. The author of that book has a way more developed tool called CodeScene, which I think is better for larger companies than my little project. I built mine as a quick thing to run locally and do a little check, and I'm really, really glad if you enjoy it. I would really appreciate it if you mentioned it. Still, I also think it's worth mentioning the book, because gathering metrics is just half the job; making an educated decision on what to do next is another crucial part.\n\nIt's funny, I came up with a name because of a TV show called Numb3rs, where the main character, named Charlie, uses math to solve crimes :-)",
                  "score": 2,
                  "created_utc": "2026-02-18 11:25:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o61cqzw",
          "author": "D-cyde",
          "text": "I was reading on r/programming and found it to be removed. As someone who is beginning a position with more responsibility, agency and having to interact with non-technical stakeholders, I appreciate the detailed breakdown of technical debt into financial terms that can easily understood by others.",
          "score": 2,
          "created_utc": "2026-02-18 11:45:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r559xu",
      "title": "Where fintech security architectures break [risks, blast radius, structural controls]",
      "subreddit": "softwarearchitecture",
      "url": "https://www.cerbos.dev/blog/fintech-security-architectures-where-they-break-and-why",
      "author": "West-Chard-1474",
      "created_utc": "2026-02-15 04:24:12",
      "score": 20,
      "num_comments": 2,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r559xu/where_fintech_security_architectures_break_risks/",
      "domain": "cerbos.dev",
      "is_self": false,
      "comments": [
        {
          "id": "o5h34qv",
          "author": "WorksOnMySystem",
          "text": "â€œCredentials should be short-lived and tightly scoped. Use expiring tokens and rotate signing keys on a defined schedule so that exposed credentials cannot be reused indefinitely. â€œ \n\nThis is so true , I was part of the support team on a Fintech Product. \n\nOne of our tasks was to generate API keys for Merchant APIs for 3rd Party Integrations. We used provide a Refresh API endpoint along with it. \n\nI was once going though WSO2 API usage dashboard , I noticed that Refresh APIs usage was way too low. \n\nUpon asking my colleagues , I got to know that they were handing out API keys with default expiry ( Those who are unfamiliar with WSO2 , the default expiry is basically  infinity ) . \n\nI reviewed the handover document that development team provided , I found no mention of setting a custom expiry before creating an API key. The support guys just followed the document by heart.\n\nLuckily this is practiced was stoped after that and no security lapse happened.",
          "score": 3,
          "created_utc": "2026-02-15 07:46:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60jxq8",
          "author": "KarinaOpelan",
          "text": "This is how fintech risk creeps in, not through one dramatic flaw but through defaults no one questions. An â€œinfiniteâ€ API key turns any leak into a long-term foothold, and if scopes are broad or services arenâ€™t isolated, the blast radius grows fast. The real fix isnâ€™t just shorter expiries, itâ€™s structural containment: tightly scoped tokens, strict service boundaries, enforced rotation policies, and monitoring that catches abnormal patterns. Most fintech breaches come from weak controls and ownership gaps, not broken crypto.",
          "score": 2,
          "created_utc": "2026-02-18 07:28:08",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r5hyox",
      "title": "Help in deciding on architecture in fintech.",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1r5hyox/help_in_deciding_on_architecture_in_fintech/",
      "author": "No-Dimension-5661",
      "created_utc": "2026-02-15 15:52:36",
      "score": 20,
      "num_comments": 31,
      "upvote_ratio": 0.86,
      "text": "Hi everyone.\n\nWe work at a fintech company and we need to reduce costs associated with closed customer invoices stored in an RDS database in a table.\n\nWe need to purge the immutable, read-only data from this table into cold storage, leaving only the mutable data in RDS.\n\nHowever, the REST API needs to query both the cold and hot data. The cold data has a smaller volume than the hot data.\n\nThe initial architectural idea was to copy the cold data to S3 in JSON format using AWS Glue. However, I'm not sure if it's ideal for an API to read JSONs directly from S3.\n\nWhat do you think? Perhaps using an analytical database for the cold data? The idea is that the storage supports a volume load about 20% lower than the hot storage, and that this percentage will gradually decrease over time.\n\nThank you.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r5hyox/help_in_deciding_on_architecture_in_fintech/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o5iwd34",
          "author": "flavius-as",
          "text": "I think you should evaluate closer:\n\n* why exactly the data needs to be purged\n* what data needs to still be read and why: which data fields and the relationship between them\n\nAnd by \"why\" I mean the complete list of use cases.\n\nVery often these answers offer a better solution.",
          "score": 13,
          "created_utc": "2026-02-15 15:56:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5iyxa1",
              "author": "No-Dimension-5661",
              "text": "The data needs to be moved and disconnected from RDS (PostgreSQL) to reduce database storage costs while improving performance.\n\n\nSince this is immutable historical data, the company wants to move it to cold storage.\n\n\nThe hot data will remain in RDS. Hot data consists of open invoices that can be updated and are frequently consulted. After 1 month, this hot data becomes cold, as it becomes an immutable closed invoice.",
              "score": 0,
              "created_utc": "2026-02-15 16:09:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5j14r8",
                  "author": "flavius-as",
                  "text": "You skipped the use cases with \"reading the cold data\" which is key.",
                  "score": 7,
                  "created_utc": "2026-02-15 16:19:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5ug9et",
                  "author": "confusing-world",
                  "text": "How many invoice rows do you have in your database to make this change? I think this is only something to consider when we have billions of rows.",
                  "score": 1,
                  "created_utc": "2026-02-17 10:51:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5jahce",
          "author": "never-starting-over",
          "text": "This is an interesting and seemingly a real-world problem. I wonder why you're getting downvoted.\n\nAnyway, have you considered caching the cold data? It seems to fit the bill:\n\n1. The data is immutable\n2. The data is not retrieved that often\n3. The data wants to be stored in a place that's cost-efficient for low volume on reads\n\nBesides this, I'd consider AWS S3 with IA or Glacier, depending on how fast you need the data (consider adding this and data size to your question, by the way). If you don't need the data fast it could be alright. You could query with AWS Athena.\n\nIf you need the cold data for analytics, it could be an option to also create snapshots of the calculated data as an aggregate for a period, using the lowest required period. So, for example, if you only need granularity down to a day then you could have that calculation for the day stored and use that for the calculations rather than every single invoice. Think of like caching AWS Athena results.\n\nUltimately, you'll probably end up having to calculate how much each of these will cost you.",
          "score": 5,
          "created_utc": "2026-02-15 17:04:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ixhds",
          "author": "mikepun-locol",
          "text": "Our data team decided to use duckDB against delta lake tables in S3. There are several variations around duckDB and s3, like Iceberg instead, depending on the rest of your stack.\n\nCould be something worth looking at.",
          "score": 3,
          "created_utc": "2026-02-15 16:02:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5j0j2c",
              "author": "No-Dimension-5661",
              "text": "Since DuckDB is an OLAP solution, will it support a high TPS (Transactions Per Second)? I'm thinking about indexing, if it's efficient. Does your solution store JSON files in S3 that are injected into DuckDB, or some other type of file? Is your REST API in Java Spring Boot?",
              "score": 1,
              "created_utc": "2026-02-15 16:17:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5jvdle",
                  "author": "MVanderloo",
                  "text": "if the data is immutable then you shouldnâ€™t need transactions",
                  "score": 7,
                  "created_utc": "2026-02-15 18:46:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5j3a4p",
                  "author": "mikepun-locol",
                  "text": "Candidly there is not much transactional stuff in the data team's work. So don't know. However they were Parquet rather than JSON files. Interface was SQL with python.\n\nEdited: responded too fast. Corrected.",
                  "score": 1,
                  "created_utc": "2026-02-15 16:30:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5j56tv",
                  "author": "BarfingOnMyFace",
                  "text": "Whatâ€™s the volume and throughput you are dealing with?",
                  "score": 1,
                  "created_utc": "2026-02-15 16:39:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5j8x20",
          "author": "catcherfox7",
          "text": "Have you considered AWS Athena?",
          "score": 4,
          "created_utc": "2026-02-15 16:57:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5k0sbl",
              "author": "No-Dimension-5661",
              "text": "Iâ€™ve considered using it, but the main concern is that AWS Athena is an analytical database, and Iâ€™m not sure whether it would be suitable to use alongside a REST API that receives 3,500 requests per second on a daily basis.\n\nIâ€™d like to know whether there is any real-world use case of AWS Athena being used together with a REST API at that level of volume. Do you know of any?",
              "score": 1,
              "created_utc": "2026-02-15 19:13:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5k53qt",
                  "author": "catcherfox7",
                  "text": "Define suitable, because athena is stateless and data is kept S3 - so it works. It is about money, performance requirements and deep knowledge about the data access patterns.\n\nThe way that I see the problem that you are facing is cost optimization - not necessarily an architectural one\n\nYou really need to understand how much the current set up costs , and by how much the any of the proposed solutions that you are evaluating will be able to cut that down.\n\nIf you are not able to do any napkin math to get a sense of it, the best solution is to put both solutions side by side or gradual rollout to compare.\n\nEdit: typos",
                  "score": 1,
                  "created_utc": "2026-02-15 19:34:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5kvc2e",
          "author": "paca-vaca",
          "text": "Data access rate between hot data 6000/rps and cold data 3500/rps not that a much of difference to change the access pattern and to maintain two access engines merged my API. What if the API query accesses both hot and cold records or you do need filtering or aggregation on top of two datasets?\n\nBut as it is more a cost optimization problem, accessing from S3 should be fine as soon as you partition your data. S3 supports up to 5500/rps  reads per partition, so for your current estimated rate it will handle even if everything is under one user.\n\nThat will be cheap. But if you need more than simple retrieval AND high throughout AND filtering I would move both types of invoices into a document database.",
          "score": 3,
          "created_utc": "2026-02-15 21:48:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5k2lpf",
          "author": "PmMeCuteDogsThanks",
          "text": "Keep the current design, go on prem instead.Â ",
          "score": 2,
          "created_utc": "2026-02-15 19:22:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5jk569",
          "author": "tehdlp",
          "text": "When you say query old and new, are you referring to just listing full content or filtering too?\n\n\nOr is it a minimal list (i.e. identifiers only) and full record content only by single record request?",
          "score": 1,
          "created_utc": "2026-02-15 17:52:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jyiia",
              "author": "No-Dimension-5661",
              "text": "For now, it only lists the full content, since the API does not support filters. In the future, we will have filters, but at the moment the solution focuses on an API without filtering capabilities.\n\nThe API retrieves data from two tables:  \n1 â€“ the invoice headers table;  \n2 â€“ the invoice header transactions table.\n\nThe API response is a JSON containing the header plus its transactions.\n\nThe query logic is quite simple: a straightforward `SELECT` with a `WHERE` clause filtering by due date and account to retrieve the header. With the header ID found, it then retrieves the transactions associated with that header, which consists of another simple `SELECT`.\n\nWhen an invoice closes (after one month), those header and transaction records become immutable in these tables. The idea, then, is to remove them from PostgreSQL and move them to cold storage, because over time these closed invoice records are queried less and less in the database. Someone would only query an invoice from 2018 if they really wanted to check what they purchased in that specific month/year. Queries will be higher for current invoices and recently closed ones, and will decrease as time goes by.\n\nThe number of requests for a recently closed invoice can reach around 3,500 req/s, and then gradually decrease over time to 3,000, 1,000, 500, 100 req/s. Hot data, on the other hand, can reach 5,000â€“6,000 req/s, which is supported by RDS with proper indexing in PostgreSQL.",
              "score": 1,
              "created_utc": "2026-02-15 19:01:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5k0ryy",
          "author": "Glove_Witty",
          "text": "Do you have partitions and partition keys in your data? That will make managing the different db engines. Write the data to S3 in iceberg format and query with Athena.",
          "score": 1,
          "created_utc": "2026-02-15 19:13:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5k2g0n",
              "author": "No-Dimension-5661",
              "text": "I do have partition keys. In fact, I already have AWS Glue jobs that extract this data to S3 in JSON format.\n\nThe main question is whether Athena, being an analytical database, will be able to handle the API load of 3,500 req/s. Do you think Athena is suitable for high-scale, single-record lookups?",
              "score": 1,
              "created_utc": "2026-02-15 19:21:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5k3mre",
                  "author": "Glove_Witty",
                  "text": "Lookups will be per partition. I used Athena on top of S3/parquet for telemetry data a while back and have forgotten the metrics. You should be able to find the info from Amazon.",
                  "score": 1,
                  "created_utc": "2026-02-15 19:27:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5l6fvu",
          "author": "java_dev_throwaway",
          "text": "Lots of options here. You could implement a partitioning strategy within RDS to try and keep the hot and cold data partitioned by date. You could keep a table for cold data. You could just store the customer id and object idfor s3 to postgres or use dynamodb. S3 and Athena would also work.\n\nOne thing you should ask is if you could do webhooks or some kind of async event/response for API calls that need the cold data. If you have some wiggle room there, then any option could work.\n\nDefinitely get more concrete requirements and use cases ironed out. Don't let a PM just nonstop throw terms like real-time out there and bake in some constraint. Frequently these kinds of historical or look back queries don't need sub 40ms response, so don't box yourself in. The API needing to query both hot and cold data doesn't mean the acceptable latency needs to be the same for both hot data only lookups vs both.",
          "score": 1,
          "created_utc": "2026-02-15 22:48:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5lkdqm",
          "author": "PaulPhxAz",
          "text": "I would probably get a super cheap VPS, install Postgres on it, migrate your \"cold\" data.  Maybe you'll spend 20$ a month on this.  Just be aware of the limitations, and make an occasional backup of it.\n\nAnd you can query it the same way you always have, change your connection string and it should be there.",
          "score": 1,
          "created_utc": "2026-02-16 00:09:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5m1xse",
          "author": "True_Context_6852",
          "text": "S3 is a good storage option; however, you would still need an additional tool or service to efficiently query and retrieve data from S3. Based on my understanding, a better solution would be to use DynamoDB with receipt\\_id as the partition key and implement appropriate Global Secondary Indexes  to support flexible and efficient search patterns. This approach would also allow you to leverage DDB Streams to move data to S3 if needed, and use TTL to automatically records when the data is no longer required by your team",
          "score": 1,
          "created_utc": "2026-02-16 01:57:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uw482",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-17 12:53:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ydfdv",
              "author": "No-Dimension-5661",
              "text": "But Athena is analytical and, as far as I know, doesn't perform well with REST APIs and requests around 3500 requests/second. Analytical databases are good for BI reports, but not as a backend API solution. What do you think?",
              "score": 1,
              "created_utc": "2026-02-17 23:15:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o60kf87",
          "author": "KarinaOpelan",
          "text": "Athena is the wrong tool if your main workload is 3,500 rps point lookups with low latency. Itâ€™s built for scan-heavy analytics, not high-QPS transactional reads. Reading JSON directly from S3 will also hurt once joins and schema evolution show up. If you need the API to behave exactly the same, the safest path is Postgres partitioning by close date and detaching old partitions to cheaper storage, or moving cold data to a separate low-cost Postgres archive with the same schema. DynamoDB could work, but that forces a data model redesign. For this access pattern, stick to a query-optimized store, not Athena.",
          "score": 1,
          "created_utc": "2026-02-18 07:32:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8619b",
      "title": "How do you give coding agents Infrastructure knowledge?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1r8619b/how_do_you_give_coding_agents_infrastructure/",
      "author": "Immediate-Landscape1",
      "created_utc": "2026-02-18 15:30:09",
      "score": 20,
      "num_comments": 26,
      "upvote_ratio": 0.81,
      "text": "I recently started working with Claude Code at the company I work at.\n\nIt really does a great job about 85% of the time.\n\nBut I feel that every time I need to do something that is a bit more than just â€œwriting codeâ€ - something that requires broader organizational / infra knowledge (I work at a very large company) - it just misses, or makes things up.\n\nI tried writing different tools and using various open-source MCP solutions and others, but nothing really gives it real organizational (infrastructure, design, etc.) context.\n\nIs there anyone here who works with agents and has solutions for this issue?",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r8619b/how_do_you_give_coding_agents_infrastructure/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o62lpuh",
          "author": "Sixstringsickness",
          "text": "Use Claude to generate a mermaid diagram of your complete system/infra (.mmd) files. Claude is usually very good at this.  If you use a JetBrains IDE they have a .mmd plugin, however; it isn't the best.  Once it is generated you can import it here [https://www.mermaid.ai/](https://www.mermaid.ai/) or [https://miro.com/](https://miro.com/) for easier viewing of large sized diagrams. I would suggest when generating it, use a broader approach for the primary file (high level concepts), and then build out more detailed individual documents for each specific subset.  Mermaid diagrams can start to get a bit wacky as they grow. \n\nOnce you have mapped out the infrastructure you can save it to your repo and then add it as a reference claude must review at the start of each session in your claude.md.  I would also suggest writing instructions to update the diagram whenever any significant changes are made.\n\nI personally haven't needed to add it to the [claude.md](http://claude.md) yet, however; in a few scenarios I have pointed it at the .mmd file.  I mostly work in agentic space so the relationships aren't bonkers just yet.",
          "score": 13,
          "created_utc": "2026-02-18 15:53:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62onjz",
              "author": "Bonejob",
              "text": "I just use visual studio code with the Markdown Preview Github Styling by Matt Bierner. You can then display mermaid and edit right in the editor. As far as Architecture goes, I prefer OpenAI 5.2 over Claude.\n\nI have a \"personality\" with the Clean Code Synopsis in it. OpenAI 5.2  prepares decent diagrams when you describe the intent of the system.",
              "score": 6,
              "created_utc": "2026-02-18 16:06:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o62qnat",
                  "author": "Immediate-Landscape1",
                  "text": "For example, I had an issue a few weeks ago, where I tried to deploy code (Which claude approved) into production,  \nbut because of misconfigured security group, everything failed  \nare you actually mapping SG and infra-related entities in your mermaid diagrams? and how do you actually keep them updated?",
                  "score": 1,
                  "created_utc": "2026-02-18 16:16:01",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o62tt2k",
                  "author": "Sixstringsickness",
                  "text": "I have steered away from VS code and 3rd party plugins, to each their own but aiming to stick to 1st party solutions.  Not that I'm insinuating Matt Bierner has security issues, simply me being a bit paranoid and JetBrains offers a 1st party solution.  Unfortunately it doesn't sound as robust! \n\n[https://www.bleepingcomputer.com/news/security/malicious-vscode-extensions-with-millions-of-installs-discovered/](https://www.bleepingcomputer.com/news/security/malicious-vscode-extensions-with-millions-of-installs-discovered/)",
                  "score": 1,
                  "created_utc": "2026-02-18 16:30:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o62ml25",
              "author": "Sixstringsickness",
              "text": "To compliment this, ensure you have copious amounts of documentation - you can also point to a docs folder that claude can look at if it needs the reference.  If you want to get fancy, I have also setup an MCP server with a vector db for semantic search.  Currently I use it only for external reference and documentation, can't put company info on it, however; if need be I could see that being useful.  Vectorize all documentation for each repo in the company so Claude can rapidly search and iterate on concepts. ",
              "score": 1,
              "created_utc": "2026-02-18 15:57:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o62ocat",
                  "author": "Immediate-Landscape1",
                  "text": "Good idea, you have any example for that? or any open-source tool for doing such a task?",
                  "score": 1,
                  "created_utc": "2026-02-18 16:05:34",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o65dxdi",
          "author": "snuggl",
          "text": "We are using an IDP (I.e Port.io) which has an MCP that agent use to find out about infra and api schemas etc",
          "score": 1,
          "created_utc": "2026-02-18 23:38:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69015a",
          "author": "ryan_the_dev",
          "text": "Look at creating custom skills. This is the way.",
          "score": 1,
          "created_utc": "2026-02-19 14:52:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o69hlsk",
              "author": "Immediate-Landscape1",
              "text": "u/ryan_the_dev when you say custom skills, do you mean wrapping internal infra APIs so the agent can query them?",
              "score": 1,
              "created_utc": "2026-02-19 16:19:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o69i9rv",
                  "author": "ryan_the_dev",
                  "text": "Check this out  \n[https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview)\n\n  \nI handle some cloud stuff. So here would be some azure skills I might have to enable my claude to be more successful. You of course can use these as an idea, and build the skill tailored to your companies infra.\n\nhttps://preview.redd.it/oup3nkds8hkg1.jpeg?width=1110&format=pjpg&auto=webp&s=c60754c5517e27a9638038c5cf4d1d0e269da02e\n\n",
                  "score": 1,
                  "created_utc": "2026-02-19 16:22:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o698y1v",
          "author": "jippiex2k",
          "text": "You need to have an Infrastructure as Code environment. Once that is in place, it becomes trivial to have your gitops and ci/cd configuration as part of the coding agent context.\n\nIf such modern best practices regarding devops isn't implemented yet, you will first need to solve that on an organizational level. As it then is not merely a technical issue anymore.",
          "score": 1,
          "created_utc": "2026-02-19 15:37:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6b9n1v",
          "author": "disciplemarc",
          "text": "What youâ€™re describing isnâ€™t really a model problem, itâ€™s a context problem.\n\nAt large companies, infra knowledge lives in ADRs, CI config, Terraform modules, ownership boundaries, platform rules, etc. If that isnâ€™t encoded in a way the agent can retrieve, it will confidently guess.\n\nWhatâ€™s worked better for me is treating architecture as policy and validating at PR time instead of expecting the agent to internalize organizational memory.\n\nIâ€™ve been experimenting with this via a side project called ArchRails, the core idea is enforcing declared architectural intent rather than inferring it.\n\nCurious: do you have your infra/architecture decisions encoded anywhere machine-readable, or mostly in docs?",
          "score": 1,
          "created_utc": "2026-02-19 21:26:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63fp3c",
          "author": "v693",
          "text": "Yes. Iâ€™m actually building a beta version for launch. Filed provisional patents a month ago. I should launch in about 6-8 weeks. If i remember, I ll come give you the link.",
          "score": -6,
          "created_utc": "2026-02-18 18:08:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o69hy5v",
              "author": "Immediate-Landscape1",
              "text": "u/v693 Thatâ€™s interesting.\n\nCurious what angle youâ€™re taking! more around giving agents infra visibility, or more around impact analysis / constraint awareness?\n\nWould definitely be interested to see what youâ€™re building when itâ€™s live.",
              "score": 1,
              "created_utc": "2026-02-19 16:21:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o69j1kv",
                  "author": "v693",
                  "text": "Interesting that I got downvoted. When did Reddit become like this. \n\nItâ€™s a new way to store information as memory not data. A layer above it that acts a control plane.",
                  "score": 1,
                  "created_utc": "2026-02-19 16:26:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r6rzi1",
      "title": "How should you design a multi tenant system?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1r6rzi1/how_should_you_design_a_multi_tenant_system/",
      "author": "rudrakshyabarman",
      "created_utc": "2026-02-17 01:08:26",
      "score": 19,
      "num_comments": 36,
      "upvote_ratio": 0.95,
      "text": "I wonder how you guys are designing a multi-tenant system? I mean a same codebase (e.g FastAPI) and maintain multiple B2B enterprises. What you feel safe and easy to handle if using PostgreSQL? RLS (Row level security) or Schema per tenant?  \nSchema per tenant seems more isolated but wonder if scale when 100+ enterprise crossed. RLS seems scalable, but wonder whether it can accidentally reveals other's data.  \nNeed you suggestion.\n\nEdit: This is about Healthcare Management Software (Hospitals, LABs etc). Some large corporate Hospitals has huge data and some small lab has low volume data.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r6rzi1/how_should_you_design_a_multi_tenant_system/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o5so61q",
          "author": "Isogash",
          "text": "It really depends on the expected size and quantity of your tenants and what you can bill for.\n\nIf you're doing heavy data processing and most of your clients need a chunky DB that they would need to pay for anyway, then you should have a db instance per deployment and charge for it, or license it to run on their own DB instance.\n\nIf you want to have lots of small clients that might not use that many rows each, then RLS is worth pursuing.",
          "score": 16,
          "created_utc": "2026-02-17 02:19:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5t02gn",
              "author": "rudrakshyabarman",
              "text": "What if I use same database but different schema in PG?",
              "score": 3,
              "created_utc": "2026-02-17 03:33:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5u52oq",
                  "author": "Humble-Persimmon2471",
                  "text": "Depends on how many tenants. If you're expecting thoudands of tenants then also think how you'll keep those schemas in sync when it needs to change.",
                  "score": 5,
                  "created_utc": "2026-02-17 09:07:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5sizy9",
          "author": "Ok_Swordfish_7676",
          "text": "multi tenant usually shares the same infra ( including code base and db) unless one tenant want full isolation\n\nin terms of db design, u should have field tenant_id to do the isolation in your main table  since its shared infra",
          "score": 11,
          "created_utc": "2026-02-17 01:48:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5thjhg",
              "author": "Worldly_Expression43",
              "text": "This is what I do too",
              "score": 5,
              "created_utc": "2026-02-17 05:36:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5shoxv",
          "author": "zenware",
          "text": "For the record if you have 100+ enterprise customers, you should have enough cashflow to solve the scalability issues of Schema/tenant if any such issues ever do present themselves.",
          "score": 10,
          "created_utc": "2026-02-17 01:40:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5szmqo",
              "author": "rudrakshyabarman",
              "text": "What do you mean enough cashflow? Do you mean that I an increase the resources e.g. CPU, MEMORY (RAM)? It is not about only scaling, it is about to use the right architecture in my use cases.",
              "score": -6,
              "created_utc": "2026-02-17 03:30:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5txw2v",
                  "author": "OkTrade8132",
                  "text": "more like cash to pay your opex",
                  "score": 10,
                  "created_utc": "2026-02-17 07:58:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o608d4j",
                  "author": "zenware",
                  "text": "If you arenâ€™t doing original research on theoretical designs for multi-tenant systemsâ€¦ then your architecture exists in the context of a business which has financial incentives. The prime directive of which is essentially â€œearn profitâ€, if hemming and hawing on this gets in the way of profit today just to gain a little efficiency next year, you have made an egregious architectural blunder â€” failing both your organization and your team. So, the correct answer is â€œpick what gets you paying customers the fastestâ€, and then migrate to a new solution later, by using that money to fund the change.\n\nAnd if you never cross 100+ enterprise tenants, then you never need to migrate to a new solution, so the theoretically optimal architecture never mattered.\n\nIt is also a mistake not to think to the future, but it really sounds like youâ€™re at a stage where you canâ€™t afford to spend the time on this level of minutia.",
                  "score": 1,
                  "created_utc": "2026-02-18 05:49:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5slgdu",
          "author": "Acrobatic-Ice-5877",
          "text": "Use a tenant_id field for each entity that is tenant based and do E2E testing for each scenario where data leakage can occur. If you do database seeding itâ€™s a real fast process. I have a Spring Boot project that runs several dozen automated E2E tests and itÂ seeds the database for each test. Itâ€™s a lot of work to get it going but once itâ€™s going it works real well in the long run.",
          "score": 7,
          "created_utc": "2026-02-17 02:03:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tn2mv",
              "author": "Mobsuke106v2",
              "text": "Hey I would like to know more about testing a multi tenant architecture project, so we shoud have a seperate db just for testing right? what I am doing right now for e2e testing is testing two tenants in the test db, and dont really have much test cases, some tenant-routing test cases, and some test cases for the  checkout-flow. \n\nOfc I am doing unit testing and integration tests as well, but kind of confused on how to do  e2e testing for a multi tenant architecture. ",
              "score": 2,
              "created_utc": "2026-02-17 06:21:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5upytm",
                  "author": "Acrobatic-Ice-5877",
                  "text": "You definitely do not want to run tests on your prod db, so yes you want two.\n\nThe tests donâ€™t need to be complicated. You can generate two tenants, pick a table, and add three rows.Â \n\nTwo rows go to tenant 1 and 1 row for tenant 2. Try to access row 2 that belongs to tenant 1 with tenant 2.Â \n\nYou could then assert something like, my URL is now pointing to /401 because that resource doesnâ€™t exist.",
                  "score": 1,
                  "created_utc": "2026-02-17 12:10:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5u59sq",
              "author": "Humble-Persimmon2471",
              "text": "I would not spend time on e2e in that way to test for leakage. You can use RLS for that at least in postgres. Then you primarily need to check that it's implemented correctly",
              "score": 2,
              "created_utc": "2026-02-17 09:09:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5uqnaq",
                  "author": "Acrobatic-Ice-5877",
                  "text": "Partly agree. Trust RLS but verify with E2E. Theyâ€™re fast and easy to make if you make a seed factory and are experienced with writing tests.\n\nBroken access control isÂ one of the top security flaws in applications and all it takes is a properly scoped test on a regular basis.Â ",
                  "score": 1,
                  "created_utc": "2026-02-17 12:15:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5sg8f9",
          "author": "Careless-Cloud2009",
          "text": "Database per tenant",
          "score": 7,
          "created_utc": "2026-02-17 01:32:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5slze5",
          "author": "secretBuffetHero",
          "text": "depends a great deal on the size of the company you are working at. \n\nif it is a startup, I think RLS is adequate security. it's not perfectly separated, but true separation comes at a cost.\n\nIf you have the money, then multiple databases can make sense, but this comes at the cost of maintaining separate databases and the overhead associated with that.",
          "score": 2,
          "created_utc": "2026-02-17 02:06:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5t01qp",
              "author": "rudrakshyabarman",
              "text": "What if I use same database but different schema in PG?",
              "score": 1,
              "created_utc": "2026-02-17 03:32:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5u0ixr",
                  "author": "secretBuffetHero",
                  "text": "what do you mean different schema in PG?",
                  "score": 1,
                  "created_utc": "2026-02-17 08:23:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5suon2",
          "author": "expatjake",
          "text": "Bear in mind that Postgres RLS has some performance implications because it acts as an optimization barrier to prevent any possibility of data leakage such as via error messages. \n\nIf you go with the classic tenant id on a table make sure you use it on all tables, it makes enforcement and some performance cases easier to deal with. Iâ€™d also suggest making your tenants portable by using compound (with tenant id) or uuid keys. This way you could simply copy rows to a new DB if you need to redistribute load.",
          "score": 2,
          "created_utc": "2026-02-17 02:59:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5u5k28",
              "author": "Humble-Persimmon2471",
              "text": "Now you're trading performance for security, and trying to stop the gap yourself. Either security is important or it isn't important enough to stop a potential issue creeping through",
              "score": 1,
              "created_utc": "2026-02-17 09:11:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5tdlnw",
          "author": "evergreen-spacecat",
          "text": "How many/big tenants? If they are big (lotâ€™s of data), you may want a DB per tenant. If they are small you want a row discriminator. I usually go with both, then you can have a lot of small customers in a shared DB and big/VIP customers in separate DBs. In any case, you must auto inject â€œWhere tenant_id = <current tenant is>â€ on all entities as well as auto inserts them on add/update. It will never be secure if you leave this to each developer to remember. This is easier to achieve with an ORM layer than hand written SQL",
          "score": 2,
          "created_utc": "2026-02-17 05:06:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vddt4",
              "author": "rudrakshyabarman",
              "text": "This is about Healthcare Management Software (Hospitals, LABs etc). Some large corporate has huge data, some small lab has low volume data.",
              "score": 2,
              "created_utc": "2026-02-17 14:31:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5weucy",
                  "author": "evergreen-spacecat",
                  "text": "Had to handle this very discussion for a medical records system of sorts (with DB, domain, auth separated per tenant) and investigated expanding the systems market to single person clinics. Think therapists, psychologists or similar. I could not figure out how to adapt the DB per tenant model that was already in place and optimized to serve large care givers to small tenants without the overhead cost would eat all potential profit. I had to architect a row level tenant separator for small clinics to scale to the new market. You may be able to figure it out, it entirely depends on your tech stack/provisoning system and the economics of your product.",
                  "score": 2,
                  "created_utc": "2026-02-17 17:38:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5tly98",
          "author": "VillageDisastrous230",
          "text": "You can have DB per tenant and code / service deployment can be common, based on logged in user (a tenant id in JWT if you are using JWT) can identify to which db request need to connect\nConsider this approach based on the below points\n1. You have considerable number of clients and your client base is going to grow\n2. In already existing clients some of your client going to grow rapidly (in this case separate dbs better because same db might affect other client)\n3. Your clients needs their data to be separated \n4. When your clients needs all their data or database when they exit \n5. Your clients needs daily or periodic dumps of their data",
          "score": 2,
          "created_utc": "2026-02-17 06:11:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5sz9y4",
          "author": "halfway-to-the-grave",
          "text": "Tenant id on the user table and the assets that matter then inject that on the model. Leakage can be a concern for any raw queries though that donâ€™t use your orm",
          "score": 1,
          "created_utc": "2026-02-17 03:28:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tjqg9",
          "author": "Mobsuke106v2",
          "text": "Definitely depends, as others have said it depends on the size of the client and their needs and privacy. \n\nRegarding tenant isolation by schema, it does provide flexibility in schemas for each and every tenants, better security but migrations and maintenance can be a hassle when thousands of schemas. \n\nI am also creating a project with multi tenant architecture, I am doing isolation with tenant\\_id, rls, and also making sure that every drizzle query has the specific tenant\\_id wrapped to it, so that no dev does any query without the tenant\\_id or wrong tenant\\_id. Regarding noisy neighbours will be doing rate limiting, and when a tenant actually grows quite big then they can be shifted to a sepeprate server. ",
          "score": 1,
          "created_utc": "2026-02-17 05:53:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vdgdo",
              "author": "rudrakshyabarman",
              "text": "This is about Healthcare Management Software (Hospitals, LABs etc). Some large corporate Hospitals has huge data and some small lab has low volume data.",
              "score": 2,
              "created_utc": "2026-02-17 14:31:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ttlgx",
          "author": "dariusbiggs",
          "text": "Completely dependent on the who what where when and why. You've not provided near enough information for people to give a recommendation.\n\nWhat are the constraints, what's the size of a tenant, how much data are you storing, what Privacy and encryption requirements are there, what PII are you storing, do they provide users, etc, etc \n\nMy current live project just uses PostgreSQL with one database for everyone, and the development and test data for the number of tenants and users per tenant are two orders of magnitude larger than the current largest tenant in production. But each user only has 20 related db rows stored in PostgreSQL, so a million users would only generate about 20 million database rowa across all the various tables.\nAudit logs are stored elsewhere.\n\nThe product uses one platform and API for all tenants, there is no tenant specific functionality.",
          "score": 1,
          "created_utc": "2026-02-17 07:18:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vdic7",
              "author": "rudrakshyabarman",
              "text": "This is about Healthcare Management Software (Hospitals, LABs etc). Some large corporate Hospitals has huge data and some small lab has low volume data.",
              "score": 1,
              "created_utc": "2026-02-17 14:32:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5tyber",
          "author": "czlowiek4888",
          "text": "I do rsl with transparent encryption at rest.\n\nWhen I setup rls I can use postGREST with virtually 0 cost.",
          "score": 1,
          "created_utc": "2026-02-17 08:02:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tzee5",
          "author": "codeonline",
          "text": "The first questions aren't technical, they are based on your business model. Will you have 10s of high value tenants each with bespoke needs and high touch sales and integration needs. Or thousands of low value tenants with a few configurations settings per tenant.\nAlso are your tenants storing medical records / PII or ToDo lists?",
          "score": 1,
          "created_utc": "2026-02-17 08:12:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vdig4",
              "author": "rudrakshyabarman",
              "text": "This is about Healthcare Management Software (Hospitals, LABs etc). Some large corporate Hospitals has huge data and some small lab has low volume data.",
              "score": 1,
              "created_utc": "2026-02-17 14:32:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5uo7p8",
          "author": "expatjake",
          "text": "Where you sit on that continuum is obviously a decision you have to make. My experience tells me that cost is going to be the limiting factor and that tradeoff is not always easy to make while managing it. But everyone needs to make that assessment!\n\nYou are right that it should be considered, and carefully.",
          "score": 1,
          "created_utc": "2026-02-17 11:57:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6619if",
          "author": "Square-Arachnid-10",
          "text": "Both approaches work â€” the â€œrightâ€ choice depends on operational complexity vs isolation requirements.\n\nIf you want simpler ops at 100+ tenants, RLS + a shared schema usually scales better (one migration path, one set of indexes, one code path). The safety comes from enforcing tenant\\_id everywhere + setting it at the connection/session level, plus tests that prove cross-tenant reads are impossible.\n\nSchema-per-tenant gives stronger isolation, but migrations, search paths, monitoring, and cross-tenant analytics get painful as tenants grow.\n\nA common middle ground in healthcare: shared schema + RLS for most tenants, and â€œheavyâ€ tenants get their own database (not just schema) when volume/compliance needs justify it.",
          "score": 1,
          "created_utc": "2026-02-19 01:50:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r72pvw",
      "title": "API Design 101: From Basics to Best Practices",
      "subreddit": "softwarearchitecture",
      "url": "https://javarevisited.substack.com/p/api-design-101-from-basics-to-best",
      "author": "javinpaul",
      "created_utc": "2026-02-17 10:41:54",
      "score": 17,
      "num_comments": 1,
      "upvote_ratio": 0.77,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r72pvw/api_design_101_from_basics_to_best_practices/",
      "domain": "javarevisited.substack.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5wyeha",
          "author": "umlcat",
          "text": "\"Web A.P.I.\" design ...",
          "score": 1,
          "created_utc": "2026-02-17 19:08:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6qes5",
      "title": "How Messengers like Telegram handles big chats",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1r6qes5/how_messengers_like_telegram_handles_big_chats/",
      "author": "andreyka26_",
      "created_utc": "2026-02-17 00:00:27",
      "score": 15,
      "num_comments": 14,
      "upvote_ratio": 0.83,
      "text": "I would like to ask a genuine question about how real-world apps like Telegram can handle big chats (they have 200k users per chat limit). Why am I asking?\n\n\n\n# Components\n\n`MessageApi` \\- for simplicity, stateless replicated API that receives the message for chat\\_id, and distributes it to the end user\n\n`GatewayNode` \\- stateful websocket server that handles user connections\n\n`UserGatewayStorage` \\- stores map {userid => GatwayNodeUrl}, sharded by user\\_id\n\n`ChatStorage` \\- stores {chat\\_id => \\[user1, user2, user3\\]} map, and tells who are the users in a particular chat\n\nI do believe it can handle chats up to 250 participants, but I don't see how it can handle big chats/channels with 10k+ subscribers\n\nTypical approach I saw on the internet\n\n**UserConnection**: we connect user to random GatewayNode, GatewayNode updates the mapping in UserGatewayStorage {userid => CurrentGatwayNodeUrl}\n\n\n\n**Message Delivery**: message arrives to MessageApi, it retrieves participants from ChatStorage, then it retrieves all GatewayNodeUrls from UserGatewayStorage, and fans out the message to these GatewayNodes\n\n\n\n# Problem\n\nLet's say we have 10k chats that have 50k+ subscribers each. Let's say we have 1k GatewayNodes, 1k UserStorage nodes, and 1k ChatStorageNodes.\n\nLet's say we evenly distribute the users between GatewayNodes, same for UserStorage shards (consistent hashing)\n\nNow every message in big chat will require querying ALL GatewayNodes and ALL UserStorage shards, because:\n\n\n\n50k / 1k = 50 users in big chat of 50k participants per UserStorage shard\n\n50k / 1k = 50 users in big chat of 50k participants per GatewayNode instance\n\n\n\nIf we have 10k of such chats, and even 1 message per second in every single chat, it means that we are calling ALL our UserShards 10k times per second, and then ALL our GatewayNodes 10k times per second.\n\nIt is broadcast, as for single message we need to call ALL UserStorage shards to resolve necessary GatewayNodes, then we will send message update to ALL GatewayNodes, because for big chat, we will have all GatewayNodes keeping at least one user who is participant in this big chat.\n\n\n\n# Follow up\n\nSome people add one more layer, called ChatNode. Now we connect GatewayNodes to ChatNode based on the chat (let's say consistent hashing). The message then goes first to ChatNode, and then ChatNode distributes it to all interested GatewayNodes. It is still broadcast. According to math, we are going to have ALL GatewayNodes subscribed to ALL ChatNodes.\n\n\n\nAny ideas how this is solved?",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r6qes5/how_messengers_like_telegram_handles_big_chats/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o5s9gg5",
          "author": "Flimsy_Complaint490",
          "text": "It's kinda hard to design this system in the abstract, because if you can leverage and tie yourself to a specific tool, so many things become easier IMO. Lets say im using MQTT and my favorite broker, VerneMQ, though i suspect all brokers have the same capabilities. And your architecture is complicated and expensive to run as you probably noticed. I think Signal does something like what you dscribe, but their chat rooms are quite small and they emphasize privacy over performance.\n\nNow, If you pretend a chat room is a topic, and chat members are subscribers, you now enter the realm of publisher-subscriber architecture and your problem is reduced to such. We still need to keep some sort of membership somewhere and if we want 200k chat members, we have to do it server side.\n\n1. in the database we store all chats the user is a part of\n2. User opens up app and tries to connect. We authenticate him on this topic once via some callback, maybe even write some Lua to save a network call. He will have an MQTT session for this topic and we dont need him to auth him again. Our VerneMQ is sharded and distributed and supports session migration by itself, though you probably want to add some load balancer with session affinity to avoid migration overhead. VerneMQ is configured with retain, which means it always retains the last published message for a topic.\n3. once authenticated, the user receives the last published message. This can be a full chat message or whatever, but the important aspect is that it has a date or some sort of identifier which tells the user the current message.\n4. the user can ask the server to provide all the messages intended for him in the mailbox on the server and he receives all messages.\n\nBy leveraging some implementation details, we have reduced the problem to the user connecting to a broker, authenticating, receiving a timestamp or some sort of identifier that allows him to query the server (or somebody else if you are a p2p protocol) for the entire chat history he missed and the entire load is on the broker and whatever else you are using as a database. No more gateways, sharded session state where only a specific subset lives on a specific node and so on, we used MQTT as a broker for signalling and people can get their chat history from our central mailbox, which is your favorite scalable database solution. Maybe you can play around with queues here to store that history (i dont think storing it on the MQTT broker is acceptable for latency reasons, but it is an option) or whatever else. \n\nAnd as long as he has the app active, we can just publish messages directly to him via the broker and MQTT shines at that.\n\nnow, there are certain bottlenecks in this design - i replaced that whole distributed state thing with a centralized DB that needs to store messages and will get a shitload of IO, but fundamentally, if you have an async chat app, you absolutely must have some fancy central database to store messages as a mailbox for users and distributed state is painful to handle and buggy as hell. And now the problem is reduced from pubsub to scaling your database IO and that is a well studied field. And note that with 200k members in a chat, its probably a notification channel and not an actual channel where all 200k members write at the same time, so we have a relatively very high latency tolerance here - it fundamentally doesnt matter if you get a notification now, or 5 seconds later, but 5 mins later would suck. \n\nWhat i described is similiar to what whatsapp is doing, and unlike telegram, they have written a few whitepapers about their transport protocol (at one point, maybe even today, they deemed TLS bloatware and did Noise pipes instead !)",
          "score": 3,
          "created_utc": "2026-02-17 00:51:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5usfye",
              "author": "andreyka26_",
              "text": "PubSub seems to not scale.  \n  \nAs I understood we  connect user as subscriber to \"his\" queue, meaning we are going to have topic/queue per user. We can have up to half a billion DAU, what broker will allow to spawn that many topics?   \nSecond and most blocking problem, it will overload each queue, because now every single user in big chat => thus every queue that this user is served by needs to process the every message in big chat. So pretty much upon message creation we will send this message to ALL the queue, problem remains the same: given 10k+ such large chats it means 10k+ updates per second on every queue => it does not scale lineary.\n\n===\n\nIn case you meant queue/topic per chat. Same problem, we might have Billions of chats, which broker will allow cheaply create BILLION of topics/channels? Even though, again, every GatewayNode that is going to subscribe to specific Chat Channel is going to process way too many updates.\n\nMath: we have 10k chats, every single one of them has 50k participants. We have 1k gateway nodes, 50/1 = 50 users in every gatewaynode interested in single chat (some topic/queue)-> every message published to this topic/queue  delivers update to ALL gatewaynodes.\n\nNow just multiply it by 10k (as we have 10k such large chats)",
              "score": 1,
              "created_utc": "2026-02-17 12:28:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5vhkm4",
                  "author": "Flimsy_Complaint490",
                  "text": "Hmm, looking at Meta as an example (they have a billion users and send billions of messages, but their rooms are quite small, 5k max i believe), i think something like this would work\n\n1. Run MQTT as our signalling platform. We subscribe to all our topics. This is both our MessageAPI and GatewayNode.\n2. User writes a message to the chatroom\n3. Our MQTT receives the message and forwards it to some sort of other process for handling\n4. we process the message: store it on some sort of ordered queue. Every chat has an ordered append only queue.\n5. We store group memberships somehow. Can we shard chats ? Like, a million users actually may look like a lot, but a 4 core i3 from 2017 can send on vernemq 10k messages per second and we could theoretically send a million messages in 1.5 minutes to a million users with a 4 core i3. If we can shard and identify which server or servers host our 1 million, we send one message there and it calls publish to clients in a loop.\n6. These messages end up in the MQTT cluster. It will figure it out, but a potential bottleneck here is the inner cluster communication. Lastly, do note that MQTT is mostly stateless - you can indeed open millions of topics, they do not cost much as long as they are not used much. \n7. users receive message or delta, can sync with our ordered append only log queue. Another potential bottleneck.\n\nI think this should scale as long as the sharding works and the mqtt server does not choke on intercluster communication. And yes,  MQTT can handle billions of topics, facebook proved it by having every instagram user open 22 topics, so their cluster handles 22 billion topics somehow.\n\nLast point:\n\n>Math: we have 10k chats, every single one of them has 50k participants. We have 1k gateway nodes, 50/1 = 50 users in every gatewaynode interested in single chat (some topic/queue)-> every message published to this topic/queue delivers update to ALL gatewaynodes.\n\nFundamentally, for a user to receive a message, somebody has to find his TCP connection file descriptor and call write on it. Therefore, there is physically no way to avoid having  a message or a notification being sent to ALL connected users. Either they poll the server constantly, or we send. Thus as you note, depending on your granurality of sharding, you will will need to find all those shards and have them emit a notification, there just is no way around this.\n\nThis is realistically less of a worry than you think - you can have quite large shards, i proposed sharding by entire room. And these days you can buy 256 cores 4 TB servers and if you are operating at Telegram scale, you can afford it. And if you can't, well, that 4 core i3 from 2017 will do the job in 2 minutes, which is acceptable for the telegram channels with a million subscribers, since they can only be written to by admins and people wont notice if a notification arrives a minute sooner or later, they just need it delivered in a reasonable amount of time.",
                  "score": 1,
                  "created_utc": "2026-02-17 14:53:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5sa33o",
          "author": "UnreasonableEconomy",
          "text": "> Now every message in big chat will require querying ALL GatewayNodes and ALL UserStorage shards, because:\n\nwhy not just cache it? no need to query all that every single time. yes, the chat service will have to dispatch 200k messages, but they're all unicast. \n\n> Message Delivery: message arrives to MessageApi, it retrieves participants from ChatStorage \n\ninstead of doing that, you can just pull the reference to the correct dispatcher object, and forward the message to the appropriate service instance.",
          "score": 2,
          "created_utc": "2026-02-17 00:55:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uruod",
              "author": "andreyka26_",
              "text": "Caching would help to resolve Gatewaynode per user, but won't help with GatewayNode scalability. Because GatewayNode processes ALL the messages from ALL the big chats. If we are evenly distributing users between GatewayNodes, every GatewayNode would be interested in ALL big chats.\n\nMath: we have 10k chats, every single one of them has 50k participants. We have 1k gateway nodes, 50/1 = 50 users in every gatewaynode interested in single chat -> every message in this chat triggers update to ALL gatewaynodes.\n\nNow just multiply it by 10k (as we have 10k such large chats)",
              "score": 1,
              "created_utc": "2026-02-17 12:24:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5wu4lx",
                  "author": "UnreasonableEconomy",
                  "text": "> Now just multiply it by 10k (as we have 10k such large chats)\n\nyeah, but the gateway nodes don't need to concern themselves with the dispatch logic. \n\nJust passing a message through a gateway node is fairly cheap. And if your nodes are struggling, you just make more. More nodes, fewer messages per node.\n\nAt the end of the day, you can't get around having to send at least (members) * (message size) data.",
                  "score": 1,
                  "created_utc": "2026-02-17 18:48:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5tb9qw",
          "author": "Hiithz",
          "text": "Actor model design pattern\nElixir is a language made over this pattern, but you can use frameworks in other languages \nIs a language made for communication...",
          "score": 1,
          "created_utc": "2026-02-17 04:49:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o616q05",
          "author": "ConstructionInside27",
          "text": "You're right that telegram is doing something apparently rather impressive. Live connection between \nN global users * C average per-user connections,\n\nwhere C is in the 10s of thousands. Also, the problem isn't cleanly partionable. And finally, it's a complete non-starter because you'll be blowing up users' phones with push events.\n\nWhen answering a question like this, it's best not to start with   sketching a system topology but asking yourself \"what is the algorithm that produces minimum number of operations necessary to satisfy the users?\". Once you have the algorithm you can move to the next step of distributing it.\n\nThe Product Manager may have said \"I want live instant messaging between all users in massive groups\" but you shouldn't treat that as a rigid technical spec. It's a description of the user experience vision. So you might push back and just say no, but it's much better if you can come back with a proposal satisfying their vision. \n\nFirst step is to look at the user interface. In the case of telegram there are 3 main modes for our purposes. Viewing chatlist, viewing a chat and app backgrounded but open to notifications. Immediately what becomes clear is that a person scrolling their chat list doesn't need to see them all live updating and doesn't need to load all the recent messages. When the phone is in their pocket they don't want constant notifications from big groups at all.\n\nFrom this, what I'd imagine telegram actually does goes something like this:\n\nWhen the app is open users are subscribed to message pushes from their 1:1 chats. Perhaps limited to a shortlist of active chats.\n\nFor group chats, users are subscribed to receive a summary every N minutes or else it's pull based. Perhaps that switches to N seconds when the app is foregrounded. The summary actually need only contain the last message truncated. It could also contain the count of unread messages, but that's a bit of per user computation that might also need optimizing away. We can't rely on a static message count per summary because we can't assume the user received every single summary so can add them up. (We might also ask the PM if an accurate number is necessary beyond a certain count or if \"100+\" is ok)\n\nNow, this has already solved most of the problem. Switching from per-message pushes to periodic removes that explosive C number from the scaling equation. It no longer matters how many participants are in each chat, only the number of chats per user.\n\nStill, we can take it a little further. What other qualities of the product can you take advantage of? Well, even though messages are editable, that's the exception that can be layered on top. It is mostly an *append-only* format. There are lots of big optimizations available with append-only systems.\n\nNot only that, the chat is a shared artifact. There isn't a custom version of it for each chat participant. This together with the append-only property means you can aggregate it into chunks of a few hundred messages. That's a static, highly cacheable asset. When the user enters the chat, no server needs to push N unread messages to them they just need to point them to the latest static chat chunk.\n\nSo, summing up, the server architecture you laid out indeed doesn't solve the whole problem. The full telegram architecture has to have additional layers like this. That's why chat apps never launch with such large scale chat features that actually work. It's definitely a bigger project. In a real project you'll want to go back to PM, tell them it's possible but visually represent the sheer amount of extra complexity it will entail. Explain that yes we can achieve this in the end, but what does the more limited intermediate product look like? Limit to small groups? Group chats don't even pretend to be live? If we can make some compromises, that's the v1 we can ship much quicker.",
          "score": 1,
          "created_utc": "2026-02-18 10:56:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62fwqy",
              "author": "andreyka26_",
              "text": "It is greatly covers the chatlist part of the problem, my concern is to how to handle these users that are in opened big chat. So they DO need realtime, it is not acceptable to have 1 second delay due to polling. We need realtime, and telegram makes it realtime, you can test it.  \nFor chat list I agree we can fully switch basic http polling once per second, spawn a lot of read replicase = done, it is trivial problem",
              "score": 1,
              "created_utc": "2026-02-18 15:27:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r3qx71",
      "title": "Andrej Karpathy's microGPT Architecture - Step-by-Step Flow in Plain English",
      "subreddit": "softwarearchitecture",
      "url": "https://i.redd.it/xyt42hvmr9jg1.png",
      "author": "rsrini7",
      "created_utc": "2026-02-13 14:41:40",
      "score": 15,
      "num_comments": 3,
      "upvote_ratio": 0.83,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r3qx71/andrej_karpathys_microgpt_architecture_stepbystep/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o59vhsp",
          "author": "Tyhgujgt",
          "text": "*This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*\n\nadvise elastic violet treatment squeal seed close unpack groovy serious",
          "score": 3,
          "created_utc": "2026-02-14 02:16:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o59yot4",
              "author": "rsrini7",
              "text": "https://karpathy.ai/microgpt.html\n\nhttps://gist.github.com/karpathy/8627fe009c40f57531cb18360106ce95",
              "score": 2,
              "created_utc": "2026-02-14 02:36:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5gg0m3",
          "author": "SimpleChemical5804",
          "text": "Interesting.",
          "score": 2,
          "created_utc": "2026-02-15 04:25:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4djkq",
      "title": "Micro Frontends: When They Make Sense and When They Donâ€™t",
      "subreddit": "softwarearchitecture",
      "url": "https://lukasniessen.medium.com/micro-frontends-when-they-make-sense-and-when-they-dont-a1a06b726065",
      "author": "trolleid",
      "created_utc": "2026-02-14 06:37:47",
      "score": 14,
      "num_comments": 2,
      "upvote_ratio": 0.75,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r4djkq/micro_frontends_when_they_make_sense_and_when/",
      "domain": "lukasniessen.medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5ckvpc",
          "author": "asdfdelta",
          "text": "Really stellar article! Thanks for putting this together.\n\nWe're looking at microfrontends now, and I've looked at it in the past as well. Solving the organizational meed is crucial, and I feel like you covered this here pretty well.\n\nCoupling complexity can be immense with teams fewer than 5. We're an org that has a frontend team that split into stream-aligned teams without changing anything about the monolith app. It's been a nightmare where everyone touches everything and teams frequently impact each other. We currently have 4 teams. If the app were well modularized, the risk would be lower, of course, but it really isn't.\n\nOne question with the MPA approach: as different teams are serving from different URLs, how do you maintain page state and shared components?",
          "score": 2,
          "created_utc": "2026-02-14 15:07:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fq7ob",
              "author": "Mortale",
              "text": "I was once working with micro frontends with SPA. We have some kind of â€œframeâ€ (it was before the module federation) so every team with their modules could register module, route for the module and position for the module. \n\nSo, module â€œmy-cartâ€ could be registered under path â€œ/cartâ€ and on position â€œcontentâ€. That configuration was provided by backend and frontend was building it. Every module was stored in some CDN so â€œframeâ€ had to pull files and then load them. \n\nLead engineers decided to leave at most freedom as itâ€™s possible for teams. So it was to possible to have different versions of React in system. And we had. Same with state. Every module had separate state. So if some module fetched data for user, another module didnâ€™t have that kind of data. Exceptâ€¦\n\nThere were â€œfrontend core teamâ€. Something like that. They built the frame, the React UI components that every team should use to build modules and â€œagnostic librariesâ€. Agnostic so they werenâ€™t written in React. And they provided methods likes â€œgetUserâ€. And those methods were cached so if two different modules fetched for user, there was only one request. \n\nOver the time I think it was a brilliant architecture.",
              "score": 3,
              "created_utc": "2026-02-15 01:25:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r8x6vh",
      "title": "I've spent past 6 months building this vision to generate Software Architecture from Specs or Existing Repo (Open Source)",
      "subreddit": "softwarearchitecture",
      "url": "https://v.redd.it/hf6hohk4wfkg1",
      "author": "Calm_Sandwich069",
      "created_utc": "2026-02-19 11:50:17",
      "score": 14,
      "num_comments": 2,
      "upvote_ratio": 0.79,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r8x6vh/ive_spent_past_6_months_building_this_vision_to/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o68gwlo",
          "author": "Adorable_Pickle_4048",
          "text": "I would set the focus of the software on maintaining in place documentation and user driven doc spec aggregations using this platform. \n\nTask management sets the problem statement of change management, but change management is secondary to good software context for any AI powered workflow. Thereâ€™s some similar tools being built inside Amazon rn. To be clear, I think this can be used for task management effectively, but it should be lower priority than an in place, durable, regeneratable agentic knowledge store",
          "score": 3,
          "created_utc": "2026-02-19 13:04:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o694zpd",
              "author": "Calm_Sandwich069",
              "text": "Interesting, you mean something like deepwiki?\n\n",
              "score": 1,
              "created_utc": "2026-02-19 15:17:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r6qvhv",
      "title": "Words are a Leaky Abstraction",
      "subreddit": "softwarearchitecture",
      "url": "https://brianschrader.com/archive/words-are-a-leaky-abstraction/",
      "author": "sonicrocketman",
      "created_utc": "2026-02-17 00:19:38",
      "score": 13,
      "num_comments": 19,
      "upvote_ratio": 0.69,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r6qvhv/words_are_a_leaky_abstraction/",
      "domain": "brianschrader.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5sfsjr",
          "author": "FetaMight",
          "text": "I only skimmed this, but how is it software architecture related?  It just seems like a few related thoughts on language (not words, per se) put into a blog post and shared repeatedly on reddit.",
          "score": 8,
          "created_utc": "2026-02-17 01:29:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5t61hr",
              "author": "asdfdelta",
              "text": "You really should read the entire article. It is littered with practical examples of how this relates to architecture.\n\nI've said it many times before and will continue to say it; success in software architecture has so much to do with the People System. This article is HUGE for architects, had you fully read it that might be more apparent.",
              "score": 4,
              "created_utc": "2026-02-17 04:12:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5u0dhb",
                  "author": "FetaMight",
                  "text": "I didn't *not* read it.Â  I skimmed through it several times.\n\n\nHow is this HUGE for architects?Â  I read though again and still don't see it.Â \n\n\nEnlighten me.",
                  "score": 2,
                  "created_utc": "2026-02-17 08:22:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5sgx8d",
              "author": "sonicrocketman",
              "text": "I mean, I do think the post is somewhat related to SA. As an architect myself, I think what we call things is important and how we define our terms internal to our systems is crucial to how we view the data that flows through it and how it constrains our own thinking. Especially re:AI and AI systems. Agreed it's not hard-SA, but I do think it's certainly related.",
              "score": 1,
              "created_utc": "2026-02-17 01:36:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5si9rg",
                  "author": "FetaMight",
                  "text": "Sure, but the article doesn't touch on any of that.\n\nIt's purely about language.  And as such it relates to SA as much as it relates to billiards:  Language is a useful tool when interacting with other people and trying to achieve a common goal.\n\n  \nETA:  Sorry, I don't mean to be rude or mean.  I'm just not seeing the link to Software Architecture.  It's late here though.  that might be it.",
                  "score": 4,
                  "created_utc": "2026-02-17 01:44:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5uemou",
          "author": "severoon",
          "text": "I get that this is a reflection on moltbook, hence centering words as the relevant medium of communication â€¦ but I think that's unfortunate for this sub because words do not form the space that concerns software architecture.\n\nA software system is a model of some problem (or business) domain in which transformations of identified problems into solutions can be implemented. This is similar to the way a scientific theory is a model of reality that allows reliable predictions to be made about outputs based on specified inputs.\n\nThe important point here is to distinguish between the scientific model of reality and reality itself. When physicists discuss a theory of gravitation, they understand at some level that they are making confident statements *about the model*, not about reality itself, and while there may be (and hopefully is) some correspondence between the theory and reality, confidence in the former does not necessarily extend to the latter. We should not confused the map for the territory.\n\nLikewise, software is a model of the business domain. When we define a Person table in the database, it's not an assertion of what it means to be a person out in the real world of the business domain, it's an assertion of what it means to be a \"person\" in this model of that domain, which is only concerned with encapsulating *certain aspects* of the real person useful to the model.\n\nWe may not be able to define exactly what a person, or intelligence, or a soul is out in the real world, but we absolutely can nail down the aspects of that entity we want to capture in the model and how those aspects are to be represented, and it's perfectly okay to make confident statements about the entities in the model. It should go without saying that those statements do not necessarily apply to the whole thing being modeled.",
          "score": 2,
          "created_utc": "2026-02-17 10:37:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uyvic",
          "author": "andarmanik",
          "text": "Thereâ€™s a context I think is missing in this article. There is information in the delta between what a concept means and how itâ€™s being used. In general itâ€™s considered being â€œcleverâ€, but in specific cases it drives language development.\n\nThe delta between a â€œsoulâ€ and a â€œsoul.mdâ€ is exactly the delta which we want the model to infer. We want to infer what it means to interpret a text file as a soul.\n\nThe indivisibility of â€œpersonhoodâ€ was largely excluded from its definition. It wasnâ€™t until person meant like god as 3 â€œpersonsâ€ a sort of unified yet distinct impression god has on reality in Christianity. Basically, the whole notion of individuality didnâ€™t exist in the original word for persons, it wasnâ€™t until they tried to define god as a person that the delta then redefine person as individuality.\n\nItâ€™s the delta between what that is and what we are which informed â€œpersonhoodâ€.",
          "score": 2,
          "created_utc": "2026-02-17 13:10:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5v8aud",
              "author": "asdfdelta",
              "text": "Isn't that just subjectiveness though?\n\nThe definition versus the colloquial usage. That's what I interpreted from the high/low cohesion section.",
              "score": 1,
              "created_utc": "2026-02-17 14:03:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5v8qvd",
                  "author": "andarmanik",
                  "text": "Iâ€™m pointing to a different thing. Words get redefined all the time and the distance from the definition and what is being said is part of the equation for how a word changes.\n\nPerson meant like dog or cat, but through failing to define god as three persons, we realized a category to expand the definition of â€œpersonâ€.\n\nWithout the delta between god as three person and â€œpersonâ€ as defined like dog or cat, you wouldnâ€™t get the current, subjectively, more thorough definition of â€œpersonâ€.",
                  "score": 2,
                  "created_utc": "2026-02-17 14:06:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5t6k36",
          "author": "asdfdelta",
          "text": "Having to navigate the consequences of an attempted violation of Conway's Law not once, but twice so far, this really hits home for me.\n\nWe're standing up an Enterprise Architecture practice for the first time in our org, and the topic of nomenclature has been simultaneously such a difficult monster to wrangle and a sneaky, nefarious saboteur to our efforts.\n\nThank you for stating it so elegantly. Wonderful article, this should be required reading for all Software Architects at all levels.",
          "score": 0,
          "created_utc": "2026-02-17 04:16:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r87uq5",
      "title": "From Cron to Distributed Schedulers: Scaling Job Execution to Thousands of Jobs per Second",
      "subreddit": "softwarearchitecture",
      "url": "https://animeshgaitonde.medium.com/from-cron-to-distributed-schedulers-scaling-job-execution-to-thousands-of-jobs-per-second-ef05955bf3d9",
      "author": "Local_Ad_6109",
      "created_utc": "2026-02-18 16:35:53",
      "score": 13,
      "num_comments": 1,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r87uq5/from_cron_to_distributed_schedulers_scaling_job/",
      "domain": "animeshgaitonde.medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "o63o2xg",
          "author": "rkaw92",
          "text": "Pretty cool. I have implemented this using ScyllaDB and RabbitMQ. I also have done materialized tickers to allow for equality checks on task lookups vs. \"scheduledAt <= now\".",
          "score": 3,
          "created_utc": "2026-02-18 18:45:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r70huo",
      "title": "calling it an ai pair programmer is misleading marketing",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1r70huo/calling_it_an_ai_pair_programmer_is_misleading/",
      "author": "No-Vast-9143",
      "created_utc": "2026-02-17 08:21:48",
      "score": 12,
      "num_comments": 22,
      "upvote_ratio": 0.65,
      "text": "pair programming is about collaboration and discussion\n\n\n\n\"should we refactor this now or later\"\n\n\"this approach will be hard to test\"\n\n\"remember we tried something similar last year and it had issues\"\n\n\n\nai tools just generate code\n\nthey dont question your approach. they dont warn you about tradeoffs. they dont remember what failed before. they dont push back when youre making a mistake.\n\n\n\ntheyre autocomplete not a pair programmer\n\n\n\nfeels like we're setting up juniors to think this is what collaboration looks like when its really just a fancier IDE feature",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1r70huo/calling_it_an_ai_pair_programmer_is_misleading/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o5uw923",
          "author": "Justin_3486",
          "text": "juniors on my team literally think pairing means sitting next to an AI. we've lost something important here",
          "score": 5,
          "created_utc": "2026-02-17 12:53:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uwlyz",
          "author": "Jenna32345",
          "text": "Thank you! The terminology is so misleading. It's like calling spell-check a 'writing partner'.",
          "score": 3,
          "created_utc": "2026-02-17 12:56:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5u0x9r",
          "author": "Relevant_Accident666",
          "text": "You are partly right, but if you adjust your system prompt or you ask for options and trade offs you sure get different perspectives on the problem at hand. \n\nOnly works with the right models (Gemini 3 pro, Opus 4.5 / 4.6, ...) ",
          "score": 8,
          "created_utc": "2026-02-17 08:27:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uc3ij",
              "author": "Dnomyar96",
              "text": "Yeah, if you tell it to implement X, it's going to implement X. But if you tell it think critically, challenge your assertions and not just mindlessly implement stuff, it absolutely can work like OP describes pair programming.",
              "score": 7,
              "created_utc": "2026-02-17 10:13:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5u4byg",
          "author": "Flixter993",
          "text": "I was in the same boat, but after playing a lot with Opus 4.6 I have changed my mind. It feels like a different game out there, no it is not only code generation. I can brainstorm with it and ask all the right questions with explanations in great detail, it writes diagrams which we both learn from and iterate on. With good prompting and guidance you can do crazy stuff. Yes it does make mistakes and hallucinations, but so do we.",
          "score": 4,
          "created_utc": "2026-02-17 09:00:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o66qv2y",
              "author": "Certain-Researcher72",
              "text": "I had someone tell me it's useless, nondeterminative and writes buggy code and I had to wonder if he'd ever worked with another human being before. Talk about hallucinations.",
              "score": 0,
              "created_utc": "2026-02-19 04:25:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5uvbfw",
          "author": "Aware-Version-23",
          "text": "exactly. real pairing involves pushback and discussion. ai just says yes to everything",
          "score": 2,
          "created_utc": "2026-02-17 12:47:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5w8hxh",
              "author": "Fidodo",
              "text": "You need to enforce your own standard of quality. They will challenge you if you ask them to. I do this all the time when researching. First I'll ask for an exhaustive list of potential solutions, I'll pare it down, adapt the ideas, then ask it to challenge an approach to brainstorm how it could go wrong. \n\nI'm leading the whole process but the domain knowledge LLMs can surface and the rapid extrapolation they can perform helps me think much faster than I could on my own.",
              "score": 1,
              "created_utc": "2026-02-17 17:07:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5xt9c1",
              "author": "Hotfro",
              "text": "So question every output it gives? If you provide concrete edge cases itâ€™ll give you better output. Itâ€™s not perfect, but it improves the output when you do this. Also have other devs review your code and also any design decisions you use AI as part of.",
              "score": 1,
              "created_utc": "2026-02-17 21:34:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5uvo6f",
              "author": "Turbulent_Carob_7158",
              "text": "tbh even the 'smart' ones dont really challenge you. they just generate what you ask for",
              "score": 1,
              "created_utc": "2026-02-17 12:50:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5w7ulk",
          "author": "Fidodo",
          "text": "However, AI is wonderful at surfacing domain specific information that is incredibly hard to find otherwise. \n\nIt has greatly accelerated my research and allowed me to surface CS knowledge I'd never be able to find on my own and learn it much faster.\n\nYou're right that an LLM won't voluntarily challenge you, but it will if you ask it to challenge you. While it's not as good as having a knowledgeable human as a partner, finding knowledgeable humans you can collaborate with as much as you want is very hard.\n\nI view LLMs like a rubber duck on steroids combined with an encyclopedia. It's incredibly useful if you use it with the goal of educating yourself instead of offloading your thinking to it.",
          "score": 2,
          "created_utc": "2026-02-17 17:04:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5xt2g0",
          "author": "Hotfro",
          "text": "The thing is everything you stated can still be done to a certain extent with AI. Why canâ€™t you question AI for every point you listed? It can be a pair programmer if you actually treat it like so.",
          "score": 1,
          "created_utc": "2026-02-17 21:33:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61w6qr",
          "author": "aroras",
          "text": "Agreed. the benefit of pair programming is continuous line-by-line review.  By contrast, AI usage creates batches that require independent review.  It's a totally different thing. ",
          "score": 1,
          "created_utc": "2026-02-18 13:48:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69p5j0",
          "author": "MaverickGuardian",
          "text": "I guess AI can be pair programmer but not for junior. Junior developer can't know yet which ideas are worth pursuing. AI will give list of common known solutions to similar problem. But it won't solve your specific problem. \n\nEven if you include performance and cost constraints or even approximate data amount in the system, usage pattern and everything. It still won't ask more details.\n\nWriting good specification is hard work.\n\nWe need to hire juniors so that they can learn. \n\nIt has been said many times before. AI is multiplier. You can multiple zero as much as you want. It's still zero.",
          "score": 1,
          "created_utc": "2026-02-19 16:55:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uh522",
          "author": "ALAS_POOR_YORICK_LOL",
          "text": "We're way past auto complete. It's 2026 man",
          "score": 0,
          "created_utc": "2026-02-17 10:59:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ua1j6",
          "author": "MrEs",
          "text": "I have better trade-off conversations with my Ai then my current team ðŸ˜¢",
          "score": 0,
          "created_utc": "2026-02-17 09:54:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5utsbm",
              "author": "va1en0k",
              "text": "definitely more patient and interested... notÂ  critical enough but at least helps with sustaining my own attention on a complex line of thoughtsÂ ",
              "score": 1,
              "created_utc": "2026-02-17 12:37:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ubeg0",
          "author": "thiem3",
          "text": "I get your point. But I also think it is about how you use it. You must be mindful to be a lot more inquisitive and explorative. You are correct it is not very pro active. It rarely  reflects upon what you tell it to do. It just does, and follows the existing pattern if possible. \n\nI demonstrated this with design patterns for my students. It kept just making the same \"dumb implementation\", when I asked it to expand the current code. \n\nBut once I started asking for feedback and other/better approaches, I got several options and could discuss pros and cons. But I (!) had to take control and keep exploring. It took a few tried before it suggested to apply the design pattern I had in mind, to the problem.\n\nIn this particular case, I knew what I wanted from the ai and could keep on until we arrived at the solution.\n\nIf I did not have the basic understanding of design, I might have stopped exploring too early.\n\nAt another time I had some issues with the current approach, but didn't know what to do about it. I was able to have a fairly informative discussion, and found a new approach, I had not thought of.\n\nBut it does put more responsibility on you, compared to human pair programming.",
          "score": 0,
          "created_utc": "2026-02-17 10:07:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uen2w",
          "author": "manuelhe",
          "text": "It will do all of that if you prompt it",
          "score": 0,
          "created_utc": "2026-02-17 10:37:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uy97j",
          "author": "failsafe-author",
          "text": "I havenâ€™t heard AI called paired programming, however, if you use it right it absolutely pushes back on approaches and all that other stuff.",
          "score": 0,
          "created_utc": "2026-02-17 13:06:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uen1f",
          "author": "veryspicypickle",
          "text": "Tell me about it",
          "score": -1,
          "created_utc": "2026-02-17 10:37:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}