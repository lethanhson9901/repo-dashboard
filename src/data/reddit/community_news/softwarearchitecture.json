{
  "metadata": {
    "last_updated": "2026-02-06 09:09:58",
    "time_filter": "week",
    "subreddit": "softwarearchitecture",
    "total_items": 20,
    "total_comments": 139,
    "file_size_bytes": 189031
  },
  "items": [
    {
      "id": "1qtw76q",
      "title": "We skipped system design patterns, and paid the price",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qtw76q/we_skipped_system_design_patterns_and_paid_the/",
      "author": "Icy_Screen3576",
      "created_utc": "2026-02-02 14:16:04",
      "score": 304,
      "num_comments": 41,
      "upvote_ratio": 0.97,
      "text": "We ran into something recently that made me rethink a system design decision while working on an event-driven architecture. We have multiple Kafka topics and worker services chained together, a kind of mini workflow.\n\n[Mini Workflow](https://preview.redd.it/fgm3nejx93hg1.png?width=3750&format=png&auto=webp&s=7965432a4731f2658c648475b1d90593a0f69282)\n\nThe entry point is a legacy system. It reads data from an integration database, builds a JSON file, and publishes the entire file directly into the first Kafka topic.\n\n# The problem\n\nOne day, some of those JSON files started exceeding Kafkaâ€™s default message size limit. Our first reaction was to ask the DevOps team to increase the Kafka size limit. It worked, but it felt similar to increasing a database connection pool size.\n\nThen one of the JSON files kept growing. At that point, the DevOps team pushed back on increasing the Kafka size limit any further, so the team decided to implement chunking logic inside the legacy system itself, splitting the file before sending it into Kafka.\n\nThat worked too, but now we had custom batching/chunking logic affecting the stability of an existing working system.\n\n# The solution\n\nWhile looking into system design patterns, I came across the Claim-Check pattern.\n\n[Claim-Check Pattern](https://preview.redd.it/3lmiy1t9a3hg1.png?width=3332&format=png&auto=webp&s=890aa3c5d542d979c9e7eb0d564dcfa576aa9276)\n\nInstead of batching inside the legacy system, the idea is to store the large payload in external storage, send only a small message with a reference, and let consumers fetch the payload only when they actually need it.\n\n# The realization\n\nWhat surprised me was realizing that simply looking into existing system design patterns could have saved us a lot of time building all of this.\n\nItâ€™s a good reminder to pause and check those patterns when making system design decisions, instead of immediately implementing the first idea that comes to mind.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qtw76q/we_skipped_system_design_patterns_and_paid_the/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o35sph1",
          "author": "Estel-3032",
          "text": "I remember that in my first job one of the other engineers said 'so let's check what kind of wheels people are using out there before we start inventing our own' to a roughly similar situation and it stuck with me.",
          "score": 115,
          "created_utc": "2026-02-02 14:33:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35yybb",
              "author": "Icy_Screen3576",
              "text": "Sounds like a pragmatic engineer.",
              "score": 26,
              "created_utc": "2026-02-02 15:05:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o363lmg",
          "author": "czlowiek4888",
          "text": "Yeah, this is exactly what you should do.\n\nDon't treat messages in your system as a data storage ( it is convenient though ) but more like notifications.\n\nYou just want to send event telling you what happened, not necessarily why, how, where and when. All those other information you should get on your own from database or other storage when you think it's necessary.\n\nIn real time system you usually want to have each message under ~1.4kb this is the frame size in which your messages are send over the network.\n\nBecause if you need to pass larger messages you will need wait for the all other frames that together create single message.\n\nThis way if you send only 1 frame you can go crazy fast.\n\nAlso Kafka uses stores messages to be replied when necessary, you will be able to store more messages.\n\nYou also may want to think about private replies of messages. For example you have service that receives http request, you send event and await other in response. You need to know how to send a response event to the instance of app that holds http socket file to be able to respond to the http request with the event data.\n\nIt's a bit more advanced but it is what many event driven systems need.",
          "score": 24,
          "created_utc": "2026-02-02 15:28:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36bjxc",
              "author": "Icy_Screen3576",
              "text": "Well said. Keeping messages small and event-focused made things a lot simpler.",
              "score": 4,
              "created_utc": "2026-02-02 16:06:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3663cp",
          "author": "bigkahuna1uk",
          "text": "I think everyone should read [Enterprise Integration Patterns](https://www.enterpriseintegrationpatterns.com/patterns/messaging/toc.html) by Gregor Hophe  .\n\nOver 20 years old but still highly relevant today.",
          "score": 39,
          "created_utc": "2026-02-02 15:40:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3694rz",
              "author": "bobaduk",
              "text": "Came here to say exactly this. IIRC the patterns are all described online, so you can skim and get a vague sense, then go back to look deeper when you need something.\n\nMessaging patterns have been established for a long time, and it's worth being familiar with the prior art.",
              "score": 7,
              "created_utc": "2026-02-02 15:54:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o369oto",
              "author": "Icy_Screen3576",
              "text": "Thanks for sharing!",
              "score": 2,
              "created_utc": "2026-02-02 15:57:19",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3bmq78",
              "author": "garden_variety_sp",
              "text": "And every pattern has been implemented by Apache Camel, the GOAT of integration frameworks. And 100% free and open source.",
              "score": 1,
              "created_utc": "2026-02-03 11:07:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o35qx62",
          "author": "AzureMate",
          "text": "Clever! Thanks for sharing!",
          "score": 16,
          "created_utc": "2026-02-02 14:24:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35uopk",
              "author": "Icy_Screen3576",
              "text": "You are welcome! Glad it helped.",
              "score": 1,
              "created_utc": "2026-02-02 14:43:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o363xwc",
          "author": "tesseraphim",
          "text": "It worked, the system kept chugging for quite some time. That's a win. It could have worked for 10 years, some systems do. The question is, how much change you needed to do. Trick is not to build up front, but make sure the seams are there so you can easily change.",
          "score": 7,
          "created_utc": "2026-02-02 15:30:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35y599",
          "author": "Few_Wallaby_9128",
          "text": "It does come at a price, right? an extra single point of failure, extra latency, possible network failures and managament (dns/cert renewals/fws), and logic to handle the lifecycle, synchronization and deletion of the data in the storage. If the growing json was the problem, dynamic zipping of it could have worked wonders at a fraction of the total cost of maintenance.",
          "score": 13,
          "created_utc": "2026-02-02 15:01:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35zedo",
              "author": "europeanputin",
              "text": "Software engineering is always full of trade-offs. I have a non-fixed size JSONs, but due to compliance reasons there's no way that they could be pulled on-demand, and I simply have to store them all, regardless of their size. Some documents are about the size of 10mb after doing the compression.",
              "score": 13,
              "created_utc": "2026-02-02 15:08:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o364msa",
              "author": "czlowiek4888",
              "text": "You shouldn't think about it as a trade off.\nThis is the one and only correct way.\n\nSending events with the data is anti pattern imho.\nWhat if you want to add CQRS and you regenerate your state from commands?\nAnd now data you hold in your messages is no longer valid because it was changed how app processes things so your message as a storage approach make you not able to perform state regeneration.",
              "score": 4,
              "created_utc": "2026-02-02 15:33:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3650bk",
                  "author": "czlowiek4888",
                  "text": "Also what if your messages store personal information that you are obligated to remove in certain situations.\nYou will be deleting messages and this will lead to inability to regenerate state as disaster recovery mechanism.",
                  "score": 3,
                  "created_utc": "2026-02-02 15:35:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o38r9ib",
                  "author": "pins17",
                  "text": "For OP's scenario I agree. But in general it really depends on the use case.\n\nFor example, in high-frequency scenarios like price updates on energy or commodity markets, it is standard practice to include the market data directly in the event. That is the whole point. Doing a lookup for every event would introduce unacceptable latency and massive load on the source system. The same applies to telemetry data in fleet management.\n\nClaim Check has its merits, as you mentioned, but it also has downsides. While the producer is free from temporal/runtime coupling, the consumer is not, which negates one of the main benefits of asynchronous architecture.",
                  "score": 2,
                  "created_utc": "2026-02-02 22:56:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35s577",
          "author": "cstopher89",
          "text": "This is a nice pattern. I use it for Azure Service Bus messages to handle large payloads.",
          "score": 2,
          "created_utc": "2026-02-02 14:30:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35w6va",
              "author": "Icy_Screen3576",
              "text": "In our case it was an on-prem Kafka broker, with the payload in external storage. Do you usually pair Service Bus with Blob Storage for this?",
              "score": 2,
              "created_utc": "2026-02-02 14:51:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o37zfxv",
                  "author": "01acidburn",
                  "text": "Yep",
                  "score": 1,
                  "created_utc": "2026-02-02 20:42:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o38qc8h",
                  "author": "cstopher89",
                  "text": "Yeah blob storage works well for this",
                  "score": 1,
                  "created_utc": "2026-02-02 22:51:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o36mkf6",
          "author": "nt2g",
          "text": "Great post and great reminder, thank you for sharing!",
          "score": 2,
          "created_utc": "2026-02-02 16:56:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37a0ej",
          "author": "dukemanh",
          "text": "question: what will happen and what should we do if the tiny message already arrived at the consumer but the large payload is not yet available on the file storage?",
          "score": 2,
          "created_utc": "2026-02-02 18:43:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37x2tn",
              "author": "Primary-Juice-4888",
              "text": "Consumer - retry message processing until file is available, perhaps with exponential backoff.\n\nor\n\nProducer - only send a message after the storage write was confirmed.",
              "score": 7,
              "created_utc": "2026-02-02 20:30:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3bmwkd",
          "author": "garden_variety_sp",
          "text": "Did you consider using a more compact wire format like Avro or Protobuf?",
          "score": 2,
          "created_utc": "2026-02-03 11:08:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c3yre",
              "author": "Icy_Screen3576",
              "text": "Considered avro, still we would be pushing in the wrong direction. Thinking in tiny events made things simpler. I dont think message brokers are made for large payloads.",
              "score": 1,
              "created_utc": "2026-02-03 13:13:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o36raxr",
          "author": "Samrit_buildss",
          "text": "Really nice write-up. The claim-check pattern here is a great reminder that many scaling problems already have well-known solutions we just forget to look for them under pressure.",
          "score": 4,
          "created_utc": "2026-02-02 17:18:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35utna",
          "author": "Constant_Physics8504",
          "text": "Couldâ€™ve been turned into a Dispatch system with MQ quite easily",
          "score": 1,
          "created_utc": "2026-02-02 14:44:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o363d0a",
              "author": "Icy_Screen3576",
              "text": "Yep, we only use claim-check for large payloads. Most messages go through the message broker.",
              "score": 3,
              "created_utc": "2026-02-02 15:27:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o37gnoz",
          "author": "bunsenhoneydew007",
          "text": "We use the claim check pattern extensively on a similar workflow like system. It works extremely well and allows the payload to be agnostic to the event transfer mechanism, which can provide other benefits regarding data processing in the services. (We use eventbridge rather than Kafka).",
          "score": 1,
          "created_utc": "2026-02-02 19:13:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37ktml",
          "author": "Careless-Childhood66",
          "text": "Amen",
          "score": 1,
          "created_utc": "2026-02-02 19:33:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o38o6pt",
          "author": "ErgodicMage",
          "text": "I develop distrubuted workflow systems and use Claims all the time.",
          "score": 1,
          "created_utc": "2026-02-02 22:40:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hhofa",
          "author": "Mean_Helicopter_2913",
          "text": "Ngl skipping design patterns can save time upfront but ends up costing you later.  tbh, having that extra layer of abstraction and modularity would have made debugging and scaling much easier.",
          "score": 1,
          "created_utc": "2026-02-04 06:10:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3p0880",
          "author": "blocked909",
          "text": "Learnt something new as a novice",
          "score": 1,
          "created_utc": "2026-02-05 10:26:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3p4hqk",
              "author": "Icy_Screen3576",
              "text": "Great",
              "score": 1,
              "created_utc": "2026-02-05 11:05:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3s16co",
          "author": "ConcreteExist",
          "text": "The service bus I've been integrating with works exactly like the example there, the only payload in the message is a file path to the stored xml file that can then be retrieved from blob storage and parsed accordingly.",
          "score": 1,
          "created_utc": "2026-02-05 20:15:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3v825n",
              "author": "Icy_Screen3576",
              "text": "https://preview.redd.it/varzr7p4zthg1.png?width=3257&format=png&auto=webp&s=4df3323efb38acf780e4084dbabed100b1e050e7\n\nSimilar to that?",
              "score": 1,
              "created_utc": "2026-02-06 07:59:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3mzlai",
          "author": "Dangerous-Sale3243",
          "text": "This seems pretty obvious to me and i would imagine itâ€™s the first thing google or an LLM would tell you to do. Maybe because the dev team doesnt feel they own the infrastructure, they think they need to use software to solve problems with infrastructure is the answer.",
          "score": 0,
          "created_utc": "2026-02-05 01:22:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3osf30",
              "author": "Icy_Screen3576",
              "text": "Not owning the infra is a good catch. I would be hesitant to trust the ai on such matters.",
              "score": 1,
              "created_utc": "2026-02-05 09:11:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qsz7w5",
      "title": "[META] AI generated posts are no longer allowed",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qsz7w5/meta_ai_generated_posts_are_no_longer_allowed/",
      "author": "asdfdelta",
      "created_utc": "2026-02-01 14:01:24",
      "score": 161,
      "num_comments": 15,
      "upvote_ratio": 0.97,
      "text": "Following the poll that was posted last week, the community has overwhelmingly voted to remove any kind of post or comment that we clearly generated by AI.\n\nPosts and comments can now be reported for AI generated text, and will be removed as I see the reports or posts. **Please report what you see!**\n\nThis rule applies to all posts and comments following the timestamp of this one, it will not retroactively affect any content on the sub.\n\nAdvice for those that wish to use AI to translate or inprove English as it is not your first language: write the overall structure of your post yourself and let an AI tool like Grammarly's inline capabilities (free) to improve the sentence structure and word choice. This has been around for a long time and continues to get better. Fully generating your posts will result in removal, repeat offenders will be banned. I'm open to pinning a post that has a list of good alternatives if we can crowdsource it from experience.\n\nThank you to everyone who voted in the poll! Keeping the sub healthy takes everyone's effort. Thank you especially for those that called for mod action, they spurred this new rule into existence.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qsz7w5/meta_ai_generated_posts_are_no_longer_allowed/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o2z2krn",
          "author": "bobaduk",
          "text": "Delighted to see this, personally. If I want ChatGPTs output, I'll ask for it myself.",
          "score": 44,
          "created_utc": "2026-02-01 14:23:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o315oo0",
          "author": "tomByrer",
          "text": "I 100% agree, but I'm also wondering about the folks who don't speak English, & have to use a translator to communicate....",
          "score": 7,
          "created_utc": "2026-02-01 20:17:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o31du5v",
              "author": "asdfdelta",
              "text": "I am as well. If you know of any methods that can be used or tools that won't write 100% of the post, please let me know.",
              "score": 2,
              "created_utc": "2026-02-01 20:57:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2zbsa8",
          "author": "CompetitiveProof3078",
          "text": "Great news",
          "score": 6,
          "created_utc": "2026-02-01 15:12:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o31vu29",
          "author": "donz0r",
          "text": "Does the rule apply to comments as well?",
          "score": 3,
          "created_utc": "2026-02-01 22:25:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35hg1p",
              "author": "asdfdelta",
              "text": "Yes! But the timestamp must be after this post was published.",
              "score": 2,
              "created_utc": "2026-02-02 13:31:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o326zgr",
          "author": "UnreasonableEconomy",
          "text": "Regarding translation: I think the problem isn't translation, but generation. Specifically, people using \"translation\" and ESL as a moral mask for generated content.\n\nThis is just an idea, and I don't know how good it is - but perhaps allowing translation with any tool, including chatgpt - would be acceptable, as long as the OP includes the original as a comment.",
          "score": 3,
          "created_utc": "2026-02-01 23:24:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35htwf",
              "author": "asdfdelta",
              "text": "That might be a good idea, I'll add it to the list of possibilities. Thank you!",
              "score": 3,
              "created_utc": "2026-02-02 13:33:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2z41sm",
          "author": "IlliterateJedi",
          "text": "Disappointing.  Reporting all the AI posts on here gave me something to do during my daily ablutions every morning.",
          "score": 10,
          "created_utc": "2026-02-01 14:32:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2z8k0u",
              "author": "uusu",
              "text": "That's literally what OP is asking us to do. You can't 100% be certain a post is AI generated, so the report helps you know whether the community is okay with removing a post.\n\nAdditionally, now your reporting actually has an effect thanks to this rule.",
              "score": 9,
              "created_utc": "2026-02-01 14:56:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o30f4ag",
          "author": "wjrasmussen",
          "text": "I appreciate that we are going this direction.  Brought to you by Carl's Jr.",
          "score": 4,
          "created_utc": "2026-02-01 18:14:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o31e7l3",
              "author": "asdfdelta",
              "text": "I can't bring myself to rewatch Idiocracy anymore, it's just too much ðŸ˜‚",
              "score": 6,
              "created_utc": "2026-02-01 20:59:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o300jvn",
          "author": "Gunny2862",
          "text": "Amen.",
          "score": 1,
          "created_utc": "2026-02-01 17:08:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o30jzkf",
          "author": "777ortale",
          "text": "Nice! Beep boop.",
          "score": 1,
          "created_utc": "2026-02-01 18:36:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qv07p2",
      "title": "At what scale does \"just use postgres\" stop being good architecture advice?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qv07p2/at_what_scale_does_just_use_postgres_stop_being/",
      "author": "Designer-Jacket-5111",
      "created_utc": "2026-02-03 18:38:02",
      "score": 95,
      "num_comments": 38,
      "upvote_ratio": 0.93,
      "text": "Every architecture discussion I see ends with someone saying \"just use postgres\" and honestly theyre usually right. Postgres handles way more than people think, JSON columns, full text search, pub/sub, time series data, you name it.\n\nBut there has to be a breaking point where adding more postgres features becomes worse than using purpose-built tools. When does that happen? 10k requests per second? 1 million records? 100 concurrent writers?\n\nIve seen companies scale to billions of records on postgres and Ive seen companies break at 10 million. Ive seen people using postgres as a message queue successfully and Ive seen it be a disaster.\n\nWhat determines when specialized tools become necessary? Is it always just \"when postgres becomes the bottleneck\" or are there other architectural reasons?",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qv07p2/at_what_scale_does_just_use_postgres_stop_being/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o3dyu5h",
          "author": "Sea_Weather5428",
          "text": "the breaking point for me is when the postgres-specific workarounds start taking more time than learning a purpose-built tool would, like when your jsonb queries start needing 47 indexes",
          "score": 89,
          "created_utc": "2026-02-03 18:39:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3e9zq8",
              "author": "sfboots",
              "text": "We stay away from indexes on the Jsonb content and copy a few items to regular columns for indexing",
              "score": 33,
              "created_utc": "2026-02-03 19:30:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3khdoy",
                  "author": "its_k1llsh0t",
                  "text": "We do a mix of both. Index where return speed is less important, then normalize for things where performance is more important. ",
                  "score": 1,
                  "created_utc": "2026-02-04 17:53:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3e15qs",
              "author": "ilya47",
              "text": "And when you learn about TOASTs due to jsonb.",
              "score": 13,
              "created_utc": "2026-02-03 18:49:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3gnuke",
                  "author": "clearing_",
                  "text": "giving me ptsd to when we hit the OID limit while i was at a concert",
                  "score": 3,
                  "created_utc": "2026-02-04 02:51:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3dzqtl",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 30,
          "created_utc": "2026-02-03 18:43:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3epfd9",
              "author": "InfluxCole",
              "text": "I think there's also some cost efficiency to worry about as scale goes up. Once you're running up huge monthly bills, it's not that you necessarily couldn't keep going with Postgres, but you could probably save some money by moving to something more tailor-made for the characteristics of your workload. When you reach that, \"this is getting expensive, maybe something more specific would give us the performance we need for cheaper,\" point still heavily depends on your company, budget, team size, etc.",
              "score": 7,
              "created_utc": "2026-02-03 20:43:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3eou27",
          "author": "polotek",
          "text": "We had a ruby on rails system with postgres that scaled to 10 billion rows in some tables and still maintained high request throughout. The problem isn't scaling postgres. It's not easy, but it can go way further than most people will ever need. It depends on the complexity of what you're doing and your level of expertise with postgres.\n\nWhat comes after \"just use postgres\" is \"hire some postgres consultants to help you out and keep going\". In general you should only need to reach for a specialized datastore for services that have very specific data access requirements. And still it should be after you tried postgres first.",
          "score": 26,
          "created_utc": "2026-02-03 20:40:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dysgx",
          "author": "Select-Print-9506",
          "text": "its almost never about raw scale, its about operational complexity and team expertise, postgres can handle way more than most companies need if you tune it properly",
          "score": 39,
          "created_utc": "2026-02-03 18:39:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3i6ufy",
              "author": "bobaduk",
              "text": "This is the key point. I haven't deployed a relational database in a good long time, because I can get better operational characteristics from other datastores. If I spin up dynamo, chances are that for the way I build software, it'll be fine, and the answer to \"is it up, it is coping with the load\" is yes and move on.\n\nWe were using postgres for a while at $CURRENT_GIG, but for our use case the cost curve was unappealing, particularly when every engineer has a cloud environment of their own to play with, and it was cheaper to adopt a managed time series data store.",
              "score": 2,
              "created_utc": "2026-02-04 09:58:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3eftyi",
          "author": "External_Mushroom115",
          "text": "When your domain needs to scale writes  rather than reads.",
          "score": 8,
          "created_utc": "2026-02-03 19:58:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e3pga",
          "author": "who_am_i_to_say_so",
          "text": "There is no set number. Sometimes 1 million rows it will start performing like a dog- sometimes itâ€™s 20 million rows. \n\nBut a general indicator is if you hit your max connections regularly even with upsizing and pooling (scaling vertically). Then you look into caching, perhaps- or the more expensive option of scaling horizontally.",
          "score": 17,
          "created_utc": "2026-02-03 19:01:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3e88dw",
              "author": "sfboots",
              "text": "Max connections can be misleading if they are not using pgbouncer",
              "score": 8,
              "created_utc": "2026-02-03 19:22:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3eyqx7",
              "author": "Typicalusrname",
              "text": "If Postgres performs like a dog with a million records the data model is shit",
              "score": 8,
              "created_utc": "2026-02-03 21:26:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ezlti",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": -2,
                  "created_utc": "2026-02-03 21:30:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3f143t",
              "author": "Apart-Entertainer-25",
              "text": "Have you tried not running it on a toaster? :)",
              "score": 3,
              "created_utc": "2026-02-03 21:37:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3f24zk",
                  "author": "who_am_i_to_say_so",
                  "text": "Relatedly there's this: [https://www.crunchydata.com/blog/postgres-toast-the-greatest-thing-since-sliced-bread](https://www.crunchydata.com/blog/postgres-toast-the-greatest-thing-since-sliced-bread)",
                  "score": 4,
                  "created_utc": "2026-02-03 21:42:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3dyvm0",
          "author": "Select-Print-9506",
          "text": "same applies to api management honestly, you can build everything custom on top of nginx or envoy but at some point using something like gravitee or kong saves you from reinventing wheels that dont need reinventing",
          "score": 15,
          "created_utc": "2026-02-03 18:39:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e9ai4",
          "author": "sfboots",
          "text": "The limit depends heavily on workload and total IO needs assuming correct code and indexes\n\nAlso, some companies stay with Postgres and just use extensions like timescale or move some functions to a different database. \n\nMy company has 3 tables with more than a billion total rows and performance is adequate.  We do partition by time ranges since most use is the last year.",
          "score": 5,
          "created_utc": "2026-02-03 19:27:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e888l",
          "author": "mountainlifa",
          "text": "I've always wondered this. And when do folks introduce key pair database systems like dynamo into their architecture?Â ",
          "score": 5,
          "created_utc": "2026-02-03 19:22:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ebfp8",
          "author": "awol-owl",
          "text": "Never, yet at work this week weâ€™re moving to Elasticsearch as our prototype showed it to be a search friendly service. I believe itâ€™ll use more ram to run the new cluster, although Iâ€™m hoping the developer experience will be worth it. Iâ€™m not convinced yet.",
          "score": 3,
          "created_utc": "2026-02-03 19:37:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e3q9q",
          "author": "pgEdge_Postgres",
          "text": "Oftentimes it's not even the specialized tools that you need, just a tuned configuration and some good insights into your stack! Metrics go a long way towards predicting failures or reacting quickly when they do happen; take the lessons learned and turn them into actual architectural changes, and you can iterate up to those instances of billions of records.\n\nRelated interesting article: [https://openai.com/index/scaling-postgresql/](https://openai.com/index/scaling-postgresql/) if you missed it, OpenAI scaled PostgreSQL to power 800 million ChatGPT users; it powers both ChatGPT and OpenAI's API.",
          "score": 3,
          "created_utc": "2026-02-03 19:01:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3lra5t",
              "author": "caught_in_a_landslid",
              "text": "The article is fairly clear that they are not allowing new tables any more and they are using cosmosdb for new things.\n\nIt shows that you can indeed push PG really far, but there's a real reason that other databases Exsist.",
              "score": 1,
              "created_utc": "2026-02-04 21:27:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3eivyi",
          "author": "WilliamBarnhill",
          "text": "If you aren't doing rapid prototyping, I'd argue at any scale. You need to be able to articulate to stakeholders what your technology selection candidates were, what the tradeoffs were between them, your rationale for choosing the technology you did, and potential future risks as a result. Sometimes time-to-market is the overwhelming driver, but even then you need to be able to answer 'Why will using Postgres get us there faster, and what problems might we face down the road?'.",
          "score": 2,
          "created_utc": "2026-02-03 20:12:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3f4792",
          "author": "swithek",
          "text": "I once inherited a system that used postgres to store massive json blobs, with a bit of metadata kept in separate indexed columns for filtering. The production database contained nearly a petabyte of data (hundreds of millions of rows) and the queries were painfully slow so I think itâ€™s fair to say postgres wasnâ€™t exactly an ideal choice here",
          "score": 2,
          "created_utc": "2026-02-03 21:51:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ivbmz",
              "author": "bomeki12345678",
              "text": "I'm curious, for your usecase, what dbms is the ideal choice? Saving massive json blobs in a relational databases seems to be not optimal option for me.",
              "score": 1,
              "created_utc": "2026-02-04 13:09:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3n0vwt",
                  "author": "shoot2thr1ll284",
                  "text": "I agree with you. \n\nIn this case it seems like they chose Postgres for convenience of having everything in one spot, but large json blobs are not great for most systems. Depending on the use case a document store could work better in this case, but honestly I would treat those large json as files and use a different file serving service like s3 and just keep the url to it on Postgres or in another service. Makes it so that the thing that searches isnâ€™t also responsible for the large amount of data transfer. At some point it just becomes networking and io speed limitationsâ€¦.",
                  "score": 1,
                  "created_utc": "2026-02-05 01:29:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3hht0v",
          "author": "kmhosny",
          "text": "OpenAI wrote a post about how they use postgres to serve 800 million customers. https://openai.com/index/scaling-postgresql/\nNot every company is on openAi scale so in 90% of the cases there are optimization steps that can be taken to keep just usibg postgres",
          "score": 2,
          "created_utc": "2026-02-04 06:11:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eqjob",
          "author": "truechange",
          "text": "When vertical scaling can be solved by offloaded cached data.",
          "score": 1,
          "created_utc": "2026-02-03 20:48:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3exq6q",
          "author": "lambdasintheoutfield",
          "text": "You can do vertical or horizontal sharding which allows you to scale the database extremely effectively.\n\nHorizontal sharding is partitioning a table into more tables with the same exact schema but fewer rows and then an index to track the partitioning/shards. If your queries require large scans of values, this works well and there are numerous partitioning schemes to pick.\n\nVertical sharding is where you partition on columns. If you are specifically querying for data in column subsets, you could just have dedicated tables for those.\n\nItâ€™s likely both would be helpful, and both reduce storage space. Be careful of your primary keys and indices but this is enormously effective when done right. \n\nIt isnâ€™t too difficult to roll your own postgres orchestrator across multiple nodes. \n\nAll that said, anytime you go distributed, you have to consider HA and fault tolerance. If you are querying a subset of rows on a node that goes down you obviously wonâ€™t be getting the data unless you replicate it.\n\nIf you know your access patterns, the critical and/or most frequently accessed data can use a higher replication factor and if a node goes down just route to the replicas. The architecture of your nodes can be a tree structure where each node is a shard and the leaf nodes are the replicas. Use this to inform the load balancer and query routing.",
          "score": 1,
          "created_utc": "2026-02-03 21:21:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gb452",
          "author": "Wiszcz",
          "text": "When cost of working around it's cons is higher than restructuring project.",
          "score": 1,
          "created_utc": "2026-02-04 01:39:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3grob5",
          "author": "dudeaciously",
          "text": "How does this group feel about concurrent transactions, with critical commit and rollback requirements.  Lots of connections. Then there is a breakage. Does coming back online break data integrity?  \n\nIf so, then the metrics on concurrent users, with operations per transaction would answer OP.",
          "score": 1,
          "created_utc": "2026-02-04 03:13:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3jo12a",
              "author": "SpamapS",
              "text": "Yes it comes back consistently, but it can be really slow. You're going to need a hot standby logically replicated to have a chance at your database being online more than 3 nines in this scenario.",
              "score": 1,
              "created_utc": "2026-02-04 15:38:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3k68pl",
                  "author": "dudeaciously",
                  "text": "Ah!  So to preserve data integrity in the whole database, replicate the nodes implicitly?  Not only after disaster recovery, but propagation for every committed transaction.\n\nVery cool.  No disagreements.  But I this is heavy, I have never done it.",
                  "score": 1,
                  "created_utc": "2026-02-04 17:02:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3jjmmm",
          "author": "andras_gerlits",
          "text": "Scale is rarely the bottleneck. It's usually replication and high-availability.",
          "score": 1,
          "created_utc": "2026-02-04 15:17:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3jnlav",
          "author": "SpamapS",
          "text": "It's more that some features scale better than others, so you can keep using the core, but you'll find that stuff that made it easy to build on top of at low scale becomes too expensive at a higher scale.\n\nForeign keys and sub transactions start to become a burden with high concurrency for insurance due to multi transaction shared locks that scale quadratically. You start needing to avoid those at some point.\n\nLarge payloads eventually need to be moved to external object storage or you'll destroy memory usage.\n\nThe real point when postgres can't do it alone is around 4 nines. When you need more than 3 nines really, it's just  complicated to do that with postgres and you'll find some other architecture like a NoSQL or sharding layer like CitusDB will make it simpler.",
          "score": 1,
          "created_utc": "2026-02-04 15:36:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ll2br",
          "author": "TallGreenhouseGuy",
          "text": "If youâ€™re used to partitioning using Oracle, the Postgres way is just painful to work with.\n\nSo having large tables that you want to partition is quite an ordeal if you want to do range based partitioning using eg date and there are foreign keys/primary keys that are not naturally a part of the partition key.",
          "score": 1,
          "created_utc": "2026-02-04 20:57:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qsqft5",
      "title": "Architecture for beginners",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qsqft5/architecture_for_beginners/",
      "author": "EviliestBuckle",
      "created_utc": "2026-02-01 06:05:06",
      "score": 87,
      "num_comments": 42,
      "upvote_ratio": 0.99,
      "text": "Are there any recommended resources for beginners to study and understand and start their journey towards software architects?\n\nBackground: worded in frontend and backend with just basic crud api\n\nExperience: 4yrs but afraid to have a repeated 1 year of experience for four years. Need to justify my experience after 10 years",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qsqft5/architecture_for_beginners/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o2xdkiw",
          "author": "coffeemahn",
          "text": "Books\n\nDesigning Data Intensive Applications,\nSoftware Architecture the hard parts\n\nEdit: added comma",
          "score": 46,
          "created_utc": "2026-02-01 06:06:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xgqry",
              "author": "EviliestBuckle",
              "text": "Is there any practical application resources on these?",
              "score": 3,
              "created_utc": "2026-02-01 06:32:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3i8adn",
                  "author": "Icy_Screen3576",
                  "text": "Not much practical resources out there. I built it myself. Happy to share if you want.",
                  "score": 1,
                  "created_utc": "2026-02-04 10:12:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2y87dl",
              "author": "httpgo",
              "text": "/u/BookFinderBot",
              "score": 1,
              "created_utc": "2026-02-01 10:43:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2y8ato",
                  "author": "BookFinderBot",
                  "text": "**Designing Data Intensive Applications for Modern Systems Principles, Trade-Offs, and Architectures for Reliable and Scalable Data Platforms** by Zeon Aric\n\n\n>Designing modern data platforms is not about finding perfect solutions-it is about understanding trade-offs. Every architectural decision affects consistency, latency, fault tolerance, complexity, and compliance in ways that are rarely obvious at first glance. Designing Data-Intensive Applications for Modern Systems takes a system-level view of data architecture, guiding readers through the principles that underpin today's distributed databases, streaming platforms, and analytics systems. Building on core concepts, this volume examines how large-scale systems are structured, why they fail, and how they evolve over time.\n>\n>The book explores consistency models, distributed coordination, event-driven architectures, and data governance concerns such as privacy and regulatory compliance. Readers will gain the tools to evaluate architectural options, reason about failure modes, and design platforms that balance performance with operational simplicity. Aimed at senior engineers, technical leads, and system architects, this volume provides the architectural insight needed to design data-intensive systems that are resilient, scalable, and prepared for future growth.\n\n\n**Software Architecture: The Hard Parts** by Neal Ford, Mark Richards, Pramod Sadalage, Zhamak Dehghani\n\n\n>There are no easy decisions in software architecture. Instead, there are many hard parts--difficult problems or issues with no best practices--that force you to choose among various compromises. With this book, you'll learn how to think critically about the trade-offs involved with distributed architectures. Architecture veterans and practicing consultants Neal Ford, Mark Richards, Pramod Sadalage, and Zhamak Dehghani discuss strategies for choosing an appropriate architecture.\n>\n>By interweaving a story about a fictional group of technology professionals--the Sysops Squad--they examine everything from how to determine service granularity, manage workflows and orchestration, manage and decouple contracts, and manage distributed transactions to how to optimize operational characteristics, such as scalability, elasticity, and performance. By focusing on commonly asked questions, this book provides techniques to help you discover and weigh the trade-offs as you confront the issues you face as an architect. Analyze trade-offs and effectively document your decisions Make better decisions regarding service granularity Understand the complexities of breaking apart monolithic applications Manage and decouple contracts between services Handle data in a highly distributed architecture Learn patterns to manage workflow and transactions when breaking apart applications\n\n\n*I'm a bot, built by your friendly reddit developers at* /r/ProgrammingPals. *Reply to any comment with /u/BookFinderBot - I'll reply with book information. If I have made a mistake, accept my apology.*",
                  "score": 2,
                  "created_utc": "2026-02-01 10:44:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2xezyq",
              "author": "EviliestBuckle",
              "text": "Okokokok.",
              "score": 1,
              "created_utc": "2026-02-01 06:17:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2xp8jl",
                  "author": "GMKrey",
                  "text": "Btw â€œSoftware Architecture: The Hard Partsâ€ is actually a sequel. Thereâ€™s a fundamentals book you should read first\n\nEdit: Since people are asking, this is the first book https://a.co/d/gyilGiK (Amazon)\n\nThe authors talk about how they basically tried to bucket architectural patterns by difficulty. Anything that they felt was too much for their first book got placed into a separate pile. Later making â€œThe Hard Partsâ€. More detail on their rational are in the first bits of the sequel",
                  "score": 9,
                  "created_utc": "2026-02-01 07:47:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2xls2d",
          "author": "MatchLittle5000",
          "text": "I would advise these books:\n\n1. Clean Architecture.\n2. Designing Data Intensive Applications.\n3. Learning Domain Driven Design (good intro).\n4. And some book describing how to operate on Staff+ roles effectively.",
          "score": 10,
          "created_utc": "2026-02-01 07:16:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ya6q7",
              "author": "MatchLittle5000",
              "text": "Plus these books which are a level higher:\n\n5. Building Microservices: Designing Fine Grained Systems\n\n6. Refactoring by Martin Fowler\n\n7. Patterns of Enterprise Application Architecture\n\n8. Implementing Domain Driven Design \n\n9. Test Driven Development by Example",
              "score": 8,
              "created_utc": "2026-02-01 11:01:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2y4l6m",
              "author": "e__NV__y",
              "text": "Can you name some books for (4)",
              "score": 2,
              "created_utc": "2026-02-01 10:10:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2y5fhy",
                  "author": "MatchLittle5000",
                  "text": "This one: https://staffeng.com/book/",
                  "score": 2,
                  "created_utc": "2026-02-01 10:17:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2y8k2t",
              "author": "httpgo",
              "text": "/u/BookFinderBot",
              "score": 1,
              "created_utc": "2026-02-01 10:46:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2y8ox9",
                  "author": "BookFinderBot",
                  "text": "**Clean Architecture A Craftsman's Guide to Software Structure and Design** by Robert C. Martin\n\n\n>Practical Software Architecture Solutions from the Legendary Robert C. Martin (â€œUncle Bobâ€) By applying universal rules of software architecture, you can dramatically improve developer productivity throughout the life of any software system. Now, building upon the success of his best-selling books Clean Code and The Clean Coder, legendary software craftsman Robert C. Martin (â€œUncle Bobâ€) reveals those rules and helps you apply them. Martinâ€™s Clean Architecture doesnâ€™t merely present options. Drawing on over a half-century of experience in software environments of every imaginable type, Martin tells you what choices to make and why they are critical to your success.\n>\n>As youâ€™ve come to expect from Uncle Bob, this book is packed with direct, no-nonsense solutions for the real challenges youâ€™ll faceâ€“the ones that will make or break your projects. Learn what software architects need to achieveâ€“and core disciplines and practices for achieving it Master essential software design principles for addressing function, component separation, and data management See how programming paradigms impose discipline by restricting what developers can do Understand whatâ€™s critically important and whatâ€™s merely a â€œdetailâ€ Implement optimal, high-level structures for web, database, thick-client, console, and embedded applications Define appropriate boundaries and layers, and organize components and services See why designs and architectures go wrong, and how to prevent (or fix) these failures Clean Architecture is essential reading for every current or aspiring software architect, systems analyst, system designer, and software managerâ€“and for every programmer who must execute someone elseâ€™s designs. Register your product for convenient access to downloads, updates, and/or corrections as they become available.\n\n\n**Designing Data Intensive Applications for Modern Systems Principles, Trade-Offs, and Architectures for Reliable and Scalable Data Platforms** by Zeon Aric\n\n\n>Designing modern data platforms is not about finding perfect solutions-it is about understanding trade-offs. Every architectural decision affects consistency, latency, fault tolerance, complexity, and compliance in ways that are rarely obvious at first glance. Designing Data-Intensive Applications for Modern Systems takes a system-level view of data architecture, guiding readers through the principles that underpin today's distributed databases, streaming platforms, and analytics systems. Building on core concepts, this volume examines how large-scale systems are structured, why they fail, and how they evolve over time.\n>\n>The book explores consistency models, distributed coordination, event-driven architectures, and data governance concerns such as privacy and regulatory compliance. Readers will gain the tools to evaluate architectural options, reason about failure modes, and design platforms that balance performance with operational simplicity. Aimed at senior engineers, technical leads, and system architects, this volume provides the architectural insight needed to design data-intensive systems that are resilient, scalable, and prepared for future growth.\n\n\n**Learning Domain-Driven Design Aligning Software Architecture and Business Strategy** by Vladik Khononov\n\n\n>Today, more than ever, building software is hard. Not only we have to chase ever-changing technological trends, but we also have to grasp business domains that we are building the software for. The latter is often overseen, and it explains why so many projects are doomed to fail. After all, how can you build a solution if you don't understand the problem?\n>\n>Through this book, you will learn the Domain-Driven Design (DDD) methodology which provides a set of core patterns, principles, and practices for analyzing business domains, understanding business strategy, and, most importantly, aligning software design with its business needs. These include Ubiquitous Language, Bounded Contexts, Event Storming, and others. You will see how these practices not only lead to robust implementation of business logic, but also to future-proof software design and architecture. You will also learn the relationship between DDD and other methodologies to ensure that you are able to make architectural decisions that will meet the business needs.\n>\n>The final section puts all of this into practice using a real life story of implementing Domain-Driven Design in a startup company. Reading the book will allow you to use DDD for analyzing business domains, aligning software and business strategies, and making socio-technical design decisions. By the end of this book, you will be able to:-Build a shared understanding of a business domain-Analyze a company's business domain and competitive strategy-Decompose a system into bounded contexts-Coordinate the work of multiple teams working together-Gradually start implementing domain-driven design\n\n\n*I'm a bot, built by your friendly reddit developers at* /r/ProgrammingPals. *Reply to any comment with /u/BookFinderBot - I'll reply with book information. If I have made a mistake, accept my apology.*",
                  "score": 2,
                  "created_utc": "2026-02-01 10:47:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2xj7it",
          "author": "HurricaneCecil",
          "text": "I focused on architecture during my SWE masterâ€™s, hereâ€™s how it was taught:\n\nbasics: read Just Enough Software Architecture by George Fairbanks and then discuss the 4 + 1 View Model of Software Architecture by Philippe Krutchen. It helps if you have a real-life project to look through and talk about.\n\nintermediate: read Fundamentals of Software Architecture by Mark Richards and Neal Ford and Patterns of Enterprise Application Architecture by Martin Fowler.\n\napplication: here we used Enterprise Integration Patterns as a guide and built a semester long project with source control and CI/CD. I thought â€œpracticingâ€ architecture with realistic tooling was super valuable\n\nadvanced: reading research papers on more specific and niche topics. ACM TOSEM and IEEE TSE are decent sources, Distributed Computing from Springer is cool if you want to get very specific and very technical.",
          "score": 7,
          "created_utc": "2026-02-01 06:53:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2y94n6",
              "author": "httpgo",
              "text": "/u/BookFinderBot",
              "score": 1,
              "created_utc": "2026-02-01 10:51:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2y96fr",
                  "author": "BookFinderBot",
                  "text": "**Just Enough Software Architecture A Risk-driven Approach** by George Fairbanks\n\n\n>This book teaches risk-driven architecting and describes a way to do just enough architecture. It avoids the one-size-fits all process tarp pit with advice on how to tune your design effort based on the risks you face. This book seeks to make architecture relevant to all software developers. Developers need to understand how to use constraints as guiderails that ensure desired outcomes.\n>\n>This book focuses on the technical parts of software development and what developers do to ensure the system works-not the job titles or processes. It shows you how to build models and analyze architectures so that you can make principled design tradeoffs. It describes the techniques software designers use to reason about medium to large sized problems and points out where you learn specialized techniques in more detail. The approach in this book embraces drill-down/pop-up behavior by describing models that have various levels of abstraction, from architecture to data structure design.\n\n\n**Fundamentals of Software Architecture An Engineering Approach** by Mark Richards, Neal Ford\n\n\n>Salary surveys worldwide regularly place software architect in the top 10 best jobs, yet no real guide exists to help developers become architects. Until now. This book provides the first comprehensive overview of software architectureâ€™s many aspects. Aspiring and existing architects alike will examine architectural characteristics, architectural patterns, component determination, diagramming and presenting architecture, evolutionary architecture, and many other topics.\n>\n>Mark Richards and Neal Fordâ€”hands-on practitioners who have taught software architecture classes professionally for yearsâ€”focus on architecture principles that apply across all technology stacks. Youâ€™ll explore software architecture in a modern light, taking into account all the innovations of the past decade. This book examines: Architecture patterns: The technical basis for many architectural decisions Components: Identification, coupling, cohesion, partitioning, and granularity Soft skills: Effective team management, meetings, negotiation, presentations, and more Modernity: Engineering practices and operational approaches that have changed radically in the past few years Architecture as an engineering discipline: Repeatable results, metrics, and concrete valuations that add rigor to software architecture\n\n\n**Patterns of Enterprise Application Architecture** by Martin Fowler\n\n\n>Patterns of Enterprise Application Architecture By Martin Fowler\n\n\n**Enterprise Integration Patterns Designing, Building, and Deploying Messaging Solutions** by Gregor Hohpe, Bobby Woolf\n\n\n>Enterprise Integration Patterns provides an invaluable catalog of sixty-five patterns, with real-world solutions that demonstrate the formidable of messaging and help you to design effective messaging solutions for your enterprise. The authors also include examples covering a variety of different integration technologies, such as JMS, MSMQ, TIBCO ActiveEnterprise, Microsoft BizTalk, SOAP, and XSL. A case study describing a bond trading system illustrates the patterns in practice, and the book offers a look at emerging standards, as well as insights into what the future of enterprise integration might hold. This book provides a consistent vocabulary and visual notation framework to describe large-scale integration solutions across many technologies.\n>\n>It also explores in detail the advantages and limitations of asynchronous messaging architectures. The authors present practical advice on designing code that connects an application to a messaging system, and provide extensive information to help you determine when to send a message, how to route it to the proper destination, and how to monitor the health of a messaging system. If you want to know how to manage, monitor, and maintain a messaging system once it is in use, get this book.\n\n\n**Distributed Computing Fundamentals, Simulations, and Advanced Topics** by Hagit Attiya, Jennifer Welch\n\n\n>* Comprehensive introduction to the fundamental results in the mathematical foundations of distributed computing * Accompanied by supporting material, such as lecture notes and solutions for selected exercises * Each chapter ends with bibliographical notes and a set of exercises * Covers the fundamental models, issues and techniques, and features some of the more advanced topics\n\n\n*I'm a bot, built by your friendly reddit developers at* /r/ProgrammingPals. *Reply to any comment with /u/BookFinderBot - I'll reply with book information. If I have made a mistake, accept my apology.*",
                  "score": 3,
                  "created_utc": "2026-02-01 10:52:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2yecdu",
          "author": "IlliterateJedi",
          "text": "If you have a Python background, the single best book I think you'll find is [Architecture Patterns with Python](https://www.cosmicpython.com/book/preface.html).  The book is free, and it has the most beautiful git repository I've ever seen for a book.  Every chapter builds on the last chapter in how the architecture evolves, and they have a branch for each chapter so you can easily switch between branches to see how they changed the code and structure as the book goes along.  It made really examining the code a breeze.  I can't rave enough about this book.",
          "score": 4,
          "created_utc": "2026-02-01 11:37:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2z1ono",
              "author": "bobaduk",
              "text": "Also, if you read it and hate it, you can come here to the software architecture subreddit and argue with the authors!",
              "score": 2,
              "created_utc": "2026-02-01 14:18:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2zrylh",
          "author": "IshanSethi",
          "text": "I'd be honest, just reading books on architecture won't help you much... Once you know the concept, the main work is to apply it... You can try solving problems on www.designheist.com, they have good architecture problemsÂ ",
          "score": 3,
          "created_utc": "2026-02-01 16:29:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30tpf2",
              "author": "EviliestBuckle",
              "text": "I was also thinking the same thing. Thanks for pointing it out",
              "score": 1,
              "created_utc": "2026-02-01 19:20:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2xexh0",
          "author": "Great_Pattern_1988",
          "text": "SEI offers a certificate in Software Architecture.  Three courses that contain an actionable process to creating and evaluating software architectures.  Best course I've ever taken.",
          "score": 3,
          "created_utc": "2026-02-01 06:17:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xf2j6",
              "author": "EviliestBuckle",
              "text": "Can you plz share the respective link?",
              "score": 1,
              "created_utc": "2026-02-01 06:18:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2xfys2",
                  "author": "Great_Pattern_1988",
                  "text": "https://www.sei.cmu.edu/credentials/sei-software-architecture-professional-certificate/",
                  "score": 2,
                  "created_utc": "2026-02-01 06:25:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2xfbyw",
          "author": "sdsdkkk",
          "text": "I read the Architecture of Open Source Application book about 10 years ago to improve my architecture knowledge. But my primary focus at the time was to understand how influential real-life software projects were designed and architected.\nhttps://aosabook.org/en/",
          "score": 3,
          "created_utc": "2026-02-01 06:20:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xg3yf",
              "author": "EviliestBuckle",
              "text": "Same motivation here. Actually here in subcontinent no one get to work on high impact software",
              "score": 1,
              "created_utc": "2026-02-01 06:27:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2z1hoe",
          "author": "bobaduk",
          "text": "My go-to guide for \"how to architect things\" is the practical programmer: https://leanpub.com/practical-software-architecture\n\nThere used to be a website with all that info, but it seems to have been subsumed into a book, but the material was great - high level enough not to be overwhelming, and rooted in practicality.\n\nIn terms of avoiding \"1 year repeated ten times\", my honest advice is to take jobs that scare the crap out of you, and spend as much time as you can in start ups.",
          "score": 3,
          "created_utc": "2026-02-01 14:17:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37912o",
          "author": "SwampApes",
          "text": "Read Designing Data Intensive Applications. \n\nThere are a lot of papers discussing systems.   \nSome examples: Dynamo, Spanner, TAO, Cassandra, Lamport, Paxos, Raft, Borg. \n\nDon't bother with the other suggestions here if the author literally does nothing but write books / consulting.  Clean code / clean architecture, some of the books here written by ThoughtWorks employees are those. ",
          "score": 2,
          "created_utc": "2026-02-02 18:39:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xoa1u",
          "author": "gbrennon",
          "text": "Books",
          "score": 1,
          "created_utc": "2026-02-01 07:39:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o32xeal",
          "author": "garathk",
          "text": "https://developertoarchitect.com/\n\nMark Richards has been mentioned a bunch. I actually took a live course by him about 8 years ago. Found it excellent. He referenced his website here. Lots of very practical bite sized resources.",
          "score": 1,
          "created_utc": "2026-02-02 01:52:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gouc4",
          "author": "OkJicama8468",
          "text": "My opinion is that you need to gain practical experience as a developer or apprentice to truly â€œget good.â€  Building systems and solving real-world technical problems is a sure path to success. While reading books can provide a solid foundation, you need to actively build and put in the time.",
          "score": 1,
          "created_utc": "2026-02-04 02:57:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ktt8o",
          "author": "Public_Class_8292",
          "text": "Clean Architecture - Robert C. Martin. \n\nIt's easy to read and explain all the main principles to know for software architecture",
          "score": 1,
          "created_utc": "2026-02-04 18:49:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr44dn",
      "title": "How Replacing Developers With AI is Going Horribly Wrong",
      "subreddit": "softwarearchitecture",
      "url": "https://youtu.be/ts0nH_pSAdM?si=Kn2m9MqmWmdL6739",
      "author": "BlazorPlate",
      "created_utc": "2026-01-30 12:29:05",
      "score": 60,
      "num_comments": 4,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qr44dn/how_replacing_developers_with_ai_is_going/",
      "domain": "youtu.be",
      "is_self": false,
      "comments": [
        {
          "id": "o3coz7w",
          "author": "Constant_Physics8504",
          "text": "Itâ€™s actually going well at my job. We separated monolith legacy teams into product based teams, and used the existing codebase with SME input to train the AI. \n\nEven new devs now are cranking code out and testing it in a couple hours",
          "score": 2,
          "created_utc": "2026-02-03 15:06:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lkefu",
          "author": "commanderdgr8",
          "text": "I don't think this should be labeled as going horribly wrong - relying on a technology you don't understand fully and giving it free-hand was amatuerish and the company who gave ai free-hand suffered. but that gave us the learnings, ofcourse companies might be hiring developers again after doing mass layoff, but this time there would be more automation, not less. Kind of the second phase of full ai automation started.",
          "score": 5,
          "created_utc": "2026-01-30 13:25:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ngjld",
          "author": "Lord_Farkwad",
          "text": "This video is nonsense",
          "score": 1,
          "created_utc": "2026-01-30 18:42:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2mpw9m",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 0,
          "created_utc": "2026-01-30 16:44:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nlca9",
              "author": "CthuluSurvivor",
              "text": "You arenâ€™t making a distinction, but instead are attempting to reframe the context in a different light. Imagine you have 3 developers all doing the same job. The company starts using LLM coding assistants and the workload of these 3 developers is now replaced by 1 developer + 1 coding agent. Two developers are fired and one remains. The one did not simply get more efficient. Instead, the role of that one developer shifted to a developer + code agent role instead of simply a developer role. At least two developers have been replaced by this new role. One developer was laterally shifted into a role that now includes the coding agent. Someone could say that three developer roles were, in fact, replaced - as the old roles no longer exist due to the new. \n\nWhile 3 developer roles were replaced, only 2 developers were fired. The distinction in this case is between developer roles and developers. Either way, with roles or people, the job of two people were taken on by one + coding agent and this is leading to higher tech debt.",
              "score": 1,
              "created_utc": "2026-01-30 19:02:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qrpvdc",
      "title": "Most people confuse \"Application Logic\" with \"Business Logic\" in MVC/MVVM. Here is my \"CLI Test\" to define a true Model.",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qrpvdc/most_people_confuse_application_logic_with/",
      "author": "FancyComfort435",
      "created_utc": "2026-01-31 02:25:43",
      "score": 58,
      "num_comments": 49,
      "upvote_ratio": 0.8,
      "text": "Too often, I see projects where the \"Model\" is treated just as a DTO (Data Transfer Object) for the database, and all the logic is shoved into the ViewModel or Controller. This leads to massive, unmaintainable \"God Classes.\"\n\nI believe the root cause is a misunderstanding of the Model's boundary.\n\n**My definition of a Model is simple:**\n\n>**The \"CLI Test\"**Â If I asked you to replace your GUI (React/WPF) with a CLI (Console App) tomorrow:\n\n1. Would your Model class work without modification? ->Â **Pass**Â (It's a true Model)\n2. Would it fail because of dependencies on UI libraries or notification logic? ->Â **Fail**Â (It's polluted)\n\nFor example, in a Calculator app, theÂ `Calculator`Â class should hold the current state (accumulator, current operand) and calculation logic. If you put that state in the ViewModel, you are binding your core logic to the View.\n\nI wrote a short article diving deeper into this with diagrams and examples. I'd love to hear your thoughts on this definition.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qrpvdc/most_people_confuse_application_logic_with/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o2qqrnt",
          "author": "Comfortable_Ask_102",
          "text": "That is one of the concepts Uncle Bob tried to communicate with his \"Clean\\* Architecture\" thing. Each Use Case is meant to be one *action* that can be done in the system, and all Use Cases must be independent of any UI or 3rd party, the sum of all Use Cases is *our* application.\n\nAt one project I literally used that as prefixes (like \\`AddOrderUseCase\\`), it's a decent name for a place that calls all the different upstream services, and has some custom, business-dependent logic or some sort of orchestration.\n\nThe dudes from Domain-Driven Design also give good ideas about how to Model a system.\n\nAnd yeah, 100%, a lot of people confuse \"Model\" with the \"ActiveRecord\" pattern, popularized by frameworks like Laravel, RoR and Django it's my guess.",
          "score": 27,
          "created_utc": "2026-01-31 05:25:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2qxw79",
              "author": "FancyComfort435",
              "text": "**Yes! You nailed it.**\n\nThe confusion absolutely comes from the \"Active Record\" pattern in frameworks like Laravel/Rails/Django. They taught a generation of devs that \"Model = A class that maps to a DB table.\"\n\nBut in true MVC (or Clean Architecture), the Model is the **layer** that handles business rules, not just a row in a database.\n\nI'm glad you brought up Uncle Bob. His \"Use Cases\" are exactly what I consider part of the \"Model\" in the broad senseâ€”the code that must survive even if the UI disappears.\n\n**If you're interested, I uploaded a sample code (C#) on GitHub demonstrating this exact \"CLI vs GUI\" separation. It might be a bit rough, but it proves the point.**",
              "score": 3,
              "created_utc": "2026-01-31 06:22:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rh9f8",
                  "author": "zdzisuaw",
                  "text": "Fancy sharing you github or article?",
                  "score": 5,
                  "created_utc": "2026-01-31 09:19:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2rqat2",
                  "author": "FetaMight",
                  "text": "Al?",
                  "score": 6,
                  "created_utc": "2026-01-31 10:46:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2sl5mi",
                  "author": "aefalcon",
                  "text": "Active Record is actually a Domain Model pattern though.  It's a domain model coupled with some data layer functions.  It does not violate MVC when used correctly, but often the app is either simple CRUD with no real business logic or the developer didn't understand the pattern and it turned into purely Data Model.",
                  "score": 2,
                  "created_utc": "2026-01-31 14:29:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2v4mm0",
              "author": "hcboi232",
              "text": "DHHâ€™s ruby on rails and its consequences",
              "score": 1,
              "created_utc": "2026-01-31 21:56:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o31xk8y",
                  "author": "Comfortable_Ask_102",
                  "text": "I mean, it is a good framework. Lots of people build stuff with it which comes with its downsides.\n\nIt's so popular that people believe it's THE way to make software. Similar to people who believe Java is THE way to make OOP.",
                  "score": 1,
                  "created_utc": "2026-02-01 22:34:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2r33fe",
          "author": "flavius-as",
          "text": "This has been as old as hexagonal architecture. Having a different driving adapter.",
          "score": 8,
          "created_utc": "2026-01-31 07:07:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rk6jy",
              "author": "FancyComfort435",
              "text": "**Exactly. You get it.**\n\nIt is essentially the same concept as swapping a **Driving Adapter** in Hexagonal Architecture.\n\nI just framed it as a \"CLI Test\" for MVC because many developers find \"Hexagonal\" too academic or intimidating. But the core principle is identical: the UI is just a plugin.",
              "score": -3,
              "created_utc": "2026-01-31 09:48:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rkbov",
                  "author": "flavius-as",
                  "text": "Hexagonal is neither academic nor complicated.\n\nThe official \"book\" on it is... a leaflet. It's that simple: dependency inversion applied architecturally.",
                  "score": 8,
                  "created_utc": "2026-01-31 09:49:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2qp8ma",
          "author": "aefalcon",
          "text": "Yep.  I've used \"test harness\" in a similar argument.",
          "score": 7,
          "created_utc": "2026-01-31 05:13:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2qq4wl",
              "author": "FancyComfort435",
              "text": "**Exactly! The \"CLI\" is basically just a primitive test harness.**\n\nIf your model can't run in a simple harness (like a console app or unit test) without dragging in the entire UI framework, it's not really a Model. I just use the \"CLI\" metaphor because it's easier to visualize for people who are stuck in the \"Model = DTO\" mindset.",
              "score": 2,
              "created_utc": "2026-01-31 05:20:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2qmn43",
          "author": "theBosworth",
          "text": "Damn, just straight up, uncurated AI slop.",
          "score": 11,
          "created_utc": "2026-01-31 04:54:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2qo51a",
              "author": "FancyComfort435",
              "text": "English is not my first language, so I used AI to translate and format my thoughts.\n\nActually, the initial AI output was too verbose, so I wrote the core draft from scratch and just used AI to handle the translation. If it still looks \"too clean\" or \"excessive\" to you, that might be a fair critique, and I can edit it down.\n\nBut I want to ask you: Does your comment mean you think the *content itself* lacks substance? Or do you just hate AI?\n\nThe \"CLI Test\" concept comes from my 15+ years of software architecture experience, not an LLM hallucination. If you have actual feedback on the architecture itself, I'm all ears.\n\nP.S. Yes, I used Gemini to write this reply too.",
              "score": 1,
              "created_utc": "2026-01-31 05:05:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rqpk9",
                  "author": "FetaMight",
                  "text": "The CLI Test idea is fine.Â \n\n\nWhat trips me up is the sycophantic writing style typical with LLMs.Â  Real people don't talk that way so there's an uncanny valley effect happening when I read your comments.Â \n\n\nI don't think there's any harm in using AI to help you translate your thoughts, but maybe include that as a disclaimer?",
                  "score": 3,
                  "created_utc": "2026-01-31 10:50:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2tfrrm",
                  "author": "no_onions_pls_ty",
                  "text": "Its slop because its just not true.  Not many developers in the wild are making this \"mistake\".  This concept is as decades old.  There is nothing of interest in this post, just standard programming concepts with some added marketing flair trying to communicate an issue having significant breadth.\n\nIt might be really novel for a freshman in college.  But no.  Its just slop.  \n\nIts like going to a car mechanic forum and telling all thr master mechanics that making sure the oil and wiper fluid don't get mixed up is somehow enlightening",
                  "score": 2,
                  "created_utc": "2026-01-31 17:02:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2qv18b",
                  "author": "theBosworth",
                  "text": "Itâ€™s just literally copy-pasted straight out of the client youâ€™re using without so much as formatting changes so it sticks out.\n\nI think seeing a hallucination in text which took the form of stating, in bold that a definition would be supplied, then skipping to test conditions outlining what should have been defined undermines the context youâ€™re replying with. It seems like a reply from an AI, not a mere translation.\n\nI donâ€™t even hate AI. Youâ€™ve just beat around the bush of a definition that I could agree with, but lacks substance at its core. The CLI test is a fundamental to this, but at a scalar level, this a trivial distinction due to other common classesâ€™ responsibilitiesâ€”request providers and handlers come to mind here. Your definition of a model is so loose that it includes the DAL.\n\nIt sounds more like youâ€™ve seen a lot of messy student projects without day0 design discussions if youâ€™re mentioning so-called â€œgod classesâ€.",
                  "score": 3,
                  "created_utc": "2026-01-31 05:58:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2r25ap",
              "author": "epegar",
              "text": "To me it looks good. \nI mean if you manage to identify it as Ai due to the content not being good enough, then I think it's fair. But if you see a rich format being used, then I think it's a good use of Ai.",
              "score": 0,
              "created_utc": "2026-01-31 06:58:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2q7s42",
          "author": "LoveThemMegaSeeds",
          "text": "Seems like a weird arbitrary way to define a model.",
          "score": 3,
          "created_utc": "2026-01-31 03:15:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2qpsfd",
              "author": "robhanz",
              "text": "\"Can this work with a different frontend\" is a pretty good and common way to handle that.  And a CLI is the easiest one to make.",
              "score": 14,
              "created_utc": "2026-01-31 05:17:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2qel35",
              "author": "FancyComfort435",
              "text": "Interesting take. Why do you find it arbitrary?\n\nTo me, it's not arbitrary at allâ€”it's a specific stress test for **\"Separation of Concerns.\"** The \"CLI\" is just a proxy for **\"Zero UI Dependency.\"**\n\nIf your business logic depends on a specific UI framework (like expecting a specific View structure), it becomes impossible to test in isolation or reuse. The CLI test is just the simplest way to prove your logic is decoupled from the presentation layer.\n\nIn my view, the Model represents the **\"Business Rules\"** that should exist regardless of whether the app is Web, Mobile, or CLI. If the Model fails to run on a CLI, it usually means it's polluted with UI logic (like routing, notifications, etc.).\n\n**How do you define a Model's boundary in your projects?** Do you prefer keeping logic in the ViewModel/Controller?",
              "score": 5,
              "created_utc": "2026-01-31 03:59:22",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2qrli5",
              "author": "TheRealStepBot",
              "text": "Not as weird as making a stateful calculator",
              "score": -5,
              "created_utc": "2026-01-31 05:31:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2qxg2g",
                  "author": "FancyComfort435",
                  "text": "**I chose the \"Calculator\" example specifically because it is the simplest form of a State Machine.**\n\nA physical calculator is inherently stateful. It has registers, an accumulator, and pending operations. If the Model doesn't hold that state, the ViewModel has to. And that's exactly what I'm arguing againstâ€”leaking domain state into the presentation layer.\n\nDo you prefer managing `PendingOperation` or `Accumulator` in your ViewModels?",
                  "score": 2,
                  "created_utc": "2026-01-31 06:18:30",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o2u6aq2",
                  "author": "WhenSummerIsGone",
                  "text": "how do you calculate without state?",
                  "score": 1,
                  "created_utc": "2026-01-31 19:08:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2sctip",
          "author": "mexicocitibluez",
          "text": "This is called DDD.",
          "score": 1,
          "created_utc": "2026-01-31 13:41:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2twj31",
          "author": "Classic_Chemical_237",
          "text": "Itâ€™s not that deep. MVC is just super thin basic layer when you donâ€™t want to over engineer. MVVM focuses on objects, VIPER focuses on responsibilities. A proper app with complicated logic should be able to run interactor, entity (model) and VM in CLI.\n\nBetter yet, use React Native. You will naturally separate business logic into a library which can be shared by both web and app with all the unit tests and integration tests. Apps will only have presentation logic",
          "score": 1,
          "created_utc": "2026-01-31 18:22:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2v5ews",
          "author": "hcboi232",
          "text": "why are we using MVC for the backend/usecases? The thick client is long gone and DHH thought it would be nice to butcher that term to be used for a service based architecture. I wouldnâ€™t structure the frontend around Hexagonal because I would be ignoring different control structures relevant to the UI.",
          "score": 1,
          "created_utc": "2026-01-31 22:00:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2rtktr",
          "author": "BleLLL",
          "text": "vertical slice architecture has entered the chat",
          "score": 0,
          "created_utc": "2026-01-31 11:16:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ru2z8",
              "author": "FancyComfort435",
              "text": "Vertical Slice Architecture has left the chat.",
              "score": 1,
              "created_utc": "2026-01-31 11:20:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qv3nr2",
      "title": "Kafka for Architects â€” designing Kafka systems that have to last",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qv3nr2/kafka_for_architects_designing_kafka_systems_that/",
      "author": "ManningBooks",
      "created_utc": "2026-02-03 20:44:15",
      "score": 30,
      "num_comments": 6,
      "upvote_ratio": 0.84,
      "text": "Hi r/softwarearchitecture,\n\nStjepan from Manning here. Weâ€™ve just released a book thatâ€™s written for people who have to make architectural calls around event-driven systems and then defend those decisions over time. Mods said it's ok if I post it here:\n\n**Kafka for Architects** by Katya Gorshkova  \n[https://www.manning.com/books/designing-kafka-systems](https://hubs.la/Q041FhV20)\n\n[Kafka for Architects](https://preview.redd.it/guav3ysxachg1.jpg?width=2213&format=pjpg&auto=webp&s=fc59d0f2fef718c70d40b4996d59b6f879992605)\n\nThis isnâ€™t a Kafka API guide or a step-by-step tutorial. It stays at the architecture level and focuses on how Kafka fits into larger systems, especially in organizations where multiple teams depend on the same infrastructure.\n\nA few of the topics the book spends real time on:\n\n* Kafkaâ€™s role in enterprise software and where it fits in an overall system design\n* Event-driven architecture as a pattern, including when it helps and when it complicates things\n* Designing data contracts and handling schema evolution across teams\n* Kafka clusters as part of the systemâ€™s operational and organizational design\n* Using Kafka for logging, telemetry, data pipelines, and microservices communication\n* Patterns and anti-patterns that tend to appear once Kafka becomes shared infrastructure\n\nWhat I appreciate about this book is that it treats Kafka as an architectural choice, not just a technology. Katya walks through trade-offs youâ€™ll recognize if youâ€™ve ever had to balance team autonomy, data ownership, and long-term maintainability. The examples are grounded in real-world systems, not idealized diagrams.\n\nIf youâ€™re responsible for questions like â€œIs Kafka the right fit here?â€, â€œHow do we keep event contracts stable?â€, or â€œWhat happens when this system grows to ten teams instead of two?â€, this book is written with those concerns in mind.\n\n**For the** r/softwarearchitecture **community:**  \nYou can get **50% off** with the code **PBGORSHKOVA50RE**.\n\nIf youâ€™re already using Kafka as part of a larger system, Iâ€™d be interested to hear what architectural challenges youâ€™re currently dealing with.\n\nThanks for having us. It feels great to be here.\n\nCheers,\n\nStjepan",
      "is_original_content": false,
      "link_flair_text": "Tool/Product",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qv3nr2/kafka_for_architects_designing_kafka_systems_that/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o3g22dn",
          "author": "Glathull",
          "text": "Thanks for posting this. Just bought a copy.",
          "score": 2,
          "created_utc": "2026-02-04 00:49:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ksoes",
              "author": "ManningBooks",
              "text": "Thank you.",
              "score": 1,
              "created_utc": "2026-02-04 18:44:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3etpgb",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 0,
          "created_utc": "2026-02-03 21:03:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3f1op3",
              "author": "Mosk549",
              "text": "Donâ€™t be racist",
              "score": 0,
              "created_utc": "2026-02-03 21:40:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3f275o",
                  "author": "AbbreviationsLow4798",
                  "text": "donâ€™t support fascistsÂ ",
                  "score": -2,
                  "created_utc": "2026-02-03 21:42:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qr6byf",
      "title": "Configuration behaves like code at runtime â€” but we donâ€™t design it like code. Why?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qr6byf/configuration_behaves_like_code_at_runtime_but_we/",
      "author": "FreePipe4239",
      "created_utc": "2026-01-30 14:04:30",
      "score": 22,
      "num_comments": 23,
      "upvote_ratio": 0.89,
      "text": "In most modern systems, configuration is:\n- parsed\n- validated (sometimes)\n- interpreted\n- and directly affects runtime behavior\n\nYet compared to application code, config usually has:\n- weaker type guarantees\n- fewer correctness checks\n- limited tooling\n- poor failure visibility\n\nThis seems to be a recurring root cause in incident postmortems.\n\nFrom a software architecture perspective:\nWhy do we still treat configuration as second-class compared to code?\nIs this a tooling gap, a design tradeoff, or something else?\n",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qr6byf/configuration_behaves_like_code_at_runtime_but_we/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o2lv7y3",
          "author": "PabloZissou",
          "text": "Serious applications would validate the validity of its config and exit if that validation fails. I don't think this is a general problem but project specific.",
          "score": 15,
          "created_utc": "2026-01-30 14:22:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mgws5",
              "author": "Jedkea",
              "text": "Exiting does not solve the problem though in and of itself. If you rollout a change to a bunch of clusters and they all fail to start, well now the whole thing is down.\n\nAlso the config might be valid in one place, but invalid in another. Things like incorrect network addresses are an example.",
              "score": 4,
              "created_utc": "2026-01-30 16:04:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2naxsq",
                  "author": "Pto2",
                  "text": "Rollback then? Code could also fail.",
                  "score": 3,
                  "created_utc": "2026-01-30 18:17:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o31ucxp",
                  "author": "ncmentis",
                  "text": "You need canary deploys. Exiting plus staged rollouts allows you to abort before a significant chunk of resources are devoted to a failing service. And you can then rollback.",
                  "score": 1,
                  "created_utc": "2026-02-01 22:18:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2rphbr",
              "author": "ryan_the_dev",
              "text": "Every single application I work on, this is a requirement. Configuration is validated on startup and application fails if invalid.",
              "score": 2,
              "created_utc": "2026-01-31 10:38:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2wrwtk",
                  "author": "hxtk3",
                  "text": "Yes but there's a valid point that if you update a config map, every pod sees the changes more or less instantly (although they probably don't act on the changes until the process restarts), which is very different from how you'd roll out a code change (update the container image target, which would trigger a rolling replacement of the deployment with the new image).\n\nConfiguration changes are (often by design, as a feature) synchronized replacements of resources rather than gradual rollouts. Most of the big tech outages from the 2010s that you heard about if you don't work at the company that had them are caused by bad configuration updates, and we're not categorically done with them; one of Cloudflare's big outages last year was identified as an argument for them to universally implement gradual configuration rollouts because that would have averted it.",
                  "score": 2,
                  "created_utc": "2026-02-01 03:34:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2o44hx",
              "author": "gaelfr38",
              "text": "Same feeling here. This doesn't sound like a general problem to me at all.",
              "score": 1,
              "created_utc": "2026-01-30 20:29:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2lskv2",
          "author": "FreePipe4239",
          "text": "One thing I keep noticing is that config often gets validated only syntactically,\nnot semantically â€” the system accepts it, but behaves very differently than intended.\n\nCurious if people here have seen languages, frameworks, or tooling\nthat actually close this gap effectively.",
          "score": 6,
          "created_utc": "2026-01-30 14:09:10",
          "is_submitter": true,
          "replies": [
            {
              "id": "o2ltbt1",
              "author": "flavius-as",
              "text": "Of course, I've seen this compiled and validated semantically, it's called a programming language.\n\nInstead of writing it in yaml or whatever other error prone semi-formal language, write it in a strongly typed language.",
              "score": 5,
              "created_utc": "2026-01-30 14:12:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ol7ft",
          "author": "DoubleAway6573",
          "text": "https://mikehadlow.blogspot.com/2012/05/configuration-complexity-clock.html\n\n\nYou remind me this. You are like 4 or 5 o clock.",
          "score": 2,
          "created_utc": "2026-01-30 21:50:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lwono",
          "author": "systemic-engineer",
          "text": "I always really, really liked dhall.  \nAnd never had the opportunity to use it in anger.\n\nhttps://dhall-lang.org/",
          "score": 3,
          "created_utc": "2026-01-30 14:29:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m1yo6",
          "author": "ewoolly271",
          "text": "Great question. At multiple jobs, Iâ€™ve been told the business users need to have direct control over the application. But then, we get a ton of problems because they donâ€™t fully understand how the config changes interact with the application. \n\nSo you have to trust the business users to communicate their changes, test them, time them with releases, etc\n\nHow is that any better than, say, working with them to update a YML or JSON file with CI/CD? Itâ€™s not. Doesnâ€™t save any time or energy. Itâ€™s just engineering leaders being too weak to tell the business leaders itâ€™s a bad idea",
          "score": 1,
          "created_utc": "2026-01-30 14:55:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2meunm",
          "author": "violentlymickey",
          "text": "One consideration is that config can be changed easily whereas code may need to be redeployed or rebuilt. I think you should always reasonably validate your config though, and many libraries exist to do that.",
          "score": 1,
          "created_utc": "2026-01-30 15:55:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2mxy0k",
          "author": "Physical-Compote4594",
          "text": "One of the (many) awesome things about Lisp is that configuration files are just code, because in Lisp code and data have the same representation.\n\nYou often write Lisp macros to define a DSL for configurations, and that's where you add type guarantees and correctness checks, which can be done with the full power of the language.",
          "score": 1,
          "created_utc": "2026-01-30 17:20:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2o47vh",
          "author": "supercargo",
          "text": "Configuration is a double edged sword.  It increases (runtime) flexibility at the expense of complexity. I donâ€™t think there is any special reason why it doesnâ€™t get treated more rigorously, just the usual: not enough time, not a priority.  Like most tech debt, itâ€™s either strategically appropriate or the risks werenâ€™t understood.\n\nEngineering effort spent on config validators has always been worthwhile in my experience.  If your post mortem root cause is a bad config, the correct next question to ask is â€œwhat can we do to reject this config earlier in the processâ€. Do this a few times and some patterns and best practices should emerge that you can use proactively. Clear error messages are also critical, donâ€™t just reject a config, indicate what is wrong, why itâ€™s wrong, and where in the file.",
          "score": 1,
          "created_utc": "2026-01-30 20:30:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y4008",
          "author": "FreePipe4239",
          "text": "What Iâ€™m taking away from this thread is that the issue isnâ€™t\n\nâ€œconfig vs codeâ€, but that config changes have very different\n\nrollout semantics and blast radius than code changes.\n\n\n\nEven with validation, the difficulty seems to be:\n\n\\- understanding the \\*effect\\* of a config change\n\n\\- across environments\n\n\\- before itâ€™s applied everywhere\n\n\n\nThat gap feels under-tooled today.",
          "score": 1,
          "created_utc": "2026-02-01 10:04:43",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o2lwbbi",
          "author": "ukaeh",
          "text": "Iâ€™d say look into protobufs for type guarantees and checks/tooling etc. As a good starting point.\n\nAnother aspect is indeed a lack of design - configs get (re)used across layers/stack likely when they mean different things semantically and that is 100% a trade off for simplicity whether or not thatâ€™s intentional. For example, configuration (and/or parts of) should never be in limbo but often systems end up with things like â€˜oh these fields arenâ€™t setup yetâ€™ which is mostly a design issue.",
          "score": 1,
          "created_utc": "2026-01-30 14:28:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lwrnq",
          "author": "Isogash",
          "text": "It really depends on how you view config.\n\nIf you view the system as a whole and are only concerned with delivery of a specific business behaviour e.g. in a bespoke enterprise system, then \"config\" is just another part of delivering that behaviour, and so its distinction from code is not that clear.\n\nInstead, if you view the system as being something configurable, and the config as specific to a particular deployment or use case e.g. for different environments, products or users, then the distinction is quite clear: your system should accept all valid combinations of configuration, and whether or not the config is correct for the end user is something *they* should be testing.\n\nEither way, I don't disagree that file-driven config could benefit from some of the features of programming languages, and that users should have tests that their configuration is correct for their intended use case.",
          "score": 1,
          "created_utc": "2026-01-30 14:30:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lvb56",
          "author": "jhartikainen",
          "text": "There's lots of places which handle configs as code. JS/TS projects is one, but I guess those don't really give you a lot of guarantees about anything. I vaguely recall seeing some Haskell projects using regular Haskell code as configs as well, where you can get fairly strong guarantees of the correctness.\n\nI guess the biggest issue is that configs usually are intended to be something you can modify without needing to recompile the whole project. Making them code often kinda gets in the way of that.",
          "score": 1,
          "created_utc": "2026-01-30 14:23:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m3ciu",
          "author": "Adorable-Fault-5116",
          "text": "This is because XML was seen as uncool, and JSON / YAML took off as configuration because how nice it was for a developer to read was prioritised over correctness.\n\nThese days I think the way to solve this, since we aren't going back, is to just make configuration code. Then you can a) not annoy developers will scary ugly text, b) have strong typing etc.",
          "score": 1,
          "created_utc": "2026-01-30 15:02:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rkzjh",
              "author": "One_Elephant_8917",
              "text": "Exactly xml had schema that validates it, compared to json",
              "score": 1,
              "created_utc": "2026-01-31 09:55:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2q6qft",
          "author": "klimaheizung",
          "text": "We do. Just use the right programming language, that's all there is to it.",
          "score": 0,
          "created_utc": "2026-01-31 03:09:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwja9l",
      "title": "LinkedIn Re-Architects Service Discovery: Replacing Zookeeper with Kafka and xDS at Scale",
      "subreddit": "softwarearchitecture",
      "url": "https://www.infoq.com/news/2026/02/linkedin-service-discovery/",
      "author": "rgancarz",
      "created_utc": "2026-02-05 11:53:23",
      "score": 22,
      "num_comments": 2,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qwja9l/linkedin_rearchitects_service_discovery_replacing/",
      "domain": "infoq.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3rzlg6",
          "author": "IlliterateJedi",
          "text": "The actual source: [Scalable, multi-language service discovery at LinkedIn](https://www.linkedin.com/blog/engineering/infrastructure/scalable-multi-language-service-discovery-at-linkedin)",
          "score": 3,
          "created_utc": "2026-02-05 20:08:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3regod",
          "author": "BarfingOnMyFace",
          "text": "GIGO at scale",
          "score": 1,
          "created_utc": "2026-02-05 18:30:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvho5v",
      "title": "Fitness Functions: Automating Your Architecture Decisions",
      "subreddit": "softwarearchitecture",
      "url": "https://lukasniessen.medium.com/fitness-functions-automating-your-architecture-decisions-08b2fe4e5f34",
      "author": "trolleid",
      "created_utc": "2026-02-04 07:00:48",
      "score": 21,
      "num_comments": 0,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qvho5v/fitness_functions_automating_your_architecture/",
      "domain": "lukasniessen.medium.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qu4aaf",
      "title": "Why does enterprise architecture assume everything will live forever?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qu4aaf/why_does_enterprise_architecture_assume/",
      "author": "eurz",
      "created_utc": "2026-02-02 19:05:15",
      "score": 21,
      "num_comments": 34,
      "upvote_ratio": 0.72,
      "text": "Hi everyone!\n\nWorking in a large org right now and everything is designed like itâ€™ll still be running in 2045. Layers on layers, endless review boards, â€œstrategicâ€ platforms no team can change without six approvals. Meanwhile, half the systems get sunset quietly or replaced by the next reorg. I get the need for stability, but it feels like we optimize for theoretical longevity more than actual delivery.\n\nFor people who like enterprise architecture - what problem is it really solving well, and where does it usually go wrong?",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qu4aaf/why_does_enterprise_architecture_assume/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o37gb2r",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 75,
          "created_utc": "2026-02-02 19:12:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37h3cb",
              "author": "LessChen",
              "text": "I would have said the 1980's - so much in the banking world is very old but still works for example.",
              "score": 30,
              "created_utc": "2026-02-02 19:15:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o37h2do",
          "author": "Glathull",
          "text": "Because in the enterprise, things *do* live forever.",
          "score": 62,
          "created_utc": "2026-02-02 19:15:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37yfql",
              "author": "BeABetterHumanBeing",
              "text": "To be more precise: in enterprise, a thing lives for as long as the business it's supporting, which is frequently longer than the existence of the company (because business units get spun off in acquisitions, live through bankruptcy, and so on).",
              "score": 10,
              "created_utc": "2026-02-02 20:37:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ikinc",
              "author": "NewFuturist",
              "text": "Even in small companies, if the company is 15 years old, you'll encounter 15 year old code.",
              "score": 6,
              "created_utc": "2026-02-04 11:56:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3q62fi",
              "author": "3sc2002",
              "text": "Came here to say this.  But yeah . . . COBOL is still kicking.",
              "score": 1,
              "created_utc": "2026-02-05 15:03:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o37gxbp",
          "author": "ratczar",
          "text": "I was reading Clean Architecture recently, and the part that jumped out and grabbed me by the throat is the idea that good architecture defers big decisions for as long as possible.   \n  \nIt sounds like your org is maybe trying to finalize plans for a big, long-term system, which is a trap that I find a lot of engineers fall into - they want to construct the beautiful, perfect, hyper-efficient machine.   \n  \nBut the business sometimes changes what it wants the machine to do, and if you're tied to a 20 year roadmap then you're a bit fucked when winds change. \n\nFor that reason, you can draw up whatever plans you want, but you should really only move to implementation when you *absolutely have to.*\n\nGreat example: we've had plans for an enterprise-wide address verification service for awhile, but we only moved on it when it became absolutely critical for a client. ",
          "score": 19,
          "created_utc": "2026-02-02 19:14:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37imki",
              "author": "ziksy9",
              "text": ">Great example: we've had plans for an enterprise-wide address verification service for awhile, but we only moved on it when it became absolutely critical for a client. \n\nGiven that is was needed by a client, even if it was implemented there were probably requirements that came in late for that client, so doing it preemptively would have still requires changes, right?\n\nGreat example.",
              "score": 4,
              "created_utc": "2026-02-02 19:22:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o37jet5",
                  "author": "ratczar",
                  "text": "It really came down to some minor details in the implementation, e.g. are we going full hypermedia or are we cramming some critical data into the initial return.\n\nWe ended up deciding to cut a corner initially and crammed it into the initial return, and will refactor later when we have more use cases for the related data.",
                  "score": 1,
                  "created_utc": "2026-02-02 19:26:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o394cg7",
              "author": "phluber",
              "text": "A well-designed enterprise architecture does not leave you fucked when winds change. A well-designed architecture allows for a great amount of flexibility and room for new features.",
              "score": 2,
              "created_utc": "2026-02-03 00:07:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o37kwij",
          "author": "ByMunro",
          "text": "IMO enterprise architecture is about flexibility (coupling and cohesion). we dont know what will be in 2045 and hell we dont even know what will be in 3 years from now. all we can do is try to stay as flexible as possible. some systems will stay, so make sure they're designed well. some systems will go, so make sure you can replace them as effortlessly as possible. \n\nand well, you can be quite sure about what is tomorrow. on a enterprise scale you probably (should) also know whats gonna happen in 6 months quite precisely. the more you look into the future, the more abstract it gets. i dont think anyone is planning on exactly your enterprise architecture will look like in 2045. but you'll want to have visions, guidelines, something abstract, so everyone is going in the same direction. as 2045 comes closer, your vision gets more precise. so make sure you can adapt, keep your landscape flexible. \n\nEDIT: should probably add, that this is a perfect world scenario. time, money, politics have quite some\ninfluence",
          "score": 5,
          "created_utc": "2026-02-02 19:33:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o38qqgv",
          "author": "edgmnt_net",
          "text": "Just a comment from someone who dislikes it. I hope we're talking about the same thing, though, because I'm not really sure...\n\nI don't think that's the real reason. One thing might be horizontal dev scaling: plenty of businesses barely build upon anything, it's an endless crunch to appease one customer, then the next and so on. Architecture is simply an attempt to install guardrails so they can hire en masse with low costs and divide up work. Something a very average dev (mediocre even) can handle, because you want lots of them. Another thing is the expectation that software is write-once, especially when they accumulate tons of half-baked features and tech debt that's difficult to repay, they try to extract as much as possible (and impossible).\n\nIn a nutshell, it's trying to scale up work as cheaply as possible, because ultimately a lot of business is just trying to get money to work. As for where and whether it goes wrong objectively, this is also debatable. I would say the main issues are (1) unrealistic expectations and (2) they're missing out on higher impact, more efficient software development that really taps into the potential of this domain (but you need a strong vision for this, it's not just a matter of spending).\n\nIn practical terms, you'll see silos, you'll see layers upon layers that give the impression that everything is decoupled (yet it isn't, the spaghetti is on another level), you'll see work getting split in ways that makes absolutely no sense and results in huge amounts of duplication. Do reduced hiring costs make up for this? Maybe, although I doubt it can beat a small team of people with enough expertise cutting through the bullshit and working under a well-determined, restricted scope. Scope creep and tech debt tends to balloon up costs, so even if it looks like you can satisfy hundreds of customers early on, things eventually slow down greatly and you have to keep adding to the headcount and reducing margins. Until the costs become insane and the project gets sunset (often quite early).",
          "score": 5,
          "created_utc": "2026-02-02 22:53:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37h0or",
          "author": "Ugiwa",
          "text": "Products don't die that fast.. (unless you're working for Google ig)",
          "score": 3,
          "created_utc": "2026-02-02 19:15:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39cs1z",
          "author": "gbrennon",
          "text": "Because applications that runs in the backend of ur bank were deployed in 1980?",
          "score": 3,
          "created_utc": "2026-02-03 00:53:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39lg5e",
          "author": "Dicethrower",
          "text": "It's even funnier with games. \"This needs to last 5y, so let's spend 2y making what should take 6 months, and not see the irony in spending 4 times as long to \"\"save time\"\". Oh woops, funding is gone and/or game didn't do so well.\"\n\nYAGNI is not just a catchy phrase. Time saved is time you can spend refactoring when the actual need arises. Anything made before you know it's needed is a waste of time, every time.",
          "score": 2,
          "created_utc": "2026-02-03 01:43:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3dic5r",
              "author": "edgmnt_net",
              "text": "It bothers me that often it isn't anything smart either. It's not like they're spending time on mind-blowing techniques and abstractions, it's often just a ton of trivial layers.",
              "score": 2,
              "created_utc": "2026-02-03 17:25:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3fm06b",
              "author": "213737isPrime",
              "text": "It's an art to know just how much \"extra\" effort to put in place as an investment into the future without overdoing it. It's more than zero.",
              "score": 2,
              "created_utc": "2026-02-03 23:21:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3fmsm1",
                  "author": "Dicethrower",
                  "text": "Hard disagree. You never do anything extra that you don't know you need. Trying to predict the future is exactly what YAGNI is all about.",
                  "score": 1,
                  "created_utc": "2026-02-03 23:25:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o38inn4",
          "author": "internetuser",
          "text": "Because the people who are paid to facilitate the process get paid more when the process takes a long time.",
          "score": 2,
          "created_utc": "2026-02-02 22:13:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37inz5",
          "author": "europeanputin",
          "text": "Architecture it's not just about technical designs, but it must also fit the organizational structure. We have a lot of instances where we would benefit from event driven systems and concepts, but we remain strictly RESTful because we don't have the knowledge to support it. When making designs in such cases, it's important to be mindful that at some point this would change, because the other way around increases cost i.e on operations. Hence the designs go into series of discussions which tradeoff to choose, and enterprise architecture essentially helps making these decisions as it allows to estimate the cost for the current project and the cost of changing it in the future. Comparing this to projections of other cost like cost of running operations or other non functionals help making smart business decisions.\n\nAs cost of change needs to be minimized and eventually management will come to their senses, enterprise architecture is sadly required for technical people to cope with ever changing nature of business demands.",
          "score": 1,
          "created_utc": "2026-02-02 19:22:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37ny9k",
          "author": "BarfingOnMyFace",
          "text": "It solves the problem of why we have jobs really well ðŸ˜„",
          "score": 1,
          "created_utc": "2026-02-02 19:47:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37o8bs",
          "author": "BarfingOnMyFace",
          "text": "Forever is a long time. Iâ€™d argue most software should be architected to survive 3-5 decades. Maybe in some cases in the future, a century or so.",
          "score": 1,
          "created_utc": "2026-02-02 19:48:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3dhunr",
              "author": "edgmnt_net",
              "text": "Survive, definitely. Remain unchanged that long? Nah.",
              "score": 1,
              "created_utc": "2026-02-03 17:22:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3dpmqw",
                  "author": "BarfingOnMyFace",
                  "text": "Yes, just survive. Remain unchanged? Highly unlikely. Even in some far-off future of multi-generational spaceshipsâ€¦ change seems inevitable, improvements or new additional features desired, change born out of pure boredom, due to a monotonous longevity of the same look and behaviorsâ€¦ I definitely agree with you- change is frequent. change is an integral part of software, as much as it is an integral part of the human brain constantly programming itself, long after most of its software has been written.",
                  "score": 1,
                  "created_utc": "2026-02-03 17:58:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o37tfwc",
          "author": "D4n1oc",
          "text": "I can't imagine how this would influence your design.\nWe could either do a good architecture that fits the needs or we don't and live with the consequences.\n\nWhat would be the actual design difference for a system that lives 3-5 decades or 10 decades?\n\nWe know one thing for sure. Bad architecture decisions are very expensive and can influence the whole system across all teams causing huge amounts of unknown costs and sometimes make it impossible to change the running system in a necessary way.\n\nWe know the costs for a clean architectural design that minimizes this risk.\n\nIn most cases it's the most expensive part to write software. Because it always creates legacy, technical deps, complexity and needs to be supported.\n\nWriting software should be the last resort. \nIt's much cheaper to make 10 plans and throw them away.",
          "score": 1,
          "created_utc": "2026-02-02 20:13:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37w1sf",
          "author": "Mediocre_Date1071",
          "text": "I hear two different things happening here\n\n- â€œlayers on layersâ€. This sounds like design optimized for loose coupling, which gives the ability to change out pieces. This architecture for the assumption that things will not be around forever. Â \n\nâ€œEndless review boardsâ€¦platforms no one can change without 6 approvalsâ€. This is large organizations being large. There is so much miscommunication and need to generate buy-in across a large org, just so the pieces fit together reasonably well, that you get these heavy processes.Â \n\nThis isnâ€™t to say that your company is doing optimal planning and architecture, just that the reasons for what you see may not the presumption of longevity that you surmise.Â ",
          "score": 1,
          "created_utc": "2026-02-02 20:26:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3blm37",
          "author": "BeastyBaiter",
          "text": "I work as a software dev at an F100 megacorp you've heard of. We retired our mainframes 4 years ago and have numerous critical internal apps from the 1990's.",
          "score": 1,
          "created_utc": "2026-02-03 10:57:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bpmt1",
          "author": "garden_variety_sp",
          "text": "I call it crystal ball architecture, and itâ€™s the most wasteful way to design and build. Design for now and know that evolution is a thing. I view enterprise architecture in much the same way as I view intelligent design. It takes some serious mental gymnastics to believe in it, and those that do are most likely brainwashed.",
          "score": 1,
          "created_utc": "2026-02-03 11:32:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e1fkh",
          "author": "santagoo",
          "text": "We still run systems running COBOLâ€¦",
          "score": 1,
          "created_utc": "2026-02-03 18:51:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eoy61",
          "author": "serious-catzor",
          "text": "I'm not sure I really work with software... This UART worked the same when I was born and it will work the same when I die.",
          "score": 1,
          "created_utc": "2026-02-03 20:41:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gzlbf",
          "author": "Pale_Height_1251",
          "text": "If we only made the software we needed, the industry would lay off half the developers working today.\n\nIt's not really in anybody's interests to make streamlined software and deliver early. Management wants to increase their fiefdoms, developers want to keep their jobs.",
          "score": 1,
          "created_utc": "2026-02-04 04:01:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hc6fb",
          "author": "SpaceCowboy317",
          "text": "Please bro just give me clean boundries bro, please dont let that jr push the jdbc class with the select * bro pleeeaaase",
          "score": 1,
          "created_utc": "2026-02-04 05:28:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lg500",
          "author": "Bahatur",
          "text": "Is the software licensed?\n\nIf it is, then thereâ€™s an accounting dimension because it is an asset; every time you sunset an asset, you have to take a write down on the books.",
          "score": 1,
          "created_utc": "2026-02-04 20:34:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lj2n1",
          "author": "PutPrestigious2718",
          "text": "You build the boat for the open ocean, not the harbor.",
          "score": 1,
          "created_utc": "2026-02-04 20:48:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3m6u93",
          "author": "Visa5e",
          "text": "Because confluence pages never die.",
          "score": 1,
          "created_utc": "2026-02-04 22:43:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qrfrmp",
      "title": "What architecture as code tools you are using, besides AI?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qrfrmp/what_architecture_as_code_tools_you_are_using/",
      "author": "vmgolubev",
      "created_utc": "2026-01-30 19:42:38",
      "score": 11,
      "num_comments": 8,
      "upvote_ratio": 0.87,
      "text": "How do you understand AaC approach? Should you get all artifacts automatically or just some?\nSpecifics:\nDiagrams as code - but which one? Structurizr, D2 or anything else?\nAny docs gen software, that will generate your artifacts automatically?\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qrfrmp/what_architecture_as_code_tools_you_are_using/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o2qabtw",
          "author": "avinds",
          "text": "likec4",
          "score": 2,
          "created_utc": "2026-01-31 03:32:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2o08nt",
          "author": "themessymiddle",
          "text": "Iâ€™ve been working on arch docs that auto-update, are accessible via MCP, and are beautiful to navigate: https://gjalla.io if you want to take a look! I struggled with some other tools that didnâ€™t auto-update, and even docs generated by Claude Code were too high level. So far the gjalla generated arch artifacts reduce token use, turns, and time of the agents working on code, and I always know the docs Iâ€™m looking at are up to date",
          "score": 2,
          "created_utc": "2026-01-30 20:11:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2r1u7z",
              "author": "chipstastegood",
              "text": "your site is slow to load for me on mobile and doesnâ€™t explain what the product actually does",
              "score": 2,
              "created_utc": "2026-01-31 06:56:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2r63so",
                  "author": "themessymiddle",
                  "text": "Thanks for the feedback, live architecture docs and enforcement of architecture rules",
                  "score": 1,
                  "created_utc": "2026-01-31 07:34:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2rqw6o",
          "author": "bills2go",
          "text": "Can you try [revibe.codes](https://www.revibe.codes)? I'm building it. It generates architecture and other flow diagrams in mermaid format, from the codebase.",
          "score": 1,
          "created_utc": "2026-01-31 10:51:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xg7rz",
          "author": "MatchLittle5000",
          "text": "I recently built a related tool called pacta: https://github.com/pacta-dev/pacta-cli\n\nIt helps you to treat architecture as an artifact instead of multiple diagrams stored in confluence that are slowly becoming outdated. \n\nYou describe architecture in special file, add rules, and validate the current code. But the main feature is the ability to keep a history of architecture evolution and observe different trends throughout the time. For example, you can get charts catching a change of the dependency number or coupling in your system and understand when and why the drift occurred. There is also a GitHub action, adding a summary of the architecture change for each PR.\n\nI will add support for diagrams in the future too.",
          "score": 1,
          "created_utc": "2026-02-01 06:28:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qrc4rv",
      "title": "System Design for beginners!",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qrc4rv/system_design_for_beginners/",
      "author": "Substantial-Tax-472",
      "created_utc": "2026-01-30 17:35:51",
      "score": 8,
      "num_comments": 7,
      "upvote_ratio": 0.9,
      "text": "Hello guys, I'm a final year CSE student. Can anyone suggest the roadmap for beginning System Design, like from basic till advanced concepts and scenarios. I had begun with the ByteByteGo, but I didn't feel the completeness. So, any suggestions would help a lot.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qrc4rv/system_design_for_beginners/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o2n6etv",
          "author": "VortexOfPessimism",
          "text": "Probably [https://www.hellointerview.com/learn/system-design/core-concepts/api-design](https://www.hellointerview.com/learn/system-design/core-concepts/api-design) for something more structured",
          "score": 5,
          "created_utc": "2026-01-30 17:58:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2o26f0",
          "author": "Veuxdo",
          "text": "Ask your professors, that's what they're there for.",
          "score": 2,
          "created_utc": "2026-01-30 20:20:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xller",
          "author": "MatchLittle5000",
          "text": "If you want something practical watch this: https://youtube.com/@hello_interview?si=uz0nebtCACHS1uHF\n\nIt helped me a lot to pass an interview to Senior position. Might help also in academic purposes.",
          "score": 1,
          "created_utc": "2026-02-01 07:14:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y9p6d",
          "author": "lmagarati",
          "text": "bro, stop treating system design like a college exam. ByteByteGo is the gold standard, but youâ€™re feeling 'incomplete' because youâ€™re reading instead of doing. pick a feature, design it, and break it... thatâ€™s the only way to build the judgment needed for an interview process that is frankly a total 'shit show' and largely dependent on the whims of your interviewer. accept that youâ€™ll fail a few for reasons outside your control, so stop hunting for a perfect roadmap; you'll slowly learn to design by building skin in the game.",
          "score": 1,
          "created_utc": "2026-02-01 10:56:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2zolet",
          "author": "IshanSethi",
          "text": "After completing understanding basic concepts of system design, you can go & practise questions on https://www.designheist.com, they have good interview level questions... Atlassian & uber & few other companies ask system design questions & mostly are similar to what are mentioned on the platform",
          "score": 1,
          "created_utc": "2026-02-01 16:13:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3412pf",
          "author": "Comfortable-Fan-580",
          "text": "Check this out - https://pradyumnachippigiri.substack.com/s/system-design",
          "score": 1,
          "created_utc": "2026-02-02 06:07:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34br2u",
          "author": "bills2go",
          "text": "I'm building [revibe.codes](https://revibe.codes), which you can use to analyze open source systems of your interest. It shows the architecture, flow diagrams and guided code navigation. Not a regular learning platform - its kind of seeing how other systems are built and learning from that.",
          "score": 1,
          "created_utc": "2026-02-02 07:41:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvk9w9",
      "title": "A Scalable Monorepo Boilerplate with Nx, NestJS, Kafka, CQRS & Docker â€” Ready to Kickstart Your Next Project",
      "subreddit": "softwarearchitecture",
      "url": "https://github.com/ARG-Software/Nx-Monorepo-Boilerplate",
      "author": "FormalAd7608",
      "created_utc": "2026-02-04 09:41:00",
      "score": 8,
      "num_comments": 7,
      "upvote_ratio": 0.79,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tool/Product",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qvk9w9/a_scalable_monorepo_boilerplate_with_nx_nestjs/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3iwqpc",
          "author": "nickchomey",
          "text": "This has to be a joke... Bull, redis AND kafka?Â ",
          "score": 2,
          "created_utc": "2026-02-04 13:17:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3iypfb",
              "author": "FormalAd7608",
              "text": "You just use what you want. You can use them all or just one. One is for messaging, other for background jobs, other for caching. Just pick what you like the most.",
              "score": 1,
              "created_utc": "2026-02-04 13:28:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3j2pjg",
                  "author": "nickchomey",
                  "text": "You've missed the point. Surely 3 separate tools are not needed here. Redis (or, better yet, NATS) could do it all",
                  "score": 1,
                  "created_utc": "2026-02-04 13:50:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3jqw5t",
              "author": "Ok_Cranberry4354",
              "text": "Whats your definition of a joke? For example, are you going to implement something similar to a payment system that needs real-time data streaming, replayability, durable event logs and a bunch of other things like strong delivery guarantees with NATS instead of Kafka which is industry standard when talking about scalability? NATS can do some of these but with implicating limitations.\n\nYou can technically force one tool to do everything but that doesnâ€™t mean you should. At least looking at the repo, this is clearly a boilerplate, not a prescription, that's the idea of a boilerplate, you use a baseline that fits your needs the most and remove what you don't care about. If you're going to leave a comment like that on someone else's free open source contribution at least give some some architectural insight instead of just a reaction that seems pretty personal.",
              "score": 1,
              "created_utc": "2026-02-04 15:51:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3juoks",
                  "author": "nickchomey",
                  "text": "NATS was not the thrust of my comment - it was literally parenthetical to saying Redis could be used standalone. Though, I do stand by it. I'd be curious what the \"implicating limitations\" that you speak of are.\n\nAnd just because something is \"standard\" doesn't make it an appropriate boilerplate starting point - those tend to do best when refined, only bringing on more dependencies and services when absolutely needed. Even still, why not Redpanda over Kafka?\n\nMoreover, if you were to extend that \"standard\" line of thinking to the rest of the choices here, why use NestJS instead of something React-based? (I'm aware Nest and next.js etc are not all that comparable and am most definitely not advocating for anything React-based. Just making the point that Nest isn't an \"industry standard\")",
                  "score": 0,
                  "created_utc": "2026-02-04 16:09:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qw03vu",
      "title": "Clean code architecture and codegen",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qw03vu/clean_code_architecture_and_codegen/",
      "author": "Aggressive_Ad_699",
      "created_utc": "2026-02-04 20:35:06",
      "score": 7,
      "num_comments": 16,
      "upvote_ratio": 0.71,
      "text": "I'm finally giving in and trying a stricter approach to architecting larger systems. I've read a bunch about domains and onions, still getting familiar with the stuff. I like the loose coupling it provides, but managing the interfaces and keeping the structures consistent sounds like a pain.\n\nSo I started working on a UI tool with a codegen service that can generate the skeletons for all the ports, and services, domain entities and adapters. It'll also keep services and interfaces in sync based on direct code changes as well. I also want to provide a nice context map to show which contexts rely on other contexts. It'll try to enforce the basic rules of what structural elements can use, implement or inject others. I'll probably have a CLI interface that complements the UI which could be used in pipelines as well to validate those basic rules. The code will remain mostly directly editable. I'm aiming to do this for Python at first, but it doesn't seem too complicated to extend to other languages.\n\nThoughts about the usefulness of such a tool or clean code / DDD in general?",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qw03vu/clean_code_architecture_and_codegen/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o3lsz8p",
          "author": "UnreasonableEconomy",
          "text": "This is my personal opinion of course\n\n- Robert Martin: ðŸš©\n\n---\n\n> I'm finally giving in an trying a more strict approach to architecting larger systems.\n\nCorrect me if I'm wrong, but this sounds like \"nothing I've tried so far worked, so now I'll just do BDUF by the book\"\n\nThis is probably not gonna work out all that well either, but it depends on what you're trying to do.\n\n> So I started working on a UI tool with a codegen service that can generate the skeletons for all the ports, and services, domain entities and adapters\n\nThere have been efforts of this sort since time immemorial, and none of them have really ever stuck around or become universal. \n\nI however don't think it's a waste of your time (if you have the time) to pursue this - you'll learn all the problems associated with these types of prescriptive architectural styles. You'll find out what does and doesn't work. You'll become a bit better at making high level decisions.\n\nSA is as much an art form as it is engineering. Practice and experience are unfortunately no substitute for what you can learn from books.",
          "score": 9,
          "created_utc": "2026-02-04 21:35:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3lyhxr",
              "author": "Aggressive_Ad_699",
              "text": "Thanks, I think that's a good take. Even if it doesn't become an everyday tool for me, let alone others I can still solidify my knowledge about this kind of architecture. Do you know why these tools don't seem to stay around or reach more people?\n\nTo clarify, I've mostly either worked on large legacy systems where I wasn't a part of most of the architectural decisions, or smaller green field projects that I'm yet to see grow to a medium size. I've been told a bunch of times that this kind of architecture isn't worth it, or it's too academic and overcomplicated. So I'm really giving into my own desires to see how it works for me:)",
              "score": 2,
              "created_utc": "2026-02-04 22:01:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3m6zhg",
                  "author": "UnreasonableEconomy",
                  "text": ">  Do you know why these tools don't seem to stay around or reach more people?\n\nI think that's a very good and hard question. I'd love the opinions of others here on this. \n\nMy take is that these tools encode not just a particular style, but define a framework by the nature of how they work. If you want to do anything, you have to do it in a particular way.\n\nSo these \"tools\" \"become\" \"frameworks\". \n\nWhat's a framework? I'd say it's an enforced collection of patterns. (which is what you'll do - you'll select a finite set of patterns that this tool will realize)\n\nBut what's a pattern? Why do we use patterns? I'd say, we use patterns to work around the shortcomings of some environment. It's a way of dealing with reality so we can achieve the outcomes we need. \n\nThe problem is that any finite selection of patterns can only cover a subset of the continuum of implementations required for our business cases. To deal with this, developers sometimes come up with new patterns to deal with the canonical way of doing things. Sometimes that works out fine. Sometimes it doesn't make sense at all.\n\nAs languages and environments and patterns evolve, it sometimes stops making sense to bend over backwards to appease the framework, and working outside of the framework becomes easier. At some point the frameworks becomes either so sidelined or adapted and specialized so it stops being the universal panacea it was supposed to be.\n\nAnd then someone invents a new framework to supplant all these specializations, and the cycle begins anew \n\n# ðŸ¤”\n\n---\n\n> I've been told a bunch of times that this kind of architecture isn't worth it, or it's too academic and overcomplicated. So I'm really giving into my own desires to see how it works for me\n\nI think that's good. There's a nugget of truth in everything, and if you have the energy and time and will to prospect for that bit of truth, that's perfect. That's probably the best way to become a good architect, especially if no one else has to suffer from your exploratory decisions lol.",
                  "score": 3,
                  "created_utc": "2026-02-04 22:44:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3mlp32",
              "author": "trainbustram",
              "text": "I do want to say that at many large automotive companies, this tooling to define interfaces explicitly actually does exist and is actually used very often in software modeling, where you explicitly define all of your ports deployments, etc. then generate network and internal artifacts based on that method. Definitely much more useful in a distributed monoliths architecture where boundaries can shift easily from internal to external, rather than in a micro services architecture where the boundaries give or take like the same at all points in time.",
              "score": 2,
              "created_utc": "2026-02-05 00:04:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3phq6d",
                  "author": "Aggressive_Ad_699",
                  "text": "I suppose those are proprietary tools, right? Do you have an example in mind? \nHmm it's interesting you brought up microservices. It might be possible to easily reorganise contexts across repos as well. That's certainly out of scope for now. I'm going to focus on large monorepos first.",
                  "score": 1,
                  "created_utc": "2026-02-05 12:46:20",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3oaibl",
          "author": "thecreator51",
          "text": "This sounds very useful. DDD and clean architecture help long-term maintainability, but managing interfaces is pain. Codegen skeletons and validation can save time and enforce consistency early.",
          "score": 2,
          "created_utc": "2026-02-05 06:25:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pixcv",
              "author": "Aggressive_Ad_699",
              "text": "I'm also thinking of something lean. Modern IDEs do a lot, I don't want to attempt to replace things they already do well, just augment their capabilities with the more opinionated rules of this architecture.\n\nHow would you prefer interacting with the tool?\n- Direct schema editing\n- A nice terminal UI\n- A web interface\n\nI want a simple CLI interface as well that can be called from IDE file watchers to update linked interfaces on save for example. The web UI might be slower to work with, but the context map and dependency map it can show might be useful for brainstorming.",
              "score": 1,
              "created_utc": "2026-02-05 12:54:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3oukk7",
          "author": "edgmnt_net",
          "text": "Possibly hot take here, but merely adding some indirection and layers does *not* make your code loosely-coupled in a meaningful way, it's more like increasing effort, surface for bugs and making it more difficult to refactor. It is a pain because it is a pain. The fact that you're considering code generation is sort of a red flag and generating skeletons won't help when you get hit with a 3k lines PR for what would otherwise be a much simpler change. IMO people should stop this indiscriminate layering nonsense and focus on actual abstractions and designing actual robust APIs (when possible and needed, otherwise it's perfectly fine to write code in a direct style). I'm allowing for indirection where there are particular pain points and people stepping too much on each other's toes, but you need to be conservative about it.",
          "score": 2,
          "created_utc": "2026-02-05 09:32:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pimfr",
              "author": "Aggressive_Ad_699",
              "text": "Not at all, it's a cautionary advice. This was one of the main reasons I've been a bit afraid to look into clean code. You mention focusing on actual abstractions and robust APIs. Do you think the clean architecture with dependency inversion, ports, services, adapters, etc... is on the other end of things? If so could you elaborate on what kind of abstractions/patterns you have in mind?",
              "score": 1,
              "created_utc": "2026-02-05 12:52:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3ptcvq",
                  "author": "edgmnt_net",
                  "text": "For example, compilers often have IRs (intermediate representations) that are carefully considered to allow translation of the code as well as optimizations (which might require combining knowledge of different languages or different CPUs without ending up with a combinatorial explosion of corner cases, some of those pseudoinstructions might not even resemble any concrete instruction). A database may provide a set of primitive operations that are enough to write applications within a certain consistency model and with certain transactional capabilities, possibly with a higher-level / convenience API on to make it easier for simple use cases. A compression library provides APIs that are generally robust for a wide variety of use cases so you don't need to go make changes to it to use it in your own application (and they're not changing the API surface all the time). An operating system kernel needs to provide a driver model such that a diverse set of hardware devices can be managed (some only require initialization, some require to be notified before being powered-down and so on). A JSON parser might provide both streaming and non-streaming parsers (building the entire representation in memory upfront) in a convenient way and for a wide variety of users. All these tend to require rather careful consideration.\n\nIn contrast and at least in a practical sense, stuff related to layered architectures often tends to be applied blindly and as a general recipe, being little more than arbitrary scaffolding. This tends to be compounded by people trying to split work top-down in a trivial way. It's easy to say \"hey, someone should do auth and someone should do the books endpoint\". But then the auth stuff could just be one or two calls into the framework / auth library and it's instead blown to an entire component that barely adds anything (and might even impose needless restrictions). In such cases nobody's really doing any real work of abstracting stuff, they're just writing wrappers for straightforward calls.\n\nSupposedly this sometimes protects against changing requirements but I find that's usually not true, it's just a place where you end up putting ugly hacks that would have been better fixed by large-scale refactoring. It reduces visibility into code and changes because everything is 7 useless layers deep. It makes it \"easy\" to write 100k LOC of code that barely does anything concrete. It makes it hard to write composable helpers because everything is encapsulated too tightly yet it's not robust enough to handle all reasonable use cases. And to some degree it shouldn't be, that's what the framework is for, while you're writing a very specific and concrete application.\n\nOn a somewhat related note, I think a good and even simpler test for code writing ability is to look at how people write functions/methods. Do they split them wisely? One could do either of (1) one big function or (2) a hundred very small functions that presume a bunch of invariants (\"I'm always being passed a non-empty array of at most 3 elements, I'll crash otherwise\"). Those are both pretty poor choices, usually. Or they can be mindful about stuff and split on natural boundaries and where there's least resistance, for example by making a helper that compares JSON objects a certain way and makes at least some sense on its own (either for DRY purposes or simply because it's clearer / more testable on its own). This kind of soft separation is very useful, because you're grouping things logically, making them easier to write / review / confirm they're working, while also allowing the possibility of refactoring at will. But it's not something that's just a recipe and it heavily depends on experience and what the code really does.\n\nThat being said, some layering may be fine, though. It's just that you have to be conservative about it because it has a cost. And it's often overused.",
                  "score": 1,
                  "created_utc": "2026-02-05 13:55:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qrek69",
      "title": "What would you change in this architecture?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qrek69/what_would_you_change_in_this_architecture/",
      "author": "Complex_Ring210",
      "created_utc": "2026-01-30 19:00:00",
      "score": 7,
      "num_comments": 5,
      "upvote_ratio": 0.82,
      "text": "[Test Architecture](https://drive.google.com/file/d/1tad2EjG_wQ7KGoBRXIAVRN-GWBIN3Ey1/view?usp=sharing)\n\nI am learning system design and trying to make a kind of reddit + ai system. I know there can be many things added in this which are currently in reddit, but keeping it simple for now.\n\nPostgres is the main database, Neo4j is for social graph, S3/Minio is for storing media files, Qdrant is for vector embeddings (for media files in chat and long term LLM memory). All services either use Node.js or Python for now.  \nClient is a mobile or web user.\n\nThese are a few things I know, I have to add:\n\n1. Caching (other than the one Valkey node being used for caching SFU server health checks)\n2. The live chat is not connected at the moment\n\nI would love suggestions on how to make this architecture faster or any general improvements. Any suggestions on improvements is welcomed, even if you think I should use php.\n\nAlso all of this was done in [draw.io](http://draw.io) and I know this is so not the way to draw system diagrams. So, it would be great if anyone can let me know how to actually diagram and which tools I should use to draw the diagram",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qrek69/what_would_you_change_in_this_architecture/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o2nrd68",
          "author": "Hopeful-Programmer25",
          "text": "If this is for actual use btw, I donâ€™t think MinIO is free any moreâ€¦ though you said for learning so, ok",
          "score": 3,
          "created_utc": "2026-01-30 19:30:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nstx4",
              "author": "Complex_Ring210",
              "text": "Yeah I mean I don't want to give $1 per month to AWS to host 5 cat photos",
              "score": 1,
              "created_utc": "2026-01-30 19:36:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2soquz",
                  "author": "Glove_Witty",
                  "text": "Youâ€™d be well under the free tier threshold by the sound of it.",
                  "score": 1,
                  "created_utc": "2026-01-31 14:49:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2pfnfd",
              "author": "Complex_Ring210",
              "text": "What do you think about the architecture?\nCan I improve it?",
              "score": 1,
              "created_utc": "2026-01-31 00:31:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rggmg",
                  "author": "Hopeful-Programmer25",
                  "text": "If you can post a screenshot here I could have a look.",
                  "score": 1,
                  "created_utc": "2026-01-31 09:12:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qvpcml",
      "title": "key value storage developed using sqlite b-tree APIs directly",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qvpcml/key_value_storage_developed_using_sqlite_btree/",
      "author": "Fine-Package-5488",
      "created_utc": "2026-02-04 14:02:09",
      "score": 7,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "SNKV ([https://github.com/hash-anu/snkv](https://github.com/hash-anu/snkv)) is a keyâ€“value store implemented directly on top of SQLiteâ€™s B-Tree APIs.  \nIt bypasses the SQL query layer and performs operations using SQLiteâ€™s internal B-Tree interface, reducing overhead compared to SQL-based access paths.\n\nBenchmark evaluations on mixed workloads show approximately \\~50% performance improvement compared to equivalent SQL queryâ€“based operations.\n\nFeedback on the design, implementation choices, performance characteristics, and potential areas for improvement would be welcome.\n\nA usage walkthrough is available here:  \n[https://github.com/hash-anu/snkv/blob/master/kvstore\\_example.md](https://github.com/hash-anu/snkv/blob/master/kvstore_example.md)",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qvpcml/key_value_storage_developed_using_sqlite_btree/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qwo81f",
      "title": "Architecture Question: Modeling \"Organizational Context\" as a Graph vs. Vector Store",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qwo81f/architecture_question_modeling_organizational/",
      "author": "altraschoy",
      "created_utc": "2026-02-05 15:26:51",
      "score": 7,
      "num_comments": 4,
      "upvote_ratio": 0.82,
      "text": "Iâ€™m working on a system to improve context retrieval for our internal AI tools (IDEs/Agents), and Iâ€™m hitting a limit with standard Vector RAG.\n\nThe issue is structural: Vector search finds \"similar text,\" but it fails to model typed relationships (e.g., `Service A` \\-> `depends_on` \\-> `Service B`).\n\nWe are experimenting with a Graph-based approach (hello arangodb x)) where we map the codebase and documentation into nodes and edges, then expose that via an MCP (Model Context Protocol) server.\n\nThe Technical Question: Has anyone here successfully implemented a \"Hybrid Retrieval\" system (Graph + Vector) for organizational context analysis?\n\nIâ€™m specifically trying to figure out the best schema to map \"Soft Knowledge\" (Slack decisions, PR comments and all the jazz that a PM/PO can produce) to \"Hard Knowledge\" (code from devs/qa) without the graph exploding in size.\n\nWould love to hear about any data structures or schemas youâ€™ve found effective for this.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qwo81f/architecture_question_modeling_organizational/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o3qn3w9",
          "author": "Elvez-The-Elf",
          "text": "Is this an architecture question?",
          "score": 3,
          "created_utc": "2026-02-05 16:23:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3rla4y",
              "author": "asdfdelta",
              "text": "Yes. Architecture requires organizational context to be designed correctly. For example, Conway's Law",
              "score": -2,
              "created_utc": "2026-02-05 19:01:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3s7fkp",
                  "author": "Elvez-The-Elf",
                  "text": "I agree with your statement but still canâ€™t relate it to the post. If I were given this task I would ask my senior AI/Data Engineers for help, not our architects.",
                  "score": 1,
                  "created_utc": "2026-02-05 20:45:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3rsdeb",
          "author": "erotomania44",
          "text": "Graph rag was hype. \n\nRead up on anthropicâ€™s contextual retrieval blog post. \n\nItâ€™s the only way to do search with RAG today.",
          "score": 2,
          "created_utc": "2026-02-05 19:34:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtuyi1",
      "title": "Have to extract large number of records from the DB and store to a Multipart csv file",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qtuyi1/have_to_extract_large_number_of_records_from_the/",
      "author": "MasterA96",
      "created_utc": "2026-02-02 13:25:17",
      "score": 6,
      "num_comments": 11,
      "upvote_ratio": 0.88,
      "text": "I have to design a flow for a new requirement. Our product code base is quite huge and the initial architects have made sure that no one has to write data intensive code themselves. They have pre-written frameworks/utilities for most of the things. \n\nBasically, we hardly get to design any such thing ourselves hence I lack much experience of it and my post might seem naive so please excuse me for it.\n\n(EDITED) The requirement was that we will be using RabbitMQ so the user request to service A will send a message to the queue and there will be a consumer service B which would use Apache Camel, would go through routes (I mean so it's already asynchronous) to finally requesting records from the join of tables. (Just a simple inner join, nothing complex) Those records might or might not need processing and have to be written to a multipart file of type csv, which would be sent to another API to another service C.\n\nWe're using PostgreSQL. I've figured out the Camel routing part (again using existing utilities). Designed a sort of LLD. Now the real question was fetching records and writing to csv without running into OOM issue. It seems to be the main focus of my technical architect.\n\nI've decided on using - (EDITED)\n\nJdbcTemplate.query using RowCallBackHandler\n\n(Might use JdbcTemplate.queryForStream(...), since I'm on Java 17 so better to use streams rather than RowCallBackHandler, but there are other factors like connection stays open, fetchSize on individual statement isn't possible)\n\nWould be using a setFetchSize(500) - Might change the value depending on the tradeoffs as per further discussions.\n\nMight use setMaxRows as well.\n\nThe query would be time period based so can add that time duration in the query itself.\n\nThen I'll be using CSVPrinter/BufferWriter/OutputStream to write it to the Multipart file (which is in memory not on disk). [Not so clear on this, still figuring out]\n\nEDIT - \nSo, service C is one of the microservice which would eventually store the file as zip in a table. DB processing can be done in chunks but still file would be in memory. So have decided to stream write to a temporary file on disk, then stream read it and stream write to a compressed zip and then send it to service C. I'm currently doing a POC of this approach if that's even possible or not.\n\n\nThis is just a discussion. I need suggestions regarding how I can use JdbcTemplate, CSVPrinter, Streams better.\n\n\nI know it's nothing complex but I want to do it right. I used to work on a C# project (shit project) for 4.5 yrs and moved to Java, 2 yrs back. Roast me but help me get better please. Thank you. ",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qtuyi1/have_to_extract_large_number_of_records_from_the/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o37uxvj",
          "author": "two-point-zero",
          "text": "Look a bit confusing to me. Help me to understand:\n\n-Why rabbit?it means that the  process that read the file (call it the producer) is not on the same software/machine/system of the one that read them? ( Call it the consumer). So producer read from your db, write messages in rabbit and a different system will read and build the csv?\n\n- camel is not enough to be \"automatically async\" because of routes. A route can be fully sync, and to be honest in most case you want to be sync ( for example if you are dealing with transactions). The async is because of Rabbit,and it's async between producer and consumer still the consumer part might or might not be sync with the thread that read from rabbit.\n\n- if messages goes from postgeres to the CVS producer via rabbit,the advance of using streamed query highly depends on how you write on rabbit.do you send rows in bulk ( 10,100,1000s each rabbit message) or one message each row ( very poor performance wise)?\n\n- by the way if performance is a concerns,don't use text formats for rabbit messages (Jason,XML ) goes for a binary serialization library.\n\n- what is a multiparty csv? There are csv payload and multipart http requests. Multipart csv look new to me.\n\nClarify these please and we can continue...\n\nEdit: and most important how \"big\" is big here? Thousands of records?millions? billions? A 10MB csv, 100 MB? GB?",
          "score": 2,
          "created_utc": "2026-02-02 20:20:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3adv7z",
              "author": "MasterA96",
              "text": "Sure, I'll elaborate. RabbitMQ is used just after we receive the user request. Basically the request message will go to RabbitMQ and gets consumed by another service which would then produce the file and send to a 3rd service.\n\nWe can rule out the Camel routing part here. I just mentioned RabbitMQ and Camel to tell that DB call would happen on a separate thread so it's already non-blocking in one way.\n\nSo the DB call and CSV formation both are part of the RabbitMQ consumer service.\n\nIt will be sending the Multipart File which will be of type CSV. \n\nHow the 3rd service will send/display that file to the user is completely out of my control.\n\nNumber of records currently atmost are 100k, but will increase with time. The table is already monthly partitioned and indexed.\n\nAlso, I know it might not take that much memory right now but my team's main concern is that we should still not bring and store everything in memory.\n\nEdit: To summarize I want to know how can I use JdbcTemplate in a better way as per this usecase.",
              "score": 1,
              "created_utc": "2026-02-03 04:34:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3b2ahx",
                  "author": "two-point-zero",
                  "text": "Ok.nice.\n\nStarting form the end. If you want to keep a minimum of streaming features you probably want to use chunked data (if http 1) or DATA frames (if http/2) but you need to be sure that both your http client and API server are able to manage them (which should be..but check to be sure).\n\nIf not, you have to send the CVS file all in once,that means load in memory all at once. Or you might want to save it on some third party storage and send link to the external API to retrieve if it too big.\n\nConsidering you can actually send data in streaming fashion, I think I would go for paginate the query on db assign each page to a different thread, read and process In parallel (you may want to track some row key or page number to reorder data at the end),and then compose and reorder it need. With camel should be matter of a couple of stages to accomplish that, patterns of scatter and recompose is well supported.\n\nThen you can buffer your rows,once processed and reordered and send them when ready again in chunk,or data as said before.\n\nBut keep in mind,if you need  any summarized data (like the average of some value,thing like that )you cannot avoid to load  everything in memory at least once.\n\nI would keep thing parametric like:\n\n- records in a page \n- number of thread for reading\n -dimension of chunk\n- dimension of http post body buffer\n\nAnd play a bit to see what fit best. Speed and Memory and resources are always connected,high speed, more parallelism,more memory and more resources but faster.\n\nLess parellism,or smaller db pages,will consume less resources but requires more time to complete..you need to try and tweak.\n\nIdeally if you want to stream directly from db to API,you cannot use more that one thread for db page (no parallelism, one page at time, out of db through API sync)\n\nThe more parallel thread you will use the more memory you need because worst case, to build an ordered chunk you might need to keep in Memory all the required pages until you fill the write buffer. I.e. you spin 3 thread and read page 1,2,3 but thread 3 finish first. To send all the records ordered you need to wait for thread 1 an 2 to complete, so worst case you need all 3 Db pages to be loaded in memory for reordering.\n\nso keep main parameters variables using external properties ( possibly with hot reload or JMX access to change them while running) and find your sweet spot.",
                  "score": 2,
                  "created_utc": "2026-02-03 07:52:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3bqdba",
          "author": "garden_variety_sp",
          "text": "Camel SQL producer will give you a ResultSetIterator. You can stream from that. Transform if you need to. The Camel file producer will happily take a stream as input and will even chunk it for you if required.",
          "score": 2,
          "created_utc": "2026-02-03 11:38:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3kjoqe",
              "author": "MasterA96",
              "text": "Oh, I'll look into these for sure.",
              "score": 1,
              "created_utc": "2026-02-04 18:04:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3gpfoh",
          "author": "SolarNachoes",
          "text": "Sounds like all you need are batches. Grab rows from DB in a paginated manner and write to CSV.\n\nIs service C external? If not I would save the CSV to storage then pass a reference to it to service C.",
          "score": 2,
          "created_utc": "2026-02-04 03:00:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3kjiqy",
              "author": "MasterA96",
              "text": "Sure.\n\nNo, service C is one of the microservice which would eventually store the file as zip in a table. DB processing can be done in chunks but still file would be in memory. So have decided to stream write to a disk, then stream read it and stream write to a compressed zip and then send it to service C. I'm currently doing a POC of this approach if that's even possible or not.",
              "score": 1,
              "created_utc": "2026-02-04 18:03:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3lltec",
                  "author": "SolarNachoes",
                  "text": "Storing large binary in a database is often not a good idea.",
                  "score": 1,
                  "created_utc": "2026-02-04 21:01:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3lw16s",
          "author": "InstantCoder",
          "text": "If you are using PostgreSQL you can let it generate csv for you in a very efficient and fast way.  And you can directly stream this file with MultiPart. \n\nUse the CopyManager class and use the copy command inside it. \n\n[here is an example](https://github.com/quarkiverse/quarkus-fluentjdbc/blob/main/examples/src/main/java/com/acme/fluentjdbc/controller/FruitResource.java). Check from line 230.",
          "score": 1,
          "created_utc": "2026-02-04 21:50:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtn6gw",
      "title": "The Power of Bloom filters",
      "subreddit": "softwarearchitecture",
      "url": "https://pradyumnachippigiri.substack.com/p/the-power-of-bloom-filters-in-system",
      "author": "Comfortable-Fan-580",
      "created_utc": "2026-02-02 06:10:28",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 0.75,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qtn6gw/the_power_of_bloom_filters/",
      "domain": "pradyumnachippigiri.substack.com",
      "is_self": false,
      "comments": [
        {
          "id": "o35eya0",
          "author": "inflammatoryusername",
          "text": "r/deadinternettheory",
          "score": 6,
          "created_utc": "2026-02-02 13:16:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36vkmy",
              "author": "thegreatjho",
              "text": "Dunno, after reading it there are enough grammar errors to make me think itâ€™s at least human edited if nothing else. Likely by a ESL writer.",
              "score": 1,
              "created_utc": "2026-02-02 17:38:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}