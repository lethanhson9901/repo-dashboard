{
  "metadata": {
    "last_updated": "2026-01-08 02:30:00",
    "time_filter": "week",
    "subreddit": "softwarearchitecture",
    "total_items": 32,
    "total_comments": 174,
    "file_size_bytes": 236715
  },
  "items": [
    {
      "id": "1pz9v5b",
      "title": "Is it still true that 30 percent of the workforce runs 100 percent of the project?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1pz9v5b/is_it_still_true_that_30_percent_of_the_workforce/",
      "author": "StillUnkownProfile",
      "created_utc": "2025-12-30 05:39:34",
      "score": 89,
      "num_comments": 71,
      "upvote_ratio": 0.89,
      "text": "I recently hit a point of total burnout and frustration. I finally went to my manager to complain that I was doing all the work, that others werenâ€™t contributing much, and their unfinished tasks were constantly being pushed onto my plate. His response was pretty blunt: he said thatâ€™s just the reality of corporate life, especially in IT, where only about 30% of the team actually contributes to the project. Iâ€™m wondering if this is still a common, accepted truth in the industry?",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1pz9v5b/is_it_still_true_that_30_percent_of_the_workforce/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nwp6xo1",
          "author": "Oliceh",
          "text": "I have worked for 20 years now in various large organizations. 80% of the people is absolutely useless. Of that 80% there is a group of 25%-ish that is actively harming progress with their incompetence. They are even worse than useless. This isn't intentional incompetence, this is them doing their best. \n\nWhat I learned is... stick to the 20% that actually do stuff and learn and work with them.",
          "score": 19,
          "created_utc": "2025-12-30 08:32:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwu27ip",
              "author": "Extreme_Elderberry16",
              "text": "The 25% that actively harm the process with their incompetence is so true (at least at my company). I usually realize this when for a few weeks you are not constantly in firefighting mode. This is usually during yearly vacation periods when a large portion of said people are ooo",
              "score": 3,
              "created_utc": "2025-12-31 01:05:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx1393o",
              "author": "vikings-gg",
              "text": "The quote I was told by a CVP at top technology company was this â€œ80% of the workers do 20% of the work while the other 20% of the workers do the remaining 80% of the workâ€ itâ€™s up to you what group youâ€™re going end up in",
              "score": 2,
              "created_utc": "2026-01-01 04:01:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwpcrdz",
              "author": "StillUnkownProfile",
              "text": "Appreciate you sharing that. I will do my best to stay in the 20% that learns and gets things done.",
              "score": 2,
              "created_utc": "2025-12-30 09:27:27",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwz0sxr",
              "author": "MaverickGuardian",
              "text": "Weirdest part is that incompetency doesn't prevent people ending up as ctos, architects or tech leads. Causing even more problems.",
              "score": 1,
              "created_utc": "2025-12-31 20:26:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx1rfie",
                  "author": "Oliceh",
                  "text": "Because the people promoting them are part of the 80%",
                  "score": 1,
                  "created_utc": "2026-01-01 07:28:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx5h6qr",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2026-01-01 22:18:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx7m19d",
                  "author": "Oliceh",
                  "text": "Guess you were the 80%",
                  "score": 1,
                  "created_utc": "2026-01-02 06:12:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwp0kus",
          "author": "mistyharsh",
          "text": "As much as it may sound like Pareto Principle but it is not. Pareto Principle is about systems and their interconnections. Your manager saying this is wrong assumption on human capability.\n\nThe situation you describe is a case of bad management and bad assimilation of knowledge. The bad management because they have failed to build proper performance culture and haven't been able to incentivize teams/people to finish the projects or tasks. The bad assimilation of knowledge in team because likely the case that people are not possessing enough knowledge about the system to get the projects to the finish line.\n\nYour manager is just normalizing bad management and cloaking it with some misunderstood principle. Remember that Pareto is about explaining the natural uneven distribution within the system and not about the uneven distribution of work within the group of people. One classic example is \"Google Search and Ads\" is 70% of Google revenue (uneven earning compared to other services but can be explained by Pareto Principles) but that doesn't mean their Android or Cloud teams are useless.\n\nConsider this situation as a first red flag. There are ways to measure organization's health. If you see more red flags, it is time that you leave that place immediately.",
          "score": 38,
          "created_utc": "2025-12-30 07:34:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwph7rf",
              "author": "OkTrade8132",
              "text": "got any pointers with regards to measuring an organizations health?",
              "score": 4,
              "created_utc": "2025-12-30 10:08:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwyj8oy",
                  "author": "ericmutta",
                  "text": "The way it affects *your* health is the best measure I've found.",
                  "score": 1,
                  "created_utc": "2025-12-31 18:54:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwpb4o2",
              "author": "StillUnkownProfile",
              "text": "It clarified a lot of what I have been sensing. Thank you.",
              "score": 2,
              "created_utc": "2025-12-30 09:11:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwoo9i6",
          "author": "OneHumanBill",
          "text": "It's the good old 80/20, aka the Pareto Principle.  Twenty percent of the people contribute roughly eighty percent of the value.  It's true in any industry.  Always has been.  In the old days it was the 20% that you'd be looking to get into leadership roles as they got into their forties and fifties.\n\nWhat's going to be interesting in the next few years is if AI is going to be effectively replacing the eighty percent of the workforce that only contributes the twenty percent.  If you're frustrated just remember which side of that divide you want to be on, and how you build your reputation for value productivity.",
          "score": 43,
          "created_utc": "2025-12-30 05:50:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwor9be",
              "author": "StillUnkownProfile",
              "text": "I understand that dynamic, and Iâ€™m already on the value side. My question is whether being on that side now also means accepting burnout as normal, or if thereâ€™s still an expectation that itâ€™s managed better.",
              "score": 11,
              "created_utc": "2025-12-30 06:14:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwpuaco",
                  "author": "bezik7124",
                  "text": "Take it easy man, I was like that doing extreme overtime on top of it for a few years. It's unmanageable in the long run, and destroys your health. Do what you're comfortable with, take things slower when you're not feeling like it, find time to relax and take frequent breaks at work. And clock out exactly when your shift ends. You're still going to be more productive than the 80%, and while this might be counter-intuitive, it's probably not going to hinder your career in any way - people generally respect you more when you value your time and don't overwork yourself.",
                  "score": 5,
                  "created_utc": "2025-12-30 12:03:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwpwd2b",
                  "author": "OneHumanBill",
                  "text": "I've been at this a long long time now.  I'm on what I hope will be my final software project as I'm approaching 50.\n\nYeah you have to accept this to some extent.  Frequent breaks and clocking out exactly on time blah blah blah will rather quickly put you on the non-value side because people are looking to you to set the pace.  If you slow down, they'll get worse. \n\nSo instead what you do is look to improve team performance via process.  Look at metrics.  Invent them if necessary.  Hey involved in methodological comparisons.  Give XP a close look.  Look to improve team accountability.  If you can improve the teams' productivity even a little bit you can then try to evade burnout.  You won't always be able to, especially when you're personal life hands you emergencies right around crunch times.\n\nOn your side, look into mental disciplines like stoicism.  Don't laugh, it's helped me.  My next trick is getting into yoga.  Software creation the highest levels does take a toll on your body and mine doesn't quite handle the physical stress like it did thirty years ago when I was getting started.\n\nThe more you try to embrace process improvements the more you'll be pulled into leadership, sales, staffing, and non-technical type of roles.  I've pushed back on this for years but I'm finally at the age where I feel like I have nothing left to prove in the technical arena.  Like I said I'm on my final project as an architect/tech lead, and starting to make that transition.  I'll be a hobbyist again, and I think I'll be able to really enjoy writing software just for fun again like I did as a kid. \n\nThis isn't the answer you're looking for probably but I've had a pretty fulfilling career, including the burnout parts.  I hope it helps.",
                  "score": 3,
                  "created_utc": "2025-12-30 12:19:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwp7i92",
              "author": "IndividualShape2468",
              "text": "And the 20% are over in the overemployed subredditÂ ",
              "score": 3,
              "created_utc": "2025-12-30 08:38:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwpwz1f",
                  "author": "OneHumanBill",
                  "text": "No.  The overemployed are screwing us all over and kidding themselves with how productive they think they are.  I've fired maybe a dozen of these assholes who try to overclock meetings and think that nobody notices.  Somebody like me will because their productivity is in the bottom 4%, Pareto squared territory, and investigate.  And if nobody notices then they're still not in the top 20%.",
                  "score": 1,
                  "created_utc": "2025-12-30 12:24:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwppozw",
              "author": "Ok-Craft4844",
              "text": "Judging by my evaluations, im perceived to be be on the 20% doing 80% side, but tbh, that won't help in the pictured scenario.\n\nIf AI really replaces 80% of the workforce, there is no one left for the 20% to sell the shit we build to, and you don't need most of the 20% either.",
              "score": 1,
              "created_utc": "2025-12-30 11:25:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwptvct",
                  "author": "ALAS_POOR_YORICK_LOL",
                  "text": "You cant really know that with any kind of confidence. There are so many variables here it's hard to confidently project how it will change the workforce.",
                  "score": 1,
                  "created_utc": "2025-12-30 12:00:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwpwjgs",
                  "author": "OneHumanBill",
                  "text": "I'm aware.  It's one of those things that the powers that be haven't thought through very well.  I don't have any good solutions though.  Do you?",
                  "score": 1,
                  "created_utc": "2025-12-30 12:20:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwoxl5i",
          "author": "Qinistral",
          "text": "Iâ€™m surprised no one is commenting on your managers response. Thatâ€™s pretty crap IMO. His job is to balance out the work and make sure people are pulling their weight. This should be HIS problem, not yours.\n\nThere are a couple main levers that lead to inequality. 1. Ability. 2. Effort. Not everyone will be high ability and high effort. Some will be medium ability and medium effort. But your manager needs to be culling low ability and/or low effort. Work is a team sport and low performers kill morale.",
          "score": 13,
          "created_utc": "2025-12-30 07:07:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwoy8sn",
              "author": "StillUnkownProfile",
              "text": "Couldnâ€™t agree more. The manager should be managing the workload and addressing low performers, itâ€™s not really the teamâ€™s responsibility to carry that.",
              "score": 1,
              "created_utc": "2025-12-30 07:13:14",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwp5y1y",
              "author": "Rincho",
              "text": "Well, not really. Manager's needs to make sure they deliver in time, costs etc. How it is done may differ",
              "score": 1,
              "created_utc": "2025-12-30 08:23:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwopx1a",
          "author": "GrauDiamand",
          "text": "Just dont do much either lol",
          "score": 7,
          "created_utc": "2025-12-30 06:03:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwoqmn9",
              "author": "StillUnkownProfile",
              "text": "Doing the same now :)",
              "score": 4,
              "created_utc": "2025-12-30 06:09:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwormx0",
          "author": "larowin",
          "text": "Do what you can, be communicative, and document everything. Youâ€™ll float a level up, or youâ€™ll survive the next cull. Itâ€™s easy to float in environments like this, but itâ€™s easy to get cut as well.",
          "score": 5,
          "created_utc": "2025-12-30 06:17:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwoty3k",
              "author": "StillUnkownProfile",
              "text": "Iâ€™m working as a consultant so my company has no idea of what I will do, and client doesnâ€™t care how I will do.",
              "score": 2,
              "created_utc": "2025-12-30 06:36:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwoxw4z",
                  "author": "Qinistral",
                  "text": "Sounds like your best strategy is to tune for learning as much as you can so you can get a job elsewhere with better coworkers.",
                  "score": 3,
                  "created_utc": "2025-12-30 07:10:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwounzs",
          "author": "justUseAnSvm",
          "text": "I'd put concerns about your co-workers out of your mind, that stuff all averages out in the end, burnout is a far greater concern and amplifies all those anxieties about co-workers.\n\nI hope your manager helped you develop a plan, but for me, the combination of deciding to let certain things go, and being consistent in my schedule (have to walk the dog), and always tempering my effort and expectations has worked really well.\n\nJust hang in there! Burnout happens when you put work in and don't get the reward. Our brain can't help but \"learn\" that activity isn't something worth doing anymore, so celebrate your wins when you can!",
          "score": 4,
          "created_utc": "2025-12-30 06:42:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwow3la",
              "author": "StillUnkownProfile",
              "text": "I get what youâ€™re saying, but being in the same cubicle and seeing others not contribute makes it tough to just let go. How do you keep your focus in that kind of environment?",
              "score": 1,
              "created_utc": "2025-12-30 06:54:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwoyahf",
                  "author": "justUseAnSvm",
                  "text": "Be very deliberate about letting go of things you can't control. This thesis is the idea behind Stoicism, and although that belief system is largely replaced, it's survived so long because at its core is a powerful idea.\n\nIt isn't always easy, but accepting your coworkers failings make your work harder, is a far more effective belief to hold because it centers your concern wholly on what you can do.",
                  "score": 3,
                  "created_utc": "2025-12-30 07:13:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx20l8c",
          "author": "matrium0",
          "text": "My experience  after 16+ years as Software Developer, developing on some 20 to 30ish projects over the years, I would say there is SOME truth to that.\n\nTo be really productive I think there are two binary variables:\n\n\\- highly motivated\n\n\\- highly skilled\n\n  \nAn developer with both TRUE is very productive. Though in my personal experience these are about equally distributed, so you could say  that only 1/4 of devs is really great, the others either lack in-depth understanding or are a bit unmotivated or (absolute worst case) both.\n\nJust my personal experience ofc.",
          "score": 3,
          "created_utc": "2026-01-01 09:05:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwonvqd",
          "author": "Rygel_XV",
          "text": "The pareto principle. 80% of the work is being done by 20% of the people. It's a truth of life. But it is sad that your manager is ok with putting all work on you. This does not sound like a healthy place.",
          "score": 7,
          "created_utc": "2025-12-30 05:47:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwoobkn",
              "author": "StillUnkownProfile",
              "text": "Yeah, given the current market situation, making a shift is nearly impossible, so Iâ€™ll have to put up with this environment or project for now.",
              "score": 2,
              "created_utc": "2025-12-30 05:51:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpp7q5",
          "author": "Ok-Craft4844",
          "text": "Tbh, \"70% not contributing\" is optimistic, it's more like 30% not contributing, 20% trying to contribute at a net loss (but maybe will be there some day) and 20% actively working against the project, be it with forcing discussions over fictional or already solved concerns, introducing bullshit compliance or \"best practices\".",
          "score": 2,
          "created_utc": "2025-12-30 11:21:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqi5g2",
          "author": "dmangd",
          "text": "My response would be: ok, the Fire the non-contributing 70% and give me their salary",
          "score": 2,
          "created_utc": "2025-12-30 14:35:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwv82wu",
          "author": "Crafty-Pool7864",
          "text": "Start saying no. Your manager has clearly told you thereâ€™s no repercussions for bad performance.",
          "score": 2,
          "created_utc": "2025-12-31 05:24:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nww0spe",
          "author": "SpecificNo8047",
          "text": "Excuse me, but this is just a bad manager, using \"it has always been like this everywhere\" as an excuse for his inability to fix the work process. If he knows there is a problem, but not fixing it, though it is literally his job, he is enabling and creating this problem.\n\nDon't listen to this bs about \"everywhere is like this\", I worked in several companies and half of them had normal work life balance, and quite an equal team contributions (not possible to have 100% equal as people are different, but it was at the level acceptable for everyone). And you know what? This normal work life balance and equal contributions were the things that were organized by a team lead and a manager, it is literally their job to organize processes in a team, pick people capable for equal consistent performance and handle these issues. So you are just working in a mismanaged place with delusional management.\n\nTrust me, as soon as you obtain health issues due to overwork and stress, and will be unable to perform as good, you will be replaced in this company in a heartbeat. Place YOUR needs first, company second. Sadly most if us learn it the hard way, as well as I did.",
          "score": 2,
          "created_utc": "2025-12-31 09:35:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwoodrb",
          "author": "FreshPrinceOfRivia",
          "text": "Somebody at my org complained that 20% of people do 80% of the work and mentioned the Pareto principle. I'm not sure it's actually that bad, but a few people do take a disproportionate amount of tasks consistently.",
          "score": 2,
          "created_utc": "2025-12-30 05:51:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwor47q",
              "author": "StillUnkownProfile",
              "text": "Itâ€™s not that they will take more tasks, the other people are not able to deliver on time and Iâ€™m being pulled into it.",
              "score": 1,
              "created_utc": "2025-12-30 06:12:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwpbtjp",
                  "author": "FreshPrinceOfRivia",
                  "text": "I've experienced that this year also. At least I'm getting promoted soon, but it sucks being pulled into projects because the \"owners\" cannot handle it on their own.",
                  "score": 2,
                  "created_utc": "2025-12-30 09:18:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwovz10",
          "author": "gbrennon",
          "text": "I think i underrstood ur \"pain\"... But thats life ðŸ˜¢\n\nTry to motivate other contributors so u don't carry the whole company.... \n\nIve experienced this several times and it proved that the company doesnt even isnt autonomous....\n\nIn this scenario if 1 persona got involved in any accident the businness willl be impacted",
          "score": 1,
          "created_utc": "2025-12-30 06:53:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwozmey",
              "author": "StillUnkownProfile",
              "text": "True, theyâ€™re senior, so feedback might not go anywhere. But I guess itâ€™s worth a try since there arenâ€™t many other options.",
              "score": 1,
              "created_utc": "2025-12-30 07:25:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx54oqb",
                  "author": "salva922",
                  "text": "Always been on the 20%. I have no degree and lead a team of eth grads.\n\nI used this as leverage for getting higher salary as all others. Like this i bought a gls amg 63, RR Cullinan and a house.\n\nI make visible what I do...presentstions, internal blog posts, etc. And ofc the metrics of your ticketing system etc.",
                  "score": 1,
                  "created_utc": "2026-01-01 21:14:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpbaif",
          "author": "wonder_grove",
          "text": "Are we sure the 20(30, whatever)% do a good job with the 80(70)% of the work? In my recent experience, there are devs who start a project/feature, they leave to the next sexy thing and the others are left with their bugs/leftovers.",
          "score": 1,
          "created_utc": "2025-12-30 09:13:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwprpj7",
              "author": "StillUnkownProfile",
              "text": "Yeah, that happens too. I think it really varies by organization and culture. In my case, the frustration is that I end up doing both: building new features and cleaning up bugs left behind by others.",
              "score": 1,
              "created_utc": "2025-12-30 11:42:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpjy0m",
          "author": "quincycs",
          "text": "Hi, been there.  Itâ€™s alluring to become part of the problem by having unfinished work too. \n\nTry to verify some accusations you may be having and make a friend with another manager or someone above your manager. \n\n1. Is it really true that the manager is doing nothing nor sees it as a problem to solve?  Or was it just a way of the manager giving you validation that it is a problem.  I canâ€™t imagine the 80/20 rule being enough to explain away the situation to a higher up.  Everyone should be contributing to the teamâ€™s performance appropriate to their level.  If not a contributorâ€¦ boom. \n\n2. Gather data so itâ€™s not just your own feelings of burn out talking.  Are there metrics that are tracked today?  Find a way to explain that the organization can be significantly more efficient and craft a measurement system.  The measurement could be as simple as tickets completed per sprint.  Then the managers job should be to identify individuals who are consistently underperforming to the teamâ€™s avg.   Consider level (junior/senior) as another factor whether someone should be contributing more or less.",
          "score": 1,
          "created_utc": "2025-12-30 10:33:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpl4cy",
          "author": "quincycs",
          "text": "Consider also you may just be experiencing growing pains of seniority.  Generally the more good you get, the more lonely it can feel.  This â€œlonelinessâ€ is a way of framing the pain you feel of â€œwhy am I the onlyâ€¦â€.   Sometimes the answer is simply because you care more or worked harder or had better parents.  Try and pick a lost sheep who has potential in being trained to be more like you â€” mentor someone & find someone to mentor you.",
          "score": 1,
          "created_utc": "2025-12-30 10:44:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwq6zjf",
          "author": "gormami",
          "text": "I would say in terms of contribution, that may be correct, depending on how you define the project team.  As a security practitioner, I need to be aware of projects, and have my own items to check off, but don't contribute to what most people think of as the project.  The same is true of operations and support roles, depending on exactly how the definitions fall.  They are there to receive information, and perhaps steer things a bit, but don't contribute to the execution of the project directly, they just make sure the exit criteria are met so that they can do their jobs once it is launched.\n\nThat is very different than having tasks assigned to others moved to you when they are not completed by the original assignee.  That is a management problem.  If those persons work for your manager, they should be held directly accountable for delivery.  If they work for other teams, it could be performance that your manager should address with theirs, or it could be poor project planning/management.  If that person's supervisor was not made aware of the workload of the project, and agreed to it before it got started, then it is not surprising that other tasks for their team might be preventing them from completing the ones for this project.  This is one of the biggest failures I've seen in project management, grabbing someone, particularly SMEs, for a project, but never getting their boss's agreement, so they don't have the time to do what the project wants. \"Matrix organizations\" are famous for that, in the end, you can't really serve more than one master.  Some**one** has to have the final say on your time and production.",
          "score": 1,
          "created_utc": "2025-12-30 13:31:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6rkgk",
          "author": "Pale_Height_1251",
          "text": "The 30% will be variable, probably depending on the size of the company/team, smaller teams tend to be better, in my experience. \n\nBut as a concept, probably true, it's surprising how many people in a team aren't really adding much value. Even people who are *good* at what they do, when they leave sometimes you realise that they were good at what they did, but didn't actually *do* that much of it.",
          "score": 1,
          "created_utc": "2026-01-02 02:45:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx77al5",
          "author": "Main-Eagle-26",
          "text": "Always been true. Every workplace Iâ€™ve ever been in there is dead weight and then the actual workers.",
          "score": 1,
          "created_utc": "2026-01-02 04:26:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx77uma",
              "author": "StillUnkownProfile",
              "text": "Even the startups?",
              "score": 1,
              "created_utc": "2026-01-02 04:29:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx81t4k",
          "author": "Slow-Bodybuilder-972",
          "text": "Iâ€™d be surprised if it was as high as 30%.\n\nMy current job, Iâ€™d say itâ€™s about 50%, previous job, 10%.",
          "score": 1,
          "created_utc": "2026-01-02 08:34:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqf5ha",
          "author": "dashingThroughSnow12",
          "text": "It varies over time and part of your managerâ€™s job is to fix this.\n\nYou can do a task in an hour that Jim would take two days and a lengthy review to do. It is obvious why you get the task. But Jim is a perfectly smart guy. He needs coaching and opportunities to get better. Given enough experience in your stack, Jim can do that task in half a day and an easy review. Debora likewise. She works on a bunch of small tickets because her confidence sucks. Your manager needs to get her out of her comfort zone and have her do larger, more impactful tasks. To be the primary contributor to a small project instead of only ever a helper.\n\nI was in the scenario you describe yourself in earlier this year. My manager fixed it by upskilling many of the team mates.",
          "score": 0,
          "created_utc": "2025-12-30 14:19:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q20ike",
      "title": "A lot of edge cases donâ€™t live in code , they live between teams",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q20ike/a_lot_of_edge_cases_dont_live_in_code_they_live/",
      "author": "Suspicious-Case1667",
      "created_utc": "2026-01-02 14:49:53",
      "score": 39,
      "num_comments": 9,
      "upvote_ratio": 0.9,
      "text": "Something Iâ€™ve noticed working with complex SaaS products: many of the hardest edge cases arenâ€™t caused by missing validations or bad logic. They come from how different teams interpret and own the system.\n\nProduct defines a rule one way.\nEngineering implements a reasonable version of it.\nBilling assumes something slightly different.\nSupport adds exceptions to keep customers happy.\nFinance looks at outcomes months later.\nEach piece is â€œcorrectâ€ in isolation.\n\nBut when those interpretations stack over time, you end up with workflows that technically work, yet produce unintended long-lived states financial drift, entitlement confusion, or accounts that donâ€™t match policy anymore.\nNo single line of code is wrong.\nNo single team â€œbrokeâ€ anything.\nAnd because nothing crashes or alerts, the issue survives quietly.\n\nThatâ€™s why these edge cases are so hard to fix:\n\nNo clear owner across the full lifecycle\nFixing it might hurt legitimate users\nSupport already has a manual workaround\nThe cost shows up slowly, not catastrophically\nFrom the outside it looks like a weird edge case.\nFrom inside the org, itâ€™s often just organizational gravity.\nThis is also why many of these issues are discoverable purely through the frontend. The UI reflects what the company allows culturally and operationally, not just what the backend enforces.\n\nHave you run into edge cases that werenâ€™t â€œbugsâ€ but also werenâ€™t really intentional?\nHow do your teams decide when something is acceptable behavior vs something to close?",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q20ike/a_lot_of_edge_cases_dont_live_in_code_they_live/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nx9vuwx",
          "author": "dashingThroughSnow12",
          "text": "AI generated?",
          "score": 18,
          "created_utc": "2026-01-02 16:16:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx9x2pr",
          "author": "Sad_Amphibian_2311",
          "text": "These are IMO the most interesting things to find and be aware of in a system. I found them in every job I had, and they are often a missing piece to many puzzles. Not that any the puzzles could easily be solved, in most cases things were too cemented and the perceived business value of the edge cases was too low to address the problem at a fundamental level. By now my mantra is \"there are no edge cases\" because too often it's not an isolated edge case but a variation which - if properly understood - would lead to a whole new understanding of the non-edge cases as well.",
          "score": 3,
          "created_utc": "2026-01-02 16:22:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxapo5f",
          "author": "TehLittleOne",
          "text": "For me it's always a matter of how big of a problem it is. There's always going to be something but the guiding principle is always based on what the outcome is. If it's a five alarm fire where it will block users from logging in, great, I'm fixing it now, consequences be damned for any other team. If it causes some field to show up wrong in the support portal that they can live with, probably won't be fixed any time soon. So essentially my acceptability aligns directly with severity. Maybe once upon a time I cared but at some point things scale and you kind of just have to accept no harm no foul.\n\nAlso one way I try to counteract this is have engineers write documentation that is full-featured. I want to see what the admin portal looks like with the data, I want to know how the data flows between different parts or what the database is supposed to look like. I basically tackle every problem of documentation as anyone in the org should be capable of reading it to some degree. Obviously not everyone is going to understand everything, but I want something for everyone in there, organized well enough they can quickly skim to the relevant parts. I quite routinely tell people to pretend someone else is reading it and to see if they can make sense of it. For example, I'll tell them to pretend the CTO is reading it. Is the documentation lacking a high level technical summary? What if it's the CFO instead? One of them I can be much more technical with but neither of them want to understand the schemas.\n\nAnother way we counteract this is by cross team reviews. If you are working on something that touches code another team owns you need to reach out to that team (typically their engineering lead) and get them to review. I've caught a lot of issues like this by reviewing code for other teams. Better to spend 15 minutes now preventing an issue than 15 hours fixing it later.",
          "score": 3,
          "created_utc": "2026-01-02 18:35:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxrkslj",
          "author": "couchwarmer",
          "text": "All the time. Slurping data from Epic is always an adventure. The HL7 v2 feed and FHIR API result are generally easy to match up. But when you need to pull from the crazy that is the Clarity extract, you eventually laugh, cry, or drink in frustration. Someone somewhere knows how all three correspond exactly for a given FHIR resource, but in however many years I've yet to find one of those someones.",
          "score": 3,
          "created_utc": "2026-01-05 04:59:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxde2j0",
          "author": "Quiet-Arm-641",
          "text": "Conwayâ€™s Law",
          "score": 5,
          "created_utc": "2026-01-03 02:58:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx9jn6m",
          "author": "halfxdeveloper",
          "text": "Thereâ€™s a company that started on the mainframe. Users were comfortable with it and had learned its quirks. The development teams would build a product with loose restrictions and the users would find ways to make it work for their specific use case. One in particular was a field called â€œstatusâ€ that was just an open field with two characters. The uses for that field were so wild that I canâ€™t even name 10% of them. But each team had its own use for that field and Iâ€™m fairly certain every combination of two characters was used. The business wanted to modernize eventually and the cobol programs were converted to jsp pages with spring backend. And of course, a two character â€œstatusâ€ field. One day a director asked the development team to have a certain two character combination (a period and question mark) trigger a workflow in the backend when a user saved that status. Once other directors found out that was a thing you could do, they requested their own triggers for combinations and of course that switch statement grew like wildfire. Of course, any smart individual would see where this is headed. Some teams were having processes kick off because they typed a combination that meant one thing to them but something else for a different team. Was this a bug? No. But it highlights your point precisely. As the number of stakeholders grows and the number of development teams grows, this is just how things go in large corporations. Funny enough, the next modernization effort was led by an IT VP who was a very close minded individual that insisted the â€œstatusâ€ field would not live to see another day. It was (unsurprisingly) one of the top listed reasons why users refused to use the new web interface and several went back to using the mainframe.",
          "score": 4,
          "created_utc": "2026-01-02 15:17:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxscbae",
          "author": "elch78",
          "text": "The quote \"all models are wrong, some models are useful\" comes to my mind when I read this.",
          "score": 2,
          "created_utc": "2026-01-05 08:47:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxscwb8",
              "author": "Suspicious-Case1667",
              "text": "Exactly. The model isn't \"wrong\" in isolation it's just incomplete once it meets real people, incentives, and time. Most of the issues I've seen come from where multiple \"useful\" models overlap and quietly contradict each other.",
              "score": 1,
              "created_utc": "2026-01-05 08:52:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q0buq1",
      "title": "Did i do any good? Trying to graph and understand DDD using Clean Architecture book as source.",
      "subreddit": "softwarearchitecture",
      "url": "https://i.redd.it/8vjt3bgz6jag1.jpeg",
      "author": "Smileynator",
      "created_utc": "2025-12-31 12:26:12",
      "score": 37,
      "num_comments": 12,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q0buq1/did_i_do_any_good_trying_to_graph_and_understand/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwwmsej",
          "author": "heavy-minium",
          "text": "I think this mostly addresses the later part that comes after DDD. First you start with the domain(s) and not the architecture. Then you create bounded contexts, make up the core business rules, define an ubiquitous language, think about how to integrate different bounded contexts (e.g. events, ACLs) and once you start diving into what you've been looking at here, that's where the DDD design phase actually already ended and you are basically \"implementing\" it with a specific software architecture. And that's where ports and adapters (hexagonal architecture) often come in, because you want the domain model independent from frameworks and storage. The often used SAGA pattern is also as a concern of implementation that fullfills DDD constraints, but isn't part of the DDD itself.",
          "score": 16,
          "created_utc": "2025-12-31 12:48:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwsb3i",
              "author": "Smileynator",
              "text": "i might not have all my terminology and segregation thereof down yet then. are there any good sources to recommend for Hexagonal Architecture?",
              "score": 2,
              "created_utc": "2025-12-31 13:26:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwwu9sv",
                  "author": "heavy-minium",
                  "text": "Isn't that coming up in the Clean Architecture book? Hmm, there are so many things named like this and similar. The terms are actually quite ambiguous, I just remembered a page where this kind of stuff was elaborated on this way:\n\n>Applications that follow the Dependency Inversion Principle as well as the Domain-Driven Design (DDD) principles tend to arrive at a similar architecture. This architecture has gone by many names over the years. One of the first names was Hexagonal Architecture, followed by Ports-and-Adapters. More recently, it's been cited as theÂ [Onion Architecture](https://jeffreypalermo.com/blog/the-onion-architecture-part-1/)Â orÂ [Clean Architecture](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html). The latter name, Clean Architecture, is used as the name for this architecture in this e-book.\n\n>\\[...\\]\n\n>Clean architecture puts the business logic and application model at the center of the application. Instead of having business logic depend on data access or other infrastructure concerns, this dependency is inverted: infrastructure and implementation details depend on the Application Core. This functionality is achieved by defining abstractions, or interfaces, in the Application Core, which are then implemented by types defined in the Infrastructure layer. A common way of visualizing this architecture is to use a series of concentric circles, similar to an onion. Figure 5-7 shows an example of this style of architectural representation.",
                  "score": 3,
                  "created_utc": "2025-12-31 13:38:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwwx2zr",
          "author": "RipProfessional3375",
          "text": "Honestly, with things like Clean Architecture and DDD, read them, try to get a feeling for the general principles, and then try to apply them to some real cases and see how it feels.\n\nI am very positive that you cannot grasp a larger architectural principle by reading about it. The reading helps introduce you to the ideas so you can color your real world experience with a new perspective. Anyone trying to memorize the rules of an architectural style without understanding the principles is going to make some pretty terrible stuff.\n\nAlways focus on making things that work, while doing so, learn how some the principles of the architectures you read about could apply here, could have saved you some trouble, etc. Don't try to let a ruleset do the thinking for you, it never works.",
          "score": 9,
          "created_utc": "2025-12-31 13:55:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxequ7",
              "author": "Smileynator",
              "text": "i don't think i am trying too. the whole point of this diagram was to make some sort of mold. not a strict rule set.\n\nthe issue i personally had with reasoning through an idea in any idea of an architecure was \"ok but i don't see how or where i would then resolve X or Y, or if i do, i think the end result is a mess, or poorly maintainable\"\n\nIn my effort to get other team members on board with DDD in general, and clean architecture that is somewhat standardized across the growing company, i wanted to try and use the diagram to reason through use-cases, to reason why X or Y should be resolved at step Z or W.\n\n  \ni am trying to figure out a way to get people along which doesn't boil down to \"read this 300 page book and practice it unquestionably for a few months\" that is never going to fly anyway. then again maybe i am too ambitious for wanting to even try this.",
              "score": 2,
              "created_utc": "2025-12-31 15:32:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx7sq2p",
                  "author": "gbrennon",
                  "text": "I think u can do some practice sessions with ur team members and slowly apply some concepts so they understand it without noticing! \n\nAnd then u just tell them something like \"u just applied the foo principles from the book bar\" ðŸ¤“",
                  "score": 1,
                  "created_utc": "2026-01-02 07:09:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx5th3k",
          "author": "Gorgo4",
          "text": "If you want to do it with clean architecture, than I think you are looking for this kind of book\n\nhttps://preview.redd.it/w2xclgdzjtag1.jpeg?width=3024&format=pjpg&auto=webp&s=522dbeeed34bf5a9e2c7376a5d09907f021a4b2c\n\nI get the feeling, that you might have mixed DDD with clean architecture a bit. When I tried something similar (convincing a customer that is), I have benefited from turning this around. There was no Point for me convincing anyone. It was more beneficial to explore why DDD might be helpful with what we suffer with (measurable). So first, I had to explore what I struggle with and if DDD might be worth it over other solutions that are faster, easier, cheaper or more accepted by my fellow engineers. Like writing an ADR and challenge the options by your Team. This was a more open aproach than trying to convince someone (which was my first Impuls als well).\n\nIt also helped me to understand the difference between strategical and tactical DDD to see why clean architecture is just ohne way  to do domain centric implemtation. The DDD-crew repo might be a good Point to picture this. See: [https://github.com/ddd-crew/ddd-starter-modelling-process](https://github.com/ddd-crew/ddd-starter-modelling-process)\n\nWhile clean architecture is good to close the architecture Code gap, it is not always beneficial. I guess you know most of this, as you have mentioned with the silver bullet. But this Point did only driven into my brain once I really started working with it. But I still prefer clean architecture whenever it is reasonable. I simply have a new measure for what is reasonable.\n\nI recoment \"learing Domain driven Design\" from vlad khononov to learn DDD itself. Or rather, to visit a good course to discuss this with others who try to lear this and a teacher who is stuck with you.",
          "score": 2,
          "created_utc": "2026-01-01 23:25:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7sw2u",
              "author": "gbrennon",
              "text": "I love this book because its about how to do and what to do!",
              "score": 2,
              "created_utc": "2026-01-02 07:10:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx6ramq",
          "author": "gbrennon",
          "text": "domain shouldnt call any other layer.\n\nit should be like the kernel of ur software.\n\napplication layer should call domain layer and delegate logic to infrastructure layer through ports.\n\npresentation layer should manage the calls through presenters.\n\nthis layer can contains a composition root that wires the implementations",
          "score": 1,
          "created_utc": "2026-01-02 02:44:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7q82f",
              "author": "bigkahuna1uk",
              "text": "Iâ€™m donâ€™t quite follow. The domain can be driven or or it can drive other domains through the use of ports  that are part of its domain. The implementation of the ports, the adapters, allow the domain to call the other layers through ports. So the domain layer can interact indirectly with other layers. \n\nYou describe a driver scenario which invokes the domain. But the converse can also be true. The domain can also drive. For instance the domain wishing to persist data to a repository or sending out a notification is an action driven from the domain. Itâ€™s instigated from the domain itself.",
              "score": 1,
              "created_utc": "2026-01-02 06:47:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx7rrc8",
                  "author": "gbrennon",
                  "text": "I undestood u bro ðŸ¤“\n\nI love ports and adapters from alistair cockburn!\n\nremember that if the domain is driving or been driven  it defines the ports so it can be driven, right?\n\nIf he uses some port for composing an implementatio it is doing this so that who is outside interact with it, right? \n\nPorts are a way to delegate logic to someone else and to focus on the business or application logic!",
                  "score": 1,
                  "created_utc": "2026-01-02 07:00:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q19kce",
      "title": "How do large hotel metasearch platforms (like Booking or Expedia) handle sorting, filtering, and pricing caches at scale?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q19kce/how_do_large_hotel_metasearch_platforms_like/",
      "author": "Sweaty_Ingenuity_824",
      "created_utc": "2026-01-01 17:26:33",
      "score": 35,
      "num_comments": 34,
      "upvote_ratio": 0.89,
      "text": "Iâ€™m building a unified hotel search API that aggregates inventory from multiple suppliers (TBO, Hotelbeds, etc.). Users search by city, dates, and room configuration, and I return a list of hotels with prices, similar to Google Hotels or Booking.\n\nI currently have around 3 million hotels stored in PostgreSQL with full static metadata (name, city, star rating, facilities, coordinates, and so on). Pricing, however, is fully dynamic and only comes from external supplier APIs. I canâ€™t know the price until I call the supplier with specific dates and occupancy.\n\n**Goal**\n\n* Expose a fast, stateless, paginated `/search` endpoint.\n* Support sorting (price, rating) and filtering (stars, facilities).\n* Minimize real-time supplier calls, since they are slow, rate-limited, and expensive.\n\n**Core problem**  \nIf I only fetch real-time prices for, say, 20 hotels per page, how do I accurately sort or filter the full result set? For example, â€œshow the cheapest hotel among 10,000 hotels in Dubai.â€  \nCalling suppliers for all hotels on every search is not feasible due to cost, latency, and reliability.\n\n**Current ideas**\n\n1. Cache prices per hotel, date, and occupancy in Redis with a TTL of around 30â€“60 minutes. Use cached or estimated prices in search results, and only call suppliers in real time on the hotel detail page.\n2. Pre-warm caches for popular routes and date ranges (for example, Dubai or Paris for the next month) using background jobs.\n3. Restrict search-time sorting and filtering to whatâ€™s possible with cached or static data:\n   * Sort by cached price.\n   * Filter by stars and facilities.\n   * Avoid filters that require real-time data, such as free cancellation.\n\n**Questions**\n\n1. How do large platforms like Booking or Expedia actually approach this? Do they rely on cached or estimated prices in search results and only fetch real rates on the detail page?\n2. Whatâ€™s a reasonable caching strategy for highly dynamic pricing?\n   * Typical TTLs?\n   * How do you handle volatility or last-minute price changes?\n   * Is ML-based price prediction commonly used when the cache is stale?\n3. How is sorting implemented without pricing every hotel? Is it common to price a larger subset (for example, the top 500â€“1,000 hotels) and sort only within that set?\n4. Any advice on data modeling? Should cached prices live in Redis only, PostgreSQL, or a dedicated pricing service?\n5. What common pitfalls should I watch out for, especially around stale prices and user trust?\n\n**Stack**\n\n* NestJS with TypeScript\n* PostgreSQL (PostGIS for location queries)\n* Redis for caching\n* Multiple external supplier APIs, called asynchronously\n\nIâ€™ve read a lot about metasearch architectures at a high level, but I havenâ€™t found concrete details on how large systems handle pricing and sorting together at scale. Insights from anyone who has worked on travel or large-scale e-commerce search would be really appreciated.\n\nThanks.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q19kce/how_do_large_hotel_metasearch_platforms_like/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nx3ynjw",
          "author": "Slow-Entertainment20",
          "text": "My assumption is that when people are searching for prices is based on a city, so geographic location with a specific geospatial DB matters. There might be 10k hotels in Dubai but in a specific city thereâ€™s probably 200 or less. Which breaks the problem down drastically.",
          "score": 8,
          "created_utc": "2026-01-01 17:42:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx4117m",
              "author": "Sweaty_Ingenuity_824",
              "text": "Youâ€™re right that search is geo-based, but in practice the number can still be very large. Many major cities have thousands of properties once you include hotels, serviced apartments, and other types of stays. For example, Dubai has 8,000+ properties and Paris has 5,000+, so even within a single city the search space is often much bigger than a few hundred hotels. Thatâ€™s why pricing, caching, and ranking still need to work at large scale even with geographic filtering.",
              "score": 1,
              "created_utc": "2026-01-01 17:54:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx5h6mg",
                  "author": "mnp",
                  "text": "Sorting a collection of 1e3 items should only take milliseconds. Is that really the problem here?",
                  "score": 7,
                  "created_utc": "2026-01-01 22:18:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx6ejnl",
                  "author": "BlackHolesAreHungry",
                  "text": "You can sort an array of a million integers in memory easily. You need a big db only if you have more than a million rows.",
                  "score": 2,
                  "created_utc": "2026-01-02 01:26:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx66n5o",
          "author": "lighthouserecipes",
          "text": "I was technical co-founder of an accomodations metasearch that included both hotels and Airbnb.Â  It is now defunct but we solved this by a similar stack to what you are thinking of.\n\n\nNodejs, postgresql with postgis, redis.\n\n\nOur data sources were a mix of real time APIs, scraped calendars off Airbnb, real-time scraping of some sites, ftp of daily inventory and price feeds, etcÂ \n\n\nWe went for max accuracy by hitting every API every time, with a little caching here and there. We would start rendering results instantly and send the prices to the browser as they arrived. The server handled pagination and filter range calculation and we only needed to send the browser a couple pages, but during the first 10 seconds those pages would churn a lot. The full result set was several MB for a big city, but that would just sit in memory for some minutes after the session and then get dumped.",
          "score": 6,
          "created_utc": "2026-01-02 00:39:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx48amm",
          "author": "Qinistral",
          "text": "Why wouldnâ€™t you price every hotel? You canâ€™t sort by price if you donâ€™t price them all.\n\nFor architecture You need to use a search engine like ElasticSearch.\n\nYou keep your source of truth in Postgres, which you update at a regular cadence, then you update your search engine from that. \n\nIf you need to update your prices from 3P more frequently then you can do something like query on demand when a user queries and gets a page of results you can trigger an async query to refresh that data if itâ€™s not been refreshed in say an hour. (So most active hotels have most fresh data).\n\n1. The secret here is that customers are NOT always seeing the best most accurate globally true answer to their query. This is just a secret reality. Product design has to make hard decisions like this and account for it.\n\n2. I donâ€™t know what the landscape looks like in this industry but there are probably change FEEDs that brokers connect to. So instead of repeated polling and caching, they just listen to events that notify of price changes. This gives them near real time data.\n\n3. Brokers set their own prices. Brokers have a lot of data, so they can analyze trends and triage the market. They can buy hotel rooms with bulk discounts and then mark them up themselves, since they are setting the price, there is no consistency concerns.",
          "score": 9,
          "created_utc": "2026-01-01 18:29:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx6ea7l",
              "author": "BlackHolesAreHungry",
              "text": "Why elasticsearch? Postgres table per city or a Redis cache will do the trick",
              "score": 3,
              "created_utc": "2026-01-02 01:24:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx7jwrv",
                  "author": "ccb621",
                  "text": "Why would you create one table per city? There are anywhere from 500 to 4 million cities in the world depending on your definition of the term.Â ",
                  "score": 4,
                  "created_utc": "2026-01-02 05:55:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx7pajq",
                  "author": "Sweaty_Ingenuity_824",
                  "text": "I agree with the separation-of-concerns argument. Postgres is my source of truth, but once you mix geo, filters, sorting, scoring, and pagination at scale, a search engine becomes more practical. Postgres *can* do a lot of this (especially with PostGIS), but once ranking and re-ranking logic grows, pushing that workload into a search index feels safer long-term.",
                  "score": 3,
                  "created_utc": "2026-01-02 06:39:39",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nx6ighm",
                  "author": "Qinistral",
                  "text": "1. **Features**: I Have heard that PG has gotten more and more 'search' extensions, but I don't know how complete it is, whereas ES is basically functionally complete. Full text search, filtering on any combination of fields, sorting on many combinations of fields, relevant scoring, etc; these cannot use normal btree style indexes. Search engines are build from the ground up to support these queries, along with being very easy to scale horizontally.\n\n2. **Separation of concerns**:  Good architecture is about risk mitigation, organizational alignment, and enablement for future features.  Having a separate search engine supports all of these values.  Granted OP sounds like they're building alone in their basement so they may want to optimize for 'fast to build' over 'good' and that's fine. But for public guidance I'm going going to optimize my comments for 'good' :).",
                  "score": 3,
                  "created_utc": "2026-01-02 01:50:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny0y14d",
                  "author": "saravanasai1412",
                  "text": "Elasticsearch / Alogila / Typesense is build for these searching capabilities. Postgres can't handle user typo & perform semantic search in sub ms latency at very large dataset. Its come with cost but worth than implementing our own search algorithms.",
                  "score": 1,
                  "created_utc": "2026-01-06 15:57:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx7p4ud",
              "author": "Sweaty_Ingenuity_824",
              "text": "Pricing every hotel sounds correct in theory, but at 3M+ properties it isnâ€™t feasible in practice due to supplier rate limits, latency, and cost. Even within one city, pricing thousands of hotels for every date/occupancy combination explodes quickly. Thatâ€™s why Iâ€™m exploring partial pricing + cached/derived prices for ranking, with real pricing happening on detail or pre-booking. I agree with your point though: users are not always seeing a globally perfect answer, and product has to accept that trade-off.",
              "score": 1,
              "created_utc": "2026-01-02 06:38:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx88j7t",
          "author": "newleafturned2024",
          "text": "I used to work in this space. A couple of things in no particular order:-\n\n1. Booking and Expedia are not metasearch, they're OTAs. Metasearch refers to services like Google Hotels and Kayak where they aggregate OTA results.\n\n2. Typically what happens is between search and reservation, there's an extra step that does live search. Some call  it availability check, it has all sorts of names - there's no standard here. This allows you to have slightly more control over the TTL while balancing between supplier rate limits and info accuracy.\n\n3. Back to caching search results: you pretty much figured it out already but unfortunately I don't believe there's a perfect solution. You'll have to find a sweet spot that works for you in terms of supplier rate limits, cost, and accuracy. \n\n4. My suggestion is specialize in a niche and limit the number of hotels. For TTL, I think we used to set it to a constant number like x minutes. In general, prices for stays far in the future tend to fluctuate less. But it's not a law! They also get less searches. So if you set a higher TTL for these searches, you might get higher hit but sacrifice cache utilization - which is important if you want to optimize for cost - you don't want Redis to store data no one will access!\n\n5. Pre-warming cache - only works if your feed is small and your search traffic has low entropy (all of them search for the same hotel/location). Otherwise you'll be wasting supplier API rate limits on artificial queries.\n\nI no longer work in this space but I'm still following travel tech from time to time. Hit me up if you want some free advice that may or may not be relevant.",
          "score": 2,
          "created_utc": "2026-01-02 09:38:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx51z7l",
          "author": "maxufimo",
          "text": "If I remember correctly, the large providers like Expedia and Booking are maintaining their own inventory, most channel managers will be pushing the current price to them.\n\n\nOne pattern I see with smaller aggregators is to pull the pricing data periodically, since bulk operations are usually cheaper, and caching this for searching and sorting. Then they refresh the pricing data for specific booking dates and occupancy when displaying the details.",
          "score": 1,
          "created_utc": "2026-01-01 20:59:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7puc2",
              "author": "Sweaty_Ingenuity_824",
              "text": "Yes, that matches what Iâ€™ve seen as well. Large players get pushed updates or bulk feeds and can maintain their own inventory, while smaller aggregators usually rely on periodic bulk pulls and caching for search and sorting. Then they re-fetch or refresh prices for the exact dates and occupancy on the detail or booking step. My challenge is figuring out how to model and cache those bulk prices in a way that still works for sorting when search parameters vary a lot.",
              "score": 1,
              "created_utc": "2026-01-02 06:44:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx5w4ev",
          "author": "sansp00",
          "text": "Used to work in the field a couple of years ago. At that time, companies like Expedia would get a daily dump of the inventory+price to build their catalog. They used to have only  a subset of the pricing (1/2/4 pax) which are the most common. At the time , the look to book ratio was around 3%, so when customers would move forward, the real call to the tour operator would be done and the price would be updated to reflect the 'true' value.",
          "score": 1,
          "created_utc": "2026-01-01 23:40:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7q6pm",
              "author": "Sweaty_Ingenuity_824",
              "text": "Yes, thatâ€™s exactly the direction I want to take as well avoid calling providers until the user is actually moving toward booking. Periodic dumps for a subset (like 1/2/4 pax) make sense and I can do that for top 200â€“500 hotels in a city.\n\nThe open question for me is the long tail. In a city like Dubai, that still leaves 6â€“7k less popular hotels. I canâ€™t realistically dump or keep prices updated for all of them, but I still need some price signal for search and sorting. Thatâ€™s the part Iâ€™m trying to figure out: how to represent pricing for those long-tail properties without polling every hotel or overloading suppliers.",
              "score": 1,
              "created_utc": "2026-01-02 06:47:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx9jnm6",
                  "author": "sansp00",
                  "text": "Do you have 'deals' brokered with them ? Back in the day, we needed deals to resell and most of them included the B2B API's and inventory catalog (not all sites get the same inventory). The block of inventory you are allowed to sell can in some cases not even be hosted with the provider. For long tail stuff, the information is sometimes entered manually within the system and you don't have any API and or dump. Happened a couple of times on previous trips where I had a confirmed booking with an online platform only to realize at the hotel that the room was already booked (due to no real time B2B integration)",
                  "score": 1,
                  "created_utc": "2026-01-02 15:17:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx6vnwm",
          "author": "bert1589",
          "text": "I worked in this space years ago. Most of those suppliers just have negotiated rates and allotments that they knew the pricing for based on all the variables.",
          "score": 1,
          "created_utc": "2026-01-02 03:11:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7qhg6",
              "author": "Sweaty_Ingenuity_824",
              "text": "That makes sense for large suppliers or OTAs that directly negotiate rates and control allotments. In my case, the product is a unified hotel API for smaller OTAs. They donâ€™t want to integrate 3â€“4 different suppliers, manage separate integrations, handle hotel mapping, or maintain static hotel data themselves. The goal is to abstract all of that behind a single API, so they can access inventory and pricing from multiple providers without dealing with individual supplier integrations or maintaining their own hotel database.",
              "score": 1,
              "created_utc": "2026-01-02 06:49:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxdj7b0",
          "author": "Happyman501",
          "text": "Have couple of questions ,\n1 . Do  hotel prices vary daily .\n2. Do they have base prices set . \n\nDepending on the answers it would be combination of elastic search and redis . Redis would be the main guy here, since it would hold prices with a expiry date etc and fast lookups . Plus event driven architecture either a queue and lamda or  function updating redis keys  and other things like notifyjng customers etc.\n\nAlso redis has geo search and geo columns , i gues postgress and comos also have them but redis is faster . You can narrow your searvh and have a radius to search",
          "score": 1,
          "created_utc": "2026-01-03 03:29:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxdy578",
          "author": "Blakeacheson",
          "text": "What if you sampled each hotel (continually) to establish a general cost profile â€¦. And then used this data to perform a full fetch in realtime of the top 10 cheapest hotels?",
          "score": 1,
          "created_utc": "2026-01-03 05:06:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx44zoe",
          "author": "mark_tyler",
          "text": "Look at ElasticSearch or something similar",
          "score": 1,
          "created_utc": "2026-01-01 18:13:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7lfns",
          "author": "No_Flan4401",
          "text": "I don't see the problem with only 3 million rows? Slap good index on it and run the queries?Â \n\n\nI admit I only skimmed your post but what problem do you experience at the moment, what are we trying to solve here?",
          "score": 0,
          "created_utc": "2026-01-02 06:07:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7r0ra",
              "author": "Sweaty_Ingenuity_824",
              "text": "The issue isnâ€™t the 3 million rows or querying them static data is easy to handle with proper indexing. The real problem is pricing.\n\nPrices donâ€™t live in my database; they come from supplier APIs, and fetching them requires external calls. I donâ€™t want to call suppliers for every hotel on every search. Thatâ€™s why Iâ€™m looking to design a pricing cache/pool that is refreshed periodically.\n\nThe difficulty is that a single hotel doesnâ€™t have one price. Pricing depends on multiple variables like check-in date, length of stay, rooms, and occupancy. So the question isnâ€™t â€œhow to query 3M hotels,â€ but â€œhow to model and cache pricing signalsâ€ in a way that:\n\n* Avoids calling suppliers for every search\n* Handles many pricing permutations reasonably\n* Allows approximate pricing for low-visibility hotels (without supplier calls) so sorting still works\n* Uses real supplier calls only for popular properties or when the user moves toward booking\n\nThatâ€™s the core problem Iâ€™m trying to solve.",
              "score": 1,
              "created_utc": "2026-01-02 06:54:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx87wuf",
                  "author": "No_Flan4401",
                  "text": "Thanks for clarifying.Â \n\n\nSo the problem is you don't have access to the data or am I still misreading? Is this a personal project or a commercial?Â \nI don't know the hotel and pricing space, but I'm guessing the other providers use either a common pricing api/brooker where hotels deliver informations or they make individual agreements with hotels and calculate price based on some different rules?\nIf you need this data for commercial use you need to consider the legal stuff, if it's ok to show the data on your site. I would investigate how the other providers get their data.\n\n\nI'm not sure if it's possible but perhaps you need to limit the scope to a start. So you users can only get prices for x variables u support? Perhaps you can combine the cache with some scraping of the individual sites, but again it depends on how non static the pricing data is.Â \n\n\nI totally get you think this is hard but perhaps a possibility is your application don't make sense when you don't own the pricing data?",
                  "score": 1,
                  "created_utc": "2026-01-02 09:32:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx46bmb",
          "author": "GrogRedLub4242",
          "text": "I've worked for 2 of the major travel ecommerce shops that did exactly that as a senior engineer/architect. If you have budget for professional consultation you're welcome to DM me.",
          "score": -13,
          "created_utc": "2026-01-01 18:20:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx4s64j",
          "author": "dashingThroughSnow12",
          "text": "By not spamming a bunch of subreddits with this question.",
          "score": -7,
          "created_utc": "2026-01-01 20:08:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q23osh",
      "title": "How do you keep architecture decisions lightweight without losing context over time?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q23osh/how_do_you_keep_architecture_decisions/",
      "author": "manwhoos",
      "created_utc": "2026-01-02 16:50:20",
      "score": 34,
      "num_comments": 16,
      "upvote_ratio": 1.0,
      "text": "Iâ€™m trying to find a balance between keeping architecture decisions flexible and still documenting enough context so things donâ€™t get lost after a few months. Full-blown documentation tends to age quickly, but when nothing is written down, future developers have no idea why certain choices were made. ADRs seem useful, but in many teams they either feel too formal or eventually get ignored.  \n  \nIâ€™ve seen this general trade-off mentioned in some high-level materials published by [Sumatoâ¤Soft for mobile app development](https://sumatosoft.com/blog/ai-powered-iot-overview), but Iâ€™m more interested in what actually worâ¤ks in real projects. How do you document decisions just enough without letting the process become a chore?",
      "is_original_content": false,
      "link_flair_text": "Tool/Product",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q23osh/how_do_you_keep_architecture_decisions/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nxa5vn5",
          "author": "joelparkerhenderson",
          "text": "Start with a lightweight architect decision record, not a heavyweight one. See the ADR example templates and teamwork documentation here: [https://github.com/joelparkerhenderson/architecture-decision-record](https://github.com/joelparkerhenderson/architecture-decision-record)\n\nFor SumatoSoft specifically, their process documentation recommends doing ADRs with their vendors. That's a really good idea IMHO because it shows how the vendor thinks about stacks and tradeoffs.",
          "score": 10,
          "created_utc": "2026-01-02 17:03:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxah2s0",
          "author": "Qinistral",
          "text": "Iâ€™ve almost never felt the need for a decision tuned framework. We have 1:3:1 docs, design docs, tickets, pull requests, all with context.\n\nI think understanding how the system works now is more important than why it was decided. If you know how it works now you should be able to determine if it fits the needs going forward.\n\nI donâ€™t spend my time wondering â€œwhy did they pick ActoveMQ 5 years ago,â€ instead I wonder â€œgiven our current and future needs is it worth switching to Kafkaâ€, etc.",
          "score": 5,
          "created_utc": "2026-01-02 17:55:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxb30fq",
              "author": "serverhorror",
              "text": "What's \"1:3:1 docs\"?",
              "score": 4,
              "created_utc": "2026-01-02 19:37:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxbegns",
                  "author": "Qinistral",
                  "text": "\"One problem, three options, one recommendation\", and for each option you briefly describe it and list pros/cons. Then you review it with your team. (You can google \"1-3-1 decision making\" and see a lot of articles about it.)\n\nIn the context of OP, these do provide some history of decision making, but that is not their purpose. Their purpose is to make good decisions now, and they are not done for every decision, so it's not a true ledger of decisions over time.",
                  "score": 6,
                  "created_utc": "2026-01-02 20:33:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxewjqq",
              "author": "ArtSpeaker",
              "text": "\\> I think understanding how the system works now is more important than why it was decided.  \n\\> I donâ€™t spend my time wondering â€œwhy did they pick ActoveMQ 5 years ago,â€ instead I wonder â€œgiven our current and future needs is it worth switching to Kafkaâ€, etc.  \n  \nThe whys are important too, just not for everyone. Cause it's going to be a list of GOTCHAS.  Whys like \"this is currently incompatible with the tech we have (and are waiting on the right update)\", and \"our customer's  use case forcing legacy support\", and \"all teams are willing to make the change but there isn't a way to prioritize it this year\"  are all nice to have somewhere to save the future team days/weeks/months of pain rediscovering what we already know now. Not critical, but nice.  \n  \nEstablishing a set of assumptions as the foundation for the API + service choices make BIG cross team changes much easier. But not many folks are in that boat.",
              "score": 2,
              "created_utc": "2026-01-03 09:52:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxaqd2a",
          "author": "SolarNachoes",
          "text": "Wiki meeting transcripts and notes. Promote key decisions to ADRs.\n\nAnything that involves R&D gets its own wiki pages. Final take away goes to ADRs.\n\nAI can summarize a whole bunch of ADRs in one go.",
          "score": 3,
          "created_utc": "2026-01-02 18:38:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxb0wfi",
          "author": "No_Flan4401",
          "text": "As a developer what I need when on boarding a new project is to understand the system at high level. A combination of writing and diagram.works best.\nThen some docs about how the code base is structured, then some docs on design and code conventions. Often some docs about data modeling is helpful.\nFrom here on it will differ what I need, and often the above is enough and I can go read the code.Â ",
          "score": 3,
          "created_utc": "2026-01-02 19:27:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxbjyfs",
          "author": "heraldev",
          "text": "My suggestion - religiously keep all meeting notes, photos of the whiteboard, then use AI to create docs based on that. At Meta we just simply used google docs for all projects, and as long as you don't duplicate information, and keep log of everything, the documentation won't go too stale. Meeting notes get more important during the late stages of the project - when you need to update assumptions that didn't work, and this context gets lost, or more like buried in the codebase.\n\nI'm currently building a tool on top of Claude Code to generate diagrams from meeting notes and keep track of the PRDs that come after, lmk if you want to try.",
          "score": 3,
          "created_utc": "2026-01-02 21:00:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxeo1yh",
          "author": "ducki666",
          "text": "I do a lot brown field reviews.\n\nBack then it was a lot work. (And money)\n\nNow, with decent code base and iac, throw an AI on it and let explain. What I have done in weeks in the past takes now 1 day plus review and fine tuning.",
          "score": 2,
          "created_utc": "2026-01-03 08:37:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxbdjzd",
          "author": "da8BitKid",
          "text": "AIis good at summarizing. You can't just vibe it, you need to edit, but it's a good place to start.",
          "score": 1,
          "created_utc": "2026-01-02 20:29:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxc69gh",
          "author": "Happy_Breakfast7965",
          "text": "It is a chore, nothing wrong with chores.\n\nSoftware engineering requires discipline. Analysis, thinking, design, implementation, testing, releasing, etc. All require accountability and professional approach. \n\nADR can be pretty lightweight.\n\nHowever, if you want lightweight consuption of the documentation, you need to put efforts into production. If you are trying to make documentation production lightweight, consumption will be heavy.",
          "score": 1,
          "created_utc": "2026-01-02 22:51:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxbsbvv",
          "author": "Lekrii",
          "text": "Separate architecture from engineering, and don't let engineers dominate architecture conversations.",
          "score": -3,
          "created_utc": "2026-01-02 21:40:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxby80u",
              "author": "SpaceGerbil",
              "text": "What?",
              "score": 2,
              "created_utc": "2026-01-02 22:09:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxc5kxv",
                  "author": "Lekrii",
                  "text": "Architecture is high level, and strategic.  Engineering is more detailed.  If you let architecture discussions devolve into engineering, you'll spend all your time talking about details instead of the high level design and strategy.",
                  "score": 0,
                  "created_utc": "2026-01-02 22:47:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pyimcw",
      "title": "How do you work with AI as a long-term architect (docs + decisions + staying up-to-date)?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1pyimcw/how_do_you_work_with_ai_as_a_longterm_architect/",
      "author": "Acceptable-End-4636",
      "created_utc": "2025-12-29 10:08:31",
      "score": 32,
      "num_comments": 8,
      "upvote_ratio": 0.85,
      "text": "Iâ€™m looking for practical setups people use when working as an architect / platform owner on long-running projects (1â€“3 years).\n\nWhat Iâ€™m trying to optimize for:\n\n* one main workspace\n* chat with an AI assistant who can do research (also in web)\n* assistant should uses project documentation as context\n* can edit docs (e.g. Markdown or integrate with Conflu), not just answer questions\n* minimal context switching - ideally one tool\n* collaboration (let others do the same in the workspace)\n\nAdditionally, could be a separate tool for:\n\n* staying up-to-date with latest tech changes (OpenAI, Anthropic, Microsoft, Google, etc.), key aspect of new versions of frameworks etc - with ability to edit list of my interest.\n\n  \nAt the moment I have some licenses in my organization - MS Copilot license (and entire MS 365 ecosystem), Github copilot license, Confluence, and privately ChatGPT Go. But I am open for any toolsets. ",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1pyimcw/how_do_you_work_with_ai_as_a_longterm_architect/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nwj1yoz",
          "author": "arikisfruits",
          "text": "It kind of depends, but you should look into:\n* A workflow that keeps your documentation up to date, and ensures that each system and process have clear information on the scope, constraints, data models, contracts, etc. If this drifts, youâ€™re always starting from a losing position if you want to maximise correctness of the AI outputs. This can be AI assisted. \n* Governance of architectural decisions (clear why, options, decided approach, etc). Similar to the above, it ensures that you, your peers and AI have correct context.\n\nOnce you have the above, and the governance around it, you can centralise it in e.g. a git repo, and teach your LLM of choice about it. You can use pretty much any provider, but Anthropic models, especially Opus 4.5 (even Sonnet) work great with it.\n\nThis also very much depends on the size, scope and the goals youâ€™re trying to achieve. For more complex setups and tasks, Iâ€™d advise getting deep into the ecosystem of skills, MCPs, sub agents, etc.",
          "score": 9,
          "created_utc": "2025-12-29 11:27:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwj3y99",
              "author": "Acceptable-End-4636",
              "text": "Regarding centralizing in a repo - I was thinking about the same (e.g. VS Code + Github Copilot). By teaching our LLM, do you think of creating a custom system prompt that would let the agent work in more 'architect' role ? Since it is not coding, do you think Sonnet could act also great when it comes to architectural thinking, decision making, research (including tools from different players).",
              "score": 1,
              "created_utc": "2025-12-29 11:44:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwj69w3",
                  "author": "arikisfruits",
                  "text": "In essence, what you want is that the LLM always has enough quality context dependent on what goal you're trying to achieve. You do this by ensuring:  \n  \n1. You have machine-readable context (e.g. md files)  \n2. That the model is instructed to use that context, and that you steer it to behave in a certain way (boundaries, reasoning, examples of output) by giving it instructions in e.g. [CLAUDE.md](http://CLAUDE.md) file.\n\nRE: architect role, it very much depends on the quality of context you give it toâ€”that's what you want to focus on. Saying \"please write architectural documentation for an order management system\" is going to give you *something*, but most likely not what you want. On the other hand, steering the model in the right way can give you absolutely great output.\n\nRE: research capabilitiesâ€”not sure, someone else can chime in.",
                  "score": 1,
                  "created_utc": "2025-12-29 12:02:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwnky2j",
          "author": "Lekrii",
          "text": "I'm an architect for everything in three lines of business (shortest projects are a few months long, the longest running project I have has been going for 2 1/2 years so far).\n\nI occasionally ask AI questions the same as I would search on Google, but other than that I don't really use AI.  My most valuable asset is my personal knowledge.  This is just my opinion, but I'd rather put in more time and be able to do the work myself.\n\nI know a lot of people will disagree, but I'm of the mindset that AI causes as many problems as it solves.  I use it very hesitantly.",
          "score": 2,
          "created_utc": "2025-12-30 01:52:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwpi3sd",
              "author": "Acceptable-End-4636",
              "text": "Here's the confusion - I do use my knowledge, but creating a detailed System Design document with a lot of things (architecture, infrastructure, security, business logic and more) - it takes a lot of time. My idea is like - talking to chat gpt within a Project, he gets my points but produces a clean, well-structured white paper, that it can keep updating when something comes up to my mind. Also, as you might know we could give it a specific role and behavior, which may result in challenging my thoughts and sometimes bringing up topics I forgot to put into white paper. Based on such documentation, you could later easily define tasks for developers or share it with higher management.",
              "score": 1,
              "created_utc": "2025-12-30 10:16:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwu01ey",
          "author": "ElectronicFrame5726",
          "text": "You might be interested in [Where Architects Sit in the Era of AI](https://www.infoq.com/articles/architects-ai-era/) which is more of a meta perspective than a practical setup for an architect's workstation. As far as tooling is concerned, take a look at [Ask the Software Architect](https://www.exploravention.com/products/askarch/) which helps architects formulate plans for large initiatives such as major feature enhancements or paying down tech debt. In the context of the article, the tool would be an example of an AOTL model.",
          "score": 2,
          "created_utc": "2025-12-31 00:52:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmp34l",
          "author": "gmosalazar",
          "text": "Depending on how far down the rabbit hole you want to go, I might also suggest using a local version of an LLM model instead of the cloud provided ones. Thatâ€™d be one or two iterations deep.\n\nOverall Iâ€™m interested about this too, I just have a dedicated project with a major LLM provider that tracks .md files that I provide.",
          "score": 1,
          "created_utc": "2025-12-29 22:57:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmy59y",
          "author": "SirOk748",
          "text": "At some point, the decisions you make may not make sense to others without context. Collaboration across teams or individuals will be easier when everyone can easily find answers or access to previous decisions. I highly recommend this short read : [https://decisionrecords.org/blog/how-should-teams-document-important-decisions](https://decisionrecords.org/blog/how-should-teams-document-important-decisions) \\- A tool I can recommend on this topic is [decisionrecords.org](http://decisionrecords.org)",
          "score": 1,
          "created_utc": "2025-12-29 23:46:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q59bu2",
      "title": "ProtoBuf Question",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q59bu2/protobuf_question/",
      "author": "Landmark-Sloth",
      "created_utc": "2026-01-06 04:54:23",
      "score": 31,
      "num_comments": 34,
      "upvote_ratio": 0.88,
      "text": "This is probably a stupid question but I only just started looking into ProtoBuf and buffer serialization within the last week and I cannot find a solid answer to this online. \n\n  \nQ: Let's say I have a client - server setup. The server feeds many messages (of different types) to the client. At some point, the client will need to take in the byte streams and deserialize them to \"do work\". Protobuf or whatever other serialization library has methods for this but all the examples I've seen already know the end result datatype. What happens when I just receive generic messages but don't know end datatype? \n\n  \nOnline search shows possible addition of some header data that could be used to map to a datatype. Idk. Curious to hear the best way to do it, not in love with this extra info when not completely necessary. ",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q59bu2/protobuf_question/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nxyevj3",
          "author": "_Trio13_",
          "text": "I think that's one of the major issues with protobuf - the byte streams aren't self-identifying. You need to wrap or prefix each object with some type specifier. The protobuf.Any type might be a workable container. Or you could create a single top-level protobuf message and use a oneof field as a union of all your message types.",
          "score": 25,
          "created_utc": "2026-01-06 04:59:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxygfcx",
              "author": "larowin",
              "text": "This is the whole point of gRPC - you get protobufs with metadata",
              "score": 23,
              "created_utc": "2026-01-06 05:10:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxyfg6c",
          "author": "AvailableFalconn",
          "text": "Most situations Iâ€™ve used it, like in GRPC or in data warehouses, you know what data type youâ€™re expecting so this isnâ€™t an issue. Â Depending on why your data type is ambiguous, there might be solutions like using unions to wrap the relevant options. Â But in general itâ€™s not a self-documenting format.",
          "score": 13,
          "created_utc": "2026-01-06 05:03:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4qiyp",
              "author": "Landmark-Sloth",
              "text": "Thanks for the comment. I will give an example to feed the \"depending on why your data type is ambiguous\".  \n\n  \nLet's say I have a logger module. It connects to server or broker or whatever to get messages. Log messages aren't guaranteed to be the same (unless special consideration is taken). Let's say I have an embedded system. I might log data for a device, say a few voltage values, current etc. Now I also want to log system info, maybe a state machine transition etc.",
              "score": 1,
              "created_utc": "2026-01-07 02:55:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxyydjo",
          "author": "st4reater",
          "text": "Why don't you know what you're receiving?",
          "score": 9,
          "created_utc": "2026-01-06 07:37:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4qpl7",
              "author": "Landmark-Sloth",
              "text": "I responded to another message above with this example but copy - pasting here: Let's say I have a logger module. It connects to server or broker or whatever to get messages. Log messages aren't guaranteed to be the same (unless special consideration is taken). Let's say I have an embedded system. I might log data for a device, say a few voltage values, current etc. Now I also want to log system info, maybe a state machine transition etc.\n\n  \nLet me know what you think. Thanks for the comment. Below looks like bot behavior.",
              "score": 1,
              "created_utc": "2026-01-07 02:56:20",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nxz5h38",
              "author": "black_at_heart",
              "text": "Protocol Buffers (protobuf) are designed for **maximum efficiency**, which means they strip away almost all metadata that humans find helpfulâ€”like field names and data typesâ€”to save space.\n\nWhen you receive a raw protobuf byte stream, it is effectively a \"nameless\" string of numbers. Here is exactly why you can't decode it without a schema or a header.\n\n1. It Uses \"Tags\" instead of Names\n\nIn JSON, you see `\"user_id\": 123`. In protobuf, the name \"user\\_id\" is never sent. Instead, it only sends a **field number** (the \"tag\") that was defined in your `.proto` file.\n\n* **The Problem:** If you receive a message starting with `Field #5`, you have no idea if #5 stands for `price`, `age`, or `zip_code` unless you have the original schema to look it up.\n\n2. The \"Wire Type\" is Ambiguous\n\nProtobuf groups all data types into just a few \"wire types\" (categories of encoding). For example, `int32`, `int64`, `uint32`, `bool`, and `enum` are all encoded using the **Varint** wire type.\n\n* **The Problem:** If the decoder sees a Varint with the value `1`, it doesn't know if that means `true` (bool), the number `1` (int), or the first entry in a list (enum). It needs the schema to know how to \"cast\" that number into the correct programmatic type.\n\n3. There Is No \"Outer\" Message Type\n\nIf you send a `LoginRequest` and a `LogoutRequest`, the binary payloads might look very similar. Unlike a self-describing format (like a JSON object that might have a `\"type\": \"Login\"` field), a raw protobuf message **does not identify itself**.\n\n* **The Problem:** The receiver just gets bytes. Without a **header** (like an ID in the TCP packet or a gRPC metadata field) or a pre-defined sequence, the receiver won't even know which message class to use for decoding.\n\n4. It Is Not \"Self-Delimiting\"\n\nProtobuf does not have \"start\" or \"end\" markers (like `{ }` in JSON). It is just a stream of fields.\n\n* **The Problem:** If you are reading from a stream (like a network socket), you don't know where one message ends and the next begins. This is why most implementations use a \"Length-Prefixed\" headerâ€”essentially a small number at the very beginning that tells you \"the next 150 bytes are one message.\"\n\n#",
              "score": -26,
              "created_utc": "2026-01-06 08:43:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxz5xvt",
                  "author": "st4reater",
                  "text": "I'm not reading that slop, sorry",
                  "score": 11,
                  "created_utc": "2026-01-06 08:48:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxz5kzm",
                  "author": "black_at_heart",
                  "text": "How do we fix this?\n\nIn practice, we handle this in two ways:\n\n1. **The Schema:** Both the sender and receiver have a compiled version of the `.proto` file. This acts as the \"decoder ring.\"\n2. **The Envelope (Header):** Most developers wrap their protobuf messages in a \"Wrapper\" or \"Envelope\" message that includes a field for the message type and the length of the payload.",
                  "score": -24,
                  "created_utc": "2026-01-06 08:44:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxyeyq8",
          "author": "no1SomeGuy",
          "text": "Just use a standard wrapper on it like cloudevents...the point of protobuf is just efficient serialization of the main payload.  \n[https://github.com/cloudevents/spec/blob/main/cloudevents/formats/protobuf-format.md](https://github.com/cloudevents/spec/blob/main/cloudevents/formats/protobuf-format.md)",
          "score": 6,
          "created_utc": "2026-01-06 05:00:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz2mts",
          "author": "jeffbell",
          "text": "You are correct. You have to know what data is coming.Â \n\nTo make them self defining (like json) adds overhead to the message. At the scale of Google if you add a few percent to the processing required you have to build another datacenter or lay more fiber and thatâ€™s real money.Â \n\nItâ€™s an intermediate design between specifying all the bits like a C struct, and accepting everything like a string key-value store. Itâ€™s more of an integer key-value.",
          "score": 4,
          "created_utc": "2026-01-06 08:16:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyoj1u",
          "author": "Foreign_Clue9403",
          "text": "Technically is this not an issue with all protocols and interfaces?  \n\nFrom a ZTA view you could always argue that â€œthis header says this is type X of size Y but I donâ€™t know if I can just accept thatâ€\n\nBut to this end it encourages simplifying and limiting the number of types you ought to allow. \n\nAnd from a design standpoint, metadata is necessary info in order for the system to behave to requirement, even if itâ€™s quite redundant in many individual application use cases.",
          "score": 3,
          "created_utc": "2026-01-06 06:11:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny039kj",
          "author": "asdfdelta",
          "text": "You're seeing protobufs as REST APIs that blindly call endpoints with mystery packages. It's different in a big way.\n\nThe whole point of RPC is that the server and client know more about each other, like what procedure to call and what data types to expect. This in turn increases performance because less compute cycles are spent figuring out what to do with the payload, interfaces, and abstractions.",
          "score": 3,
          "created_utc": "2026-01-06 13:19:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4nxye",
              "author": "Landmark-Sloth",
              "text": "This is a good answer, thank you. I understand a lot of other comments talking about this being the issue with protobufs. But something tells me google knew better and didn't incorporate. Its not a limitation but rather its just not intended usage and I don't completely understand intended usage. \n\n  \nI am still fuzzy on exactly how multiple data types can be handled. I understand the intention of client / server knowing more about each other than just being blind. But I still think having multiple datatype between the two does not signal poor design. Let me know your thoughts here. Thanks again for the comment.",
              "score": 2,
              "created_utc": "2026-01-07 02:41:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny4so3l",
                  "author": "asdfdelta",
                  "text": "In strongly typed paradigms, you wouldn't pass multiple data types internally to a service unless you overloaded a method signature.\n\nRPC (where protobufs get their main use) stands for Remote Procedure Call. Procedure, in this case, implies a *single method*. Yes, this is essentially evoking a method call in an entirely separate runtime over the network.\n\nWith that mindset, a different data type would simply be an overloaded signature and ergo a different method or RPC call. It's not 'restrictive' in the same sense that OOP isn't 'rescrictive' of how objects can be used. It's that way because that's OOP. \n\nYou **could** pass them all with some blank and others populated, then have the receiving method decipher what the hell it just got... But at that point you've lost the plot. It's why infinitely dynamic signatures don't really exist (we're ignoring loosely typed languages here).\n\nRPC is glorious because it bypasses all of the interpretation layers of compute just trying to figure out what to do with what data was given to it. All you get is exactly what you expect then you immediately get to using it. Clean, to the point, and extremely performant. Obviously not meant for general-purpose stuff as this tightly couples both services together so proceed with care.",
                  "score": 1,
                  "created_utc": "2026-01-07 03:07:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxz7sd6",
          "author": "afops",
          "text": "You can mark classes and subclassses. E.g if you have an abstract class animal and messages is an array of animal which are Cat or Dog then the subtypes will be indexed e.g 1=Cat 2=Dog followed by the common Animal data and then the specific data.\n\nBut of course the possible subtypes must be known (a closed set) at both transmitter and receiver.",
          "score": 2,
          "created_utc": "2026-01-06 09:05:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz8mj3",
          "author": "sessamekesh",
          "text": "You _can_ haggle together a vaguely JSON-ish protobuf type to hold arbitrary data with a big ol' union type that optionally holds another instance of itself. I've seen it done successfully, and if you're really concerned about size over the wire and are sending a bunch of numeric data it might even be worth it for you.\n\n\nGenerally though, protos hold structured data. If your server and client both understand the possible data types (or the client is only responsible for ferrying it to downstream consumers that do) you can also encode an arbitrary proto as a blob or string and pass that as a field. I've done that for proxy layers that don't actually understand the data they are forwarding, just the header proto data.",
          "score": 1,
          "created_utc": "2026-01-06 09:14:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzxlk4",
          "author": "Wh00ster",
          "text": "Me of the benefits is that you know what to expect. Itâ€™s an RPC. A remote function. Statically compiled. If you want to accept generic data where the client can send whatever, then thatâ€™s just a POST request with JSON. Going even further you could ask â€œwhat if I donâ€™t know if itâ€™s a POST or GET?â€ This sounds like an XY problem",
          "score": 1,
          "created_utc": "2026-01-06 12:43:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0im45",
          "author": "fogchaser35",
          "text": "This is only a problem if you are using protobufs as a mechanism to only serialize/deserialize data, and using your own custom code to read/write from a socket. When I first used protobufs back in 2010-11, I did it the same way. I used the first 8 bytes for a code to indicate the object type, the next 8 bytes for the length of the protobuf blob, and then the protobuf blob itself.\nYou donâ€™t have to do this anymore. You should be using GRPC now to handle all of this.",
          "score": 1,
          "created_utc": "2026-01-06 14:43:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4pu0s",
              "author": "Landmark-Sloth",
              "text": "I am exactly in your situation. I am thinking of using ZMQ (or some other similar like socket API messaging library) and protobuf as the mechanism to get to and from serialized data. gRPC doesn't really make much sense for me, but then again I haven't dug too deep on gRPC. Let me know your thoughts. Appreciate the comment.",
              "score": 1,
              "created_utc": "2026-01-07 02:51:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2yi6y",
          "author": "sukaibontaru",
          "text": "Maybe json-rpc",
          "score": 1,
          "created_utc": "2026-01-06 21:27:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3ygag",
          "author": "_Trio13_",
          "text": "gRPC depends on the client and server having agreed about the type information ahead of time. I don't know of any way to derive a type name from a gPRC stream and dynamically create an instance based on the data. The endpoints are strongly typed.",
          "score": 1,
          "created_utc": "2026-01-07 00:24:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4hm6f",
          "author": "kbeta",
          "text": "Protobuf can also use a set of Descriptors (https://protobuf.com/docs/descriptors)  to dynamically marshal/unmarshal messages without having the generated proto code for the message compiled in. These descriptors are themselves protobufs (and always compiled in), so can be sent over the wire / included as a header in a data file, etc.",
          "score": 1,
          "created_utc": "2026-01-07 02:07:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny4s9hy",
              "author": "Landmark-Sloth",
              "text": "Yes thank you for this. I went down a rabbit hole and came to the same ending page (more or less):  [https://protobuf.dev/programming-guides/techniques/#union](https://protobuf.dev/programming-guides/techniques/#union)",
              "score": 1,
              "created_utc": "2026-01-07 03:04:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxym3mu",
          "author": "HRApprovedUsername",
          "text": "try deserialize expected type a; catch try deserialize expected type b; etc",
          "score": -12,
          "created_utc": "2026-01-06 05:52:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz60cs",
              "author": "st4reater",
              "text": "Wtf",
              "score": 2,
              "created_utc": "2026-01-06 08:48:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny4qkiq",
              "author": "Landmark-Sloth",
              "text": "yea i know enough to know that aint it",
              "score": 1,
              "created_utc": "2026-01-07 02:55:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q3ufzi",
      "title": "Was Kevin Mitnick actually right about security?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q3ufzi/was_kevin_mitnick_actually_right_about_security/",
      "author": "Suspicious-Case1667",
      "created_utc": "2026-01-04 16:36:29",
      "score": 30,
      "num_comments": 12,
      "upvote_ratio": 0.8,
      "text": "Kevin Mitnick spent decades repeating one idea that still makes people uncomfortable:\n\nâ€œPeople are the weakest link.â€\nAt the time, it sounded like a hackerâ€™s oversimplification. But looking at modern breaches, itâ€™s hard not to see his point.\nMost failures donâ€™t start with zero-days or broken crypto.\n\nThey start with:\nsomeone trusting context instead of verifying\nsomeone acting under urgency or authority\nsomeone following a workflow that technically allows a bad outcome\nMitnick believed hacking was less about breaking systems and more about understanding how humans behave inside them. \n\nSocial engineering worked not because systems were weak, but because people had to make decisions with incomplete information.\nWhatâ€™s interesting is that even today, many incidents labeled as â€œtechnicalâ€ are really human edge cases: valid actions, taken in the wrong sequence, under the wrong assumptions.\n\nSo I want to know how people here see it now:\nWas Mitnick right, and we still havenâ€™t fully designed for human failure?\nOr have modern systems (MFA, zero trust, guardrails) finally reduced the human factor enough?\n\nIf people are the weakest link, is that a security failure or just reality we need to accept and design around?\n\nGenuinely interested in how practitioners think about this today",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q3ufzi/was_kevin_mitnick_actually_right_about_security/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nxnjd68",
          "author": "Iryanus",
          "text": "I am curious: Was that ever really in doubt?",
          "score": 39,
          "created_utc": "2026-01-04 17:02:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxovhvq",
              "author": "mackfactor",
              "text": "This. It never was in doubt. That's why everyone that works at a company of even a relatively small size takes info sec training every year. Even for software vulnerabilities, those are still human weaknesses (though not the type that Mitnick was talking about). Software will act the same way when exposed to the same stressors - meanwhile you have companies that have hundreds of people that work for them that have a high variation in the way they might respond. There was never any question that humans are the weak point.",
              "score": 8,
              "created_utc": "2026-01-04 20:38:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxo026h",
              "author": "dashingThroughSnow12",
              "text": "The crypto folks systematically seem to ignore that humans are the weakest link and that a finance system has to protect that. They seem to only be concerned with things being algorithmically secure as opposed to holistically secure.\n\nI digress.\n\nWhile most will not disagree out loud, most will silently ignore the human factor. Throw up their hands and say there is nothing they can do in such and such a circumstance when it involves flesh and blood humans being the root cause.\n\nOften Iâ€™ll hear devs have some half-baked definition of authorization that conveniently leaves out tricky elements.",
              "score": 7,
              "created_utc": "2026-01-04 18:18:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxqqutz",
                  "author": "UnreasonableEconomy",
                  "text": "> Often Iâ€™ll hear devs have some half-baked definition of authorization that conveniently leaves out tricky elements.\n\nWe're already getting rid of passwords altogether. There's unfortunately only so many hours in a day...",
                  "score": 1,
                  "created_utc": "2026-01-05 02:10:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxnfn86",
          "author": "gambit_kory",
          "text": "He was 100% correct.",
          "score": 25,
          "created_utc": "2026-01-04 16:45:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxrr4br",
          "author": "faultydesign",
          "text": "https://xkcd.com/538/",
          "score": 3,
          "created_utc": "2026-01-05 05:43:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxnoxqd",
          "author": "Bodine12",
          "text": "\"Genuinely interested in...\" = Not really interested because this is AI-slop.",
          "score": 9,
          "created_utc": "2026-01-04 17:28:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxp2wx5",
          "author": "justUseAnSvm",
          "text": "The *reduction ad absurdum* is that with a rubber hose, or your family on the line, you'll do anything an attacker wants.",
          "score": 2,
          "created_utc": "2026-01-04 21:13:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxpg3u7",
          "author": "serverhorror",
          "text": "Why would we assume it's anything but humans? And what makes you think it's an oversimplification?",
          "score": 2,
          "created_utc": "2026-01-04 22:14:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxsgmnz",
          "author": "ERP_Architect",
          "text": "From what Iâ€™ve seen, he was pointing at an uncomfortable reality more than blaming people.\n\nMost failures Iâ€™ve been close to werenâ€™t caused by someone doing something obviously wrong. They were caused by someone making a reasonable decision under pressure, with incomplete context, inside a system that technically allowed it.\n\nModern guardrails help, but they donâ€™t remove the human factor. They just shift where it shows up. Instead of clicking the wrong thing, it becomes approving the wrong request or working around friction to get work done.\n\nWhere systems still break is when they assume perfect behavior. In practice, good security designs accept human judgment as a constant and focus on limiting impact and recovering quickly, not pretending people can be engineered out of the loop.",
          "score": 2,
          "created_utc": "2026-01-05 09:28:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxswln7",
          "author": "darkwyrm42",
          "text": "He was 100% correct, and before you think you can solve the problem, nothing is foolproof because people are geniuses at being stupid.",
          "score": 2,
          "created_utc": "2026-01-05 11:48:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxolycw",
          "author": "Aggressive_Ad_5454",
          "text": "Bit pointless to try to identify the â€œweakestâ€ link when youâ€™re defending against bad actors. They only need to find one weak link. You need to reinforce all the weak links.",
          "score": 1,
          "created_utc": "2026-01-04 19:55:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pxpop7",
      "title": "Microservices as an Architecture vs. a Management Pattern",
      "subreddit": "softwarearchitecture",
      "url": "https://youtu.be/eEiKM8njGvk",
      "author": "parsaeisa",
      "created_utc": "2025-12-28 11:57:35",
      "score": 21,
      "num_comments": 1,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1pxpop7/microservices_as_an_architecture_vs_a_management/",
      "domain": "youtu.be",
      "is_self": false,
      "comments": [
        {
          "id": "nwe1u8c",
          "author": "SeniorIdiot",
          "text": "That was always the point. Conway's Law and DDD bounded contexts making a baby.",
          "score": 7,
          "created_utc": "2025-12-28 17:04:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q4fvri",
      "title": "How much software design is a junior expected to know?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q4fvri/how_much_software_design_is_a_junior_expected_to/",
      "author": "megacrops",
      "created_utc": "2026-01-05 08:01:12",
      "score": 18,
      "num_comments": 13,
      "upvote_ratio": 0.91,
      "text": "Hello all,\n\nI'm going to graduate college in a few months, and join a team at a big bank as a new grad. In big corpos, how much software design is a junior expected to know? I'm talking about OOD, System design, and ability to understand large, complex codebases.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q4fvri/how_much_software_design_is_a_junior_expected_to/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nxshjni",
          "author": "mistyharsh",
          "text": "Absolutely none. The most important I feel that a junior needs to understand is SOLID principles and an ability to recognise the code that doesn't follow one. But, that's it. Learning to make it an intuition is the only step that matters in the beginning.",
          "score": 22,
          "created_utc": "2026-01-05 09:37:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxvtr3u",
              "author": "iMac_Hunt",
              "text": "Maybe my standards are low but even a basic understanding of SOLID for a junior puts you better than most in my books. \n\nI expect juniors to be able to read/write code somewhat fluently - knowing some design patterns or specific frameworks are bonuses.",
              "score": 9,
              "created_utc": "2026-01-05 20:44:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxwqcf8",
              "author": "megacrops",
              "text": "I see. I feel that I can do at least that much in that case. Do you have any recommendations for wat I can do to be better prepared?",
              "score": 1,
              "created_utc": "2026-01-05 23:21:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxu9vsc",
          "author": "iceburg47",
          "text": "When starting my first entry level position my manager semi-jokingly told me that on day-1 I was just expected to be able to find my way back from the bathroom but to start learning certain things immediately (mostly relevant to our specific domain.)\n\nJust be prepared for expectations to grow quickly but organically.",
          "score": 3,
          "created_utc": "2026-01-05 16:28:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxsc3fb",
          "author": "RipProfessional3375",
          "text": "There is 'know' and 'understand' and these two are very different.\n\nI would expect a junior to know about these concepts, know their most important terminology, know enough about them to begin the long process of actually understanding them.",
          "score": 5,
          "created_utc": "2026-01-05 08:44:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxva4mt",
          "author": "sennalen",
          "text": "In an interview? All of it. On the job? None of it.",
          "score": 2,
          "created_utc": "2026-01-05 19:13:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxvcyhp",
          "author": "christianhelps",
          "text": "When I get new grads I expect them to know basically zero. You should be capable of researching issues on your own and asking for help afterwards. The only time I've ever had issue giving a junior my time and knowledge is when they haven't made a solid effort themselves first.Â \n\n\nAs long as you're willing to learn, seniors will be more than happy to lend you a hand and mentor you. My best advice is to listen hard, people don't like having to repeat themselves and you build report by showing that you follow feedback.",
          "score": 2,
          "created_utc": "2026-01-05 19:26:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxxxdpr",
          "author": "VictorBaird_",
          "text": "Way less than youâ€™re probably worried about. They expect you to write clean code, follow the existing patterns, ask for help early, and not get lost in the repo forever. Basic OOP and being able to reason about trade offs is enough, real system design youâ€™ll learn alongside seniors on the job.",
          "score": 2,
          "created_utc": "2026-01-06 03:11:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxw4j6q",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-05 21:34:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxwpxq9",
              "author": "megacrops",
              "text": "The bank I'm joining is more invested in Tech than most others, I heard that spring boot and python are the two main langs there.",
              "score": 2,
              "created_utc": "2026-01-05 23:19:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxxkqpc",
          "author": "tr14l",
          "text": "For loops, conditionals, classes... A few other things. \n\n\nI would expect a solid foundation in CS, whether self taught or not. However, many do not.",
          "score": 1,
          "created_utc": "2026-01-06 02:02:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxychlb",
          "author": "Separate_Earth3725",
          "text": "Probably zero. I know in the US, CS coursework involves at least one software engineering course but for me there is no expectation that you come in knowing what youâ€™re doing.\n\nAt the very least, just be aware of how object orientation works in terms of classes vs objects and very basic inheritance like whatâ€™s a base class and a child class and how do they interact.",
          "score": 1,
          "created_utc": "2026-01-06 04:43:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nybmy79",
          "author": "dash_bro",
          "text": "So long they get LLD it's a win. \n\nLLD is very learnable on the job, HLD is through experience once they learn what needs to be learnt in the first place \n\nIn my opinion, very similar to how there are teaching schools for dentistry, surgery, etc. - you learn the theory and then an experienced professional shows you the actual thing on the job. \n\nThis is what I'd recommend, if I had enough time and mental space for coaching juniors actively:\n\nHave juniors pick up the basics (theory, ideas about HLD from a simple 2 week bootcamp etc) -> look at company's existing arch -> sit in design meetings and make notes/questions -> research and answer questions, run by the seniors -> the seniors start involving the juniors for their opinions -> seniors start letting juniors design with just course corrections -> juniors are now mid level or senior",
          "score": 1,
          "created_utc": "2026-01-08 02:21:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxsy1d1",
          "author": "Fippy-Darkpaw",
          "text": "As a senior software engineer, you should know at least what is in the design docs and the training docs.\n\nAny decent workplace would train you up on both. ðŸ‘",
          "score": 1,
          "created_utc": "2026-01-05 11:59:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pz3vkb",
      "title": "This is a detailed breakdown of a FinTech project from my consulting career.",
      "subreddit": "softwarearchitecture",
      "url": "https://lukasniessen.medium.com/this-is-a-detailed-breakdown-of-a-fintech-project-from-my-consulting-career-9ec61603709c",
      "author": "trolleid",
      "created_utc": "2025-12-30 00:59:09",
      "score": 18,
      "num_comments": 2,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1pz3vkb/this_is_a_detailed_breakdown_of_a_fintech_project/",
      "domain": "lukasniessen.medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwzv0e9",
          "author": "Mehazawa",
          "text": "Thanks for sharing. What is the advantage of having events in db, over than using the state + cdc to dump them to mq and after save somewhere for auditability?",
          "score": 3,
          "created_utc": "2025-12-31 23:16:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwwz62u",
          "author": "4nh7i3m",
          "text": "Thank you for sharing. It helps me to have a better understanding of how the other real system works.",
          "score": 1,
          "created_utc": "2025-12-31 14:07:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q18j30",
      "title": "Where does software architecture fit into backend design process?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q18j30/where_does_software_architecture_fit_into_backend/",
      "author": "tejveeer",
      "created_utc": "2026-01-01 16:44:39",
      "score": 17,
      "num_comments": 12,
      "upvote_ratio": 0.9,
      "text": "Hey, I'm a junior aspiring to be a backend engineer.\n\nI'm currently trying to understand database and api design in greater depth, and now I've encountered software architecture.\n\nHow do these three fit into the product design process?\n\nMy current understanding of the product design process is as follows:\n\n1. Determine product functionality\n2. Translate into requirements and constraints\n3. Design the API (the specifics of which I'm learning through *The Design of Web APIs* by Lauret)\n4. Design the database based on the resources required for the API\n\nWhere does software architecture fit into this? What about system design? What is the relationship of software architecture and system design? When does system design appear in the design process?\n\nSorry for question spamming, would appreciate any pointers on this subject.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q18j30/where_does_software_architecture_fit_into_backend/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nx3saiv",
          "author": "Glove_Witty",
          "text": "What about your non functional requirements and constraints? Performance, availability, scalability, security, maintainability, dev velocity, cost.",
          "score": 10,
          "created_utc": "2026-01-01 17:09:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx43mxj",
          "author": "bobaduk",
          "text": "What you're describing _is_ software architecture and _is_ system design.\n\nThe architecture of a system is the set of decisions we make that are hard to change and constrain future decisions. For example, we might decide that we're building a monolithic golang app with a postgres database, or we might decide that we're building a set of typescript microservices that will run as cloudflare workers. Those decisions will lead to very different constraints in future.\n\nSoftware architecture as a _process_ is the practices we employ to make those hard-to-change decisions. We ideally make those decisions by gathering the functional and non-functional requirements, understanding the constraints, and then making choices that satisfy all our constraints while providing maximum optionality for the future, ie, the ability to change our minds when we realise we got it wrong.\n\nSystem design is ... designing a system... I guess it's possible to design a system without considering the constraints or the ability to change our minds, but I would still call that \"doing architecture\", just doing it badly.\n\nA software architect is someone who leads that process of making decisions and builds consensus and understanding with teams so that everyone is on the same page about the decisions they're making, and the reasons for choosing those decisions.\n\nI think you're looking for clear definitions for things, but that's not how human endeavours work. We're describing processes by which people create a thing together, and that's necessarily messy and without hard edges.",
          "score": 6,
          "created_utc": "2026-01-01 18:07:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx3uqwr",
          "author": "Classic_Chemical_237",
          "text": "Itâ€™s not about the current product requirements. Database migration sucks (downtime, chance of bugs, and occasional migration done wrong can completely disable the business for days) so you want to minimize as much as possible. So itâ€™s always good to challenge PM on whatâ€™s the potential direction in the future, and design the DB to be flexible, even if itâ€™s not needed right now.\n\nBe aware of pager duty. Thatâ€™s always a BE responsibility to respond to emergency DB/API downtime. You need proper monitoring with automation to alert you when this happens, and you need a troubleshooting playbook to follow at 3AM when your mind is half asleep.",
          "score": 7,
          "created_utc": "2026-01-01 17:22:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx433ur",
          "author": "gaelfr38",
          "text": "Software architecture and system design are similar in the way I see it.\n\nIt happens when an application grows in features and/or need to communicate with other applications.\n\nIf you start small on a single feature, I think that's why software architecture is unclear to you for now.\n\nSome things you may want to look at: DDD, hexagonal architecture, event-based architecture, micro services, monolith, modulith as we call it now (intermediate between micro services and monolith), ...",
          "score": 3,
          "created_utc": "2026-01-01 18:04:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7sw88",
          "author": "ERP_Architect",
          "text": "A simple way to think about it is that architecture sets the boundaries, and API and database design happen inside those boundaries.\n\nAPIs and schemas are concrete. Architecture is where you decide things like what owns what data, what needs to scale, what can fail, and what should stay simple. Those choices quietly shape how your APIs look and how your database ends up structured.\n\nSystem design usually sits in between. Itâ€™s the step where you sketch the big pieces and their responsibilities before you worry about endpoints or tables. In real projects this isnâ€™t linear. You bounce back and forth as constraints show up.",
          "score": 2,
          "created_utc": "2026-01-02 07:10:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6cnm1",
          "author": "systemic-engineer",
          "text": "None of the answers are wrong.\n\nAll talk tech.  \nWhile the answer is humans. \n\nThis question is one you best ask in your org.  \nFind a trustworthy senior.\n\nNot the 10x engineer.  \nFind the engineer who maintains the team calendar.  \nAnd doesn't groan.  \nBecause someone needs to do it. \n\nAnd then let them explain it to you,\nin the context of the org.\n\nTheory is great.  \nUntil you sit in a meeting room.  \nAnd need to explain it to real humans.",
          "score": 1,
          "created_utc": "2026-01-02 01:14:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6i52h",
          "author": "who_am_i_to_say_so",
          "text": "Architecture super-high-level is describing how the arrows connect the data together, how the layers interact with each other.\n\nHereâ€™s one little pattern that can carry you for almost forever: Model, View, Controller. MVC.\n\nThereâ€™s your start. Enjoy!",
          "score": 1,
          "created_utc": "2026-01-02 01:48:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6ouki",
          "author": "Purple-Control8336",
          "text": "Solution Architecture should define standards, principles, guardrails(constraints). \n\nSoftware Architecture should translate Solution Architecture (logical) to Technology Architecture(Physical ) level which is softwares we need to build web/mobile/ AI Agentic for Front end, integration, backend, database, cross cutting concerns like login, auditing, logging ,monitoring, unit testing, DevSecOps, infra environment needs, non functional all itties. \n\nIf Solution and Technical Architects roles do not exists and all done by engineers in squad team, then its all over the place.",
          "score": 1,
          "created_utc": "2026-01-02 02:29:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6qamb",
          "author": "tr14l",
          "text": "No, sam, we aren't asking for AGI. We're literally just asking for a definition of it so you stop using it as a blank check marketing term.",
          "score": 1,
          "created_utc": "2026-01-02 02:38:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7pdpn",
          "author": "No_Flan4401",
          "text": "So when building and starting a new project, we need to understand the domain (e.g. shipping), what problems the application should handle and hereafter get requirements and scope the process.Â \nFrom here on you should have a good idea on what you are building. Based on this you start to make choices, everything from programming languages and database to how the application should communicate (there are other options than http protocol).Â \nYou also draw some boxes on a whiteboard to try to slice it up, and decides on how the data models should look.Â \nLastly you decide on if it makes more sense to do a monolith or microservices architecture and what this even means for your application.\n\n\nThen you start building th MVP and keep in mind your probably misunderstood a lot so you make adjustments and the way. Hopefully I did a good enough job so none of the big decisions needs to be changed.Â ",
          "score": 1,
          "created_utc": "2026-01-02 06:40:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxsnmqz",
          "author": "mother_fkr",
          "text": "between 2 and 3",
          "score": 1,
          "created_utc": "2026-01-05 10:32:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny67uzp",
          "author": "Borster_91",
          "text": "software architecture, and more general, solution architecture cover 2 full and 3/4 partially until define which kind of datastore your solution needs (sql, no-sql, object store, ...) and the context (where entities goes into)  \n  \nSolution architecture output should be the components and the technologies that can grant the requirements of your system, not the implementation. So for example API can be an outcome but then you can design it as HATEOAS priciple or not.",
          "score": 1,
          "created_utc": "2026-01-07 09:35:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q08rl2",
      "title": "My side project ArchUnitTS reached 200 stars on GitHub",
      "subreddit": "softwarearchitecture",
      "url": "https://lukasniessen.medium.com/my-side-project-archunitts-reached-200-stars-on-github-bb9d47f9b442",
      "author": "trolleid",
      "created_utc": "2025-12-31 09:15:12",
      "score": 15,
      "num_comments": 1,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q08rl2/my_side_project_archunitts_reached_200_stars_on/",
      "domain": "lukasniessen.medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "nx0xqld",
          "author": "wampey",
          "text": "Hey cool! Was just reading about such tests in fundamentals of software architecture!",
          "score": 1,
          "created_utc": "2026-01-01 03:24:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q5m1ms",
      "title": "Iâ€™m evaluating a write-behind caching pattern for a latency-sensitive API.",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q5m1ms/im_evaluating_a_writebehind_caching_pattern_for_a/",
      "author": "saravanasai1412",
      "created_utc": "2026-01-06 15:44:10",
      "score": 11,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "Flow  \n\n*   Write to Redis first (authoritative for reads) \n* Return response immediately to reduce latency \n*  Persist to DB asynchronously as a fallback (used only during Redis failure)\n\n  \nThe open question  \n  \nWould you persist to DB using **in-process background tasks** (simpler, fewer moving parts)  \nor use a **durable queue (Celery / Redis Streams / etc.)** for isolation, retries, and crash safety?\n\nAt what scale or failure risk does the extra infra become â€œworth itâ€ in your experience?  \nCurious how other solution architects think about this trade-off.\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q5m1ms/im_evaluating_a_writebehind_caching_pattern_for_a/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "ny14i74",
          "author": "YakRepresentative336",
          "text": "IMO the key questions between in-process backgrouns tasks and durable queue will be to determine if data lost, inconsistency and lost write are acceptable, if not go for durable queue",
          "score": 7,
          "created_utc": "2026-01-06 16:27:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1uuor",
          "author": "madrida17f94d6-69e6",
          "text": "What do you do if you persist to Redis and return, then fail to persist to the database for some reason, and eventually the data expires from Redis? Writing to the database doesnâ€™t need to be fast, but it does need to be durable, so you should, before anything else, write to some queue first, as you said, so failures can end up in some sort of DLQ and those writes can eventually be retried, both to Redis and to the database. Make sure both writes are idempotent. \n\nOf course, thereâ€™s nuance all over the place, and without knowing your latency, availability, and durability requirements, we canâ€™t help much more. But good principles always apply: donâ€™t over-engineer too much from the get-go. Itâ€™s easier to evolve a first version than to never get anywhere because weâ€™re designing for six months for scale that weâ€™ll never have.",
          "score": 6,
          "created_utc": "2026-01-06 18:26:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny172ij",
          "author": "asdfdelta",
          "text": "Caches for APIs that need low latency carries with it an acceptance that *some* calls will pay the cost to fetch the data at some point. In the event of a Redis failure where the entire cache goes down, reloading the entire cache from a db might already be stale depending on how long the manual load takes.\n\nA secondary fallback to a cache is redundant with your fallback to the source of truth, since it will always be more up-to-date than a secondary db.\n\nIf you must have one, then keep the load compute separate to not interfere with the performance.",
          "score": 2,
          "created_utc": "2026-01-06 16:39:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2h2sy",
          "author": "Few_Wallaby_9128",
          "text": "If you tolerate failures (data loss), you could write to a memory ring cache and return immediarely; then asynchronously from the ring cache you would publish to something like a kafka stream and from there finally to redis and/or db. If you dont want data loss, you can drop the ring cache and write to kafka stream with the appropriate configuration. With the ring cache you probably dont need kafka and a less performant durable queue would do too.",
          "score": 2,
          "created_utc": "2026-01-06 20:07:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3cd34",
          "author": "FrostingLong4107",
          "text": "I am a complete noob and have recently subscribed to this sub. So please pardon my basic questions here. Only intention is to learn here for myself. \n\nOP, Curious to why data is being written to redis first and not to db? Is it only because this data is not needed long term and any failure to insert to db is not an issue? And also more importantly writing to db first and returning response is slower than writing to redis for this API use case?\n\nThe usual pattern I have seen, people write to db and then on a fetch, add a copy to redis cache and on any subsequent query for the same key return the cached copy instead of fetching from db.",
          "score": 2,
          "created_utc": "2026-01-06 22:32:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nybaeb5",
          "author": "rkaw92",
          "text": "It does not become worth it at all, in most scenarios. Instead, write it directly into Redis only. Redis is now your single source of truth. Set up durability to meet your SLA. Done.\n\n\nRedis not meeting your SLA (e.g. several seconds of data loss not acceptable)? Get a fast but durable DB like ScyllaDB or Cassandra, or use a managed one like DynamoDB. Or maybe consider Volt Active Data. There's a lot of interesting infra to choose from.\n\n\nIf your entities are fairly few but mutating fast, consider an in-memory architecture where there's no read-modify-write loop, only appends. Event Sourcing dovetails with this, but is far from the only choice. In any case, invest early in concurrency control (mutual exclusion) so that a split brain can't ruin your consistency.\n\n\nIn some very rare write-only scenarios, it makes sense to persist to a stream only, like Kafka, NATS JetStream, or Apache Pulsar. This can be great for maintaining a stable latency, but has one major downside: there is no way to know if the operation eventually succeeds or fails. Therefore, it is only useful in fire-and-forget requests, like Web telemetry where the client doesn't really care about getting data back.",
          "score": 1,
          "created_utc": "2026-01-08 01:15:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pyppzt",
      "title": "Recommendations for Postgraduate Programs or MBAs in Software Architecture?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1pyppzt/recommendations_for_postgraduate_programs_or_mbas/",
      "author": "manubecks",
      "created_utc": "2025-12-29 15:51:17",
      "score": 11,
      "num_comments": 2,
      "upvote_ratio": 0.92,
      "text": "Hi everyone,\n\nIâ€™m looking for recommendations for a postgraduate program or an MBA focused on Software Architecture.\n\nMy main interest is in programs that go beyond theory and cover real-world architectural decision making, such as:\n\nSystem design and architectural patterns\n\nScalability and distributed systems\n\nMicroservices vs monoliths\n\nCloud architecture and trade-offs\n\nDocumentation and communication of architecture\n\nOnline or on-site programs are both fine.\nIf youâ€™ve taken a course yourself or have direct experience with one, Iâ€™d really appreciate your thoughts (pros/cons, depth, applicability in real projects, etc.).\n\nThanks in advance!",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1pyppzt/recommendations_for_postgraduate_programs_or_mbas/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nwtvrj2",
          "author": "Great_Pattern_1988",
          "text": "You might not need a degree. SEI offers a certificate program that covers a lot of what you've listed.  Three courses and an exam.  You should at least look into it.",
          "score": 1,
          "created_utc": "2025-12-31 00:29:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx3in5z",
              "author": "manubecks",
              "text": "Thanks a lot!",
              "score": 1,
              "created_utc": "2026-01-01 16:17:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pyniw7",
      "title": "How do you enforce escalation processes across teams?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1pyniw7/how_do_you_enforce_escalation_processes_across/",
      "author": "StartingVibe",
      "created_utc": "2025-12-29 14:23:26",
      "score": 11,
      "num_comments": 4,
      "upvote_ratio": 0.92,
      "text": "In environments with multiple teams and external dependencies, how do you enforce that escalation processes are actually respected?\n\nSpecifically:\n\n* required inputs are always provided\n* ownership is clear\n* escalations donâ€™t rely on calls or tribal knowledge\n\nOr does it still mostly depend on people chasing others on Slack?\n\nLooking for real experiences, not theoretical frameworks.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1pyniw7/how_do_you_enforce_escalation_processes_across/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nwk66nc",
          "author": "ERP_Architect",
          "text": "In practice, escalation only works when itâ€™s designed into the workflow, not documented as a process people are expected to remember.\n\nThe teams Iâ€™ve seen succeed do three things consistently. First, they make escalation entry structured. If required inputs arenâ€™t there, the escalation literally canâ€™t be raised. That removes back and forth and Slack chasing. Second, ownership is role based, not person based. A queue or rotation beats â€œask whoever is around.â€ Third, escalations are visible by default. A shared board or system that shows status, age, and next action creates pressure without anyone nagging.\n\nIf escalation depends on calls or DMs, itâ€™s already broken. People will always route around friction. The goal is to make the right path the easiest path, and the wrong one annoying enough that it fades out naturally.\n\nMost real improvements come from tightening intake and visibility, not adding more rules.",
          "score": 6,
          "created_utc": "2025-12-29 15:40:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwk8rn7",
              "author": "StartingVibe",
              "text": ">",
              "score": 2,
              "created_utc": "2025-12-29 15:52:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwjvcd6",
          "author": "ProbsNotManBearPig",
          "text": "My experience is only top down enforced processes work to cut across teams. You need actual standardized forms/templates and enforce they are filled out between handoffs as evidence. But if someone at the top isnâ€™t enforcing people follow it, no one will. Or some will, but it doesnâ€™t work if some donâ€™t follow it. I find this to be an issue at larger companies where the only common upper management across teams might be VP level and they arenâ€™t getting involved in these things. So then the solution is some levels of management down the chain need to coordinate and agree and they tend to be in their own worlds at big companies, not focused on coordinating with other directors on processes. \n\nSo all that is to say, itâ€™s real easy in theory, but my experience is itâ€™s hard at big companies where management of all the teams involved are not necessarily tightly synced on processes and their views on enforcing/following them. At smaller companies, the VP of engineering might actually be involved in these things and enforce that the different teams involved actually follow the processes. \n\nJust my experience. Iâ€™m sure some larger companies have their shit together, but I havenâ€™t seen it myself.",
          "score": 2,
          "created_utc": "2025-12-29 14:45:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwjwlt3",
              "author": "StartingVibe",
              "text": "This matches what Iâ€™ve seen as well at my company. Defining processes and templates is the easy part. Enforcement is where things break, especially as orgs grow and management attention gets diluted.\n\nCurious: have you ever seen enforcement work *without* constant top-down pressure, or does it always come back to people chasing others?",
              "score": 1,
              "created_utc": "2025-12-29 14:51:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pzj71f",
      "title": "Alternatives to apigee? anyone else frustrated just us",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1pzj71f/alternatives_to_apigee_anyone_else_frustrated/",
      "author": "Ron_Swanson_1990",
      "created_utc": "2025-12-30 14:15:51",
      "score": 11,
      "num_comments": 5,
      "upvote_ratio": 0.92,
      "text": "We're on apigee and honestly considering other options, the GCP lock-in is annoying since we use multiple clouds, and our bill keeps climbing for features we barely use. Setting up new apis feels overly complicated with all the XML configs, and nobody on our team really understands how half of it works anymore.\n\nThe part that's frustrating is we started using kafka heavily this year and apigee doesn't support it at all so now we're managing two completely separate systems for apis and event streams. Anyone else dealing with this or found alternatives that handle both?",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1pzj71f/alternatives_to_apigee_anyone_else_frustrated/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nwqga05",
          "author": "SpaceGerbil",
          "text": "Why would an API Gateway support event streams? Two completely different interface implementations. You may want to look at Kong as an API gateway alternative if you still need something enterprise worthy. If you want something no fuss lightweight, I've used Spring API Gateway",
          "score": 8,
          "created_utc": "2025-12-30 14:25:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr3pu1",
              "author": "gaelfr38",
              "text": "I'm not sure I would ever recommend using this pattern (exposing Kafka through an API GW) but it does exist in several products, like in [Gravitee](https://www.gravitee.io/platform/kafka-gateway)",
              "score": 1,
              "created_utc": "2025-12-30 16:22:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqigkv",
          "author": "Exterminate007",
          "text": "google is clearly pushing everyone towards full gcp with apigeex, the on-prem version is basically abandonware at this point",
          "score": 3,
          "created_utc": "2025-12-30 14:37:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqiiq1",
          "author": "Maleficent_Mine_6741",
          "text": "we switched off apigee, we consolidated everything into gravitee handles both apis and kafka natively in one platform, the no code policy stuff is way easier than apigees xml configs and the developer portal auto generates docs from openapi spec, but real talk gravitee's graphql support is limited and the community is way smaller so troubleshooting obscure issues takes longer but at least we're not juggling two separate systems anymore",
          "score": 4,
          "created_utc": "2025-12-30 14:37:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqidvp",
          "author": "This_Minimum3579",
          "text": "the xml policy configuration in apigee is painful, feels like we're stuck in 2010",
          "score": 1,
          "created_utc": "2025-12-30 14:37:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q19v0y",
      "title": "Residues: Time, Change & Uncertainty in Software Architecture â€¢ Barry O'Reilly",
      "subreddit": "softwarearchitecture",
      "url": "https://youtu.be/D8qQUHrksrE?list=PLEx5khR4g7PINwOsYrkwz3lTTJUYoXC53",
      "author": "goto-con",
      "created_utc": "2026-01-01 17:38:28",
      "score": 10,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q19v0y/residues_time_change_uncertainty_in_software/",
      "domain": "youtu.be",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1q5ns6v",
      "title": "At what point does ERP customization become technical debt instead of an advantage?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q5ns6v/at_what_point_does_erp_customization_become/",
      "author": "Bestwebhost",
      "created_utc": "2026-01-06 16:47:07",
      "score": 9,
      "num_comments": 11,
      "upvote_ratio": 0.92,
      "text": "When we implemented our ERP, we customized heavily to match how the business already operated. At the time, it felt right like  \"why force the business to change for software?\" Now a year later all the upgrades are painful, documentation is messy, and only a few people truly understand how things work under the hood.\n\nSome of the custom logic does give us an edge. But other parts just exist because \"that's how we've always done it,\" even though the original reason is long gone. Now every new request turns into a debate: build another workaround or finally simplify and break habits?\n\nI'm curious how others draw that line. How do you decide which customizations are worth keeping and which should be retired? Do you periodically audit custom logic or does it just accumulate until it becomes a problem? Would love to hear real-world rules of thumb or something like that.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q5ns6v/at_what_point_does_erp_customization_become/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "ny20w3e",
          "author": "madrida17f94d6-69e6",
          "text": "The thing about in-house systems or customizations is that often the sky is the limit, and in theory, you can build whatever you want. Everyone and their cousins will have opinions, because, well, itâ€™s easy to say that A instead of B is better. Iâ€™ve retired complex in-house systems in favor of open source software; moving closer to the industry means youâ€™re not reinventing the wheel again, and being constrained to what you can do - the programming model of that software  - forces to make hard decisions and to think about trade offs. You need to challenge the status quo and break old habits, and yes, that might mean existing features of custom software wonâ€™t be available anymore. Thereâ€™s obviously a lot of nuance here and trade offs too, just my thoughts.",
          "score": 10,
          "created_utc": "2026-01-06 18:53:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny51wva",
              "author": "avm7878",
              "text": "This is why itâ€™s important to have a strong team that can take what users WANT and only deliver what they actually NEED.",
              "score": 1,
              "created_utc": "2026-01-07 04:00:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny5eltu",
                  "author": "SolarNachoes",
                  "text": "But over time needs change. Some projects have 10x growth, some get stuck in time and others wither and die and new ones spring up out of nowhere! At some point they are all needed.",
                  "score": 1,
                  "created_utc": "2026-01-07 05:24:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny3o3ux",
          "author": "Euphoric-Usual-5169",
          "text": "I have heard many times that adapting your processes to the ERP is long term the better solution compared to extensive customization. Updates become more and more difficult with customization.",
          "score": 3,
          "created_utc": "2026-01-06 23:30:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4u1t9",
          "author": "avm7878",
          "text": "For context, I have over 15 years of experience building custom ERP and MES systems. Iâ€™ve also configured complex systems like Salesforce and Workday.\n\nIâ€™m often asked about the debate on build vs. buy. My advice isâ€¦ if you find a system that does what you want out of the box with simple configuration changes, itâ€™s worth buying. The moment you decide to build custom components, youâ€™re entering into vendor-lock and maintenance hell. Itâ€™s better to just build a bespoke system hyper-tailored to your requirements that can grow WITH the business over time.\n\nItâ€™s like buying a suit. If that Walmart suit fits perfectly, then hooray. But once you start trying to alter it to fit (poorly)â€¦ it quickly becomes a better idea to just go get a custom suit.",
          "score": 3,
          "created_utc": "2026-01-07 03:14:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3c08e",
          "author": "i_be_illin",
          "text": "Almost immediately. Upgrades will be miserable.",
          "score": 1,
          "created_utc": "2026-01-06 22:30:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3fxc1",
              "author": "Frosty_Customer_9243",
              "text": "This is the correct answer. \n\nOne rule to keep in mind against customisation: You are special, but you are not different.",
              "score": 2,
              "created_utc": "2026-01-06 22:49:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny5f6j0",
                  "author": "SolarNachoes",
                  "text": "A lot of ERP systems arenâ€™t equipped for on-demand engineering. And some companies have both on-demand and inventory based systems and those get brittle pretty fast.",
                  "score": 1,
                  "created_utc": "2026-01-07 05:28:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny5uj4z",
          "author": "ERP_Architect",
          "text": "From what Iâ€™ve seen, customization turns into technical debt when it stops being intentional and starts being inherited. The moment no one can clearly explain why a piece of logic exists or what breaks if you remove it, upgrades and change become painful by default. How we at Vestra Inet usually think about this is through a real example. We worked with an engineering solutions company whose quoting, pricing, and delivery logic depended on variables like customer location, electrical standards, units of measurement, and highly configurable products. For them, forcing those workflows into a standard ERP would have meant endless patches. A custom ERP made sense because each module had a clear reason to exist and directly supported how the business actually made money.",
          "score": 1,
          "created_utc": "2026-01-07 07:32:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6f5pf",
          "author": "captain_ankles",
          "text": "Users typically want what theyâ€™ve got already and resist change. EA should be embedding business review and change into the SDLC. I regret not having realised this sooner :(",
          "score": 1,
          "created_utc": "2026-01-07 10:41:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q26w95",
      "title": "Outbox vs re-publish job for communication between internal modules",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q26w95/outbox_vs_republish_job_for_communication_between/",
      "author": "0x4ddd",
      "created_utc": "2026-01-02 18:45:41",
      "score": 8,
      "num_comments": 16,
      "upvote_ratio": 1.0,
      "text": "The important part is this consideration is for communication between internal modules and async process status is stored in database.\n\nTypically outbox is used to make sure no events are lost. But outbox has its own cost:\n- amplifies db writes - assume 10k entities inserted per second where each needs to publish an event, now you need to insert 10k additional records to db, which are going to be deleted seconds later by outbox job, so looks like db needs to do 3 times more work (CDC can help a lot though if it is available) - more CPU usage, more IOPS utilization, transactional log burden\n- outbox introduces some additional latency as it typically runs every X seconds\n- implementation with noSQL variants not supporting cross table/collection transactions is more complex than with SQL\n\nFor some cases, outbox or CDC is required - for example where consumer is some other service which does not confirms back.\n\nHowever, in case of communication between internal modules, where you publish event from let's say API layer, then some background process does its own processing and later on publishes success/failure event so API updates its db state and is aware whether process finished or not, what about alternative approach to just have re-publish background job. It queries db and finds unfinished processes with with sone threshold like 5 minute and simply republishes events.\n\nPros:\n- in high throughput systems, much less DB burden (query per X seconds instead of YYYY inserts per second)\n- event publication without delay incurred by outbox/CDC scan leads to better E2E times\n\nCons:\n- not immediately clear whether process is 'hanged' due to failed publication or downstream service failure, if it's downstream failure relublishing will only put more load on downstream service and duplicate events (anyway, idempotent processing should be implemented)\n- usable only when downstream publishes feedback messages at the end of its processing, otherwise no way to know whether 3rd party received event or not\n\nWhat do you think?\n\nFor me:\n- baseline - standard outbox with outbox processor/CDC\n- if you have very good reasons - maybe republishing job could work under specific circumstances \n",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q26w95/outbox_vs_republish_job_for_communication_between/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nxauq29",
          "author": "chipstastegood",
          "text": "If the database is a bottleneck, the simple option is to spin up another database instance. The cost of getting another instance pales in comparison to paying developers to design, implement, test, and maintain a more sophisticated solution.",
          "score": 5,
          "created_utc": "2026-01-02 18:58:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxaw63f",
              "author": "0x4ddd",
              "text": "Yeah, good point. If this isn't big ball of monolith where who knows which queries join what, spinning additional db per 'module' or sharding existing db would be easier.",
              "score": 1,
              "created_utc": "2026-01-02 19:05:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxaue9f",
          "author": "elkazz",
          "text": "How is your second method meaningfully different from the outbox pattern?",
          "score": 1,
          "created_utc": "2026-01-02 18:56:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxawe6e",
              "author": "0x4ddd",
              "text": "Only different from technical perspective.",
              "score": 1,
              "created_utc": "2026-01-02 19:06:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxaxuxg",
                  "author": "elkazz",
                  "text": "How so? Sounds like a background process is querying the db every x seconds to find events to publish.. exactly like the outbox.",
                  "score": 1,
                  "created_utc": "2026-01-02 19:13:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxcffdv",
          "author": "yoggolian",
          "text": "I guess the advantage of always-outbox is that things can be processed in a consistent sequence, whereas a replay no-ACK events (or even an outbox-on-failure-to-immediately-send strategy) doesnâ€™t get this without a bunch of work.Â ",
          "score": 1,
          "created_utc": "2026-01-02 23:41:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxdy82w",
          "author": "Glove_Witty",
          "text": "If you are doing 10k transactions per second you really should have some other event bus/streaming system.",
          "score": 1,
          "created_utc": "2026-01-03 05:07:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxew585",
              "author": "0x4ddd",
              "text": "To which I need to publish reliably?\nSo either outbox or some republishing job is required.\n\nUnless I misunderstood you",
              "score": 1,
              "created_utc": "2026-01-03 09:48:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxgn4tt",
                  "author": "Glove_Witty",
                  "text": "Sorry. My bad, I didnâ€™t read your post well enough. You are right about the overhead an outbox places on a database, especially if it is already stressed. \n\nThere are a set of other depending on your technology, business and nonfunctional requirements - eg in your alternative it would work fine in the event you can tolerate out of order messages and the 5 min delay in the rare even that the API commits the DB and fails to publish a message. Other systems are ok dropping messages in this situation.",
                  "score": 2,
                  "created_utc": "2026-01-03 16:32:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxlhmgs",
          "author": "clegginab0x",
          "text": "Something like temporal might work?",
          "score": 1,
          "created_utc": "2026-01-04 08:59:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q4zb3k",
      "title": "How to elegantly handle large number of errors in a large codebase?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q4zb3k/how_to_elegantly_handle_large_number_of_errors_in/",
      "author": "tejveeer",
      "created_utc": "2026-01-05 21:51:14",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I'm designing a google classroom clone as a learning experience. I realized I don't know how to manage errors properly besides just throwing and catching wherever, whenever. Here are the issues I'm encountering.\n\nRight now I have three layers. The controllers, services, and repositories.\n\nThere might be errors in the repository layer that need to be handled in the service layer, or handled in the controller layer. These errors may be silenced in that place, or propagated up all the way to the frontend. So we need to be concerned with:\n\n1. Catching errors at the right boundary\n2. Propagating them further if necessary\n\nThen there's the issue of creating errors consistently. There will be many errors that are of the same kind. I may end up creating a message for one kind of error in one way, then a completely different error message for the same kind of error in the same file (or service).\n\nSo I would say error management applies to the following targets: creating errors, handling errors at their boundaries, and propagating them further.\n\nFor each target, we need to be concerned with consistency and completeness. Thus we have the following concerns: \n\n1. Error creation\n   1. Have we consistently created errors? \n   2. Have we created the errors necessary? \n2. Error handling\n   1. Have we consistently handled the same kind of errors at their boundaries? \n   2. Have we covered all the errors' boundaries?\n3. Error propagation\n   1. Have we consistently propagated the same kind of errors?\n   2. Have we propagated all the errors necessary?\n\nHow do we best answer these concerns?",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q4zb3k/how_to_elegantly_handle_large_number_of_errors_in/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nxwg7w9",
          "author": "who_am_i_to_say_so",
          "text": "You have two schools of thought: throwing and trapping/logging the error wherever it happens, and the other is returning the error all the up the call stack to the ui. \n\nSome errors you will want to inform the user. If a user is saving something and thereâ€™s a 500 error, you would want to inform them vaguely of it: â€œwhoops! There was an error. Please try againâ€.  That can be in the controller layer. \n\nOthers you want to happen noisily in the logs to inspect later. Maybe itâ€™s a queue job that can rerun again in an hour, wonâ€™t affect the user experience. Thatâ€™s an example of something going wrong in the service layer.\n\nThere is no one size fits all- it has to fit the situation.",
          "score": 8,
          "created_utc": "2026-01-05 22:30:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxwosno",
          "author": "ings0c",
          "text": "This is a good use case for middleware - treat error handling as a cross-cutting concern. Spreading error handling code around your app, as a pattern rather than through necessity, can get very messy.\n\nSay youâ€™re trying to read a user from the DB and it fails.\n\nYouâ€™d probably have something in your infrastructure layer to catch that error, log it and retry, if itâ€™s still failing after retrying it gets thrown to bubble up the call stack.\n\nYour service layer may be able to continue despite the failing query, in which case it can. If it canâ€™t, it also allows the error to bubble up.\n\nThat eventually reaches your middleware and you have something that automatically writes out a 500 with a problem details RFC response and logs the error.\n\nErrors relating to user input should be raised as high up the call stack as possible, close to the source. You donâ€™t want an invalid request being partially processed. As soon as a request comes in, validate it, and return a 400 if itâ€™s invalid - your framework can usually do this for you.\n\nIf a request is valid, then it should only fail due to things like a network error, a dependency being unavailable, etc, which the middleware approach works fine for.\n\nWhy do you find yourself creating many exception classes / messages yourself? Itâ€™s not that this is bad per se, but you donâ€™t need to be catching a DB error and throwing your own custom exception for the same thing, just allow the original exception to bubble up.",
          "score": 3,
          "created_utc": "2026-01-05 23:13:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q523tk",
      "title": "researching the best low code development platforms 2026, our devs need to move faster.",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q523tk/researching_the_best_low_code_development/",
      "author": "Ancient_Composer2349",
      "created_utc": "2026-01-05 23:39:31",
      "score": 7,
      "num_comments": 21,
      "upvote_ratio": 0.58,
      "text": "our development team is constantly pulled into building simple internal crud apps and admin panels, taking them away from core product work. we're evaluating low code platforms to accelerate this type of development, allowing our devs to focus on complex problems while empowering product managers and business analysts to build simpler tools. we're targeting a 2026 rollout for this new approach.\n\nwe need a platform that offers more power and flexibility than pure no code tools, ideally allowing for custom code (javascript, sql) where needed. it should have strong data modeling, api creation capabilities, and role based security. integration with our existing devops and version control (like git) is important.\n\nwe want to increase our development velocity without sacrificing control. any advice is appreciated.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q523tk/researching_the_best_low_code_development/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nxyi02t",
          "author": "NeloXI",
          "text": "Lol, when this fails and actually sets you further back as it always does, do come back and let us know all the funny details.Â ",
          "score": 28,
          "created_utc": "2026-01-06 05:21:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyf25l",
          "author": "nedal8",
          "text": "lul,\n\na tale as old as time.",
          "score": 9,
          "created_utc": "2026-01-06 05:00:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzdzdv",
          "author": "violentlymickey",
          "text": "I would think about how to enable your developers to do this type of work more quickly (via things like templating/cookiecutter, centralized platform with gui, agents etc) rather than non-devs.",
          "score": 9,
          "created_utc": "2026-01-06 10:05:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3e7ei",
              "author": "HosseinKakavand",
              "text": "Totally agree. The biggest wins weâ€™ve seen come from empowering existing devs, not pushing complexity onto non-devs. The trick is letting engineers focus on domain logic while minimizing glue code, integrations, and orchestration work that consumes cycles. That approach has held up from startups all the way to large orgs like Citi, Allianz, and DLA Piper. We have examples of the approach here: [https://www.reddit.com/r/luthersystems/](https://www.reddit.com/r/luthersystems/)",
              "score": 1,
              "created_utc": "2026-01-06 22:40:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxy0lyw",
          "author": "JadeCikayda",
          "text": "In my experience this never really works - the development team will inevitably own/become involved in \"debugging\" the low code \"apps\"  and it becomes self-defeating - if you want to try this anyway Microsoft's Power Platform is reasonably OK.",
          "score": 16,
          "created_utc": "2026-01-06 03:30:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxxqe4e",
          "author": "rwilcox",
          "text": "Can your BA/Product people be trained to work with these tools?\n\nOr are you just handing developers worse tools (because Pat the PO knows when they get frustrated theyâ€™ll have Quinn the developer do it for them, with worse quality tools than Quinn expects).\n\nEdit: but assuming all that, I see a suggestion for MS already, Iâ€™ll throw in a random suggestion that errs more sql than anything else: a data lake with Google Looker might also work",
          "score": 11,
          "created_utc": "2026-01-06 02:33:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzygb7",
          "author": "ERP_Architect",
          "text": "Iâ€™ve seen teams go down this path for the same reason, and the outcome usually depends less on the platform and more on how narrowly itâ€™s scoped.\n\nWhat tends to work is using low code specifically for internal tools that already have well understood patterns. Simple CRUD apps, internal dashboards, approval flows. When the data model is stable and the rules are mostly straightforward, devs get real time back and the business can move faster without constant handoffs.\n\nWhere it starts to break is when these tools slowly drift into core product territory. Once complex logic, performance constraints, or long lived workflows creep in, people either fight the abstraction or start bypassing it with custom code until it becomes hard to reason about.\n\nThe integration points you mentioned matter more than they sound. If versioning, environments, and access control donâ€™t align with how your dev team already works, you end up with shadow systems no one wants to own. Iâ€™ve also seen friction when non devs can build things but not maintain them once the original context is gone.",
          "score": 4,
          "created_utc": "2026-01-06 12:49:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2zwda",
              "author": "LordWecker",
              "text": "With the biggest issue being; your non-dev staff won't have the experience to recognize when it's growing past its constraints, which means it _will_ grow into something unsustainable.",
              "score": 3,
              "created_utc": "2026-01-06 21:33:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxz3ezo",
          "author": "ruben_vanwyk",
          "text": "Agree with other comments - teach product owners to build their own little tools, that work shouldn't fall on your Product Developers at all.",
          "score": 3,
          "created_utc": "2026-01-06 08:23:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2mnyn",
          "author": "powdertaker",
          "text": "Congratulations!! You've discovered why SQL was invented in the first place! At the time, it was going to be\"empower anyone\" to query all the data within an organization themselves without having to write a program to do it.. Sounds familiar huh?\n\nSo your requirements are: it should provide maximum flexibility and power, be completely customizable and extensible, integrate with all your current tools and be so simple any PO can do it thus freeing up your developers to do the other 10,000 other things they need to do.\n\nSure. Good luck with that.",
          "score": 3,
          "created_utc": "2026-01-06 20:33:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4jg1y",
          "author": "crunchy_code",
          "text": "ask your devs. not random strangers on the internet. \n\nwhat you want to do will make you progress much slower in the long run. \n\nyour devs and you should pull in the same directions for a unified vision. these quick tools are always proposed by non technical people not wanting to accept and contemplate the complexity of building software while at the same time not trusting your devs opinions. so then better go over their head with these â€œquick and flexible toolsâ€.",
          "score": 2,
          "created_utc": "2026-01-07 02:16:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxywimm",
          "author": "cloudsquall8888",
          "text": "In my old job we used jhipster, which is a generator. Essentially you give it entities and their relationships, and it outputs a spring boot backend and a frontend (you choose either react, angular, or vue iirc) with some user management and admin views with crud. \nIt is customisable, and you can also write your own plugins for more custom generation. \n\nIf your work is simple enough, I guess you could stay \"locked in\" jhipster and keep adding entities and stuff and generating again.\n\nOtherwise, you will need to \"eject\" (iirc this is the term they use), and further development will be like usual. So for this use-case, you would be generating only once at the start (saving you the time of setting up projects).\n\nOf course it is not a silver bullet, it is pretty involved to make it behave exactly how you want it, but down the line you might gain from it. We used it because we too had a lot of projects in the public sector, and wanted to be able to start more quickly.",
          "score": 3,
          "created_utc": "2026-01-06 07:19:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6lpjw",
          "author": "dash_bro",
          "text": "Good luck :))\n\nSeriously though - the better fix might be to either get your PMs be ruthlessly optimising for what they need built (prototypes are NOT MVPs); OR enlist a couple of engineers / block their time to cycle through these tasks.\n\nProtect context switching or get more resources to do this. The low code solutioning rarely works out if team velocity is genuinely dragged down due to these demos.",
          "score": 1,
          "created_utc": "2026-01-07 11:36:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6pe2s",
          "author": "-TRlNlTY-",
          "text": "Low-code platform means paying expensive professionals specialized in the platform. Unless the scope of the project is pretty restricted and well defined, I'm skeptical of such tools.",
          "score": 1,
          "created_utc": "2026-01-07 12:03:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxxe8xu",
          "author": "sleepingthom",
          "text": "Do you already have Office 365? I am biased but I find the Power Platform with SharePoint to be the best. You get intranet, document libraries, lists (SQL tables with built in REST and Graph APIs) permission managementâ€¦ etc. \n\nPower Platform gives you workflow / automation, canvas apps, forms, and Power BI. If you need additional features you can build apps using SPFx which I use a lot to host SPA react apps. \n\nIf you can buy into the whole ecosystem it is fantastic for low code. If you donâ€™t already have O365 licenses itâ€™s probably a tough sell though.",
          "score": 0,
          "created_utc": "2026-01-06 01:27:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyyd5b",
          "author": "tleipzig",
          "text": "That's what usually happens in larger dev teams, so I think you are in the right track. Try to avoid vendor lockin and libraries that will at some point be in the way of your developers instead of helping them. You can check out Bootify.io which provides all the points you've mentioned based on Spring Boot.",
          "score": 0,
          "created_utc": "2026-01-06 07:36:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzj53u",
          "author": "ssuing8825",
          "text": "Everything is low code now",
          "score": 0,
          "created_utc": "2026-01-06 10:51:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1kphh",
          "author": "HosseinKakavand",
          "text": "This really resonates with what weâ€™ve seenâ€“speed without losing control usually means keeping critical logic in code, to get all the best tooling (e.g., versioning, approvals, and auditability), and pushing everything else into the platform. Low code can work for basic CRUD, but it tends to break down once flows span many systems and need more advanced logic and reliable operations. That is where an orchestration layer helps, and why we at Luther chose to keep the process logic as code (what we call the Common Operations script). Luther is built for mega-workflows with workflow templates and hundreds of connectors, to deliver faster. More details are on the Luther Enterprise subreddit: [https://www.reddit.com/r/luthersystems/](https://www.reddit.com/r/luthersystems/)",
          "score": -1,
          "created_utc": "2026-01-06 17:41:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxxlv7e",
          "author": "[deleted]",
          "text": "[removed]",
          "score": -14,
          "created_utc": "2026-01-06 02:08:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxoikr",
              "author": "Bodine12",
              "text": "It's amazing how AI-drivel can use so many words to say so little.",
              "score": 8,
              "created_utc": "2026-01-06 02:22:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxy0p7e",
              "author": "JuanPabloElSegundo",
              "text": "Is this some kind of meta comment insinuating to use more AI in development?",
              "score": 2,
              "created_utc": "2026-01-06 03:30:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pyoy5u",
      "title": "recommendations on books to architecture",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1pyoy5u/recommendations_on_books_to_architecture/",
      "author": "deadGrimReaper",
      "created_utc": "2025-12-29 15:21:22",
      "score": 7,
      "num_comments": 6,
      "upvote_ratio": 0.82,
      "text": "I want to learn strategies to build software like DDD and the architectural patterns like onion or hexagonal, and then implementation patterns like CQRS, I don't want to be confused. is there a book that introduces these hierarchies? or if there are multiple books for each concept. I'm open to other sources like YouTube, too. thanks",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1pyoy5u/recommendations_on_books_to_architecture/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nwkq5mz",
          "author": "Alzyros",
          "text": "There's a book recommendation megathread in this sub that's quite helpful",
          "score": 4,
          "created_utc": "2025-12-29 17:15:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwl62jh",
              "author": "deadGrimReaper",
              "text": "thanks, that was actually helpful",
              "score": 3,
              "created_utc": "2025-12-29 18:28:59",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwv4e0f",
              "author": "Interesting-Good7903",
              "text": "I am new and I am not sure where the megsthread. Mind to share a link?",
              "score": 2,
              "created_utc": "2025-12-31 04:57:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwvvuxx",
                  "author": "Alzyros",
                  "text": "It's one of the community highlights: https://www.reddit.com/r/softwarearchitecture/s/4dE1dXl0fP",
                  "score": 1,
                  "created_utc": "2025-12-31 08:48:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwqbqmu",
          "author": "A_Mosaibh",
          "text": "https://preview.redd.it/rzr6a2zwkcag1.jpeg?width=1179&format=pjpg&auto=webp&s=ac12160c0e9965fa762c4672f2c3441085b3b6eb\n\nThis is a really great book",
          "score": 1,
          "created_utc": "2025-12-30 13:59:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwsrdkc",
          "author": "HyperDanon",
          "text": "- \"Hexagonal Architecture\" by Alistair Cockburn\n- \"Enterprise architecture\" by Martin Fowler\n- \"Clean Architecture\" by Robert Martin",
          "score": 1,
          "created_utc": "2025-12-30 21:03:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzz9tp",
      "title": "â€œAgency without governance isnâ€™t intelligence. Itâ€™s debt.â€",
      "subreddit": "softwarearchitecture",
      "url": "/r/u_lexseasson/comments/1pzz8i1/agency_without_governance_isnt_intelligence_its/",
      "author": "lexseasson",
      "created_utc": "2025-12-31 00:57:00",
      "score": 7,
      "num_comments": 2,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1pzz9tp/agency_without_governance_isnt_intelligence_its/",
      "domain": "",
      "is_self": false,
      "comments": [
        {
          "id": "nwvsi1k",
          "author": "Tyhgujgt",
          "text": "It's not that different from people. But you can prompt agent to write down a plan, follow it, test result and then mark which part of the plan was implemented. I'm yet to see a person who can do it this way.Â ",
          "score": 1,
          "created_utc": "2025-12-31 08:16:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxzuw1",
              "author": "lexseasson",
              "text": "I agree with the observation â€” at the individual level, this does look similar to people.\nThe difference shows up at scale.\nHumans get away with not externalizing plans because they share context, intent, and corrective feedback socially. When a person deviates, the blast radius is usually local.\nAgents donâ€™t have that safety net. Once you have multiple agents acting asynchronously across time, tools, and domains, relying on â€œtheyâ€™ll write a plan and follow itâ€ stops working. Not because they canâ€™t â€” but because no one else can inspect, replay, or reason about why something happened later.\nThatâ€™s where governance matters: not as discipline, but as infrastructure. Making intent, assumptions, and success criteria first-class artifacts so decisions remain legible after the fact.\nIn other words, agency without governance isnâ€™t worse than people â€” itâ€™s worse than people at scale.",
              "score": 1,
              "created_utc": "2025-12-31 17:17:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q2321h",
      "title": "WhatsApp Clone... But Decentralized and P2P Encrypted.",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q2321h/whatsapp_clone_but_decentralized_and_p2p_encrypted/",
      "author": "Accurate-Screen8774",
      "created_utc": "2026-01-02 16:27:03",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 0.8,
      "text": "NOTE: This is still a work-in-progress and partially a close-source project. To view the open source version seeÂ [here](https://github.com/positive-intentions/chat). It has NOT been audited or reviewed. For testing purposes only, not a replacement for your current messaging app. I have open source examples of various part of the app and im sure more investigation needs to be done for all details of this project. USE RESPONSIBLY!\n\nIm aiming to create the \"theoretically\" most secure messaging app. This has to be entirely theoretical because its impossible to create the \"worlds most secure messaging app\". Cyber-security is a constantly evolving field and no system can be completely secure.\n\nIf you'd humor me, i tried to create an exhaustive list of features and practices that could help make my messaging app as secure as possible. Id like to open it up to scrutiny.\n\n[Demo](https://p2p.positive-intentions.com/iframe.html?globals=&id=demo-p2p-messaging--p-2-p-messaging&viewMode=story)\n\n(Im grouping into green, orange and red because i coudnt think of a more appropriate title for the grouping.)\n\nGreen\n\n* P2P - so that it can be decentralized and not rely on a central server for exchanging messages. The project is using WebRTC to establish a p2p connection between browsers.\n* End to end encryption - so that even if the messages are intercepted, they cannot be read. The project is using an application-levelÂ [cascading cipher](https://www.reddit.com/r/crypto/comments/1oi4xqt/multiprotocol_cascading_roundrobin_cipher/)Â on top of the encryption provided by WebRTC. the key sub-protocols involves in the approach areÂ [Signal](https://www.reddit.com/r/signal/comments/1orsjw2/signal_protocol_in_javascript/), MLS and AES. while there has been pushback on the cascading cipher, rest-assured that this is functioning on and application-level and the purpose of the cipher is that it guarantees that the \"stronger\" algoritm comes up on top. any failure will result in a cascading failure... ultimately redundent on top of the mandated WebRTC encryption. i would plan to add more protocols into this cascade to investigate post-quantum solutions.\n* Perfect forward secrecy - so that if a key is compromised, past messages cannot be decrypted. WebRTC already provides a reasonable support for this in firefox. but the signal and mls protocol in the cascading cipher also contribute resiliance in this regard.\n* Key management - so that users can manage their own keys and not rely on a central authority. there is key focus on having local-only encryption keys. sets of keys are generated for each new connection and resued in future sessions.\n* Secure signaling - so that the initial connection between peers is established securely. there are many approaches to secure signaling and while a good approach could be exchanging connection data offline, i would also be further improving this by providing more options. its possible to establish a webrtc connection without a connection-brokerÂ [like this](https://github.com/positive-intentions/chat/issues/6).\n* Minimal infrastructure - so that there are fewer points of failure and attack. in the Webrtc approach, messages can be sent without the need of a central server and would also work in an offline hotspot network.\n* Support multimedia - so that users can share animations and videos. this is important to provide an experience to users that makes the project appraling. there is progress made on theÂ [ui component library](https://ui.positive-intentions.com/)Â to provide various features and functionality users expect in a messaging app.\n* Minimize metadata - so no one knows whoâ€™s messaging who or when. i think the metadata is faily minimal, but ultimately is reletive to how feature-rich i want the application. things like notification that a \"user is typing\" can be disabled, but its a common offering in normal messaging apps. similarly i things read-reciepts can be a useful feature but comes with metadata overhead. i hope to discuss these feature more in the future and ultimately provide the ability to disable this.\n\nOrange\n\n* Open source - moving towards a hybrid approach where relevent repositories are open source.\n* Remove registration - creating a messaging app that eliminates the need for users to register is a feature that i think is desired in the cybersec space. the webapp approach seems to offer the capabilities and is working. as i move towards trying to figure out monetization, im unable to see how registration can be avoided.\n* Encrypted storage - browser based cryptography is fairly capable and its possible to have important data like encryption keys encrypted at rest. this is working well when using passkeys to derive a password. this approach is still not complete because there will be improvements to take advantage of the filesystem API in order to have better persistence. passkeys wont be able to address this easily because they get cleared when you clear the site-data (and you lose the password for decrypting the data).\n* User education - the app is faily technical and i could use a lot more time to provide better information to users. the current website has a lot of technical details... but i think its a mess if you want to find information. this needs to be improved.\n* Offline messaging - p2p messaging has its limitations, but i have an idea in mind for addressing this, by being able to spin up a selfhosted version that will remain online and proxy messages to users when they come online. this is still in the early stages of development and is yet to be demonstrated.\n* Self-destructing messages - this is a common offering from secure messaging apps. it should be relatively simple to provide and will be added as a feature \"soon\".\n* Javascript - there is a lot of rhetiric against using javascript for a project like this because of conerns about it being served over the internet. this is undestandable, but i thinkÂ [concerns can be mitigated](https://www.reddit.com/r/CyberSecurityAdvice/comments/1ev5kqn/is_this_a_secure_messaging_app/). i can provide a selfhostable static-bundle to avoid fetching statics from the intetnet. there is additional investigation towards using service workers to cache the nessesary files for offline. i would like to make an explicit button to \"fetch latests statics\". the functionality is working, but more nees to be done before rolling out this functionality.\n* Decentralized profile: users will want to be able to continue conversations across devices. It's possible to implement a p2p solution for this. This is an ongoing investigation.\n\nRed\n\n* Regular security audits - this could be important so that vulnerabilities can be identified and fixed promptly. security audits are very expensive and until there is any funding, this wont be possible. a spicier alternative here is an in-house security audit. i have made attempts to create such audits for the signal protocols and MLS. im sure i can dive into more details, but ultimately an in-house audit in invalidated by any bias i might impart.\n* Anonymity - so that users can communicate without revealing their identity is a feature many privacy-advocates want. p2p messages has nuanced trandoffs. id like to further investigate onion style routing, so that the origins can be hidden, but i also notice that webrtc is generally discourage when using the TOR network. it could help if users user a VPN, but that strays further from what i can offer as part of my app. this is an ongoing investigation.\n\nAiming to provide industry grade security encapsulated into a standalone webapp. Feel free to reach out for clarity on any details.\n\n [Demo](https://p2p.positive-intentions.com/iframe.html?globals=&id=demo-p2p-messaging--p-2-p-messaging&viewMode=story)\n\nIMPORTANT NOTE: It's worth repeating, this is still a work in progress and not ready to replace any existing solution. Provided for testing, demo and feedback purposes only.",
      "is_original_content": false,
      "link_flair_text": "Tool/Product",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q2321h/whatsapp_clone_but_decentralized_and_p2p_encrypted/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q06qzw",
      "title": "We â€œsolvedâ€ C10K years ago yet we keep reinventing it",
      "subreddit": "softwarearchitecture",
      "url": "https://www.kegel.com/c10k.html",
      "author": "Digitalunicon",
      "created_utc": "2025-12-31 07:07:51",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q06qzw/we_solved_c10k_years_ago_yet_we_keep_reinventing/",
      "domain": "kegel.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1q0sq32",
      "title": "Plugin system that similar to Figmaâ€™s one",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q0sq32/plugin_system_that_similar_to_figmas_one/",
      "author": "voldaew",
      "created_utc": "2026-01-01 01:39:59",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 0.86,
      "text": "I want to build plugin system that should be run on the web without DOM access. It should live in sandbox for security. Imagine an predefined UI component which is like a software function, it takes arguments and it returns values.\n\nconst example = (params) => values\n\nI need an architecture to allow developer that can create their own functions in the UI.\n\nHave you ever built plugin system for web projects? Please let me know your experiences and know-how.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q0sq32/plugin_system_that_similar_to_figmas_one/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nx196w0",
          "author": "mistyharsh",
          "text": "It is nearly impossible to do it. You can try patching window, globalThis and other global objects to prevent access but you cannot do it reliably across multiple plugins.\n\nIf security is paramount, then you have two choices. Put all the external/plugin scripts into a web worker or load them via invisible iframe. Then, you can use the post message API to communicate back and forth.\n\nAlso note that Figma is quite a sophisticated system. It has its own canvas based renderer and doesn't really use DOM, so they can control the API surface.",
          "score": 2,
          "created_utc": "2026-01-01 04:45:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx0tkyb",
          "author": "asdfdelta",
          "text": "Sounds like just an imported script.\n\nWrap your code in a self-invoking scope so that no outside code can inspect or interact with it. Lots of tools and companies use that, easiest way to achieve it is to minify your code. It usually adds the self-invoking scope around it, on top it obfuscates the code itself (which cannot be protected from viewing).\n\nOtherwise maybe a service worker or web component.\n\nGood luck!",
          "score": 1,
          "created_utc": "2026-01-01 02:55:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q0kb92",
      "title": "why does metric high cardinality break things",
      "subreddit": "softwarearchitecture",
      "url": "/r/devops/comments/1q0kaqi/why_does_metric_high_cardinality_break_things/",
      "author": "nroar",
      "created_utc": "2025-12-31 18:45:38",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q0kb92/why_does_metric_high_cardinality_break_things/",
      "domain": "",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1q5a881",
      "title": "Itâ€™s 2026 â€” if you were starting a new frontend today, what stack/tooling would you choose and why? What would you avoid?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q5a881/its_2026_if_you_were_starting_a_new_frontend/",
      "author": "CodePatrol",
      "created_utc": "2026-01-06 05:38:53",
      "score": 4,
      "num_comments": 6,
      "upvote_ratio": 0.61,
      "text": "Iâ€™m bullish on Qwik and the resumability model to reduce hydration cost, increase Core Web Vital scores, and keep SSR apps from shipping huge bundles. What else is moving the needle for you?",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q5a881/its_2026_if_you_were_starting_a_new_frontend/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nxzcfgt",
          "author": "Klutzy_Table_6671",
          "text": "I would always choose html css and TypescriptÂ ",
          "score": 9,
          "created_utc": "2026-01-06 09:50:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzyr7b",
          "author": "ERP_Architect",
          "text": "If I were starting fresh now, Iâ€™d probably bias toward things that are boring and predictable rather than chasing whatever looks most clever. Whatâ€™s worked best for me is keeping initial load light and server rendering straightforward, without making everyday changes feel complicated. Reducing how much code wakes up in the browser is a real win, but only if the mental model stays simple once you add state, auth, forms, and all the messy stuff. Where Iâ€™ve seen teams struggle is stacking too many advanced ideas early. They look great in demos, but debugging and iteration slow down fast once real requirements show up. At this point, Iâ€™d avoid anything that needs constant expert attention just to stay productive. A forgiving stack thatâ€™s easy to reason about under pressure tends to matter more than squeezing out theoretical performance gains.",
          "score": 7,
          "created_utc": "2026-01-06 12:51:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzppq2",
          "author": "Vincent-Thomas",
          "text": "Rust askama, pg, lit.dev and htmx",
          "score": 3,
          "created_utc": "2026-01-06 11:46:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0h8sh",
          "author": "asdfdelta",
          "text": "Svelte.\n\nFast to pick up for people with any framework experience, runs extremely fast out of the box, really difficult to screw up, adapt the same codebase for various channels, really easy to upgrade to microfrontends in the future.\n\nAlso can handle other frameworks running in it, which is important when you're migrating from an existing frontend.",
          "score": 2,
          "created_utc": "2026-01-06 14:36:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5trmk",
          "author": "JosephineRoberts_",
          "text": "If I were starting today, Iâ€™d probably go TypeScript + React with a boring meta-framework (Next or Remix), SSR first, and be aggressive about server components / islands so as little JS as possible wakes up on the client. Itâ€™s easy to hire for, plays nicely with typed API contracts, and the ecosystem is huge. Iâ€™d avoid anything that needs a framework expert on call just to debug auth, forms, or data fetching; â€œcleverâ€ stacks tend to age badly once the app and team grow.",
          "score": 2,
          "created_utc": "2026-01-07 07:25:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyn9w9",
          "author": "jonathon8903",
          "text": "Eh it really depends on what Iâ€™m building. If itâ€™s a simple application/site with limited expected growth, I might just go with straight HTML/JS/CSS. Why include a JS framework if I donâ€™t need it. Maybe I integrate some HTMX and something like Alpine. If the application is going to be bigger than look into React or Next. React isnâ€™t the best and I donâ€™t personally love it but when it comes time to onboard new developers you canâ€™t go wrong with React. I really love the Tanstack libraries but who knows, two years from now it may start to become the bad practice. May as well pick something stable and that you can create with quickly.",
          "score": 1,
          "created_utc": "2026-01-06 06:01:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q1r1zc",
      "title": "Patching: The Boring Security Practice That Could Save You $700 Million",
      "subreddit": "softwarearchitecture",
      "url": "https://lukasniessen.medium.com/patching-the-boring-security-practice-that-could-save-you-700-million-4d8f8b4b56a1?source=user_profile_page---------2-------------e997ef2a34b8----------------------",
      "author": "trolleid",
      "created_utc": "2026-01-02 06:11:54",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 0.75,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q1r1zc/patching_the_boring_security_practice_that_could/",
      "domain": "lukasniessen.medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "nx7q0ge",
          "author": "gbrennon",
          "text": "Later jll read this. Im already in bed",
          "score": -4,
          "created_utc": "2026-01-02 06:45:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q5cp2p",
      "title": "Why I want to reimplement architecture as code approach?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q5cp2p/why_i_want_to_reimplement_architecture_as_code/",
      "author": "vmgolubev",
      "created_utc": "2026-01-06 08:01:19",
      "score": 3,
      "num_comments": 2,
      "upvote_ratio": 0.62,
      "text": "Hello everyone!\n\nI needed a tool that can help me in my daily tasks as an architect - prototype a system, discuss it with a team, update artifacts, and after some time, track does the reality fits the design while team is working on the implementation. But all of the existing tools - doesn't provide me with all the features that I need. I hate static architecture artifacts that should be updated every time a small change is made. Structurizr, LikeC4 or FINOS CALM approach is not for me, you need to write a lot of custom DSL or JSON(in CALM approach). But I want automation and a code-first approach, not a DSL first approach! I believe that every developer or architect(they are/were developers, they know how to code, if an architectÂ  don't want to code than AI assistant can help you with that) should easily create any of architecture artifact, update them, keep them in sync with reality without any hustle!\n\nThats why I write this post, I want to create such tool, so I started [FlowConsole](https://slackmaster9999.github.io/flowconsole/?utm_source=reddit) as an open source project with a goal to create an Architecture as Code Platform that helps developers and architects to have a single source of truth for systems that they are building with their favorite tools - programming language, ide, git, etc.\n\nImagine if you can define architecture using your favorite language(TS, Python, Java, C# or any other language) - all the components, how it's connects, protocols and tech stack it's using, etc, and based on that model you get a complete set of architectural artifacts â€” including auto-positioned live(animated) diagrams(data flows, sequences), documentation and you can track how the actual implementation deviates from the defined design. And all of that automatically, without the need to create static artifacts, no needs to learn some custom DSL and automation boilerplate!\n\nI started small, built a Typescript Fluent API and a simple engine that can generate architecture diagrams to test this approach. Still a lot has to be done, but You can try it out in the browser to get my idea.\n\nÂ My roadmap:\n\n* VS Code extension(live view of artifacts)\n* Jetbrains IDEA/Rider extension\n* CLI tool for artifacts generation in your CI/CD pipeline\n* C#(WIP), Java, Go, Python support(vote your language!)\n* Drift CLI tool to check for architecture drifts\n\nI will appreciate any meaningful comments on my project, thanks!",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q5cp2p/why_i_want_to_reimplement_architecture_as_code/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "ny0wr5l",
          "author": "arnorhs",
          "text": "I need to try this in my desktop when I get home. I like the general idea and agree with your take",
          "score": 2,
          "created_utc": "2026-01-06 15:52:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5ju4h",
              "author": "vmgolubev",
              "text": "Thanks for the feedback.",
              "score": 1,
              "created_utc": "2026-01-07 06:02:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q0aciz",
      "title": "Narrative systems architecture",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1q0aciz/narrative_systems_architecture/",
      "author": "Comment_Alert",
      "created_utc": "2025-12-31 10:55:40",
      "score": 2,
      "num_comments": 14,
      "upvote_ratio": 0.57,
      "text": "Hello not sure if I'm in the right place or not but for 5 months I've been learning how to use ai like literally using ai chat bots and what happened was I was creating a fictional story with ai and cos I'm non linear (got the tism ðŸ˜…) the ai pointed out that my fictional RPG/anime story was actually a system which I tried to argue back it wasn't it was just a cool ass story but the ai straightened it out and then showed me it was a system. Now I have no tech background no uni no degree just a 40 year old guy who's a story teller. Im looking for help or validation that is not ai to see if what I'm doing is either new, not new, if it's useful cos I legit have no idea ðŸ˜… this is my first time using Reddit so any help would be appreciated. If it helps I used mario as a visual for my brain to latch on to expand my system and happy to share?",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1q0aciz/narrative_systems_architecture/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "nwwb1z7",
          "author": "elkazz",
          "text": "I think you're looking for r/gamedev",
          "score": 4,
          "created_utc": "2025-12-31 11:11:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwwic7a",
          "author": "ERP_Architect",
          "text": "Youâ€™re actually not as far off as you think, and what youâ€™re describing isnâ€™t nonsense or new in a bad way.\n\nA lot of systems architecture starts as narrative. People just donâ€™t usually call it that. When architects explain how a system behaves, they talk in flows, roles, states, conflicts, and outcomes. Thatâ€™s storytelling with constraints.\n\nWhatâ€™s interesting about your approach is that youâ€™re starting from story and discovering structure instead of starting from structure and forcing meaning onto it. Thatâ€™s how many good designs are born, especially when dealing with complex or non linear systems.\n\nThis isnâ€™t unique in the sense that no oneâ€™s ever done it, but it is useful. Domain driven design, event modeling, and even game design all use narrative thinking to reason about systems. Your Mario analogy is actually a classic mental model. Clear actors, rules, progression, failure states.\n\nYou donâ€™t need a tech background to do this well. What matters is whether your story can answer questions like who acts, what changes state, what triggers what, and what happens when things go wrong.\n\nIf it helps you reason clearly and communicate complexity to others, itâ€™s valid. Sharing an example would probably make it much easier for people here to react in a concrete way.",
          "score": 3,
          "created_utc": "2025-12-31 12:14:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwjdyx",
              "author": "Comment_Alert",
              "text": "https://preview.redd.it/0lgxvdyl8jag1.jpeg?width=1080&format=pjpg&auto=webp&s=2fbbb87440b5134872bae3c0e424772dd3a9480c\n\nSo what I did was to avoid the copyright situation cos well Nintendo lol I decided to change the narrative and use spells instead..I asked the ai to translate it into machine logic and managed to get it done via xtext",
              "score": 3,
              "created_utc": "2025-12-31 12:22:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwwk6gh",
                  "author": "ERP_Architect",
                  "text": "That actually makes a lot of sense, and itâ€™s a good move.\n\nBy swapping out Mario for spells, youâ€™re basically peeling the idea down to its mechanics instead of the skin. Spells are just actions, they change state, they have rules, limits, and effects. Thatâ€™s exactly how people end up thinking about systems, even if they donâ€™t call it that.\n\nThe fact that you pushed it through Xtext is interesting too. At that point youâ€™re not just telling a story anymore, youâ€™re trying to formalize it so something else can understand and act on it. Thatâ€™s very close to how domain specific languages come into existence.\n\nThe thing Iâ€™d pay attention to next is consistency. If the same spell shows up in different situations, does it behave the same way every time? Are there states that should never be allowed, or failure cases that are clear instead of hand waved?\n\nIf someone else can look at your model and roughly predict what happens without you walking them through it, youâ€™re onto something real.",
                  "score": 2,
                  "created_utc": "2025-12-31 12:28:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwwbapx",
          "author": "Comment_Alert",
          "text": "Oh it's not a game I've been doing this is just how it started I've actually mapped fiction to systems mechanics and made systems using ai?",
          "score": 2,
          "created_utc": "2025-12-31 11:13:40",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nwxqp6w",
          "author": "Glove_Witty",
          "text": "Hi OP. This is pretty cool. I am wondering where you want to take this? Do you want to take it back to narrative form or have the whole story told in code?\n\nIn any case, like u/ERP_architect said, the next step would be to create some objects for your world and think about their state. You might enjoy reading about object oriented programming languages.",
          "score": 2,
          "created_utc": "2025-12-31 16:32:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxsbq1",
              "author": "Comment_Alert",
              "text": "I donâ€™t really want to take it back to pure narrative, and I donâ€™t want it to become â€œjust codeâ€ either. The story was how I discovered the structure, but the end goal is a formal system you can reason about and reuse.\nThe spells behave more like constraints and behaviors than classic objects. State tends to emerge from how things are layered, chained, or nested, which is why I leaned toward a DSL (Xtext).\n\nThat said, I get what youâ€™re pointing at â€” once the grammar is stable, it can be projected into objects, processes, or agents depending on the domain. Iâ€™ll definitely dig more into OOP, even if just as a comparison.\n\nSo far the systems I've made (about 8-10) seem to work fluidly and I'm hoping that it's another lens that can be used to create systems. It's really fun if I'm honest even tho I'm just using a mobile phone and a Rog ally ðŸ˜…ðŸ˜…",
              "score": 1,
              "created_utc": "2025-12-31 16:40:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwxsuj7",
                  "author": "Glove_Witty",
                  "text": "Iâ€™ve been thinking of a story with a hard physics system I cooked up with DeepSeek. I get why this is fun.",
                  "score": 1,
                  "created_utc": "2025-12-31 16:42:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwwbxp4",
          "author": "Comment_Alert",
          "text": "https://preview.redd.it/nsvogdabxiag1.jpeg?width=1080&format=pjpg&auto=webp&s=de3c2654f53c3ee8403cfffef7d2823143776768\n\nIt looked like this but I've modified it since then",
          "score": 1,
          "created_utc": "2025-12-31 11:19:28",
          "is_submitter": true,
          "replies": []
        }
      ]
    }
  ]
}