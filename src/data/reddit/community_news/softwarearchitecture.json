{
  "metadata": {
    "last_updated": "2026-02-04 02:59:57",
    "time_filter": "week",
    "subreddit": "softwarearchitecture",
    "total_items": 20,
    "total_comments": 126,
    "file_size_bytes": 174013
  },
  "items": [
    {
      "id": "1qtw76q",
      "title": "We skipped system design patterns, and paid the price",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qtw76q/we_skipped_system_design_patterns_and_paid_the/",
      "author": "Icy_Screen3576",
      "created_utc": "2026-02-02 14:16:04",
      "score": 243,
      "num_comments": 34,
      "upvote_ratio": 0.97,
      "text": "We ran into something recently that made me rethink a system design decision while working on an event-driven architecture. We have multiple Kafka topics and worker services chained together, a kind of mini workflow.\n\n[Mini Workflow](https://preview.redd.it/fgm3nejx93hg1.png?width=3750&format=png&auto=webp&s=7965432a4731f2658c648475b1d90593a0f69282)\n\nThe entry point is a legacy system. It reads data from an integration database, builds a JSON file, and publishes the entire file directly into the first Kafka topic.\n\n# The problem\n\nOne day, some of those JSON files started exceeding Kafkaâ€™s default message size limit. Our first reaction was to ask the DevOps team to increase the Kafka size limit. It worked, but it felt similar to increasing a database connection pool size.\n\nThen one of the JSON files kept growing. At that point, the DevOps team pushed back on increasing the Kafka size limit any further, so the team decided to implement chunking logic inside the legacy system itself, splitting the file before sending it into Kafka.\n\nThat worked too, but now we had custom batching/chunking logic affecting the stability of an existing working system.\n\n# The solution\n\nWhile looking into system design patterns, I came across the Claim-Check pattern.\n\n[Claim-Check Pattern](https://preview.redd.it/3lmiy1t9a3hg1.png?width=3332&format=png&auto=webp&s=890aa3c5d542d979c9e7eb0d564dcfa576aa9276)\n\nInstead of batching inside the legacy system, the idea is to store the large payload in external storage, send only a small message with a reference, and let consumers fetch the payload only when they actually need it.\n\n# The realization\n\nWhat surprised me was realizing that simply looking into existing system design patterns could have saved us a lot of time building all of this.\n\nItâ€™s a good reminder to pause and check those patterns when making system design decisions, instead of immediately implementing the first idea that comes to mind.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qtw76q/we_skipped_system_design_patterns_and_paid_the/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o35sph1",
          "author": "Estel-3032",
          "text": "I remember that in my first job one of the other engineers said 'so let's check what kind of wheels people are using out there before we start inventing our own' to a roughly similar situation and it stuck with me.",
          "score": 107,
          "created_utc": "2026-02-02 14:33:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35yybb",
              "author": "Icy_Screen3576",
              "text": "Sounds like a pragmatic engineer.",
              "score": 26,
              "created_utc": "2026-02-02 15:05:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o363lmg",
          "author": "czlowiek4888",
          "text": "Yeah, this is exactly what you should do.\n\nDon't treat messages in your system as a data storage ( it is convenient though ) but more like notifications.\n\nYou just want to send event telling you what happened, not necessarily why, how, where and when. All those other information you should get on your own from database or other storage when you think it's necessary.\n\nIn real time system you usually want to have each message under ~1.4kb this is the frame size in which your messages are send over the network.\n\nBecause if you need to pass larger messages you will need wait for the all other frames that together create single message.\n\nThis way if you send only 1 frame you can go crazy fast.\n\nAlso Kafka uses stores messages to be replied when necessary, you will be able to store more messages.\n\nYou also may want to think about private replies of messages. For example you have service that receives http request, you send event and await other in response. You need to know how to send a response event to the instance of app that holds http socket file to be able to respond to the http request with the event data.\n\nIt's a bit more advanced but it is what many event driven systems need.",
          "score": 22,
          "created_utc": "2026-02-02 15:28:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36bjxc",
              "author": "Icy_Screen3576",
              "text": "Well said. Keeping messages small and event-focused made things a lot simpler.",
              "score": 4,
              "created_utc": "2026-02-02 16:06:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3663cp",
          "author": "bigkahuna1uk",
          "text": "I think everyone should read [Enterprise Integration Patterns](https://www.enterpriseintegrationpatterns.com/patterns/messaging/toc.html) by Gregor Hophe  .\n\nOver 20 years old but still highly relevant today.",
          "score": 37,
          "created_utc": "2026-02-02 15:40:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3694rz",
              "author": "bobaduk",
              "text": "Came here to say exactly this. IIRC the patterns are all described online, so you can skim and get a vague sense, then go back to look deeper when you need something.\n\nMessaging patterns have been established for a long time, and it's worth being familiar with the prior art.",
              "score": 7,
              "created_utc": "2026-02-02 15:54:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o369oto",
              "author": "Icy_Screen3576",
              "text": "Thanks for sharing!",
              "score": 2,
              "created_utc": "2026-02-02 15:57:19",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3bmq78",
              "author": "garden_variety_sp",
              "text": "And every pattern has been implemented by Apache Camel, the GOAT of integration frameworks. And 100% free and open source.",
              "score": 1,
              "created_utc": "2026-02-03 11:07:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o35qx62",
          "author": "AzureMate",
          "text": "Clever! Thanks for sharing!",
          "score": 14,
          "created_utc": "2026-02-02 14:24:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35uopk",
              "author": "Icy_Screen3576",
              "text": "You are welcome! Glad it helped.",
              "score": 1,
              "created_utc": "2026-02-02 14:43:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o363xwc",
          "author": "tesseraphim",
          "text": "It worked, the system kept chugging for quite some time. That's a win. It could have worked for 10 years, some systems do. The question is, how much change you needed to do. Trick is not to build up front, but make sure the seams are there so you can easily change.",
          "score": 6,
          "created_utc": "2026-02-02 15:30:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35y599",
          "author": "Few_Wallaby_9128",
          "text": "It does come at a price, right? an extra single point of failure, extra latency, possible network failures and managament (dns/cert renewals/fws), and logic to handle the lifecycle, synchronization and deletion of the data in the storage. If the growing json was the problem, dynamic zipping of it could have worked wonders at a fraction of the total cost of maintenance.",
          "score": 11,
          "created_utc": "2026-02-02 15:01:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35zedo",
              "author": "europeanputin",
              "text": "Software engineering is always full of trade-offs. I have a non-fixed size JSONs, but due to compliance reasons there's no way that they could be pulled on-demand, and I simply have to store them all, regardless of their size. Some documents are about the size of 10mb after doing the compression.",
              "score": 13,
              "created_utc": "2026-02-02 15:08:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o364msa",
              "author": "czlowiek4888",
              "text": "You shouldn't think about it as a trade off.\nThis is the one and only correct way.\n\nSending events with the data is anti pattern imho.\nWhat if you want to add CQRS and you regenerate your state from commands?\nAnd now data you hold in your messages is no longer valid because it was changed how app processes things so your message as a storage approach make you not able to perform state regeneration.",
              "score": 3,
              "created_utc": "2026-02-02 15:33:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3650bk",
                  "author": "czlowiek4888",
                  "text": "Also what if your messages store personal information that you are obligated to remove in certain situations.\nYou will be deleting messages and this will lead to inability to regenerate state as disaster recovery mechanism.",
                  "score": 3,
                  "created_utc": "2026-02-02 15:35:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o38r9ib",
                  "author": "pins17",
                  "text": "For OP's scenario I agree. But in general it really depends on the use case.\n\nFor example, in high-frequency scenarios like price updates on energy or commodity markets, it is standard practice to include the market data directly in the event. That is the whole point. Doing a lookup for every event would introduce unacceptable latency and massive load on the source system. The same applies to telemetry data in fleet management.\n\nClaim Check has its merits, as you mentioned, but it also has downsides. While the producer is free from temporal/runtime coupling, the consumer is not, which negates one of the main benefits of asynchronous architecture.",
                  "score": 2,
                  "created_utc": "2026-02-02 22:56:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35s577",
          "author": "cstopher89",
          "text": "This is a nice pattern. I use it for Azure Service Bus messages to handle large payloads.",
          "score": 2,
          "created_utc": "2026-02-02 14:30:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35w6va",
              "author": "Icy_Screen3576",
              "text": "In our case it was an on-prem Kafka broker, with the payload in external storage. Do you usually pair Service Bus with Blob Storage for this?",
              "score": 2,
              "created_utc": "2026-02-02 14:51:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o37zfxv",
                  "author": "01acidburn",
                  "text": "Yep",
                  "score": 1,
                  "created_utc": "2026-02-02 20:42:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o38qc8h",
                  "author": "cstopher89",
                  "text": "Yeah blob storage works well for this",
                  "score": 1,
                  "created_utc": "2026-02-02 22:51:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o36mkf6",
          "author": "nt2g",
          "text": "Great post and great reminder, thank you for sharing!",
          "score": 2,
          "created_utc": "2026-02-02 16:56:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37a0ej",
          "author": "dukemanh",
          "text": "question: what will happen and what should we do if the tiny message already arrived at the consumer but the large payload is not yet available on the file storage?",
          "score": 2,
          "created_utc": "2026-02-02 18:43:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37x2tn",
              "author": "Primary-Juice-4888",
              "text": "Consumer - retry message processing until file is available, perhaps with exponential backoff.\n\nor\n\nProducer - only send a message after the storage write was confirmed.",
              "score": 5,
              "created_utc": "2026-02-02 20:30:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o36raxr",
          "author": "Samrit_buildss",
          "text": "Really nice write-up. The claim-check pattern here is a great reminder that many scaling problems already have well-known solutions we just forget to look for them under pressure.",
          "score": 3,
          "created_utc": "2026-02-02 17:18:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35utna",
          "author": "Constant_Physics8504",
          "text": "Couldâ€™ve been turned into a Dispatch system with MQ quite easily",
          "score": 1,
          "created_utc": "2026-02-02 14:44:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o363d0a",
              "author": "Icy_Screen3576",
              "text": "Yep, we only use claim-check for large payloads. Most messages go through the message broker.",
              "score": 3,
              "created_utc": "2026-02-02 15:27:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o37gnoz",
          "author": "bunsenhoneydew007",
          "text": "We use the claim check pattern extensively on a similar workflow like system. It works extremely well and allows the payload to be agnostic to the event transfer mechanism, which can provide other benefits regarding data processing in the services. (We use eventbridge rather than Kafka).",
          "score": 1,
          "created_utc": "2026-02-02 19:13:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37ktml",
          "author": "Careless-Childhood66",
          "text": "Amen",
          "score": 1,
          "created_utc": "2026-02-02 19:33:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o38o6pt",
          "author": "ErgodicMage",
          "text": "I develop distrubuted workflow systems and use Claims all the time.",
          "score": 1,
          "created_utc": "2026-02-02 22:40:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bmwkd",
          "author": "garden_variety_sp",
          "text": "Did you consider using a more compact wire format like Avro or Protobuf?",
          "score": 1,
          "created_utc": "2026-02-03 11:08:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c3yre",
              "author": "Icy_Screen3576",
              "text": "Considered avro, still we would be pushing in the wrong direction. Thinking in tiny events made things simpler. I dont think message brokers are made for large payloads.",
              "score": 1,
              "created_utc": "2026-02-03 13:13:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qsz7w5",
      "title": "[META] AI generated posts are no longer allowed",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qsz7w5/meta_ai_generated_posts_are_no_longer_allowed/",
      "author": "asdfdelta",
      "created_utc": "2026-02-01 14:01:24",
      "score": 152,
      "num_comments": 15,
      "upvote_ratio": 0.97,
      "text": "Following the poll that was posted last week, the community has overwhelmingly voted to remove any kind of post or comment that we clearly generated by AI.\n\nPosts and comments can now be reported for AI generated text, and will be removed as I see the reports or posts. **Please report what you see!**\n\nThis rule applies to all posts and comments following the timestamp of this one, it will not retroactively affect any content on the sub.\n\nAdvice for those that wish to use AI to translate or inprove English as it is not your first language: write the overall structure of your post yourself and let an AI tool like Grammarly's inline capabilities (free) to improve the sentence structure and word choice. This has been around for a long time and continues to get better. Fully generating your posts will result in removal, repeat offenders will be banned. I'm open to pinning a post that has a list of good alternatives if we can crowdsource it from experience.\n\nThank you to everyone who voted in the poll! Keeping the sub healthy takes everyone's effort. Thank you especially for those that called for mod action, they spurred this new rule into existence.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qsz7w5/meta_ai_generated_posts_are_no_longer_allowed/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o2z2krn",
          "author": "bobaduk",
          "text": "Delighted to see this, personally. If I want ChatGPTs output, I'll ask for it myself.",
          "score": 42,
          "created_utc": "2026-02-01 14:23:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o315oo0",
          "author": "tomByrer",
          "text": "I 100% agree, but I'm also wondering about the folks who don't speak English, & have to use a translator to communicate....",
          "score": 7,
          "created_utc": "2026-02-01 20:17:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o31du5v",
              "author": "asdfdelta",
              "text": "I am as well. If you know of any methods that can be used or tools that won't write 100% of the post, please let me know.",
              "score": 2,
              "created_utc": "2026-02-01 20:57:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2zbsa8",
          "author": "CompetitiveProof3078",
          "text": "Great news",
          "score": 6,
          "created_utc": "2026-02-01 15:12:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o31vu29",
          "author": "donz0r",
          "text": "Does the rule apply to comments as well?",
          "score": 3,
          "created_utc": "2026-02-01 22:25:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35hg1p",
              "author": "asdfdelta",
              "text": "Yes! But the timestamp must be after this post was published.",
              "score": 2,
              "created_utc": "2026-02-02 13:31:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o326zgr",
          "author": "UnreasonableEconomy",
          "text": "Regarding translation: I think the problem isn't translation, but generation. Specifically, people using \"translation\" and ESL as a moral mask for generated content.\n\nThis is just an idea, and I don't know how good it is - but perhaps allowing translation with any tool, including chatgpt - would be acceptable, as long as the OP includes the original as a comment.",
          "score": 3,
          "created_utc": "2026-02-01 23:24:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35htwf",
              "author": "asdfdelta",
              "text": "That might be a good idea, I'll add it to the list of possibilities. Thank you!",
              "score": 3,
              "created_utc": "2026-02-02 13:33:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2z41sm",
          "author": "IlliterateJedi",
          "text": "Disappointing.  Reporting all the AI posts on here gave me something to do during my daily ablutions every morning.",
          "score": 11,
          "created_utc": "2026-02-01 14:32:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2z8k0u",
              "author": "uusu",
              "text": "That's literally what OP is asking us to do. You can't 100% be certain a post is AI generated, so the report helps you know whether the community is okay with removing a post.\n\nAdditionally, now your reporting actually has an effect thanks to this rule.",
              "score": 9,
              "created_utc": "2026-02-01 14:56:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o30f4ag",
          "author": "wjrasmussen",
          "text": "I appreciate that we are going this direction.  Brought to you by Carl's Jr.",
          "score": 4,
          "created_utc": "2026-02-01 18:14:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o31e7l3",
              "author": "asdfdelta",
              "text": "I can't bring myself to rewatch Idiocracy anymore, it's just too much ðŸ˜‚",
              "score": 6,
              "created_utc": "2026-02-01 20:59:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o300jvn",
          "author": "Gunny2862",
          "text": "Amen.",
          "score": 1,
          "created_utc": "2026-02-01 17:08:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o30jzkf",
          "author": "777ortale",
          "text": "Nice! Beep boop.",
          "score": 1,
          "created_utc": "2026-02-01 18:36:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qsqft5",
      "title": "Architecture for beginners",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qsqft5/architecture_for_beginners/",
      "author": "EviliestBuckle",
      "created_utc": "2026-02-01 06:05:06",
      "score": 87,
      "num_comments": 37,
      "upvote_ratio": 0.99,
      "text": "Are there any recommended resources for beginners to study and understand and start their journey towards software architects?\n\nBackground: worded in frontend and backend with just basic crud api\n\nExperience: 4yrs but afraid to have a repeated 1 year of experience for four years. Need to justify my experience after 10 years",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qsqft5/architecture_for_beginners/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o2xdkiw",
          "author": "coffeemahn",
          "text": "Books\n\nDesigning Data Intensive Applications,\nSoftware Architecture the hard parts\n\nEdit: added comma",
          "score": 43,
          "created_utc": "2026-02-01 06:06:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xgqry",
              "author": "EviliestBuckle",
              "text": "Is there any practical application resources on these?",
              "score": 3,
              "created_utc": "2026-02-01 06:32:35",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2y87dl",
              "author": "httpgo",
              "text": "/u/BookFinderBot",
              "score": 1,
              "created_utc": "2026-02-01 10:43:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2y8ato",
                  "author": "BookFinderBot",
                  "text": "**Designing Data Intensive Applications for Modern Systems Principles, Trade-Offs, and Architectures for Reliable and Scalable Data Platforms** by Zeon Aric\n\n\n>Designing modern data platforms is not about finding perfect solutions-it is about understanding trade-offs. Every architectural decision affects consistency, latency, fault tolerance, complexity, and compliance in ways that are rarely obvious at first glance. Designing Data-Intensive Applications for Modern Systems takes a system-level view of data architecture, guiding readers through the principles that underpin today's distributed databases, streaming platforms, and analytics systems. Building on core concepts, this volume examines how large-scale systems are structured, why they fail, and how they evolve over time.\n>\n>The book explores consistency models, distributed coordination, event-driven architectures, and data governance concerns such as privacy and regulatory compliance. Readers will gain the tools to evaluate architectural options, reason about failure modes, and design platforms that balance performance with operational simplicity. Aimed at senior engineers, technical leads, and system architects, this volume provides the architectural insight needed to design data-intensive systems that are resilient, scalable, and prepared for future growth.\n\n\n**Software Architecture: The Hard Parts** by Neal Ford, Mark Richards, Pramod Sadalage, Zhamak Dehghani\n\n\n>There are no easy decisions in software architecture. Instead, there are many hard parts--difficult problems or issues with no best practices--that force you to choose among various compromises. With this book, you'll learn how to think critically about the trade-offs involved with distributed architectures. Architecture veterans and practicing consultants Neal Ford, Mark Richards, Pramod Sadalage, and Zhamak Dehghani discuss strategies for choosing an appropriate architecture.\n>\n>By interweaving a story about a fictional group of technology professionals--the Sysops Squad--they examine everything from how to determine service granularity, manage workflows and orchestration, manage and decouple contracts, and manage distributed transactions to how to optimize operational characteristics, such as scalability, elasticity, and performance. By focusing on commonly asked questions, this book provides techniques to help you discover and weigh the trade-offs as you confront the issues you face as an architect. Analyze trade-offs and effectively document your decisions Make better decisions regarding service granularity Understand the complexities of breaking apart monolithic applications Manage and decouple contracts between services Handle data in a highly distributed architecture Learn patterns to manage workflow and transactions when breaking apart applications\n\n\n*I'm a bot, built by your friendly reddit developers at* /r/ProgrammingPals. *Reply to any comment with /u/BookFinderBot - I'll reply with book information. If I have made a mistake, accept my apology.*",
                  "score": 2,
                  "created_utc": "2026-02-01 10:44:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2xezyq",
              "author": "EviliestBuckle",
              "text": "Okokokok.",
              "score": 1,
              "created_utc": "2026-02-01 06:17:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2xp8jl",
                  "author": "GMKrey",
                  "text": "Btw â€œSoftware Architecture: The Hard Partsâ€ is actually a sequel. Thereâ€™s a fundamentals book you should read first\n\nEdit: Since people are asking, this is the first book https://a.co/d/gyilGiK (Amazon)\n\nThe authors talk about how they basically tried to bucket architectural patterns by difficulty. Anything that they felt was too much for their first book got placed into a separate pile. Later making â€œThe Hard Partsâ€. More detail on their rational are in the first bits of the sequel",
                  "score": 8,
                  "created_utc": "2026-02-01 07:47:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2xls2d",
          "author": "MatchLittle5000",
          "text": "I would advise these books:\n\n1. Clean Architecture.\n2. Designing Data Intensive Applications.\n3. Learning Domain Driven Design (good intro).\n4. And some book describing how to operate on Staff+ roles effectively.",
          "score": 11,
          "created_utc": "2026-02-01 07:16:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ya6q7",
              "author": "MatchLittle5000",
              "text": "Plus these books which are a level higher:\n\n5. Building Microservices: Designing Fine Grained Systems\n\n6. Refactoring by Martin Fowler\n\n7. Patterns of Enterprise Application Architecture\n\n8. Implementing Domain Driven Design \n\n9. Test Driven Development by Example",
              "score": 8,
              "created_utc": "2026-02-01 11:01:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2y4l6m",
              "author": "e__NV__y",
              "text": "Can you name some books for (4)",
              "score": 2,
              "created_utc": "2026-02-01 10:10:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2y5fhy",
                  "author": "MatchLittle5000",
                  "text": "This one: https://staffeng.com/book/",
                  "score": 2,
                  "created_utc": "2026-02-01 10:17:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2y8k2t",
              "author": "httpgo",
              "text": "/u/BookFinderBot",
              "score": 1,
              "created_utc": "2026-02-01 10:46:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2y8ox9",
                  "author": "BookFinderBot",
                  "text": "**Clean Architecture A Craftsman's Guide to Software Structure and Design** by Robert C. Martin\n\n\n>Practical Software Architecture Solutions from the Legendary Robert C. Martin (â€œUncle Bobâ€) By applying universal rules of software architecture, you can dramatically improve developer productivity throughout the life of any software system. Now, building upon the success of his best-selling books Clean Code and The Clean Coder, legendary software craftsman Robert C. Martin (â€œUncle Bobâ€) reveals those rules and helps you apply them. Martinâ€™s Clean Architecture doesnâ€™t merely present options. Drawing on over a half-century of experience in software environments of every imaginable type, Martin tells you what choices to make and why they are critical to your success.\n>\n>As youâ€™ve come to expect from Uncle Bob, this book is packed with direct, no-nonsense solutions for the real challenges youâ€™ll faceâ€“the ones that will make or break your projects. Learn what software architects need to achieveâ€“and core disciplines and practices for achieving it Master essential software design principles for addressing function, component separation, and data management See how programming paradigms impose discipline by restricting what developers can do Understand whatâ€™s critically important and whatâ€™s merely a â€œdetailâ€ Implement optimal, high-level structures for web, database, thick-client, console, and embedded applications Define appropriate boundaries and layers, and organize components and services See why designs and architectures go wrong, and how to prevent (or fix) these failures Clean Architecture is essential reading for every current or aspiring software architect, systems analyst, system designer, and software managerâ€“and for every programmer who must execute someone elseâ€™s designs. Register your product for convenient access to downloads, updates, and/or corrections as they become available.\n\n\n**Designing Data Intensive Applications for Modern Systems Principles, Trade-Offs, and Architectures for Reliable and Scalable Data Platforms** by Zeon Aric\n\n\n>Designing modern data platforms is not about finding perfect solutions-it is about understanding trade-offs. Every architectural decision affects consistency, latency, fault tolerance, complexity, and compliance in ways that are rarely obvious at first glance. Designing Data-Intensive Applications for Modern Systems takes a system-level view of data architecture, guiding readers through the principles that underpin today's distributed databases, streaming platforms, and analytics systems. Building on core concepts, this volume examines how large-scale systems are structured, why they fail, and how they evolve over time.\n>\n>The book explores consistency models, distributed coordination, event-driven architectures, and data governance concerns such as privacy and regulatory compliance. Readers will gain the tools to evaluate architectural options, reason about failure modes, and design platforms that balance performance with operational simplicity. Aimed at senior engineers, technical leads, and system architects, this volume provides the architectural insight needed to design data-intensive systems that are resilient, scalable, and prepared for future growth.\n\n\n**Learning Domain-Driven Design Aligning Software Architecture and Business Strategy** by Vladik Khononov\n\n\n>Today, more than ever, building software is hard. Not only we have to chase ever-changing technological trends, but we also have to grasp business domains that we are building the software for. The latter is often overseen, and it explains why so many projects are doomed to fail. After all, how can you build a solution if you don't understand the problem?\n>\n>Through this book, you will learn the Domain-Driven Design (DDD) methodology which provides a set of core patterns, principles, and practices for analyzing business domains, understanding business strategy, and, most importantly, aligning software design with its business needs. These include Ubiquitous Language, Bounded Contexts, Event Storming, and others. You will see how these practices not only lead to robust implementation of business logic, but also to future-proof software design and architecture. You will also learn the relationship between DDD and other methodologies to ensure that you are able to make architectural decisions that will meet the business needs.\n>\n>The final section puts all of this into practice using a real life story of implementing Domain-Driven Design in a startup company. Reading the book will allow you to use DDD for analyzing business domains, aligning software and business strategies, and making socio-technical design decisions. By the end of this book, you will be able to:-Build a shared understanding of a business domain-Analyze a company's business domain and competitive strategy-Decompose a system into bounded contexts-Coordinate the work of multiple teams working together-Gradually start implementing domain-driven design\n\n\n*I'm a bot, built by your friendly reddit developers at* /r/ProgrammingPals. *Reply to any comment with /u/BookFinderBot - I'll reply with book information. If I have made a mistake, accept my apology.*",
                  "score": 2,
                  "created_utc": "2026-02-01 10:47:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2xj7it",
          "author": "HurricaneCecil",
          "text": "I focused on architecture during my SWE masterâ€™s, hereâ€™s how it was taught:\n\nbasics: read Just Enough Software Architecture by George Fairbanks and then discuss the 4 + 1 View Model of Software Architecture by Philippe Krutchen. It helps if you have a real-life project to look through and talk about.\n\nintermediate: read Fundamentals of Software Architecture by Mark Richards and Neal Ford and Patterns of Enterprise Application Architecture by Martin Fowler.\n\napplication: here we used Enterprise Integration Patterns as a guide and built a semester long project with source control and CI/CD. I thought â€œpracticingâ€ architecture with realistic tooling was super valuable\n\nadvanced: reading research papers on more specific and niche topics. ACM TOSEM and IEEE TSE are decent sources, Distributed Computing from Springer is cool if you want to get very specific and very technical.",
          "score": 9,
          "created_utc": "2026-02-01 06:53:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2y94n6",
              "author": "httpgo",
              "text": "/u/BookFinderBot",
              "score": 1,
              "created_utc": "2026-02-01 10:51:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2y96fr",
                  "author": "BookFinderBot",
                  "text": "**Just Enough Software Architecture A Risk-driven Approach** by George Fairbanks\n\n\n>This book teaches risk-driven architecting and describes a way to do just enough architecture. It avoids the one-size-fits all process tarp pit with advice on how to tune your design effort based on the risks you face. This book seeks to make architecture relevant to all software developers. Developers need to understand how to use constraints as guiderails that ensure desired outcomes.\n>\n>This book focuses on the technical parts of software development and what developers do to ensure the system works-not the job titles or processes. It shows you how to build models and analyze architectures so that you can make principled design tradeoffs. It describes the techniques software designers use to reason about medium to large sized problems and points out where you learn specialized techniques in more detail. The approach in this book embraces drill-down/pop-up behavior by describing models that have various levels of abstraction, from architecture to data structure design.\n\n\n**Fundamentals of Software Architecture An Engineering Approach** by Mark Richards, Neal Ford\n\n\n>Salary surveys worldwide regularly place software architect in the top 10 best jobs, yet no real guide exists to help developers become architects. Until now. This book provides the first comprehensive overview of software architectureâ€™s many aspects. Aspiring and existing architects alike will examine architectural characteristics, architectural patterns, component determination, diagramming and presenting architecture, evolutionary architecture, and many other topics.\n>\n>Mark Richards and Neal Fordâ€”hands-on practitioners who have taught software architecture classes professionally for yearsâ€”focus on architecture principles that apply across all technology stacks. Youâ€™ll explore software architecture in a modern light, taking into account all the innovations of the past decade. This book examines: Architecture patterns: The technical basis for many architectural decisions Components: Identification, coupling, cohesion, partitioning, and granularity Soft skills: Effective team management, meetings, negotiation, presentations, and more Modernity: Engineering practices and operational approaches that have changed radically in the past few years Architecture as an engineering discipline: Repeatable results, metrics, and concrete valuations that add rigor to software architecture\n\n\n**Patterns of Enterprise Application Architecture** by Martin Fowler\n\n\n>Patterns of Enterprise Application Architecture By Martin Fowler\n\n\n**Enterprise Integration Patterns Designing, Building, and Deploying Messaging Solutions** by Gregor Hohpe, Bobby Woolf\n\n\n>Enterprise Integration Patterns provides an invaluable catalog of sixty-five patterns, with real-world solutions that demonstrate the formidable of messaging and help you to design effective messaging solutions for your enterprise. The authors also include examples covering a variety of different integration technologies, such as JMS, MSMQ, TIBCO ActiveEnterprise, Microsoft BizTalk, SOAP, and XSL. A case study describing a bond trading system illustrates the patterns in practice, and the book offers a look at emerging standards, as well as insights into what the future of enterprise integration might hold. This book provides a consistent vocabulary and visual notation framework to describe large-scale integration solutions across many technologies.\n>\n>It also explores in detail the advantages and limitations of asynchronous messaging architectures. The authors present practical advice on designing code that connects an application to a messaging system, and provide extensive information to help you determine when to send a message, how to route it to the proper destination, and how to monitor the health of a messaging system. If you want to know how to manage, monitor, and maintain a messaging system once it is in use, get this book.\n\n\n**Distributed Computing Fundamentals, Simulations, and Advanced Topics** by Hagit Attiya, Jennifer Welch\n\n\n>* Comprehensive introduction to the fundamental results in the mathematical foundations of distributed computing * Accompanied by supporting material, such as lecture notes and solutions for selected exercises * Each chapter ends with bibliographical notes and a set of exercises * Covers the fundamental models, issues and techniques, and features some of the more advanced topics\n\n\n*I'm a bot, built by your friendly reddit developers at* /r/ProgrammingPals. *Reply to any comment with /u/BookFinderBot - I'll reply with book information. If I have made a mistake, accept my apology.*",
                  "score": 3,
                  "created_utc": "2026-02-01 10:52:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2yecdu",
          "author": "IlliterateJedi",
          "text": "If you have a Python background, the single best book I think you'll find is [Architecture Patterns with Python](https://www.cosmicpython.com/book/preface.html).  The book is free, and it has the most beautiful git repository I've ever seen for a book.  Every chapter builds on the last chapter in how the architecture evolves, and they have a branch for each chapter so you can easily switch between branches to see how they changed the code and structure as the book goes along.  It made really examining the code a breeze.  I can't rave enough about this book.",
          "score": 5,
          "created_utc": "2026-02-01 11:37:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2z1ono",
              "author": "bobaduk",
              "text": "Also, if you read it and hate it, you can come here to the software architecture subreddit and argue with the authors!",
              "score": 2,
              "created_utc": "2026-02-01 14:18:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2zrylh",
          "author": "IshanSethi",
          "text": "I'd be honest, just reading books on architecture won't help you much... Once you know the concept, the main work is to apply it... You can try solving problems on www.designheist.com, they have good architecture problemsÂ ",
          "score": 4,
          "created_utc": "2026-02-01 16:29:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30tpf2",
              "author": "EviliestBuckle",
              "text": "I was also thinking the same thing. Thanks for pointing it out",
              "score": 1,
              "created_utc": "2026-02-01 19:20:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2xexh0",
          "author": "Great_Pattern_1988",
          "text": "SEI offers a certificate in Software Architecture.  Three courses that contain an actionable process to creating and evaluating software architectures.  Best course I've ever taken.",
          "score": 3,
          "created_utc": "2026-02-01 06:17:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xf2j6",
              "author": "EviliestBuckle",
              "text": "Can you plz share the respective link?",
              "score": 1,
              "created_utc": "2026-02-01 06:18:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2xfys2",
                  "author": "Great_Pattern_1988",
                  "text": "https://www.sei.cmu.edu/credentials/sei-software-architecture-professional-certificate/",
                  "score": 2,
                  "created_utc": "2026-02-01 06:25:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2xfbyw",
          "author": "sdsdkkk",
          "text": "I read the Architecture of Open Source Application book about 10 years ago to improve my architecture knowledge. But my primary focus at the time was to understand how influential real-life software projects were designed and architected.\nhttps://aosabook.org/en/",
          "score": 3,
          "created_utc": "2026-02-01 06:20:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xg3yf",
              "author": "EviliestBuckle",
              "text": "Same motivation here. Actually here in subcontinent no one get to work on high impact software",
              "score": 1,
              "created_utc": "2026-02-01 06:27:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2z1hoe",
          "author": "bobaduk",
          "text": "My go-to guide for \"how to architect things\" is the practical programmer: https://leanpub.com/practical-software-architecture\n\nThere used to be a website with all that info, but it seems to have been subsumed into a book, but the material was great - high level enough not to be overwhelming, and rooted in practicality.\n\nIn terms of avoiding \"1 year repeated ten times\", my honest advice is to take jobs that scare the crap out of you, and spend as much time as you can in start ups.",
          "score": 3,
          "created_utc": "2026-02-01 14:17:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37912o",
          "author": "SwampApes",
          "text": "Read Designing Data Intensive Applications. \n\nThere are a lot of papers discussing systems.   \nSome examples: Dynamo, Spanner, TAO, Cassandra, Lamport, Paxos, Raft, Borg. \n\nDon't bother with the other suggestions here if the author literally does nothing but write books / consulting.  Clean code / clean architecture, some of the books here written by ThoughtWorks employees are those. ",
          "score": 2,
          "created_utc": "2026-02-02 18:39:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xoa1u",
          "author": "gbrennon",
          "text": "Books",
          "score": 1,
          "created_utc": "2026-02-01 07:39:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o32xeal",
          "author": "garathk",
          "text": "https://developertoarchitect.com/\n\nMark Richards has been mentioned a bunch. I actually took a live course by him about 8 years ago. Found it excellent. He referenced his website here. Lots of very practical bite sized resources.",
          "score": 1,
          "created_utc": "2026-02-02 01:52:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qrpvdc",
      "title": "Most people confuse \"Application Logic\" with \"Business Logic\" in MVC/MVVM. Here is my \"CLI Test\" to define a true Model.",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qrpvdc/most_people_confuse_application_logic_with/",
      "author": "FancyComfort435",
      "created_utc": "2026-01-31 02:25:43",
      "score": 61,
      "num_comments": 48,
      "upvote_ratio": 0.8,
      "text": "Too often, I see projects where the \"Model\" is treated just as a DTO (Data Transfer Object) for the database, and all the logic is shoved into the ViewModel or Controller. This leads to massive, unmaintainable \"God Classes.\"\n\nI believe the root cause is a misunderstanding of the Model's boundary.\n\n**My definition of a Model is simple:**\n\n>**The \"CLI Test\"**Â If I asked you to replace your GUI (React/WPF) with a CLI (Console App) tomorrow:\n\n1. Would your Model class work without modification? ->Â **Pass**Â (It's a true Model)\n2. Would it fail because of dependencies on UI libraries or notification logic? ->Â **Fail**Â (It's polluted)\n\nFor example, in a Calculator app, theÂ `Calculator`Â class should hold the current state (accumulator, current operand) and calculation logic. If you put that state in the ViewModel, you are binding your core logic to the View.\n\nI wrote a short article diving deeper into this with diagrams and examples. I'd love to hear your thoughts on this definition.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qrpvdc/most_people_confuse_application_logic_with/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o2qqrnt",
          "author": "Comfortable_Ask_102",
          "text": "That is one of the concepts Uncle Bob tried to communicate with his \"Clean\\* Architecture\" thing. Each Use Case is meant to be one *action* that can be done in the system, and all Use Cases must be independent of any UI or 3rd party, the sum of all Use Cases is *our* application.\n\nAt one project I literally used that as prefixes (like \\`AddOrderUseCase\\`), it's a decent name for a place that calls all the different upstream services, and has some custom, business-dependent logic or some sort of orchestration.\n\nThe dudes from Domain-Driven Design also give good ideas about how to Model a system.\n\nAnd yeah, 100%, a lot of people confuse \"Model\" with the \"ActiveRecord\" pattern, popularized by frameworks like Laravel, RoR and Django it's my guess.",
          "score": 26,
          "created_utc": "2026-01-31 05:25:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2qxw79",
              "author": "FancyComfort435",
              "text": "**Yes! You nailed it.**\n\nThe confusion absolutely comes from the \"Active Record\" pattern in frameworks like Laravel/Rails/Django. They taught a generation of devs that \"Model = A class that maps to a DB table.\"\n\nBut in true MVC (or Clean Architecture), the Model is the **layer** that handles business rules, not just a row in a database.\n\nI'm glad you brought up Uncle Bob. His \"Use Cases\" are exactly what I consider part of the \"Model\" in the broad senseâ€”the code that must survive even if the UI disappears.\n\n**If you're interested, I uploaded a sample code (C#) on GitHub demonstrating this exact \"CLI vs GUI\" separation. It might be a bit rough, but it proves the point.**",
              "score": 7,
              "created_utc": "2026-01-31 06:22:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rh9f8",
                  "author": "zdzisuaw",
                  "text": "Fancy sharing you github or article?",
                  "score": 5,
                  "created_utc": "2026-01-31 09:19:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2rqat2",
                  "author": "FetaMight",
                  "text": "Al?",
                  "score": 5,
                  "created_utc": "2026-01-31 10:46:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2sl5mi",
                  "author": "aefalcon",
                  "text": "Active Record is actually a Domain Model pattern though.  It's a domain model coupled with some data layer functions.  It does not violate MVC when used correctly, but often the app is either simple CRUD with no real business logic or the developer didn't understand the pattern and it turned into purely Data Model.",
                  "score": 1,
                  "created_utc": "2026-01-31 14:29:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2v4mm0",
              "author": "hcboi232",
              "text": "DHHâ€™s ruby on rails and its consequences",
              "score": 1,
              "created_utc": "2026-01-31 21:56:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o31xk8y",
                  "author": "Comfortable_Ask_102",
                  "text": "I mean, it is a good framework. Lots of people build stuff with it which comes with its downsides.\n\nIt's so popular that people believe it's THE way to make software. Similar to people who believe Java is THE way to make OOP.",
                  "score": 1,
                  "created_utc": "2026-02-01 22:34:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2r33fe",
          "author": "flavius-as",
          "text": "This has been as old as hexagonal architecture. Having a different driving adapter.",
          "score": 9,
          "created_utc": "2026-01-31 07:07:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rk6jy",
              "author": "FancyComfort435",
              "text": "**Exactly. You get it.**\n\nIt is essentially the same concept as swapping a **Driving Adapter** in Hexagonal Architecture.\n\nI just framed it as a \"CLI Test\" for MVC because many developers find \"Hexagonal\" too academic or intimidating. But the core principle is identical: the UI is just a plugin.",
              "score": 0,
              "created_utc": "2026-01-31 09:48:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rkbov",
                  "author": "flavius-as",
                  "text": "Hexagonal is neither academic nor complicated.\n\nThe official \"book\" on it is... a leaflet. It's that simple: dependency inversion applied architecturally.",
                  "score": 8,
                  "created_utc": "2026-01-31 09:49:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2qp8ma",
          "author": "aefalcon",
          "text": "Yep.  I've used \"test harness\" in a similar argument.",
          "score": 7,
          "created_utc": "2026-01-31 05:13:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2qq4wl",
              "author": "FancyComfort435",
              "text": "**Exactly! The \"CLI\" is basically just a primitive test harness.**\n\nIf your model can't run in a simple harness (like a console app or unit test) without dragging in the entire UI framework, it's not really a Model. I just use the \"CLI\" metaphor because it's easier to visualize for people who are stuck in the \"Model = DTO\" mindset.",
              "score": -1,
              "created_utc": "2026-01-31 05:20:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2qmn43",
          "author": "theBosworth",
          "text": "Damn, just straight up, uncurated AI slop.",
          "score": 12,
          "created_utc": "2026-01-31 04:54:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2qo51a",
              "author": "FancyComfort435",
              "text": "English is not my first language, so I used AI to translate and format my thoughts.\n\nActually, the initial AI output was too verbose, so I wrote the core draft from scratch and just used AI to handle the translation. If it still looks \"too clean\" or \"excessive\" to you, that might be a fair critique, and I can edit it down.\n\nBut I want to ask you: Does your comment mean you think the *content itself* lacks substance? Or do you just hate AI?\n\nThe \"CLI Test\" concept comes from my 15+ years of software architecture experience, not an LLM hallucination. If you have actual feedback on the architecture itself, I'm all ears.\n\nP.S. Yes, I used Gemini to write this reply too.",
              "score": 3,
              "created_utc": "2026-01-31 05:05:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rqpk9",
                  "author": "FetaMight",
                  "text": "The CLI Test idea is fine.Â \n\n\nWhat trips me up is the sycophantic writing style typical with LLMs.Â  Real people don't talk that way so there's an uncanny valley effect happening when I read your comments.Â \n\n\nI don't think there's any harm in using AI to help you translate your thoughts, but maybe include that as a disclaimer?",
                  "score": 3,
                  "created_utc": "2026-01-31 10:50:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2tfrrm",
                  "author": "no_onions_pls_ty",
                  "text": "Its slop because its just not true.  Not many developers in the wild are making this \"mistake\".  This concept is as decades old.  There is nothing of interest in this post, just standard programming concepts with some added marketing flair trying to communicate an issue having significant breadth.\n\nIt might be really novel for a freshman in college.  But no.  Its just slop.  \n\nIts like going to a car mechanic forum and telling all thr master mechanics that making sure the oil and wiper fluid don't get mixed up is somehow enlightening",
                  "score": 2,
                  "created_utc": "2026-01-31 17:02:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2qv18b",
                  "author": "theBosworth",
                  "text": "Itâ€™s just literally copy-pasted straight out of the client youâ€™re using without so much as formatting changes so it sticks out.\n\nI think seeing a hallucination in text which took the form of stating, in bold that a definition would be supplied, then skipping to test conditions outlining what should have been defined undermines the context youâ€™re replying with. It seems like a reply from an AI, not a mere translation.\n\nI donâ€™t even hate AI. Youâ€™ve just beat around the bush of a definition that I could agree with, but lacks substance at its core. The CLI test is a fundamental to this, but at a scalar level, this a trivial distinction due to other common classesâ€™ responsibilitiesâ€”request providers and handlers come to mind here. Your definition of a model is so loose that it includes the DAL.\n\nIt sounds more like youâ€™ve seen a lot of messy student projects without day0 design discussions if youâ€™re mentioning so-called â€œgod classesâ€.",
                  "score": 3,
                  "created_utc": "2026-01-31 05:58:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2r25ap",
              "author": "epegar",
              "text": "To me it looks good. \nI mean if you manage to identify it as Ai due to the content not being good enough, then I think it's fair. But if you see a rich format being used, then I think it's a good use of Ai.",
              "score": 0,
              "created_utc": "2026-01-31 06:58:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2q7s42",
          "author": "LoveThemMegaSeeds",
          "text": "Seems like a weird arbitrary way to define a model.",
          "score": 1,
          "created_utc": "2026-01-31 03:15:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2qpsfd",
              "author": "robhanz",
              "text": "\"Can this work with a different frontend\" is a pretty good and common way to handle that.  And a CLI is the easiest one to make.",
              "score": 14,
              "created_utc": "2026-01-31 05:17:49",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2qel35",
              "author": "FancyComfort435",
              "text": "Interesting take. Why do you find it arbitrary?\n\nTo me, it's not arbitrary at allâ€”it's a specific stress test for **\"Separation of Concerns.\"** The \"CLI\" is just a proxy for **\"Zero UI Dependency.\"**\n\nIf your business logic depends on a specific UI framework (like expecting a specific View structure), it becomes impossible to test in isolation or reuse. The CLI test is just the simplest way to prove your logic is decoupled from the presentation layer.\n\nIn my view, the Model represents the **\"Business Rules\"** that should exist regardless of whether the app is Web, Mobile, or CLI. If the Model fails to run on a CLI, it usually means it's polluted with UI logic (like routing, notifications, etc.).\n\n**How do you define a Model's boundary in your projects?** Do you prefer keeping logic in the ViewModel/Controller?",
              "score": 4,
              "created_utc": "2026-01-31 03:59:22",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2qrli5",
              "author": "TheRealStepBot",
              "text": "Not as weird as making a stateful calculator",
              "score": -4,
              "created_utc": "2026-01-31 05:31:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2qxg2g",
                  "author": "FancyComfort435",
                  "text": "**I chose the \"Calculator\" example specifically because it is the simplest form of a State Machine.**\n\nA physical calculator is inherently stateful. It has registers, an accumulator, and pending operations. If the Model doesn't hold that state, the ViewModel has to. And that's exactly what I'm arguing againstâ€”leaking domain state into the presentation layer.\n\nDo you prefer managing `PendingOperation` or `Accumulator` in your ViewModels?",
                  "score": 2,
                  "created_utc": "2026-01-31 06:18:30",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o2u6aq2",
                  "author": "WhenSummerIsGone",
                  "text": "how do you calculate without state?",
                  "score": 1,
                  "created_utc": "2026-01-31 19:08:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2sctip",
          "author": "mexicocitibluez",
          "text": "This is called DDD.",
          "score": 1,
          "created_utc": "2026-01-31 13:41:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2twj31",
          "author": "Classic_Chemical_237",
          "text": "Itâ€™s not that deep. MVC is just super thin basic layer when you donâ€™t want to over engineer. MVVM focuses on objects, VIPER focuses on responsibilities. A proper app with complicated logic should be able to run interactor, entity (model) and VM in CLI.\n\nBetter yet, use React Native. You will naturally separate business logic into a library which can be shared by both web and app with all the unit tests and integration tests. Apps will only have presentation logic",
          "score": 1,
          "created_utc": "2026-01-31 18:22:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2v5ews",
          "author": "hcboi232",
          "text": "why are we using MVC for the backend/usecases? The thick client is long gone and DHH thought it would be nice to butcher that term to be used for a service based architecture. I wouldnâ€™t structure the frontend around Hexagonal because I would be ignoring different control structures relevant to the UI.",
          "score": 1,
          "created_utc": "2026-01-31 22:00:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2rtktr",
          "author": "BleLLL",
          "text": "vertical slice architecture has entered the chat",
          "score": 0,
          "created_utc": "2026-01-31 11:16:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ru2z8",
              "author": "FancyComfort435",
              "text": "Vertical Slice Architecture has left the chat.",
              "score": 1,
              "created_utc": "2026-01-31 11:20:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qr44dn",
      "title": "How Replacing Developers With AI is Going Horribly Wrong",
      "subreddit": "softwarearchitecture",
      "url": "https://youtu.be/ts0nH_pSAdM?si=Kn2m9MqmWmdL6739",
      "author": "BlazorPlate",
      "created_utc": "2026-01-30 12:29:05",
      "score": 56,
      "num_comments": 4,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qr44dn/how_replacing_developers_with_ai_is_going/",
      "domain": "youtu.be",
      "is_self": false,
      "comments": [
        {
          "id": "o2lkefu",
          "author": "commanderdgr8",
          "text": "I don't think this should be labeled as going horribly wrong - relying on a technology you don't understand fully and giving it free-hand was amatuerish and the company who gave ai free-hand suffered. but that gave us the learnings, ofcourse companies might be hiring developers again after doing mass layoff, but this time there would be more automation, not less. Kind of the second phase of full ai automation started.",
          "score": 3,
          "created_utc": "2026-01-30 13:25:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ngjld",
          "author": "Lord_Farkwad",
          "text": "This video is nonsense",
          "score": 3,
          "created_utc": "2026-01-30 18:42:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3coz7w",
          "author": "Constant_Physics8504",
          "text": "Itâ€™s actually going well at my job. We separated monolith legacy teams into product based teams, and used the existing codebase with SME input to train the AI. \n\nEven new devs now are cranking code out and testing it in a couple hours",
          "score": 1,
          "created_utc": "2026-02-03 15:06:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2mpw9m",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 0,
          "created_utc": "2026-01-30 16:44:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nlca9",
              "author": "CthuluSurvivor",
              "text": "You arenâ€™t making a distinction, but instead are attempting to reframe the context in a different light. Imagine you have 3 developers all doing the same job. The company starts using LLM coding assistants and the workload of these 3 developers is now replaced by 1 developer + 1 coding agent. Two developers are fired and one remains. The one did not simply get more efficient. Instead, the role of that one developer shifted to a developer + code agent role instead of simply a developer role. At least two developers have been replaced by this new role. One developer was laterally shifted into a role that now includes the coding agent. Someone could say that three developer roles were, in fact, replaced - as the old roles no longer exist due to the new. \n\nWhile 3 developer roles were replaced, only 2 developers were fired. The distinction in this case is between developer roles and developers. Either way, with roles or people, the job of two people were taken on by one + coding agent and this is leading to higher tech debt.",
              "score": 1,
              "created_utc": "2026-01-30 19:02:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qv07p2",
      "title": "At what scale does \"just use postgres\" stop being good architecture advice?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qv07p2/at_what_scale_does_just_use_postgres_stop_being/",
      "author": "Designer-Jacket-5111",
      "created_utc": "2026-02-03 18:38:02",
      "score": 42,
      "num_comments": 27,
      "upvote_ratio": 0.92,
      "text": "Every architecture discussion I see ends with someone saying \"just use postgres\" and honestly theyre usually right. Postgres handles way more than people think, JSON columns, full text search, pub/sub, time series data, you name it.\n\nBut there has to be a breaking point where adding more postgres features becomes worse than using purpose-built tools. When does that happen? 10k requests per second? 1 million records? 100 concurrent writers?\n\nIve seen companies scale to billions of records on postgres and Ive seen companies break at 10 million. Ive seen people using postgres as a message queue successfully and Ive seen it be a disaster.\n\nWhat determines when specialized tools become necessary? Is it always just \"when postgres becomes the bottleneck\" or are there other architectural reasons?",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qv07p2/at_what_scale_does_just_use_postgres_stop_being/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o3dyu5h",
          "author": "Sea_Weather5428",
          "text": "the breaking point for me is when the postgres-specific workarounds start taking more time than learning a purpose-built tool would, like when your jsonb queries start needing 47 indexes",
          "score": 49,
          "created_utc": "2026-02-03 18:39:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3e9zq8",
              "author": "sfboots",
              "text": "We stay away from indexes on the Jsonb content and copy a few items to regular columns for indexing",
              "score": 20,
              "created_utc": "2026-02-03 19:30:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3e15qs",
              "author": "ilya47",
              "text": "And when you learn about TOASTs due to jsonb.",
              "score": 13,
              "created_utc": "2026-02-03 18:49:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3gnuke",
                  "author": "clearing_",
                  "text": "giving me ptsd to when we hit the OID limit while i was at a concert",
                  "score": 1,
                  "created_utc": "2026-02-04 02:51:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3dzqtl",
          "author": "ClideLennon",
          "text": "You can shard postgres, so done right, it can probably scale indefinitely.  Now, if your data model is gross and you need a thousand indexes, maybe not.",
          "score": 28,
          "created_utc": "2026-02-03 18:43:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3epfd9",
              "author": "InfluxCole",
              "text": "I think there's also some cost efficiency to worry about as scale goes up. Once you're running up huge monthly bills, it's not that you necessarily couldn't keep going with Postgres, but you could probably save some money by moving to something more tailor-made for the characteristics of your workload. When you reach that, \"this is getting expensive, maybe something more specific would give us the performance we need for cheaper,\" point still heavily depends on your company, budget, team size, etc.",
              "score": 6,
              "created_utc": "2026-02-03 20:43:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3e3pga",
          "author": "who_am_i_to_say_so",
          "text": "There is no set number. Sometimes 1 million rows it will start performing like a dog- sometimes itâ€™s 20 million rows. \n\nBut a general indicator is if you hit your max connections regularly even with upsizing and pooling (scaling vertically). Then you look into caching, perhaps- or the more expensive option of scaling horizontally.",
          "score": 12,
          "created_utc": "2026-02-03 19:01:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3e88dw",
              "author": "sfboots",
              "text": "Max connections can be misleading if they are not using pgbouncer",
              "score": 6,
              "created_utc": "2026-02-03 19:22:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3eyqx7",
              "author": "Typicalusrname",
              "text": "If Postgres performs like a dog with a million records the data model is shit",
              "score": 3,
              "created_utc": "2026-02-03 21:26:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ezlti",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": -2,
                  "created_utc": "2026-02-03 21:30:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3f143t",
              "author": "Apart-Entertainer-25",
              "text": "Have you tried not running it on a toaster? :)",
              "score": 1,
              "created_utc": "2026-02-03 21:37:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3f24zk",
                  "author": "who_am_i_to_say_so",
                  "text": "Relatedly there's this: [https://www.crunchydata.com/blog/postgres-toast-the-greatest-thing-since-sliced-bread](https://www.crunchydata.com/blog/postgres-toast-the-greatest-thing-since-sliced-bread)",
                  "score": 3,
                  "created_utc": "2026-02-03 21:42:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3dysgx",
          "author": "Select-Print-9506",
          "text": "its almost never about raw scale, its about operational complexity and team expertise, postgres can handle way more than most companies need if you tune it properly",
          "score": 21,
          "created_utc": "2026-02-03 18:39:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e9ai4",
          "author": "sfboots",
          "text": "The limit depends heavily on workload and total IO needs assuming correct code and indexes\n\nAlso, some companies stay with Postgres and just use extensions like timescale or move some functions to a different database. \n\nMy company has 3 tables with more than a billion total rows and performance is adequate.  We do partition by time ranges since most use is the last year.",
          "score": 4,
          "created_utc": "2026-02-03 19:27:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eftyi",
          "author": "External_Mushroom115",
          "text": "When your domain needs to scale writes  rather than reads.",
          "score": 4,
          "created_utc": "2026-02-03 19:58:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eou27",
          "author": "polotek",
          "text": "We had a ruby on rails system with postgres that scaled to 10 billion rows in some tables and still maintained high request throughout. The problem isn't scaling postgres. It's not easy, but it can go way further than most people will ever need. It depends on the complexity of what you're doing and your level of expertise with postgres.\n\nWhat comes after \"just use postgres\" is \"hire some postgres consultants to help you out and keep going\". In general you should only need to reach for a specialized datastore for services that have very specific data access requirements. And still it should be after you tried postgres first.",
          "score": 5,
          "created_utc": "2026-02-03 20:40:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dyvm0",
          "author": "Select-Print-9506",
          "text": "same applies to api management honestly, you can build everything custom on top of nginx or envoy but at some point using something like gravitee or kong saves you from reinventing wheels that dont need reinventing",
          "score": 7,
          "created_utc": "2026-02-03 18:39:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ebfp8",
          "author": "awol-owl",
          "text": "Never, yet at work this week weâ€™re moving to Elasticsearch as our prototype showed it to be a search friendly service. I believe itâ€™ll use more ram to run the new cluster, although Iâ€™m hoping the developer experience will be worth it. Iâ€™m not convinced yet.",
          "score": 3,
          "created_utc": "2026-02-03 19:37:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e3q9q",
          "author": "pgEdge_Postgres",
          "text": "Oftentimes it's not even the specialized tools that you need, just a tuned configuration and some good insights into your stack! Metrics go a long way towards predicting failures or reacting quickly when they do happen; take the lessons learned and turn them into actual architectural changes, and you can iterate up to those instances of billions of records.\n\nRelated interesting article: [https://openai.com/index/scaling-postgresql/](https://openai.com/index/scaling-postgresql/) if you missed it, OpenAI scaled PostgreSQL to power 800 million ChatGPT users; it powers both ChatGPT and OpenAI's API.",
          "score": 4,
          "created_utc": "2026-02-03 19:01:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3f4792",
          "author": "swithek",
          "text": "I once inherited a system that used postgres to store massive json blobs, with a bit of metadata kept in separate indexed columns for filtering. The production database contained nearly a petabyte of data (hundreds of millions of rows) and the queries were painfully slow so I think itâ€™s fair to say postgres wasnâ€™t exactly an ideal choice here",
          "score": 2,
          "created_utc": "2026-02-03 21:51:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e888l",
          "author": "mountainlifa",
          "text": "I've always wondered this. And when do folks introduce key pair database systems like dynamo into their architecture?Â ",
          "score": 1,
          "created_utc": "2026-02-03 19:22:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eivyi",
          "author": "WilliamBarnhill",
          "text": "If you aren't doing rapid prototyping, I'd argue at any scale. You need to be able to articulate to stakeholders what your technology selection candidates were, what the tradeoffs were between them, your rationale for choosing the technology you did, and potential future risks as a result. Sometimes time-to-market is the overwhelming driver, but even then you need to be able to answer 'Why will using Postgres get us there faster, and what problems might we face down the road?'.",
          "score": 1,
          "created_utc": "2026-02-03 20:12:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eqjob",
          "author": "truechange",
          "text": "When vertical scaling can be solved by offloaded cached data.",
          "score": 1,
          "created_utc": "2026-02-03 20:48:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3exq6q",
          "author": "lambdasintheoutfield",
          "text": "You can do vertical or horizontal sharding which allows you to scale the database extremely effectively.\n\nHorizontal sharding is partitioning a table into more tables with the same exact schema but fewer rows and then an index to track the partitioning/shards. If your queries require large scans of values, this works well and there are numerous partitioning schemes to pick.\n\nVertical sharding is where you partition on columns. If you are specifically querying for data in column subsets, you could just have dedicated tables for those.\n\nItâ€™s likely both would be helpful, and both reduce storage space. Be careful of your primary keys and indices but this is enormously effective when done right. \n\nIt isnâ€™t too difficult to roll your own postgres orchestrator across multiple nodes. \n\nAll that said, anytime you go distributed, you have to consider HA and fault tolerance. If you are querying a subset of rows on a node that goes down you obviously wonâ€™t be getting the data unless you replicate it.\n\nIf you know your access patterns, the critical and/or most frequently accessed data can use a higher replication factor and if a node goes down just route to the replicas. The architecture of your nodes can be a tree structure where each node is a shard and the leaf nodes are the replicas. Use this to inform the load balancer and query routing.",
          "score": 1,
          "created_utc": "2026-02-03 21:21:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gb452",
          "author": "Wiszcz",
          "text": "When cost of working around it's cons is higher than restructuring project.",
          "score": 1,
          "created_utc": "2026-02-04 01:39:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr6byf",
      "title": "Configuration behaves like code at runtime â€” but we donâ€™t design it like code. Why?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qr6byf/configuration_behaves_like_code_at_runtime_but_we/",
      "author": "FreePipe4239",
      "created_utc": "2026-01-30 14:04:30",
      "score": 22,
      "num_comments": 23,
      "upvote_ratio": 0.89,
      "text": "In most modern systems, configuration is:\n- parsed\n- validated (sometimes)\n- interpreted\n- and directly affects runtime behavior\n\nYet compared to application code, config usually has:\n- weaker type guarantees\n- fewer correctness checks\n- limited tooling\n- poor failure visibility\n\nThis seems to be a recurring root cause in incident postmortems.\n\nFrom a software architecture perspective:\nWhy do we still treat configuration as second-class compared to code?\nIs this a tooling gap, a design tradeoff, or something else?\n",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qr6byf/configuration_behaves_like_code_at_runtime_but_we/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o2lv7y3",
          "author": "PabloZissou",
          "text": "Serious applications would validate the validity of its config and exit if that validation fails. I don't think this is a general problem but project specific.",
          "score": 14,
          "created_utc": "2026-01-30 14:22:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mgws5",
              "author": "Jedkea",
              "text": "Exiting does not solve the problem though in and of itself. If you rollout a change to a bunch of clusters and they all fail to start, well now the whole thing is down.\n\nAlso the config might be valid in one place, but invalid in another. Things like incorrect network addresses are an example.",
              "score": 3,
              "created_utc": "2026-01-30 16:04:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2naxsq",
                  "author": "Pto2",
                  "text": "Rollback then? Code could also fail.",
                  "score": 3,
                  "created_utc": "2026-01-30 18:17:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o31ucxp",
                  "author": "ncmentis",
                  "text": "You need canary deploys. Exiting plus staged rollouts allows you to abort before a significant chunk of resources are devoted to a failing service. And you can then rollback.",
                  "score": 1,
                  "created_utc": "2026-02-01 22:18:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2rphbr",
              "author": "ryan_the_dev",
              "text": "Every single application I work on, this is a requirement. Configuration is validated on startup and application fails if invalid.",
              "score": 2,
              "created_utc": "2026-01-31 10:38:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2wrwtk",
                  "author": "hxtk3",
                  "text": "Yes but there's a valid point that if you update a config map, every pod sees the changes more or less instantly (although they probably don't act on the changes until the process restarts), which is very different from how you'd roll out a code change (update the container image target, which would trigger a rolling replacement of the deployment with the new image).\n\nConfiguration changes are (often by design, as a feature) synchronized replacements of resources rather than gradual rollouts. Most of the big tech outages from the 2010s that you heard about if you don't work at the company that had them are caused by bad configuration updates, and we're not categorically done with them; one of Cloudflare's big outages last year was identified as an argument for them to universally implement gradual configuration rollouts because that would have averted it.",
                  "score": 2,
                  "created_utc": "2026-02-01 03:34:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2o44hx",
              "author": "gaelfr38",
              "text": "Same feeling here. This doesn't sound like a general problem to me at all.",
              "score": 1,
              "created_utc": "2026-01-30 20:29:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2lskv2",
          "author": "FreePipe4239",
          "text": "One thing I keep noticing is that config often gets validated only syntactically,\nnot semantically â€” the system accepts it, but behaves very differently than intended.\n\nCurious if people here have seen languages, frameworks, or tooling\nthat actually close this gap effectively.",
          "score": 7,
          "created_utc": "2026-01-30 14:09:10",
          "is_submitter": true,
          "replies": [
            {
              "id": "o2ltbt1",
              "author": "flavius-as",
              "text": "Of course, I've seen this compiled and validated semantically, it's called a programming language.\n\nInstead of writing it in yaml or whatever other error prone semi-formal language, write it in a strongly typed language.",
              "score": 5,
              "created_utc": "2026-01-30 14:12:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ol7ft",
          "author": "DoubleAway6573",
          "text": "https://mikehadlow.blogspot.com/2012/05/configuration-complexity-clock.html\n\n\nYou remind me this. You are like 4 or 5 o clock.",
          "score": 2,
          "created_utc": "2026-01-30 21:50:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lwono",
          "author": "systemic-engineer",
          "text": "I always really, really liked dhall.  \nAnd never had the opportunity to use it in anger.\n\nhttps://dhall-lang.org/",
          "score": 3,
          "created_utc": "2026-01-30 14:29:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m1yo6",
          "author": "ewoolly271",
          "text": "Great question. At multiple jobs, Iâ€™ve been told the business users need to have direct control over the application. But then, we get a ton of problems because they donâ€™t fully understand how the config changes interact with the application. \n\nSo you have to trust the business users to communicate their changes, test them, time them with releases, etc\n\nHow is that any better than, say, working with them to update a YML or JSON file with CI/CD? Itâ€™s not. Doesnâ€™t save any time or energy. Itâ€™s just engineering leaders being too weak to tell the business leaders itâ€™s a bad idea",
          "score": 1,
          "created_utc": "2026-01-30 14:55:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2meunm",
          "author": "violentlymickey",
          "text": "One consideration is that config can be changed easily whereas code may need to be redeployed or rebuilt. I think you should always reasonably validate your config though, and many libraries exist to do that.",
          "score": 1,
          "created_utc": "2026-01-30 15:55:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2mxy0k",
          "author": "Physical-Compote4594",
          "text": "One of the (many) awesome things about Lisp is that configuration files are just code, because in Lisp code and data have the same representation.\n\nYou often write Lisp macros to define a DSL for configurations, and that's where you add type guarantees and correctness checks, which can be done with the full power of the language.",
          "score": 1,
          "created_utc": "2026-01-30 17:20:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2o47vh",
          "author": "supercargo",
          "text": "Configuration is a double edged sword.  It increases (runtime) flexibility at the expense of complexity. I donâ€™t think there is any special reason why it doesnâ€™t get treated more rigorously, just the usual: not enough time, not a priority.  Like most tech debt, itâ€™s either strategically appropriate or the risks werenâ€™t understood.\n\nEngineering effort spent on config validators has always been worthwhile in my experience.  If your post mortem root cause is a bad config, the correct next question to ask is â€œwhat can we do to reject this config earlier in the processâ€. Do this a few times and some patterns and best practices should emerge that you can use proactively. Clear error messages are also critical, donâ€™t just reject a config, indicate what is wrong, why itâ€™s wrong, and where in the file.",
          "score": 1,
          "created_utc": "2026-01-30 20:30:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y4008",
          "author": "FreePipe4239",
          "text": "What Iâ€™m taking away from this thread is that the issue isnâ€™t\n\nâ€œconfig vs codeâ€, but that config changes have very different\n\nrollout semantics and blast radius than code changes.\n\n\n\nEven with validation, the difficulty seems to be:\n\n\\- understanding the \\*effect\\* of a config change\n\n\\- across environments\n\n\\- before itâ€™s applied everywhere\n\n\n\nThat gap feels under-tooled today.",
          "score": 1,
          "created_utc": "2026-02-01 10:04:43",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o2lwbbi",
          "author": "ukaeh",
          "text": "Iâ€™d say look into protobufs for type guarantees and checks/tooling etc. As a good starting point.\n\nAnother aspect is indeed a lack of design - configs get (re)used across layers/stack likely when they mean different things semantically and that is 100% a trade off for simplicity whether or not thatâ€™s intentional. For example, configuration (and/or parts of) should never be in limbo but often systems end up with things like â€˜oh these fields arenâ€™t setup yetâ€™ which is mostly a design issue.",
          "score": 1,
          "created_utc": "2026-01-30 14:28:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lwrnq",
          "author": "Isogash",
          "text": "It really depends on how you view config.\n\nIf you view the system as a whole and are only concerned with delivery of a specific business behaviour e.g. in a bespoke enterprise system, then \"config\" is just another part of delivering that behaviour, and so its distinction from code is not that clear.\n\nInstead, if you view the system as being something configurable, and the config as specific to a particular deployment or use case e.g. for different environments, products or users, then the distinction is quite clear: your system should accept all valid combinations of configuration, and whether or not the config is correct for the end user is something *they* should be testing.\n\nEither way, I don't disagree that file-driven config could benefit from some of the features of programming languages, and that users should have tests that their configuration is correct for their intended use case.",
          "score": 1,
          "created_utc": "2026-01-30 14:30:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lvb56",
          "author": "jhartikainen",
          "text": "There's lots of places which handle configs as code. JS/TS projects is one, but I guess those don't really give you a lot of guarantees about anything. I vaguely recall seeing some Haskell projects using regular Haskell code as configs as well, where you can get fairly strong guarantees of the correctness.\n\nI guess the biggest issue is that configs usually are intended to be something you can modify without needing to recompile the whole project. Making them code often kinda gets in the way of that.",
          "score": 1,
          "created_utc": "2026-01-30 14:23:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m3ciu",
          "author": "Adorable-Fault-5116",
          "text": "This is because XML was seen as uncool, and JSON / YAML took off as configuration because how nice it was for a developer to read was prioritised over correctness.\n\nThese days I think the way to solve this, since we aren't going back, is to just make configuration code. Then you can a) not annoy developers will scary ugly text, b) have strong typing etc.",
          "score": 1,
          "created_utc": "2026-01-30 15:02:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rkzjh",
              "author": "One_Elephant_8917",
              "text": "Exactly xml had schema that validates it, compared to json",
              "score": 1,
              "created_utc": "2026-01-31 09:55:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2q6qft",
          "author": "klimaheizung",
          "text": "We do. Just use the right programming language, that's all there is to it.",
          "score": 0,
          "created_utc": "2026-01-31 03:09:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qp2ifs",
      "title": "How do you automate your architecture inner loop?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qp2ifs/how_do_you_automate_your_architecture_inner_loop/",
      "author": "vmgolubev",
      "created_utc": "2026-01-28 05:23:50",
      "score": 18,
      "num_comments": 13,
      "upvote_ratio": 0.92,
      "text": "Hi!\nRecently I realized that my current approach with ADRs and diagrams in drawio sucks:)\nDrawio is great at the beginning, but after some time it becomes hard to manage with updates in all of the c4 diagrams that was created.\nI want to have the same experience as developer - think, write, commit! Any advice on tools that might help me? ",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qp2ifs/how_do_you_automate_your_architecture_inner_loop/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o27jxge",
          "author": "ch1pch4p",
          "text": "Without you defining what truly is \"inner loop architecture\", I'll assume you mean \"you architechting on your own, regardless if it's been shared or not.\" \n\nYou can take a crack at mermaid/puml. Text based diagramming. What you lose (or just becomes a bit hard) on the placement of the diagram you gain in text based work: proper source control, quick interations, etc.\n\nMermaid is also rendered in github so that's helpful for devs, not quite for business. You could make a github action, though, to bundle and export your diagrams to pdf or use your doc repo (I'm thinking Confluence) API to update pages. I know draw io can take in mermaid docs as import, so you may need to get creative on how the rubber meets the road on that one.\n\nI use dendron for all my notes. Dead repo now, but still useful in current form. Use schemas to organize your thoughts, and use the lookup to find what you were working on faster.\n\nI'm a text based guy at heart - I figure if I can describe what I know, well, in words, pictures can augment the information.\n\nI say all this, typing on my phone, with highly questionable grammar haha",
          "score": 3,
          "created_utc": "2026-01-28 13:21:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2argg6",
              "author": "HandsOnArch",
              "text": "Architecture as Code (Structurizr etc) gives you a dev-like workflow, but youâ€™ll still need draw.io for many stakeholders.\nPersonally, I find the update effort in draw.io negligible, since architecture changes are usually rare and very deliberate.",
              "score": 2,
              "created_utc": "2026-01-28 22:02:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o27tvae",
              "author": "never-starting-over",
              "text": "Seconded on mermaid.\n\nThey even have a (kinda janky) visual editor at https://mermaid.live/play\n\nI also use LLMs to help mr write documentation and I think diagrams as text really help them understand what I'm conveying.\n\nWith that said, I wanted so hard for PlantUML to work, but the extra setup required and no native integration with GitHub just makes it a shoehorn choice for the kind of businesses I work with. How I wish it were as batteries included and supported as mermaid is on GitHub and Notion.",
              "score": 1,
              "created_utc": "2026-01-28 14:14:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2cvnzo",
                  "author": "[deleted]",
                  "text": "[removed]",
                  "score": 1,
                  "created_utc": "2026-01-29 04:57:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o27wa48",
                  "author": "ch1pch4p",
                  "text": "LLM are a force multiplier, for sure. \n\nI'd recommend using a local plug-in in vscode. I hate dumping ideas into the internet... You lose control of them.\n\nFor puml, try the jetty server with docker. It really is a breeze to set up if you haven't tried. But.. Yea no github rendering, so if that's your jam, then skip it.",
                  "score": -1,
                  "created_utc": "2026-01-28 14:26:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3f5kfd",
          "author": "3sc2002",
          "text": "This may get deleted, but I hope this helps.  I'm working on a tool that does exactly that.  Its a container that runs in your CI/CD platform of choice. Uses the native ASTs (across 11 supported languages) to build an interactive graph (and then some) of your CURRENT architecture.  The output is a json object that gets committed back to git, so your \"most recent\" graph is what just went out to prod.  There is a pretty sexy UI on it too if I must say so myself.\n\nI'm not sure if I can post a link to the page on my site that covers it (from a high level, its not \"released\" yet).  But feel free to PM me if you are interested and we can discuss off line.\n\n(edit)  \nand it outputs PUML too if you like that.",
          "score": 1,
          "created_utc": "2026-02-03 21:58:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o28ji2h",
          "author": "SolarNachoes",
          "text": "Likec4 (use AI to spin up a vite app)\n\nD4\n\nMermaid\n\nPlantUML\n\nI use AI now exclusively to edit said documents. Either from scratch or from an exiting app.",
          "score": 0,
          "created_utc": "2026-01-28 16:13:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qrfrmp",
      "title": "What architecture as code tools you are using, besides AI?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qrfrmp/what_architecture_as_code_tools_you_are_using/",
      "author": "vmgolubev",
      "created_utc": "2026-01-30 19:42:38",
      "score": 13,
      "num_comments": 7,
      "upvote_ratio": 0.93,
      "text": "How do you understand AaC approach? Should you get all artifacts automatically or just some?\nSpecifics:\nDiagrams as code - but which one? Structurizr, D2 or anything else?\nAny docs gen software, that will generate your artifacts automatically?\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qrfrmp/what_architecture_as_code_tools_you_are_using/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o2qabtw",
          "author": "avinds",
          "text": "likec4",
          "score": 2,
          "created_utc": "2026-01-31 03:32:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2o08nt",
          "author": "themessymiddle",
          "text": "Iâ€™ve been working on arch docs that auto-update, are accessible via MCP, and are beautiful to navigate: https://gjalla.io if you want to take a look! I struggled with some other tools that didnâ€™t auto-update, and even docs generated by Claude Code were too high level. So far the gjalla generated arch artifacts reduce token use, turns, and time of the agents working on code, and I always know the docs Iâ€™m looking at are up to date",
          "score": 3,
          "created_utc": "2026-01-30 20:11:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2r1u7z",
              "author": "chipstastegood",
              "text": "your site is slow to load for me on mobile and doesnâ€™t explain what the product actually does",
              "score": 2,
              "created_utc": "2026-01-31 06:56:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2r63so",
                  "author": "themessymiddle",
                  "text": "Thanks for the feedback, live architecture docs and enforcement of architecture rules",
                  "score": 1,
                  "created_utc": "2026-01-31 07:34:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2rqw6o",
          "author": "bills2go",
          "text": "Can you try [revibe.codes](https://www.revibe.codes)? I'm building it. It generates architecture and other flow diagrams in mermaid format, from the codebase.",
          "score": 1,
          "created_utc": "2026-01-31 10:51:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xg7rz",
          "author": "MatchLittle5000",
          "text": "I recently built a related tool called pacta: https://github.com/pacta-dev/pacta-cli\n\nIt helps you to treat architecture as an artifact instead of multiple diagrams stored in confluence that are slowly becoming outdated. \n\nYou describe architecture in special file, add rules, and validate the current code. But the main feature is the ability to keep a history of architecture evolution and observe different trends throughout the time. For example, you can get charts catching a change of the dependency number or coupling in your system and understand when and why the drift occurred. There is also a GitHub action, adding a summary of the architecture change for each PR.\n\nI will add support for diagrams in the future too.",
          "score": 1,
          "created_utc": "2026-02-01 06:28:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqsg3o",
      "title": "Feeling pigeonholed as an â€œIntegration Engineerâ€, how to reposition into real engineering roles without starting from scratch?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qqsg3o/feeling_pigeonholed_as_an_integration_engineer/",
      "author": "BinariesGoalls",
      "created_utc": "2026-01-30 02:07:05",
      "score": 12,
      "num_comments": 9,
      "upvote_ratio": 1.0,
      "text": "Hey folks,\n\nI could really use some perspective from more experienced people here.\n\nIâ€™m a professional with \\~5 years of experience in tech, the last 3 working as a Data/Systems Integration Specialist at a SaaS company.\n\nMy job on this company is basically to onboard new customers by integrating their data, from ERPs, databases, APIs, and third-party systems, into our platform.  Basically a post-sale software delivery developer job. This involves reading API docs, handling authentication, data mapping, validation, troubleshooting failed requests, supporting integrations running in production, etc.\n\nSo I work with REST APIs, Postman, SQL, JSON/XML, webhooks, error handling, etc. on a daily basis.\n\nThe problem is: lately Iâ€™ve startied to feel heavily pigeonholed as â€œthe integration guyâ€.\n\nI donâ€™t build applications from scratch.  \nI donâ€™t build systems end-to-end.  \nI donâ€™t design architectures.  \nI donâ€™t write large codebases.\n\nAnd when I look at the market, especially internationally (I'm from Brazil), I see two very different paths:\n\n* SWE / Backend / Fullstack â†’ clear growth ladder\n* Integration / Implementation â†’ often seen as operational, repetitive, and not â€œreal engineeringâ€\n\nBut at the same time, Iâ€™ve seen many roles like Solutions Engineer that look very aligned with what I do, but at a much deeper technical/architectural level.\n\nI realized my issue might not be the career itself, but the level at which Iâ€™m operating.\n\nIt feels like I entered the right field through the wrong door.\n\nInstead of evolving into someone who understands systems, architecture, APIs deeply and can design integrations, I just became good at executing systems integrations.\n\nIt took a couple of years, but now Iâ€™m trying to correct that.\n\nI think my current goal is not to switch to full backend/SWE roles and \"restart\" my career. I want to evolve into a stronger Integration / Solutions / Systems Engineer, the kind that is valued in the market.\n\nSo, for those of you who have seen or worked with this type of role:\n\n* What should I study to move from â€œintegration executorâ€ to â€œsolutions engineerâ€?\n* What technical gaps usually separate these profiles?\n* What kind of projects or knowledge would reposition me correctly?\n* Is this a viable path, or is it truly a career dead-end?\n\nIâ€™d really appreciate guidance from people whoâ€™ve seen this from the inside.\n\nThanks a lot.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qqsg3o/feeling_pigeonholed_as_an_integration_engineer/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o2j10l6",
          "author": "systemic-engineer",
          "text": "Give me a rundown of a typical day right now. \n\nThen give me a rundown of what you imagine your day would look like, if you were to switch. \n\nWhat's the delta?  \nWhich changes would you expect?  \nWhere do you see growth potential?  \n\n\nSoftware engineers are ambiguity resolvers.  \nWe solve human problems through technology.  \n(And if we're not careful we add problems.)\n\nHow do you solve problems right now?  \nHow do you wish you'd solve them?",
          "score": 4,
          "created_utc": "2026-01-30 02:17:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2j8mjb",
              "author": "FearlessAmbition9548",
              "text": "Whatâ€™s a rundown",
              "score": 2,
              "created_utc": "2026-01-30 02:59:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2jbxw3",
              "author": "BinariesGoalls",
              "text": "A typical day for me today is very post-sale and demand-driven.\n\nI work for a company that provides an AI-based platform of inventory optimization for retailers , and Iâ€™m the person responsible for all customer data integrations for my country.\n\nWhenever a new customer comes in, I run technical discovery meetings with them to understand how their data is structured, ERPs, APIs, databases, file exports, whatever they use.\n\nOn our side, we already have a defined data blueprint, a very specific data requirement model that our system expects. My job is basically to design and build a simple pipeline that extracts the customerâ€™s data and transforms it into that required format so our platform can consume it.\n\nSo most of my work is about:\n\n- Reading and understanding ERP/API documentation.\n\n- Figuring out where each required data point lives in the customer system.\n\n- Handling authentication, endpoints, formats.\n\n- Building data pipelines that extract, transform and load the data.\n\n- Aligning business rules with the client for each data type.\n\n-Troubleshooting production issues and handling integration tickets.\n\nI donâ€™t work on the core product design. I donâ€™t design APIs. I donâ€™t build systems end-to-end.\n\nI work almost exclusively on the ingestion side, moving and shaping data so it fits into an existing system.\n\nWhat Iâ€™m looking for next is the opportunity to work on a wider variety of problems, architectures and platforms instead of repeatedly solving the same integration pattern around a single product.\n\nToday, my work is constrained by the fact that every solution must ultimately fit into one predefined system. \n\nThat means most of my effort goes into adapting external systems to match our platformâ€™s requirements.\n\nWhat I want is to design integrations and solutions end-to-end, with more flexibility to evaluate the customerâ€™s scenario and define the best technical approach for that context.\n\nInstead of always asking â€œhow do I make this system fit ours?â€, I want to be able to ask â€œwhat is the best way to connect these systems together?â€\n\nIâ€™m very motivated by the challenge of working with different architectures, different stacks, and different integration strategies depending on the problem, APIs, databases, data pipelines, middleware, cloud services, or whatever makes the most sense technically.\n\nRight now, I specialize in making one platform work with many different customer environments.\n\nI want to evolve into a role where I use that same experience to design solutions across many platforms and scenarios.\n\nThatâ€™s where I see the growth potential.",
              "score": 2,
              "created_utc": "2026-01-30 03:18:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2lba6d",
                  "author": "systemic-engineer",
                  "text": "Thank you for taking the time.  \n\nI read that you want to work more end2end.  \nAnd that you're still interested in connecting systems. \n\nI'm intrigued.  \nAnd busy. \n\nI'll write a longer response later. ðŸŒˆ",
                  "score": 1,
                  "created_utc": "2026-01-30 12:30:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2j251b",
          "author": "macromind",
          "text": "This is a super common spot to be in, and its not a dead end if you move up the abstraction level.\n\nThe solutions/architecture jump usually means: drawing the system boundaries, defining contracts, handling non-functional requirements (latency, failure modes, security), and making tradeoffs explicit.\n\nIf you want to study topics that map directly: distributed systems basics, API design, event-driven architecture, and practical integration patterns (outbox, saga, idempotency keys).\n\nSmall suggestion too: write 1 short architecture note per week about something you handled at work, even anonymized. Its surprisingly powerful for interviews. If youre batching content, something like https://www.promarkia.com/ can help you schedule it and keep momentum.",
          "score": 3,
          "created_utc": "2026-01-30 02:23:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2rqizp",
          "author": "OptionalEmotion",
          "text": "You are in a better spot compared to a traditional software engineer. I started in development only to move to devops and later into cloud solutions engineering. Higher level roles such as tech lead or architect requires what you already do day to day. You can switch to a tech lead role for a smaller company data team and execute the delivery of one team while helping them develop the solution inside the system boundary you defined. You can take over the integration of that team's solution into the rest of the business, which is literally what the job of a tech lead is.",
          "score": 2,
          "created_utc": "2026-01-31 10:48:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jdg8n",
          "author": "Charming-Raspberry77",
          "text": "It is not a dead end, but you are not on the path to being a software engineer. This article sums it up real well and offers advice: https://www.noidea.dog/glue",
          "score": 1,
          "created_utc": "2026-01-30 03:26:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jmzw8",
          "author": "macromind",
          "text": "Architecturally, you are already close, you just need to shift from task execution to designing the patterns. Learn and apply a few core concepts: canonical data model vs point to point mappings, versioning strategy, idempotency keys, replayability, and explicit contracts (OpenAPI, AsyncAPI). Also get comfortable with documenting tradeoffs and constraints, that is basically the job. If you can lead a discovery call, propose 2 options, and explain the risks in plain language, you are in solutions territory. And if you are writing those learnings up, batching and scheduling them makes it sustainable, https://www.promarkia.com/ can help with that.",
          "score": 1,
          "created_utc": "2026-01-30 04:24:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2wtp8n",
          "author": "engiNARF",
          "text": "I'm an electrical engineer but I was in a similar spot early in my career. I found myself in an IT support job I was \"meh\" about but wanted to do \"real engineering\".  What I did was to slowly take roles that leveraged my current experience but had more and more overlap with circuit design. It took a while but along the way I was always able to ask for a higher salary (because I always had relevant experience) and I got to see different aspects of engineering.   \n  \nI actually found that while design work is rewarding in its own way, the role has a different vibe from customer facing roles. I personally find that in customer facing roles I get to solve technically challenging issues but don't have to deal with as much office politics. Often I find more of a teamwork mindset among coworkers (even the Sales guys) when in a Support role. Obviously it depends on the company but I've seen similar dynamics at my past 2 employers. \n\nNow my job has a mix of design work and customer support which I'm pretty pleased with. Hope you find what you're looking for!",
          "score": 1,
          "created_utc": "2026-02-01 03:45:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qq3mvo",
      "title": "Resiliency in System Design: What It Actually Means",
      "subreddit": "softwarearchitecture",
      "url": "https://lukasniessen.medium.com/resiliency-in-system-design-what-it-actually-means-2bc72713ebf5",
      "author": "trolleid",
      "created_utc": "2026-01-29 09:03:47",
      "score": 12,
      "num_comments": 1,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qq3mvo/resiliency_in_system_design_what_it_actually_means/",
      "domain": "lukasniessen.medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "o2io5mb",
          "author": "shufflepoint",
          "text": "What it means for me is that the chaos monkey can do me no harm.",
          "score": 1,
          "created_utc": "2026-01-30 01:05:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqxln7",
      "title": "How do IDEs like Cursor / Antigravity implement diff based code editing with accept/reject option while modifying existing code",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qqxln7/how_do_ides_like_cursor_antigravity_implement/",
      "author": "CapableAd9320",
      "created_utc": "2026-01-30 06:15:03",
      "score": 9,
      "num_comments": 8,
      "upvote_ratio": 0.81,
      "text": "when modifying a exiting code using these tools, instead of rewriting the whole file, the tool proposes changes inline , shows a diff, and lets youÂ **accept/reject**Â the change (sometimes even per hunk). it feels very similar toÂ `git add -p`.\n\nFrom what I can tell, the rough flow is:\n\n* take the original code\n* LLM generate a modified version\n* compute a diff/patch\n* preview it\n* apply or discard based on user input\n\nIâ€™m interested in implementing this myself (probably as a CLI tool first, not an IDE), and Iâ€™m wondering:\n\n* Is this pattern formally called something?\n* how exactly is the modified code/diffs added into the source code\n* how is the accept/reject functionality implemented\n* Are there good open-source tools or libraries that already implement this workflow?\n* How do i go about implementing this",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qqxln7/how_do_ides_like_cursor_antigravity_implement/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o2kq4uv",
          "author": "Isogash",
          "text": "Isn't it just using git?",
          "score": 3,
          "created_utc": "2026-01-30 09:38:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yvd82",
              "author": "CapableAd9320",
              "text": "Do you by any chance have any resources for how git is used for this?",
              "score": 1,
              "created_utc": "2026-02-01 13:42:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2z0pay",
                  "author": "Isogash",
                  "text": "No, I'm just guessing because it's the way I'd do it",
                  "score": 1,
                  "created_utc": "2026-02-01 14:13:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2kt98n",
              "author": "ProfessionNo3952",
              "text": "I guess not all time because git diff cannot show difference between each round of code generation if you donâ€™t commit anything",
              "score": -1,
              "created_utc": "2026-01-30 10:07:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2ktkc8",
                  "author": "Isogash",
                  "text": "Sure you can, it can commit these to a special branch or stash them, I'm not saying that it has to commit them to your main branch.",
                  "score": 2,
                  "created_utc": "2026-01-30 10:09:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qv3nr2",
      "title": "Kafka for Architects â€” designing Kafka systems that have to last",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qv3nr2/kafka_for_architects_designing_kafka_systems_that/",
      "author": "ManningBooks",
      "created_utc": "2026-02-03 20:44:15",
      "score": 9,
      "num_comments": 4,
      "upvote_ratio": 0.7,
      "text": "Hi r/softwarearchitecture,\n\nStjepan from Manning here. Weâ€™ve just released a book thatâ€™s written for people who have to make architectural calls around event-driven systems and then defend those decisions over time. Mods said it's ok if I post it here:\n\n**Kafka for Architects** by Katya Gorshkova  \n[https://www.manning.com/books/designing-kafka-systems](https://hubs.la/Q041FhV20)\n\n[Kafka for Architects](https://preview.redd.it/guav3ysxachg1.jpg?width=2213&format=pjpg&auto=webp&s=fc59d0f2fef718c70d40b4996d59b6f879992605)\n\nThis isnâ€™t a Kafka API guide or a step-by-step tutorial. It stays at the architecture level and focuses on how Kafka fits into larger systems, especially in organizations where multiple teams depend on the same infrastructure.\n\nA few of the topics the book spends real time on:\n\n* Kafkaâ€™s role in enterprise software and where it fits in an overall system design\n* Event-driven architecture as a pattern, including when it helps and when it complicates things\n* Designing data contracts and handling schema evolution across teams\n* Kafka clusters as part of the systemâ€™s operational and organizational design\n* Using Kafka for logging, telemetry, data pipelines, and microservices communication\n* Patterns and anti-patterns that tend to appear once Kafka becomes shared infrastructure\n\nWhat I appreciate about this book is that it treats Kafka as an architectural choice, not just a technology. Katya walks through trade-offs youâ€™ll recognize if youâ€™ve ever had to balance team autonomy, data ownership, and long-term maintainability. The examples are grounded in real-world systems, not idealized diagrams.\n\nIf youâ€™re responsible for questions like â€œIs Kafka the right fit here?â€, â€œHow do we keep event contracts stable?â€, or â€œWhat happens when this system grows to ten teams instead of two?â€, this book is written with those concerns in mind.\n\n**For the** r/softwarearchitecture **community:**  \nYou can get **50% off** with the code **PBGORSHKOVA50RE**.\n\nIf youâ€™re already using Kafka as part of a larger system, Iâ€™d be interested to hear what architectural challenges youâ€™re currently dealing with.\n\nThanks for having us. It feels great to be here.\n\nCheers,\n\nStjepan",
      "is_original_content": false,
      "link_flair_text": "Tool/Product",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qv3nr2/kafka_for_architects_designing_kafka_systems_that/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o3g22dn",
          "author": "Glathull",
          "text": "Thanks for posting this. Just bought a copy.",
          "score": 1,
          "created_utc": "2026-02-04 00:49:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3etpgb",
          "author": "[deleted]",
          "text": "[removed]",
          "score": -1,
          "created_utc": "2026-02-03 21:03:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3f1op3",
              "author": "Mosk549",
              "text": "Donâ€™t be racist",
              "score": 1,
              "created_utc": "2026-02-03 21:40:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3f275o",
                  "author": "AbbreviationsLow4798",
                  "text": "donâ€™t support fascistsÂ ",
                  "score": 1,
                  "created_utc": "2026-02-03 21:42:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qu4aaf",
      "title": "Why does enterprise architecture assume everything will live forever?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qu4aaf/why_does_enterprise_architecture_assume/",
      "author": "eurz",
      "created_utc": "2026-02-02 19:05:15",
      "score": 8,
      "num_comments": 28,
      "upvote_ratio": 0.61,
      "text": "Hi everyone!\n\nWorking in a large org right now and everything is designed like itâ€™ll still be running in 2045. Layers on layers, endless review boards, â€œstrategicâ€ platforms no team can change without six approvals. Meanwhile, half the systems get sunset quietly or replaced by the next reorg. I get the need for stability, but it feels like we optimize for theoretical longevity more than actual delivery.\n\nFor people who like enterprise architecture - what problem is it really solving well, and where does it usually go wrong?",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qu4aaf/why_does_enterprise_architecture_assume/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o37gb2r",
          "author": "ClideLennon",
          "text": "Because we're still running systems that were designed in 2005?",
          "score": 77,
          "created_utc": "2026-02-02 19:12:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37h3cb",
              "author": "LessChen",
              "text": "I would have said the 1980's - so much in the banking world is very old but still works for example.",
              "score": 30,
              "created_utc": "2026-02-02 19:15:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o37h2do",
          "author": "Glathull",
          "text": "Because in the enterprise, things *do* live forever.",
          "score": 52,
          "created_utc": "2026-02-02 19:15:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37yfql",
              "author": "BeABetterHumanBeing",
              "text": "To be more precise: in enterprise, a thing lives for as long as the business it's supporting, which is frequently longer than the existence of the company (because business units get spun off in acquisitions, live through bankruptcy, and so on).",
              "score": 7,
              "created_utc": "2026-02-02 20:37:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o37gxbp",
          "author": "ratczar",
          "text": "I was reading Clean Architecture recently, and the part that jumped out and grabbed me by the throat is the idea that good architecture defers big decisions for as long as possible.   \n  \nIt sounds like your org is maybe trying to finalize plans for a big, long-term system, which is a trap that I find a lot of engineers fall into - they want to construct the beautiful, perfect, hyper-efficient machine.   \n  \nBut the business sometimes changes what it wants the machine to do, and if you're tied to a 20 year roadmap then you're a bit fucked when winds change. \n\nFor that reason, you can draw up whatever plans you want, but you should really only move to implementation when you *absolutely have to.*\n\nGreat example: we've had plans for an enterprise-wide address verification service for awhile, but we only moved on it when it became absolutely critical for a client. ",
          "score": 17,
          "created_utc": "2026-02-02 19:14:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37imki",
              "author": "ziksy9",
              "text": ">Great example: we've had plans for an enterprise-wide address verification service for awhile, but we only moved on it when it became absolutely critical for a client. \n\nGiven that is was needed by a client, even if it was implemented there were probably requirements that came in late for that client, so doing it preemptively would have still requires changes, right?\n\nGreat example.",
              "score": 3,
              "created_utc": "2026-02-02 19:22:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o37jet5",
                  "author": "ratczar",
                  "text": "It really came down to some minor details in the implementation, e.g. are we going full hypermedia or are we cramming some critical data into the initial return.\n\nWe ended up deciding to cut a corner initially and crammed it into the initial return, and will refactor later when we have more use cases for the related data.",
                  "score": 1,
                  "created_utc": "2026-02-02 19:26:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o394cg7",
              "author": "phluber",
              "text": "A well-designed enterprise architecture does not leave you fucked when winds change. A well-designed architecture allows for a great amount of flexibility and room for new features.",
              "score": 2,
              "created_utc": "2026-02-03 00:07:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o37kwij",
          "author": "ByMunro",
          "text": "IMO enterprise architecture is about flexibility (coupling and cohesion). we dont know what will be in 2045 and hell we dont even know what will be in 3 years from now. all we can do is try to stay as flexible as possible. some systems will stay, so make sure they're designed well. some systems will go, so make sure you can replace them as effortlessly as possible. \n\nand well, you can be quite sure about what is tomorrow. on a enterprise scale you probably (should) also know whats gonna happen in 6 months quite precisely. the more you look into the future, the more abstract it gets. i dont think anyone is planning on exactly your enterprise architecture will look like in 2045. but you'll want to have visions, guidelines, something abstract, so everyone is going in the same direction. as 2045 comes closer, your vision gets more precise. so make sure you can adapt, keep your landscape flexible. \n\nEDIT: should probably add, that this is a perfect world scenario. time, money, politics have quite some\ninfluence",
          "score": 5,
          "created_utc": "2026-02-02 19:33:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o38inn4",
          "author": "internetuser",
          "text": "Because the people who are paid to facilitate the process get paid more when the process takes a long time.",
          "score": 3,
          "created_utc": "2026-02-02 22:13:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o38qqgv",
          "author": "edgmnt_net",
          "text": "Just a comment from someone who dislikes it. I hope we're talking about the same thing, though, because I'm not really sure...\n\nI don't think that's the real reason. One thing might be horizontal dev scaling: plenty of businesses barely build upon anything, it's an endless crunch to appease one customer, then the next and so on. Architecture is simply an attempt to install guardrails so they can hire en masse with low costs and divide up work. Something a very average dev (mediocre even) can handle, because you want lots of them. Another thing is the expectation that software is write-once, especially when they accumulate tons of half-baked features and tech debt that's difficult to repay, they try to extract as much as possible (and impossible).\n\nIn a nutshell, it's trying to scale up work as cheaply as possible, because ultimately a lot of business is just trying to get money to work. As for where and whether it goes wrong objectively, this is also debatable. I would say the main issues are (1) unrealistic expectations and (2) they're missing out on higher impact, more efficient software development that really taps into the potential of this domain (but you need a strong vision for this, it's not just a matter of spending).\n\nIn practical terms, you'll see silos, you'll see layers upon layers that give the impression that everything is decoupled (yet it isn't, the spaghetti is on another level), you'll see work getting split in ways that makes absolutely no sense and results in huge amounts of duplication. Do reduced hiring costs make up for this? Maybe, although I doubt it can beat a small team of people with enough expertise cutting through the bullshit and working under a well-determined, restricted scope. Scope creep and tech debt tends to balloon up costs, so even if it looks like you can satisfy hundreds of customers early on, things eventually slow down greatly and you have to keep adding to the headcount and reducing margins. Until the costs become insane and the project gets sunset (often quite early).",
          "score": 3,
          "created_utc": "2026-02-02 22:53:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37h0or",
          "author": "Ugiwa",
          "text": "Products don't die that fast.. (unless you're working for Google ig)",
          "score": 2,
          "created_utc": "2026-02-02 19:15:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39cs1z",
          "author": "gbrennon",
          "text": "Because applications that runs in the backend of ur bank were deployed in 1980?",
          "score": 2,
          "created_utc": "2026-02-03 00:53:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39lg5e",
          "author": "Dicethrower",
          "text": "It's even funnier with games. \"This needs to last 5y, so let's spend 2y making what should take 6 months, and not see the irony in spending 4 times as long to \"\"save time\"\". Oh woops, funding is gone and/or game didn't do so well.\"\n\nYAGNI is not just a catchy phrase. Time saved is time you can spend refactoring when the actual need arises. Anything made before you know it's needed is a waste of time, every time.",
          "score": 2,
          "created_utc": "2026-02-03 01:43:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3dic5r",
              "author": "edgmnt_net",
              "text": "It bothers me that often it isn't anything smart either. It's not like they're spending time on mind-blowing techniques and abstractions, it's often just a ton of trivial layers.",
              "score": 2,
              "created_utc": "2026-02-03 17:25:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3fm06b",
              "author": "213737isPrime",
              "text": "It's an art to know just how much \"extra\" effort to put in place as an investment into the future without overdoing it. It's more than zero.",
              "score": 1,
              "created_utc": "2026-02-03 23:21:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3fmsm1",
                  "author": "Dicethrower",
                  "text": "Hard disagree. You never do anything extra that you don't know you need. Trying to predict the future is exactly what YAGNI is all about.",
                  "score": 1,
                  "created_utc": "2026-02-03 23:25:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o37inz5",
          "author": "europeanputin",
          "text": "Architecture it's not just about technical designs, but it must also fit the organizational structure. We have a lot of instances where we would benefit from event driven systems and concepts, but we remain strictly RESTful because we don't have the knowledge to support it. When making designs in such cases, it's important to be mindful that at some point this would change, because the other way around increases cost i.e on operations. Hence the designs go into series of discussions which tradeoff to choose, and enterprise architecture essentially helps making these decisions as it allows to estimate the cost for the current project and the cost of changing it in the future. Comparing this to projections of other cost like cost of running operations or other non functionals help making smart business decisions.\n\nAs cost of change needs to be minimized and eventually management will come to their senses, enterprise architecture is sadly required for technical people to cope with ever changing nature of business demands.",
          "score": 1,
          "created_utc": "2026-02-02 19:22:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37ny9k",
          "author": "BarfingOnMyFace",
          "text": "It solves the problem of why we have jobs really well ðŸ˜„",
          "score": 1,
          "created_utc": "2026-02-02 19:47:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37o8bs",
          "author": "BarfingOnMyFace",
          "text": "Forever is a long time. Iâ€™d argue most software should be architected to survive 3-5 decades. Maybe in some cases in the future, a century or so.",
          "score": 1,
          "created_utc": "2026-02-02 19:48:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3dhunr",
              "author": "edgmnt_net",
              "text": "Survive, definitely. Remain unchanged that long? Nah.",
              "score": 1,
              "created_utc": "2026-02-03 17:22:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3dpmqw",
                  "author": "BarfingOnMyFace",
                  "text": "Yes, just survive. Remain unchanged? Highly unlikely. Even in some far-off future of multi-generational spaceshipsâ€¦ change seems inevitable, improvements or new additional features desired, change born out of pure boredom, due to a monotonous longevity of the same look and behaviorsâ€¦ I definitely agree with you- change is frequent. change is an integral part of software, as much as it is an integral part of the human brain constantly programming itself, long after most of its software has been written.",
                  "score": 1,
                  "created_utc": "2026-02-03 17:58:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o37tfwc",
          "author": "D4n1oc",
          "text": "I can't imagine how this would influence your design.\nWe could either do a good architecture that fits the needs or we don't and live with the consequences.\n\nWhat would be the actual design difference for a system that lives 3-5 decades or 10 decades?\n\nWe know one thing for sure. Bad architecture decisions are very expensive and can influence the whole system across all teams causing huge amounts of unknown costs and sometimes make it impossible to change the running system in a necessary way.\n\nWe know the costs for a clean architectural design that minimizes this risk.\n\nIn most cases it's the most expensive part to write software. Because it always creates legacy, technical deps, complexity and needs to be supported.\n\nWriting software should be the last resort. \nIt's much cheaper to make 10 plans and throw them away.",
          "score": 1,
          "created_utc": "2026-02-02 20:13:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37w1sf",
          "author": "Mediocre_Date1071",
          "text": "I hear two different things happening here\n\n- â€œlayers on layersâ€. This sounds like design optimized for loose coupling, which gives the ability to change out pieces. This architecture for the assumption that things will not be around forever. Â \n\nâ€œEndless review boardsâ€¦platforms no one can change without 6 approvalsâ€. This is large organizations being large. There is so much miscommunication and need to generate buy-in across a large org, just so the pieces fit together reasonably well, that you get these heavy processes.Â \n\nThis isnâ€™t to say that your company is doing optimal planning and architecture, just that the reasons for what you see may not the presumption of longevity that you surmise.Â ",
          "score": 1,
          "created_utc": "2026-02-02 20:26:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3blm37",
          "author": "BeastyBaiter",
          "text": "I work as a software dev at an F100 megacorp you've heard of. We retired our mainframes 4 years ago and have numerous critical internal apps from the 1990's.",
          "score": 1,
          "created_utc": "2026-02-03 10:57:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bpmt1",
          "author": "garden_variety_sp",
          "text": "I call it crystal ball architecture, and itâ€™s the most wasteful way to design and build. Design for now and know that evolution is a thing. I view enterprise architecture in much the same way as I view intelligent design. It takes some serious mental gymnastics to believe in it, and those that do are most likely brainwashed.",
          "score": 1,
          "created_utc": "2026-02-03 11:32:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e1fkh",
          "author": "santagoo",
          "text": "We still run systems running COBOLâ€¦",
          "score": 1,
          "created_utc": "2026-02-03 18:51:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eoy61",
          "author": "serious-catzor",
          "text": "I'm not sure I really work with software... This UART worked the same when I was born and it will work the same when I die.",
          "score": 1,
          "created_utc": "2026-02-03 20:41:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qrc4rv",
      "title": "System Design for beginners!",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qrc4rv/system_design_for_beginners/",
      "author": "Substantial-Tax-472",
      "created_utc": "2026-01-30 17:35:51",
      "score": 6,
      "num_comments": 7,
      "upvote_ratio": 0.81,
      "text": "Hello guys, I'm a final year CSE student. Can anyone suggest the roadmap for beginning System Design, like from basic till advanced concepts and scenarios. I had begun with the ByteByteGo, but I didn't feel the completeness. So, any suggestions would help a lot.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qrc4rv/system_design_for_beginners/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o2n6etv",
          "author": "VortexOfPessimism",
          "text": "Probably [https://www.hellointerview.com/learn/system-design/core-concepts/api-design](https://www.hellointerview.com/learn/system-design/core-concepts/api-design) for something more structured",
          "score": 4,
          "created_utc": "2026-01-30 17:58:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2o26f0",
          "author": "Veuxdo",
          "text": "Ask your professors, that's what they're there for.",
          "score": 2,
          "created_utc": "2026-01-30 20:20:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xller",
          "author": "MatchLittle5000",
          "text": "If you want something practical watch this: https://youtube.com/@hello_interview?si=uz0nebtCACHS1uHF\n\nIt helped me a lot to pass an interview to Senior position. Might help also in academic purposes.",
          "score": 1,
          "created_utc": "2026-02-01 07:14:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y9p6d",
          "author": "lmagarati",
          "text": "bro, stop treating system design like a college exam. ByteByteGo is the gold standard, but youâ€™re feeling 'incomplete' because youâ€™re reading instead of doing. pick a feature, design it, and break it... thatâ€™s the only way to build the judgment needed for an interview process that is frankly a total 'shit show' and largely dependent on the whims of your interviewer. accept that youâ€™ll fail a few for reasons outside your control, so stop hunting for a perfect roadmap; you'll slowly learn to design by building skin in the game.",
          "score": 1,
          "created_utc": "2026-02-01 10:56:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2zolet",
          "author": "IshanSethi",
          "text": "After completing understanding basic concepts of system design, you can go & practise questions on https://www.designheist.com, they have good interview level questions... Atlassian & uber & few other companies ask system design questions & mostly are similar to what are mentioned on the platform",
          "score": 1,
          "created_utc": "2026-02-01 16:13:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3412pf",
          "author": "Comfortable-Fan-580",
          "text": "Check this out - https://pradyumnachippigiri.substack.com/s/system-design",
          "score": 1,
          "created_utc": "2026-02-02 06:07:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34br2u",
          "author": "bills2go",
          "text": "I'm building [revibe.codes](https://revibe.codes), which you can use to analyze open source systems of your interest. It shows the architecture, flow diagrams and guided code navigation. Not a regular learning platform - its kind of seeing how other systems are built and learning from that.",
          "score": 1,
          "created_utc": "2026-02-02 07:41:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qshikv",
      "title": "Deployed an ML Model on GCP with Full CI/CD Automation (Cloud Run + GitHub Actions)",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qshikv/deployed_an_ml_model_on_gcp_with_full_cicd/",
      "author": "gringobrsa",
      "created_utc": "2026-01-31 23:15:56",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 0.88,
      "text": "Hey folks\n\nI just published Part 2 of a tutorial showing how to deploy an ML model on GCP using Cloud Run and then evolve it from manual deployment to full CI/CD automation with GitHub Actions.\n\nOnce set up, deployment is as simple as:\n\n    git tag v1.1.0\n    git push origin v1.1.0\n\nFull post:  \n[https://medium.com/@rasvihostings/deploy-your-ml-model-on-gc-part-2-evolving-from-manual-deployments-to-ci-cd-399b0843c582](https://medium.com/@rasvihostings/deploy-your-ml-model-on-gc-part-2-evolving-from-manual-deployments-to-ci-cd-399b0843c582)",
      "is_original_content": false,
      "link_flair_text": "Article/Video",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qshikv/deployed_an_ml_model_on_gcp_with_full_cicd/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qtsd8g",
      "title": "Questions about adding ElasticSearch to my system",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qtsd8g/questions_about_adding_elasticsearch_to_my_system/",
      "author": "Illustrious-Bass4357",
      "created_utc": "2026-02-02 11:18:39",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "so Im trying to use elastic search in my app for 2 search functions one for foods , and the other for meals , anyways I have some questions\n\n\n\nQ1. Should Elasticsearch indices be created manually (DevOps/Kibana/Terraform), or should the application be responsible for creating them at runtime , or is there's something like db migrations but for ES ?\n\nQ2. If Elasticsearch indices are managed outside the application, how should the app safely depend on them without crashing if an index is missing or renamed? For example, is it okay to just return an empty list when Elasticsearch responds with an error?\n\nQ3. Without migrations like SQL, how are index mapping changes managed over time?  \n\n\nQ4. Should the application be responsible for pushing data into Elasticsearch when DB data changes, or should this be handled externally via CDC (e.g., Debezium) or am I over engineering ?\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qtsd8g/questions_about_adding_elasticsearch_to_my_system/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o3as015",
          "author": "Low_Satisfaction_819",
          "text": "As someone who has managed a few elasticsearch clusters in my life, consider typesense.",
          "score": 2,
          "created_utc": "2026-02-03 06:21:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39q8ii",
          "author": "james-dev89",
          "text": "For index creation and management look into Index lifecycle management ILM, usually you create an alias and the alias is responsible for rotating the index. \nYou can configure the shards and everything. \nNewer versions of ES have better index management than older ones. \n\nFor data yeah a CDC makes sense but for us, we do index write as a batch operation, after we write to the database we fire off an event that writes to elastic search. \n\nHope this helps.",
          "score": 1,
          "created_utc": "2026-02-03 02:10:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtsopq",
      "title": "Selenium IDE test Case Migration",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qtsopq/selenium_ide_test_case_migration/",
      "author": "amfromeverywhere",
      "created_utc": "2026-02-02 11:36:05",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.88,
      "text": "I am trying to design migrating a 20 year old JSF based system to rest controllers + angular. Tough but I feel a vanilla migration for this forum. \n\nWhat's new is they have about 5000 selenium ide suites that only runs on an ancient version of Firefox over a well designed kubernetes cluster and takes in between 5 to 15 hrs depending on how much resources you can dedicate for a run.\n\n  \nThose tests are really really thorough but are the only source of truth of the application functionality. No documents or unit or integration tests are present.\n\n  \nSo question for anyone who has experienced a migration like this:\n\n  \n1. Any effective way of speedy refactoring without waiting for 10 hours for tests feedback?\n\n2. What happens to the tests post migration? There are decades of edge case bug fixes being guarded by this regression suite but no one knows what the tests do. The historical assertions in those tests is what is keeping the system running and we don't want to lose it.",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qtsopq/selenium_ide_test_case_migration/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o36edyw",
          "author": "flavius-as",
          "text": "Run the test suite with code coverage on.\n\nThis gives you all tests grouped by use case.\n\nThen split the tests by use case and run only the relevant tests.\n\nThen refactor the code behind the scene for only that use case. One use case at a time.\n\nThen create the rest api which uses the same code like jsf. Write tests for that. Introduce mutation testing. Either both selenium and the new test suite fails, or both succeed.\n\nOnce you got enough mass, you switch users to the new UI and remove the old tests.\n\nI'd suggest a gradual Roadmap in which you migrate certain use cases to the new UI, via the infrastructure routing.",
          "score": 3,
          "created_utc": "2026-02-02 16:19:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qrek69",
      "title": "What would you change in this architecture?",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qrek69/what_would_you_change_in_this_architecture/",
      "author": "Complex_Ring210",
      "created_utc": "2026-01-30 19:00:00",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 0.73,
      "text": "[Test Architecture](https://drive.google.com/file/d/1tad2EjG_wQ7KGoBRXIAVRN-GWBIN3Ey1/view?usp=sharing)\n\nI am learning system design and trying to make a kind of reddit + ai system. I know there can be many things added in this which are currently in reddit, but keeping it simple for now.\n\nPostgres is the main database, Neo4j is for social graph, S3/Minio is for storing media files, Qdrant is for vector embeddings (for media files in chat and long term LLM memory). All services either use Node.js or Python for now.  \nClient is a mobile or web user.\n\nThese are a few things I know, I have to add:\n\n1. Caching (other than the one Valkey node being used for caching SFU server health checks)\n2. The live chat is not connected at the moment\n\nI would love suggestions on how to make this architecture faster or any general improvements. Any suggestions on improvements is welcomed, even if you think I should use php.\n\nAlso all of this was done in [draw.io](http://draw.io) and I know this is so not the way to draw system diagrams. So, it would be great if anyone can let me know how to actually diagram and which tools I should use to draw the diagram",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qrek69/what_would_you_change_in_this_architecture/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o2nrd68",
          "author": "Hopeful-Programmer25",
          "text": "If this is for actual use btw, I donâ€™t think MinIO is free any moreâ€¦ though you said for learning so, ok",
          "score": 5,
          "created_utc": "2026-01-30 19:30:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nstx4",
              "author": "Complex_Ring210",
              "text": "Yeah I mean I don't want to give $1 per month to AWS to host 5 cat photos",
              "score": 1,
              "created_utc": "2026-01-30 19:36:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2soquz",
                  "author": "Glove_Witty",
                  "text": "Youâ€™d be well under the free tier threshold by the sound of it.",
                  "score": 1,
                  "created_utc": "2026-01-31 14:49:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2pfnfd",
              "author": "Complex_Ring210",
              "text": "What do you think about the architecture?\nCan I improve it?",
              "score": 1,
              "created_utc": "2026-01-31 00:31:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rggmg",
                  "author": "Hopeful-Programmer25",
                  "text": "If you can post a screenshot here I could have a look.",
                  "score": 1,
                  "created_utc": "2026-01-31 09:12:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qtuyi1",
      "title": "Have to extract large number of records from the DB and store to a Multipart csv file",
      "subreddit": "softwarearchitecture",
      "url": "https://www.reddit.com/r/softwarearchitecture/comments/1qtuyi1/have_to_extract_large_number_of_records_from_the/",
      "author": "MasterA96",
      "created_utc": "2026-02-02 13:25:17",
      "score": 5,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "I have to design a flow for a new requirement. Our product code base is quite huge and the initial architects have made sure that no one has to write data intensive code themselves. They have pre-written frameworks/utilities for most of the things. \n\nBasically, we hardly get to design any such thing ourselves hence I lack much experience of it and my post might seem naive so please excuse me for it.\n\n(EDITED) The requirement was that we will be using RabbitMQ so the user request to service A will send a message to the queue and there will be a consumer service B which would use Apache Camel, would go through routes (I mean so it's already asynchronous) to finally requesting records from the join of tables. (Just a simple inner join, nothing complex) Those records might or might not need processing and have to be written to a multipart file of type csv, which would be sent to another API to another service C.\n\nWe're using PostgreSQL. I've figured out the Camel routing part (again using existing utilities). Designed a sort of LLD. Now the real question was fetching records and writing to csv without running into OOM issue. It seems to be the main focus of my technical architect.\n\nI've decided on using - (EDITED)\n\nJdbcTemplate.query using RowCallBackHandler\n\n(Might use JdbcTemplate.queryForStream(...), since I'm on Java 17 so better to use streams rather than RowCallBackHandler, but there are other factors like connection stays open, fetchSize on individual statement isn't possible)\n\nWould be using a setFetchSize(500) - Might change the value depending on the tradeoffs as per further discussions.\n\nMight use setMaxRows as well.\n\nThe query would be time period based so can add that time duration in the query itself.\n\nThen I'll be using CSVWriter/ByteArrayOutputStream to write it to the Multipart file (which is in memory not on disk). [Not so clear on this, still figuring out]\n\nI know it's nothing complex but I want to do it right. I used to work on a C# project (shit project) for 4.5 yrs and moved to Java, 2 yrs back. Roast me but help me get better please. Thank you. ",
      "is_original_content": false,
      "link_flair_text": "Discussion/Advice",
      "permalink": "https://reddit.com/r/softwarearchitecture/comments/1qtuyi1/have_to_extract_large_number_of_records_from_the/",
      "domain": "self.softwarearchitecture",
      "is_self": true,
      "comments": [
        {
          "id": "o37uxvj",
          "author": "two-point-zero",
          "text": "Look a bit confusing to me. Help me to understand:\n\n-Why rabbit?it means that the  process that read the file (call it the producer) is not on the same software/machine/system of the one that read them? ( Call it the consumer). So producer read from your db, write messages in rabbit and a different system will read and build the csv?\n\n- camel is not enough to be \"automatically async\" because of routes. A route can be fully sync, and to be honest in most case you want to be sync ( for example if you are dealing with transactions). The async is because of Rabbit,and it's async between producer and consumer still the consumer part might or might not be sync with the thread that read from rabbit.\n\n- if messages goes from postgeres to the CVS producer via rabbit,the advance of using streamed query highly depends on how you write on rabbit.do you send rows in bulk ( 10,100,1000s each rabbit message) or one message each row ( very poor performance wise)?\n\n- by the way if performance is a concerns,don't use text formats for rabbit messages (Jason,XML ) goes for a binary serialization library.\n\n- what is a multiparty csv? There are csv payload and multipart http requests. Multipart csv look new to me.\n\nClarify these please and we can continue...\n\nEdit: and most important how \"big\" is big here? Thousands of records?millions? billions? A 10MB csv, 100 MB? GB?",
          "score": 2,
          "created_utc": "2026-02-02 20:20:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3adv7z",
              "author": "MasterA96",
              "text": "Sure, I'll elaborate. RabbitMQ is used just after we receive the user request. Basically the request message will go to RabbitMQ and gets consumed by another service which would then produce the file and send to a 3rd service.\n\nWe can rule out the Camel routing part here. I just mentioned RabbitMQ and Camel to tell that DB call would happen on a separate thread so it's already non-blocking in one way.\n\nSo the DB call and CSV formation both are part of the RabbitMQ consumer service.\n\nIt will be sending the Multipart File which will be of type CSV. \n\nHow the 3rd service will send/display that file to the user is completely out of my control.\n\nNumber of records currently atmost are 100k, but will increase with time. The table is already monthly partitioned and indexed.\n\nAlso, I know it might not take that much memory right now but my team's main concern is that we should still not bring and store everything in memory.\n\nEdit: To summarize I want to know how can I use JdbcTemplate in a better way as per this usecase.",
              "score": 1,
              "created_utc": "2026-02-03 04:34:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3b2ahx",
                  "author": "two-point-zero",
                  "text": "Ok.nice.\n\nStarting form the end. If you want to keep a minimum of streaming features you probably want to use chunked data (if http 1) or DATA frames (if http/2) but you need to be sure that both your http client and API server are able to manage them (which should be..but check to be sure).\n\nIf not, you have to send the CVS file all in once,that means load in memory all at once. Or you might want to save it on some third party storage and send link to the external API to retrieve if it too big.\n\nConsidering you can actually send data in streaming fashion, I think I would go for paginate the query on db assign each page to a different thread, read and process In parallel (you may want to track some row key or page number to reorder data at the end),and then compose and reorder it need. With camel should be matter of a couple of stages to accomplish that, patterns of scatter and recompose is well supported.\n\nThen you can buffer your rows,once processed and reordered and send them when ready again in chunk,or data as said before.\n\nBut keep in mind,if you need  any summarized data (like the average of some value,thing like that )you cannot avoid to load  everything in memory at least once.\n\nI would keep thing parametric like:\n\n- records in a page \n- number of thread for reading\n -dimension of chunk\n- dimension of http post body buffer\n\nAnd play a bit to see what fit best. Speed and Memory and resources are always connected,high speed, more parallelism,more memory and more resources but faster.\n\nLess parellism,or smaller db pages,will consume less resources but requires more time to complete..you need to try and tweak.\n\nIdeally if you want to stream directly from db to API,you cannot use more that one thread for db page (no parallelism, one page at time, out of db through API sync)\n\nThe more parallel thread you will use the more memory you need because worst case, to build an ordered chunk you might need to keep in Memory all the required pages until you fill the write buffer. I.e. you spin 3 thread and read page 1,2,3 but thread 3 finish first. To send all the records ordered you need to wait for thread 1 an 2 to complete, so worst case you need all 3 Db pages to be loaded in memory for reordering.\n\nso keep main parameters variables using external properties ( possibly with hot reload or JMX access to change them while running) and find your sweet spot.",
                  "score": 1,
                  "created_utc": "2026-02-03 07:52:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3bqdba",
          "author": "garden_variety_sp",
          "text": "Camel SQL producer will give you a ResultSetIterator. You can stream from that. Transform if you need to. The Camel file producer will happily take a stream as input and will even chunk it for you if required.",
          "score": 1,
          "created_utc": "2026-02-03 11:38:08",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}