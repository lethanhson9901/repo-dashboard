{
  "metadata": {
    "last_updated": "2026-01-23 02:26:24",
    "time_filter": "week",
    "subreddit": "FluxAI",
    "total_items": 13,
    "total_comments": 21,
    "file_size_bytes": 28208
  },
  "items": [
    {
      "id": "1qgi0b5",
      "title": "Honest Comparison: FLUX 2 Klein (4b & 9b) vs. Z-image Turbo",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/gallery/1qgi0b5",
      "author": "Jaded_Proposal_590",
      "created_utc": "2026-01-18 19:34:25",
      "score": 46,
      "num_comments": 12,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qgi0b5/honest_comparison_flux_2_klein_4b_9b_vs_zimage/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0ct0sq",
          "author": "gtderEvan",
          "text": "My impression is much better prompt adherence on Klein 9B.",
          "score": 7,
          "created_utc": "2026-01-18 20:46:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cx306",
              "author": "Jaded_Proposal_590",
              "text": "In fact, it is. However, I like the visual style better from 4b, as if it follows it better. Overall, 9b behaves much better when editing images",
              "score": 2,
              "created_utc": "2026-01-18 21:09:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0lst39",
          "author": "i-mortal_Raja",
          "text": "Z turbo always looks cool",
          "score": 3,
          "created_utc": "2026-01-20 03:43:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ha9rd",
          "author": "zthrx",
          "text": "might share wf?",
          "score": 2,
          "created_utc": "2026-01-19 14:23:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0hcu30",
              "author": "Jaded_Proposal_590",
              "text": "It's a default wf txt2img flux 2 Klein with little changes for my comfortable. But i can share if you need",
              "score": 3,
              "created_utc": "2026-01-19 14:36:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0pv515",
                  "author": "NoceMoscata666",
                  "text": "same, if you can",
                  "score": 1,
                  "created_utc": "2026-01-20 19:11:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0gnfv0",
          "author": "barseghyanartur",
          "text": "Do you have also inference times (how long did it take to generate the image, assuming you ran this lically)?",
          "score": 1,
          "created_utc": "2026-01-19 11:56:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0gvxtf",
              "author": "Jaded_Proposal_590",
              "text": "**RTX3090**\n\nResolution for all: 1280 x 1920.\n\n* **Flux 2 klein 9b:**\n\n1. Steps: 4\n\nTotal speed: 2.85s/it, 17s/img\n\n2. Steps: 8\n\nTotal speed: 3s/it, 32s/img\n\n\n\n* **Flux 2 klein 4b:**\n\n1. Steps: 4\n\nTotal speed: 1.3s/it, 8s/img\n\n2. Steps: 8\n\nTotal speed: 1.6s/it, 15s/img\n\n\n\n* **Z-image:**\n\n1. Steps: 8\n\nTotal speed: 2.8s/it, 26s/img",
              "score": 3,
              "created_utc": "2026-01-19 12:59:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0t1fo4",
          "author": "tarkansarim",
          "text": "I gotta say Flux Klein was a surprise. It looks good!",
          "score": 1,
          "created_utc": "2026-01-21 05:28:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vi970",
          "author": "kayteee1995",
          "text": "what a complicated prompt",
          "score": 1,
          "created_utc": "2026-01-21 16:01:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qebkd6",
      "title": "Different Facial Expressions from One Face Using FLUX.2 [klein] 9B",
      "subreddit": "FluxAI",
      "url": "https://i.redd.it/de2u02bckodg1.png",
      "author": "Substantial-Fee-3910",
      "created_utc": "2026-01-16 09:30:56",
      "score": 29,
      "num_comments": 1,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Flux KLEIN",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qebkd6/different_facial_expressions_from_one_face_using/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o02ywf5",
          "author": "Pase4nik_Fedot",
          "text": "We need to wait for realistic anti-plastic LoRa)",
          "score": 1,
          "created_utc": "2026-01-17 10:03:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qe9xzq",
      "title": "New FLUX.2 [Klein] 9B is INSANELY Fast",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/r/FluxAI/comments/1qe9xzq/new_flux2_klein_9b_is_insanely_fast/",
      "author": "Lopsided_Dot_4557",
      "created_utc": "2026-01-16 07:49:47",
      "score": 22,
      "num_comments": 10,
      "upvote_ratio": 0.92,
      "text": "BFL is has done a good job with this new Klein model, though in my testing text-to-image in distilled flavor is the best:\n\n\n\nðŸ”¹ Sub-second inference on RTX 4090 hardware\n\nðŸ”¹ 9B parameters matching models 5x its size\n\nðŸ”¹ Step-distilled from 50 â†’ 4 steps, zero quality loss\n\nðŸ”¹ Unified text-to-image + multi-reference editing\n\n\n\nHF Model: black-forest-labs/FLUX.2-klein-base-9B Â· Hugging Face\n\nDetailed testing is here:  [https://youtu.be/j3-vJuVwoWs?si=XPh7\\_ZClL8qoKFhl](https://youtu.be/j3-vJuVwoWs?si=XPh7_ZClL8qoKFhl) ",
      "is_original_content": false,
      "link_flair_text": "LORAS, MODELS, etc  [Fine Tuned]",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qe9xzq/new_flux2_klein_9b_is_insanely_fast/",
      "domain": "self.FluxAI",
      "is_self": true,
      "comments": [
        {
          "id": "nzwgixf",
          "author": "OcelotUseful",
          "text": ">Â fits in ~29GB VRAM",
          "score": 5,
          "created_utc": "2026-01-16 11:14:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0e6js9",
              "author": "eagledoto",
              "text": "Works like a charm on my rtx 2060 12gb too, 9b distilled v with qwen 9b text encoder",
              "score": 1,
              "created_utc": "2026-01-19 01:01:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzw80h5",
          "author": "Herr_Drosselmeyer",
          "text": "How are you gettin sub 1 second on the 9b? Don't you mean the 4b?",
          "score": 2,
          "created_utc": "2026-01-16 09:59:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvvy12",
          "author": "Sir_McDouche",
          "text": "People really need to stop using that word.",
          "score": -1,
          "created_utc": "2026-01-16 08:07:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03e6gc",
              "author": "alb5357",
              "text": "Insanely?\n\nBecause it's derogatory toward the insane? It's the first I've heard this one.",
              "score": 1,
              "created_utc": "2026-01-17 12:20:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o06d5me",
              "author": "wesarnquist",
              "text": "What, \"fast\"? But that's an INSANELY good word!",
              "score": 1,
              "created_utc": "2026-01-17 21:29:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzymp8e",
              "author": "tommyjohn81",
              "text": "People really need to stop being so sensitive",
              "score": 1,
              "created_utc": "2026-01-16 18:01:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzzl9tn",
                  "author": "DankGabrillo",
                  "text": "I think it's time we stop\nChildren, what's that sound?\nEverybody look what's going down",
                  "score": 6,
                  "created_utc": "2026-01-16 20:38:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzxb7a3",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 0,
          "created_utc": "2026-01-16 14:26:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o06dj7o",
              "author": "wesarnquist",
              "text": "My hunch is that this will be solved through fine-tuning",
              "score": 1,
              "created_utc": "2026-01-17 21:31:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qe8sq2",
      "title": "FLux KLEIN: only 13GB VRAM needed! NEW MODEL",
      "subreddit": "FluxAI",
      "url": "https://i.redd.it/f72utk20qndg1.png",
      "author": "Unreal_777",
      "created_utc": "2026-01-16 06:42:54",
      "score": 15,
      "num_comments": 6,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qe8sq2/flux_klein_only_13gb_vram_needed_new_model/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o00acld",
          "author": "optimisticalish",
          "text": "Works fine and fast on a 3060 12Gb, with GGUF model and clip.",
          "score": 4,
          "created_utc": "2026-01-16 22:38:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o028uoq",
              "author": "Unreal_777",
              "text": "what workflow do you use",
              "score": 2,
              "created_utc": "2026-01-17 06:05:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o02zo1o",
                  "author": "Unreal_777",
                  "text": "Share examples",
                  "score": 2,
                  "created_utc": "2026-01-17 10:11:04",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o02xawi",
          "author": "Rude_Dependent_9843",
          "text": "I use the 9b base and distilled version without any problems on a 12GB 4070 Super. Editing is especially fast.",
          "score": 2,
          "created_utc": "2026-01-17 09:48:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0q50nm",
              "author": "Ant_6431",
              "text": "12gb here. Works just fine. No gguf.",
              "score": 2,
              "created_utc": "2026-01-20 19:56:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfa5m4",
      "title": "Flux 2 vs Nano Banana Pro vs FLUX.2 [klein] â€” Portrait Comparison",
      "subreddit": "FluxAI",
      "url": "https://i.redd.it/6kxcst0o2wdg1.jpeg",
      "author": "Substantial-Fee-3910",
      "created_utc": "2026-01-17 10:45:33",
      "score": 14,
      "num_comments": 3,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qfa5m4/flux_2_vs_nano_banana_pro_vs_flux2_klein_portrait/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o07z6cf",
          "author": "NES64Super",
          "text": "Good thing loras exist.",
          "score": 3,
          "created_utc": "2026-01-18 02:30:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09066u",
          "author": "pix_l",
          "text": "Add \"schnell\" and show him sprinting :D",
          "score": 3,
          "created_utc": "2026-01-18 06:32:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o091u2p",
          "author": "Sir_McDouche",
          "text": "FLUX still plastic as hell. Even the Pro/Max version is pretty bad. Banana is king.",
          "score": 1,
          "created_utc": "2026-01-18 06:46:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qg9afx",
      "title": "ComfyUI Tutorial: Flux. 2 Klein A GAME CHANGER For AI Generation & Editing",
      "subreddit": "FluxAI",
      "url": "https://youtu.be/57ppu1WmqLU",
      "author": "cgpixel23",
      "created_utc": "2026-01-18 14:00:00",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 0.8,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorials/Guides ",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qg9afx/comfyui_tutorial_flux_2_klein_a_game_changer_for/",
      "domain": "youtu.be",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qgo0ra",
      "title": "Need some guidance please! Which Flux model for an RTX 4070 12gb",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/r/FluxAI/comments/1qgo0ra/need_some_guidance_please_which_flux_model_for_an/",
      "author": "lafoxy64",
      "created_utc": "2026-01-18 23:38:13",
      "score": 5,
      "num_comments": 4,
      "upvote_ratio": 0.86,
      "text": "greetings everyone, im new here, i want to apologize in advance for my ignorance. If a kind soul could bare with me and guide me a little bit here.  \nIm kinda new to local AI, ive played around with Automatic1111 and SDXL models about a year ago but thats it.\n\nright now i have an RTX 4070 12gb with a Ryzen 7 5700X and 32gb of ram on Linux CachyOS and i wish to use ComfyUI to try some image generation and later on some video generation.  \nI suppose my 4070 is far from enough to have professional results but id like to find a way to get the best possible results with my hardware, at least enough to learn, i really want to learn, you have no idea how much but there is SO MUCH that its a bit overwhelming and i dont know where to start.\n\nIve checked some models and most apparently need ridiculous amounts of vram, could someone point me in the direction of a model that i could run on my hardware?\n\nIve been reading a lot, ive found some named \"**FLUX.2 \\[klein\\]\"** but i think it needs around 13gb of vram. Is there any way i could fit it in my 4070? or is there any other similar model that i can run?\n\nalso if you could send me a link to a very detailed guide about models, workflows and that kind of stuff for dummies? im so lost lol and everytime i try to learn there is so much incomplete or advanced information that it makes my head spin. Besides english is not my first language, still im ok with the info being in english, in fact i need it to be in english but please, PLEASE someone guide me a little bit!\n\nthanks in advance to anyone willing to read this and help me, thank you very much.",
      "is_original_content": false,
      "link_flair_text": "Question / Help",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qgo0ra/need_some_guidance_please_which_flux_model_for_an/",
      "domain": "self.FluxAI",
      "is_self": true,
      "comments": [
        {
          "id": "o0ol7hx",
          "author": "lafoxy64",
          "text": "oh well, i guess not. :(",
          "score": 1,
          "created_utc": "2026-01-20 15:40:55",
          "is_submitter": true,
          "replies": [
            {
              "id": "o0q4mvt",
              "author": "Ant_6431",
              "text": "Comfy workflow klein fp8 distilled works perfect",
              "score": 1,
              "created_utc": "2026-01-20 19:55:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0rfaby",
          "author": "MushroomCharacter411",
          "text": "Most models will work fine, just stick to the FP8 versions if you expect the whole thing to fit in VRAM. If the FP16 version is all you can get, it will be much slower but still work. I don't recommend going to FP4, because that requires a change of format from .safetensor to .gguf and none of the LoRAs you're already used to will work properly.\n\nBasically, just use what RTX 3060 owners use because those also have 12 GB of VRAM. You'll just be a bit faster than the 3060, but the selection of model and quantization is pretty much the same.",
          "score": 1,
          "created_utc": "2026-01-20 23:41:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0te116",
          "author": "RalFingerLP",
          "text": "9b base worked for me on my 4070Ti with offloading into RAM (16gb)",
          "score": 1,
          "created_utc": "2026-01-21 07:11:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfmdnn",
      "title": "Compared Quality and Speed Difference (with CUDA 13 & Sage Attention) of BF16 vs GGUF Q8 vs FP8 Scaled vs NVFP4 for Z Image Turbo, FLUX Dev, FLUX SRPO, FLUX Kontext, FLUX 2 - Full 4K step by step tutorial also published",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/gallery/1qfmdnn",
      "author": "CeFurkan",
      "created_utc": "2026-01-17 19:27:14",
      "score": 5,
      "num_comments": 1,
      "upvote_ratio": 0.65,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qfmdnn/compared_quality_and_speed_difference_with_cuda/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o05p6dv",
          "author": "CeFurkan",
          "text": "**Full 4K tutorial :**Â [**https://youtu.be/XDzspWgnzxI**](https://youtu.be/XDzspWgnzxI)\n\n[**BF16 vs GGUF, FP8 Scaled, NVFP4 Speed & Quality Compared + ComfyUI CUDA 13 Gains + FLUX 2 Klein 9B**](https://youtu.be/XDzspWgnzxI)\n\n**Check above full 4K tutorial to learn more and see uncompressed original quality and size images**\n\nhttps://preview.redd.it/dz8485exnydg1.jpeg?width=2048&format=pjpg&auto=webp&s=d4058c2c2d80292b13a5ab9a71c9d53052a35358",
          "score": 0,
          "created_utc": "2026-01-17 19:27:41",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qetgr9",
      "title": "I tried some Artstyles inspired by real word photos (Z-Image Turbo vs. Qwen 2512 vs. Qwen 2512 Turbo and Flux2.dev)",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/gallery/1qesgag",
      "author": "Accomplished_Bowl262",
      "created_utc": "2026-01-16 21:55:11",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qetgr9/i_tried_some_artstyles_inspired_by_real_word/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qfmdgs",
      "title": "Help needed: Flux model giving grey output",
      "subreddit": "FluxAI",
      "url": "https://i.redd.it/k0cw25vulydg1.png",
      "author": "Acceptable-Load2437",
      "created_utc": "2026-01-17 19:27:01",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Question / Help",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qfmdgs/help_needed_flux_model_giving_grey_output/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qgxz0h",
      "title": "quick (trivial) tip for outpainting with flux.2 klein",
      "subreddit": "FluxAI",
      "url": "https://i.redd.it/r7dp6p1p48eg1.png",
      "author": "Unreal_777",
      "created_utc": "2026-01-19 07:43:29",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Flux KLEIN",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qgxz0h/quick_trivial_tip_for_outpainting_with_flux2_klein/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qi5vpr",
      "title": "Question on consistent 2D style. Is flux 2 worth the upgrade? Or should i be exploring SDXL?",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/r/FluxAI/comments/1qi5vpr/question_on_consistent_2d_style_is_flux_2_worth/",
      "author": "Alma_Mandre",
      "created_utc": "2026-01-20 16:33:39",
      "score": 3,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "Hey everyone,\n\nFor a little context, i finally took the full plunge into Ai and comfyui about 4 or 5 months ago as needed for a job. The overall goal was to define a unique 2d style, a sort of mix of retro anime and more modern western 2d art. After a ton of research, i ended up settling on using flux instead of SDXL, and went the lora training route, as opposed to something like ipadapters.\n\nI need (and have setup) a multi-part workflow, in that i can do:  \n1. pure text to image  \n2. text to image, but with a specific face. For the most part, ive been using bytedance's USO for this.  \n3. just applying the style to an existing image, with minimal changes otherwise. I've done this through controlnets, lower denoising values, and sometimes USO w no extra prompting, or a combination of the three.\n\nSo in general, it needs to be super flexible... It also needs to work for the looooong term, as it's for an ongoing use.\n\nThe way i have this setup is one project/workflow, with many different mini workflows in the same canvas, all using the same clip/vae/model through Anything Everywhere. (is this bad for any reason?)\n\nhttps://preview.redd.it/76eojquv3jeg1.png?width=2459&format=png&auto=webp&s=c331fcb4c43ceae8ae6a7ffcb2a34058ece3434a\n\nThe thing is, it feels like im CONSTANTLY fighting an uphill battle.  It takes me hours to get a decent looking image, that has no extra fingers, fits the lora style, doesnt have weird artifacting or banding, doesnt have poor edge quality for the 2d linework, etc.\n\n**So, as for my question(s):**  \n1. Is flux maybe not the right route for this? With the new flux 2 release, im seeing a real emphasis and lean towards realism as opposed to unique styles (in my case 2d.) Would SDXL maybe be better?  \n2. What prompted me to make this post was initially, just going to be asking **if an upgrade to flux 2, along with retraining of loras, might be worth it for my case.** But in researching, i saw so little content or info on style loras and/or 2d/anime stuff for flux 2, so i thought i might make a broader post.  \n  \nIn general, im still a huge noob to this whole world, given how deep it is. So would love tips on any aspect of my setup, goals, workflow, etc. Id even consider paying someone for a few hours of consultation on a call, if anyone has a good rep here on the sub or on fiver or something.\n\n\n\n*Here are some other odds and ends random questions, please feel free to ignore, but ill include in case someone is feeling kind or has a quick answer :)*\n\n1. Flux seems to just not know what some, seemingly, common concepts are. Is there any solution or tips for when these things arise? EXAMPLE: Recently i realized it has no concept of \"vapes,\" it didnt seem to know what a vape pen or box or anything like that was. I got ok-ish results from saying like \"small electronic device that's being held up his lips, with his cheeks pursed slightly as if inhaling.\" \n   1. It also seemed to handle smoke really poorly, but is that maybe more the fault of my stile lora perhaps? Actually, could that be the issue with vapes themselves too...?\n2. Would ipadapters maybe be a better route to try? right now im primarily using loras that i trained, as well as also sometimes mixing it with USO style images (in my setup, i have 3 copies of the USO workflow, one that has the lora + subject reference, one with lora + style reference, and one with lora + style + subject reference. all include text as well.) My lora was trained of a batch of images, and i sometimes include some of those back in to the style reference in an attempt to lock it in a bit more. Mixed results.\n3. Since my style has been to be hard to keep consistent, ive been including a sentence in front of every text prompt, and even including it as the only text in the prompt when i do generations that otherwise wouldn't require text. It seems to reinforce my style a bit, and i derived it from the language that was frequently used in the auto-generated captions that civitAi assigned my original style photos while training my lora. I did NOT end up using any caption on my images for the final lora that im using however, they were trained without keyword or captions. Is there any inherent issues with this? I got to this place through trial and error, and it seems to work better than without, but i'd still like to know if im breaking any basic rules here?\n   1. It's \"A vibrant digital illustration in retro anime style, with cel shading and clean bold lines for edges\".\n4. Is there a chance that my struggle with consistent style comes from poor lora training? I trained a ton of batched, slowly improving and honing in on what seemed best. But it may still not be great.\n\n  \nObviously, i realize that i may need to provide more info/details as needed if someone is kind enough to want to help, so please feel free to ask below.",
      "is_original_content": false,
      "link_flair_text": "Question / Help",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qi5vpr/question_on_consistent_2d_style_is_flux_2_worth/",
      "domain": "self.FluxAI",
      "is_self": true,
      "comments": [
        {
          "id": "o0vfvo9",
          "author": "Alma_Mandre",
          "text": "Perhaps this was far too wordy. Put simply, does anyone have experience or advice in regards to using flux 2 with 2d anime style loras?",
          "score": 2,
          "created_utc": "2026-01-21 15:50:59",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi5hdt",
      "title": "Huge NextGen txt2img Model Comparison (Flux.2.dev, Flux.2[klein] (all 4 Variants), Z-Image Turbo, Qwen Image 2512, Qwen Image 2512 Turbo)",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/gallery/1qi5aru",
      "author": "Accomplished_Bowl262",
      "created_utc": "2026-01-20 16:19:05",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.71,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qi5hdt/huge_nextgen_txt2img_model_comparison_flux2dev/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": []
    }
  ]
}