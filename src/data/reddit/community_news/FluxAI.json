{
  "metadata": {
    "last_updated": "2026-01-17 16:48:01",
    "time_filter": "week",
    "subreddit": "FluxAI",
    "total_items": 9,
    "total_comments": 12,
    "file_size_bytes": 14097
  },
  "items": [
    {
      "id": "1qdzi7n",
      "title": "I made a 1-click app to run FLUX.2-klein on M-series Macs (8GB+ unified memory)",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/r/FluxAI/comments/1qdzi7n/i_made_a_1click_app_to_run_flux2klein_on_mseries/",
      "author": "akroletsgo",
      "created_utc": "2026-01-15 23:28:59",
      "score": 32,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "Been working on making fast image generation accessible on Apple Silicon. Just open-sourced it.\n\nWhat it does:\n\n\\- Text-to-image generation\n\n\\- Image-to-image editing (upload a photo, describe changes)\n\n\\- Runs locally on your Mac - no cloud, no API keys\n\nModels included:\n\n\\- FLUX.2-klein-4B (Int8 quantized) - 8GB, great quality, supports img2img\n\n\\- Z-Image Turbo (Quantized) - 3.5GB, fastest option\n\n\\- Z-Image Turbo (Full) - LoRA support\n\nHow fast?\n\n\\- \\~8 seconds for 512x512 on Apple Silicon\n\n\\- 4 steps default (it's distilled)\n\nRequirements:\n\n\\- M1/M2/M3/M4 Mac with 16GB+ RAM (8GB works but tight)\n\n\\- macOS\n\nTo run:\n\n1. Clone the repo\n\n2. Double-click Launch.command\n\n3. First run auto-installs everything\n\n4. Browser opens with the UI\n\nThat's it. No conda, no manual pip installs, no fighting with dependencies.\n\nGitHub: [https://github.com/newideas99/ultra-fast-image-gen](https://github.com/newideas99/ultra-fast-image-gen)\n\nThe FLUX.2-klein model is int8 quantized (I uploaded it to HuggingFace), which cuts memory from \\~22GB to \\~8GB while keeping quality nearly identical.\n\nWould love feedback. ",
      "is_original_content": false,
      "link_flair_text": "Resources/updates",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qdzi7n/i_made_a_1click_app_to_run_flux2klein_on_mseries/",
      "domain": "self.FluxAI",
      "is_self": true,
      "comments": [
        {
          "id": "nzww7it",
          "author": "hydargo101",
          "text": "Installation worked fine on my M4 Pro, the gradio UI also works great (just tested flux2 klein/ZIT quantized. Nice job. Note : the UI gives an error message after each image edit, but it goes away once I reload the image.",
          "score": 1,
          "created_utc": "2026-01-16 13:05:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzx4p6m",
              "author": "akroletsgo",
              "text": "fixing!",
              "score": 1,
              "created_utc": "2026-01-16 13:52:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qebkd6",
      "title": "Different Facial Expressions from One Face Using FLUX.2 [klein] 9B",
      "subreddit": "FluxAI",
      "url": "https://i.redd.it/de2u02bckodg1.png",
      "author": "Substantial-Fee-3910",
      "created_utc": "2026-01-16 09:30:56",
      "score": 24,
      "num_comments": 1,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Flux KLEIN",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qebkd6/different_facial_expressions_from_one_face_using/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o02ywf5",
          "author": "Pase4nik_Fedot",
          "text": "We need to wait for realistic anti-plastic LoRa)",
          "score": 1,
          "created_utc": "2026-01-17 10:03:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qe9xzq",
      "title": "New FLUX.2 [Klein] 9B is INSANELY Fast",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/r/FluxAI/comments/1qe9xzq/new_flux2_klein_9b_is_insanely_fast/",
      "author": "Lopsided_Dot_4557",
      "created_utc": "2026-01-16 07:49:47",
      "score": 16,
      "num_comments": 8,
      "upvote_ratio": 0.9,
      "text": "BFL is has done a good job with this new Klein model, though in my testing text-to-image in distilled flavor is the best:\n\n\n\nðŸ”¹ Sub-second inference on RTX 4090 hardware\n\nðŸ”¹ 9B parameters matching models 5x its size\n\nðŸ”¹ Step-distilled from 50 â†’ 4 steps, zero quality loss\n\nðŸ”¹ Unified text-to-image + multi-reference editing\n\n\n\nHF Model: black-forest-labs/FLUX.2-klein-base-9B Â· Hugging Face\n\nDetailed testing is here:  [https://youtu.be/j3-vJuVwoWs?si=XPh7\\_ZClL8qoKFhl](https://youtu.be/j3-vJuVwoWs?si=XPh7_ZClL8qoKFhl) ",
      "is_original_content": false,
      "link_flair_text": "LORAS, MODELS, etc  [Fine Tuned]",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qe9xzq/new_flux2_klein_9b_is_insanely_fast/",
      "domain": "self.FluxAI",
      "is_self": true,
      "comments": [
        {
          "id": "nzwgixf",
          "author": "OcelotUseful",
          "text": ">Â fits in ~29GB VRAM",
          "score": 4,
          "created_utc": "2026-01-16 11:14:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzw80h5",
          "author": "Herr_Drosselmeyer",
          "text": "How are you gettin sub 1 second on the 9b? Don't you mean the 4b?",
          "score": 1,
          "created_utc": "2026-01-16 09:59:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvvy12",
          "author": "Sir_McDouche",
          "text": "People really need to stop using that word.",
          "score": -1,
          "created_utc": "2026-01-16 08:07:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03e6gc",
              "author": "alb5357",
              "text": "Insanely?\n\nBecause it's derogatory toward the insane? It's the first I've heard this one.",
              "score": 1,
              "created_utc": "2026-01-17 12:20:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzymp8e",
              "author": "tommyjohn81",
              "text": "People really need to stop being so sensitive",
              "score": 0,
              "created_utc": "2026-01-16 18:01:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzzl9tn",
                  "author": "DankGabrillo",
                  "text": "I think it's time we stop\nChildren, what's that sound?\nEverybody look what's going down",
                  "score": 3,
                  "created_utc": "2026-01-16 20:38:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzxb7a3",
          "author": "Dry_Positive8572",
          "text": "Yeah, but insanely deformed human anatomy as well.",
          "score": 0,
          "created_utc": "2026-01-16 14:26:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qe8sq2",
      "title": "FLux KLEIN: only 13GB VRAM needed! NEW MODEL",
      "subreddit": "FluxAI",
      "url": "https://i.redd.it/f72utk20qndg1.png",
      "author": "Unreal_777",
      "created_utc": "2026-01-16 06:42:54",
      "score": 11,
      "num_comments": 4,
      "upvote_ratio": 0.83,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qe8sq2/flux_klein_only_13gb_vram_needed_new_model/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o00acld",
          "author": "optimisticalish",
          "text": "Works fine and fast on a 3060 12Gb, with GGUF model and clip.",
          "score": 4,
          "created_utc": "2026-01-16 22:38:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o028uoq",
              "author": "Unreal_777",
              "text": "what workflow do you use",
              "score": 1,
              "created_utc": "2026-01-17 06:05:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o02zo1o",
                  "author": "Unreal_777",
                  "text": "Share examples",
                  "score": 1,
                  "created_utc": "2026-01-17 10:11:04",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o02xawi",
          "author": "Rude_Dependent_9843",
          "text": "I use the 9b base and distilled version without any problems on a 12GB 4070 Super. Editing is especially fast.",
          "score": 1,
          "created_utc": "2026-01-17 09:48:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdrz0n",
      "title": "Improved Flux Prompt Dataset - Experimental",
      "subreddit": "FluxAI",
      "url": "https://i.redd.it/41ggp5fa6kdg1.jpeg",
      "author": "stonapzo",
      "created_utc": "2026-01-15 18:44:12",
      "score": 10,
      "num_comments": 3,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qdrz0n/improved_flux_prompt_dataset_experimental/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzsm0tt",
          "author": "nvmax",
          "text": "Am I missing something ?",
          "score": 1,
          "created_utc": "2026-01-15 20:33:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzso15o",
              "author": "jib_reddit",
              "text": "Like any context or idea of what OP is possibly talking about? Yes we are all missing that....",
              "score": 3,
              "created_utc": "2026-01-15 20:42:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o00opb8",
          "author": "SeiferGun",
          "text": "what is this.. can elaborate?",
          "score": 1,
          "created_utc": "2026-01-16 23:56:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdjd8k",
      "title": "esting character consistency with a custom LoRA. Meet Zara Noir. Really impressed with how Flux handles dark ambient lighting and ring textures.",
      "subreddit": "FluxAI",
      "url": "https://i.redd.it/lwos0nmwkidg1.jpeg",
      "author": "Leading-Date-4831",
      "created_utc": "2026-01-15 13:22:39",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 0.71,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "LORAS, MODELS, etc  [Fine Tuned]",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qdjd8k/esting_character_consistency_with_a_custom_lora/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzq3txz",
          "author": "Otherwise-Season-141",
          "text": "Itâ€™s cool. I like the lighting on the back",
          "score": 2,
          "created_utc": "2026-01-15 13:32:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzq4w1f",
          "author": "Leading-Date-4831",
          "text": "thanks. I am trying to make it as realistic as possible. Does anyone have any suggestion ? anything to add or change ?",
          "score": 2,
          "created_utc": "2026-01-15 13:38:32",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1q9hou0",
      "title": "Are there any Lightning LORAs for Kontext?",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/r/FluxAI/comments/1q9hou0/are_there_any_lightning_loras_for_kontext/",
      "author": "beti88",
      "created_utc": "2026-01-10 22:25:38",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 0.83,
      "text": "For Qwen we basically immediately got them, but if there's any for Flux Kontext, I sure can't find them",
      "is_original_content": false,
      "link_flair_text": "Question / Help",
      "permalink": "https://reddit.com/r/FluxAI/comments/1q9hou0/are_there_any_lightning_loras_for_kontext/",
      "domain": "self.FluxAI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qetgr9",
      "title": "I tried some Artstyles inspired by real word photos (Z-Image Turbo vs. Qwen 2512 vs. Qwen 2512 Turbo and Flux2.dev)",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/gallery/1qesgag",
      "author": "Accomplished_Bowl262",
      "created_utc": "2026-01-16 21:55:11",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qetgr9/i_tried_some_artstyles_inspired_by_real_word/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qb4p37",
      "title": "Sugar, spice and nothing nice. Coming soon.",
      "subreddit": "FluxAI",
      "url": "https://www.youtube.com/watch?v=TzXHdUKp2EI",
      "author": "glasswolv",
      "created_utc": "2026-01-12 19:32:43",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.59,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "VIDEO",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qb4p37/sugar_spice_and_nothing_nice_coming_soon/",
      "domain": "youtube.com",
      "is_self": false,
      "comments": []
    }
  ]
}