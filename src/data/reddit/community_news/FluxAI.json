{
  "metadata": {
    "last_updated": "2026-01-22 02:32:43",
    "time_filter": "week",
    "subreddit": "FluxAI",
    "total_items": 15,
    "total_comments": 26,
    "file_size_bytes": 28002
  },
  "items": [
    {
      "id": "1qgi0b5",
      "title": "Honest Comparison: FLUX 2 Klein (4b & 9b) vs. Z-image Turbo",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/gallery/1qgi0b5",
      "author": "Jaded_Proposal_590",
      "created_utc": "2026-01-18 19:34:25",
      "score": 44,
      "num_comments": 12,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qgi0b5/honest_comparison_flux_2_klein_4b_9b_vs_zimage/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0ct0sq",
          "author": "gtderEvan",
          "text": "My impression is much better prompt adherence on Klein 9B.",
          "score": 9,
          "created_utc": "2026-01-18 20:46:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cx306",
              "author": "Jaded_Proposal_590",
              "text": "In fact, it is. However, I like the visual style better from 4b, as if it follows it better. Overall, 9b behaves much better when editing images",
              "score": 2,
              "created_utc": "2026-01-18 21:09:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0lst39",
          "author": "i-mortal_Raja",
          "text": "Z turbo always looks cool",
          "score": 3,
          "created_utc": "2026-01-20 03:43:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ha9rd",
          "author": "zthrx",
          "text": "might share wf?",
          "score": 2,
          "created_utc": "2026-01-19 14:23:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0hcu30",
              "author": "Jaded_Proposal_590",
              "text": "It's a default wf txt2img flux 2 Klein with little changes for my comfortable. But i can share if you need",
              "score": 3,
              "created_utc": "2026-01-19 14:36:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0pv515",
                  "author": "NoceMoscata666",
                  "text": "same, if you can",
                  "score": 1,
                  "created_utc": "2026-01-20 19:11:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0gnfv0",
          "author": "barseghyanartur",
          "text": "Do you have also inference times (how long did it take to generate the image, assuming you ran this lically)?",
          "score": 1,
          "created_utc": "2026-01-19 11:56:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0gvxtf",
              "author": "Jaded_Proposal_590",
              "text": "**RTX3090**\n\nResolution for all: 1280 x 1920.\n\n* **Flux 2 klein 9b:**\n\n1. Steps: 4\n\nTotal speed: 2.85s/it, 17s/img\n\n2. Steps: 8\n\nTotal speed: 3s/it, 32s/img\n\n\n\n* **Flux 2 klein 4b:**\n\n1. Steps: 4\n\nTotal speed: 1.3s/it, 8s/img\n\n2. Steps: 8\n\nTotal speed: 1.6s/it, 15s/img\n\n\n\n* **Z-image:**\n\n1. Steps: 8\n\nTotal speed: 2.8s/it, 26s/img",
              "score": 3,
              "created_utc": "2026-01-19 12:59:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0t1fo4",
          "author": "tarkansarim",
          "text": "I gotta say Flux Klein was a surprise. It looks good!",
          "score": 1,
          "created_utc": "2026-01-21 05:28:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vi970",
          "author": "kayteee1995",
          "text": "what a complicated prompt",
          "score": 1,
          "created_utc": "2026-01-21 16:01:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdzi7n",
      "title": "I made a 1-click app to run FLUX.2-klein on M-series Macs (8GB+ unified memory)",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/r/FluxAI/comments/1qdzi7n/i_made_a_1click_app_to_run_flux2klein_on_mseries/",
      "author": "akroletsgo",
      "created_utc": "2026-01-15 23:28:59",
      "score": 33,
      "num_comments": 4,
      "upvote_ratio": 0.98,
      "text": "Been working on making fast image generation accessible on Apple Silicon. Just open-sourced it.\n\nWhat it does:\n\n\\- Text-to-image generation\n\n\\- Image-to-image editing (upload a photo, describe changes)\n\n\\- Runs locally on your Mac - no cloud, no API keys\n\nModels included:\n\n\\- FLUX.2-klein-4B (Int8 quantized) - 8GB, great quality, supports img2img\n\n\\- Z-Image Turbo (Quantized) - 3.5GB, fastest option\n\n\\- Z-Image Turbo (Full) - LoRA support\n\nHow fast?\n\n\\- \\~8 seconds for 512x512 on Apple Silicon\n\n\\- 4 steps default (it's distilled)\n\nRequirements:\n\n\\- M1/M2/M3/M4 Mac with 16GB+ RAM (8GB works but tight)\n\n\\- macOS\n\nTo run:\n\n1. Clone the repo\n\n2. Double-click Launch.command\n\n3. First run auto-installs everything\n\n4. Browser opens with the UI\n\nThat's it. No conda, no manual pip installs, no fighting with dependencies.\n\nGitHub: [https://github.com/newideas99/ultra-fast-image-gen](https://github.com/newideas99/ultra-fast-image-gen)\n\nThe FLUX.2-klein model is int8 quantized (I uploaded it to HuggingFace), which cuts memory from \\~22GB to \\~8GB while keeping quality nearly identical.\n\nWould love feedback. ",
      "is_original_content": false,
      "link_flair_text": "Resources/updates",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qdzi7n/i_made_a_1click_app_to_run_flux2klein_on_mseries/",
      "domain": "self.FluxAI",
      "is_self": true,
      "comments": [
        {
          "id": "o0dfhzn",
          "author": "PalpableTension",
          "text": "This works really well on my M4 Pro, setup couldn't have been simpler. I've gotten errors a couple times trying to generate after switching between models, but reloading launch.command always fixes it.",
          "score": 2,
          "created_utc": "2026-01-18 22:41:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzww7it",
          "author": "hydargo101",
          "text": "Installation worked fine on my M4 Pro, the gradio UI also works great (just tested flux2 klein/ZIT quantized. Nice job. Note : the UI gives an error message after each image edit, but it goes away once I reload the image.",
          "score": 1,
          "created_utc": "2026-01-16 13:05:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzx4p6m",
              "author": "akroletsgo",
              "text": "fixing!",
              "score": 1,
              "created_utc": "2026-01-16 13:52:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qebkd6",
      "title": "Different Facial Expressions from One Face Using FLUX.2 [klein] 9B",
      "subreddit": "FluxAI",
      "url": "https://i.redd.it/de2u02bckodg1.png",
      "author": "Substantial-Fee-3910",
      "created_utc": "2026-01-16 09:30:56",
      "score": 30,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Flux KLEIN",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qebkd6/different_facial_expressions_from_one_face_using/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o02ywf5",
          "author": "Pase4nik_Fedot",
          "text": "We need to wait for realistic anti-plastic LoRa)",
          "score": 1,
          "created_utc": "2026-01-17 10:03:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qe9xzq",
      "title": "New FLUX.2 [Klein] 9B is INSANELY Fast",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/r/FluxAI/comments/1qe9xzq/new_flux2_klein_9b_is_insanely_fast/",
      "author": "Lopsided_Dot_4557",
      "created_utc": "2026-01-16 07:49:47",
      "score": 22,
      "num_comments": 10,
      "upvote_ratio": 0.92,
      "text": "BFL is has done a good job with this new Klein model, though in my testing text-to-image in distilled flavor is the best:\n\n\n\nðŸ”¹ Sub-second inference on RTX 4090 hardware\n\nðŸ”¹ 9B parameters matching models 5x its size\n\nðŸ”¹ Step-distilled from 50 â†’ 4 steps, zero quality loss\n\nðŸ”¹ Unified text-to-image + multi-reference editing\n\n\n\nHF Model: black-forest-labs/FLUX.2-klein-base-9B Â· Hugging Face\n\nDetailed testing is here:  [https://youtu.be/j3-vJuVwoWs?si=XPh7\\_ZClL8qoKFhl](https://youtu.be/j3-vJuVwoWs?si=XPh7_ZClL8qoKFhl) ",
      "is_original_content": false,
      "link_flair_text": "LORAS, MODELS, etc  [Fine Tuned]",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qe9xzq/new_flux2_klein_9b_is_insanely_fast/",
      "domain": "self.FluxAI",
      "is_self": true,
      "comments": [
        {
          "id": "nzwgixf",
          "author": "OcelotUseful",
          "text": ">Â fits in ~29GB VRAM",
          "score": 4,
          "created_utc": "2026-01-16 11:14:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0e6js9",
              "author": "eagledoto",
              "text": "Works like a charm on my rtx 2060 12gb too, 9b distilled v with qwen 9b text encoder",
              "score": 1,
              "created_utc": "2026-01-19 01:01:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzw80h5",
          "author": "Herr_Drosselmeyer",
          "text": "How are you gettin sub 1 second on the 9b? Don't you mean the 4b?",
          "score": 2,
          "created_utc": "2026-01-16 09:59:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvvy12",
          "author": "Sir_McDouche",
          "text": "People really need to stop using that word.",
          "score": -2,
          "created_utc": "2026-01-16 08:07:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o03e6gc",
              "author": "alb5357",
              "text": "Insanely?\n\nBecause it's derogatory toward the insane? It's the first I've heard this one.",
              "score": 1,
              "created_utc": "2026-01-17 12:20:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o06d5me",
              "author": "wesarnquist",
              "text": "What, \"fast\"? But that's an INSANELY good word!",
              "score": 1,
              "created_utc": "2026-01-17 21:29:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzymp8e",
              "author": "tommyjohn81",
              "text": "People really need to stop being so sensitive",
              "score": 1,
              "created_utc": "2026-01-16 18:01:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzzl9tn",
                  "author": "DankGabrillo",
                  "text": "I think it's time we stop\nChildren, what's that sound?\nEverybody look what's going down",
                  "score": 6,
                  "created_utc": "2026-01-16 20:38:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzxb7a3",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 0,
          "created_utc": "2026-01-16 14:26:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o06dj7o",
              "author": "wesarnquist",
              "text": "My hunch is that this will be solved through fine-tuning",
              "score": 1,
              "created_utc": "2026-01-17 21:31:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qe8sq2",
      "title": "FLux KLEIN: only 13GB VRAM needed! NEW MODEL",
      "subreddit": "FluxAI",
      "url": "https://i.redd.it/f72utk20qndg1.png",
      "author": "Unreal_777",
      "created_utc": "2026-01-16 06:42:54",
      "score": 15,
      "num_comments": 6,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qe8sq2/flux_klein_only_13gb_vram_needed_new_model/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o00acld",
          "author": "optimisticalish",
          "text": "Works fine and fast on a 3060 12Gb, with GGUF model and clip.",
          "score": 6,
          "created_utc": "2026-01-16 22:38:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o028uoq",
              "author": "Unreal_777",
              "text": "what workflow do you use",
              "score": 2,
              "created_utc": "2026-01-17 06:05:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o02zo1o",
                  "author": "Unreal_777",
                  "text": "Share examples",
                  "score": 2,
                  "created_utc": "2026-01-17 10:11:04",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o02xawi",
          "author": "Rude_Dependent_9843",
          "text": "I use the 9b base and distilled version without any problems on a 12GB 4070 Super. Editing is especially fast.",
          "score": 2,
          "created_utc": "2026-01-17 09:48:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0q50nm",
              "author": "Ant_6431",
              "text": "12gb here. Works just fine. No gguf.",
              "score": 2,
              "created_utc": "2026-01-20 19:56:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfa5m4",
      "title": "Flux 2 vs Nano Banana Pro vs FLUX.2 [klein] â€” Portrait Comparison",
      "subreddit": "FluxAI",
      "url": "https://i.redd.it/6kxcst0o2wdg1.jpeg",
      "author": "Substantial-Fee-3910",
      "created_utc": "2026-01-17 10:45:33",
      "score": 14,
      "num_comments": 3,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qfa5m4/flux_2_vs_nano_banana_pro_vs_flux2_klein_portrait/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o07z6cf",
          "author": "NES64Super",
          "text": "Good thing loras exist.",
          "score": 3,
          "created_utc": "2026-01-18 02:30:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09066u",
          "author": "pix_l",
          "text": "Add \"schnell\" and show him sprinting :D",
          "score": 3,
          "created_utc": "2026-01-18 06:32:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o091u2p",
          "author": "Sir_McDouche",
          "text": "FLUX still plastic as hell. Even the Pro/Max version is pretty bad. Banana is king.",
          "score": 1,
          "created_utc": "2026-01-18 06:46:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdrz0n",
      "title": "Improved Flux Prompt Dataset - Experimental",
      "subreddit": "FluxAI",
      "url": "https://i.redd.it/41ggp5fa6kdg1.jpeg",
      "author": "stonapzo",
      "created_utc": "2026-01-15 18:44:12",
      "score": 11,
      "num_comments": 3,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qdrz0n/improved_flux_prompt_dataset_experimental/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzsm0tt",
          "author": "nvmax",
          "text": "Am I missing something ?",
          "score": 1,
          "created_utc": "2026-01-15 20:33:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzso15o",
              "author": "jib_reddit",
              "text": "Like any context or idea of what OP is possibly talking about? Yes we are all missing that....",
              "score": 3,
              "created_utc": "2026-01-15 20:42:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o00opb8",
          "author": "SeiferGun",
          "text": "what is this.. can elaborate?",
          "score": 1,
          "created_utc": "2026-01-16 23:56:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qg9afx",
      "title": "ComfyUI Tutorial: Flux. 2 Klein A GAME CHANGER For AI Generation & Editing",
      "subreddit": "FluxAI",
      "url": "https://youtu.be/57ppu1WmqLU",
      "author": "cgpixel23",
      "created_utc": "2026-01-18 14:00:00",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorials/Guides ",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qg9afx/comfyui_tutorial_flux_2_klein_a_game_changer_for/",
      "domain": "youtu.be",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qfmdnn",
      "title": "Compared Quality and Speed Difference (with CUDA 13 & Sage Attention) of BF16 vs GGUF Q8 vs FP8 Scaled vs NVFP4 for Z Image Turbo, FLUX Dev, FLUX SRPO, FLUX Kontext, FLUX 2 - Full 4K step by step tutorial also published",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/gallery/1qfmdnn",
      "author": "CeFurkan",
      "created_utc": "2026-01-17 19:27:14",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.69,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qfmdnn/compared_quality_and_speed_difference_with_cuda/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o05p6dv",
          "author": "CeFurkan",
          "text": "**Full 4K tutorial :**Â [**https://youtu.be/XDzspWgnzxI**](https://youtu.be/XDzspWgnzxI)\n\n[**BF16 vs GGUF, FP8 Scaled, NVFP4 Speed & Quality Compared + ComfyUI CUDA 13 Gains + FLUX 2 Klein 9B**](https://youtu.be/XDzspWgnzxI)\n\n**Check above full 4K tutorial to learn more and see uncompressed original quality and size images**\n\nhttps://preview.redd.it/dz8485exnydg1.jpeg?width=2048&format=pjpg&auto=webp&s=d4058c2c2d80292b13a5ab9a71c9d53052a35358",
          "score": 0,
          "created_utc": "2026-01-17 19:27:41",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qgo0ra",
      "title": "Need some guidance please! Which Flux model for an RTX 4070 12gb",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/r/FluxAI/comments/1qgo0ra/need_some_guidance_please_which_flux_model_for_an/",
      "author": "lafoxy64",
      "created_utc": "2026-01-18 23:38:13",
      "score": 6,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "greetings everyone, im new here, i want to apologize in advance for my ignorance. If a kind soul could bare with me and guide me a little bit here.  \nIm kinda new to local AI, ive played around with Automatic1111 and SDXL models about a year ago but thats it.\n\nright now i have an RTX 4070 12gb with a Ryzen 7 5700X and 32gb of ram on Linux CachyOS and i wish to use ComfyUI to try some image generation and later on some video generation.  \nI suppose my 4070 is far from enough to have professional results but id like to find a way to get the best possible results with my hardware, at least enough to learn, i really want to learn, you have no idea how much but there is SO MUCH that its a bit overwhelming and i dont know where to start.\n\nIve checked some models and most apparently need ridiculous amounts of vram, could someone point me in the direction of a model that i could run on my hardware?\n\nIve been reading a lot, ive found some named \"**FLUX.2 \\[klein\\]\"** but i think it needs around 13gb of vram. Is there any way i could fit it in my 4070? or is there any other similar model that i can run?\n\nalso if you could send me a link to a very detailed guide about models, workflows and that kind of stuff for dummies? im so lost lol and everytime i try to learn there is so much incomplete or advanced information that it makes my head spin. Besides english is not my first language, still im ok with the info being in english, in fact i need it to be in english but please, PLEASE someone guide me a little bit!\n\nthanks in advance to anyone willing to read this and help me, thank you very much.",
      "is_original_content": false,
      "link_flair_text": "Question / Help",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qgo0ra/need_some_guidance_please_which_flux_model_for_an/",
      "domain": "self.FluxAI",
      "is_self": true,
      "comments": [
        {
          "id": "o0ol7hx",
          "author": "lafoxy64",
          "text": "oh well, i guess not. :(",
          "score": 1,
          "created_utc": "2026-01-20 15:40:55",
          "is_submitter": true,
          "replies": [
            {
              "id": "o0q4mvt",
              "author": "Ant_6431",
              "text": "Comfy workflow klein fp8 distilled works perfect",
              "score": 1,
              "created_utc": "2026-01-20 19:55:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0rfaby",
          "author": "MushroomCharacter411",
          "text": "Most models will work fine, just stick to the FP8 versions if you expect the whole thing to fit in VRAM. If the FP16 version is all you can get, it will be much slower but still work. I don't recommend going to FP4, because that requires a change of format from .safetensor to .gguf and none of the LoRAs you're already used to will work properly.\n\nBasically, just use what RTX 3060 owners use because those also have 12 GB of VRAM. You'll just be a bit faster than the 3060, but the selection of model and quantization is pretty much the same.",
          "score": 1,
          "created_utc": "2026-01-20 23:41:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0te116",
          "author": "RalFingerLP",
          "text": "9b base worked for me on my 4070Ti with offloading into RAM (16gb)",
          "score": 1,
          "created_utc": "2026-01-21 07:11:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdjd8k",
      "title": "esting character consistency with a custom LoRA. Meet Zara Noir. Really impressed with how Flux handles dark ambient lighting and ring textures.",
      "subreddit": "FluxAI",
      "url": "https://i.redd.it/lwos0nmwkidg1.jpeg",
      "author": "Leading-Date-4831",
      "created_utc": "2026-01-15 13:22:39",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 0.69,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "LORAS, MODELS, etc  [Fine Tuned]",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qdjd8k/esting_character_consistency_with_a_custom_lora/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzq3txz",
          "author": "Otherwise-Season-141",
          "text": "Itâ€™s cool. I like the lighting on the back",
          "score": 2,
          "created_utc": "2026-01-15 13:32:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzq4w1f",
          "author": "Leading-Date-4831",
          "text": "thanks. I am trying to make it as realistic as possible. Does anyone have any suggestion ? anything to add or change ?",
          "score": 2,
          "created_utc": "2026-01-15 13:38:32",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qetgr9",
      "title": "I tried some Artstyles inspired by real word photos (Z-Image Turbo vs. Qwen 2512 vs. Qwen 2512 Turbo and Flux2.dev)",
      "subreddit": "FluxAI",
      "url": "https://www.reddit.com/gallery/1qesgag",
      "author": "Accomplished_Bowl262",
      "created_utc": "2026-01-16 21:55:11",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Comparison",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qetgr9/i_tried_some_artstyles_inspired_by_real_word/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qfmdgs",
      "title": "Help needed: Flux model giving grey output",
      "subreddit": "FluxAI",
      "url": "https://i.redd.it/k0cw25vulydg1.png",
      "author": "Acceptable-Load2437",
      "created_utc": "2026-01-17 19:27:01",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Question / Help",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qfmdgs/help_needed_flux_model_giving_grey_output/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qgxz0h",
      "title": "quick (trivial) tip for outpainting with flux.2 klein",
      "subreddit": "FluxAI",
      "url": "https://i.redd.it/r7dp6p1p48eg1.png",
      "author": "Unreal_777",
      "created_utc": "2026-01-19 07:43:29",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Flux KLEIN",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qgxz0h/quick_trivial_tip_for_outpainting_with_flux2_klein/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qdpjcw",
      "title": "Product Video",
      "subreddit": "FluxAI",
      "url": "https://v.redd.it/lph1jeowqjdg1",
      "author": "vyro-llc",
      "created_utc": "2026-01-15 17:18:13",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.67,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "VIDEO",
      "permalink": "https://reddit.com/r/FluxAI/comments/1qdpjcw/product_video/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": []
    }
  ]
}