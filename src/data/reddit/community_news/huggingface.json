{
  "metadata": {
    "last_updated": "2026-01-04 01:09:59",
    "time_filter": "week",
    "subreddit": "huggingface",
    "total_items": 5,
    "total_comments": 3,
    "file_size_bytes": 7865
  },
  "items": [
    {
      "id": "1purg10",
      "title": "Show off your Hugging Face activity on your GitHub profile!",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1purg10/show_off_your_hugging_face_activity_on_your/",
      "author": "GlitteringFootball34",
      "created_utc": "2025-12-24 16:36:27",
      "score": 5,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "Hey everyone! üëã I built a tool called **hf-grass**. It generates a GitHub-style contribution heatmap (grass) based on your Hugging Face activity.\n\nIt produces an SVG that you can easily embed in your GitHub README. It also comes with a GitHub Actions workflow, so it updates automatically every day!\n\n**Wishing everyone a Merry Christmas! üéÑ‚ú®**\n\nhttps://preview.redd.it/1aommmehj69g1.png?width=1352&format=png&auto=webp&s=ee67f2147ab482119cd5a994f7e243476f86b08d\n\n[https://github.com/kbsooo/hf-grass](https://github.com/kbsooo/hf-grass)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1purg10/show_off_your_hugging_face_activity_on_your/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": [
        {
          "id": "nvqnuog",
          "author": "Duhbeed",
          "text": "Interesting, thanks for sharing!",
          "score": 1,
          "created_utc": "2025-12-24 16:42:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pz0wid",
      "title": "CLI tool to use transformer and diffuser models",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1pz0wid/cli_tool_to_use_transformer_and_diffuser_models/",
      "author": "zashboy",
      "created_utc": "2025-12-29 22:54:01",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "At some point over the summer, I wanted to try out some image and video models from HF locally, but I didn't want to open up my IDE and hardcode my prompts each time. I've been looking for tools that would give me an Ollama CLI-like experience, but I couldn't find anything like that, so I started building something for myself. It works with the models I'm interested in and more. \n\nSince then, I haven't checked if there are any similar or better tools because this one meets my needs, but maybe there's something new out there already. I'm just sharing it in case it's useful to anyone else for quickly running image-to-image, text-to-image, text-to-video, text-to-speech and speech-to-text models locally. Definitely, if you have AMD GPUs like I do.\n\n[https://github.com/zb-ss/hftool](https://github.com/zb-ss/hftool)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1pz0wid/cli_tool_to_use_transformer_and_diffuser_models/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q0fjqc",
      "title": "I had gemini make a picture of HuggingFace. By breaking down the possible meanings of the term hugging face and then had it make a picture.",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1q0fjqc/i_had_gemini_make_a_picture_of_huggingface_by/",
      "author": "Seninut",
      "created_utc": "2025-12-31 15:25:36",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "https://preview.redd.it/cui90w415kag1.png?width=1024&format=png&auto=webp&s=20af3698faae8806ddb8329857f7827e988ba10b\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1q0fjqc/i_had_gemini_make_a_picture_of_huggingface_by/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1pw4s86",
      "title": "Fine-Tuned Model for Legal-tech Minimal Hallucination Summarization",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1pw4s86/finetuned_model_for_legaltech_minimal/",
      "author": "ThatParking526",
      "created_utc": "2025-12-26 13:52:20",
      "score": 3,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "Hey all,\n\nI‚Äôve been exploring how transformer models handle legal text and noticed that most open summarizers miss specificity; they simplify too much. That led me to build¬†**LexiBrief**, a fine-tuned Google FLAN-T5 model trained on¬†*BillSum*¬†using QLoRA for efficiency.\n\n[https://huggingface.co/AryanT11/lexibrief-legal-summarizer](https://huggingface.co/AryanT11/lexibrief-legal-summarizer)\n\nIt generates concise, clause-preserving summaries of legal and policy documents, kind of like a TL;DR that still respects the law‚Äôs intent.\n\nMetrics:\n\n* ROUGE-L F1:¬†**0.72**\n* BERTScore (F1):¬†**0.86**\n* Hallucinations (FactCC):¬†**‚Üì35% vs base FLAN-T5**\n\nIt‚Äôs up on Hugging Face if you want to play around with it. I‚Äôd love feedback from anyone who‚Äôs worked on factual summarization or domain-specific LLM tuning.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1pw4s86/finetuned_model_for_legaltech_minimal/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": [
        {
          "id": "nw11pno",
          "author": "true-though",
          "text": "Thank you, great job!",
          "score": 1,
          "created_utc": "2025-12-26 14:37:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pyv0vf",
      "title": "Reachy Mini IDE Prototype",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1pyv0vf/reachy_mini_ide_prototype/",
      "author": "Creative-Scene-6743",
      "created_utc": "2025-12-29 19:06:57",
      "score": 3,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "I received my **Reachy Mini**, and instead of sticking with the usual ‚ÄúSSH-terminal juggling‚Äù workflow, I wanted to see if I could configure something that feels closer to modern day IDE workflow using VS Code as a base.\n\nThe goal for this IDE:  \n \\- Remote development directly on Reachy Mini  \n \\- Run programs inside Reachy Mini‚Äôs App Python environement   \n \\- Full Python debugging support  \n \\- Primitive, but realtime performance monitoring \n\nI ended up combining VS Code with [Remote SSH](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-ssh), [SSH monitor](https://marketplace.visualstudio.com/items?itemName=femtowork.ssh-remote-monitor) and installation of [Python](https://marketplace.visualstudio.com/items?itemName=ms-python.python) in Remote Extension Host to enable debugging. Full step-by-step guide availlable [here](https://tobrun.github.io/blog/reachy-mini-ide/) \n\n[Remote Python Debugging](https://preview.redd.it/c6m4olwgy6ag1.png?width=2384&format=png&auto=webp&s=f02c52af4d71dd3127a758c44cbf590925596c7b)\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1pyv0vf/reachy_mini_ide_prototype/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": [
        {
          "id": "nxdbdt9",
          "author": "clem59480",
          "text": "very cool",
          "score": 1,
          "created_utc": "2026-01-03 02:42:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}