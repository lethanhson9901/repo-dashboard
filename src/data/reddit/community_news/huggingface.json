{
  "metadata": {
    "last_updated": "2026-02-19 09:09:59",
    "time_filter": "week",
    "subreddit": "huggingface",
    "total_items": 5,
    "total_comments": 6,
    "file_size_bytes": 7857
  },
  "items": [
    {
      "id": "1r4z9ax",
      "title": "What are your best prompts to benchmark an ai",
      "subreddit": "huggingface",
      "url": "/r/GeminiAI/comments/1r4z72m/what_are_your_best_prompts_to_benchmark_an_ai/",
      "author": "Naive_Bug4797",
      "created_utc": "2026-02-14 23:29:06",
      "score": 5,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1r4z9ax/what_are_your_best_prompts_to_benchmark_an_ai/",
      "domain": "",
      "is_self": false,
      "comments": [
        {
          "id": "o5n37bx",
          "author": "neil_555",
          "text": "Asking for \"A detailed explanation of the tree body problem\" is a good quick benchmark question.",
          "score": 1,
          "created_utc": "2026-02-16 06:24:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7zeg9",
      "title": "GLONET just dropped on",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1r7zeg9/glonet_just_dropped_on/",
      "author": "Ill_Ranger_8547",
      "created_utc": "2026-02-18 10:24:43",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.86,
      "text": "Just came across this and thought it was worth sharing — GLONET is now available on HuggingFace.\n\nIt’s a deep learning model for global ocean forecasting that runs in less than 3 seconds. Trained on 30 years of ocean reanalysis data, it can predict oceanographic variables (temperature, salinity, currents…) at a global scale.\n\nNot gonna lie, this might just make traditional physics-based ocean models obsolete\n\nhttps://huggingface.co/mercator-ocean/GLONET",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1r7zeg9/glonet_just_dropped_on/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1r4obt4",
      "title": "Data Search Engine for $0 using Rust, Hugging Face, and the Databricks Free Tier (Community Edition)",
      "subreddit": "huggingface",
      "url": "/r/databricks/comments/1r4mtr5/data_search_engine_for_0_using_rust_hugging_face/",
      "author": "poinT92",
      "created_utc": "2026-02-14 16:04:05",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1r4obt4/data_search_engine_for_0_using_rust_hugging_face/",
      "domain": "",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r8544v",
      "title": "We built a golf forecasting model that outperforms GPT‑5; model and dataset are open-sourced on Hugging Face",
      "subreddit": "huggingface",
      "url": "/r/LocalLLaMA/comments/1r853l6/we_built_a_golf_forecasting_model_that/",
      "author": "LightningRodLabs",
      "created_utc": "2026-02-18 14:55:17",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1r8544v/we_built_a_golf_forecasting_model_that/",
      "domain": "",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r37qvk",
      "title": "Best uncensored GGUF models",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1r37qvk/best_uncensored_gguf_models/",
      "author": "Ryan_Steele_252",
      "created_utc": "2026-02-12 22:34:56",
      "score": 2,
      "num_comments": 8,
      "upvote_ratio": 0.63,
      "text": "I am looking for the best uncensored GGUF models that a gaming Laptop with a RTX 3050 with 6GB Vram and 32GB DDR5 ram can run.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1r37qvk/best_uncensored_gguf_models/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": [
        {
          "id": "o53bmek",
          "author": "IllustriousTown4601",
          "text": "Imma give you some quick advice: go on hugging face and in the search bar, type in UGI leaderboard and click on DontPlanToEnd/UGI-Leaderboard \n\nFrom there you'll see uncensored models and then you just gotta do research from there on which models you can. Hugging face can help if you make an account and put in your setup information like GPU and RAM.",
          "score": 5,
          "created_utc": "2026-02-13 02:02:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dkvf3",
          "author": "neil_555",
          "text": "What do you want to use the model for?",
          "score": 1,
          "created_utc": "2026-02-14 18:10:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5dlbr3",
              "author": "Ryan_Steele_252",
              "text": "Mostly role-playing.",
              "score": 1,
              "created_utc": "2026-02-14 18:12:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5dm4ec",
                  "author": "neil_555",
                  "text": "6GB Vram is a bit small but if your running under windows then your driver should give you some shared GPU memory - probably 16GB in your case)\n\nGive this one a try it's tuned for roleplay ...\n\n[https://huggingface.co/XeyonAI/Mistral-Helcyon-Mercury-12b-v3.2-GGUF](https://huggingface.co/XeyonAI/Mistral-Helcyon-Mercury-12b-v3.2-GGUF)",
                  "score": 1,
                  "created_utc": "2026-02-14 18:16:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5vrapf",
          "author": "Sicarius_The_First",
          "text": "For your vram try my 3b or 4b, should work pretty fast\n\n\nhttps://huggingface.co/collections/SicariusSicariiStuff/most-of-my-models-in-order",
          "score": 1,
          "created_utc": "2026-02-17 15:41:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63igx4",
          "author": "stonecannon",
          "text": "i'd recommend checking out the Dirty\\_Shirley\\_writer family:\n\n[https://huggingface.co/models?library=gguf&sort=trending&search=dirty+shirley+writer](https://huggingface.co/models?library=gguf&sort=trending&search=dirty+shirley+writer)\n\nit includes v1, v2 v3 and v4 -- v1 is my favorite.  you can check out the different quant sizes in the model detail pages.  with your setup, i'd try a Q4\\_K\\_M version first and see how that performs.  if it drags too much, you could try Q3\\_K\\_M, which will probably not be as high quality, but should run in a smaller memory footprint.\n\nconversely, if Q4 runs fine, you could jump up to Q5 and see how that does.",
          "score": 1,
          "created_utc": "2026-02-18 18:20:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5lsj6j",
          "author": "HarjjotSinghh",
          "text": "this llm goldmine awaits your tiny machine - glow up!",
          "score": 0,
          "created_utc": "2026-02-16 00:57:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}