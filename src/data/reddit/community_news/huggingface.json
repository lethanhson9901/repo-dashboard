{
  "metadata": {
    "last_updated": "2026-02-16 03:09:31",
    "time_filter": "week",
    "subreddit": "huggingface",
    "total_items": 1,
    "total_comments": 2,
    "file_size_bytes": 5359
  },
  "items": [
    {
      "id": "1r246g5",
      "title": "Zero-touch anomaly triage on the Epstein corpus(340k+ files sanitized release, not proof) HF Space link",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1r246g5/zerotouch_anomaly_triage_on_the_epstein/",
      "author": "Either_Pound1986",
      "created_utc": "2026-02-11 17:47:37",
      "score": 20,
      "num_comments": 3,
      "upvote_ratio": 0.85,
      "text": "Alright I've tried now two times to post this to reddit and both times it was taken down. I tried datasets and I tried epstein subreddits. Third time is the charm I guess? edit: epstein sub approved post. Just want to be clear. Leaving original text as is. \n\n\nI am not a data scientist. I’m sharing this so people can review the method and outputs directly.\n\nI downloaded the files from DOJ while the zip downloads were still available, and combined dataset 8 + dataset 11.\n\nBefore running the zero-touch pipeline in Colab, I did one preprocessing step:\n\n* converted PDFs to text\n\nWhat I did:\n\n* kept original file names so records can be mapped back to source files\n* kept extracted text as-is\n* did not OCR\n* did not manually clean fragmented text\n* did not add or rewrite content\n\nImportant context:\nA lot of text is fragmented because of how redactions were done in the source material. That noise is in the corpus and still present in my release.\n\nThis is also not just a simple database + keyword search.\nThe pipeline does lexical/statistical passes, embedding passes, clustering, and then anomaly/signal ranking to reduce search space.\n\nWhat “zero-touch” means here:\n\n* pipeline auto-detects input path\n* runs end-to-end without manual cherry-picking during scoring\n\nImportant:\nThis is triage, not proof.\nA high anomaly score means “look here first,” not “this is true” and not “this proves guilt.” NOTE there are false positives, again this is only to collapse possible search space. \n\nPublic release:\n\n* App: [https://huggingface.co/spaces/cjc0013/EpsteinWithAnomScore](https://huggingface.co/spaces/cjc0013/EpsteinWithAnomScore)\n* Dataset: [https://huggingface.co/datasets/cjc0013/EpsteinWithAnomScore/tree/main](https://huggingface.co/datasets/cjc0013/EpsteinWithAnomScore/tree/main)\n* Sanitized top-N file: public_method_sanitized_topN.jsonl\n\nWhat I sanitized in public top-N:\n\n* replaced direct identities with CASE IDs (CASE-000001 to CASE-000250)\n* kept rank, anomaly score, signal count, coarse signal tags, and short context windows\n* added raw_card_sha256 trace hash for integrity\n* removed raw internal hypothesis-card details\n\nZero-touch pipeline snapshot (run log):\n\n* auto-detected input: /content/TEXT\n* hashed files: 342,249\n* read/chunked files: 342,249\n* chunks built: 521,289\n* docs processed: 342,249 (ok=342,249 failed=0 skipped=0)\n* BM25 stats written\n* embeddings generated (BAAI/bge-large-en-v1.5)\n* PCA + KMeans auto-select with guardrails\n* cluster + fused outputs written automatically\n\nSanitized top-N snapshot:\n\n* rows: 250\n* rank range: 1 to 250\n* anomaly score range: 35.525 to 43.636\n* signal count range: 10 to 14\n* common tags:\n\n  * context_shift: 250/250\n  * embedding_outlier: 250/250\n  * entity_density: 250/250\n  * lexical_pressure: 248/250\n  * self_reference: 11/250\n\nHow to view anomaly results:\nGo to the Signal tab in the Hugging Face Space. It should be straightforward, but if anyone wants a quick walkthrough I can post one.\n\nWhy I’m posting this:\n\n* transparency\n* reproducibility\n* faster manual review by collapsing search space\n* clear separation between ranking signals and factual/legal conclusions",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1r246g5/zerotouch_anomaly_triage_on_the_epstein/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": [
        {
          "id": "o534138",
          "author": "ok-painter-1646",
          "text": "Can I have a tldr for what this is?",
          "score": 1,
          "created_utc": "2026-02-13 01:15:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o539cfb",
              "author": "Either_Pound1986",
              "text": "Basically: too many files for humans to read one by one, so I built a sorter. High score = maybe worth a closer look first, not “this is true.” Source text stayed as-is, with original filenames for traceability. \n\nI can provide a more in depth explanation if you want just let me know.",
              "score": 1,
              "created_utc": "2026-02-13 01:48:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5b6lyu",
          "author": "Significant-Crow-974",
          "text": "Excellent work! Well done and a massive Thank you! Heroic work!",
          "score": 1,
          "created_utc": "2026-02-14 08:29:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}