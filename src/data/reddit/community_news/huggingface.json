{
  "metadata": {
    "last_updated": "2026-01-20 02:29:03",
    "time_filter": "week",
    "subreddit": "huggingface",
    "total_items": 5,
    "total_comments": 3,
    "file_size_bytes": 10987
  },
  "items": [
    {
      "id": "1qfth9y",
      "title": "I created new image moderation model",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1qfth9y/i_created_new_image_moderation_model/",
      "author": "DueSpecial1426",
      "created_utc": "2026-01-18 00:19:02",
      "score": 7,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "Sup everyone,\n\nJust wanted to share a project I’ve been grinding on for the past few days. I was tired of those massive, heavy NSFW filters that either eat all your VRAM or are too \"dumb\" to tell the difference between a weirdly lit room and actual explicit content.\n\nSo, I decided to see how far I could push my old **GTX 1060 6GB**. I trained a **ResNet-18** model—nothing revolutionary, but it's incredibly fast (about 5ms per image) and perfect for real-time moderation in things like Telegram/Discord bots or small websites.\n\n**The results:** Hit **99.44%** accuracy on the final test.\n\nThe coolest part for me was the fine-tuning. I spent extra time \"teaching\" the model to handle tricky cases—like flat vector illustrations, people in complex outfits, or those weird beige/skin-tone backgrounds that usually trip up simpler filters.\n\n**Specs:**\n\n**Architecture:** ResNet-18 (lightweight & efficient). \n\n**Training:** 10 epochs of trial and error.\n\nI’m an independent dev from Russia, just building stuff for fun and profit. If you need a solid, fast moderator that doesn't need a server farm to run, feel free to grab it.\n\n**Links:**\n\n**Model:** [najicreator90856/is-it-nsfw\\_ai-moderator](https://huggingface.co/najicreator90856/is-it-nsfw_ai-moderator) \n\n**Demo:** [Try it here (Gradio)](https://huggingface.co/spaces/najicreator90856/is-it-nsfw-demo)\n\nIf this saves you some work or helps your project, I’ve put my donation links (crypto/DonationAlerts) in the model card. Or just drop a star on HF, that’s also dope.\n\nPeace out! ✌️",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qfth9y/i_created_new_image_moderation_model/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": [
        {
          "id": "o07ms9q",
          "author": "Smergmerg432",
          "text": "Nice! :)",
          "score": 1,
          "created_utc": "2026-01-18 01:23:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08q17v",
              "author": "DueSpecial1426",
              "text": "Thank you)",
              "score": 1,
              "created_utc": "2026-01-18 05:13:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o08mljh",
          "author": "ResultKey6879",
          "text": "Cool, willing to share any insight into datasets used for training?",
          "score": 1,
          "created_utc": "2026-01-18 04:49:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08pzq1",
              "author": "DueSpecial1426",
              "text": "cali72mero/nsfw\\_detect (Hentai) and Xjan/PICTURES\\_X\\_SETS (Real) against SFW shots from kkcosmos/instagram-images",
              "score": 2,
              "created_utc": "2026-01-18 05:12:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qebso3",
      "title": "Different Facial Expressions from One Face Using FLUX.2 [klein] 9B",
      "subreddit": "huggingface",
      "url": "https://i.redd.it/de2u02bckodg1.png",
      "author": "Substantial-Fee-3910",
      "created_utc": "2026-01-16 09:45:32",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qebso3/different_facial_expressions_from_one_face_using/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qgs94h",
      "title": "MedGemma hosting + fine-tuning: what are you using and what GPU should I pick?",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1qgs94h/medgemma_hosting_finetuning_what_are_you_using/",
      "author": "duku-27",
      "created_utc": "2026-01-19 02:48:59",
      "score": 4,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I’m evaluating MedGemma (1.5) and trying to decide the most cost-effective way to run it.\n\nI first tried Vertex AI / Model Garden, but the always-on endpoint pricing caught me off guard (idle costs added up quickly). Now I’m reconsidering the whole approach and want to learn from people who’ve actually shipped or done serious testing.\n\nQuestions:\n\n1.\tHosting: Are you running MedGemma on your own GPU server or using a managed/serverless GPU setup\n\nIf self-hosting: which provider are you on (RunPod, Vast, Lambda, Paperspace, etc.) and why?\n\nIf managed: any setup that truly scales to zero?\n\n2.Inference stack: vLLM vs TGI vs plain Transformers what’s working best for MedGemma 1.5 (4B and/or 27B)?\n\n3.Quantization: What GGUF / AWQ / GPTQ / 4-bit approach is giving you the best balance of quality and speed?\n\n4.Fine-tuning: Did you do LoRA / QLoRA? If yes:\n\ndataset size (ballpark)\n\ntraining time + GPU\n\nmeasurable gains vs strong prompting + structured output\n\n5.GPU recommendation: If I just want a sane, cost-efficient setup:\n\nIs 4B fine on a single L4/4090?\n\nWhat do you recommend for 27B (A100? multi-GPU?) and is it worth it vs sticking to 4B?\n\nI’m mainly optimizing for: predictable costs, decent latency, and a setup that doesn’t require babysitting. Any real-world numbers (VRAM use, tokens/sec, monthly cost) would be extremely helpful.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qgs94h/medgemma_hosting_finetuning_what_are_you_using/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": [
        {
          "id": "o0ev0vw",
          "author": "3Salad",
          "text": "Is this for the Google x Kaggle competition?",
          "score": 2,
          "created_utc": "2026-01-19 03:15:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0f9xf3",
              "author": "duku-27",
              "text": "No, Is there any competition?",
              "score": 2,
              "created_utc": "2026-01-19 04:49:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qd8dza",
      "title": "Built a quiet safety-first app from lived experience — looking for honest feedback (not promotion)",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1qd8dza/built_a_quiet_safetyfirst_app_from_lived/",
      "author": "blazedinfinity",
      "created_utc": "2026-01-15 03:19:04",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.81,
      "text": "I’m sharing this carefully and with respect.\n\nI built a small Android app called MINHA based on my own lived experience with long cycles of sobriety, relapse, and medical consequences. \nThis is not a motivation app, not a tracker, not therapy, and not a replacement for professional help.\n\nMINHA does one thing only:\nIt slows a person down during risky moments using calm language, restraint, and friction. No streaks, no dopamine, no encouragement to “push through.”\n\nBefore releasing it publicly, I’m looking for 3–5 people who are in recovery, supporting someone in recovery, or working in mental health — to\nsanity-check: the language (does anything feel unsafe or wrong?)\nthe flow during moments of distress\nwhat should not exist in such an app\n\nI am not asking anyone to download or promote it publicly.\n\nPrivate feedback — including “don’t release this” — is genuinely welcome.\n\nIf this resonates, please comment or DM.\n\nIf not, that’s completely fine too.\nThank you for reading.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qd8dza/built_a_quiet_safetyfirst_app_from_lived/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qc49jl",
      "title": "Curious ablation: GPT-like LM trained with *frozen* 16‑dim *binary* token-ID embeddings (n_embed=16) It still learns end-to-end and generates coherent text.",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1qc49jl/curious_ablation_gptlike_lm_trained_with_frozen/",
      "author": "AVBochkov",
      "created_utc": "2026-01-13 21:40:05",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.8,
      "text": "Curious, fully reproducible result: I trained a GPT-like decoder-only Transformer whose entire input embedding table is **frozen** and replaced with a **16‑dimensional binary token-ID code** (values are strictly 0/1) — **this is not 16-bit quantization**.\n\nEven without trainable or semantically-initialized token embeddings, the model still trains end-to-end and can generate non-trivial text.\n\n**Key details**\n\n* `vocab_size = 65536`, `n_embed = 16` (since `2^16 = 65536`, the code uniquely identifies each token)\n* deterministic expansion `16 → d_model=1024` via `repeat_interleave` (`scale = 64`)\n* the full frozen embedding table is published (`embeddings.txt`) for auditability\n\nRepro note + verification script:  \n  \n[https://huggingface.co/blog/Bochkov/emergent-semantics-beyond-token-embeddings](https://huggingface.co/blog/Bochkov/emergent-semantics-beyond-token-embeddings)\n\nModel repo:  \n  \n[https://huggingface.co/Bochkov/emergent-semantics-model-16-bit-269m](https://huggingface.co/Bochkov/emergent-semantics-model-16-bit-269m)\n\nThe broader question is **where semantic structure emerges** in decoder-only Transformers when the input embedding layer is not trained and does not explicitly encode semantics.\n\n\n\nhttps://preview.redd.it/nhmy5ekqr6dg1.png?width=1590&format=png&auto=webp&s=042a3443e89ec31b0c7b0d16e178c26ba1386dfb\n\nLicense: Apache-2.0",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qc49jl/curious_ablation_gptlike_lm_trained_with_frozen/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": []
    }
  ]
}