{
  "metadata": {
    "last_updated": "2026-01-24 16:49:57",
    "time_filter": "week",
    "subreddit": "huggingface",
    "total_items": 5,
    "total_comments": 5,
    "file_size_bytes": 9181
  },
  "items": [
    {
      "id": "1qfth9y",
      "title": "I created new image moderation model",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1qfth9y/i_created_new_image_moderation_model/",
      "author": "DueSpecial1426",
      "created_utc": "2026-01-18 00:19:02",
      "score": 8,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "Sup everyone,\n\nJust wanted to share a project I’ve been grinding on for the past few days. I was tired of those massive, heavy NSFW filters that either eat all your VRAM or are too \"dumb\" to tell the difference between a weirdly lit room and actual explicit content.\n\nSo, I decided to see how far I could push my old **GTX 1060 6GB**. I trained a **ResNet-18** model—nothing revolutionary, but it's incredibly fast (about 5ms per image) and perfect for real-time moderation in things like Telegram/Discord bots or small websites.\n\n**The results:** Hit **99.44%** accuracy on the final test.\n\nThe coolest part for me was the fine-tuning. I spent extra time \"teaching\" the model to handle tricky cases—like flat vector illustrations, people in complex outfits, or those weird beige/skin-tone backgrounds that usually trip up simpler filters.\n\n**Specs:**\n\n**Architecture:** ResNet-18 (lightweight & efficient). \n\n**Training:** 10 epochs of trial and error.\n\nI’m an independent dev from Russia, just building stuff for fun and profit. If you need a solid, fast moderator that doesn't need a server farm to run, feel free to grab it.\n\n**Links:**\n\n**Model:** [najicreator90856/is-it-nsfw\\_ai-moderator](https://huggingface.co/najicreator90856/is-it-nsfw_ai-moderator) \n\n**Demo:** [Try it here (Gradio)](https://huggingface.co/spaces/najicreator90856/is-it-nsfw-demo)\n\nIf this saves you some work or helps your project, I’ve put my donation links (crypto/DonationAlerts) in the model card. Or just drop a star on HF, that’s also dope.\n\nPeace out! ✌️",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qfth9y/i_created_new_image_moderation_model/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": [
        {
          "id": "o07ms9q",
          "author": "Smergmerg432",
          "text": "Nice! :)",
          "score": 1,
          "created_utc": "2026-01-18 01:23:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08q17v",
              "author": "DueSpecial1426",
              "text": "Thank you)",
              "score": 1,
              "created_utc": "2026-01-18 05:13:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o08mljh",
          "author": "ResultKey6879",
          "text": "Cool, willing to share any insight into datasets used for training?",
          "score": 1,
          "created_utc": "2026-01-18 04:49:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08pzq1",
              "author": "DueSpecial1426",
              "text": "cali72mero/nsfw\\_detect (Hentai) and Xjan/PICTURES\\_X\\_SETS (Real) against SFW shots from kkcosmos/instagram-images",
              "score": 2,
              "created_utc": "2026-01-18 05:12:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qgs94h",
      "title": "MedGemma hosting + fine-tuning: what are you using and what GPU should I pick?",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1qgs94h/medgemma_hosting_finetuning_what_are_you_using/",
      "author": "duku-27",
      "created_utc": "2026-01-19 02:48:59",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I’m evaluating MedGemma (1.5) and trying to decide the most cost-effective way to run it.\n\nI first tried Vertex AI / Model Garden, but the always-on endpoint pricing caught me off guard (idle costs added up quickly). Now I’m reconsidering the whole approach and want to learn from people who’ve actually shipped or done serious testing.\n\nQuestions:\n\n1.\tHosting: Are you running MedGemma on your own GPU server or using a managed/serverless GPU setup\n\nIf self-hosting: which provider are you on (RunPod, Vast, Lambda, Paperspace, etc.) and why?\n\nIf managed: any setup that truly scales to zero?\n\n2.Inference stack: vLLM vs TGI vs plain Transformers what’s working best for MedGemma 1.5 (4B and/or 27B)?\n\n3.Quantization: What GGUF / AWQ / GPTQ / 4-bit approach is giving you the best balance of quality and speed?\n\n4.Fine-tuning: Did you do LoRA / QLoRA? If yes:\n\ndataset size (ballpark)\n\ntraining time + GPU\n\nmeasurable gains vs strong prompting + structured output\n\n5.GPU recommendation: If I just want a sane, cost-efficient setup:\n\nIs 4B fine on a single L4/4090?\n\nWhat do you recommend for 27B (A100? multi-GPU?) and is it worth it vs sticking to 4B?\n\nI’m mainly optimizing for: predictable costs, decent latency, and a setup that doesn’t require babysitting. Any real-world numbers (VRAM use, tokens/sec, monthly cost) would be extremely helpful.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qgs94h/medgemma_hosting_finetuning_what_are_you_using/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": [
        {
          "id": "o0ev0vw",
          "author": "3Salad",
          "text": "Is this for the Google x Kaggle competition?",
          "score": 2,
          "created_utc": "2026-01-19 03:15:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0f9xf3",
              "author": "duku-27",
              "text": "No, Is there any competition?",
              "score": 2,
              "created_utc": "2026-01-19 04:49:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qgv7bw",
      "title": "Try \"Nail The Interview\" Now",
      "subreddit": "huggingface",
      "url": "https://i.redd.it/93ramw2yo8eg1.jpeg",
      "author": "tarekriad66",
      "created_utc": "2026-01-19 05:11:13",
      "score": 5,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qgv7bw/try_nail_the_interview_now/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0p3z4x",
          "author": "DueDirection897",
          "text": "This looks interesting, going to give it a spin.\n\nRegarding your 'under the hood' notes, how was HuggingFace utilized?",
          "score": 1,
          "created_utc": "2026-01-20 17:07:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qimsq6",
      "title": "Check out the new Speaker Identification Model",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1qimsq6/check_out_the_new_speaker_identification_model/",
      "author": "HiMindAi",
      "created_utc": "2026-01-21 03:25:15",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[Multi-Mixture Speaker Identification - a Hugging Face Space by HiMind](https://huggingface.co/spaces/HiMind/Speaker-ID) for lightning-fast instant speaker identification, easy to use, easy to deploy.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qimsq6/check_out_the_new_speaker_identification_model/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": [
        {
          "id": "o0sncpv",
          "author": "HiMindAi",
          "text": "I also have an Automatic Speaker Identification script to go with the model if anyone is interested.",
          "score": 1,
          "created_utc": "2026-01-21 03:52:29",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qh346d",
      "title": "Small Object Detection and Segmentation using YOLO26 + SAHI",
      "subreddit": "huggingface",
      "url": "https://i.redd.it/5yxr9kkbwaeg1.png",
      "author": "yourfaruk",
      "created_utc": "2026-01-19 12:40:54",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qh346d/small_object_detection_and_segmentation_using/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    }
  ]
}