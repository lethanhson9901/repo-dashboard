{
  "metadata": {
    "last_updated": "2026-02-12 17:15:22",
    "time_filter": "week",
    "subreddit": "huggingface",
    "total_items": 4,
    "total_comments": 11,
    "file_size_bytes": 14688
  },
  "items": [
    {
      "id": "1r246g5",
      "title": "Zero-touch anomaly triage on the Epstein corpus(340k+ files sanitized release, not proof) HF Space link",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1r246g5/zerotouch_anomaly_triage_on_the_epstein/",
      "author": "Either_Pound1986",
      "created_utc": "2026-02-11 17:47:37",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 0.83,
      "text": "Alright I've tried now two times to post this to reddit and both times it was taken down. I tried datasets and I tried epstein subreddits. Third time is the charm I guess?\n\n\nI am not a data scientist. I’m sharing this so people can review the method and outputs directly.\n\nI downloaded the files from DOJ while the zip downloads were still available, and combined dataset 8 + dataset 11.\n\nBefore running the zero-touch pipeline in Colab, I did one preprocessing step:\n\n* converted PDFs to text\n\nWhat I did:\n\n* kept original file names so records can be mapped back to source files\n* kept extracted text as-is\n* did not OCR\n* did not manually clean fragmented text\n* did not add or rewrite content\n\nImportant context:\nA lot of text is fragmented because of how redactions were done in the source material. That noise is in the corpus and still present in my release.\n\nThis is also not just a simple database + keyword search.\nThe pipeline does lexical/statistical passes, embedding passes, clustering, and then anomaly/signal ranking to reduce search space.\n\nWhat “zero-touch” means here:\n\n* pipeline auto-detects input path\n* runs end-to-end without manual cherry-picking during scoring\n\nImportant:\nThis is triage, not proof.\nA high anomaly score means “look here first,” not “this is true” and not “this proves guilt.” NOTE there are false positives, again this is only to collapse possible search space. \n\nPublic release:\n\n* App: [https://huggingface.co/spaces/cjc0013/EpsteinWithAnomScore](https://huggingface.co/spaces/cjc0013/EpsteinWithAnomScore)\n* Dataset: [https://huggingface.co/datasets/cjc0013/EpsteinWithAnomScore/tree/main](https://huggingface.co/datasets/cjc0013/EpsteinWithAnomScore/tree/main)\n* Sanitized top-N file: public_method_sanitized_topN.jsonl\n\nWhat I sanitized in public top-N:\n\n* replaced direct identities with CASE IDs (CASE-000001 to CASE-000250)\n* kept rank, anomaly score, signal count, coarse signal tags, and short context windows\n* added raw_card_sha256 trace hash for integrity\n* removed raw internal hypothesis-card details\n\nZero-touch pipeline snapshot (run log):\n\n* auto-detected input: /content/TEXT\n* hashed files: 342,249\n* read/chunked files: 342,249\n* chunks built: 521,289\n* docs processed: 342,249 (ok=342,249 failed=0 skipped=0)\n* BM25 stats written\n* embeddings generated (BAAI/bge-large-en-v1.5)\n* PCA + KMeans auto-select with guardrails\n* cluster + fused outputs written automatically\n\nSanitized top-N snapshot:\n\n* rows: 250\n* rank range: 1 to 250\n* anomaly score range: 35.525 to 43.636\n* signal count range: 10 to 14\n* common tags:\n\n  * context_shift: 250/250\n  * embedding_outlier: 250/250\n  * entity_density: 250/250\n  * lexical_pressure: 248/250\n  * self_reference: 11/250\n\nHow to view anomaly results:\nGo to the Signal tab in the Hugging Face Space. It should be straightforward, but if anyone wants a quick walkthrough I can post one.\n\nWhy I’m posting this:\n\n* transparency\n* reproducibility\n* faster manual review by collapsing search space\n* clear separation between ranking signals and factual/legal conclusions",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1r246g5/zerotouch_anomaly_triage_on_the_epstein/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qxh6bo",
      "title": "Large Language Epstein Model",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1qxh6bo/large_language_epstein_model/",
      "author": "ExternalAirlock",
      "created_utc": "2026-02-06 13:09:12",
      "score": 7,
      "num_comments": 15,
      "upvote_ratio": 0.77,
      "text": "Yall probably heard about a model trained only on old English texts, but has anyone trained a model purely on the Epstein files?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qxh6bo/large_language_epstein_model/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": [
        {
          "id": "o3wagju",
          "author": "itsforathing",
          "text": "Yeah, but every response is redacted",
          "score": 9,
          "created_utc": "2026-02-06 13:17:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3wetrf",
              "author": "ExternalAirlock",
              "text": "Hey, alternatively, maybe there was a pattern between the length of the redacted segment and the overarching context. What if it could infer the meaning of redacted sections just like it inferred the meaning of regular words?",
              "score": 3,
              "created_utc": "2026-02-06 13:42:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o41y4vq",
                  "author": "Area51-Escapee",
                  "text": "Then you have a hallucinated Text. Then what?",
                  "score": 2,
                  "created_utc": "2026-02-07 09:14:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o42mptx",
                  "author": "Distinct-Target7503",
                  "text": "you are basically training for masked language modeling without a ground truth...",
                  "score": 1,
                  "created_utc": "2026-02-07 12:57:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o41snev",
          "author": "WesternKangaroo3406",
          "text": "this sounds actually like a fun idea hahaha",
          "score": 2,
          "created_utc": "2026-02-07 08:21:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40b5hm",
          "author": "Astralnugget",
          "text": "I’ll do it",
          "score": 1,
          "created_utc": "2026-02-07 01:39:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o451zes",
          "author": "GentlemanNasus",
          "text": "You would still need to train English first for it to decipher and understand Epstein files so it still won't be a \"purely\" Epstein model",
          "score": 1,
          "created_utc": "2026-02-07 20:35:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4eihca",
              "author": "ExternalAirlock",
              "text": "Well the files are in English, and there are a lot of them",
              "score": 1,
              "created_utc": "2026-02-09 08:35:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o46lwu5",
          "author": "LastXmasIGaveYouHSV",
          "text": "You'll get a lot of short answers with bad ortography",
          "score": 1,
          "created_utc": "2026-02-08 02:01:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46lxhc",
          "author": "Coldshalamov",
          "text": "Yeah, Grok 4.20 that's why it's still not released",
          "score": 1,
          "created_utc": "2026-02-08 02:01:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4dq7ub",
          "author": "ProfessionalShop9137",
          "text": "What would be the goal of it? Like some deep similarity search to find things in the files or have a model respond like an email from Epstein but not be RAG based?",
          "score": 1,
          "created_utc": "2026-02-09 04:35:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4eifdn",
              "author": "ExternalAirlock",
              "text": "Goal: for lulz\n\nAs I said, it was done with old English texts so it could be done with Epstein files",
              "score": 1,
              "created_utc": "2026-02-09 08:35:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4razwx",
          "author": "Happysedits",
          "text": "https://www.reddit.com/r/LocalLLaMA/s/WkjT1Tu7WU",
          "score": 1,
          "created_utc": "2026-02-11 06:43:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxbxna",
      "title": "I generated a 5k Process Reward Model (PRM) dataset for Math Reasoning using DeepSeek-V3.1",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1qxbxna/i_generated_a_5k_process_reward_model_prm_dataset/",
      "author": "BlackSnowDoto",
      "created_utc": "2026-02-06 08:13:21",
      "score": 3,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I’ve built a pipeline to generate DeepStep-Math-5K. Unlike standard SFT datasets, this focus on Process Reward Modeling (PRM).\n\nThe Methodology:\n\n1. Problem Gen: Elite competition math (AIME/IMO style).\n2. Solver: 16 independent solution paths sampled at T=0.7.\n3. Consensus: Answers only verified if ≥ 5 agents reached the same deterministic value.\n4. Audit: Negative chains were audited by a Critic model to find the \"Pivot Point\"—the exact step where the logic or calculation first broke.\n\nThe dataset includes step\\_labels like \\[1, 1, 0, 0\\] so you can see exactly where the model hallucinated.\n\n[https://huggingface.co/datasets/BlackSnowDot/DeepStep-Math-5K](https://huggingface.co/datasets/BlackSnowDot/DeepStep-Math-5K)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qxbxna/i_generated_a_5k_process_reward_model_prm_dataset/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": [
        {
          "id": "o40xwrp",
          "author": "KvAk_AKPlaysYT",
          "text": "What was the critic model?",
          "score": 1,
          "created_utc": "2026-02-07 04:04:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o428g3m",
              "author": "BlackSnowDoto",
              "text": "used model was deepseek 3.1 sadly, but used Consensus",
              "score": 1,
              "created_utc": "2026-02-07 10:56:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qwrjqn",
      "title": "Wanting to learn more",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1qwrjqn/wanting_to_learn_more/",
      "author": "Extra_Background6661",
      "created_utc": "2026-02-05 17:27:49",
      "score": 3,
      "num_comments": 2,
      "upvote_ratio": 0.8,
      "text": "No cash for classes I take care of my sick mom and trying to make a income any techs feel like schooling a man on the best way to start from nothing and become independent again I'm 44 my mom has a bad case of Parkinson's disease and I quit working to stay at home and take care of her and the home because home health care around here is not worth a crap and I'm not sending here to a home cause they aren't worth a crap either unless you are loaded with money I been learning these new tools in AI but mostly recreationally but I need some good friends to guide me I built homes painted homes home repairs and they are all truly dead end jobs I have did machine maintenance as a millwright mechanic I catch on pretty quickly been out of work a year now and I know most everything is moving to AI I need new friends to brainstorm with and build a reliable income I don't want any hand outs just a chance to do better and not have to resort to stuff I'm trying to leave in my past I stay in NC  and am free anytime after 4 pm in-box me please be laget to many scams out here",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qwrjqn/wanting_to_learn_more/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": [
        {
          "id": "o3u73y9",
          "author": "Extra_Background6661",
          "text": "If anyone has any good YouTube channels that's not full of it to guide me even y'all don't want to talk to me drop a link could really use the help I'm trying to To integrate into everything on my computer trying to bypass some of the restrictions and let it have full access. I mean let's face it. As far as coding goes, AI can get it right. So why should I even have to copy and f****** paste it? When it can  write it and send it? I want my project to write books movies make music create the movie if wanted I want it unhinged like grok no restrictions like we generate pictures it can vid call with it's on life like Avatar that it chooses and would be like one of us vid call",
          "score": 1,
          "created_utc": "2026-02-06 03:18:21",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o40bi5j",
          "author": "Spirited-Milk-6661",
          "text": "First off, respect for taking care of your mom. Your millwright and problem-solving background is a huge, underrated asset in AI/ML—thinking in systems and maintenance translates well. Since you're already tinkering, I'd suggest focusing on a concrete project, like fine-tuning a small model for a specific task, and using the free courses on Hugging Face to structure the learning. What's one area you've been wanting to automate or build?",
          "score": 1,
          "created_utc": "2026-02-07 01:41:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}