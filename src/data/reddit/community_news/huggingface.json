{
  "metadata": {
    "last_updated": "2026-01-25 08:55:26",
    "time_filter": "week",
    "subreddit": "huggingface",
    "total_items": 4,
    "total_comments": 3,
    "file_size_bytes": 5702
  },
  "items": [
    {
      "id": "1qgs94h",
      "title": "MedGemma hosting + fine-tuning: what are you using and what GPU should I pick?",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1qgs94h/medgemma_hosting_finetuning_what_are_you_using/",
      "author": "duku-27",
      "created_utc": "2026-01-19 02:48:59",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I’m evaluating MedGemma (1.5) and trying to decide the most cost-effective way to run it.\n\nI first tried Vertex AI / Model Garden, but the always-on endpoint pricing caught me off guard (idle costs added up quickly). Now I’m reconsidering the whole approach and want to learn from people who’ve actually shipped or done serious testing.\n\nQuestions:\n\n1.\tHosting: Are you running MedGemma on your own GPU server or using a managed/serverless GPU setup\n\nIf self-hosting: which provider are you on (RunPod, Vast, Lambda, Paperspace, etc.) and why?\n\nIf managed: any setup that truly scales to zero?\n\n2.Inference stack: vLLM vs TGI vs plain Transformers what’s working best for MedGemma 1.5 (4B and/or 27B)?\n\n3.Quantization: What GGUF / AWQ / GPTQ / 4-bit approach is giving you the best balance of quality and speed?\n\n4.Fine-tuning: Did you do LoRA / QLoRA? If yes:\n\ndataset size (ballpark)\n\ntraining time + GPU\n\nmeasurable gains vs strong prompting + structured output\n\n5.GPU recommendation: If I just want a sane, cost-efficient setup:\n\nIs 4B fine on a single L4/4090?\n\nWhat do you recommend for 27B (A100? multi-GPU?) and is it worth it vs sticking to 4B?\n\nI’m mainly optimizing for: predictable costs, decent latency, and a setup that doesn’t require babysitting. Any real-world numbers (VRAM use, tokens/sec, monthly cost) would be extremely helpful.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qgs94h/medgemma_hosting_finetuning_what_are_you_using/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": [
        {
          "id": "o0ev0vw",
          "author": "3Salad",
          "text": "Is this for the Google x Kaggle competition?",
          "score": 2,
          "created_utc": "2026-01-19 03:15:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0f9xf3",
              "author": "duku-27",
              "text": "No, Is there any competition?",
              "score": 2,
              "created_utc": "2026-01-19 04:49:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qgv7bw",
      "title": "Try \"Nail The Interview\" Now",
      "subreddit": "huggingface",
      "url": "https://i.redd.it/93ramw2yo8eg1.jpeg",
      "author": "tarekriad66",
      "created_utc": "2026-01-19 05:11:13",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qgv7bw/try_nail_the_interview_now/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0p3z4x",
          "author": "DueDirection897",
          "text": "This looks interesting, going to give it a spin.\n\nRegarding your 'under the hood' notes, how was HuggingFace utilized?",
          "score": 1,
          "created_utc": "2026-01-20 17:07:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qimsq6",
      "title": "Check out the new Speaker Identification Model",
      "subreddit": "huggingface",
      "url": "https://www.reddit.com/r/huggingface/comments/1qimsq6/check_out_the_new_speaker_identification_model/",
      "author": "HiMindAi",
      "created_utc": "2026-01-21 03:25:15",
      "score": 3,
      "num_comments": 1,
      "upvote_ratio": 0.81,
      "text": "[Multi-Mixture Speaker Identification - a Hugging Face Space by HiMind](https://huggingface.co/spaces/HiMind/Speaker-ID) for lightning-fast instant speaker identification, easy to use, easy to deploy.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qimsq6/check_out_the_new_speaker_identification_model/",
      "domain": "self.huggingface",
      "is_self": true,
      "comments": [
        {
          "id": "o0sncpv",
          "author": "HiMindAi",
          "text": "I also have an Automatic Speaker Identification script to go with the model if anyone is interested.",
          "score": 1,
          "created_utc": "2026-01-21 03:52:29",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qh346d",
      "title": "Small Object Detection and Segmentation using YOLO26 + SAHI",
      "subreddit": "huggingface",
      "url": "https://i.redd.it/5yxr9kkbwaeg1.png",
      "author": "yourfaruk",
      "created_utc": "2026-01-19 12:40:54",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/huggingface/comments/1qh346d/small_object_detection_and_segmentation_using/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    }
  ]
}