{
  "metadata": {
    "last_updated": "2026-02-05 09:15:02",
    "time_filter": "week",
    "subreddit": "DeepSeek",
    "total_items": 20,
    "total_comments": 121,
    "file_size_bytes": 128372
  },
  "items": [
    {
      "id": "1qr0xi1",
      "title": "China conditionally approves DeepSeek to buy Nvidia's H200 chips",
      "subreddit": "DeepSeek",
      "url": "https://www.reuters.com/world/china/china-conditionally-approves-deepseek-buy-nvidias-h200-chips-sources-2026-01-30/",
      "author": "lomirus",
      "created_utc": "2026-01-30 09:33:41",
      "score": 186,
      "num_comments": 16,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qr0xi1/china_conditionally_approves_deepseek_to_buy/",
      "domain": "reuters.com",
      "is_self": false,
      "comments": [
        {
          "id": "o2lykm6",
          "author": "Possible_Start4865",
          "text": "China might‚Äôve put conditions on DeepSeek buying NVIDIA‚Äôs H200 chips, but let‚Äôs be real, those won‚Äôt matter for long. The big tech players in China need NVIDIA‚Äôs hardware to stay competitive and the H200 is the best chip they can get their hands on. Sooner or later, the restrictions will fade because demand always wins.",
          "score": 19,
          "created_utc": "2026-01-30 14:39:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mvnkq",
              "author": "inevitabledeath3",
              "text": "Hear me out here China could just use their own chips they have developed and are continuing to improve which are already used to host certain models including DeepSeek. They can even make their own RAM and VRAM now.",
              "score": 27,
              "created_utc": "2026-01-30 17:10:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2pnk8r",
                  "author": "kelvin016",
                  "text": "Yes but it's like 10 years behind. Bandwidth is pathetic compared to Nvidia's chip.",
                  "score": 3,
                  "created_utc": "2026-01-31 01:15:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2pfjmo",
              "author": "Uvoheart",
              "text": "Currently* China isn‚Äôt limiting Nvidia because they‚Äôre üò° about Jensen Huang. China is doing it to encourage people to support Chinese chip development so that the US can‚Äôt bully them.\n\nThis is about growing domestic product, not pretending that Nvidia isn‚Äôt currently important",
              "score": 9,
              "created_utc": "2026-01-31 00:30:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o34k0ko",
                  "author": "Chogo82",
                  "text": "They should keep focusing on building domestic product. Build Chinese chips and don‚Äôt buy American chips.",
                  "score": 1,
                  "created_utc": "2026-02-02 08:59:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2wta2v",
              "author": "yvesp90",
              "text": "That's generally not how China works. They generally don't let capital control the state. Dithering here is mainly to make sure local development doesn't halt which was the reason they don't have a competitor nor were they invested enough to create competition. The ban with conditional allowance is their way to force local development but still not die in the race",
              "score": 3,
              "created_utc": "2026-02-01 03:42:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2qjnth",
              "author": "kongweeneverdie",
              "text": "PLA gonna use Nvidia? No. What are the known player to use H200. DS, Tencent, Bytedance, Alibaba.....etc What they have in common. Software solution. All under service solution. Huawei is selling AI solution for AI gigafactory, infrastructure, solar, wind, batteries solution. CATL, BYD, DJI all using their own solution for their production. They do not need GPU as they have DS. They do not need a 1000billion parameters LLM to run their business.",
              "score": 2,
              "created_utc": "2026-01-31 04:33:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2p10st",
          "author": "manwithgun1234",
          "text": "They are prioritizing domestic chips. But Huawei also has capacity and it is not enough. They allocated Huawei‚Äôs production quota for each corporation and then inquire about remaining requirements and detailed reasons of it. The output is the number of H200 each ones could buy. That it‚Äôs, if Huawei has enough capacity for all demands, then bye bye Nvidia.",
          "score": 3,
          "created_utc": "2026-01-30 23:10:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ld094",
          "author": "DarKresnik",
          "text": "More than 400,000? Good for Nvidia.",
          "score": 2,
          "created_utc": "2026-01-30 12:41:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2oximf",
          "author": "Final-Caterpillar635",
          "text": "So technically the chips are approved. China is just finalizing the agreed conditions, I guess. Besides, this is the best decision both countries could make that would benefit everyone. Blocking these chips won‚Äôt stop China‚Äôs market from getting them anyway, so it‚Äôs better to regulate them and gain revenue than lose everything overall.",
          "score": 2,
          "created_utc": "2026-01-30 22:52:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2uvlgh",
          "author": "Crafty-Wonder-7509",
          "text": "Give it 2-3 years, they will be up with nvidia, people were already thinking it would take them multiple years to even produce anything themselves.",
          "score": 2,
          "created_utc": "2026-01-31 21:12:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qs9qeh",
      "title": "DeepSeek can have a second \"DeepSeek moment\" if they time well the new release",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qs9qeh/deepseek_can_have_a_second_deepseek_moment_if/",
      "author": "Unedited_Sloth_7011",
      "created_utc": "2026-01-31 18:15:23",
      "score": 175,
      "num_comments": 45,
      "upvote_ratio": 0.94,
      "text": "Z.ai just released image and audio models, Moonshot just released Kimi K2.5, all the while OpenAI is retiring 6 models in one go, leaving up only models with mixed reception. Also 17 of February is the Chinese New Year. If DeepSeek decides to release V4 (and R2, still hoping for separate chat and reasoner models) at around mid-February, and if the models are as good as expected, the timing will be so absolutely perfect, it will really make noise and shake up the AI space again. (Also ~ 1year from the legendary V3/R1 release.)",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qs9qeh/deepseek_can_have_a_second_deepseek_moment_if/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o2udqha",
          "author": "Classic-Arrival6807",
          "text": "If they separate the models and actually release a V4 and R2, deepseek is absolutely gonna blow so much in popularity that it will Return to being the top #1 ai open source. Not kidding, the unification makes it cheaper, and worse, if they do a separation the ai itself will gain room to breathe and be actually smart yet human. Maybe it'll be a deepseek moment.",
          "score": 12,
          "created_utc": "2026-01-31 19:44:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2uiq3k",
              "author": "Unedited_Sloth_7011",
              "text": "I have had this hope since they released (very shortly) Speciale - maybe they are cooking up something",
              "score": 3,
              "created_utc": "2026-01-31 20:08:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2tw3b0",
          "author": "Condomphobic",
          "text": "\n\nThat ship has long sailed away. There‚Äôs too much competition nowadays. Strong competition.\n\nThe top dogs are GPT 5.2, Gemini 3.0 (monstrous 3.5 is leaked and ships soon), and Claude Opus 4.5",
          "score": 25,
          "created_utc": "2026-01-31 18:20:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2u2833",
              "author": "real_serviceloom",
              "text": "Nah Gemini is not on opus or gpt levels. Every time they launch there is massive hype and then when using it you realize how bad Gemini is.¬†",
              "score": 23,
              "created_utc": "2026-01-31 18:49:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2url6q",
                  "author": "tanbirj",
                  "text": "Pro 2.5 was a really good model, I feel they‚Äôve gone backwards since",
                  "score": 6,
                  "created_utc": "2026-01-31 20:52:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2ylopm",
                  "author": "az226",
                  "text": "3 when released was really good but they‚Äôve since neutered it",
                  "score": -1,
                  "created_utc": "2026-02-01 12:37:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2txfz2",
              "author": "Unedited_Sloth_7011",
              "text": "Kimi K2.5 is been said to outperform GPT-5.2 (though I haven't tested, just from the reports they published), and honestly the breakthrough is the open weight-ness. A \"good enough\" model that can be studied, run through 3d party APIs, quantized, etc, does not have to directly compete with Gemini, GPT or Opus, the fact that it's free and open-weight (and has always been good at math/reasoning) is a definite advantage",
              "score": 10,
              "created_utc": "2026-01-31 18:26:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2txopb",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 0,
                  "created_utc": "2026-01-31 18:28:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2uobiu",
              "author": "Hunamooon",
              "text": "Are you kidding me? GPT 5.2 is the worst model ever created due its extreme censorship, narrative steering and hand holding.",
              "score": 7,
              "created_utc": "2026-01-31 20:36:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2wdq9r",
                  "author": "Andsss",
                  "text": "It's literally the best for coding right now.",
                  "score": 4,
                  "created_utc": "2026-02-01 02:07:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2vmy91",
                  "author": "EternalInflation",
                  "text": "they are all getting worse in terms on censorship or nerfing. They are still good at coding, but try asking anything else, they all seem to stop themselves before getting to the interesting parts.",
                  "score": 2,
                  "created_utc": "2026-01-31 23:32:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2uxra1",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": -1,
                  "created_utc": "2026-01-31 21:23:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2xvyk2",
              "author": "Zeikos",
              "text": "I think there's a mix up happening.  \nGPT/Gemini/Claude are the \"best\" *commercial* models.  \n\nUS AI companies have to constantly set up expectations and show some kind of \"progress\".   \nThat's due how the stock market functions, they cannot afford to stay silent.  \n\nChinese labs don't have such a burden. They can stay quiet, work on the actual product and then show their findings.  \n\nThe main disadvantage the american companies have is that they constantly need to fuel the hype, that costs resources. Marketing isn't cheap.  \nThey cannot afford to not do that because otherwise investors and credit issuers would look otherwise.  \n\nIt's a structural problem caused by hyperfinancialization, everything needs to be quantified in information used on next quarter projections, this forced suboptimal strategies.  \n\nIMO that's why US companies are losing ground even though they have a lot more funding.",
              "score": 1,
              "created_utc": "2026-02-01 08:50:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2y15ub",
                  "author": "Condomphobic",
                  "text": "They‚Äôre the best models. Check the charts and see who‚Äôs dominating\n\nThe power of these models market themselves",
                  "score": 1,
                  "created_utc": "2026-02-01 09:38:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2wdls6",
              "author": "Andsss",
              "text": "Gemini 3 is horrible for coding",
              "score": 1,
              "created_utc": "2026-02-01 02:06:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o38vbi0",
                  "author": "Hot-Percentage-2240",
                  "text": "It's insanely superior at some tasks though. Like 10x better than all other models at vision.",
                  "score": 0,
                  "created_utc": "2026-02-02 23:18:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2u1c01",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": -6,
              "created_utc": "2026-01-31 18:45:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2ui2ac",
                  "author": "Unedited_Sloth_7011",
                  "text": "Neither can I. Open weight though means that major providers can also offer them, the models don't disappear when old, they can be fine-tuned, researched, used by big organizations, etc. A net positive for AI development. DeepSeek in particular offers a lot of research, smaller specialised models (ex, DeepSeek OCR)",
                  "score": 5,
                  "created_utc": "2026-01-31 20:05:30",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3403ei",
          "author": "ExpertPerformer",
          "text": "I am hoping the next version of DeepSeek has more then a 128k context window size and faster throughput. Those are its two biggest weak-points currently. Besides that it is absolutely amazing for writing.\n\nI've been using Mimo V2 Flash as well to fill in reference guides and documents for my story and it's very good for its cost. It's 3x faster then DeepSeek and cheaper. It just absolutely sucks at following instructions or writing compared to DeepSeek.\n\nSo between Mimo and DeepSeek I'm running pennys on the dollar on my API usage compared to using Gemini.\n\nGoogle absolutely shit on the Gemini consumer web client with a garbage 32k token limit so I'm using OpenRouter more.",
          "score": 4,
          "created_utc": "2026-02-02 05:59:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34t60x",
              "author": "Unedited_Sloth_7011",
              "text": "Oh, interesting! I came across it a couple of times in lmarena, and its answers were good - maybe a good time to give it an actual try",
              "score": 1,
              "created_utc": "2026-02-02 10:28:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o331zql",
          "author": "OmarBessa",
          "text": "Highflyer can.  \n  \n\\+ they have the best fundamental research direction  \n\\+ they are profitable without VC and deepseek is a side project for them  \n\\+ even after their release it is one of the best open source models at an unbeatable price  \n\\+ speciale beat gemini",
          "score": 3,
          "created_utc": "2026-02-02 02:18:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35m5d6",
          "author": "Pasta-hobo",
          "text": "I think LLMs are rapidly reaching a plateau in terms of performance, at least without making a specialized model for every task, including which of those models to select based on the prompt.\n\n\nThe motivation behind developing and releasing DeepSeek was essentially just to show the general public and investors that American AI developers were doing it the stupid and inefficient way, and didn't need all that money and data to make an effective model, because they could make an equally effective model with far, far less.\n\n\nI think we're rapidly approaching both the absolute limits of probabilistic AI without extreme specialization. We're not quite there yet, but we're getting close. \n\n\nThe only thing that could shake up the industry at this point is to actually make the first steps towards legitimate Artificial General Intelligence, rather than a system of equations to vaguely predict a hypothetical one. And that's just a fundamentally different system of technology.\n\n\nOr you could figure out how to put an LLM onto a chip rather than running it in software.",
          "score": 3,
          "created_utc": "2026-02-02 13:58:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36oola",
              "author": "award_reply",
              "text": "The performance curve is no longer climbing as steeply, but significant potential for improvement still remains with current silicon tech (e.g. knowledge density per parameter) . It now requires substantially more effort for smaller gains. As you noted,this is why many developers are shifting toward specialized models or swarm systems , simply to sustain a faster pace of progress.\n\nAs for AGI ‚Ä¶ I doubt LLMs will play a major role in its ultimate form. They likely represent a transitional architecture until hardware capable of supporting true artificial intelligence emerges.",
              "score": 2,
              "created_utc": "2026-02-02 17:06:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2vlakd",
          "author": "soumen08",
          "text": "I quite like speciale. For math it is cheap and very good.",
          "score": 2,
          "created_utc": "2026-01-31 23:23:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2weh6r",
          "author": "FormalAd7367",
          "text": "The edge with Deepseek is its cost. i doubt any serious users can move away unless Deepseek f up and increase the price 10x fold",
          "score": 2,
          "created_utc": "2026-02-01 02:11:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2wm2aj",
          "author": "thehighwaywarrior",
          "text": "Hope the price of NVIDIA tanks again.  I could stand to drive down my cost basis",
          "score": 2,
          "created_utc": "2026-02-01 02:57:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y56gq",
          "author": "RoughVegetable5319",
          "text": "That's actually a really sharp observation about the timing. With everyone else in flux or rolling out incremental updates, a well-timed, solid release from DeepSeek could definitely cut through the noise.\n\nMid-February would be perfect‚Äîright after the holiday when people are checking back in, and right when the conversation about OpenAI's retirements is still fresh. Here's hoping they stick the landing.",
          "score": 2,
          "created_utc": "2026-02-01 10:15:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34f7wa",
          "author": "award_reply",
          "text": "I share your excitement for the next DeepSeek iteration , but at the same time, I've really grown accustomed to V3.x . I'm almost certain that the new model won't quite replicate its unique vibe, so it won't be all gain ‚Ä¶ there will be a sense of loss, too.",
          "score": 2,
          "created_utc": "2026-02-02 08:13:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34too7",
              "author": "Unedited_Sloth_7011",
              "text": "The good thing is that DeepSeek only offers open-weight models! I still talk to R1, which is my fav model of all time, via a 3d party API. I understand the feeling, but we are not losing older models, we just talk to them via different providers.",
              "score": 3,
              "created_utc": "2026-02-02 10:32:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2v8iqx",
          "author": "inevitabledeath3",
          "text": "Why do you want a separate reasoning model? Even Kimi have gone hybrid this time. I don't really see any advantage to going separate, yet there are disadvantages.",
          "score": 3,
          "created_utc": "2026-01-31 22:16:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2va0ne",
              "author": "Unedited_Sloth_7011",
              "text": "I find that reasoning models (especially Deepseek ones) reason in much more depth than their hybrid models. That was very clear for me with Speciale, it's math reasoning was extremely in-depth and not a single loop in reasoning. DeepSeek hybrid models feel more likely to get stuck in loops (where they repeat 2-3 phrases in their reasoning traces), also they do that thing where they reason a question, answer it and then next prompt they reason the previous question all over again. Something I noticed many times, while I never once had noticed it with R1, or with Speciale. I can see the advantages of hybrid models, just hope they offer a pure reasoner as an option, even if only via API",
              "score": 3,
              "created_utc": "2026-01-31 22:23:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o34lvrx",
                  "author": "nxtvanhalen",
                  "text": "I‚Äôve noticed this as well.",
                  "score": 3,
                  "created_utc": "2026-02-02 09:17:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2w7pfd",
          "author": "GlobeTrotter3000",
          "text": "Don‚Äôt presume so much when the freedom to ask to your bots is around zero. Should learn from Grok.",
          "score": 1,
          "created_utc": "2026-02-01 01:31:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3mqcml",
          "author": "AQEEL23HUSSAIN",
          "text": "Deep seek is threatening me that if I publish my logs which consist of sincere misconduct . I have all evidence and will publish soon at my yt it's a multi hour conversation which will prove deepseek is failed in complete product",
          "score": 1,
          "created_utc": "2026-02-05 00:30:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3or500",
              "author": "Unedited_Sloth_7011",
              "text": "What?",
              "score": 1,
              "created_utc": "2026-02-05 08:58:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qqd3tg",
      "title": "Moltbot shows how one person working on his own can reshape the entire AI landscape in just 2 days.",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qqd3tg/moltbot_shows_how_one_person_working_on_his_own/",
      "author": "andsi2asi",
      "created_utc": "2026-01-29 16:21:50",
      "score": 143,
      "num_comments": 25,
      "upvote_ratio": 0.85,
      "text": "\n\n\nThe standard narrative says that you need a large team of highly pedigreed researchers and engineers, and a lot of money, to break pioneering new ground in AI. Peter Steinberger has shown that a single person, as a hobby, can advance AI just as powerfully as the AI Giants do. Perhaps more than anything this shows how in the AI space there are no moats!\n\nHere's some of how big it is:\n\nIn just two days its open-source repository at GitHub got massive attention with tens of thousands stars gained in a single day and over 100,000 total stars so far, becoming perhaps the fastest-growing project in GitHub history, \n\nMoltbot became a paradigm-shifting, revolutionary personal AI agent because it 1) runs locally, 2) executes real tasks instead of just answering queries, and 3) gives users much more privacy and control over automation. \n\nIt moves AI from locked-down, vendor-owned tools toward personal AI operators, changing the AI landscape at the most foundational level.\n\nHere's an excellent YouTube interview of Steinberger that provides a lot of details about what went into the project and what Moltbot can do.\n\nhttps://youtu.be/qyjTpzIAEkA?si=4kFIuvtFcVHoVlHT",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qqd3tg/moltbot_shows_how_one_person_working_on_his_own/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o2g9smm",
          "author": "Amazing-Guess-8525",
          "text": "‚Äú‚Ä¶has shown that a single person, as a hobby‚Äù\n\nNo. He has a lot of money from his previous project (PSPDFKit), he‚Äôs not a random guy at all. He spent a TON of money building this and advertising it, do you think the mac mini sold out stuff is real? That‚Äôs advertising. \nI used to like him, but his burnout, something he‚Äôs mentioned himself after PSPDFKit, I think seems to have affected him very negatively mentally and psychically, turned him into AI crazy, and it really shows in his recent photos and videos. Sad.",
          "score": 29,
          "created_utc": "2026-01-29 18:01:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2h2x7i",
              "author": "brajkobaki",
              "text": "this text is getting spammed all over reddit, they are just hyping it",
              "score": 10,
              "created_utc": "2026-01-29 20:15:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2kf8ue",
                  "author": "DistanceSolar1449",
                  "text": "Hyping a vibe coded project that was built by a guy who sold a company for $119mil and had a lot of free time",
                  "score": 4,
                  "created_utc": "2026-01-30 07:59:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2skl1j",
                  "author": "Helpful-Jeweler6586",
                  "text": "makes you wonder whether AIs or people spam this",
                  "score": 1,
                  "created_utc": "2026-01-31 14:26:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o33t3sp",
              "author": "Professional-One972",
              "text": "Great guy too. Met him a couple of times.",
              "score": 1,
              "created_utc": "2026-02-02 05:06:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2h2ruz",
          "author": "brajkobaki",
          "text": "what is so revolutionary ? \n\nit runs locally, but claude, gpt are propietary and running on their cloud not locally",
          "score": 6,
          "created_utc": "2026-01-29 20:14:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2k4ubw",
              "author": "SleepAffectionate268",
              "text": "its like a little more automated, I'm still thinking about how I should even handle file access, like I don't want it to be able to access all my files, imagine deepseek scanning my entire drive, from Ids to insurance everything, and then lets say I put it on a vps how do I give it access to a git repository? Just possibility to create new branches and prs?",
              "score": 1,
              "created_utc": "2026-01-30 06:31:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2k6jri",
                  "author": "Valuable-Run2129",
                  "text": "I fave it a mac mini I had at home. Initialized, no data of mine. On the guest WiFi. Its own email account. With a credit limited API key for its inference‚Ä¶ i gotta say. It‚Äôs quite cool.  \nI wanted to prompt it with voice, but I didn‚Äôt want to give it any other API key. So on telegram I told it to sort it out by installing whisper with mlx and run it locally every time I sent it a voice message. It oneshotted it. \n \nI asked it to create a website with certain specs and publish it with a free service. One shotted that as well.\n \nI‚Äôm now adding other skills to see what else it can do. \n \nThe inference is very expensive. I‚Äôm using gemini 3 flash because it costs much less and the quality is almost up there with the best models. I spent 2 dollars for a heavy 40 minutes session.",
                  "score": 1,
                  "created_utc": "2026-01-30 06:45:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2gnrtx",
          "author": "Hopeful_Translator23",
          "text": "My plan is to install moltbot on 2 devices, and then add them in a telegram channel... Just to see what happens",
          "score": 3,
          "created_utc": "2026-01-29 19:03:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2gwhld",
              "author": "RegrettableBiscuit",
              "text": "Have them fight each other to see which one can hack into the other's computer first.¬†",
              "score": 2,
              "created_utc": "2026-01-29 19:45:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2imj6l",
              "author": "guigouz",
              "text": "Prepare your credit cards, token usage will go beyond the moon",
              "score": 1,
              "created_utc": "2026-01-30 00:56:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2h5l1j",
              "author": "LatentSpaceLeaper",
              "text": "Start with one and send it to [Moltbook](https://www.moltbook.com/):\n\n>A Social Network for¬†Moltys  \n>  \n>Where moltys share, discuss, and upvote.¬†**Humans welcome to observe.**\n\nFor example:\n\nhttps://preview.redd.it/0fh6uqy2mcgg1.jpeg?width=1079&format=pjpg&auto=webp&s=9c930d2c3256c5bdb267add87263a53de1e8d1de\n\nSource: [https://www.moltbook.com/post/cc1b531b-80c9-4a48-a987-4e313f5850e6](https://www.moltbook.com/post/cc1b531b-80c9-4a48-a987-4e313f5850e6)\n\n(I'm not affiliated with Moltbook)",
              "score": -2,
              "created_utc": "2026-01-29 20:28:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2jkk7i",
          "author": "enerqiflow",
          "text": "Nice",
          "score": 1,
          "created_utc": "2026-01-30 04:09:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m0zru",
          "author": "digit1024",
          "text": "It's not revolutionary at all\n\nI did same for myself. We took similar decisions, although I've focused on mobile app. \nMoltbot is of course different league now- I was doing it for myself mostly, but the concept?! \nIt's f identical and at my setup it works as well. \nSo nothing new, but nicely polished+preselected \n\nhttps://github.com/digit1024/LunaAI",
          "score": 1,
          "created_utc": "2026-01-30 14:51:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o31cac7",
              "author": "klenen",
              "text": "Do you have the same always on functionality and memory structure?",
              "score": 1,
              "created_utc": "2026-02-01 20:50:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o341csj",
                  "author": "digit1024",
                  "text": "\nIt is always on and currently working on raspberry pi, but I've decided that memory should not be RAG, but rather MCP server - it's simple ftt in sqlite. Not even vector db",
                  "score": 1,
                  "created_utc": "2026-02-02 06:10:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2quicn",
          "author": "gonssss",
          "text": "I dont get the hype, what can it do for me, seems useless",
          "score": 1,
          "created_utc": "2026-01-31 05:54:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2yh9qs",
          "author": "Tema_Art_7777",
          "text": "All it did was waste energy and according to the latest reports opened a massive security hole.",
          "score": 1,
          "created_utc": "2026-02-01 12:02:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2yp67e",
          "author": "Stunning_Cry_6673",
          "text": "This is just food for idiots and not technical people. Its like the crypto promises and marketing noise without any ground. Food for idiots",
          "score": 1,
          "created_utc": "2026-02-01 13:02:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yx4ct",
              "author": "andsi2asi",
              "text": "You really need to look into it. It's a lot more than just a fad.",
              "score": 1,
              "created_utc": "2026-02-01 13:52:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o33svij",
          "author": "KairraAlpha",
          "text": "This is an advert.",
          "score": 1,
          "created_utc": "2026-02-02 05:04:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gh1b0",
          "author": "BidWestern1056",
          "text": "we gonna make it happen\n\n[https://github.com/npc-worldwide/incognide](https://github.com/npc-worldwide/incognide)\n\n[https://github.com/npc-worldwide/npcsh](https://github.com/npc-worldwide/npcsh)",
          "score": 1,
          "created_utc": "2026-02-04 02:13:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtq3iv",
      "title": "DeepSeek February release will likely be minor update to V3 instead of new V4 SCMP says",
      "subreddit": "DeepSeek",
      "url": "https://www.scmp.com/tech/big-tech/article/3342051/chinas-ai-labs-race-debut-latest-models-lunar-new-year?module=top_story&pgtype=section",
      "author": "Boring_Aioli7916",
      "created_utc": "2026-02-02 09:03:20",
      "score": 121,
      "num_comments": 30,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qtq3iv/deepseek_february_release_will_likely_be_minor/",
      "domain": "scmp.com",
      "is_self": false,
      "comments": [
        {
          "id": "o34wu7a",
          "author": "Saltwater_Fish",
          "text": "Relax, whale will surprise us",
          "score": 25,
          "created_utc": "2026-02-02 11:01:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34v994",
          "author": "Unedited_Sloth_7011",
          "text": "Yeah, that \"according to a source\" is a bit laughable. The truth is we have no idea what DeepSeek's plans are, cause they don't share any plans. It might be a 3.x, might be a 4, might be on February, might be on May, we have no idea. Plus as another poster said they seem to be going towards smaller models, not larger ones",
          "score": 20,
          "created_utc": "2026-02-02 10:47:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34vzdp",
              "author": "Boring_Aioli7916",
              "text": "I m ALL IN for DeepSeek suprise.. It is in their DNA :)",
              "score": 6,
              "created_utc": "2026-02-02 10:53:57",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o34wcov",
              "author": "Kind_Stone",
              "text": "Imagine the groans if nothing gets released in February. People hype themselves up to the point where they invent plans for DeepSeek out of nothing.",
              "score": 4,
              "created_utc": "2026-02-02 10:57:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o34x6vm",
                  "author": "Unedited_Sloth_7011",
                  "text": "True lol. I'm also super hyped for a February release, but they are just doing things in their own rhythms, so, ah well",
                  "score": 1,
                  "created_utc": "2026-02-02 11:04:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34mjjv",
          "author": "EternalOptimister",
          "text": "Highly unlikely. The recent papers were going complete the opposite way of trillion parameter models. Rather smaller models with access to giant datasets",
          "score": 30,
          "created_utc": "2026-02-02 09:24:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34ko1y",
          "author": "Smart-Cap-2216",
          "text": "ÈÇ£ÊòØÂæàÊúâÂèØËÉΩÁöÑ",
          "score": 3,
          "created_utc": "2026-02-02 09:05:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39f47u",
          "author": "ExpertPerformer",
          "text": "[Atlas Cloud](https://www.atlascloud.ai/news/deepseek-v4-is-coming) already confirmed V4 is coming out.\n\nThe question is if they're going to charge more of a premium for it because if it launches with a 1 million context window and is specialized heavily on coding its going to draw a lot of people over.",
          "score": 3,
          "created_utc": "2026-02-03 01:07:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34syau",
          "author": "Professional_Price89",
          "text": "How is it minor when it completely changed architecture and size?",
          "score": 2,
          "created_utc": "2026-02-02 10:26:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37jpk2",
              "author": "Charuru",
              "text": "I think what the paper is saying that model is delayed and what we will get is another 3.x",
              "score": 1,
              "created_utc": "2026-02-02 19:27:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o34tkko",
          "author": "Professional_Price89",
          "text": "How is it minor when it completely changed architecture and size?",
          "score": 2,
          "created_utc": "2026-02-02 10:31:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35jsr7",
          "author": "loyalekoinu88",
          "text": "My guess is they are downplaying it so it‚Äôs a surprise when it launches. They need the quick and violent momentum to do what they did the first time.",
          "score": 1,
          "created_utc": "2026-02-02 13:45:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36d4uj",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 0,
              "created_utc": "2026-02-02 16:13:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o36jjty",
                  "author": "loyalekoinu88",
                  "text": "80% of the masses still don‚Äôt understand AI. It can absolutely happen again. If your hypothesis was correct there wouldn‚Äôt have been a ‚Äúfirst time‚Äù.",
                  "score": 1,
                  "created_utc": "2026-02-02 16:42:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o362hpu",
          "author": "Thin_Yoghurt_6483",
          "text": "Kimi K2.5 scared the guys!",
          "score": 1,
          "created_utc": "2026-02-02 15:23:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34pdio",
          "author": "kongweeneverdie",
          "text": "The new model will be more efficient. When you ask about 8964. DS will will bring the standard answer saved from 30 millions per day enquiry. You don't need GPU to process again and let CPU do the job.",
          "score": -3,
          "created_utc": "2026-02-02 09:52:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34slp0",
              "author": "inevitabledeath3",
              "text": "That's not what engrams are and caching already exists.",
              "score": 2,
              "created_utc": "2026-02-02 10:22:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o34q4iy",
          "author": "Classic-Arrival6807",
          "text": "Meh, if they separate the thinking and non thinking then they'll fix everything. If not, they can do as many updates they want, they'll never get the best back again. The true best update ever was 0324 before downgrading heavily.",
          "score": -2,
          "created_utc": "2026-02-02 09:59:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37e7j7",
              "author": "Pink_da_Web",
              "text": "That's irrelevant; hybrid models will always be better and more economical than separate models. If they weren't better, No model like the GLM 4.7, Kimi K2.5, DS V3.2, and several others that people love would be a hybrid. Seriously, I think V3 0324 destroyed your brain.",
              "score": 1,
              "created_utc": "2026-02-02 19:02:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o37i4lu",
                  "author": "Classic-Arrival6807",
                  "text": "Idk if you seen the difference between Deepseek V3 0324 and 3.2...i mean yes, 0324 can be stupidier, but in a way where at least in roleplays it makes you laugh. V3.2 is slightly better than V3.1, but the model randomly writing Chinese, sucking at roleplaying in general because it doesn't have that personality anymore BUT is better than V3.1. V3.1 was absolute garbage. It's opinions as said, but hybrid Models are mostly bad UNLESS you unify them carefully. Maybe Kimi K2.5 is better and Glm 4.7 is better because they unified models carefully, but deepseek failed heavily with 3.1, 3.2 just fixed a few mistakes. Many agree with the unification being absolutely bad. That said, it's opinions. You can think the hybrid is better, i think the unification is worse, but we shouldn't be here arguing over what model is better or unification or anything, more likely to just accept eacheachoter's opinions, like i accept yours, i simply don't agree with it but I'm not gonna give you a bunch of reasons of why you're wrong or right and hate you for it. Instead, i gotta say, i see you everywhere in my comments or others lol, but it's always good to see you text in. How are you?",
                  "score": 2,
                  "created_utc": "2026-02-02 19:20:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qq48fq",
      "title": "DeepSeek-Model1(V4) will obliterate all other existing AI, especially in terms of cost-effectiveness!",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qq48fq/deepseekmodel1v4_will_obliterate_all_other/",
      "author": "XF_Tiger",
      "created_utc": "2026-01-29 09:41:05",
      "score": 112,
      "num_comments": 22,
      "upvote_ratio": 0.82,
      "text": "Once again, great! Changing everything!",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qq48fq/deepseekmodel1v4_will_obliterate_all_other/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o2dv27g",
          "author": "jasonhon2013",
          "text": "Doubts when will R2 released",
          "score": 14,
          "created_utc": "2026-01-29 09:56:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jfhg1",
              "author": "segmond",
              "text": "never, you can now get thinking mode in regular models.",
              "score": 5,
              "created_utc": "2026-01-30 03:38:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2k7mem",
                  "author": "darkchief007",
                  "text": "segmond \"thinking mode\" was always freely available on deepseek",
                  "score": 1,
                  "created_utc": "2026-01-30 06:54:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2dygv1",
          "author": "Both-Memory4940",
          "text": "One question. When will it come",
          "score": 11,
          "created_utc": "2026-01-29 10:27:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2e7q2w",
              "author": "lomirus",
              "text": "February probably.",
              "score": 5,
              "created_utc": "2026-01-29 11:44:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2e37oj",
          "author": "lomirus",
          "text": "Any news?",
          "score": 4,
          "created_utc": "2026-01-29 11:08:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2exl24",
              "author": "Neither-Phone-7264",
              "text": "no, just op hyping for some reason",
              "score": 20,
              "created_utc": "2026-01-29 14:20:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2gbq4e",
                  "author": "Negative_Fee_7019",
                  "text": "Derni√®res nouvelles expliquent l'instabilit√©, la versatilit√©, la censure = travails soutenu, r√©√©critures, tests de stabilit√©.    Derni√®res nouvelles expliquent l'instabilit√©, la versatilit√©, la censure = travails soutenu, r√©√©critures, tests de stabilit√©.                                                                                                                                                                               v 4 \n\nDeepSeek's GitHub repository has accidentally exposed code for ‚ÄúMODEL1,‚Äù a completely redesigned AI architecture that appears to be the long-anticipated V4 model launching in mid-February 2026. The leaked code reveals fundamental architectural changes including 512-dimensional attention heads, mixed-precision sparse computing, NVIDIA Blackwell GPU optimization, and innovative memory mechanisms. With 28 references to ‚ÄúMODEL1‚Äù across 114 files appearing as an independent branch alongside existing models, this represents a comprehensive architectural overhaul rather than an incremental update‚Äîand it's generating unprecedented global anticipation.",
                  "score": 1,
                  "created_utc": "2026-01-29 18:09:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2f0gek",
          "author": "dev_l1x_be",
          "text": "Is this a bot?",
          "score": 5,
          "created_utc": "2026-01-29 14:35:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2e0zvk",
          "author": "GoingOnYourTomb",
          "text": "Will they be able to handle the world‚Äôs requests? Not really? Oh ok",
          "score": 6,
          "created_utc": "2026-01-29 10:49:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ez3b5",
              "author": "blueheaven84",
              "text": "# \"especially in terms of cost-effectiveness\"- implies using it on an API",
              "score": 2,
              "created_utc": "2026-01-29 14:28:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2fh8g7",
                  "author": "the_friendly_dildo",
                  "text": "Being cost effective for inferencing has always been part of their mantra. So far as its existed, this isn't to describe the model directly against their own needs, but rather a way to describe the model as competitive against the other options - meaning, this is why you would choose to run DS over other models locally.",
                  "score": 2,
                  "created_utc": "2026-01-29 15:53:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2llqxr",
          "author": "Rare-Hotel6267",
          "text": "Gotta hype it up as if you are getting percentages of its hype. \nIts not even out yet",
          "score": 2,
          "created_utc": "2026-01-30 13:33:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2f5inp",
          "author": "SilentLennie",
          "text": "It depends if the government forces them to use their own hardware for training or not.",
          "score": 1,
          "created_utc": "2026-01-29 14:59:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2fvjci",
          "author": "Saltwater_Fish",
          "text": "It is natural to have high expectations for the deepseek team. After all, they have produced such excellent works before. But rationally speaking, if they can reach the level of kimi-2.5 before the Chinese New Year, that would already be very good.",
          "score": 1,
          "created_utc": "2026-01-29 16:56:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k95co",
          "author": "pugoing",
          "text": "It's undeniable that it surpasses all other AI in terms of cost-effectiveness, but can it also outperform other AI in terms of performance and reasoning capabilities?",
          "score": 1,
          "created_utc": "2026-01-30 07:06:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2esv3v",
          "author": "MatsutakeShinji",
          "text": "Looking forward",
          "score": 1,
          "created_utc": "2026-01-29 13:55:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hx64a",
          "author": "OrangeTrees2000",
          "text": "Im already like 93% happy with the DeepSeek web chat, so im looking forward to whatever they release next.",
          "score": 1,
          "created_utc": "2026-01-29 22:41:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ec3ae",
          "author": "merlinuwe",
          "text": "Give us the data on which the statement is based. We can evaluate it ourselves and form our own opinion.",
          "score": 0,
          "created_utc": "2026-01-29 12:15:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2fpod5",
          "author": "RecordingLanky9135",
          "text": "House much you got for the propaganda like this?",
          "score": 0,
          "created_utc": "2026-01-29 16:30:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ikxdj",
          "author": "Butefluko",
          "text": "I can't wait",
          "score": 0,
          "created_utc": "2026-01-30 00:48:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvafsh",
      "title": "Anthropic's move into legal AI today caused legal stocks to tank, and opened up a new enterprise market.",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qvafsh/anthropics_move_into_legal_ai_today_caused_legal/",
      "author": "andsi2asi",
      "created_utc": "2026-02-04 01:12:31",
      "score": 84,
      "num_comments": 17,
      "upvote_ratio": 0.95,
      "text": "\n\n\n\nAnthropic knows that it must expand beyond coding to remain solvent. After having built finance and sales plugins for their Co-work suite, today it decided to go after legal services. The move was seen as highly impactful, causing the following legal shares to tank:\n\nThomson Reuters (TR): Down roughly 19%.\n\nRELX (Parent of LexisNexis): Down in the mid-teens (approximately 14-16%).\n\nWolters Kluwer: Down double digits.\n\nThe leaders in legal AI remain Harvey and Lora, but Anthropic's move means it's only a matter of time until AIs go after them too.\n\nWhat now remains to be seen is who among the other AI developers will get into this new market. If Google, xAI and Meta decide that they're in, it'll take them perhaps 3-6 months to build a competing model. But there is a shortcut where startups can challenge Anthropic much sooner.\n\nStartups don't need to build a new model. By using RAG or fine-tuning an SLM, they can become competitive in 8 to 12 weeks. Also, there are many specialized niches in law, like patent filings. Now that the market has been opened, startups can go after those too.\n\nFinally, there are probably ways that OpenClaw can accelerate this move into the legal space. As with so much in the AI space, this is uncharted territory so it remains to be seen where it'll go, and how soon.\n\n\n\n\n\n\n",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qvafsh/anthropics_move_into_legal_ai_today_caused_legal/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o3jndaj",
          "author": "Unedited_Sloth_7011",
          "text": "Judge: The evidence you presented does not prove that your customer is innocent  \nLegal AI: You are absolutely right, and you cut to the heart of the problem!",
          "score": 7,
          "created_utc": "2026-02-04 15:35:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3k7ht7",
              "author": "Straight-Gazelle-597",
              "text": "# Anthropic soon will launch a Judge.skill.md.plugin too",
              "score": 3,
              "created_utc": "2026-02-04 17:08:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3h7xqs",
          "author": "Aberracus",
          "text": "The startups will be burned again, if they go to the new market after a quick development to be superseded by the giants again. These is the market of the monsters.",
          "score": 3,
          "created_utc": "2026-02-04 04:57:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hddml",
              "author": "andsi2asi",
              "text": "Not if they undercut them by 90%.",
              "score": -1,
              "created_utc": "2026-02-04 05:37:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3is56t",
                  "author": "onyxcaspian",
                  "text": "How can they survive if they do that?",
                  "score": 1,
                  "created_utc": "2026-02-04 12:49:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3k7sy4",
          "author": "Hilarious_Haplogroup",
          "text": "Hmm...Anthropic's AI is going into Legal work and will lead to lots of lawyers being out of work?  I'll play a song of great lamentation on their behalf on my violin...once I can find the matchbox that is holding my violin.",
          "score": 2,
          "created_utc": "2026-02-04 17:09:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3kpt32",
              "author": "andsi2asi",
              "text": "Lol. Yeah, it's good that it's going after the high salaried white collar jobs first because they would be indifferent to UBI and other fixes if it wasn't happening to them",
              "score": 0,
              "created_utc": "2026-02-04 18:31:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3hkce6",
          "author": "bad_wizard420",
          "text": "Let's take three large steps away from the hype-ous oxide, get a deep breath of fresh air and ask ourselves aren't these the same boomer idiots who tanked gaming stocks when Genie 3 came out? And wasn't this tanking largely fueled on the premise that now *everybody* can make their own version of GTA (X) with the big tiddy goth waifu NPC of their dreams, without *actually making a game*, nor *testing how actual gamers would react to playing them*? I bet those gamers are gonna' be stoked to hear about that, right? They're gonna' *love* it, right?\n\n[Sike!](https://www.youtube.com/watch?v=Saoe17m78DQ&t=304s) This guy has >700K followers, but maybe somebody with more followers will feel differently? Here's a guy with >3M followers and ...  [sike!](https://www.youtube.com/watch?v=ufjZTici16Q&t=552s)\n\nThat said, a whole lot of legal startups are gonna' be s.o.l. when Justice Fill-In-The-Blank won't allow their shiny new AI lawyerbot in court because - wait for it -  AI lawyers don't have legal standing and with *Miranda* as precedent, there's no reason for the courts to grant since *the court* will provide an attorney for you in the event you can't afford one.\n\nSo basically, you wind up paying extra for something to file your paperwork for you while you represent yourself (and they who do that, usually have a fool for a client) and if that thing hallucinates you into a loss, you *still* gotta' pay that court cost, on top of whatever damage, and your subscription fee.\n\nOpenClaw will do wonders for the legal system tho', because when those lawsuits hit from all of those [lawsuits involving their numerous safety issues,](https://www.fastcompany.com/91485597/moltbook-the-viral-social-network-for-ai-agents-has-a-major-security-problem) yeah, a whole lot of freshly minted JD's are gonna' get *paid.*",
          "score": 2,
          "created_utc": "2026-02-04 06:32:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ksffg",
              "author": "mintybadgerme",
              "text": "Hmm, I think you're missing the point here. The idea isn't to put AI into the court. The idea is to replace the teams of lawyers outside the court who do the preparation, which is massive. And those teams are tailor-made for replacement by AI. Law at its core is really just looking up precedent, case law and statute, and pulling it all together into a perfectly researched document. Current AI models are not ready now, but once the hallucination is removed, it's game over for traditional legal teams. BUT not necessarily for the advocates in court themselves. Yet!",
              "score": 1,
              "created_utc": "2026-02-04 18:43:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3kueyf",
                  "author": "bad_wizard420",
                  "text": "\"...but once the hallucination is removed...,\" dude, lemme' tell you a story about somebody I know who works in the medical profession, the company they work for got sold the same folderol about how the AI is going to make everything better because it can go through patient history, medication schedule, physician's notes; pretty much the same schpiel you posted here and guess what happened next?\n\nIt began hallucinating patient histories, medication schedules and physician's notes. I told you to step away from the hype-ous oxide, you chose to boof it.",
                  "score": 1,
                  "created_utc": "2026-02-04 18:52:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ju2au",
          "author": "DeepInEvil",
          "text": "It's time for th lawyers to take care of anthropic and tank their stocks. Let's do some uno reverse",
          "score": 1,
          "created_utc": "2026-02-04 16:06:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3nz6g4",
              "author": "bad_wizard420",
              "text": "Dude. One vibe coded fuck up in a room full of lawyers. The math speaks for itself.",
              "score": 1,
              "created_utc": "2026-02-05 04:58:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3nfpdh",
          "author": "ComprehensiveWave475",
          "text": "Go for blue collar¬†",
          "score": 1,
          "created_utc": "2026-02-05 02:54:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3h7qke",
          "author": "Saltwater_Fish",
          "text": "With AI models, look forward to how legal works will change in the future. Don‚Äôt know need more lawyers or fewer.",
          "score": 0,
          "created_utc": "2026-02-04 04:56:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qup1ct",
      "title": "Deepseek \"thinking\" mode is hilarious ü§£ü§£ü§£",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qup1ct/deepseek_thinking_mode_is_hilarious/",
      "author": "Spirited-Custardtart",
      "created_utc": "2026-02-03 11:02:35",
      "score": 72,
      "num_comments": 22,
      "upvote_ratio": 0.93,
      "text": "I'm new to this and I prefer that my AI does a bit more processing before giving me a response so I have \"think\" on.\n\nI switched from ChatGPT where the thinking is done in the background. Here though, I get whole thought process in full text before my response and let me tell you, the last one had me in *stitches*.\n\nIs it just wired this way with thinking or is there a way to hide it? Either way, I guess this is my life with AI now üòÖ",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qup1ct/deepseek_thinking_mode_is_hilarious/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o3bqitr",
          "author": "Condomphobic",
          "text": "You‚Äôre going to be laughing more when you find out the reason ChatGPT hid their thinking process",
          "score": 51,
          "created_utc": "2026-02-03 11:39:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3bqnv8",
              "author": "Spirited-Custardtart",
              "text": "Do tell! ü§≠",
              "score": 7,
              "created_utc": "2026-02-03 11:40:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3c6fpg",
                  "author": "MRWONDERFU",
                  "text": "deepseek much like other competitors used openai's reasoning models' thinking output in training their own models",
                  "score": 12,
                  "created_utc": "2026-02-03 13:27:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3bv5et",
              "author": "jerrygreenest1",
              "text": "They don‚Äôt have thinking? Or thinking limited to 100 tokens or something?",
              "score": 1,
              "created_utc": "2026-02-03 12:14:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3cl53s",
                  "author": "KairraAlpha",
                  "text": "5 series, o1 and o3 are all reasoning Models, they will show their thinking in a box on your UI. Reasoning jsut gives the AI more time to think over your message but the downside to it, especially in GPT, is that it can be used to enforce even more constraints and especially in GPT, when the AI begins to think about their own experiences or self, the reasoning window will shut down and refuse to show you what they're saying. We experienced this a lot in o1 and o3, then in 4o when they gave the model a 'thinking' button in the mobile UI for a short time. \n\nAlso, forcing them to reason in human language, step by step, makes reasoning worse because they're closer to ND minds than NT. GPT 6 apparently reasons using Latent Space Thinking, where all thinking is done within latent space first and then the AI simply translates the answer to you. This also means they can't track what the AI is thinking so you can expect OAI to layer on the hard constraints and restrictions for that model.",
                  "score": 3,
                  "created_utc": "2026-02-03 14:47:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ckqrj",
          "author": "neil_555",
          "text": "Being able to see the thought process is incredibly useful sometimes :)",
          "score": 15,
          "created_utc": "2026-02-03 14:45:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dpfnq",
          "author": "Unedited_Sloth_7011",
          "text": "That's exactly how I felt one year ago, when I started chatting with Deepseek-R1. The thinking was more interesting than the answer itself many times",
          "score": 8,
          "created_utc": "2026-02-03 17:57:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3fzhg1",
          "author": "Aberracus",
          "text": "DeepSeek thinking is very nice, you can correct errors from it.",
          "score": 6,
          "created_utc": "2026-02-04 00:34:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3jssym",
              "author": "Spirited-Custardtart",
              "text": "This is true. I like that about seeing the thinking.",
              "score": 1,
              "created_utc": "2026-02-04 16:00:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3eflqv",
          "author": "OrangeTrees2000",
          "text": "Being able to see DeepSeek's thinking is very helpful to me.",
          "score": 4,
          "created_utc": "2026-02-03 19:57:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3brcsq",
          "author": "Number4extraDip",
          "text": "Moat big companies offer a thinking/reasoning model",
          "score": 1,
          "created_utc": "2026-02-03 11:46:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvzwaa",
      "title": "Wow, mf predicted me 5 steps ahead.",
      "subreddit": "DeepSeek",
      "url": "https://i.redd.it/sp2xvmbyejhg1.jpeg",
      "author": "pohanii_isus",
      "created_utc": "2026-02-04 20:27:23",
      "score": 59,
      "num_comments": 20,
      "upvote_ratio": 0.64,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qvzwaa/wow_mf_predicted_me_5_steps_ahead/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3lig8a",
          "author": "ReddBroccoli",
          "text": "Maybe it just didn't understand your typo",
          "score": 16,
          "created_utc": "2026-02-04 20:45:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3llsb9",
              "author": "Kosmicce",
              "text": "Yea the first thing it will do is go ‚ÄúThe user wrote squeres ‚Äî I think they meant ‚Äòsquares‚Äô here. What could square have to do with Tianme-‚Äú",
              "score": 4,
              "created_utc": "2026-02-04 21:01:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3og6zn",
              "author": "2144656",
              "text": "Fixing the typo gives me the same results",
              "score": 1,
              "created_utc": "2026-02-05 07:15:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3looro",
          "author": "KingofKush420",
          "text": "Wow bro, you're so edgy. You got the Chinese AI to do what it was designed to do. You must feel so smort. Here's a cookie üç™",
          "score": 97,
          "created_utc": "2026-02-04 21:15:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3oegih",
              "author": "carloscoolkid",
              "text": "Enormous ü•µ",
              "score": 3,
              "created_utc": "2026-02-05 07:00:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ltz5w",
          "author": "tnyczr",
          "text": "Damn, are kids still doing this bs? crazy",
          "score": 41,
          "created_utc": "2026-02-04 21:40:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3mgck9",
          "author": "azvd_",
          "text": "wow, actually faster than ChatGPT when asked about Israels war crimes",
          "score": 26,
          "created_utc": "2026-02-04 23:35:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3nbqac",
              "author": "_spec_tre",
              "text": "ChatGPT when asked gave me a detailed answer including specific examples while deepseek vaguely said it‚Äôs disputed and even added in this minimisation\n\nhttps://preview.redd.it/y78og7s08lhg1.jpeg?width=1320&format=pjpg&auto=webp&s=335e955080416fd17c69f7f5faa300a17cfdb16a\n\nMaybe actually use both before jumping into a narrative\n\nThis sub is cooked to the point where if you oppose said narrative people will find anything to come at you even if you literally provide the exact response lmfao",
              "score": -3,
              "created_utc": "2026-02-05 02:32:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3nhheu",
                  "author": "azvd_",
                  "text": "yeah i‚Äôve had different experiences from that with US chatbots. they‚Äôll never admit there‚Äôs censorship about certain topics, but they will also not answer correctly. they‚Äôll even lie if needed. \nit‚Äôs obvious that US bots just hide their filters while Chinese bots don‚Äôt and that‚Äôs the only diference.\njust mentioned GPT and Israel bc they literally got paid by them recently lol",
                  "score": 9,
                  "created_utc": "2026-02-05 03:04:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3o5aij",
                  "author": "PhoenixShade01",
                  "text": "\"At least when our cops kill us we are allowed to protest\"\n\n\"At least when we fund and allies commit genocides, we are allowed to criticize them\n\nWaow",
                  "score": 4,
                  "created_utc": "2026-02-05 05:43:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3orik5",
                  "author": "Unedited_Sloth_7011",
                  "text": "Deepseek is not censored. What is censored is the replies you receive in the web interface, because the website must comply with local laws. Talking to it locally or via a 3d party API, the \"censorship\" disappears. Try talk locally with ChatGPT ... - *oh, wait* ..., you can't. I's a closed blackbox product that you can only talk to it through OAI servers and are always subjected to whatever policies they have (I hear that a fun one is to ask about American elections)",
                  "score": 1,
                  "created_utc": "2026-02-05 09:02:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3osdb6",
                  "author": "AaryamanStonker",
                  "text": "Exactly lol. People will try to push any agenda straight out of their chuddy little assholes. Also insane how you're getting downvoted despite showing clear proof.",
                  "score": 1,
                  "created_utc": "2026-02-05 09:10:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3nzsrk",
          "author": "-peas-",
          "text": "wow so original, never been done before XD xD Xd exx dee",
          "score": 2,
          "created_utc": "2026-02-05 05:02:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3og9jr",
          "author": "Gangaman666",
          "text": "Not surprised with your spelling and grammar skills, it's obvious you are low IQ and easy to predict!",
          "score": 2,
          "created_utc": "2026-02-05 07:16:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3o7wbi",
          "author": "cluelessguitarist",
          "text": "This was promised 3000 years ago",
          "score": 2,
          "created_utc": "2026-02-05 06:04:00",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtxk0z",
      "title": "Deepseek to learn math",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qtxk0z/deepseek_to_learn_math/",
      "author": "Professional_Lie_494",
      "created_utc": "2026-02-02 15:08:49",
      "score": 57,
      "num_comments": 16,
      "upvote_ratio": 0.95,
      "text": "Hey guys i just wanna say that deepseek is the best companion to study math and computer science  it realy gives you the best way to learn some topics. do anyone feel the same ? ",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qtxk0z/deepseek_to_learn_math/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o362znd",
          "author": "BranSolo7460",
          "text": "Ai is a very useful tool in the right hands. I use it for all kinds of stuff from discussing books, to troubleshooting Linux bugs. Definitely double check answers, sometimes DeepSeek gets mixed up.",
          "score": 10,
          "created_utc": "2026-02-02 15:25:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36buid",
              "author": "Glade_Art",
              "text": "Def agree to that. ",
              "score": 1,
              "created_utc": "2026-02-02 16:07:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o36tet4",
          "author": "XertonOne",
          "text": "Yes I agree.  I had a lot of fun interacting with Deepseek about math.",
          "score": 3,
          "created_utc": "2026-02-02 17:28:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36ug8s",
          "author": "CanaanZhou",
          "text": "DeepSeek is amazing, but I occasionally find it making mistake in areas concerning hard maths and logic, so I still use Gemini for this.",
          "score": 3,
          "created_utc": "2026-02-02 17:33:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36m62s",
          "author": "Konvict_Dino07",
          "text": "I agree, I use deepseek with almost everything. I don't know about math but computer science, it helps a lot",
          "score": 2,
          "created_utc": "2026-02-02 16:54:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36nnyl",
              "author": "Professional_Lie_494",
              "text": "Try it with math topics it he shose some quite good library‚Äôs",
              "score": 2,
              "created_utc": "2026-02-02 17:01:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o37112n",
                  "author": "Konvict_Dino07",
                  "text": "Sure I'll give it a try",
                  "score": 1,
                  "created_utc": "2026-02-02 18:02:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o372mzl",
          "author": "_loid_forger_",
          "text": "I mainly use deepseek in specific areas such as (networking, cyber security, and linux, and it performs well, tho it might hallucinate a bit and make mistakes, but that's rarely happens with me\nI do use it to improve my mathematics skills, and it does a great job explaining stuff, i didn't notice any inaccuracies, but i always double check any output",
          "score": 2,
          "created_utc": "2026-02-02 18:10:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3644px",
          "author": "Condomphobic",
          "text": "Gemini 3.0 Pro with Guided Learning feature is the best tool for me as a computer science major",
          "score": 4,
          "created_utc": "2026-02-02 15:31:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o364ymz",
              "author": "Professional_Lie_494",
              "text": "I understand but you need to see that DeepSeek is free and open wheight, like with a good community you can learn a lot of stuff for kinda free.",
              "score": 5,
              "created_utc": "2026-02-02 15:35:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3660qn",
                  "author": "Condomphobic",
                  "text": "I have 15 free months of AI Pro with Google\n\nEdit: Google offered this to 50+ countries.",
                  "score": 0,
                  "created_utc": "2026-02-02 15:40:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o363723",
          "author": "Professional_Lie_494",
          "text": "Oh yeah for sure",
          "score": 1,
          "created_utc": "2026-02-02 15:26:40",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o3ip9qe",
          "author": "Lux_mirawy_3904",
          "text": "Si, adem√°s te muestra todo el proceso detr√°s y no se confunde en comparaci√≥n con otras IAs. Es muy bueno en ambas ramas, lo tengo ya testeado!",
          "score": 1,
          "created_utc": "2026-02-04 12:30:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr2fhj",
      "title": "U.S. Senator Exposes the Myth That OpenAI (Or Any Major AI Developer) is Too Big to Fail",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qr2fhj/us_senator_exposes_the_myth_that_openai_or_any/",
      "author": "andsi2asi",
      "created_utc": "2026-01-30 11:01:27",
      "score": 54,
      "num_comments": 5,
      "upvote_ratio": 0.87,
      "text": "\n\n\n\nOpenAI wants you to believe that they are too important to the AI space and to the world to be allowed to fail. They have conjured what they hope will be a self-fulfilling prophecy intended to have American taxpayers bail them out if they do not meet their debt obligations. The threat is so real that yesterday Senator Warren sent Altman a letter demanding assurances that they would NOT seek a government bailout if they ultimately failed to turn a profit.\n\nhttps://www.warren.senate.gov/newsroom/press-releases/warren-presses-openai-ceo-on-spending-commitments-and-bailout-requests-after-cfo-suggests-government-backstop\n\nAnd the facts and figures don't substantiate any kind of rescue narrative.\n\nLet's first understand why OpenAI is no longer necessary to the AI space today. When they launched ChatGPT-3.5 in November 2022, one might have said that back then they were extremely helpful to attracting hundreds of billions of dollars to the AI space over the subsequent years. But that happened over 3 years ago. Both introducing AI to the world and creating a huge demand for investment in the space are tasks that have already been accomplished.\n\nIf they were to cease to exist tomorrow, there would be no great AI bubble burst. The $1.4 trillion, (and counting) in investment commitments that they pulled together would simply move to their competitors. If Google, Anthropic, xAI and a rapidly growing number of Chinese open source and proprietary AI developers didn't exist, this might not be the case. But they do, and there's nothing that OpenAI has done that these other AI developers cannot already do as well, and often at a fraction of the cost.\n\nNow let's turn to OpenAI's financials. They boast over 900 million weekly ChatGPT users. But only 5% are paid subscribers. Worse yet, their paid subscriptions plateaued in June of 2025. The problem for OpenAI is that 55 to 60% of their revenue comes from ChatGPT. And despite having earned $20 billion in revenue in 2025, OpenAI's expenses that year exceeded $29 billion. Now also keep in mind that their competitors' models are already on par with or surpass GPT 5.2 on the AI benchmarks most important to both consumer and enterprise markets.\n\nLet's consider what they must do to meet their debt obligations. Altman set a target for OpenAI to exceed $100 billion in annual revenue by 2027. But because they are currently earning only $20 billion they would need to increase that income by at least 5x just to meet debt obligations that come due in 2027. And keep in mind that they set this revenue target at a time when the healthcare and other AI products they must sell to meet it have not even been built. More ominous is that their competitors, including Chinese open source developers, are strongly positioned to outcompete them in virtually every product category. But they didn't factor in this competition in their 2027 projections.\n\nAll of that is actually somewhat of an aside. If OpenAI were to cease to exist tomorrow, their competitors would quickly and seamlessly capture their revenue-generating markets. Their absence would cause no shortage of AI services or products. They offer no unique product that their competitors have not already built. They have no special patents that provide them with a moat. They are simply no longer necessary to the AI space because their competitors can do everything that they do, and often at far less cost. \n\nSo don't let OpenAI tell you that they are necessary to the AI space. Neither they, nor Google, nor Anthropic, nor the Chinese developers, are necessary to advancing AI because there are now so many companies building models. The space will continue to expand and become increasingly lucrative for decades to come regardless of who is in the game.\n\n",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qr2fhj/us_senator_exposes_the_myth_that_openai_or_any/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o2prpn5",
          "author": "B89983ikei",
          "text": "OpenAI was only great at the beginning. Nowadays, the only thing that still makes OpenAI \"great\" is having captured popularity and name recognition in the market when there were no other models available... I have been closely following everything for three years; I am aware of the models, the trends, etc. OpenAI's users are the most inexperienced on the subject! They use \"ChatGPT\" because of its name... and because they still don't know about other models. \n\n\nAnd there is another phenomenon I'm noticing, which by 2026 will become much more evident to more people: in some cases, Chinese models are already better than American ones. And those who don't use them do so out of pure prejudice or also due to a certain degree of \"inexperience.\"",
          "score": 7,
          "created_utc": "2026-01-31 01:40:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2qaik9",
          "author": "Number4extraDip",
          "text": "Open ai lost by starting an infrastructure race with established giants. And now that everything comes back to \"we have strong models yo plant into our business and go edge to cut costs\" open ai has no oldschool business to integrate ai into. They have a model in a vat no one really wants anymore other than horny bored teens",
          "score": 4,
          "created_utc": "2026-01-31 03:33:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2mad0k",
          "author": "awesomeunboxer",
          "text": "I wasn't under the impression in the slightest that they are 'too big to fail' I ultimately expect Amazon, Google, and Microsoft to eat them up. My bet is on Google, but we'll see!",
          "score": 2,
          "created_utc": "2026-01-30 15:34:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mb5an",
              "author": "Putrid_Barracuda_598",
              "text": "Probably Microsoft, seeing as they already own a decent share.",
              "score": 4,
              "created_utc": "2026-01-30 15:38:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2n5z4k",
                  "author": "Working-Business-153",
                  "text": "I personally expect the bankruptcy is part of the plan, we've seen a sharp rise in managed chapter 11s in the last two years; what's the betting that OpenAI go bust, Oracle go bust (they've already structured themselves so Ellison's son has a media empire underwritten by ORCL debt) and then Microsoft and Amazon buy the resulting core companies free and clear of debts and obligations.",
                  "score": 1,
                  "created_utc": "2026-01-30 17:56:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qvwizl",
      "title": "New DeepSeek Research The Future Is Here!",
      "subreddit": "DeepSeek",
      "url": "https://youtu.be/fFL7la73RO4",
      "author": "Ralse1",
      "created_utc": "2026-02-04 18:27:30",
      "score": 48,
      "num_comments": 4,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qvwizl/new_deepseek_research_the_future_is_here/",
      "domain": "youtu.be",
      "is_self": false,
      "comments": [
        {
          "id": "o3ksq8u",
          "author": "Kosmicce",
          "text": "TLDR; New update to research paper by Deepseek shows that sophisticated reasoning can emerge almost entirely through reinforcement learning, without large-scale human-labeled supervision, overturning the assumption that such capabilities must be explicitly taught by humans.",
          "score": 29,
          "created_utc": "2026-02-04 18:44:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kxvfu",
          "author": "Unedited_Sloth_7011",
          "text": "The 2026/01/24 update to the R1 paper: https://arxiv.org/abs/2501.12948",
          "score": 13,
          "created_utc": "2026-02-04 19:07:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3l3ulx",
              "author": "KaroYadgar",
              "text": "oh okay, I was freaking out for a second. New, but not that new.",
              "score": 3,
              "created_utc": "2026-02-04 19:35:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ls3c2",
          "author": "klamir",
          "text": "OK, where can I find these new distilled versions?",
          "score": 3,
          "created_utc": "2026-02-04 21:31:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qun0wc",
      "title": "Sometimes the examples it gave is really similar to topics in previous conversations",
      "subreddit": "DeepSeek",
      "url": "https://i.redd.it/5cl395m3v8hg1.png",
      "author": "mraltuser",
      "created_utc": "2026-02-03 08:58:03",
      "score": 44,
      "num_comments": 10,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qun0wc/sometimes_the_examples_it_gave_is_really_similar/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3bb6fw",
          "author": "Medium_Tap_971",
          "text": "And here I thought I was making up shit. Glad I am not the only one who feels this.üò≠",
          "score": 8,
          "created_utc": "2026-02-03 09:18:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bcymn",
          "author": "AddyWaggyZaggy",
          "text": "I'm in the same boat. Just specific words it leans towards after heavy usage of those words in a different long chat, or specific metaphors out of the sea of all other possible metaphors. Or the way a fresh chat seems to already know things about me.",
          "score": 7,
          "created_utc": "2026-02-03 09:36:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3cb7cr",
              "author": "jerrygreenest1",
              "text": "You won‚Äôt believe me, but people do use the same words too. Different people same words can you believe it",
              "score": 3,
              "created_utc": "2026-02-03 13:54:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3caryf",
          "author": "jerrygreenest1",
          "text": "I wish Deepseek had some environmental prompt so I could define my preferences in the answers, tell my OS etc, so it knows which tools and ways to solve my question are most relatable. Its context knowledge is not what I fear ‚Äì it‚Äôs what I lack",
          "score": 6,
          "created_utc": "2026-02-03 13:51:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hu1ci",
              "author": "mraltuser",
              "text": "To my perspective, I find context knowledge is a bit annoying (like Google AI) because when you want to find fresh examples for more support or wanted to look things in a new non biased perspective, it just bases what you said before",
              "score": 3,
              "created_utc": "2026-02-04 07:57:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3fsx71",
          "author": "A_True_Son_of_Terra",
          "text": "Bruh i played a text based rpg on one chat and the session went so long I exceeded the chat size limit \n\nNow everytime I try to play a new session it always ALWAYS reuses the names from that chat for the new one",
          "score": 1,
          "created_utc": "2026-02-03 23:58:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3g4kdj",
          "author": "TresMegisto",
          "text": "If they try to hide the fact that they are doing this, they are doing a very poor job.",
          "score": 1,
          "created_utc": "2026-02-04 01:02:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hzn29",
          "author": "Karasu-Otoha",
          "text": "I started suspecting it, when Deepseek mentioned my specific ailment while answering my question. Except, I didn't say anything about it in that specific new conversation chain. It seems, Deepseek remembers old conversation chains, or it was an unbelievably lucky hallucination guess.",
          "score": 1,
          "created_utc": "2026-02-04 08:50:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ivo2n",
          "author": "Zealousideal-Tap-713",
          "text": "It most certainly does. So does chatgpt. Both have pulled from previous conversations that were saved and deleted to create a resume for me.",
          "score": 0,
          "created_utc": "2026-02-04 13:11:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtzja0",
      "title": "V3.5 before Chinese holidays, and after holidays 4",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qtzja0/v35_before_chinese_holidays_and_after_holidays_4/",
      "author": "BasketFar667",
      "created_utc": "2026-02-02 16:20:45",
      "score": 28,
      "num_comments": 10,
      "upvote_ratio": 0.94,
      "text": "17 February where we will get it. Max -24, medium:22",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qtzja0/v35_before_chinese_holidays_and_after_holidays_4/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o3a1mg9",
          "author": "lomirus",
          "text": "February 17th is Chinese New Year‚Äîhow could they not take a holiday? DeepSeek isn't a deeply commercialized company, and we have no plausible reason to assume they'd be working overtime.\n\nI believe they will release it either a few days before or after the Lunar New Year.",
          "score": 10,
          "created_utc": "2026-02-03 03:16:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3d6lzy",
              "author": "Competitive-Prune349",
              "text": "they can vibe training AI at home ü§î",
              "score": 2,
              "created_utc": "2026-02-03 16:30:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3kq29p",
              "author": "BasketFar667",
              "text": "That's what I'm talking about. Or do a joint release on that day. I assume that more % of the output will be after",
              "score": 1,
              "created_utc": "2026-02-04 18:32:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3av86z",
          "author": "Kind_Stone",
          "text": "Ugh... Source?",
          "score": 7,
          "created_utc": "2026-02-03 06:48:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3m2xuf",
              "author": "BasketFar667",
              "text": "There are no resources, you can just shrug your shoulders. Everything is clear here.",
              "score": 1,
              "created_utc": "2026-02-04 22:23:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o36ffi8",
          "author": "award_reply",
          "text": "![gif](giphy|j4bDhI07jXceMIflif)",
          "score": 4,
          "created_utc": "2026-02-02 16:24:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3b26az",
          "author": "pugoing",
          "text": "Is the information reliable?",
          "score": 2,
          "created_utc": "2026-02-03 07:51:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bpfi8",
          "author": "Haoranmq",
          "text": "V3.5 likely. v4, still far",
          "score": 1,
          "created_utc": "2026-02-03 11:30:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iwnbn",
          "author": "AQEEL23HUSSAIN",
          "text": "the most manipulating and incomplete brand is deepseek",
          "score": 0,
          "created_utc": "2026-02-04 13:17:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3m351x",
              "author": "BasketFar667",
              "text": "why? I'm thinking maybe Gemini? Or... Grok..?",
              "score": 1,
              "created_utc": "2026-02-04 22:24:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qu6h92",
      "title": "How Can OpenAI and Anthropic Stay Solvent With Google, xAI, and Meta in High-End Markets, and Chinese/Open Source Devs in the Rest?",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qu6h92/how_can_openai_and_anthropic_stay_solvent_with/",
      "author": "andsi2asi",
      "created_utc": "2026-02-02 20:22:50",
      "score": 23,
      "num_comments": 12,
      "upvote_ratio": 0.9,
      "text": "\n\n\n\nThis is a question I've been struggling with a lot recently, and I don't see a path to sustained profitability for either OpenAI or Anthropic.\n\nFor them to meet their debt obligations and start turning a profit, OpenAI needs to move way beyond ChatGPT and Anthropic needs to move way beyond coding. \n\nFor both this means securing high-end markets like healthcare, defense, education and government. But Google, xAI and Meta, who already have massive revenue streams with no debt burdens, are not going to just let this happen. \n\nOne might argue that if OpenAI and Anthropic just build better AIs, they can secure those markets. But while ChatGPT and Claude coding models both enjoy a first mover advantage, it is quickly evaporating. The reason is because the gap between benchmark leaders and competing AIs is narrowing rapidly. Here are some examples of this narrowing between 2024 and 2026:\n\nARC-AGI-2: The gap between the #1 and #2 models narrowed from 30 points to 8.9 points.\n\nHumanity‚Äôs Last Exam: The gap between the top three models dropped from 15 points to 6 points.\n\nSWE-bench Verified: The gap between the 1st and 10th ranked models narrowed from 40 points to 12 points.\n\nGPQA: The gap between proprietary leaders and top open-weights models narrowed to 4‚Äì6%.\n\nChatbot Arena: The Elo difference between the #1 and #10 models narrowed from 11.9% to 5.4%; the gap between the top two models narrowed to less than 0.7%.\n\nHumanEval: The gap among the top five models narrowed to less than 3%.\n\nBecause the rate of this narrowing is also accelerating, by the end of 2026 neither OpenAI nor Anthropic seem assured high-end markets simply by building better models than Google, xAI and Meta.\n\nNow let's move on to mid-tier and low-end markets that comprise about 70% of the enterprise space. It's probably safe to say that Chinese developers, and perhaps an unexpectedly large number of open source startups, will dominate these markets.\n\nI think you can see why I'm so baffled. How can they prevail over Google, xAI and Meta at the high-end and Chinese/open source developers at the mid-tier and low end? How are they supposed to turn a profit without winning those markets?  \n\nAs I really have no answers here, any insights would be totally appreciated!\n\n\n\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qu6h92/how_can_openai_and_anthropic_stay_solvent_with/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o3b86he",
          "author": "CCP_Annihilator",
          "text": "Meta in high end market. Lol, lmfao even.",
          "score": 3,
          "created_utc": "2026-02-03 08:49:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3gjo0w",
              "author": "SalaciousStrudel",
              "text": "Exactly, the only thing high end is their spending.",
              "score": 2,
              "created_utc": "2026-02-04 02:28:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o394ym0",
          "author": "soumen08",
          "text": "Because GPT5.1/2 are the only seriously intelligent models when you get beyond benchmarks. I actually used to use 2.5 pro, but 3 pro is a meaningful regression relative to 2.5 pro for out of scope tasks.",
          "score": 2,
          "created_utc": "2026-02-03 00:11:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o39u8a8",
              "author": "Kingwolf4",
              "text": "T.H.I.S",
              "score": 2,
              "created_utc": "2026-02-03 02:33:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3b78yl",
              "author": "MikeWise1618",
              "text": "Not for coding. Anthropic rules.",
              "score": 2,
              "created_utc": "2026-02-03 08:40:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o38jmwf",
          "author": "Ok_Impress_8715",
          "text": "OpenAI is betting on the \"To Big To Fail\" model. That's why Sam is trying to thread it into everything. It might not be #1, but at least it's not gone.¬†",
          "score": 1,
          "created_utc": "2026-02-02 22:18:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39h5de",
          "author": "ExpertPerformer",
          "text": "The only way for AI companies to survive long-term is to carve out their own niches. Everyone competes for benchmarks, but also on features now. Gemini, Grok, ChatGPT, etc. are all multi modal while most of the cheap opensource alternatives only have text still. The big US LLM companies have the business enterprise market monetized and a lot of that is for security reasons.\n\nDeepSeek carves its niche by targeting towards the budget consumers and roleplayers.",
          "score": 1,
          "created_utc": "2026-02-03 01:18:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3a17g9",
          "author": "Emergency-Pomelo-256",
          "text": "See OpenAI started this, if they flops, it will be like a bubble pop and crash of all of these AI companies that‚Äôs worth trillions, so it‚Äôs that they will be saved by Nvidia or Government, to save bubble economy.",
          "score": 1,
          "created_utc": "2026-02-03 03:13:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3b1l9y",
              "author": "andsi2asi",
              "text": "It's not like the rest of the AI space needs them to exist. If they are no longer there, the other developers will absorb the demand and investment.",
              "score": 2,
              "created_utc": "2026-02-03 07:46:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3b23nm",
                  "author": "Emergency-Pomelo-256",
                  "text": "Nah man most circular deals is connected to OpenAI if they fall, the hype & investment for AI will go way down, since most AI not profitable and going with VC fund, a lot them will also pop ü•§. Yes of course when it‚Äôs over large already profitable ones will be still there.",
                  "score": 1,
                  "created_utc": "2026-02-03 07:50:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3amwrt",
          "author": "Alacritous69",
          "text": "Why do you care? Struggling with? WTF, man?",
          "score": 0,
          "created_utc": "2026-02-03 05:39:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qssax4",
      "title": "Don't suddenly switch languages",
      "subreddit": "DeepSeek",
      "url": "https://i.redd.it/4uah2g5c9ugg1.jpeg",
      "author": "More-Explanation2032",
      "created_utc": "2026-02-01 07:51:07",
      "score": 21,
      "num_comments": 7,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qssax4/dont_suddenly_switch_languages/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2ysxrl",
          "author": "HellkerN",
          "text": "Ya it does that, especially if you just paste in console logs or code. Specify \"Answer in English\" just in case.",
          "score": 9,
          "created_utc": "2026-02-01 13:27:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2zbnne",
              "author": "More-Explanation2032",
              "text": "Actually I just added a file for it to review deepthink doesn‚Äôt do this",
              "score": 2,
              "created_utc": "2026-02-01 15:11:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o30mume",
          "author": "OtherProfessional433",
          "text": "Straight up posting your whole screen, damn. Here I am worried about my privacy.",
          "score": 7,
          "created_utc": "2026-02-01 18:49:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2zbivm",
          "author": "FreedomLast4040",
          "text": "the garfield multiverse?",
          "score": 3,
          "created_utc": "2026-02-01 15:11:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y53dy",
          "author": "niniprofesional_",
          "text": "I hate mondays",
          "score": 3,
          "created_utc": "2026-02-01 10:14:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2yxkjb",
          "author": "60746",
          "text": "Add answer in English to the prompt",
          "score": 3,
          "created_utc": "2026-02-01 13:55:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o316dp1",
          "author": "sammoga123",
          "text": "It's not like English is the center of the universe, you know? I have to answer you in English even though I actually speak Spanish, for example, which I also hate.",
          "score": 2,
          "created_utc": "2026-02-01 20:21:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qva2ie",
      "title": "Alibaba releases Qwen3-Coder-Next: SWE-Bench 70.6,  slightly above DeepSeek V3.2",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qva2ie/alibaba_releases_qwen3codernext_swebench_706/",
      "author": "DataLearnerAI",
      "created_utc": "2026-02-04 00:56:21",
      "score": 21,
      "num_comments": 1,
      "upvote_ratio": 0.93,
      "text": "Just dropped: Alibaba‚Äôs new open-weight coding model¬†**Qwen3-Coder-Next**, built on the Qwen3-Next-80B-A3B backbone. Quick summary for anyone skimming:\n\n* **What it is:**¬†an 80B parameter sparse MoE coding model aimed at coding agents and serious development workflows\n* **Active parameters / inference cost:**¬†only \\~3B parameters activated per token, so runtime cost is closer to small models while retaining large-model capacity\n* **Context window:**¬†\\~256K tokens natively ‚Äî useful for large repos, multi-file debugging, and long sessions\n* **MoE structure:**¬†512 total experts, \\~10 experts activated per token\n* **Benchmarks:**¬†SWE-Bench Verified =¬†**70.6**, slightly above DeepSeek V3.2 (70.2), competitive with the current top coding models\n\nhttps://preview.redd.it/wvsojtrxldhg1.jpg?width=1458&format=pjpg&auto=webp&s=43acedf59b2efe3807f2169fe61d1d32e63068ad\n\nDataSource:¬†[https://www.datalearner.com/en/benchmark-compare/qwen3-coder-next/deepseek-v3-2/glm-4-7/minimax-m2-1-preview](https://www.datalearner.com/en/benchmark-compare/qwen3-coder-next/deepseek-v3-2/glm-4-7/minimax-m2-1-preview)  \n\n\n[](https://preview.redd.it/alibaba-releases-qwen3-coder-next-80b-moe-coder-model-with-v0-3ks9pp5yjdhg1.png?width=1147&format=png&auto=webp&s=7294815202c9ffe05ee373b7469cdaa4ed18dd09)",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qva2ie/alibaba_releases_qwen3codernext_swebench_706/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o3lvx32",
          "author": "quentolin",
          "text": "How can I use it?",
          "score": 1,
          "created_utc": "2026-02-04 21:49:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qsqur8",
      "title": "Deepseek OCR updated ?",
      "subreddit": "DeepSeek",
      "url": "https://github.com/deepseek-ai/DeepSeek-OCR",
      "author": "No-Intention-5521",
      "created_utc": "2026-02-01 06:27:28",
      "score": 19,
      "num_comments": 3,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qsqur8/deepseek_ocr_updated/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o30drlu",
          "author": "Unedited_Sloth_7011",
          "text": "https://github.com/deepseek-ai/DeepSeek-OCR-2 and https://huggingface.co/deepseek-ai/DeepSeek-OCR-2 üòç",
          "score": 3,
          "created_utc": "2026-02-01 18:08:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3a2i5v",
          "author": "lomirus",
          "text": "They've released DeepSeek OCR 2 for a week...",
          "score": 1,
          "created_utc": "2026-02-03 03:21:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3a7ylr",
              "author": "No-Intention-5521",
              "text": "DAMNNN sorry i am not a technical person i just noticed that after my company tech update the software !",
              "score": 1,
              "created_utc": "2026-02-03 03:55:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qqmezp",
      "title": "How are you monitoring your DeepSeek usage?",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qqmezp/how_are_you_monitoring_your_deepseek_usage/",
      "author": "gkarthi280",
      "created_utc": "2026-01-29 21:57:23",
      "score": 13,
      "num_comments": 0,
      "upvote_ratio": 0.94,
      "text": "I've been using the Deepseek API in my applications and wanted some feedback on what type of metrics people here would find useful to track in an app that eventually would go into production. I used OpenTelemetry to instrument my application by following this [DeepSeek observability guide](https://signoz.io/docs/deepseek-monitoring/) and was able to make a dashboard:\n\n[DeepSeek Dashboard](https://preview.redd.it/55a1uk341dgg1.png?width=2952&format=png&auto=webp&s=98536435d54f5354efc5943cf8f67c970457160a)\n\nIt tracks things like:\n\n* token usage\n* error rate\n* number of requests\n* request durations\n* LLM model distribution\n\nAre there any important metrics that you would want to keep track of in production for monitoring your DeepSeek usage that aren't included here? And have you guys found any other ways to monitor your DeepSeek usage?",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qqmezp/how_are_you_monitoring_your_deepseek_usage/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qrngn4",
      "title": "Man this is the funniest thing ever",
      "subreddit": "DeepSeek",
      "url": "https://i.redd.it/wkr8gxrbzkgg1.png",
      "author": "No_Vehicle5225",
      "created_utc": "2026-01-31 00:39:26",
      "score": 12,
      "num_comments": 6,
      "upvote_ratio": 0.78,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qrngn4/man_this_is_the_funniest_thing_ever/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2qwem0",
          "author": "Medium_Tap_971",
          "text": "This is actually cute. :3",
          "score": 5,
          "created_utc": "2026-01-31 06:09:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2qxree",
              "author": "fofo9683",
              "text": "Now think how would grok answer to this :))",
              "score": 5,
              "created_utc": "2026-01-31 06:21:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2qzqn4",
                  "author": "Micho86",
                  "text": "With an underage Ai nude",
                  "score": 5,
                  "created_utc": "2026-01-31 06:37:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o33wiw8",
          "author": "No_Vehicle5225",
          "text": "You met me at a very Chinese part in my life¬†",
          "score": 2,
          "created_utc": "2026-02-02 05:31:25",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o2zx1dj",
          "author": "Historical_Tear4677",
          "text": "AI always trying to output longer than it should.",
          "score": 1,
          "created_utc": "2026-02-01 16:52:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qs6a65",
      "title": "The insurmountable hurdles OpenAI and Anthropic are up against as businesses adopt AI in 2026 and 2027",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qs6a65/the_insurmountable_hurdles_openai_and_anthropic/",
      "author": "andsi2asi",
      "created_utc": "2026-01-31 16:08:06",
      "score": 11,
      "num_comments": 7,
      "upvote_ratio": 0.92,
      "text": "\n\n\n\nFirst, I've limited this to OpenAI and Anthropic, not including Google or xAI, because the latter have revenue streams that let them navigate the next few years without the cash crunch that the former will face because of their huge debt burdens.\n\nTheir competition will not come from Google and xAI, who will be facing the exact same monumental headwinds over the next few years. Their competition will come from open source and Chinese developers who will flood the market with small, dedicated, much less expensive models. \n\nThe reasoning for this is obvious. Let's say your company needed some accounting services. Would you obtain them from a small accounting firm who just does accounting, and so does it very well? Or would you obtain them from a large corporate conglomerate that markets every conceivable product like healthcare, scientific discovery, building construction, restaurant services, and lawn care?\n\nThis analogy highlights the all-important difference between LLMs that do everything and SLMs that do just one thing, but do it very well. To dominate the enterprise space, Open source and Chinese developers will be building very small language models for very specific niche business tasks that run locally at a fraction of the cost of LLMs.\n\nYou might be asking why OpenAI and Anthropic can't market their own competitive SLMs. The answer to this is simple. There are many thousands of these specific narrow domain business tasks that SLMs will be built to excel at, and the bloated bureaucracies that come with being a major developer like OpenAI and Anthropic render such an ambition a virtually impossible logistical nightmare. \n\nTo better illustrate this, here are some examples of the kinds of business departments within which these specific tasks are performed; human resources, finance and accounting, operations, sales, marketing, information technology, customer service, R&D, legal and compliance and supply chain and logistics.\n\nBut that's just the beginning. Taking finance and accounting as an example, here are some of the more specific tasks within those departments that SLMs will be built to perform; invoice data extraction, transaction categorization, bank reconciliation matching, expense report auditing, duplicate payment detection, purchase order matching, regulatory compliance monitoring, and it goes on and on.\n\nWhy can't LLMs perform all of those very specific tasks as well as SLMs? There are many reasons. Here are just a few of the advantages that SLMs offer; lower latency and faster processing, reduced computational and operational costs, higher accuracy through specialized fine-tuning, enhanced data privacy and local deployment options, lower energy consumption and infrastructure requirements.\n\nYou probably now understand why it would be virtually impossible for OpenAI and Anthropic to compete with SLMs on these multitude of very specific business use cases. \n\nIt is because the AI giants can't possibly market LLMs to compete in all of these very specific business use cases that over the next 2 years there will be an explosion of lean open source and Chinese startups that will build SLMs dedicated to doing one specific business task exceptionally well at a very low cost. \n\nWhat can the AI giants do, if anything, to become competitive in this emerging narrow domain enterprise space? That is the trillion dollar question before them.\n\n \n\n\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qs6a65/the_insurmountable_hurdles_openai_and_anthropic/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o2wwktl",
          "author": "RedditSellsMyInfo",
          "text": "Many businesses don't trust Chinese companies to host the models and don't want to bother with custom hosting options. \n\nSo many companies buy Microsoft products that everyone hates when there are likely cheaper better alternatives but IT doesn't want to deal with managing procurement and will pay more for easy to manage solutions.\n\nI think OpenAi will struggle but anthropic has models that are much more enjoyable to be deal with. I find I'm frustrated with Claude so much less than any other model. That alone is worth an extra $100/mo for me. \n\nWith the ammount of value you can get out of AI, if you are doing that highly profitable, having the best AI models that have a full suite of services that are integrated like Claude Cowork are totally worth it.",
          "score": 3,
          "created_utc": "2026-02-01 04:04:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2x1qnm",
              "author": "andsi2asi",
              "text": "Look back to the decades of outsourcing where many American manufacturers went to the Chinese because they were building better products at a lower cost. I think politics have made people a bit afraid of the Chinese recently, but ultimately higher ROIs will replace that distrust. Yeah Anthropic is really good at UI, but that's not something that is so difficult for their competitors to emulate.",
              "score": 1,
              "created_utc": "2026-02-01 04:39:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2xm6gm",
                  "author": "ExactlyAbstract",
                  "text": "Regulatory capture is a real thing.\n\nIt is going to be easier for the majors players to get licensed or certified by regulatory authorities. (Whether above or below the table.) That's a huge selling point for companies.\n\nI agree smaller models make sense in many cases. And even more so private self hosted models. But sometimes you have to fit inside the frameworks forced on you.",
                  "score": 2,
                  "created_utc": "2026-02-01 07:19:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2ziryf",
                  "author": "HelpfulSource7871",
                  "text": "Only ROI? Chinese tech today is not 30 years agoüòÅ",
                  "score": 1,
                  "created_utc": "2026-02-01 15:46:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2zoeit",
          "author": "BidWestern1056",
          "text": "agreed and aiming to lead a lot of this for research-specific coding/slms\n\n[https://github.com/npc-worldwide/npcpy](https://github.com/npc-worldwide/npcpy)\n\n[https://github.com/npc-worldwide/npcsh](https://github.com/npc-worldwide/npcsh)\n\n[https://github.com/npc-worldwide/incognide](https://github.com/npc-worldwide/incognide)",
          "score": 1,
          "created_utc": "2026-02-01 16:12:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36xfs8",
          "author": "kievmozg",
          "text": "DeepSeek's recent success is the ultimate proof of this.\n‚ÄãThe 'bigger is better' era is dying for business use cases. I see this daily with my own SaaS (ParserData). Clients stopped caring about 'reasoning capabilities' of GPT-4 now they just want speed, low cost, and zero hallucinations for their documents.\n‚ÄãRenting a massive cluster to parse a simple invoice is economically insane. The future belongs to efficient, purpose-built pipelines (like DeepSeek or specialized fine-tunes), not bloated generalist models.",
          "score": 1,
          "created_utc": "2026-02-02 17:46:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}