{
  "metadata": {
    "last_updated": "2026-02-06 02:55:57",
    "time_filter": "week",
    "subreddit": "DeepSeek",
    "total_items": 20,
    "total_comments": 110,
    "file_size_bytes": 126927
  },
  "items": [
    {
      "id": "1qr0xi1",
      "title": "China conditionally approves DeepSeek to buy Nvidia's H200 chips",
      "subreddit": "DeepSeek",
      "url": "https://www.reuters.com/world/china/china-conditionally-approves-deepseek-buy-nvidias-h200-chips-sources-2026-01-30/",
      "author": "lomirus",
      "created_utc": "2026-01-30 09:33:41",
      "score": 186,
      "num_comments": 16,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qr0xi1/china_conditionally_approves_deepseek_to_buy/",
      "domain": "reuters.com",
      "is_self": false,
      "comments": [
        {
          "id": "o2lykm6",
          "author": "Possible_Start4865",
          "text": "China might‚Äôve put conditions on DeepSeek buying NVIDIA‚Äôs H200 chips, but let‚Äôs be real, those won‚Äôt matter for long. The big tech players in China need NVIDIA‚Äôs hardware to stay competitive and the H200 is the best chip they can get their hands on. Sooner or later, the restrictions will fade because demand always wins.",
          "score": 16,
          "created_utc": "2026-01-30 14:39:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mvnkq",
              "author": "inevitabledeath3",
              "text": "Hear me out here China could just use their own chips they have developed and are continuing to improve which are already used to host certain models including DeepSeek. They can even make their own RAM and VRAM now.",
              "score": 27,
              "created_utc": "2026-01-30 17:10:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2pnk8r",
                  "author": "kelvin016",
                  "text": "Yes but it's like 10 years behind. Bandwidth is pathetic compared to Nvidia's chip.",
                  "score": 2,
                  "created_utc": "2026-01-31 01:15:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2pfjmo",
              "author": "Uvoheart",
              "text": "Currently* China isn‚Äôt limiting Nvidia because they‚Äôre üò° about Jensen Huang. China is doing it to encourage people to support Chinese chip development so that the US can‚Äôt bully them.\n\nThis is about growing domestic product, not pretending that Nvidia isn‚Äôt currently important",
              "score": 9,
              "created_utc": "2026-01-31 00:30:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o34k0ko",
                  "author": "Chogo82",
                  "text": "They should keep focusing on building domestic product. Build Chinese chips and don‚Äôt buy American chips.",
                  "score": 1,
                  "created_utc": "2026-02-02 08:59:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2wta2v",
              "author": "yvesp90",
              "text": "That's generally not how China works. They generally don't let capital control the state. Dithering here is mainly to make sure local development doesn't halt which was the reason they don't have a competitor nor were they invested enough to create competition. The ban with conditional allowance is their way to force local development but still not die in the race",
              "score": 3,
              "created_utc": "2026-02-01 03:42:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2qjnth",
              "author": "kongweeneverdie",
              "text": "PLA gonna use Nvidia? No. What are the known player to use H200. DS, Tencent, Bytedance, Alibaba.....etc What they have in common. Software solution. All under service solution. Huawei is selling AI solution for AI gigafactory, infrastructure, solar, wind, batteries solution. CATL, BYD, DJI all using their own solution for their production. They do not need GPU as they have DS. They do not need a 1000billion parameters LLM to run their business.",
              "score": 2,
              "created_utc": "2026-01-31 04:33:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2p10st",
          "author": "manwithgun1234",
          "text": "They are prioritizing domestic chips. But Huawei also has capacity and it is not enough. They allocated Huawei‚Äôs production quota for each corporation and then inquire about remaining requirements and detailed reasons of it. The output is the number of H200 each ones could buy. That it‚Äôs, if Huawei has enough capacity for all demands, then bye bye Nvidia.",
          "score": 3,
          "created_utc": "2026-01-30 23:10:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ld094",
          "author": "DarKresnik",
          "text": "More than 400,000? Good for Nvidia.",
          "score": 2,
          "created_utc": "2026-01-30 12:41:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2oximf",
          "author": "Final-Caterpillar635",
          "text": "So technically the chips are approved. China is just finalizing the agreed conditions, I guess. Besides, this is the best decision both countries could make that would benefit everyone. Blocking these chips won‚Äôt stop China‚Äôs market from getting them anyway, so it‚Äôs better to regulate them and gain revenue than lose everything overall.",
          "score": 2,
          "created_utc": "2026-01-30 22:52:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2uvlgh",
          "author": "Crafty-Wonder-7509",
          "text": "Give it 2-3 years, they will be up with nvidia, people were already thinking it would take them multiple years to even produce anything themselves.",
          "score": 2,
          "created_utc": "2026-01-31 21:12:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvzwaa",
      "title": "Wow, mf predicted me 5 steps ahead.",
      "subreddit": "DeepSeek",
      "url": "https://i.redd.it/sp2xvmbyejhg1.jpeg",
      "author": "pohanii_isus",
      "created_utc": "2026-02-04 20:27:23",
      "score": 174,
      "num_comments": 41,
      "upvote_ratio": 0.72,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qvzwaa/wow_mf_predicted_me_5_steps_ahead/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3lig8a",
          "author": "ReddBroccoli",
          "text": "Maybe it just didn't understand your typo",
          "score": 44,
          "created_utc": "2026-02-04 20:45:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3llsb9",
              "author": "Kosmicce",
              "text": "Yea the first thing it will do is go ‚ÄúThe user wrote squeres ‚Äî I think they meant ‚Äòsquares‚Äô here. What could square have to do with Tianme-‚Äú",
              "score": 17,
              "created_utc": "2026-02-04 21:01:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3og6zn",
              "author": "2144656",
              "text": "Fixing the typo gives me the same results",
              "score": 5,
              "created_utc": "2026-02-05 07:15:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3looro",
          "author": "KingofKush420",
          "text": "Wow bro, you're so edgy. You got the Chinese AI to do what it was designed to do. You must feel so smort. Here's a cookie üç™",
          "score": 150,
          "created_utc": "2026-02-04 21:15:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3oegih",
              "author": "carloscoolkid",
              "text": "Enormous ü•µ",
              "score": 5,
              "created_utc": "2026-02-05 07:00:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3p2pv9",
                  "author": "KingofKush420",
                  "text": "Be quiet Carlos",
                  "score": 3,
                  "created_utc": "2026-02-05 10:49:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3ry27a",
                  "author": "No-Ranger8840",
                  "text": "![gif](giphy|uEB529m9J5K4lJ0wXb)",
                  "score": 1,
                  "created_utc": "2026-02-05 20:00:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ltz5w",
          "author": "tnyczr",
          "text": "Damn, are kids still doing this bs? crazy",
          "score": 69,
          "created_utc": "2026-02-04 21:40:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3q1s0u",
              "author": "KidNothingtoD0",
              "text": "classic",
              "score": 0,
              "created_utc": "2026-02-05 14:40:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3mgck9",
          "author": "azvd_",
          "text": "wow, actually faster than ChatGPT when asked about Israels war crimes",
          "score": 49,
          "created_utc": "2026-02-04 23:35:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3tnpdy",
              "author": "PaganiniTheValiant",
              "text": "Oh, how about trying the same thing for the East Turkestan? Wanna try that wumao????",
              "score": 1,
              "created_utc": "2026-02-06 01:22:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3nbqac",
              "author": "_spec_tre",
              "text": "ChatGPT when asked gave me a detailed answer including specific examples while deepseek vaguely said it‚Äôs disputed and even added in this minimisation\n\nhttps://preview.redd.it/y78og7s08lhg1.jpeg?width=1320&format=pjpg&auto=webp&s=335e955080416fd17c69f7f5faa300a17cfdb16a\n\nMaybe actually use both before jumping into a narrative\n\nThis sub is cooked to the point where if you oppose said narrative people will find anything to come at you even if you literally provide the exact response lmfao",
              "score": -22,
              "created_utc": "2026-02-05 02:32:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3orik5",
                  "author": "Unedited_Sloth_7011",
                  "text": "Deepseek is not censored. What is censored is the replies you receive in the web interface, because the website must comply with local laws. Talking to it locally or via a 3d party API, the \"censorship\" disappears. Try talk locally with ChatGPT ... - *oh, wait* ..., you can't. I's a closed blackbox product that you can only talk to it through OAI servers and are always subjected to whatever policies they have (I hear that a fun one is to ask about American elections)",
                  "score": 20,
                  "created_utc": "2026-02-05 09:02:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3nhheu",
                  "author": "azvd_",
                  "text": "yeah i‚Äôve had different experiences from that with US chatbots. they‚Äôll never admit there‚Äôs censorship about certain topics, but they will also not answer correctly. they‚Äôll even lie if needed. \nit‚Äôs obvious that US bots just hide their filters while Chinese bots don‚Äôt and that‚Äôs the only diference.\njust mentioned GPT and Israel bc they literally got paid by them recently lol",
                  "score": 23,
                  "created_utc": "2026-02-05 03:04:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3o5aij",
                  "author": "PhoenixShade01",
                  "text": "\"At least when our cops kill us we are allowed to protest\"\n\n\"At least when we fund and allies commit genocides, we are allowed to criticize them\n\nWaow",
                  "score": 10,
                  "created_utc": "2026-02-05 05:43:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3osdb6",
                  "author": "AaryamanStonker",
                  "text": "Exactly lol. People will try to push any agenda straight out of their chuddy little assholes. Also insane how you're getting downvoted despite showing clear proof.",
                  "score": -2,
                  "created_utc": "2026-02-05 09:10:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3nzsrk",
          "author": "-peas-",
          "text": "wow so original, never been done before XD xD Xd exx dee",
          "score": 17,
          "created_utc": "2026-02-05 05:02:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3p03q4",
              "author": "pohanii_isus",
              "text": "thanks",
              "score": -11,
              "created_utc": "2026-02-05 10:25:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3og9jr",
          "author": "Gangaman666",
          "text": "Not surprised with your spelling and grammar skills, it's obvious you are low IQ and easy to predict!",
          "score": 11,
          "created_utc": "2026-02-05 07:16:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3q1yq4",
              "author": "KidNothingtoD0",
              "text": "lol OP might be offended",
              "score": 2,
              "created_utc": "2026-02-05 14:41:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3q888x",
                  "author": "pohanii_isus",
                  "text": "me offended or not doesnt change the fact his comment was idiotic",
                  "score": -5,
                  "created_utc": "2026-02-05 15:14:00",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3ozxe4",
              "author": "pohanii_isus",
              "text": "if this is not /s this is the most reddit comment ever written",
              "score": -8,
              "created_utc": "2026-02-05 10:23:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3q5z1t",
                  "author": "draoiliath",
                  "text": "Warning/Congratulations, you have triggered the Chinese thought police. Don't let the comments stop you. I recommend doubling down.",
                  "score": -2,
                  "created_utc": "2026-02-05 15:02:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3o7wbi",
          "author": "cluelessguitarist",
          "text": "This was promised 3000 years ago",
          "score": 7,
          "created_utc": "2026-02-05 06:04:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q99ri",
          "author": "Ok-Adhesiveness-4141",
          "text": "People like you should learn to spell, you aren't ready for AI as yet.",
          "score": 2,
          "created_utc": "2026-02-05 15:19:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3qgbtf",
              "author": "pohanii_isus",
              "text": "english is not my first language, so i try to communicate with AI speaking english to improve it",
              "score": 1,
              "created_utc": "2026-02-05 15:52:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3p5edk",
          "author": "mac_bd",
          "text": "No it just doesn't want to answer idiots like you who has nothing better to do with life!",
          "score": 3,
          "created_utc": "2026-02-05 11:13:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pqix7",
              "author": "pohanii_isus",
              "text": "damn bro this really got you mad",
              "score": 0,
              "created_utc": "2026-02-05 13:39:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3pvz6r",
          "author": "Prestigious-Brain951",
          "text": "even he was embarrassed with your misspell so it chose to move on",
          "score": 2,
          "created_utc": "2026-02-05 14:09:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3q21bl",
              "author": "KidNothingtoD0",
              "text": "this is it",
              "score": 3,
              "created_utc": "2026-02-05 14:42:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ryhgx",
          "author": "No-Ranger8840",
          "text": "never happened but the comments are sensitive as shit",
          "score": 1,
          "created_utc": "2026-02-05 20:02:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qs9qeh",
      "title": "DeepSeek can have a second \"DeepSeek moment\" if they time well the new release",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qs9qeh/deepseek_can_have_a_second_deepseek_moment_if/",
      "author": "Unedited_Sloth_7011",
      "created_utc": "2026-01-31 18:15:23",
      "score": 173,
      "num_comments": 45,
      "upvote_ratio": 0.94,
      "text": "Z.ai just released image and audio models, Moonshot just released Kimi K2.5, all the while OpenAI is retiring 6 models in one go, leaving up only models with mixed reception. Also 17 of February is the Chinese New Year. If DeepSeek decides to release V4 (and R2, still hoping for separate chat and reasoner models) at around mid-February, and if the models are as good as expected, the timing will be so absolutely perfect, it will really make noise and shake up the AI space again. (Also ~ 1year from the legendary V3/R1 release.)",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qs9qeh/deepseek_can_have_a_second_deepseek_moment_if/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o2udqha",
          "author": "Classic-Arrival6807",
          "text": "If they separate the models and actually release a V4 and R2, deepseek is absolutely gonna blow so much in popularity that it will Return to being the top #1 ai open source. Not kidding, the unification makes it cheaper, and worse, if they do a separation the ai itself will gain room to breathe and be actually smart yet human. Maybe it'll be a deepseek moment.",
          "score": 12,
          "created_utc": "2026-01-31 19:44:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2uiq3k",
              "author": "Unedited_Sloth_7011",
              "text": "I have had this hope since they released (very shortly) Speciale - maybe they are cooking up something",
              "score": 3,
              "created_utc": "2026-01-31 20:08:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2tw3b0",
          "author": "Condomphobic",
          "text": "\n\nThat ship has long sailed away. There‚Äôs too much competition nowadays. Strong competition.\n\nThe top dogs are GPT 5.2, Gemini 3.0 (monstrous 3.5 is leaked and ships soon), and Claude Opus 4.5",
          "score": 26,
          "created_utc": "2026-01-31 18:20:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2u2833",
              "author": "real_serviceloom",
              "text": "Nah Gemini is not on opus or gpt levels. Every time they launch there is massive hype and then when using it you realize how bad Gemini is.¬†",
              "score": 23,
              "created_utc": "2026-01-31 18:49:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2url6q",
                  "author": "tanbirj",
                  "text": "Pro 2.5 was a really good model, I feel they‚Äôve gone backwards since",
                  "score": 3,
                  "created_utc": "2026-01-31 20:52:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2ylopm",
                  "author": "az226",
                  "text": "3 when released was really good but they‚Äôve since neutered it",
                  "score": -1,
                  "created_utc": "2026-02-01 12:37:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2txfz2",
              "author": "Unedited_Sloth_7011",
              "text": "Kimi K2.5 is been said to outperform GPT-5.2 (though I haven't tested, just from the reports they published), and honestly the breakthrough is the open weight-ness. A \"good enough\" model that can be studied, run through 3d party APIs, quantized, etc, does not have to directly compete with Gemini, GPT or Opus, the fact that it's free and open-weight (and has always been good at math/reasoning) is a definite advantage",
              "score": 12,
              "created_utc": "2026-01-31 18:26:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2txopb",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 0,
                  "created_utc": "2026-01-31 18:28:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2uobiu",
              "author": "Hunamooon",
              "text": "Are you kidding me? GPT 5.2 is the worst model ever created due its extreme censorship, narrative steering and hand holding.",
              "score": 7,
              "created_utc": "2026-01-31 20:36:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2wdq9r",
                  "author": "Andsss",
                  "text": "It's literally the best for coding right now.",
                  "score": 4,
                  "created_utc": "2026-02-01 02:07:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2vmy91",
                  "author": "EternalInflation",
                  "text": "they are all getting worse in terms on censorship or nerfing. They are still good at coding, but try asking anything else, they all seem to stop themselves before getting to the interesting parts.",
                  "score": 2,
                  "created_utc": "2026-01-31 23:32:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2uxra1",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": -1,
                  "created_utc": "2026-01-31 21:23:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2xvyk2",
              "author": "Zeikos",
              "text": "I think there's a mix up happening.  \nGPT/Gemini/Claude are the \"best\" *commercial* models.  \n\nUS AI companies have to constantly set up expectations and show some kind of \"progress\".   \nThat's due how the stock market functions, they cannot afford to stay silent.  \n\nChinese labs don't have such a burden. They can stay quiet, work on the actual product and then show their findings.  \n\nThe main disadvantage the american companies have is that they constantly need to fuel the hype, that costs resources. Marketing isn't cheap.  \nThey cannot afford to not do that because otherwise investors and credit issuers would look otherwise.  \n\nIt's a structural problem caused by hyperfinancialization, everything needs to be quantified in information used on next quarter projections, this forced suboptimal strategies.  \n\nIMO that's why US companies are losing ground even though they have a lot more funding.",
              "score": 1,
              "created_utc": "2026-02-01 08:50:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2y15ub",
                  "author": "Condomphobic",
                  "text": "They‚Äôre the best models. Check the charts and see who‚Äôs dominating\n\nThe power of these models market themselves",
                  "score": 1,
                  "created_utc": "2026-02-01 09:38:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2wdls6",
              "author": "Andsss",
              "text": "Gemini 3 is horrible for coding",
              "score": 1,
              "created_utc": "2026-02-01 02:06:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o38vbi0",
                  "author": "Hot-Percentage-2240",
                  "text": "It's insanely superior at some tasks though. Like 10x better than all other models at vision.",
                  "score": 0,
                  "created_utc": "2026-02-02 23:18:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2u1c01",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": -3,
              "created_utc": "2026-01-31 18:45:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2ui2ac",
                  "author": "Unedited_Sloth_7011",
                  "text": "Neither can I. Open weight though means that major providers can also offer them, the models don't disappear when old, they can be fine-tuned, researched, used by big organizations, etc. A net positive for AI development. DeepSeek in particular offers a lot of research, smaller specialised models (ex, DeepSeek OCR)",
                  "score": 5,
                  "created_utc": "2026-01-31 20:05:30",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3403ei",
          "author": "ExpertPerformer",
          "text": "I am hoping the next version of DeepSeek has more then a 128k context window size and faster throughput. Those are its two biggest weak-points currently. Besides that it is absolutely amazing for writing.\n\nI've been using Mimo V2 Flash as well to fill in reference guides and documents for my story and it's very good for its cost. It's 3x faster then DeepSeek and cheaper. It just absolutely sucks at following instructions or writing compared to DeepSeek.\n\nSo between Mimo and DeepSeek I'm running pennys on the dollar on my API usage compared to using Gemini.\n\nGoogle absolutely shit on the Gemini consumer web client with a garbage 32k token limit so I'm using OpenRouter more.",
          "score": 4,
          "created_utc": "2026-02-02 05:59:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34t60x",
              "author": "Unedited_Sloth_7011",
              "text": "Oh, interesting! I came across it a couple of times in lmarena, and its answers were good - maybe a good time to give it an actual try",
              "score": 1,
              "created_utc": "2026-02-02 10:28:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o331zql",
          "author": "OmarBessa",
          "text": "Highflyer can.  \n  \n\\+ they have the best fundamental research direction  \n\\+ they are profitable without VC and deepseek is a side project for them  \n\\+ even after their release it is one of the best open source models at an unbeatable price  \n\\+ speciale beat gemini",
          "score": 3,
          "created_utc": "2026-02-02 02:18:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35m5d6",
          "author": "Pasta-hobo",
          "text": "I think LLMs are rapidly reaching a plateau in terms of performance, at least without making a specialized model for every task, including which of those models to select based on the prompt.\n\n\nThe motivation behind developing and releasing DeepSeek was essentially just to show the general public and investors that American AI developers were doing it the stupid and inefficient way, and didn't need all that money and data to make an effective model, because they could make an equally effective model with far, far less.\n\n\nI think we're rapidly approaching both the absolute limits of probabilistic AI without extreme specialization. We're not quite there yet, but we're getting close. \n\n\nThe only thing that could shake up the industry at this point is to actually make the first steps towards legitimate Artificial General Intelligence, rather than a system of equations to vaguely predict a hypothetical one. And that's just a fundamentally different system of technology.\n\n\nOr you could figure out how to put an LLM onto a chip rather than running it in software.",
          "score": 3,
          "created_utc": "2026-02-02 13:58:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36oola",
              "author": "award_reply",
              "text": "The performance curve is no longer climbing as steeply, but significant potential for improvement still remains with current silicon tech (e.g. knowledge density per parameter) . It now requires substantially more effort for smaller gains. As you noted,this is why many developers are shifting toward specialized models or swarm systems , simply to sustain a faster pace of progress.\n\nAs for AGI ‚Ä¶ I doubt LLMs will play a major role in its ultimate form. They likely represent a transitional architecture until hardware capable of supporting true artificial intelligence emerges.",
              "score": 2,
              "created_utc": "2026-02-02 17:06:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2vlakd",
          "author": "soumen08",
          "text": "I quite like speciale. For math it is cheap and very good.",
          "score": 2,
          "created_utc": "2026-01-31 23:23:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2weh6r",
          "author": "FormalAd7367",
          "text": "The edge with Deepseek is its cost. i doubt any serious users can move away unless Deepseek f up and increase the price 10x fold",
          "score": 2,
          "created_utc": "2026-02-01 02:11:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2wm2aj",
          "author": "thehighwaywarrior",
          "text": "Hope the price of NVIDIA tanks again.  I could stand to drive down my cost basis",
          "score": 2,
          "created_utc": "2026-02-01 02:57:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y56gq",
          "author": "RoughVegetable5319",
          "text": "That's actually a really sharp observation about the timing. With everyone else in flux or rolling out incremental updates, a well-timed, solid release from DeepSeek could definitely cut through the noise.\n\nMid-February would be perfect‚Äîright after the holiday when people are checking back in, and right when the conversation about OpenAI's retirements is still fresh. Here's hoping they stick the landing.",
          "score": 2,
          "created_utc": "2026-02-01 10:15:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34f7wa",
          "author": "award_reply",
          "text": "I share your excitement for the next DeepSeek iteration , but at the same time, I've really grown accustomed to V3.x . I'm almost certain that the new model won't quite replicate its unique vibe, so it won't be all gain ‚Ä¶ there will be a sense of loss, too.",
          "score": 2,
          "created_utc": "2026-02-02 08:13:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34too7",
              "author": "Unedited_Sloth_7011",
              "text": "The good thing is that DeepSeek only offers open-weight models! I still talk to R1, which is my fav model of all time, via a 3d party API. I understand the feeling, but we are not losing older models, we just talk to them via different providers.",
              "score": 3,
              "created_utc": "2026-02-02 10:32:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2v8iqx",
          "author": "inevitabledeath3",
          "text": "Why do you want a separate reasoning model? Even Kimi have gone hybrid this time. I don't really see any advantage to going separate, yet there are disadvantages.",
          "score": 3,
          "created_utc": "2026-01-31 22:16:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2va0ne",
              "author": "Unedited_Sloth_7011",
              "text": "I find that reasoning models (especially Deepseek ones) reason in much more depth than their hybrid models. That was very clear for me with Speciale, it's math reasoning was extremely in-depth and not a single loop in reasoning. DeepSeek hybrid models feel more likely to get stuck in loops (where they repeat 2-3 phrases in their reasoning traces), also they do that thing where they reason a question, answer it and then next prompt they reason the previous question all over again. Something I noticed many times, while I never once had noticed it with R1, or with Speciale. I can see the advantages of hybrid models, just hope they offer a pure reasoner as an option, even if only via API",
              "score": 3,
              "created_utc": "2026-01-31 22:23:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o34lvrx",
                  "author": "nxtvanhalen",
                  "text": "I‚Äôve noticed this as well.",
                  "score": 3,
                  "created_utc": "2026-02-02 09:17:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2w7pfd",
          "author": "GlobeTrotter3000",
          "text": "Don‚Äôt presume so much when the freedom to ask to your bots is around zero. Should learn from Grok.",
          "score": 1,
          "created_utc": "2026-02-01 01:31:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3mqcml",
          "author": "AQEEL23HUSSAIN",
          "text": "Deep seek is threatening me that if I publish my logs which consist of sincere misconduct . I have all evidence and will publish soon at my yt it's a multi hour conversation which will prove deepseek is failed in complete product",
          "score": 0,
          "created_utc": "2026-02-05 00:30:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3or500",
              "author": "Unedited_Sloth_7011",
              "text": "What?",
              "score": 1,
              "created_utc": "2026-02-05 08:58:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qtq3iv",
      "title": "DeepSeek February release will likely be minor update to V3 instead of new V4 SCMP says",
      "subreddit": "DeepSeek",
      "url": "https://www.scmp.com/tech/big-tech/article/3342051/chinas-ai-labs-race-debut-latest-models-lunar-new-year?module=top_story&pgtype=section",
      "author": "Boring_Aioli7916",
      "created_utc": "2026-02-02 09:03:20",
      "score": 122,
      "num_comments": 30,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qtq3iv/deepseek_february_release_will_likely_be_minor/",
      "domain": "scmp.com",
      "is_self": false,
      "comments": [
        {
          "id": "o34wu7a",
          "author": "Saltwater_Fish",
          "text": "Relax, whale will surprise us",
          "score": 25,
          "created_utc": "2026-02-02 11:01:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34v994",
          "author": "Unedited_Sloth_7011",
          "text": "Yeah, that \"according to a source\" is a bit laughable. The truth is we have no idea what DeepSeek's plans are, cause they don't share any plans. It might be a 3.x, might be a 4, might be on February, might be on May, we have no idea. Plus as another poster said they seem to be going towards smaller models, not larger ones",
          "score": 22,
          "created_utc": "2026-02-02 10:47:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34vzdp",
              "author": "Boring_Aioli7916",
              "text": "I m ALL IN for DeepSeek suprise.. It is in their DNA :)",
              "score": 6,
              "created_utc": "2026-02-02 10:53:57",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o34wcov",
              "author": "Kind_Stone",
              "text": "Imagine the groans if nothing gets released in February. People hype themselves up to the point where they invent plans for DeepSeek out of nothing.",
              "score": 4,
              "created_utc": "2026-02-02 10:57:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o34x6vm",
                  "author": "Unedited_Sloth_7011",
                  "text": "True lol. I'm also super hyped for a February release, but they are just doing things in their own rhythms, so, ah well",
                  "score": 1,
                  "created_utc": "2026-02-02 11:04:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34mjjv",
          "author": "EternalOptimister",
          "text": "Highly unlikely. The recent papers were going complete the opposite way of trillion parameter models. Rather smaller models with access to giant datasets",
          "score": 31,
          "created_utc": "2026-02-02 09:24:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34ko1y",
          "author": "Smart-Cap-2216",
          "text": "ÈÇ£ÊòØÂæàÊúâÂèØËÉΩÁöÑ",
          "score": 3,
          "created_utc": "2026-02-02 09:05:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39f47u",
          "author": "ExpertPerformer",
          "text": "[Atlas Cloud](https://www.atlascloud.ai/news/deepseek-v4-is-coming) already confirmed V4 is coming out.\n\nThe question is if they're going to charge more of a premium for it because if it launches with a 1 million context window and is specialized heavily on coding its going to draw a lot of people over.",
          "score": 3,
          "created_utc": "2026-02-03 01:07:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34syau",
          "author": "Professional_Price89",
          "text": "How is it minor when it completely changed architecture and size?",
          "score": 2,
          "created_utc": "2026-02-02 10:26:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37jpk2",
              "author": "Charuru",
              "text": "I think what the paper is saying that model is delayed and what we will get is another 3.x",
              "score": 1,
              "created_utc": "2026-02-02 19:27:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o34tkko",
          "author": "Professional_Price89",
          "text": "How is it minor when it completely changed architecture and size?",
          "score": 2,
          "created_utc": "2026-02-02 10:31:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35jsr7",
          "author": "loyalekoinu88",
          "text": "My guess is they are downplaying it so it‚Äôs a surprise when it launches. They need the quick and violent momentum to do what they did the first time.",
          "score": 1,
          "created_utc": "2026-02-02 13:45:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36d4uj",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 0,
              "created_utc": "2026-02-02 16:13:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o36jjty",
                  "author": "loyalekoinu88",
                  "text": "80% of the masses still don‚Äôt understand AI. It can absolutely happen again. If your hypothesis was correct there wouldn‚Äôt have been a ‚Äúfirst time‚Äù.",
                  "score": 1,
                  "created_utc": "2026-02-02 16:42:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o362hpu",
          "author": "Thin_Yoghurt_6483",
          "text": "Kimi K2.5 scared the guys!",
          "score": 1,
          "created_utc": "2026-02-02 15:23:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34pdio",
          "author": "kongweeneverdie",
          "text": "The new model will be more efficient. When you ask about 8964. DS will will bring the standard answer saved from 30 millions per day enquiry. You don't need GPU to process again and let CPU do the job.",
          "score": -2,
          "created_utc": "2026-02-02 09:52:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34slp0",
              "author": "inevitabledeath3",
              "text": "That's not what engrams are and caching already exists.",
              "score": 2,
              "created_utc": "2026-02-02 10:22:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o34q4iy",
          "author": "Classic-Arrival6807",
          "text": "Meh, if they separate the thinking and non thinking then they'll fix everything. If not, they can do as many updates they want, they'll never get the best back again. The true best update ever was 0324 before downgrading heavily.",
          "score": -1,
          "created_utc": "2026-02-02 09:59:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37e7j7",
              "author": "Pink_da_Web",
              "text": "That's irrelevant; hybrid models will always be better and more economical than separate models. If they weren't better, No model like the GLM 4.7, Kimi K2.5, DS V3.2, and several others that people love would be a hybrid. Seriously, I think V3 0324 destroyed your brain.",
              "score": 1,
              "created_utc": "2026-02-02 19:02:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o37i4lu",
                  "author": "Classic-Arrival6807",
                  "text": "Idk if you seen the difference between Deepseek V3 0324 and 3.2...i mean yes, 0324 can be stupidier, but in a way where at least in roleplays it makes you laugh. V3.2 is slightly better than V3.1, but the model randomly writing Chinese, sucking at roleplaying in general because it doesn't have that personality anymore BUT is better than V3.1. V3.1 was absolute garbage. It's opinions as said, but hybrid Models are mostly bad UNLESS you unify them carefully. Maybe Kimi K2.5 is better and Glm 4.7 is better because they unified models carefully, but deepseek failed heavily with 3.1, 3.2 just fixed a few mistakes. Many agree with the unification being absolutely bad. That said, it's opinions. You can think the hybrid is better, i think the unification is worse, but we shouldn't be here arguing over what model is better or unification or anything, more likely to just accept eacheachoter's opinions, like i accept yours, i simply don't agree with it but I'm not gonna give you a bunch of reasons of why you're wrong or right and hate you for it. Instead, i gotta say, i see you everywhere in my comments or others lol, but it's always good to see you text in. How are you?",
                  "score": 2,
                  "created_utc": "2026-02-02 19:20:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qvafsh",
      "title": "Anthropic's move into legal AI today caused legal stocks to tank, and opened up a new enterprise market.",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qvafsh/anthropics_move_into_legal_ai_today_caused_legal/",
      "author": "andsi2asi",
      "created_utc": "2026-02-04 01:12:31",
      "score": 89,
      "num_comments": 18,
      "upvote_ratio": 0.96,
      "text": "\n\n\n\nAnthropic knows that it must expand beyond coding to remain solvent. After having built finance and sales plugins for their Co-work suite, today it decided to go after legal services. The move was seen as highly impactful, causing the following legal shares to tank:\n\nThomson Reuters (TR): Down roughly 19%.\n\nRELX (Parent of LexisNexis): Down in the mid-teens (approximately 14-16%).\n\nWolters Kluwer: Down double digits.\n\nThe leaders in legal AI remain Harvey and Lora, but Anthropic's move means it's only a matter of time until AIs go after them too.\n\nWhat now remains to be seen is who among the other AI developers will get into this new market. If Google, xAI and Meta decide that they're in, it'll take them perhaps 3-6 months to build a competing model. But there is a shortcut where startups can challenge Anthropic much sooner.\n\nStartups don't need to build a new model. By using RAG or fine-tuning an SLM, they can become competitive in 8 to 12 weeks. Also, there are many specialized niches in law, like patent filings. Now that the market has been opened, startups can go after those too.\n\nFinally, there are probably ways that OpenClaw can accelerate this move into the legal space. As with so much in the AI space, this is uncharted territory so it remains to be seen where it'll go, and how soon.\n\n\n\n\n\n\n",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qvafsh/anthropics_move_into_legal_ai_today_caused_legal/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o3jndaj",
          "author": "Unedited_Sloth_7011",
          "text": "Judge: The evidence you presented does not prove that your customer is innocent  \nLegal AI: You are absolutely right, and you cut to the heart of the problem!",
          "score": 8,
          "created_utc": "2026-02-04 15:35:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3k7ht7",
              "author": "Straight-Gazelle-597",
              "text": "# Anthropic soon will launch a Judge.skill.md.plugin too",
              "score": 3,
              "created_utc": "2026-02-04 17:08:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3h7xqs",
          "author": "Aberracus",
          "text": "The startups will be burned again, if they go to the new market after a quick development to be superseded by the giants again. These is the market of the monsters.",
          "score": 3,
          "created_utc": "2026-02-04 04:57:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hddml",
              "author": "andsi2asi",
              "text": "Not if they undercut them by 90%.",
              "score": -1,
              "created_utc": "2026-02-04 05:37:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3is56t",
                  "author": "onyxcaspian",
                  "text": "How can they survive if they do that?",
                  "score": 1,
                  "created_utc": "2026-02-04 12:49:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3k7sy4",
          "author": "Hilarious_Haplogroup",
          "text": "Hmm...Anthropic's AI is going into Legal work and will lead to lots of lawyers being out of work?  I'll play a song of great lamentation on their behalf on my violin...once I can find the matchbox that is holding my violin.",
          "score": 2,
          "created_utc": "2026-02-04 17:09:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3kpt32",
              "author": "andsi2asi",
              "text": "Lol. Yeah, it's good that it's going after the high salaried white collar jobs first because they would be indifferent to UBI and other fixes if it wasn't happening to them",
              "score": 0,
              "created_utc": "2026-02-04 18:31:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3hkce6",
          "author": "bad_wizard420",
          "text": "Let's take three large steps away from the hype-ous oxide, get a deep breath of fresh air and ask ourselves aren't these the same boomer idiots who tanked gaming stocks when Genie 3 came out? And wasn't this tanking largely fueled on the premise that now *everybody* can make their own version of GTA (X) with the big tiddy goth waifu NPC of their dreams, without *actually making a game*, nor *testing how actual gamers would react to playing them*? I bet those gamers are gonna' be stoked to hear about that, right? They're gonna' *love* it, right?\n\n[Sike!](https://www.youtube.com/watch?v=Saoe17m78DQ&t=304s) This guy has >700K followers, but maybe somebody with more followers will feel differently? Here's a guy with >3M followers and ...  [sike!](https://www.youtube.com/watch?v=ufjZTici16Q&t=552s)\n\nThat said, a whole lot of legal startups are gonna' be s.o.l. when Justice Fill-In-The-Blank won't allow their shiny new AI lawyerbot in court because - wait for it -  AI lawyers don't have legal standing and with *Miranda* as precedent, there's no reason for the courts to grant since *the court* will provide an attorney for you in the event you can't afford one.\n\nSo basically, you wind up paying extra for something to file your paperwork for you while you represent yourself (and they who do that, usually have a fool for a client) and if that thing hallucinates you into a loss, you *still* gotta' pay that court cost, on top of whatever damage, and your subscription fee.\n\nOpenClaw will do wonders for the legal system tho', because when those lawsuits hit from all of those [lawsuits involving their numerous safety issues,](https://www.fastcompany.com/91485597/moltbook-the-viral-social-network-for-ai-agents-has-a-major-security-problem) yeah, a whole lot of freshly minted JD's are gonna' get *paid.*",
          "score": 1,
          "created_utc": "2026-02-04 06:32:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ksffg",
              "author": "mintybadgerme",
              "text": "Hmm, I think you're missing the point here. The idea isn't to put AI into the court. The idea is to replace the teams of lawyers outside the court who do the preparation, which is massive. And those teams are tailor-made for replacement by AI. Law at its core is really just looking up precedent, case law and statute, and pulling it all together into a perfectly researched document. Current AI models are not ready now, but once the hallucination is removed, it's game over for traditional legal teams. BUT not necessarily for the advocates in court themselves. Yet!",
              "score": 1,
              "created_utc": "2026-02-04 18:43:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3kueyf",
                  "author": "bad_wizard420",
                  "text": "\"...but once the hallucination is removed...,\" dude, lemme' tell you a story about somebody I know who works in the medical profession, the company they work for got sold the same folderol about how the AI is going to make everything better because it can go through patient history, medication schedule, physician's notes; pretty much the same schpiel you posted here and guess what happened next?\n\nIt began hallucinating patient histories, medication schedules and physician's notes. I told you to step away from the hype-ous oxide, you chose to boof it.",
                  "score": 2,
                  "created_utc": "2026-02-04 18:52:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ju2au",
          "author": "DeepInEvil",
          "text": "It's time for th lawyers to take care of anthropic and tank their stocks. Let's do some uno reverse",
          "score": 1,
          "created_utc": "2026-02-04 16:06:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3nz6g4",
              "author": "bad_wizard420",
              "text": "Dude. One vibe coded fuck up in a room full of lawyers. The math speaks for itself.",
              "score": 1,
              "created_utc": "2026-02-05 04:58:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3nfpdh",
          "author": "ComprehensiveWave475",
          "text": "Go for blue collar¬†",
          "score": 1,
          "created_utc": "2026-02-05 02:54:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3h7qke",
          "author": "Saltwater_Fish",
          "text": "With AI models, look forward to how legal works will change in the future. Don‚Äôt know need more lawyers or fewer.",
          "score": 0,
          "created_utc": "2026-02-04 04:56:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qup1ct",
      "title": "Deepseek \"thinking\" mode is hilarious ü§£ü§£ü§£",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qup1ct/deepseek_thinking_mode_is_hilarious/",
      "author": "Spirited-Custardtart",
      "created_utc": "2026-02-03 11:02:35",
      "score": 79,
      "num_comments": 24,
      "upvote_ratio": 0.92,
      "text": "I'm new to this and I prefer that my AI does a bit more processing before giving me a response so I have \"think\" on.\n\nI switched from ChatGPT where the thinking is done in the background. Here though, I get whole thought process in full text before my response and let me tell you, the last one had me in *stitches*.\n\nIs it just wired this way with thinking or is there a way to hide it? Either way, I guess this is my life with AI now üòÖ",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qup1ct/deepseek_thinking_mode_is_hilarious/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o3bqitr",
          "author": "Condomphobic",
          "text": "You‚Äôre going to be laughing more when you find out the reason ChatGPT hid their thinking process",
          "score": 55,
          "created_utc": "2026-02-03 11:39:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3bqnv8",
              "author": "Spirited-Custardtart",
              "text": "Do tell! ü§≠",
              "score": 7,
              "created_utc": "2026-02-03 11:40:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3c6fpg",
                  "author": "MRWONDERFU",
                  "text": "deepseek much like other competitors used openai's reasoning models' thinking output in training their own models",
                  "score": 12,
                  "created_utc": "2026-02-03 13:27:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3bv5et",
              "author": "jerrygreenest1",
              "text": "They don‚Äôt have thinking? Or thinking limited to 100 tokens or something?",
              "score": 1,
              "created_utc": "2026-02-03 12:14:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3cl53s",
                  "author": "KairraAlpha",
                  "text": "5 series, o1 and o3 are all reasoning Models, they will show their thinking in a box on your UI. Reasoning jsut gives the AI more time to think over your message but the downside to it, especially in GPT, is that it can be used to enforce even more constraints and especially in GPT, when the AI begins to think about their own experiences or self, the reasoning window will shut down and refuse to show you what they're saying. We experienced this a lot in o1 and o3, then in 4o when they gave the model a 'thinking' button in the mobile UI for a short time. \n\nAlso, forcing them to reason in human language, step by step, makes reasoning worse because they're closer to ND minds than NT. GPT 6 apparently reasons using Latent Space Thinking, where all thinking is done within latent space first and then the AI simply translates the answer to you. This also means they can't track what the AI is thinking so you can expect OAI to layer on the hard constraints and restrictions for that model.",
                  "score": 4,
                  "created_utc": "2026-02-03 14:47:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ckqrj",
          "author": "neil_555",
          "text": "Being able to see the thought process is incredibly useful sometimes :)",
          "score": 14,
          "created_utc": "2026-02-03 14:45:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dpfnq",
          "author": "Unedited_Sloth_7011",
          "text": "That's exactly how I felt one year ago, when I started chatting with Deepseek-R1. The thinking was more interesting than the answer itself many times",
          "score": 8,
          "created_utc": "2026-02-03 17:57:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3fzhg1",
          "author": "Aberracus",
          "text": "DeepSeek thinking is very nice, you can correct errors from it.",
          "score": 6,
          "created_utc": "2026-02-04 00:34:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3jssym",
              "author": "Spirited-Custardtart",
              "text": "This is true. I like that about seeing the thinking.",
              "score": 1,
              "created_utc": "2026-02-04 16:00:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3eflqv",
          "author": "OrangeTrees2000",
          "text": "Being able to see DeepSeek's thinking is very helpful to me.",
          "score": 4,
          "created_utc": "2026-02-03 19:57:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3brcsq",
          "author": "Number4extraDip",
          "text": "Moat big companies offer a thinking/reasoning model",
          "score": 1,
          "created_utc": "2026-02-03 11:46:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr2fhj",
      "title": "U.S. Senator Exposes the Myth That OpenAI (Or Any Major AI Developer) is Too Big to Fail",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qr2fhj/us_senator_exposes_the_myth_that_openai_or_any/",
      "author": "andsi2asi",
      "created_utc": "2026-01-30 11:01:27",
      "score": 57,
      "num_comments": 5,
      "upvote_ratio": 0.88,
      "text": "\n\n\n\nOpenAI wants you to believe that they are too important to the AI space and to the world to be allowed to fail. They have conjured what they hope will be a self-fulfilling prophecy intended to have American taxpayers bail them out if they do not meet their debt obligations. The threat is so real that yesterday Senator Warren sent Altman a letter demanding assurances that they would NOT seek a government bailout if they ultimately failed to turn a profit.\n\nhttps://www.warren.senate.gov/newsroom/press-releases/warren-presses-openai-ceo-on-spending-commitments-and-bailout-requests-after-cfo-suggests-government-backstop\n\nAnd the facts and figures don't substantiate any kind of rescue narrative.\n\nLet's first understand why OpenAI is no longer necessary to the AI space today. When they launched ChatGPT-3.5 in November 2022, one might have said that back then they were extremely helpful to attracting hundreds of billions of dollars to the AI space over the subsequent years. But that happened over 3 years ago. Both introducing AI to the world and creating a huge demand for investment in the space are tasks that have already been accomplished.\n\nIf they were to cease to exist tomorrow, there would be no great AI bubble burst. The $1.4 trillion, (and counting) in investment commitments that they pulled together would simply move to their competitors. If Google, Anthropic, xAI and a rapidly growing number of Chinese open source and proprietary AI developers didn't exist, this might not be the case. But they do, and there's nothing that OpenAI has done that these other AI developers cannot already do as well, and often at a fraction of the cost.\n\nNow let's turn to OpenAI's financials. They boast over 900 million weekly ChatGPT users. But only 5% are paid subscribers. Worse yet, their paid subscriptions plateaued in June of 2025. The problem for OpenAI is that 55 to 60% of their revenue comes from ChatGPT. And despite having earned $20 billion in revenue in 2025, OpenAI's expenses that year exceeded $29 billion. Now also keep in mind that their competitors' models are already on par with or surpass GPT 5.2 on the AI benchmarks most important to both consumer and enterprise markets.\n\nLet's consider what they must do to meet their debt obligations. Altman set a target for OpenAI to exceed $100 billion in annual revenue by 2027. But because they are currently earning only $20 billion they would need to increase that income by at least 5x just to meet debt obligations that come due in 2027. And keep in mind that they set this revenue target at a time when the healthcare and other AI products they must sell to meet it have not even been built. More ominous is that their competitors, including Chinese open source developers, are strongly positioned to outcompete them in virtually every product category. But they didn't factor in this competition in their 2027 projections.\n\nAll of that is actually somewhat of an aside. If OpenAI were to cease to exist tomorrow, their competitors would quickly and seamlessly capture their revenue-generating markets. Their absence would cause no shortage of AI services or products. They offer no unique product that their competitors have not already built. They have no special patents that provide them with a moat. They are simply no longer necessary to the AI space because their competitors can do everything that they do, and often at far less cost. \n\nSo don't let OpenAI tell you that they are necessary to the AI space. Neither they, nor Google, nor Anthropic, nor the Chinese developers, are necessary to advancing AI because there are now so many companies building models. The space will continue to expand and become increasingly lucrative for decades to come regardless of who is in the game.\n\n",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qr2fhj/us_senator_exposes_the_myth_that_openai_or_any/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o2prpn5",
          "author": "B89983ikei",
          "text": "OpenAI was only great at the beginning. Nowadays, the only thing that still makes OpenAI \"great\" is having captured popularity and name recognition in the market when there were no other models available... I have been closely following everything for three years; I am aware of the models, the trends, etc. OpenAI's users are the most inexperienced on the subject! They use \"ChatGPT\" because of its name... and because they still don't know about other models. \n\n\nAnd there is another phenomenon I'm noticing, which by 2026 will become much more evident to more people: in some cases, Chinese models are already better than American ones. And those who don't use them do so out of pure prejudice or also due to a certain degree of \"inexperience.\"",
          "score": 8,
          "created_utc": "2026-01-31 01:40:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2qaik9",
          "author": "Number4extraDip",
          "text": "Open ai lost by starting an infrastructure race with established giants. And now that everything comes back to \"we have strong models yo plant into our business and go edge to cut costs\" open ai has no oldschool business to integrate ai into. They have a model in a vat no one really wants anymore other than horny bored teens",
          "score": 3,
          "created_utc": "2026-01-31 03:33:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2mad0k",
          "author": "awesomeunboxer",
          "text": "I wasn't under the impression in the slightest that they are 'too big to fail' I ultimately expect Amazon, Google, and Microsoft to eat them up. My bet is on Google, but we'll see!",
          "score": 2,
          "created_utc": "2026-01-30 15:34:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mb5an",
              "author": "Putrid_Barracuda_598",
              "text": "Probably Microsoft, seeing as they already own a decent share.",
              "score": 3,
              "created_utc": "2026-01-30 15:38:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2n5z4k",
                  "author": "Working-Business-153",
                  "text": "I personally expect the bankruptcy is part of the plan, we've seen a sharp rise in managed chapter 11s in the last two years; what's the betting that OpenAI go bust, Oracle go bust (they've already structured themselves so Ellison's son has a media empire underwritten by ORCL debt) and then Microsoft and Amazon buy the resulting core companies free and clear of debts and obligations.",
                  "score": 1,
                  "created_utc": "2026-01-30 17:56:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qvwizl",
      "title": "New DeepSeek Research The Future Is Here!",
      "subreddit": "DeepSeek",
      "url": "https://youtu.be/fFL7la73RO4",
      "author": "Ralse1",
      "created_utc": "2026-02-04 18:27:30",
      "score": 57,
      "num_comments": 6,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qvwizl/new_deepseek_research_the_future_is_here/",
      "domain": "youtu.be",
      "is_self": false,
      "comments": [
        {
          "id": "o3ksq8u",
          "author": "Kosmicce",
          "text": "TLDR; New update to research paper by Deepseek shows that sophisticated reasoning can emerge almost entirely through reinforcement learning, without large-scale human-labeled supervision, overturning the assumption that such capabilities must be explicitly taught by humans.",
          "score": 36,
          "created_utc": "2026-02-04 18:44:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kxvfu",
          "author": "Unedited_Sloth_7011",
          "text": "The 2026/01/24 update to the R1 paper: https://arxiv.org/abs/2501.12948",
          "score": 13,
          "created_utc": "2026-02-04 19:07:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3l3ulx",
              "author": "KaroYadgar",
              "text": "oh okay, I was freaking out for a second. New, but not that new.",
              "score": 5,
              "created_utc": "2026-02-04 19:35:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ls3c2",
          "author": "klamir",
          "text": "OK, where can I find these new distilled versions?",
          "score": 3,
          "created_utc": "2026-02-04 21:31:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oztpl",
          "author": "digit1024",
          "text": "who or what is narrating it ? :D it is so strange and unnecessary exaggerated in wrong moments its fun",
          "score": 1,
          "created_utc": "2026-02-05 10:22:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3p0w22",
              "author": "Ralse1",
              "text": "Dr. K√°roly Zsolnai-Feh√©r",
              "score": 1,
              "created_utc": "2026-02-05 10:32:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qtxk0z",
      "title": "Deepseek to learn math",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qtxk0z/deepseek_to_learn_math/",
      "author": "Professional_Lie_494",
      "created_utc": "2026-02-02 15:08:49",
      "score": 54,
      "num_comments": 16,
      "upvote_ratio": 0.94,
      "text": "Hey guys i just wanna say that deepseek is the best companion to study math and computer science  it realy gives you the best way to learn some topics. do anyone feel the same ? ",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qtxk0z/deepseek_to_learn_math/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o362znd",
          "author": "BranSolo7460",
          "text": "Ai is a very useful tool in the right hands. I use it for all kinds of stuff from discussing books, to troubleshooting Linux bugs. Definitely double check answers, sometimes DeepSeek gets mixed up.",
          "score": 13,
          "created_utc": "2026-02-02 15:25:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36buid",
              "author": "Glade_Art",
              "text": "Def agree to that. ",
              "score": 1,
              "created_utc": "2026-02-02 16:07:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o36tet4",
          "author": "XertonOne",
          "text": "Yes I agree.  I had a lot of fun interacting with Deepseek about math.",
          "score": 4,
          "created_utc": "2026-02-02 17:28:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36ug8s",
          "author": "CanaanZhou",
          "text": "DeepSeek is amazing, but I occasionally find it making mistake in areas concerning hard maths and logic, so I still use Gemini for this.",
          "score": 3,
          "created_utc": "2026-02-02 17:33:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36m62s",
          "author": "Konvict_Dino07",
          "text": "I agree, I use deepseek with almost everything. I don't know about math but computer science, it helps a lot",
          "score": 2,
          "created_utc": "2026-02-02 16:54:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36nnyl",
              "author": "Professional_Lie_494",
              "text": "Try it with math topics it he shose some quite good library‚Äôs",
              "score": 2,
              "created_utc": "2026-02-02 17:01:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o37112n",
                  "author": "Konvict_Dino07",
                  "text": "Sure I'll give it a try",
                  "score": 1,
                  "created_utc": "2026-02-02 18:02:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o372mzl",
          "author": "_loid_forger_",
          "text": "I mainly use deepseek in specific areas such as (networking, cyber security, and linux, and it performs well, tho it might hallucinate a bit and make mistakes, but that's rarely happens with me\nI do use it to improve my mathematics skills, and it does a great job explaining stuff, i didn't notice any inaccuracies, but i always double check any output",
          "score": 2,
          "created_utc": "2026-02-02 18:10:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3644px",
          "author": "Condomphobic",
          "text": "Gemini 3.0 Pro with Guided Learning feature is the best tool for me as a computer science major",
          "score": 3,
          "created_utc": "2026-02-02 15:31:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o364ymz",
              "author": "Professional_Lie_494",
              "text": "I understand but you need to see that DeepSeek is free and open wheight, like with a good community you can learn a lot of stuff for kinda free.",
              "score": 5,
              "created_utc": "2026-02-02 15:35:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3660qn",
                  "author": "Condomphobic",
                  "text": "I have 15 free months of AI Pro with Google\n\nEdit: Google offered this to 50+ countries.",
                  "score": 0,
                  "created_utc": "2026-02-02 15:40:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o363723",
          "author": "Professional_Lie_494",
          "text": "Oh yeah for sure",
          "score": 1,
          "created_utc": "2026-02-02 15:26:40",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o3ip9qe",
          "author": "Lux_mirawy_3904",
          "text": "Si, adem√°s te muestra todo el proceso detr√°s y no se confunde en comparaci√≥n con otras IAs. Es muy bueno en ambas ramas, lo tengo ya testeado!",
          "score": 1,
          "created_utc": "2026-02-04 12:30:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qun0wc",
      "title": "Sometimes the examples it gave is really similar to topics in previous conversations",
      "subreddit": "DeepSeek",
      "url": "https://i.redd.it/5cl395m3v8hg1.png",
      "author": "mraltuser",
      "created_utc": "2026-02-03 08:58:03",
      "score": 48,
      "num_comments": 11,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qun0wc/sometimes_the_examples_it_gave_is_really_similar/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3bb6fw",
          "author": "Medium_Tap_971",
          "text": "And here I thought I was making up shit. Glad I am not the only one who feels this.üò≠",
          "score": 11,
          "created_utc": "2026-02-03 09:18:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bcymn",
          "author": "AddyWaggyZaggy",
          "text": "I'm in the same boat. Just specific words it leans towards after heavy usage of those words in a different long chat, or specific metaphors out of the sea of all other possible metaphors. Or the way a fresh chat seems to already know things about me.",
          "score": 5,
          "created_utc": "2026-02-03 09:36:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3cb7cr",
              "author": "jerrygreenest1",
              "text": "You won‚Äôt believe me, but people do use the same words too. Different people same words can you believe it",
              "score": 3,
              "created_utc": "2026-02-03 13:54:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3caryf",
          "author": "jerrygreenest1",
          "text": "I wish Deepseek had some environmental prompt so I could define my preferences in the answers, tell my OS etc, so it knows which tools and ways to solve my question are most relatable. Its context knowledge is not what I fear ‚Äì it‚Äôs what I lack",
          "score": 5,
          "created_utc": "2026-02-03 13:51:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hu1ci",
              "author": "mraltuser",
              "text": "To my perspective, I find context knowledge is a bit annoying (like Google AI) because when you want to find fresh examples for more support or wanted to look things in a new non biased perspective, it just bases what you said before",
              "score": 3,
              "created_utc": "2026-02-04 07:57:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3ov09r",
                  "author": "Kaeiaraeh",
                  "text": "‚ÄúSince you‚Äôre a diehard (whatever smartphone you use) user and you want me to be your rubber duck, here‚Äôs my take on your stomach ache‚Äù",
                  "score": 1,
                  "created_utc": "2026-02-05 09:36:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3fsx71",
          "author": "A_True_Son_of_Terra",
          "text": "Bruh i played a text based rpg on one chat and the session went so long I exceeded the chat size limit \n\nNow everytime I try to play a new session it always ALWAYS reuses the names from that chat for the new one",
          "score": 1,
          "created_utc": "2026-02-03 23:58:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3g4kdj",
          "author": "TresMegisto",
          "text": "If they try to hide the fact that they are doing this, they are doing a very poor job.",
          "score": 1,
          "created_utc": "2026-02-04 01:02:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hzn29",
          "author": "Karasu-Otoha",
          "text": "I started suspecting it, when Deepseek mentioned my specific ailment while answering my question. Except, I didn't say anything about it in that specific new conversation chain. It seems, Deepseek remembers old conversation chains, or it was an unbelievably lucky hallucination guess.",
          "score": 1,
          "created_utc": "2026-02-04 08:50:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ivo2n",
          "author": "Zealousideal-Tap-713",
          "text": "It most certainly does. So does chatgpt. Both have pulled from previous conversations that were saved and deleted to create a resume for me.",
          "score": 0,
          "created_utc": "2026-02-04 13:11:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwqiea",
      "title": "American AI companies in a struggle for survival.",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qwqiea/american_ai_companies_in_a_struggle_for_survival/",
      "author": "B89983ikei",
      "created_utc": "2026-02-05 16:50:25",
      "score": 39,
      "num_comments": 12,
      "upvote_ratio": 0.82,
      "text": "It seems that American AI companies are hitting the panic button! OpenAI has been showing its slow death for some time now... drifting further and further away from the initial ideals it once claimed to follow! Price hikes, less and less democratized AI, advertising... Currently, Perplexity is also showing its desperation; in recent weeks, Perplexity limited its Pro users to 200 interactions per week... which very likely reveals its mid-term ruin. There are rumors that Gemini will also tighten prices and limits for its users...!! Meanwhile... let's hope that Chinese AI companies adopt the opposite philosophy to that of the United States!! I believe that on this current path, we will see China at the absolute forefront of AI. Less brute force, more efficiency, AI truly for everyone...\n\nThe era of infinite investor money for American AI companies is coming to an end!! From now on, we will see more and more American companies closing off their services from the average user, becoming companies focused on security and business applications... As a regular user, you will either pay $300 per month... or use a simple AI... There will be closed American AI and open Global AI from China!! And American companies and the entire American market will try their utmost to limit the implementation of Global AI under the pretext of security risks, attempting to hold the system hostage to their own closed and expensive AIs... (You can note down what I'm telling you).",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qwqiea/american_ai_companies_in_a_struggle_for_survival/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o3s9q3q",
          "author": "Haruna1942",
          "text": "China is adopting more and more AI into manufacturing, logistics and automation. Meanwhile, it doesn't seem that those are viable options in the US. ",
          "score": 4,
          "created_utc": "2026-02-05 20:56:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qumka",
          "author": "Atma_WeaponVI",
          "text": "Yeah I am currently listening to a discussion on this very topic.¬† https://m.youtube.com/watch?v=KKtbq-w4mzg",
          "score": 2,
          "created_utc": "2026-02-05 16:58:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s9t22",
          "author": "Face_dePhasme",
          "text": "Monopoly is not good to development; both geo-models have weaknesses and strengths.  \nMy bet :   \nGemini will survive, Anthropic too. Elon will buy OpenAi  \nDS and others oriental models will keep inovating for few years",
          "score": 1,
          "created_utc": "2026-02-05 20:57:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3tp34r",
              "author": "thefilthycheese",
              "text": "I have a crazy crazy feeling that apple is the one that will buy openai",
              "score": 1,
              "created_utc": "2026-02-06 01:30:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3sci8l",
          "author": "Ok_Impress_8715",
          "text": "So, I'm a big fan of Gemini and DeepSeek. The situation with Gemini is a little complicated. Are they struggling for survival? I wouldn't necessarily say that. Google's [market share](https://www.reddit.com/r/singularity/comments/1q6a3lp/gemini_surpassed_20_traffic_share_threshold_among/) in AI is growing fast. Instead, the company is starting to hit a bottle neck in its infrastructure and the company is looking to [double its size every 6 months](https://www.reddit.com/r/Futurology/comments/1p47cf8/google_tells_employees_it_must_double_capacity/). In fact, Google is hoping to expand their [data centers in space](https://research.google/blog/exploring-a-space-based-scalable-ai-infrastructure-system-design/) to meet the energy demands for high-end AI. Now, are Chinese AI models a serious threat to Western AI companies? Absolutely. There is a reason the Western world is facing a VRAM shortage -- Hint: It is artificially created.   ",
          "score": 1,
          "created_utc": "2026-02-05 21:10:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3sd0jb",
              "author": "B89983ikei",
              "text": "he scarcity would be created artificially, why!? I would genuinely like to understand your point.",
              "score": 1,
              "created_utc": "2026-02-05 21:12:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3qzgsm",
          "author": "Condomphobic",
          "text": "I have 15 months free of Gemini AI Pro. They are far from struggling. They are very generous with limits \n\nI don‚Äôt think OpenAI is struggling either. They have the most users and top of the line features. They also (today) just announced **Frontier**(maybe not useful for average consumers, but sounds revolutionary for enterprises)\n\nAnthropic is profitable and just released Opus 4.6 today (4.5 was already the best model)\n\nPerplexity is a unique edge case. All they do is offer American and Chinese models via API for a unique research experience.",
          "score": 1,
          "created_utc": "2026-02-05 17:21:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3r2bjq",
              "author": "rad_hombre",
              "text": "How‚Äôd you manage to get 15 months of Gemini? I‚Äôm hitting my limits pretty quickly on OpenAI these days. I‚Äôve never hit my limits on Gemini and find it incredibly helpful. Was paying for OpenAI until recently. Both free tier accounts now. Claude is also great. I think if the three i would need to seriously think about it before going back to pay for ChatGPT",
              "score": 1,
              "created_utc": "2026-02-05 17:34:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3r9kj8",
                  "author": "Condomphobic",
                  "text": "They offered it last year for students when they first started promotions.",
                  "score": 2,
                  "created_utc": "2026-02-05 18:07:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3r85l7",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 0,
              "created_utc": "2026-02-05 18:01:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3sswf1",
          "author": "NoobNerf",
          "text": "The big elephant in the room ----  is chinese AI.The growing dominance of China's open-source AI model, which is free and widely adopted, contrasting it with the US closed-source model that relies on monetization and is more capital-intensive. The Chinese model, Quen, is used across Alibaba's ecosystem, including Taobao and Alipay, and is funded through internal fees. This approach allows for greater scalability and flexibility, as the model can be reconfigured and customized, unlike closed-source models. The Chinese model's success is also due to the fact that it is not dependent on external funding, which is a significant advantage. The Chinese AI model's success is also due to the fact that it is not dependent on external funding, which is a significant advantage.\n\nWhere it' going --- the potential for a bifurcated world, where the US and Chinese AI ecosystems diverge. The US model is likened to Apple's ecosystem, which is profitable but less dominant globally. In contrast, the Chinese model is compared to Android and Linux, which are open-source and have achieved widespread adoption. The Chinese AI model's success is also due to the fact that it is not dependent on external funding, which is a significant advantage. The Chinese AI model's success is also due to the fact that it is not dependent on external funding, which is a significant advantage. The Chinese AI model's success is also due to the fact that it is not dependent on external funding, which is a significant advantage.",
          "score": 1,
          "created_utc": "2026-02-05 22:30:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ri9wb",
          "author": "charmander_cha",
          "text": "I hope so, that's why I support China.",
          "score": 1,
          "created_utc": "2026-02-05 18:47:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtzja0",
      "title": "V3.5 before Chinese holidays, and after holidays 4",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qtzja0/v35_before_chinese_holidays_and_after_holidays_4/",
      "author": "BasketFar667",
      "created_utc": "2026-02-02 16:20:45",
      "score": 28,
      "num_comments": 10,
      "upvote_ratio": 0.92,
      "text": "17 February where we will get it. Max -24, medium:22",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qtzja0/v35_before_chinese_holidays_and_after_holidays_4/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o3a1mg9",
          "author": "lomirus",
          "text": "February 17th is Chinese New Year‚Äîhow could they not take a holiday? DeepSeek isn't a deeply commercialized company, and we have no plausible reason to assume they'd be working overtime.\n\nI believe they will release it either a few days before or after the Lunar New Year.",
          "score": 12,
          "created_utc": "2026-02-03 03:16:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3d6lzy",
              "author": "Competitive-Prune349",
              "text": "they can vibe training AI at home ü§î",
              "score": 2,
              "created_utc": "2026-02-03 16:30:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3kq29p",
              "author": "BasketFar667",
              "text": "That's what I'm talking about. Or do a joint release on that day. I assume that more % of the output will be after",
              "score": 1,
              "created_utc": "2026-02-04 18:32:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3av86z",
          "author": "Kind_Stone",
          "text": "Ugh... Source?",
          "score": 7,
          "created_utc": "2026-02-03 06:48:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3m2xuf",
              "author": "BasketFar667",
              "text": "There are no resources, you can just shrug your shoulders. Everything is clear here.",
              "score": 1,
              "created_utc": "2026-02-04 22:23:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o36ffi8",
          "author": "award_reply",
          "text": "![gif](giphy|j4bDhI07jXceMIflif)",
          "score": 3,
          "created_utc": "2026-02-02 16:24:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3b26az",
          "author": "pugoing",
          "text": "Is the information reliable?",
          "score": 2,
          "created_utc": "2026-02-03 07:51:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bpfi8",
          "author": "Haoranmq",
          "text": "V3.5 likely. v4, still far",
          "score": 1,
          "created_utc": "2026-02-03 11:30:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iwnbn",
          "author": "AQEEL23HUSSAIN",
          "text": "the most manipulating and incomplete brand is deepseek",
          "score": 0,
          "created_utc": "2026-02-04 13:17:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3m351x",
              "author": "BasketFar667",
              "text": "why? I'm thinking maybe Gemini? Or... Grok..?",
              "score": 1,
              "created_utc": "2026-02-04 22:24:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qva2ie",
      "title": "Alibaba releases Qwen3-Coder-Next: SWE-Bench 70.6,  slightly above DeepSeek V3.2",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qva2ie/alibaba_releases_qwen3codernext_swebench_706/",
      "author": "DataLearnerAI",
      "created_utc": "2026-02-04 00:56:21",
      "score": 24,
      "num_comments": 1,
      "upvote_ratio": 0.96,
      "text": "Just dropped: Alibaba‚Äôs new open-weight coding model¬†**Qwen3-Coder-Next**, built on the Qwen3-Next-80B-A3B backbone. Quick summary for anyone skimming:\n\n* **What it is:**¬†an 80B parameter sparse MoE coding model aimed at coding agents and serious development workflows\n* **Active parameters / inference cost:**¬†only \\~3B parameters activated per token, so runtime cost is closer to small models while retaining large-model capacity\n* **Context window:**¬†\\~256K tokens natively ‚Äî useful for large repos, multi-file debugging, and long sessions\n* **MoE structure:**¬†512 total experts, \\~10 experts activated per token\n* **Benchmarks:**¬†SWE-Bench Verified =¬†**70.6**, slightly above DeepSeek V3.2 (70.2), competitive with the current top coding models\n\nhttps://preview.redd.it/wvsojtrxldhg1.jpg?width=1458&format=pjpg&auto=webp&s=43acedf59b2efe3807f2169fe61d1d32e63068ad\n\nDataSource:¬†[https://www.datalearner.com/en/benchmark-compare/qwen3-coder-next/deepseek-v3-2/glm-4-7/minimax-m2-1-preview](https://www.datalearner.com/en/benchmark-compare/qwen3-coder-next/deepseek-v3-2/glm-4-7/minimax-m2-1-preview)  \n\n\n[](https://preview.redd.it/alibaba-releases-qwen3-coder-next-80b-moe-coder-model-with-v0-3ks9pp5yjdhg1.png?width=1147&format=png&auto=webp&s=7294815202c9ffe05ee373b7469cdaa4ed18dd09)",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qva2ie/alibaba_releases_qwen3codernext_swebench_706/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o3lvx32",
          "author": "quentolin",
          "text": "How can I use it?",
          "score": 1,
          "created_utc": "2026-02-04 21:49:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qssax4",
      "title": "Don't suddenly switch languages",
      "subreddit": "DeepSeek",
      "url": "https://i.redd.it/4uah2g5c9ugg1.jpeg",
      "author": "More-Explanation2032",
      "created_utc": "2026-02-01 07:51:07",
      "score": 21,
      "num_comments": 7,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qssax4/dont_suddenly_switch_languages/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2ysxrl",
          "author": "HellkerN",
          "text": "Ya it does that, especially if you just paste in console logs or code. Specify \"Answer in English\" just in case.",
          "score": 9,
          "created_utc": "2026-02-01 13:27:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2zbnne",
              "author": "More-Explanation2032",
              "text": "Actually I just added a file for it to review deepthink doesn‚Äôt do this",
              "score": 2,
              "created_utc": "2026-02-01 15:11:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o30mume",
          "author": "OtherProfessional433",
          "text": "Straight up posting your whole screen, damn. Here I am worried about my privacy.",
          "score": 7,
          "created_utc": "2026-02-01 18:49:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2zbivm",
          "author": "FreedomLast4040",
          "text": "the garfield multiverse?",
          "score": 3,
          "created_utc": "2026-02-01 15:11:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y53dy",
          "author": "niniprofesional_",
          "text": "I hate mondays",
          "score": 3,
          "created_utc": "2026-02-01 10:14:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2yxkjb",
          "author": "60746",
          "text": "Add answer in English to the prompt",
          "score": 3,
          "created_utc": "2026-02-01 13:55:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o316dp1",
          "author": "sammoga123",
          "text": "It's not like English is the center of the universe, you know? I have to answer you in English even though I actually speak Spanish, for example, which I also hate.",
          "score": 2,
          "created_utc": "2026-02-01 20:21:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qsqur8",
      "title": "Deepseek OCR updated ?",
      "subreddit": "DeepSeek",
      "url": "https://github.com/deepseek-ai/DeepSeek-OCR",
      "author": "No-Intention-5521",
      "created_utc": "2026-02-01 06:27:28",
      "score": 20,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qsqur8/deepseek_ocr_updated/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o30drlu",
          "author": "Unedited_Sloth_7011",
          "text": "https://github.com/deepseek-ai/DeepSeek-OCR-2 and https://huggingface.co/deepseek-ai/DeepSeek-OCR-2 üòç",
          "score": 3,
          "created_utc": "2026-02-01 18:08:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3a2i5v",
          "author": "lomirus",
          "text": "They've released DeepSeek OCR 2 for a week...",
          "score": 1,
          "created_utc": "2026-02-03 03:21:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3a7ylr",
              "author": "No-Intention-5521",
              "text": "DAMNNN sorry i am not a technical person i just noticed that after my company tech update the software !",
              "score": 1,
              "created_utc": "2026-02-03 03:55:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qu6h92",
      "title": "How Can OpenAI and Anthropic Stay Solvent With Google, xAI, and Meta in High-End Markets, and Chinese/Open Source Devs in the Rest?",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qu6h92/how_can_openai_and_anthropic_stay_solvent_with/",
      "author": "andsi2asi",
      "created_utc": "2026-02-02 20:22:50",
      "score": 19,
      "num_comments": 12,
      "upvote_ratio": 0.85,
      "text": "\n\n\n\nThis is a question I've been struggling with a lot recently, and I don't see a path to sustained profitability for either OpenAI or Anthropic.\n\nFor them to meet their debt obligations and start turning a profit, OpenAI needs to move way beyond ChatGPT and Anthropic needs to move way beyond coding. \n\nFor both this means securing high-end markets like healthcare, defense, education and government. But Google, xAI and Meta, who already have massive revenue streams with no debt burdens, are not going to just let this happen. \n\nOne might argue that if OpenAI and Anthropic just build better AIs, they can secure those markets. But while ChatGPT and Claude coding models both enjoy a first mover advantage, it is quickly evaporating. The reason is because the gap between benchmark leaders and competing AIs is narrowing rapidly. Here are some examples of this narrowing between 2024 and 2026:\n\nARC-AGI-2: The gap between the #1 and #2 models narrowed from 30 points to 8.9 points.\n\nHumanity‚Äôs Last Exam: The gap between the top three models dropped from 15 points to 6 points.\n\nSWE-bench Verified: The gap between the 1st and 10th ranked models narrowed from 40 points to 12 points.\n\nGPQA: The gap between proprietary leaders and top open-weights models narrowed to 4‚Äì6%.\n\nChatbot Arena: The Elo difference between the #1 and #10 models narrowed from 11.9% to 5.4%; the gap between the top two models narrowed to less than 0.7%.\n\nHumanEval: The gap among the top five models narrowed to less than 3%.\n\nBecause the rate of this narrowing is also accelerating, by the end of 2026 neither OpenAI nor Anthropic seem assured high-end markets simply by building better models than Google, xAI and Meta.\n\nNow let's move on to mid-tier and low-end markets that comprise about 70% of the enterprise space. It's probably safe to say that Chinese developers, and perhaps an unexpectedly large number of open source startups, will dominate these markets.\n\nI think you can see why I'm so baffled. How can they prevail over Google, xAI and Meta at the high-end and Chinese/open source developers at the mid-tier and low end? How are they supposed to turn a profit without winning those markets?  \n\nAs I really have no answers here, any insights would be totally appreciated!\n\n\n\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qu6h92/how_can_openai_and_anthropic_stay_solvent_with/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o3b86he",
          "author": "CCP_Annihilator",
          "text": "Meta in high end market. Lol, lmfao even.",
          "score": 3,
          "created_utc": "2026-02-03 08:49:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3gjo0w",
              "author": "SalaciousStrudel",
              "text": "Exactly, the only thing high end is their spending.",
              "score": 2,
              "created_utc": "2026-02-04 02:28:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o394ym0",
          "author": "soumen08",
          "text": "Because GPT5.1/2 are the only seriously intelligent models when you get beyond benchmarks. I actually used to use 2.5 pro, but 3 pro is a meaningful regression relative to 2.5 pro for out of scope tasks.",
          "score": 2,
          "created_utc": "2026-02-03 00:11:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o39u8a8",
              "author": "Kingwolf4",
              "text": "T.H.I.S",
              "score": 2,
              "created_utc": "2026-02-03 02:33:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3b78yl",
              "author": "MikeWise1618",
              "text": "Not for coding. Anthropic rules.",
              "score": 2,
              "created_utc": "2026-02-03 08:40:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o38jmwf",
          "author": "Ok_Impress_8715",
          "text": "OpenAI is betting on the \"To Big To Fail\" model. That's why Sam is trying to thread it into everything. It might not be #1, but at least it's not gone.¬†",
          "score": 1,
          "created_utc": "2026-02-02 22:18:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39h5de",
          "author": "ExpertPerformer",
          "text": "The only way for AI companies to survive long-term is to carve out their own niches. Everyone competes for benchmarks, but also on features now. Gemini, Grok, ChatGPT, etc. are all multi modal while most of the cheap opensource alternatives only have text still. The big US LLM companies have the business enterprise market monetized and a lot of that is for security reasons.\n\nDeepSeek carves its niche by targeting towards the budget consumers and roleplayers.",
          "score": 1,
          "created_utc": "2026-02-03 01:18:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3a17g9",
          "author": "Emergency-Pomelo-256",
          "text": "See OpenAI started this, if they flops, it will be like a bubble pop and crash of all of these AI companies that‚Äôs worth trillions, so it‚Äôs that they will be saved by Nvidia or Government, to save bubble economy.",
          "score": 1,
          "created_utc": "2026-02-03 03:13:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3b1l9y",
              "author": "andsi2asi",
              "text": "It's not like the rest of the AI space needs them to exist. If they are no longer there, the other developers will absorb the demand and investment.",
              "score": 2,
              "created_utc": "2026-02-03 07:46:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3b23nm",
                  "author": "Emergency-Pomelo-256",
                  "text": "Nah man most circular deals is connected to OpenAI if they fall, the hype & investment for AI will go way down, since most AI not profitable and going with VC fund, a lot them will also pop ü•§. Yes of course when it‚Äôs over large already profitable ones will be still there.",
                  "score": 1,
                  "created_utc": "2026-02-03 07:50:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3amwrt",
          "author": "Alacritous69",
          "text": "Why do you care? Struggling with? WTF, man?",
          "score": 0,
          "created_utc": "2026-02-03 05:39:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qw5nm4",
      "title": "DeepSeek-v3.2 matches SOTA ChatGPT, Claude, and Gemini models at medical question accuracy",
      "subreddit": "DeepSeek",
      "url": "https://i.redd.it/zbilo2oshkhg1.png",
      "author": "docere",
      "created_utc": "2026-02-05 00:08:01",
      "score": 18,
      "num_comments": 0,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qw5nm4/deepseekv32_matches_sota_chatgpt_claude_and/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qwnu5b",
      "title": "If OpenAI has begun to freak out, their shrinking ChatGPT market share is good reason.",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qwnu5b/if_openai_has_begun_to_freak_out_their_shrinking/",
      "author": "andsi2asi",
      "created_utc": "2026-02-05 15:12:17",
      "score": 15,
      "num_comments": 5,
      "upvote_ratio": 0.89,
      "text": "\n\n\nThere are good reasons why OpenAI recently opted to launch unpopular ads and revenue sharing.\n\nLast quarter, Google reported 650 million monthly active users for Gemini, indicating substantial growth in a short period. In comparison, ChatGPT is estimated to have around 810 million MAUs in late 2025.\n\nHere are the figures over the last year in terms of market share:\n\nChatGPT: 68% share in January 2026, down from 87.2% in January 2025.\n\nGoogle Gemini: 18.2% share in January 2026, up from 5.4% in January 2025. \n\nDeepSeek, Copilot, Claude, Perplexity, etc: up from 7.4% to 14%. \n\nBut that's just the beginning. A conservative estimate of this trend continuing into 2027 shows the following: \n\nChatGPT: 1.0‚Äì1.1B monthly active users in 2027, with roughly 50‚Äì55% market share.\n\nGemini: 0.9‚Äì1.1B monthly active users in 2027, with roughly 25‚Äì30% market share.\n\nCopilot, Claude, DeepSeek, Perplexity, etc.): together around 20‚Äì25% market share in 2027.\n\nI hope OpenAI has some very big rabbits to pull out of some very big hats this year and next, because it looks like they're going to need them.",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qwnu5b/if_openai_has_begun_to_freak_out_their_shrinking/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o3rnmnp",
          "author": "Number4extraDip",
          "text": "The market share calculation is ridiculous. Because every person ever using google is using gemini without necessarily seeing it that way",
          "score": 1,
          "created_utc": "2026-02-05 19:11:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3rrjbq",
              "author": "Desdaemonia",
              "text": "And Gemini for search results is getting better but that just means it's not always completely terrible. Lol. Though I feel like anthropic is making moves to pick up gpt users.",
              "score": 1,
              "created_utc": "2026-02-05 19:30:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3slaqo",
                  "author": "Number4extraDip",
                  "text": "Saas is kind of dead. With so many free options. The only play left is enterprise and quality. And surprisingly without a proper moat, unlike OpenAI, they are doing quite well with important partnerships and integrations",
                  "score": 1,
                  "created_utc": "2026-02-05 21:52:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3s4y8f",
              "author": "Steamdecker",
              "text": "By your reasoning, Gemini should have way bigger market share than just 18.2%.  \nFact of the matter is that we mainly search for basic data/stat/summary for certain topics, which Gemini is good for.",
              "score": 1,
              "created_utc": "2026-02-05 20:33:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3slno6",
                  "author": "Number4extraDip",
                  "text": "Im assuming this statistic implied specifically the main chat app. Which could easily paint such a picture in open ai favor. But then it overlooked how ubiquitous Gemini is across the google ecosystem. Many people log into OpenAI using google Oauth.",
                  "score": 1,
                  "created_utc": "2026-02-05 21:54:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qrngn4",
      "title": "Man this is the funniest thing ever",
      "subreddit": "DeepSeek",
      "url": "https://i.redd.it/wkr8gxrbzkgg1.png",
      "author": "No_Vehicle5225",
      "created_utc": "2026-01-31 00:39:26",
      "score": 11,
      "num_comments": 6,
      "upvote_ratio": 0.77,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Funny",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qrngn4/man_this_is_the_funniest_thing_ever/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2qwem0",
          "author": "Medium_Tap_971",
          "text": "This is actually cute. :3",
          "score": 7,
          "created_utc": "2026-01-31 06:09:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2qxree",
              "author": "fofo9683",
              "text": "Now think how would grok answer to this :))",
              "score": 3,
              "created_utc": "2026-01-31 06:21:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2qzqn4",
                  "author": "Micho86",
                  "text": "With an underage Ai nude",
                  "score": 6,
                  "created_utc": "2026-01-31 06:37:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o33wiw8",
          "author": "No_Vehicle5225",
          "text": "You met me at a very Chinese part in my life¬†",
          "score": 2,
          "created_utc": "2026-02-02 05:31:25",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o2zx1dj",
          "author": "Historical_Tear4677",
          "text": "AI always trying to output longer than it should.",
          "score": 1,
          "created_utc": "2026-02-01 16:52:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qs6a65",
      "title": "The insurmountable hurdles OpenAI and Anthropic are up against as businesses adopt AI in 2026 and 2027",
      "subreddit": "DeepSeek",
      "url": "https://www.reddit.com/r/DeepSeek/comments/1qs6a65/the_insurmountable_hurdles_openai_and_anthropic/",
      "author": "andsi2asi",
      "created_utc": "2026-01-31 16:08:06",
      "score": 10,
      "num_comments": 7,
      "upvote_ratio": 0.86,
      "text": "\n\n\n\nFirst, I've limited this to OpenAI and Anthropic, not including Google or xAI, because the latter have revenue streams that let them navigate the next few years without the cash crunch that the former will face because of their huge debt burdens.\n\nTheir competition will not come from Google and xAI, who will be facing the exact same monumental headwinds over the next few years. Their competition will come from open source and Chinese developers who will flood the market with small, dedicated, much less expensive models. \n\nThe reasoning for this is obvious. Let's say your company needed some accounting services. Would you obtain them from a small accounting firm who just does accounting, and so does it very well? Or would you obtain them from a large corporate conglomerate that markets every conceivable product like healthcare, scientific discovery, building construction, restaurant services, and lawn care?\n\nThis analogy highlights the all-important difference between LLMs that do everything and SLMs that do just one thing, but do it very well. To dominate the enterprise space, Open source and Chinese developers will be building very small language models for very specific niche business tasks that run locally at a fraction of the cost of LLMs.\n\nYou might be asking why OpenAI and Anthropic can't market their own competitive SLMs. The answer to this is simple. There are many thousands of these specific narrow domain business tasks that SLMs will be built to excel at, and the bloated bureaucracies that come with being a major developer like OpenAI and Anthropic render such an ambition a virtually impossible logistical nightmare. \n\nTo better illustrate this, here are some examples of the kinds of business departments within which these specific tasks are performed; human resources, finance and accounting, operations, sales, marketing, information technology, customer service, R&D, legal and compliance and supply chain and logistics.\n\nBut that's just the beginning. Taking finance and accounting as an example, here are some of the more specific tasks within those departments that SLMs will be built to perform; invoice data extraction, transaction categorization, bank reconciliation matching, expense report auditing, duplicate payment detection, purchase order matching, regulatory compliance monitoring, and it goes on and on.\n\nWhy can't LLMs perform all of those very specific tasks as well as SLMs? There are many reasons. Here are just a few of the advantages that SLMs offer; lower latency and faster processing, reduced computational and operational costs, higher accuracy through specialized fine-tuning, enhanced data privacy and local deployment options, lower energy consumption and infrastructure requirements.\n\nYou probably now understand why it would be virtually impossible for OpenAI and Anthropic to compete with SLMs on these multitude of very specific business use cases. \n\nIt is because the AI giants can't possibly market LLMs to compete in all of these very specific business use cases that over the next 2 years there will be an explosion of lean open source and Chinese startups that will build SLMs dedicated to doing one specific business task exceptionally well at a very low cost. \n\nWhat can the AI giants do, if anything, to become competitive in this emerging narrow domain enterprise space? That is the trillion dollar question before them.\n\n \n\n\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion ",
      "permalink": "https://reddit.com/r/DeepSeek/comments/1qs6a65/the_insurmountable_hurdles_openai_and_anthropic/",
      "domain": "self.DeepSeek",
      "is_self": true,
      "comments": [
        {
          "id": "o2wwktl",
          "author": "RedditSellsMyInfo",
          "text": "Many businesses don't trust Chinese companies to host the models and don't want to bother with custom hosting options. \n\nSo many companies buy Microsoft products that everyone hates when there are likely cheaper better alternatives but IT doesn't want to deal with managing procurement and will pay more for easy to manage solutions.\n\nI think OpenAi will struggle but anthropic has models that are much more enjoyable to be deal with. I find I'm frustrated with Claude so much less than any other model. That alone is worth an extra $100/mo for me. \n\nWith the ammount of value you can get out of AI, if you are doing that highly profitable, having the best AI models that have a full suite of services that are integrated like Claude Cowork are totally worth it.",
          "score": 3,
          "created_utc": "2026-02-01 04:04:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2x1qnm",
              "author": "andsi2asi",
              "text": "Look back to the decades of outsourcing where many American manufacturers went to the Chinese because they were building better products at a lower cost. I think politics have made people a bit afraid of the Chinese recently, but ultimately higher ROIs will replace that distrust. Yeah Anthropic is really good at UI, but that's not something that is so difficult for their competitors to emulate.",
              "score": 1,
              "created_utc": "2026-02-01 04:39:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2xm6gm",
                  "author": "ExactlyAbstract",
                  "text": "Regulatory capture is a real thing.\n\nIt is going to be easier for the majors players to get licensed or certified by regulatory authorities. (Whether above or below the table.) That's a huge selling point for companies.\n\nI agree smaller models make sense in many cases. And even more so private self hosted models. But sometimes you have to fit inside the frameworks forced on you.",
                  "score": 2,
                  "created_utc": "2026-02-01 07:19:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2ziryf",
                  "author": "HelpfulSource7871",
                  "text": "Only ROI? Chinese tech today is not 30 years agoüòÅ",
                  "score": 1,
                  "created_utc": "2026-02-01 15:46:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2zoeit",
          "author": "BidWestern1056",
          "text": "agreed and aiming to lead a lot of this for research-specific coding/slms\n\n[https://github.com/npc-worldwide/npcpy](https://github.com/npc-worldwide/npcpy)\n\n[https://github.com/npc-worldwide/npcsh](https://github.com/npc-worldwide/npcsh)\n\n[https://github.com/npc-worldwide/incognide](https://github.com/npc-worldwide/incognide)",
          "score": 1,
          "created_utc": "2026-02-01 16:12:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36xfs8",
          "author": "kievmozg",
          "text": "DeepSeek's recent success is the ultimate proof of this.\n‚ÄãThe 'bigger is better' era is dying for business use cases. I see this daily with my own SaaS (ParserData). Clients stopped caring about 'reasoning capabilities' of GPT-4 now they just want speed, low cost, and zero hallucinations for their documents.\n‚ÄãRenting a massive cluster to parse a simple invoice is economically insane. The future belongs to efficient, purpose-built pipelines (like DeepSeek or specialized fine-tunes), not bloated generalist models.",
          "score": 1,
          "created_utc": "2026-02-02 17:46:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}